"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Eva: A Virtual pet in Augmented Reality","A. Costa; R. Lima; S. Tamayo","SIDIA, Instituto de Ciência e Tecnologia Manaus, Manaus, Brazil; SIDIA, Instituto de Ciência e Tecnologia Manaus, Manaus, Brazil; SIDIA, Instituto de Ciência e Tecnologia Manaus, Manaus, Brazil","2019 21st Symposium on Virtual and Augmented Reality (SVR)","5 Dec 2019","2019","","","47","51","Augmented Reality applications are present in our daily lives and the smartphones are nowadays the common tool to make this possible. Several applications are being built for different areas, like medicine, engineering, education and entertainment. The main purpose of this paper is to present an Open Source application called Eva, which is a virtual pet that lives in the Augmented Reality world. This application is being built for Android devices and its main features are described in this paper as well.","","978-1-7281-5434-3","10.1109/SVR.2019.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8921099","augmented reality;mobile devices;virtual pet;entertainment","Three-dimensional displays;Androids;Humanoid robots;Bluetooth;Visualization;Smart phones;Augmented reality","augmented reality;mobile computing;smart phones","Augmented Reality applications;smartphones;common tool;education;entertainment;Open Source application;Eva;virtual pet;Augmented Reality world","","2","","","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Stepping into the operating theater: ARAV — Augmented Reality Aided Vertebroplasty","C. Bichlmeier; B. Ockert; S. M. Heining; A. Ahmadi; N. Navab","Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universitat München, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universitat München, Germany; Trauma Surgery Department, Klinikum Innenstadt, LMU München, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universitat München, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universitat München, Germany","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","165","166","Augmented reality (AR) for preoperative diagnostics and planning, intra operative navigation and postoperative follow-up examination has been a topic of intensive research over the last two decades. However, clinical studies showing AR technology integrated into the real clinical environment and workflow are still rare. The incorporation of an AR system as a standard tool into the real clinical workflow has not been presented so far. This paper reports on the strategies and intermediate results of the ARAV - augmented reality aided vertebroplasty project that has been initiated to make an AR system based on a stereo video see-through head mounted display that is permanently available in the operating room (OR).","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637348","H.5.1 [Information Interfaces and Presentation]: Artificial, augmented, and virtual realities;J.3 [Life and Medical Sciences]","Surgery;Fault currents;Computed tomography;Current transformers;Circuit faults;Biomedical imaging;Augmented reality","augmented reality;medical computing","ARAV;augmented reality aided vertebroplasty;preoperative diagnostics;preoperative planning;intraoperative navigation;postoperative follow-up examination;operating room","","13","","9","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Vision based people tracking for ubiquitous Augmented Reality applications","C. A. L. Waechter; D. Pustka; G. J. Klinker","Fachgebiet Augmented Reality, Technische Universität München, Germany; Fachgebiet Augmented Reality, Technische Universität München, Germany; Fachgebiet Augmented Reality, Technische Universität München, Germany","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","221","222","The task of vision based people tracking is a major research problem in the context of surveillance applications or human behavior estimation, but it has had only minimal impact on (Ubiquitous) Augmented Reality applications thus far. Deploying stationary infrastructural cameras within indoor environments for the purpose of Augmented Reality could provide a users' devices with additional functionality that a small device and mobile sensors cannot provide to its user. Therefore people tracking could be expected to become an ubiquitously available infrastructural element in buildings since surveillance cameras are widely used. The use for scenarios indoors or close to buildings is obvious. We present and discuss several different ways where people tracking in real-time could influence the fields of Augmented Reality and further vision based applications.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336452","Augmented Reality;People Tracking;Sensor Fusion","Augmented reality;Cameras;Surveillance;Sensor fusion;Global Positioning System;Target tracking;Particle filters;Image analysis;Sensor systems;Fuses","augmented reality;cameras;computer vision;sensor fusion;surveillance;tracking;ubiquitous computing","vision based people tracking;ubiquitous augmented reality;surveillance;human behavior estimation;stationary infrastructural cameras;mobile sensors;sensor fusion","","8","1","7","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Advanced training methods using an Augmented Reality ultrasound simulator","T. Blum; S. M. Heining; O. Kutter; N. Navab","Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Trauma Surgery Department, Klinikum Innenstadt, LMU München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","177","178","Ultrasound (US) is a medical imaging modality which is extremely difficult to learn as it is user-dependent, has low image quality and requires much knowledge about US physics and human anatomy. For training US we propose an Augmented Reality (AR) ultrasound simulator where the US slice is simulated from a CT volume. The location of the US slice inside the body is visualized using contextual in-situ techniques. We also propose advanced methods how to use an AR simulator for training.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336476","H.5.1 [Information Interfaces and Presentation]: Artificial, augmented, and virtual realities;J.3 [Life and Medical Sciences]: —","Augmented reality;Ultrasonic imaging;Medical simulation;Biological system modeling;Biomedical imaging;Image quality;Physics;Human anatomy;Computed tomography;Visualization","augmented reality;biomedical ultrasonics;computer based training;data visualisation;medical image processing;teaching","augmented reality ultrasound simulator;medical imaging;training method;image quality;US physics-and-human anatomy;CT volume;US slice;contextual in-situ visualization;teaching","","30","","10","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Superman-like X-ray vision: Towards brain-computer interfaces for medical augmented reality","T. Blum; R. Stauder; E. Euler; N. Navab","Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Germany; Surgery Department, LMU München, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Germany","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","271","272","This paper describes first steps towards a Superman-like X-ray vision where a brain-computer interface (BCI) device and a gaze-tracker are used to allow the user controlling the augmented reality (AR) visualization. A BCI device is integrated into two medical AR systems. To assess the potential of this technology first feedback from medical doctors is gathered. While in this pilot study not the full range of available signals but only electromyographic signals are used, the medical doctors provided very positive feedback on the use of BCI for medical AR.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402569","H.5.1 [Information Interfaces and Presentation]: Artificial, augmented, and virtual realities—","Biomedical imaging;Surgery;Visualization;Electromyography;Augmented reality;X-ray imaging;Monitoring","augmented reality;brain-computer interfaces;data visualisation;electromyography;medical signal processing;object tracking;visual evoked potentials","brain-computer interface;medical augmented reality;Superman-like X-ray vision;gaze-tracker;AR visualization;BCI device;medical AR system;electromyographic signal","","21","","9","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Inverse Augmented Reality: A Virtual Agent's Perspective","Z. Zhang; D. Weng; H. Jiang; Y. Liu; Y. Wang","Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","154","157","We propose a framework called inverse augmented reality (IAR) which describes the scenario that a virtual agent living in the virtual world can observe both virtual objects and real objects. This is different from the traditional augmented reality. The traditional virtual reality, mixed reality and augmented reality are all generated for humans, i.e., they are human-centered frameworks. On the contrary, the proposed inverse augmented reality is a virtual agent-centered framework, which represents and analyzes the reality from a virtual agent's perspective. In this paper, we elaborate the framework of inverse augmented reality to argue the equivalence of the virtual world and the physical world regarding the whole physical structure.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699316","augmented reality;inverse;virtual agent","Augmented reality;Physics;Virtual environments;Evolution (biology);Augmented virtuality;Mathematical model","augmented reality;human computer interaction;multi-agent systems","inverse augmented reality;virtual agent-centered framework;virtual world;virtual objects;traditional augmented reality;traditional virtual reality;mixed reality;IAR;human-centered frameworks","","12","","13","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"An Industrial Augmented Reality Solution For Discrepancy Check","P. Georgel; P. Schroeder; S. Benhimane; S. Hinterstoisser; M. Appel; N. Navab","Chair for Computer Aided Medical Procedures and Augmented Reality, TUM Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, TUM Munich, Germany; Siemens Corporate Technology, Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, TUM Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, TUM Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, TUM Munich, Germany","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","111","115","Construction companies employ CAD software during the planning phase, but what is finally built often does not match the original plan. The procedure of validating the model is called ""discrepancy check"". The system proposed here allows the user to easily obtain an augmentation in order to find differences between the planned 3D model and the built items. The main difference to previous body of work in this field is the emphasis on usability and acceptance of the solution. While standard image-based solutions use markers or rely on a ""perfect"" 3D model to find the pose of the camera, our software uses anchor-plates. Anchor-Plates are rectangular structures installed on walls and ceiling in the majority of industrial edifices. We are using them as landmarks because they are the most reliable components often used as reference coordinates by constructors. Furthermore, for real industrial applications, they are the most suitable solutions in terms of general applicability. Unfortunately, they have not been designed with computer vision applications in mind. On the contrary, they are often made or painted in such way that they are not easily popping out. They are therefore difficult targets to segment and to track. This paper proposes a solution to extract and match them to their 3D counterparts. We created a software that uses the detected structures for pose estimation and image augmentation. The software has been successfully employed to find discrepancies in several rooms of two industrial plants.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538834","H.5.1 [Multimedia Information Systems];H.5.2 [User Interfaces];I.4.6 [Segmentation];I.4.9 [Applications]","Augmented reality;Application software;Construction industry;Usability;Software standards;Cameras;Computer vision;Image segmentation;Target tracking;Industrial plants","augmented reality;CAD;computer vision;construction industry;production engineering computing","industrial augmented reality solution;discrepancy check;CAD software;construction companies;anchor-plates;computer vision","","26","7","18","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"mirracle: An augmented reality magic mirror system for anatomy education","T. Blum; V. Kleeberger; C. Bichlmeier; N. Navab","Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","115","116","We present an augmented reality magic mirror for teaching anatomy. The system uses a depth camera to track the pose of a user standing in front of a large display. A volume visualization of a CT dataset is augmented onto the user, creating the illusion that the user can look into his body. Using gestures, different slices from the CT and a photographic dataset can be selected for visualization. In addition, the system can show 3D models of organs, text information and images about anatomy. For interaction with this data we present a new interaction metaphor that makes use of the depth camera. The visibility of hands and body is modified based on the distance to a virtual interaction plane. This helps the user to understand the spatial relations between his body and the virtual interaction plane.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180909","H.5.1 [Information Interfaces and Presentation]: Artificial, augmented, and virtual realities","Visualization;Glass;Computed tomography;Mirrors;Cameras;Augmented reality;Education","augmented reality;biomedical education;cameras;computer aided instruction;computerised tomography;data visualisation","mirracle;anatomy education;augmented reality magic mirror system;depth camera;pose tracking;large display;volume visualization;CT dataset;CT slices;photographic dataset;3D models;organs;text information;interaction metaphor","","114","","8","IEEE","12 Apr 2012","","","IEEE","IEEE Conferences"
"User awareness of tracking uncertainties in AR navigation scenarios","F. Pankratz; A. Dippon; T. Coskun; G. Klinker","Fachgebiet Augmented Reality, Technische Universität München, Garching b. München, Germany; Fachgebiet Augmented Reality, Technische Universität München, Garching b. München, Germany; Fachgebiet Augmented Reality, Technische Universität München, Garching b. München, Germany; Fachgebiet Augmented Reality, Technische Universität München, Garching b. München, Germany","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","285","286","Current Augmented Reality navigation applications for pedestrians usually do not visualize tracking errors. However, tracking uncertainties can accumulate so that the user is presented with a distorted impression of navigation accuracy. To increase the awareness of users about potential imperfections of the tracking at a given time, we alter the visualization of the navigation system. We developed four visualization and error visualization concepts and used a controlled Mixed Reality environment to conduct a pilot study. We found that, while error visualization has the potential to improve AR navigation systems, it is difficult to find suitable visualizations, which are correctly understood among the users.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671807","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671807","","Visualization;Navigation;Target tracking;Augmented reality;Accuracy;Color","augmented reality;navigation;pedestrians","user awareness;tracking uncertainties;AR navigation scenarios;augmented reality navigation applications;pedestrians;tracking errors;navigation accuracy;error visualization;mixed reality environment;AR navigation systems","","8","","6","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Industrial Augmented Reality: Requirements for an Augmented Reality Maintenance Worker Support System","M. Lorenz; S. Knopp; P. Klimant","Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","151","153","Supporting maintenance workers with Augmented Reality (AR) applications has always been one key use case to demonstrate the advantages of AR. However, such AR applications are still not widely used in industry, which may lay at the complex industrial requirements. We present the user, technical, environmental and regulative requirements for an AR maintenance worker support system, which were gathered by analyzing three diverse production sites.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699183","Augmented Reality;Requirements;Maintenance;Service;[Human-centered computing]: Mixed / augmented reality;[Computer systems organization]: Embedded and cyber-physical systems","Maintenance engineering;Augmented reality;Task analysis;Safety;Gears;Glass","augmented reality;maintenance engineering;personnel;production engineering computing","AR applications;complex industrial requirements;technical requirements;environmental requirements;regulative requirements;AR maintenance worker support system;maintenance workers;augmented reality applications;augmented reality maintenance worker support system;industrial augmented reality;production sites","","33","","12","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Augmented Reality (AR) joiners, a novel expanded cinematic form","H. Papagiannis","Augmented Reality Laboratory, Department of Film, Faculty of Fine Arts, York University, Canada","2009 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media and Humanities","17 Nov 2009","2009","","","39","42","Traditionally belonging to Computer Science and Engineering disciplines, Augmented Reality (AR) is beginning to emerge in the field of Visual Art. The creative possibilities for this new media form are rich and vast extending across and in between disciplines including cinema, photography, and interactive digital media. This paper will focus on my AR Joiner series, which applies 2D planar video to compose novel scenes utilizing multiple adjoined AR markers across both physical and virtual time and space to create new experiences of seeing.","2381-8360","978-1-4244-5508-9","10.1109/ISMAR-AMH.2009.5336728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336728","Augmented Reality;Interactive Digital Arts;New Media Art;Contemporary Art Practice;J.5 [Art and Humanities];Fine Arts;H.5.1 [Information Interfaces and Presentation];Multimedia Information Systems-augmented reality","Augmented reality;Layout;Cameras;Motion pictures;Photography;Production;Computer science;Digital art;Multimedia systems;Rivers","augmented reality;image fusion;photography","augmented reality joiners;cinematic form;visual art;cinema;AR joiner series;2D planar video;photography;interactive digital media","","4","","20","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Augmented Reality in Education Learning and Training","D. N. Nasser","Birzeit University, Birzeit, PS","2018 JCCO Joint International Conference on ICT in Education and Training, International Conference on Computing in Arabic, and International Conference on Geocomputing (JCCO: TICET-ICCA-GECO)","30 May 2019","2018","","","1","7","The uses and applications of VR and AR technologies have been widespread in the last few years. One of its most important areas of use is the use of virtual and augmented reality in education, learning and training. Hence, this research paper examines the latest developments and the scientific findings in the field of augmented software industry, its applications, and uses in teaching, learning and training. Tens of augmented reality applications, their areas of application, and practical uses were studied with the aim of: Identifying strengths and weaknesses and selecting the appropriate ones in teaching, learning and training. To achieve the objectives of the research: The method of content analysis based on the applied approach was used, The researcher recommended: It is necessary to adopt the application and usage of augmented reality technologies in education, learning and training at the highest levels, and recommended the use of a set of software and platforms that would enhance the quality of teaching, learning and training and improve its outcomes.","","978-1-5386-6880-1","10.1109/ICCA-TICET.2018.8726192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726192","Teaching;Learning;Training;Augmented reality;Virtual reality","Augmented reality;Training;Companies;Software;Resists","augmented reality;computer based training;computer science education;DP industry;teaching","augmented reality technologies;education learning;augmented software industry;education training;virtual reality technologies","","6","","","IEEE","30 May 2019","","","IEEE","IEEE Conferences"
"Altered reality: Augmenting and diminishing reality in real time","C. W. M. Leão; J. P. Lima; V. Teichrieb; E. S. Albuquerque; J. Kelner","Virtual Reality and Multimedia Research Group, Informatics Center – Federal University of Pernambuco, Brazil; Virtual Reality and Multimedia Research Group, Informatics Center – Federal University of Pernambuco, Brazil; Virtual Reality and Multimedia Research Group, Informatics Center – Federal University of Pernambuco, Brazil; Virtual Reality and Multimedia Research Group, Informatics Institute-Federal University of Goiás, Brazil; Virtual Reality and Multimedia Research Group, Informatics Center – Federal University of Pernambuco, Brazil","2011 IEEE Virtual Reality Conference","29 Apr 2011","2011","","","219","220","Augmented Reality applications overlap virtual objects over a real scene, taking into account the context, in order to add information to the end user. Nowadays, more advanced applications also make use of Diminished Reality that removes real objects from a scene. This paper describes an approach that combines Augmented Reality and Diminished Reality techniques to modify real objects present in applications. The proposed approach removes an object and replaces it with its purposely-modified replica. The solution uses dynamic texture techniques and Inpaint to enhance the visual response of the modification performed. The results are promising considering both realism of the modified real object and performance of the application.","2375-5334","978-1-4577-0038-5","10.1109/VR.2011.5759477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759477","augmented reality;diminished reality;physically-based simulation","Augmented reality;Real time systems;Lighting;Solid modeling;Three dimensional displays;Multimedia communication","augmented reality;image texture","altered reality;augmented reality applications;virtual objects;diminished reality;dynamic texture techniques;visual response","","8","3","6","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"[POSTER] AR4AR: Using Augmented Reality for guidance in Augmented Reality Systems Setup","F. Pankratz; G. Klinker","Fachgebiet Augmented Reality, Technische Universität München, Garching b. München, Germany; Fachgebiet Augmented Reality, Technische Universität München, Garching b. München, Germany","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","140","143","AR systems have been developed for many years now, ranging from systems consisting of a single sensor and output device to systems with a multitude of sensors and/or output devices. With the increasing complexity of the setup, the complexity of handling the different sensors as well as the necessary calibrations and registrations increases accordingly. A much needed (yet missing) area of augmented reality applications is to support AR system engineers when they set up and maintain an AR system by providing visual guides and giving immediate feedback on the current quality of their calibration measurements. In this poster we present an approach to use Augmented Reality itself to support the user in calibrating an Augmented Reality system.","","978-1-4673-7660-0","10.1109/ISMAR.2015.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328081","","Cameras;Calibration;Target tracking;Augmented reality;Three-dimensional displays;Current measurement;Visualization","augmented reality;calibration","augmented reality systems setup;AR systems;visual guides;calibration measurements","","4","","15","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"“Wonder Turner” and “The Amazing Cinemagician” augmented reality and mixed reality art installations","H. Papagiannis","York University, Toronto, Canada","2010 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","22 Nov 2010","2010","","","27","32","This paper discusses the approach, evolution and exhibition of the augmented reality art installation Wonder Turner and mixed reality work The Amazing Cinemagician at the Ontario Science Centre Idea Gallery from May 29 through September 6, 2010 in Toronto, Canada, by artist and researcher Helen Papagiannis. Both interactive artworks are featured in the exhibition entitled, The Amazing Cinemagician: New Media Meets Victorian Magic by Helen Papagiannis in association with the Augmented Reality Lab at York University.","2381-8360","978-1-4244-9342-5","10.1109/ISMAR-AMH.2010.5643297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643297","Augmented Reality;Mixed Reality;Art;exhibition;interactive;RFID;FogScreen","Films;Motion pictures;Art;Radiofrequency identification;Videos;Augmented reality;Media","art;augmented reality;exhibitions","mixed reality art installation;augmented reality art installation wonder turner;amazing cinemagician;ontario science centre idea gallery;Helen Papagiannis;interactive artworks;victorian magic;York University","","","","10","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"ARpm: an augmented reality interface for polygonal modeling","P. Fiala; N. Adamo-Villani","Purdue Univ., West Lafayette, IN, USA; Purdue University, USA","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","196","197","We present a prototype system called ARpm, (augmented reality for polygonal modeling). Created as a front-end to a commercially available 3D animation program (3D Studio Max), it does not require it's modification through inaccessible software code. Users look through a head mounted display (HMD) and the object being modeled appears as a 3D augmentation in the real world. This object can be manipulated using a tangible interface of marker panels that correspond to the modeling tools in 3D Studio Max, and a wireless pointer device. Unlike virtual reality which brings the user into the virtual world, this system places the 3D model in the user's world while allowing the use of a large range of complex 3D polygonal modeling tools provided by 3D Studio Max.","","0-7695-2459-1","10.1109/ISMAR.2005.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544691","","Augmented reality","augmented reality;solid modelling;graphical user interfaces;computer animation;helmet mounted displays","ARpm prototype system;augmented reality interface;polygonal modeling;3D animation program;3D Studio Max;head mounted display;3D augmentation;wireless pointer device","","5","","2","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Industrial Augmented Reality: Lessons learned from a long-term On-site Assessment of Augmented Reality Maintenance Worker Support Systems","M. Lorenz; S. Knopp; J. Brade; P. Klimant; M. Dix","Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","678","681","Augmented Reality (AR) has ever since made big promises in terms of improving maintenance in industry. However, long-term on-site assessments of AR maintenance worker support systems do not exist. In cooperation with three industrial companies we developed two such systems and conducted a 14-month evaluation period. The lessons we learned from the pitfalls we ran into during this assessment period provide valuable insights for researchers and practitioners alike who want to deploy AR maintenance worker support systems to the shop floor.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974438","Augmented Reality;Evaluation;Deployment;Maintenance;Long-term Study.;Human-centered computing → Mixed / augmented reality;Computer systems organization → Embedded and cyber-physical systems","Industries;Companies;Maintenance engineering;Cyber-physical systems;Augmented reality;Monitoring","augmented reality;maintenance engineering;production engineering computing","AR maintenance worker support systems;assessment period;augmented reality maintenance worker support systems;industrial augmented reality;long-term on-site assessment;shop floor","","","","15","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"A Global Illumination and BRDF Solution Applied to Photorealistic Augmented Reality","S. A. Pessoa; G. de S. Moura; J. P. S. M. Lima; V. Teichrieb; J. Kelner","Virtual Reality and Multimedia Research Group, Informatics Center, Federal University of Pernambuco, Brazil; Universidade Federal de Pernambuco, Recife, PE, BR; Virtual Reality and Multimedia Research Group, Informatics Center, Federal University of Pernambuco, Brazil; Virtual Reality and Multimedia Research Group, Informatics Center, Federal University of Pernambuco, Brazil; Virtual Reality and Multimedia Research Group, Informatics Center, Federal University of Pernambuco, Brazil","2009 IEEE Virtual Reality Conference","7 Apr 2009","2009","","","243","244","This paper presents a solution for the photorealistic rendering of synthetic objects into dynamic real scenes, in Augmented Reality applications. In order to achieve this goal, an Image Based Lighting approach is proposed, where environment maps with different levels of glossiness are generated for each virtual object in the scene at every frame. Due to this, illumination effects, such as color bleeding and specular reflections, can be simulated for virtual objects in a consistent way, even under the presence of scene changes. A unifying sampling method for the spherical harmonics transformation pass is also used. It is independent of map format and does not need to apply different weights for each sample. The developed technique is combined with an extended version of Lafortune Spatial BRDF, featuring Fresnel effect and an innovative tangent rotation parameterization. The solution is evaluated in various Augmented Reality case studies, where other features like shadowing and lens effects are also exploited.","2375-5334","978-1-4244-3943-0","10.1109/VR.2009.4811036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811036","Photorealism;global illumination;BRDF;augmented reality;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;Augmented;and Virtual Realities;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Color;Shading;Shadowing;and Texture","Lighting;Augmented reality;Layout;Sampling methods;Optical reflection;Virtual reality;Hemorrhaging;Shadow mapping;Computer graphics;Informatics","augmented reality;realistic images;rendering (computer graphics)","global illumination;BRDF solution;photorealistic augmented reality;photorealistic rendering;synthetic objects;dynamic real scenes;image based lighting;environment maps;illumination effects;color bleeding;specular reflection;virtual objects;spherical harmonics transformation;Lafortune spatial BRDF;Fresnel effect;tangent rotation parameterization","","3","","3","IEEE","7 Apr 2009","","","IEEE","IEEE Conferences"
"Adaptive line tracking with multiple hypotheses for augmented reality","H. Wuest; F. Vial; D. Stricker","Department of Virtual and Augmented Reality, Fraunhofer IGD, Darmstadt, Germany; Department of Virtual and Augmented Reality, Fraunhofer IGD, Darmstadt, Germany; Dept. of Virtual & Augmented Reality, Fraunhofer IGD, Darmstadt, Germany","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","62","69","We present a real-time model-based line tracking approach with adaptive learning of image edge features that can handle partial occlusion and illumination changes. A CAD (VRML) model of the object to track is needed. First, the visible edges of the model with respect to the camera pose estimate are sorted out by a visibility test performed on standard graphics hardware. For every sample point of every projected visible 3D model line a search for gradient maxima in the image is then carried out in a direction perpendicular to that line. Multiple hypotheses of these maxima are considered as putative matches. The camera pose is updated by minimizing the distances between the projection of all sample points of the visible 3D model lines and the most likely matches found in the image. The state of every edge's visual properties is updated after each successful camera pose estimation. We evaluated the algorithm and showed the improvements compared to other tracking approaches.","","0-7695-2459-1","10.1109/ISMAR.2005.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544665","","Augmented reality;Cameras;Testing;Lighting;Performance evaluation;Hardware;Robustness;Graphics;State estimation;Gyroscopes","CAD;augmented reality;virtual reality languages;edge detection;feature extraction;image matching;image sampling;tracking;hidden feature removal;solid modelling;computer graphic equipment;video cameras","real-time visible 3D model-based line tracking approach;augmented reality;adaptive learning;image edge feature;partial occlusion;image illumination;CAD model;VRML model;camera pose estimate;graphics hardware;image gradient maxima search;image matching;edge visual property","","64","15","13","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Panorama of Researches Related to the Application of Virtual Reality in the Health Area in SVR","T. Silva Barbosa; A. Henrique Kronbauer","Escola de Arquitetura, Engenharia e Tecnologia da Informação, Universidade Salvador, Salvador, Brazil; Programa de Pós-Graduação em Sistemas e Computação, Universidade Salvador, Salvador, Brazil","2019 21st Symposium on Virtual and Augmented Reality (SVR)","5 Dec 2019","2019","","","69","76","The use of Virtual Reality for the development of applications that can help in the treatment of different pathologies and the training of health professionals has been increasing gradually in the last decade. In this context, the purpose of this paper is to present a systematic review of the articles describing virtual reality applications for the health area, published in the last five editions of the Symposium on Virtual and Augmented Reality (SVR). Seven research questions were defined to identify the current panorama and possible trends. The results of the research present quantitative data regarding the number of published works, universities and states involved, types of treatments and training performed, as well as presenting data regarding the technologies used and the incidence of games.","","978-1-7281-5434-3","10.1109/SVR.2019.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920907","systematic review, virtual reality, SVR, technology, health","Training;Augmented reality;Systematics;Libraries;Visualization;Pathology","augmented reality;medical computing","health area;SVR;pathologies;health professionals;systematic review;virtual reality applications;Augmented Reality;research questions;current panorama;quantitative data;universities","","1","","","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"The Arlab and Cave libraries: On authoring augmented reality and virtual reality experiences using a graphical programming language","A. Roth","Augmented Reality Laboratory, York University, Toronto, Canada","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","101","102","In an attempt to better understand how the use of graphical programming environments can be beneficial to artists, I have designed two new libraries for authoring augmented reality (AR), mixed reality (MR), and virtual reality (VR) experiences in Max/MSP/Jitter. I propose that libraries of pre-constructed objects, known as abstractions, as well as the use of existing graphical interfaces, could facilitate experimentation and could encourage programmers to repurpose projects for use by non-programmers. This paper describes these libraries and their uses.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093664","Max/MSP/Jitter;6DOF Tracking;Cosm;DART;virtual environments;graphical programming language","Libraries;Computer languages;Augmented reality;Three dimensional displays;Jitter;Multimedia communication","augmented reality;authoring languages;digital libraries;graphical user interfaces;visual languages","Arlab libraries;Cave libraries;authoring augmented reality;virtual reality experiences;graphical programming language;mixed reality;Max-MSP-Jitter;graphical interfaces","","4","","8","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Mosaicing a Wide Geometric Field of View for Effective Interaction in Augmented Reality","S. Jeon; G. J. Kim","Department of Computer Science and Engineering Postech, Haptics and Virtual Reality Laboratory, South Korea; Digital Experiance Laboratory Department of Computer Science and Engineering, Korea University, South Korea","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","265","266","In this paper, we have addressed the usability issue of augmented reality systems. In order to overcome the lack of view into the interaction space in nominal AR systems, we proposed to create and use a mosaiced image as a cost effective and practical solution. One of the obvious problem is that even if the view span is increased by the mosaicing, because of the fixed and limited resolution/size of the display(either HMD or upright display), the content must be viewed in smaller scale. Yang et al. has found out that increasing the geometric field of view can be tolerated to some degree without much degradation in task performance [3]. In our pilot experiment, a comparison of our mosaiced AR display to the nominal set up improved task performance when the task involved manipulation of many tangible props in a relatively wide area. Our future work is to conduct a more formal usability study and address other AR usability issues.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538859","Mosaicing;Augmented Reality;Spatial Awareness","Augmented reality;Cameras;Head;Displays;Transmission line matrix methods;Virtual reality;Computer science;Tracking;Equations;Haptic interfaces","augmented reality;helmet mounted displays;human computer interaction;image segmentation;video cameras","augmented reality system;usability issue;image mosaicing;augmented reality display resolution;head mounted display","","","10","3","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"mirracle: Augmented Reality in-situ visualization of human anatomy using a magic mirror","T. Blum; V. Kleeberger; C. Bichlmeier; N. Navab","Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität, Mänchen, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität, Mänchen, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität, Mänchen, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität, Mänchen, Munich, Germany","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","169","170","The mirracle system extends the concept of an Augmented Reality (AR) magic mirror to the visualization of human anatomy on the body of the user. Using a medical volume renderer a CT dataset is augmented onto the user. By a slice based user interface, slice from the CT and an additional photographic dataset can be selected.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180934","H.5.1 [Information Interfaces and Presentation]: Artificial, augmented, and virtual realities","Cameras;Visualization;Biomedical imaging;Computed tomography;Skeleton;X-ray imaging;Surgery","augmented reality","augmented reality;magic mirror;mirracle system;human anatomy visualization;medical volume renderer;CT dataset;user interface;photographic dataset","","7","","","IEEE","12 Apr 2012","","","IEEE","IEEE Conferences"
"Keynote Speaker: User Experience Considerations for Everyday Augmented Reality","",,"2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","1 Nov 2021","2021","","","16","16","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Future AR glasses will be much like today’s smartphones, as our everyday information access and productivity devices. Technical challenges in optics, power, and tracking remain, but are solvable. However, technical achievements alone are insufficient to ensure that everyday AR systems will be productive, usable, useful, and satisfying. We must also design effective methods for interacting with and managing AR content, and we must understand the effects of always-on AR, on both individuals and communities. In this talk, I will present a vision of future everyday AR use cases, and discuss recent user experience (UX) research aimed at enabling this vision. I will discuss UX design recommendations for making information access through AR more convenient and usable than today's smartphones and smartwatches, while at the same time not distracting users from what's going on in the real world around them. I will conclude with a call to action for researchers and designers to carefully consider how everyday AR can benefit society and how to avoid potential pitfalls. ","1554-7868","978-1-6654-0158-6","10.1109/ISMAR52148.2021.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583809","","Three-dimensional displays;User experience;Smart phones;Human computer interaction;Computer science;Augmented reality;Visualization","augmented reality;mobile computing;user interfaces","keynote speaker;user experience considerations;everyday augmented reality;summary form;complete presentation;conference proceedings;future AR glasses;smartphones;everyday information access;productivity devices;technical challenges;technical achievements;everyday AR systems;AR content;future everyday AR use cases;recent user experience;UX design recommendations","","","","","IEEE","1 Nov 2021","","","IEEE","IEEE Conferences"
"A High-level Event System for Augmented Reality","J. -L. Lugrin; R. Chaignon; M. Cavazza","University of Teesside, Middlesbrough, UK; Teesside University, Middlesbrough, North Yorkshire, GB; Teesside University, Middlesbrough, North Yorkshire, GB","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","269","270","3D graphics systems increasingly rely on sophisticated event systems derived from collision detection mechanisms, which support the discretisation of Physics as well as high-level programming and scripting. By contrast, augmented reality systems have not yet adopted this approach. We describe the development of a high-level event system on top of the ARToolkit environment incorporating the ODE Physics engine. We first define a typology of events encompassing interactions between virtual objects as well as interactions involving markers. We then describe how these events can be recognised in real-time from elementary collisions detected by the ODE Physics engine. We conclude by discussing examples of high-level event recognitions and how they can support the development of applications.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538861","Augmented Reality;Event Systems;ARToolKit","Augmented reality;Engines;Virtual reality;Application software;Physics computing;Event detection;Sampling methods;Graphics;Chromium;Multimedia systems","augmented reality;computer graphics;computer vision","high-level event system;augmented reality;3D graphics systems;high-level programming;scripting;augmented reality systems","","","","7","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Industrial Augmented Reality: Concepts and User Interface Designs for Augmented Reality Maintenance Worker Support Systems","J. Kim; M. Lorenz; S. Knopp; P. Klimant","Institute for Machine Tools and Production Processes, Chemnitz University of Technology, Bauhaus-Universität Weimar; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","67","69","Maintenance departments of producing companies in most industrial countries are facing challenges originating from an aging workforce, increasing product variety, and the pressure to increase productivity. We present the concepts and the user interface (UI) designs for two Augmented Reality (AR) applications, which help to tackle these issues. An AR Guidance System will allow new and unexperienced staff to perform medium to highly complex maintenance tasks, which they currently incapable to. The AR Remote Service System enables technicians at the machine to establish a voice/video stream with an internal or external expert. The video stream can be augmented with 3D models and drawings so that problems can be solved remotely and more efficiently. A qualitative assessment with maintenance managers and technicians from three producing companies rated the AR application concept as beneficial and the UI designs as very usable.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288451","Augmented Reality;User interface;Maintenance","Productivity;Three-dimensional displays;Companies;Maintenance engineering;User interfaces;Task analysis;Augmented reality","augmented reality;maintenance engineering;personnel;production engineering computing;solid modelling;user interfaces","industrial augmented reality;user interface designs;aging workforce;product variety;productivity;AR guidance system;UI designs;augmented reality maintenance worker support systems;AR remote service system;video stream;3D models","","9","","11","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"From Lab to Reality: Optimization of Industrial Augmented Reality Interfaces","E. Laviola; A. E. Uva",Polytechnic University of Bari; Polytechnic University of Bari,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","931","934","My thesis work is focused on the creation of guidelines for the authoring of the next-generation Industrial Augmented Reality Technical Documentation. The research project aims to provide clear recommendations to optimize the template presentation related to the instruction authoring in an industrial context focusing attention in assessing the real economic impact that AR can offer for companies. This optimization not only will improve the operators' performance by providing them with more easily interpretable information, but also will reduce developers' computational costs to companies in both programming and 3D modeling. Finally, the outcomes obtained will provide guidelines that can make the authoring of AR technical documentation accessible even to technical writers who are not particularly skilled in AR.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974582","Industrial Augmented Reality;Technical Documentation;Work Instructions;Authoring;Information Presentation;[Human-centered computing]: Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;[Human-centered computing]: Visualization;Visualization design and evaluation methods","Human computer interaction;Visualization;Three-dimensional displays;Focusing;Documentation;Companies;Augmented reality","augmented reality;production engineering computing","AR technical documentation;computational costs;economic impact;industrial augmented reality interfaces;instruction authoring;interpretable information;next-generation industrial augmented reality technical documentation;research project;template presentation","","","","26","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Industrial Augmented Reality: 3D-Content Editor for Augmented Reality Maintenance Worker Support System","M. Lorenz; S. Knopp; J. Kim; P. Klimant","Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","203","205","Supporting maintenance with 3D object enhanced instruction is one of the key applications of Augmented Reality (AR) in industry. For the breakthrough of AR in maintenance, it is important that the technicians themselves can create AR-instructions and perform the challenging task of placing 3D objects as they know best how to perform a task and what necessary information needs to be displayed. For this challenge, a 3D-content editor is being presented wherein a first step the 3D objects can roughly be placed using a 2D image of the machine, therefore, limiting the time required to access the machine. In a second step, the positions of the 3D objects can be fine-tuned at the machine site using live footage. The key challenges were to develop an easily accessible UI that requires no prior knowledge of AR content creation in a tool that works both with live footage and images and is usable with a touch screen and keyboard/mouse. The 3D-content editor was qualitatively assessed by technicians revealing its general applicability, but also the requirement for a lot of time to gain the necessary experience for positioning 3D objects.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288477","Augmented Reality;3D content editing;User interface;Maintenance","Three-dimensional displays;Two dimensional displays;Maintenance engineering;Touch sensitive screens;Tools;Task analysis;Augmented reality","augmented reality;machining;maintenance engineering;personnel;production engineering computing;user interfaces","industrial augmented reality;3D-content editor;augmented reality maintenance worker support system;3D object enhanced instruction;2D image;3D object positioning;machine access;user interface;touch screen;keyboard;mouse","","5","","8","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Exploring Augmented Reality Notification Placement while Communicating with Virtual Avatar","H. Lee; W. Woo",KAIST UVR Lab; KAIST UVR Lab,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","686","689","Augmented reality head-mounted displays (AR HMD) enable visual notifications directly into the user's field of view (FoV) to perform dual-task. However, research on the efficient presentation of notifications when communicating with a virtual avatar in augmented reality (AR) situation has been insufficient. For efficient AR notification presentations, it is necessary to understand where to display notifications without interfering with virtual avatar communication. We investigated two coordinate systems (world-fixed and display-fixed) and eight positions for AR notifications when conversing with the virtual avatar. Results showed that the top-left position increased response time and task load. Our study contributes as a cornerstone to designing AR notifications in communication with virtual avatars.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974599","Human-centered computing;Human Computer Interaction (HCI);Interaction paradigms;Virtual reality Mixed/augmented reality","Visualization;Head-mounted displays;Avatars;Resists;Time factors;Task analysis;Augmented reality","augmented reality;avatars;helmet mounted displays","AR notifications;augmented reality head-mounted displays;augmented reality notification placement;augmented reality situation;display-fixed coordinate systems;efficient AR notification presentations;virtual avatar communication;visual notifications","","","","19","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Lower Limb Balance Rehabilitation of Post-stroke Patients Using an Evaluating and Training Combined Augmented Reality System","S. Chen; B. Hu; Y. Gao; Z. Liao; J. Li; A. Hao","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, Research Institute of Frontier Science, Beihang University; Sir Run Run Shaw Hospital, Zhejiang University School of Medicine; Sir Run Run Shaw Hospital, Zhejiang University School of Medicine; State Key Laboratory of Virtual Reality Technology and Systems, Research Institute of Frontier Science, Beihang University","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","217","218","Augmented/virtual reality applications can provide immersive and interactive virtual environment for motor rehabilitation using the collaborative stimulations of multiple sensory channels such as sight, hearing, and movement, enhance the rehabilitation effect through repetitions, feedbacks, and encouragement. In this paper, we propose an evaluating and training integrated application for the rehabilitation of patients with lower limb balance disorder. The AR-based evaluation module visualizes the limits of lower limbs patients' balance abilities and provides quantitative data to their therapists, then rehabilitation therapists can customize personalized VR training games accordingly.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288446","Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Social and professional topics;Computing / technology policy;Medical information policy;Medical technologies","Training;Human computer interaction;Virtual environments;Medical treatment;Games;Usability;Augmented reality","augmented reality;medical computing;patient rehabilitation;patient treatment;serious games (computing)","post-stroke patients;immersive environment;interactive virtual environment;motor rehabilitation;collaborative stimulations;sensory channels;rehabilitation effect;lower limb balance disorder;evaluation module;lower limbs patients;rehabilitation therapists;VR training games;lower limb balance rehabilitation","","6","","11","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Reimagining the Stadium Spectator Experience using Augmented Reality and Visual Positioning System","K. Cheng; K. Koda; S. Masuko","Rakuten Institute of Technology, Rakuten Group, Inc., Japan; Rakuten Institute of Technology, Rakuten Group, Inc., Japan; Rakuten Institute of Technology, Rakuten Group, Inc., Japan","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","786","787","Professional sports clubs around the world have been looking for ways to innovate and engage fans with novel sports watching experiences at the stadium. Augmented reality is often used to offer an immersive and interactive experience at a specific place, connecting virtual artefacts with the physical location in meaningful ways. In this work, we introduce the practical use of Visual Positioning System, combined with our unique AR design, together with novel placement of content, interaction with live sports data, and linking them directly to e-commerce services on-demand to create a unique, immersive, and interactive sports watching experience at the stadium.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974231","Visual positioning system;augmented reality;mixed reality;stadium experience;spectator experience;real-time statistics;player tracking;e-commerce;advertising;Human-Centered Computing - Human Computer Interaction (HCI) - Interaction Paradigms - Mixed / Augmented Reality","Human computer interaction;Visualization;Fans;Electronic commerce;Augmented reality;Sports","augmented reality;electronic commerce;sport","augmented reality;immersive experience;immersive, sports;innovate engage fans;interactive experience;interactive sports;live sports data;meaningful ways;physical location;professional sports clubs;specific place;stadium spectator experience;unique sports;virtual artefacts;Visual Positioning System","","","","3","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"ARKLib: An Augmented Reality Library for Applications using Kinect","D. Melo Amaral; L. Chaves Dutra da Rocha; M. Carvalho Viana; M. de Paiva Guimarães; D. R. Colombo Dias",Universidade Federal de São João del-Rei; Universidade Federal de São João del-Rei; Universidade Federal de São João del-Rei; Universidade Federal de São Paulo; Universidade Federal de São João del-Rei,"2019 21st Symposium on Virtual and Augmented Reality (SVR)","5 Dec 2019","2019","","","107","111","In the course of the emergence of new technological solutions, ways of applying them must be studied and proposed. In this context, the objective of this work was to use the augmented reality to the merchandising, increasing the number of technological options for the improvement of conventional commercial establishments. We proposed and developed a library that makes use of Microsoft Kinect to help developers build augmented reality applications that can be used in physical retail commerce as marketing tools, allowing passers-by to interact with the application. The goal is for them to become shop customers during the interaction process. Finally, the application of an interactive virtual showroom was developed to show the practical utility of the tool for both developers and the commercial retail sector.","","978-1-7281-5434-3","10.1109/SVR.2019.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920878","Augmented Reality, Library, Microsoft Kinect, OpenGL, Software Engineering","Augmented reality;Software libraries;Electronic commerce","augmented reality;electronic commerce;retail data processing;software libraries","commercial retail sector;interactive virtual showroom;interaction process;marketing tools;physical retail commerce;augmented reality applications;Microsoft Kinect;conventional commercial establishments;technological options;merchandising;technological solutions;augmented reality library;ARKLib","","1","","","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"[Poster] Contextually panned and zoomed augmented reality interactions using COTS heads up displays","A. Hill; H. Leach",Merlin Mobility Incorporated; Merlin Mobility Incorporated,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","269","270","Consumer of the shelf heads up displays with onboard cameras and processing power have recently become available. Evaluations of a naive implementation of video-see-through augmented reality suggest that their small display and off-axis camera presents usability problems. We panned and zoomed a composited video feed on the Google Glass device to center the augmented reality context within the display and to give the appearance of a fixed distance to the content. We pilot tested both the panned and zoomed display against a naive implementation and found that users preferred the view-stabilized version.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948444","Mixed/Augmented Reality;Displays and Imagers;Computer Vision;Interaction Techniques","Cameras;Glass;Augmented reality;Google;Feeds;Image resolution;Head","augmented reality;computer displays","contextually panned and zoomed augmented reality interaction;COTS heads up displays;commecial-off-the-shelf;video-see-through augmented reality;composite video feed;Google Glass device;panned and zoomed display;view-stabilized display","","","","5","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Analysis of Low-Cost Virtual and Augmented Reality Technology in Case of Motor Rehabilitation","R. F. de Souza; D. L. Farias; R. C. L. Flor da Rosa; E. F. Damasceno","Departamento de Computação - Programa de Mestrado em Informática, Universidade Tecnológica Federal do Paraná, Cornelio Procopio, Brazil; Departamento de Computação - Programa de Mestrado em Informática, Universidade Tecnológica Federal do Paraná, Cornelio Procopio, Brazil; Departamento de Computação - Programa de Mestrado em Informática, Universidade Tecnológica Federal do Paraná, Cornelio Procopio, Brazil; Departamento de Computação - Programa de Mestrado em Informática, Universidade Tecnológica Federal do Paraná, Cornelio Procopio, Brazil","2019 21st Symposium on Virtual and Augmented Reality (SVR)","5 Dec 2019","2019","","","161","164","We evaluated the effectiveness of Low-cost Immersive Virtual Reality (IVR) and Desktop Augmented Reality (DAR) in Motor Rehabilitation of Spasmodic Torticollis (ST) with a case study of 12 subjects. Goal: To verify by functional (kinesiological) criteria and computational criteria (interaction and involvement) which was the best approach technique for the treatment of ST. Method: The comparative cross-sectional study method was applied, analyzing a cut of the moment of the subjects compared with control groups at the same moment. Result: The two technologies, IVR and DAR are presented as an instrument that adds a playful object to the therapy and favors the active participation of the patient during the treatment. However, IVR tends to have higher fidelity for range of motion data generation.","","978-1-7281-5434-3","10.1109/SVR.2019.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8921382","Analysis Technology Use;Virutal Reality;Augmented Reality;Motor Rehabilitation","Visualization;Augmented reality;Instruments;Webcams;Medical treatment;Indexes","augmented reality;patient rehabilitation","low-cost immersive virtual reality;motion data generation;control groups;desktop augmented reality;comparative cross-sectional study method;computational criteria;functional criteria;ST;Spasmodic Torticollis;DAR;motor rehabilitation;IVR","","2","","","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Augmented chemical reactions: An augmented reality tool to support chemistry teaching","P. Maier; G. Klinker","Fachgebiet Augmented Reality (FAR), Tecnische Universität München, Garching b. München, Germany; Fachgebiet Augmented Reality (FAR), Tecnische Universität München, Garching b. München, Germany","2013 2nd Experiment@ International Conference (exp.at'13)","9 Jan 2014","2013","","","164","165","This demonstration shows an Augmented Reality tool to support teaching chemistry. The understanding of spacial relations in and between molecules is an essential part that has to be understood by students to learn chemistry As nowadays the techniques to show and simulate molecular behaviors get faster and better, 3D applications to show the molecules become more and more popular also in schools. Augmented Chemical Reactions is an application that shows the 3D spatial structure of molecules as well as the dynamics of the atoms in and between molecules. This application does not use the commonly used 3D user interface of mice and keyboards to move and rotate the virtual objects but it makes use of an intuitive 3D user interface. This 3D User interface is an direct manipulation user interface using the augmented reality technique. With this user interface it enables the users to better understand the spacial structure of the shown geometries.","","978-1-4799-2741-8","10.1109/ExpAt.2013.6703055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703055","","Chemicals;Three-dimensional displays;Augmented reality;User interfaces;Webcams;Education","augmented reality;chemistry computing;teaching;user interfaces","augmented chemical reactions;augmented reality tool;chemistry teaching;molecular behaviors;3D spatial structure;virtual objects;intuitive 3D user interface;direct manipulation user interface","","18","","6","IEEE","9 Jan 2014","","","IEEE","IEEE Conferences"
"Does visualize industries matter? A technology foresight of global Virtual Reality and Augmented Reality Industry","S. -N. Chang; W. -L. Chen","Taiwan Association for Virtual and Augmented Reality, Taiwan; Drexel University, USA","2017 International Conference on Applied System Innovation (ICASI)","24 Jul 2017","2017","","","382","385","The trends of Virtual Reality and Augmented Reality Industry. This study tends to figure out the industrial trends and technology foresight of Virtual Reality (VR) and Augmented Reality (AR) Industry, including the business trends, food chain, ecosystem, technology foresight, and future direction. We hope this study can bring some important inspiration for the future of Virtual Reality and Augmented Reality Industry.","","978-1-5090-4897-7","10.1109/ICASI.2017.7988432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988432","Technology Foresight;Ecosystem;Platform Economy;Virtual Reality;Augmented Reality","Industries;Ecosystems;Hardware;Augmented reality;Business;Mobile communication","augmented reality","global virtual reality;augmented reality industry;business trends;food chain;ecosystem;technology foresight","","4","","6","IEEE","24 Jul 2017","","","IEEE","IEEE Conferences"
"Addressing the Occlusion Problem in Augmented Reality Environments with Phantom Hollow Objects","J. Gimeno; S. Casas; C. Portalés; M. Fernádez","Universitat de Valencia, Valencia, Comunitat Valenciana, ES; Universitat de Valencia, Valencia, Comunitat Valenciana, ES; Universitat de Valencia, Valencia, Comunitat Valenciana, ES; Universitat de Valencia, Valencia, Comunitat Valenciana, ES","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","21","24","Occlusion handling is essential to provide a seamless integration of virtual and real objects in AR applications. Different approaches have been presented with a variety of technologies, environment conditions and methods. Among these methods, 3D model-based occlusion approaches have been extensively used. However, these solutions could be too time-consuming in certain situations, since they must render all the occlusion objects even though they are invisible. For this reason, we propose an inverse 3D model-based solution for handling occlusions, designed for those AR applications in which virtual objects are placed inside a real object with holes or windows. With this restriction, the occlusion problem could be solved by rendering the geometry of transparent/hollow objects instead of rendering the opaque geometry. The method has been tested in a real case study with an augmented car in which the virtual content is shown in the interior of the vehicle. Results show that our method outperforms the traditional method, proving that this approach is an efficient option for solving the occlusion problem in certain AR applications.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699304","Augmented Reality;occlusion;hollow;inverse phantom objects;depth rendering;offline 3D reconstruction;K.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities","Augmented reality","augmented reality;rendering (computer graphics);solid modelling","inverse 3D model-based solution;AR applications;virtual objects;occlusion problem;virtual content;augmented reality environments;phantom hollow objects;occlusion handling;seamless integration;real objects;environment conditions;model-based occlusion approaches;transparent objects;rendering","","3","","","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Demo — Altered reality: Augmenting and diminishing reality in real time","C. W. M. Leão; J. P. Lima; V. Teichrieb; E. S. Albuquerque; J. Kelner","Virtual Reality and Multimedia Research Group, Federal University of Pernambuco, Brazil; Virtual Reality and Multimedia Research Group, Federal University of Pernambuco, Brazil; Virtual Reality and Multimedia Research Group, Federal University of Pernambuco, Brazil; Informatics Institute, Federal University of Goiás, Brazil; Virtual Reality and Multimedia Research Group, Federal University of Pernambuco, Brazil","2011 IEEE Virtual Reality Conference","29 Apr 2011","2011","","","259","260","Augmented Reality applications overlap virtual objects over a real scene, taking into account context, in order to add information to the end user. Nowadays, more advanced applications also make use of Diminished Reality that removes real objects from a scene. This paper describes an approach that combines Augmented Reality and Diminished Reality techniques to modify real objects present in applications. The proposed approach removes an object and replaces it with its purposely-modified replica. The solution uses dynamic texture techniques and Inpaint to enhance the visual response of the modification performed. The results are promising considering both realism of the modified real object and performance of the application.","2375-5334","978-1-4577-0038-5","10.1109/VR.2011.5759497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759497","","Solid modeling;Augmented reality;Computational modeling;Three dimensional displays;Real time systems;Mobile handsets","augmented reality","augmented reality;virtual objects;diminished reality;dynamic texture technique;visual response enhancement","","1","","","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"[POSTER] Industrial Augmented Reality: Transferring a Numerical Control Connected Augmented Realty System from Marketing to Maintenance","C. Kollatsch; M. Schumann; P. Klimant; M. Lorenz","Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; IWU, Fraunhofer Institute for Machine Tools and Forming Technology; Department of Orthopedics, Trauma and Plastic Surgery","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","39","41","Connecting third party systems like machine controls and product data management systems with Augmented Reality (AR) support applications is crucial for their industrial success. We present a marketing use case of a Virtual Press demonstrator where the connection to a machine control was successfully implemented. The realization of this application utilized the AR framework ARViewer that is introduced in this paper. Subsequent, an outlook is given how this framework can be extended using three examples of AR maintenance applications.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088444","Augmented Reality;Numerical Control;Machine Control;Marketing;Maintenance","Augmented reality","augmented reality;maintenance engineering;marketing data processing;numerical control;production engineering computing","numerical control connected augmented reality system;industrial augmented reality;AR framework ARViewer;AR maintenance applications;Virtual Press demonstrator;marketing;machine control","","11","","8","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"A tour guiding system of historical relics based on augmented reality","X. Wei; D. Weng; Y. Liu; Y. Wang","Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology","2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","307","308","Yuanmingyuan is a relic park and only few cultural relics are left due to the looting and burning down in history, which makes that most of the scenic spots of the park look boring. To address such issue, a game-based guidance system for Yuanmingyuan and a time travel game called MAGIC-EYES has been proposed with Augmented Reality technology. Six interactive modes are designed in the proposed system to guide tourists to visit the specified place. The evaluation results of a pilot study shows that the proposed guidance system has significantly improved the tourist experiences.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504776","Guidance system;Augmented reality;Game-based learning;Location-based","Augmented reality;Games;Buildings;History;Cultural differences;Multimedia communication","augmented reality;computer games;history;travel industry","tour guiding system;historical relics;Yuanmingyuan;relic park;cultural relics;game-based guidance system;time travel game;MAGIC-EYES;augmented reality technology;interactive modes;tourist experiences","","13","","2","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Acceleration methods for radiance transfer in photorealistic augmented reality","L. Gruber; P. Sen; T. Höllerer; D. Schmalstieg","Graz University of Technology; University of California, Santa Barbara; University of California, Santa Barbara; Graz University of Technology","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","255","256","Radiance transfer computation from unknown real-world environments is an intrinsic task in probe-less photometric registration for photorealistic augmented reality, which affects both the accuracy of the real-world light estimation and the quality of the rendering. We discuss acceleration methods that can reduce the overall ray-tracing costs for computing the radiance transfer for photometric registration in order to free up resources for more advanced augmented reality lighting. We also present evaluation metrics for a systematic evaluation.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671792","","Lighting;Geometry;Acceleration;Cameras;Rendering (computer graphics);Vectors;Augmented reality","augmented reality;brightness;ray tracing;rendering (computer graphics)","acceleration methods;radiance transfer;photorealistic augmented reality;ray-tracing costs reduction;photometric registration;augmented reality lighting","","1","","7","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Augmented Reality-Based Peephole Interaction using Real Space Information","M. Miyazaki; T. Komuro",Saitama University; Saitama University,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","8","11","In this paper, we investigate the effectiveness of augmented reality-based peephole interaction on a smartphone which fixes a virtual screen on a flat surface in real space and that enables a user to change the viewing area rapidly by moving or tilting the device. Since the virtual screen is superimposed in real space, the user can easily grasp the sense of distance to the virtual screen and move the device to a proper position rapidly. In addition, it is expected that the user can remember the positions of target objects easily by associating the objects with real space information. We conducted an experiment to compare the proposed augmented reality-based peephole interface with a conventional non-augmented reality-based peephole interface, and the conventional touchscreen interface. Although there was no significant difference in task completion time, the results of the questionnaire showed that the proposed interface and the conventional peephole interface were preferred to the conventional touchscreen interface and that it could be possible to show the effectiveness of the proposed interface in further investigations.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951955","mobile-device;peephole-interaction;augmented-reality","Augmented reality","augmented reality;human computer interaction;touch sensitive screens;user interfaces","virtual screen;real space information;augmented reality-based peephole interface;nonaugmented reality-based peephole interface;touchscreen interface;conventional peephole interface;augmented reality-based peephole interaction","","1","","16","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Supervised classification for customized intraoperative augmented reality visualization","O. Pauly; A. Katouzian; A. Eslami; P. Fallavollita; N. Navab","Chair for Computer Aided Medical Procedures, Technical University of Munich, Germany; Chair for Computer Aided Medical Procedures, Technical University of Munich, Germany; Chair for Computer Aided Medical Procedures, Technical University of Munich, Germany; Chair for Computer Aided Medical Procedures, Technical University of Munich, Germany; Chair for Computer Aided Medical Procedures, Technical University of Munich, Germany","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","311","312","In this paper, we present a fusion algorithm supplemented with appropriate visualization by selecting relevant information from different modalities in mixed and augmented reality (AR). This encompasses a learning based method upon relevance of information, defined by an expert, which ultimately enables confident interventional decisions based on mixed reality (MR) images. The performance of our developed fusion and tailored visualization techniques was evaluated by employing X-ray/optical images during surgery and validated qualitatively using a 5-point Likert scale. Our observations indicated that the proposed technique provided semantic contextual information about underlying pixels and in general was preferred over the traditional pixel-wise linear alpha-blending method.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402589","Medical Augmented Reality;Fusion;Relevant Information;Visualization;X-ray;CamC","Surgery;X-ray imaging;Biomedical optical imaging;Optical imaging;Optical mixing;Visualization;Augmented reality","augmented reality;biomedical optical imaging;data visualisation;diagnostic radiography;image classification;learning (artificial intelligence);medical image processing;sensor fusion","supervised classification;customized intraoperative augmented reality visualization;fusion algorithm;mixed reality;augmented reality;AR;MR;learning based method;information relevance;interventional decision;X-ray image;optical image;5-point Likert scale;surgery;pixel-wise linear alpha-blending method","","10","","4","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Embodied learning mechanics and their relationship to usability of handheld augmented reality","I. Radu; A. Antle",Georgia Institute of Technology; Simon Fraser University,"2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual & Augmented Reality (KELVAR)","29 Jun 2017","2017","","","1","5","Researchers in HCI have designed and developed Augmented Reality for over two decades. Recently, there has been increased interest in exploring an embodied perspective on interaction, where the focus is on the fundamental role played by the physical body in how we experience. This paper presents an overview of embodied cognition as it relates to augmented reality, along with specific interaction mechanics that can engage embodied learning in augmented reality. Further, we reflect on children's usability of handheld augmented reality, presenting a set of usability problems encountered by children, and reflections on how these problems impact the use of embodied interaction learning mechanics for young children.","","978-1-5386-1892-9","10.1109/KELVAR.2017.7961561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961561","Embodied Cognition;Embodiment;Children;Interaction Design;Physicality;Tangible Interfaces;Augmented Reality;Education;Teaching;Pedagogy","Augmented reality;Cognition;Usability;Three-dimensional displays;Games;Solid modeling;Education","augmented reality;cognition;computer aided instruction;human computer interaction;user interfaces","embodied learning mechanics;usability;handheld augmented reality;human computer interaction;HCI;embodied cognition;interaction mechanics;young children","","6","","31","IEEE","29 Jun 2017","","","IEEE","IEEE Conferences"
"An Augmented Reality Review on Production Environments","L. F. d. S. Cardoso; E. R. Zorzal","Instituto de Ciência e Tecnologia (ICT), Universidade Federal de São Paulo (UNIFESP), São José dos Campos, Brasil; Instituto de Ciência e Tecnologia (ICT), Universidade Federal de São Paulo (UNIFESP), São José dos Campos, Brasil","2018 20th Symposium on Virtual and Augmented Reality (SVR)","19 Aug 2019","2018","","","143","149","More effective process development is one of key factors, identified during history, to companies' perpetuity, making them more market competitive. In the last decades, industries looked for computer tools to develop and improve their manufacturing process. In this context, Augmented Reality became target to new studies and industrial applications development. In contrast, its usage in this environment is not a common practice. To understand this behavior the present paper propose a literature review in order to identify this technology application in industrial environment. It was identified the Augmented Reality target industrial segments, its applicability and discussed post-implementation gains and limitations.","","978-1-7281-0604-5","10.1109/SVR.2018.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802441","Augmented Reality;Mixed Reality;Process Innovation;Industrial Process;Production Environment","Augmented reality;Visualization;Monitoring;Manufacturing;Production facilities","augmented reality;Internet;manufacturing processes;production engineering computing","production environments;effective process development;computer tools;manufacturing process;technology application;industrial environment;augmented reality target industrial segments","","3","","0","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"Tinmith - mobile outdoor augmented reality modelling demonstration","W. Piekarski; B. H. Thomas","Wearable Computer LaboratorySchool of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer LaboratorySchool of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","317","318","This paper outlines some of the capabilities of the Tinmith-Metro modeling system, based on mobile outdoor augmented reality technology. This system implements a new user interface based on tracked pinch gloves and a series of techniques named construction at a distance for the capture and creation of 3D geometry. The user controls the modeling process using hand and head motions, with modelling accuracy guided by the requirements of the user. Using Tinmith-Metro, users are able to model outdoor geometry representing buildings and natural features in an intuitive fashion.","","0-7695-2006-5","10.1109/ISMAR.2003.1240738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240738","","Augmented reality;User interfaces;Virtual reality;Avatars;Wearable computers;Information geometry;Visualization;Fingers;Laboratories;Information science","augmented reality;data gloves;computational geometry;gesture recognition","mobile augmented reality;augmented reality modelling demonstration;Tinmith-Metro;modeling system;outdoor augmented reality;user interface;tracked pinch gloves;3D geometry capture;3D geometry creation;modeling process;outdoor geometry;natural features;intuitive fashion","","4","","4","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Comparison in Depth Perception between Virtual Reality and Augmented Reality Systems","J. Ping; Y. Liu; D. Weng","Beijing Institute of Technology, Beijing, Beijing, CN; Beijing Institute of Technology, Beijing, Beijing, CN; Beijing Institute of Technology, Beijing, Beijing, CN","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1124","1125","The virtual reality (VR) and augmented reality (AR) applications have been widely used in a variety of fields; one of the key requirements in a VR or AR system is to understand how users perceive depth in the virtual environment and augmented reality. This paper conducts an experiment to compare users' performance of depth perception in VR and AR system using an optical see-through head-mounted display (HMD). The result shows that the accuracy of depth estimation in AR is higher than in VR. Besides, the matching error increases as the distance becomes farther.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798174","Human-centered computing;Interaction paradigms;Virtual reality;Mixed/augmented reality;Computing methodologies;Computer Graphics;Graphics systems and interface;Perception","Task analysis;Augmented reality;Resists;Adaptive optics;Bars;Virtual environments","augmented reality;helmet mounted displays","VR system;AR system;optical see-through head-mounted display;depth estimation;depth perception;virtual environment;augmented reality systems;virtual reality","","20","","5","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Mobile augmented reality and context-awareness for firefighters","T. Siu; V. Herskovic","Pontificia Universidad Catolica de Chile, Santiago, CL; Pontificia Universidad Catolica de Chile, Santiago, CL","IEEE Latin America Transactions","20 Jan 2014","2014","12","1","42","47","Firefighters form action teams who work in challenging environments to solve complex situations. This type of work requires firefighters to have the relevant information about the emergency site and its surroundings in an efficient, effective way. We analyzed three focus groups from the evaluation of a previous mobile application to understand the needs of firefighters at an emergency site. Then, we developed an application that proposes two approaches to provide firefighters with quick access to data: an augmented reality interface and context-awareness to switch between views of the data. A preliminary evaluation with a small set of firefighters found the application to be useful to their work.","1548-0992","","10.1109/TLA.2014.6716491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716491","augmented reality;awareness;firefighters","Augmented reality;Mobile communication;Context awareness;Human computer interaction;Teamwork;Collaboration","augmented reality;emergency services;mobile computing;user interfaces","action teams;firefighters;emergency site;mobile application;data access;mobile augmented reality interface;context awareness","","3","","","IEEE","20 Jan 2014","","","IEEE","IEEE Journals"
"Extending a User Involvement Tool with Virtual and Augmented Reality","C. Florea; P. Alavesa; L. Arhippainen; M. Pouke; W. Huang; L. Haukipuro; S. Väinämö; A. Niemelä; M. C. Orduña; M. A. Pakanen; T. Ojala","University of Oulu, Oulu; University of Oulu, Oulu; University of Oulu, Oulu; University of Oulu, Oulu; University of Oulu, Oulu; University of Oulu, Oulu; University of Oulu, Oulu; Trä Group Oy, Helsinki, 00160, Finland; University of Oulu, Oulu; Socio-Technical Design, Inge Lehmanns Gade 10, Aarhus, 8000, Denmark; University of Oulu, Oulu, FI","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","925","926","Living labs are environments for acquiring user feedback on new products and services. Virtual environments can complement living labs by providing dynamic immersive setup for depicting change. This paper describes implementation of Virtual and Augmented Reality clients as an extension to a user involvement tool for an existing living lab. We conducted a user experience study with 14 participants to compare the clients. According to our study, the virtual reality client was experienced as innovative, easy to use, entertaining and fun. Whereas the augmented reality client was perceived playful and empowering.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798299","living lab;user involvement;user experience;virtual reality;augmented reality;H.5.1 [Information Interfaces and Presentation] Multimedia Information Systems;Artificial, augmented and virtual realities","Three-dimensional displays;Tools;Augmented reality;Technological innovation;Visualization;Virtual environments","augmented reality","user involvement tool;living labs;user feedback;dynamic immersive setup;user experience study;virtual reality client;virtual environments;augmented reality clients;augmented reality","","2","","9","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Demo: End-to-end open-source location-based augmented reality in 5G","G. Sörös; J. Nilsson; N. Wu; J. Shane; A. Kadlubsky","Nokia Bell Labs, Open AR Cloud; 3D Interactive; George Mason University; Rutgers University; Open AR Cloud","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","897","898","The vision of an augmented reality (AR) cloud is about an enhanced version of the real world extended by persistent, location-anchored digital objects. We present a fully open source, end-to-end solution for placing, storing, and re-discovering geo-anchored AR contents in the real world. We advanced various components of the Open Spatial Computing Platform (OSCP) and deployed it in a 5G testbed. We created a new OSCP reference client in Unity and built representative demo applications that allow virtual objects to persist throughout space and time. We created a data collector application for spatial mapping, and we connected the OSCP with an open-source visual positioning system. Furthermore, we created tutorials on the setup to foster its adoption in the scientific community as a platform for location-based AR experiments.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974229","Human-centered computing-Mixed/augmented reality;Human-centered computing-Ubiquitous and mobile computing systems and tools;Networks-Location based services","Human computer interaction;Visualization;Cloud computing;5G mobile communication;Tutorials;Augmented reality;Mobile computing","5G mobile communication;augmented reality;public domain software;virtual reality","augmented reality cloud;data collector application;fully open source;geo-anchored AR contents;location-anchored digital objects;location-based AR experiments;Open Spatial Computing Platform;open-source location-based augmented reality;open-source visual positioning system;OSCP reference client;representative demo applications;virtual objects","","","","5","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"An Augmented Reality museum guide","T. Miyashita; P. Meier; T. Tachikawa; S. Orlic; T. Eble; V. Scholz; A. Gapel; O. Gerl; S. Arnaudov; S. Lieberknecht","DNP DIGITALCOM Company Limited, Japan; Metaio GmbH, Germany; Dai Nippon Printing Company Limited, Japan; Dai Nippon Printing Company Limited, France; Metaio GmbH, Germany; Metaio GmbH, Germany; Metaio GmbH, Germany; Metaio GmbH, Germany; Metaio GmbH, Germany; Metaio GmbH, Japan","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","103","106","Recent years have seen advances in many enabling augmented reality technologies. Furthermore, much research has been carried out on how augmented reality can be used to enhance existing applications. This paper describes our experiences with an AR-museum guide that combines some of the latest technologies. Amongst other technologies, markerless tracking, hybrid tracking, and an ultra-mobile-PC were used. Like existing audio guides, the AR-guide can be used by any museum visitor, during a six-month exhibition on Islamic art. We provide a detailed description of the museumpsilas motivation for using AR, of our experiences in developing the system, and the initial results of user surveys. Taking this information into account, we can derive possible system improvements.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637334","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637334","augmented reality;mobile computing;multimedia in the museum;1.3.6 [Computer Graphics]: Methodology and Techniques — Interaction Techniques;H5.1. [Information Systems]: Artificial, augmented and virtual realities","Animation;Cameras;Augmented reality;Computer graphics;Robustness;Mobile communication;Interviews","art;augmented reality;exhibitions","augmented reality;museum guide;markerless tracking;hybrid tracking;ultra-mobile-PC;exhibition;Islamic art","","102","","10","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Laparoscopic Virtual Mirror for Understanding Vessel Structure Evaluation Study by Twelve Surgeons","C. Bichlmeier; S. M. Heining; M. Rustaee; N. Navab","TUM, Computer Aided Medical Procedures & Augmented Reality (CAMP), Munich, Germany; Trauma Surgery Department, Klinikum Innenstadt, LMU, Munich, Germany; TUM, Computer Aided Medical Procedures & Augmented Reality (CAMP), Munich, Germany; TUM, Computer Aided Medical Procedures & Augmented Reality (CAMP), Munich, Germany","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","125","128","In this paper we present the evaluation of a virtual mirror used as a navigational tool within a medical augmented reality (AR) system for laparoscopy. 12 surgeons of our clinical partner participated in an experiment to evaluate whether laparoscope augmentation extended by a virtual mirror is useful for improved perception of complex structures. Such complex structures are encountered for instance in laparoscopic resection of tumor affected liver tissue. The blood vessels supplying the tumor have to be cut and closed before tumorous tissue can be removed. A laparoscopic camera and an optical tracking system allow for the visualization of visualized medical volumetric data registered with the real anatomy. Previously injected contrast agent provides an accentuation of blood vessels within the visualization. For evaluating the suitability of a virtual mirror to support the mentioned procedure, we designed a phantom consisting of wooden branches simulating the structure of blood vessel trees. Quantitative results of the experiment show the advantage of a mirror in certain cases, when blood vessels cannot be directly seen from the camera point of view due to self-occlusion of the structure. Results of a questionnaire filled out by the surgeons after the experiments confirm the acceptance of AR technology for particular medical procedures.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538836","Augmented reality;navigated surgery;medical visualization;user interaction","Laparoscopes;Mirrors;Surgery;Blood vessels;Data visualization;Liver neoplasms;Cameras;Navigation;Augmented reality;Biomedical optical imaging","augmented reality;blood vessels;liver;medical computing;tumours","laparoscopic virtual mirror;vessel structure evaluation;navigational tool;medical augmented reality system;laparoscopy;tumor;liver tissue;blood vessels;medical volumetric data","","11","","10","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Evaluation of labelling layout methods in augmented reality","G. Li; Y. Liu; Y. Wang","Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, China","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","351","352","View management techniques are commonly used for labelling of objects in augmented reality environments. Combining with image analysis, search space and adaptive representations, they can be utilized to achieve desired labelling tasks. However, the evaluation of different search space methods on labelling are still an open problem. In this paper, we propose an image analysis based view management method, which first adopts the image processing to superimpose 2D labels to the specific object. We then conduct three search space methods to an augmented reality scenario. Without the requirements of setting rules and constraints for occlusion among the labels, the results of three search space methods are evaluated by using objective analysis of related parameters. The evaluation results indicate that different search space methods could generate different time costs and occlusion, thereby affecting the final labelling effects.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892321","Augmented reality;labelling;search space","Labeling;Augmented reality;Search problems;Layout;Cameras;Two dimensional displays;Image edge detection","augmented reality;image representation;search problems","labelling layout;augmented reality;view management;image analysis;search space;adaptive representations;image processing","","1","","4","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"LabXscape: A Prototype for Enhancing Player Experience in Cross-Reality Gameplay","M. McCready; A. Covaci; L. Tabbaa",University of Kent; University of Kent; University of Kent,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","183","187","Interest in multiplayer games that allow players to connect and play together using different technologies, such as virtual or augmented reality (VR/AR) has increased. Research has shown that in cross-reality gaming experiences (eg. where there are differences in players' abilities, user interface (UI), and methods of interaction) it is possible to achieve an enhanced player experience (PX) through various interdependencies. However, most of the previous work focuses on co-located scenarios, where the space and proximity of the players are local and utilized. In this study we present a cross-reality prototype called LabXscape. Through the prototype we are researching how asymmetries of space, UI, methods of interaction, information access, and narrative impact the PX for players using different technologies (eg. VR, AR, PC). In this cross-reality prototype, players can connect with different devices found on the Milgram and Kishino's Reality-Virtuality Continuum [1]. Their interactions, movements, and information influence and are shared with each other, creating a cross-reality experience [2]. Our observations reveal that there are factors that allow non-VR players to have as engaging experience as VR players, despite using a less immersive device.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974172","Virtual reality;mixed/augmented reality;gameplay;narrative;multiplayer;asymmetric;cross-reality","Prototypes;Games;User interfaces;Augmented reality","augmented reality;computer games;user interfaces;virtual reality","augmented reality;cross-reality experience;cross-Reality gameplay;cross-reality gaming experiences;cross-reality prototype;engaging experience;enhanced player experience;enhancing player experience;Kishino's Reality;LabXscape;multiplayer games;nonVR players;PX;UI;virtual reality;VR players","","","","23","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Augmented foam: a tangible augmented reality for product design","Woohun Lee; Jun Park","Department of Industrial Design, KAIST, Daejeon, South Korea; Department of Computer Science, Hongik University, Seoul, South Korea","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","106","109","Computer aided design applications have become designers' inevitable tools for expressing and simulating innovative ideas and concepts. However, replacing traditional materials and mock-ups with 3D CAD systems, designers are faced with the intangibility problem, unable to physically interact with test products in early stages of design process. As a touchable and graspable interface based on 3D CAD data, we propose augmented foam, which applies augmented reality technologies to physical blue foams. Using augmented foam, a blue foam mock-up is overlaid with a 3D virtual object, which is rendered with the same CAD model used for mock-up production. We presented a method to correct occlusions of the virtual products by user's hand. Augmented foam was tested for a mug design and a cleaning robot design. Designers were able to inspect and evaluate the design alternatives interactively and efficiently.","","0-7695-2459-1","10.1109/ISMAR.2005.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544670","","Augmented reality;Product design;Design automation;Computer applications;Application software;Computational modeling;Computer simulation;Materials testing;System testing;Process design","CAD/CAM;product design;virtual manufacturing;augmented reality;graphical user interfaces;rendering (computer graphics);hidden feature removal;foams","augmented foam;tangible augmented reality;product design;computer aided design;3D CAD system interface;augmented reality;blue foam mock-up;3D virtual object rendering;CAD model;mock-up production;occlusion;virtual product;mug design;cleaning robot design","","18","4","17","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Fingertips Interaction Method in Handheld Augmented Reality for 3D Manipulation","M. N. A. Nor’a; F. E. Fadzli; A. W. Ismail; Z. S. O. Vicubelab; M. Y. F. Aladin; W. A. A. W. Hanif","Mixed and Virtual Reality Research Lab, Vicubelab School of Computing, Universiti Teknologi Malaysia, Johore, Malaysia; Mixed and Virtual Reality Research Lab, Vicubelab School of Computing, Universiti Teknologi Malaysia, Johore, Malaysia; Mixed and Virtual Reality Research Lab, Vicubelab School of Computing, Universiti Teknologi Malaysia, Johore, Malaysia; School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia, Johore, Malaysia; Mixed and Virtual Reality Research Lab, Vicubelab School of Computing, Universiti Teknologi Malaysia, Johore, Malaysia; Mixed and Virtual Reality Research Lab, Vicubelab School of Computing, Universiti Teknologi Malaysia, Johore, Malaysia","2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA)","10 Nov 2020","2020","","","161","166","Augmented Reality (AR) technology enhanced real world environment with virtual information either in two-dimensional (2D) or three-dimensional (3D) format. AR requires the interactive techniques to be as intuitive as possible for the user to accept. The issues to be addressed are the tracking inaccuracy and occlusion problems. Therefore, a prototype that enables fingertip manipulation method in handheld AR interface is developed. This paper explains user ability to interact directly with the virtual 3D object and manipulate it using fingertip-based gestures in handheld AR. It is used to perform 3D object manipulation for users to naturally interact and manipulate the virtual 3D objects. The paper describes the development phase, AR application with fingertip-based manipulation method to manipulate 3D object. Gesture tracking device is attached to handheld device to track the user's natural hand interaction. The result presents in this research is a new prototype to Ancient Malacca AR application with fingertip-based manipulation method for handheld AR interface.","2642-7354","978-1-7281-6324-6","10.1109/ICCCA49541.2020.9250913","Universiti Teknologi Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250913","Augmented Reality;Fingertip Interaction;Gesture Recognition;3D Object Manipulation;Handheld Augmented Reality","Performance evaluation;Three-dimensional displays;Handheld computers;Conferences;Two dimensional displays;Prototypes;Augmented reality","augmented reality;gesture recognition","handheld augmented reality;virtual information;three-dimensional format;interactive techniques;occlusion problems;fingertip manipulation method;handheld AR interface;user ability;virtual 3D object;fingertip-based gestures;3D object manipulation;gesture tracking device;natural hand interaction;fingertip interaction method;augmented reality technology enhanced real world environment;Ancient Malacca AR application","","3","","22","IEEE","10 Nov 2020","","","IEEE","IEEE Conferences"
"Wearable augmented reality system using gaze interaction","H. M. Park; Seok Han Lee; Jong Soo Choi","The Graduate School of Advanced Imaging Science, Multimedia & Film, University of Chung-Ang, Seoul, South Korea; The Graduate School of Advanced Imaging Science, Multimedia & Film, University of Chung-Ang, Seoul, South Korea; The Graduate School of Advanced Imaging Science, Multimedia & Film, University of Chung-Ang, Seoul, South Korea","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","175","176","Undisturbed interaction is essential to provide immersive AR environments. There have been a lot of approaches to interact with VEs (virtual environments) so far, especially in hand metaphor. When the user’s hands are being used for hand-based work such as maintenance and repair, necessity of alternative interaction technique has arisen. In recent research, hands-free gaze information is adopted to AR to perform original actions in concurrence with interaction. [3, 4]. There has been little progress on that research, still at a pilot study in a laboratory setting. In this paper, we introduce such a simple WARS(wearable augmented reality system) equipped with an HMD, scene camera, eye tracker. We propose ‘Aging’ technique improving traditional dwell-time selection, demonstrate AR gallery — dynamic exhibition space with wearable system.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637353","wearable;augmented reality;gaze interaction;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces and Presentation]: User Interfaces","Aging;Augmented reality;Maintenance engineering;Virtual environment;Integrated optics;Cameras;Art","augmented reality;helmet mounted displays;human computer interaction;motion estimation;wearable computers","wearable augmented reality system;gaze interaction;AR;virtual environments;VE;hand-based work;alternative interaction technique;WARS;HMD;head mounted display;scene camera;eye tracker","","34","5","6","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Augmented Reality Remote Collaboration with Dense Reconstruction","J. Zillner; E. Mendez; D. Wagner",DAQRI Vienna; DAQRI Vienna; DAQRI Vienna,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","38","39","This paper describes an Augmented Reality remote collaboration system leveraging high-fidelity, dense scene reconstruction for intuitive and precise remote guidance. A local worker in need of help can use our system to automatically generate a 3D mesh of the surrounding and stream it to a remote expert. The remote expert can navigate and explore the reconstructed environment independently of the local worker in six degrees of freedom. World-stabilized text- and image-annotations can be placed in the scene and strokes drawn on surfaces are intelligently positioned in the world. In addition, the reconstruction allows the remote expert to segment colored objects from the mesh and use the resulting 3D model to create simple animations in order to convey precise instructions.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699225","Augmented Reality;CSCW;Remote Collaboration;Telepresence;Dense Reconstruction;Human-centered computing;Human computer interaction;Interaction paradigms;Mixed / augmented reality","Image reconstruction;Three-dimensional displays;Augmented reality;Collaboration;Glass;Real-time systems;Tools","augmented reality;computer animation;image colour analysis;image reconstruction;image segmentation;mesh generation;solid modelling","remote expert;dense scene reconstruction;augmented reality remote collaboration system;3D mesh generation;colored objects segmentation;3D model","","16","","8","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Future Agriculture Farm Management using Augmented Reality","M. Xi; M. Adcock; J. McCulloch",CSIRO; CSIRO; CSIRO,"2018 IEEE Workshop on Augmented and Virtual Realities for Good (VAR4Good)","16 Dec 2018","2018","","","1","3","Augmented reality (AR) technology is blooming in the past few years with a growing number of low-cost AR devices becoming available to the general public. AR techniques have demonstrated the capacity to optimise task efficiency in a broad range of industries and provide engaging entertainment and education experiences. However, the potential of AR has not yet been fully explored. One of the extremely underexplored areas is its application in broad agriculture sector. As a major source of food, agriculture has always been a national priority. Agriculture farming is highly labour-intensive and heavily relies on individual farmer's expertise, resulting in challenging farm management issues. We argue that AR can make critical contributions to the optimum management of agriculture farms. We take aquaculture ponds as an example, and presented three use cases to show how AR can potentially support more efficient farm management activities: water quality management, remote collaboration, and boardroom discussion.","","978-1-5386-5977-9","10.1109/VAR4GOOD.2018.8576887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576887","Augmented reality;interactive data visualisation;decision making;farm management;H.5.1 [Information Interfaces and Presentation (e.g., HCI)]: Multimedia Information Systems;Artificial, augmented, and virtual realities","Aquaculture;Augmented reality;Collaboration;Task analysis;Training;Biomass","agricultural engineering;agriculture;aquaculture;augmented reality;decision making;food products;water quality","water quality management;augmented reality technology;decision making;agriculture farm management;food source;aquaculture ponds;remote collaboration;boardroom discussion","","12","","34","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"In-place Augmented Reality","N. Hagbi; O. Bergig; J. El-Sana; K. Kedem; M. Billinghurst","Computer Science Department, Ben-Gurion University, Israel; Computer Science Department, Ben-Gurion University, Israel; Computer Science Department, Ben-Gurion University, Israel; Computer Science Department, Ben-Gurion University, Israel; The HIT Lab, NZ University of Canterbury, New Zealand","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","135","138","In this paper we present a new vision-based approach for transmitting virtual models for augmented reality (AR). A two dimensional representation of the virtual models is embedded in a printed image. We apply image-processing techniques to interpret the printed image and extract the virtual models, which are then overlaid back on the printed image. The main advantages of our approach are: (1) the image of the embedded virtual models and their behaviors are understandable to a human without using an AR system, and (2) no database or network communication is required to retrieve the models. The latter is useful in scenarios with large numbers of users. We implemented an AR system that demonstrates the feasibility of our approach. Applications in education, advertisement, gaming, and other domains can benefit from our approach, since content providers need only to publish the printed content and all virtual information arrives with it.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637339","Augmented Reality content;content transmission;model embedding;dual perception encoding;H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities;I.4.0 [Image Processing and Computer Vision]: Image processing software","Augmented reality;Image color analysis;Libraries;Solid modeling;Pixel;Visualization;Databases","augmented reality;image processing","augmented reality;image-processing techniques;printed content","","8","2","17","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Seeing is Believing: Improving the Perceived Trust in Visually Embodied Alexa in Augmented Reality","S. Haesler; K. Kim; G. Bruder; G. Welch",University of Würzburg; University of Central Florida; University of Central Florida; University of Central Florida,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","204","205","Voice-activated Intelligent Virtual Assistants (IVAs) such as Amazon Alexa offer a natural and realistic form of interaction that pursues the level of social interaction among real humans. The user experience with such technologies depends to a large degree on the perceived trust in and reliability of the IVA. In this poster, we explore the effects of a three-dimensional embodied representation of Amazon Alexa in Augmented Reality (AR) on the user's perceived trust in her being able to control Internet of Things (IoT) devices in a smart home environment. We present a preliminary study and discuss the potential of positive effects in perceived trust due to the embodied representation compared to a voice-only condition.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699187","Augmented reality;intelligent virtual assistants;social interaction;perceived trust and reliability;Internet of Things;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, Augmented, and Virtual Realities","Task analysis;Visualization;Augmented reality;Internet of Things;Resists;Market research;Personal digital assistants","augmented reality;home computing;human computer interaction;Internet of Things;speech-based user interfaces;trusted computing;user experience","perceived trust;visually embodied Alexa;Augmented Reality;Voice-activated Intelligent Virtual Assistants;IVA;social interaction;user experience;three-dimensional embodied representation;Amazon Alexa;Internet of Things devices;IoT devices;smart home environment","","6","","6","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Evaluation of Direct Manipulation Methods in Augmented Reality Environments Using Google Glass","A. Ohlei; T. Winkler; D. Wessel; M. Herczeg","Institute for Multimedia and Interactive Systems (IMIS), University of Luebeck; Institute for Multimedia and Interactive Systems (IMIS), University of Luebeck; Institute for Multimedia and Interactive Systems (IMIS), University of Luebeck; Institute for Multimedia and Interactive Systems (IMIS), University of Luebeck","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","266","269","This paper presents a study examining interaction methods for manipulating objects in augmented reality (AR) environments using Google Glass (Glass). We compared five interaction methods; three of them were implemented on Glass (virtual buttons, swipe pad of Glass, remote control via the touchscreen of a smartwatch) and two on a smartphone (virtual buttons and the touch interaction). 32 participants were asked to scale and rotate a virtual 3D object created from a physical sculpture of the Museum Günter Grass-Haus in Luebeck using the AR-App InfoGrid4Glass. We studied the interaction methods by measuring effectiveness, efficiency, and satisfaction of the users. The results of the study showed that smartphone interaction is superior to any Google Glass interaction methods. Of the interaction methods implemented for Glass, a combination of Glass with a smartwatch shows the highest usability. Our findings suggest that if users have a smartwatch available, it offers them a higher usability for interacting with virtual objects rather than using the touch pad of Glass or virtual buttons on Glass.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699326","Augmented Reality;Cross-Device Interaction;User study;Google Glass;Smartwatch;•Human-centered computing → Mixed / augmented reality","Augmented reality","augmented reality;human computer interaction;smart phones;touch sensitive screens","direct manipulation methods;augmented reality environments;touch interaction;virtual 3D object;AR-App InfoGrid4Glass;smartphone interaction;Google Glass interaction methods;Museum Günter Grass-Haus;smartwatch","","","","12","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"VRCEMIG: A virtual reality system for real time control of electric substations","A. Cardoso; E. Lamounier; G. Lima; L. Oliveira; L. Mattioli; G. Júnior; A. Silva; K. Nogueira; P. do Prado; J. Newton","Virtual and Augmented Reality Group, Faculty of Electrical Engineering, Federal University of Uberlândia, Brazil; Virtual and Augmented Reality Group, Faculty of Electrical Engineering, Federal University of Uberlândia, Brazil; Virtual and Augmented Reality Group, Faculty of Electrical Engineering, Federal University of Uberlândia, Brazil; Virtual and Augmented Reality Group, Faculty of Electrical Engineering, Federal University of Uberlândia, Brazil; Virtual and Augmented Reality Group, Faculty of Electrical Engineering, Federal University of Uberlândia, Brazil; Virtual and Augmented Reality Group, Faculty of Electrical Engineering, Federal University of Uberlândia, Brazil; Virtual and Augmented Reality Group, Faculty of Electrical Engineering, Federal University of Uberlândia, Brazil; Virtual and Augmented Reality Group, Faculty of Electrical Engineering, Federal University of Uberlândia, Brazil; Electric Energy Company of Minas Gerais, Brazil; Electric Energy Company of Minas Gerais, Brazil","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","165","166","This research demonstration presents an integrated hardware and software platform developed for controlling electric substations, through a virtual environment. Each 3D substation is integrated with the supervision, data acquisition and control center of a real electric energy company. Today, this is pursued on a 2D diagram, lacking intuitiveness. VRCEMIG explores techniques to provide deeper immersion and intuitive interactions in order to support not only training for future employees, but also real time operation. During the demonstration visitors will be able to use different devices such as joystick, gamepad and VR glasses to navigate and operate an electric substation (for training purposes only). This substation belongs to the Brazilian company CEMIG, a research partner.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549414","virtual reality;electric power substations;operation control system","Virtual reality","augmented reality;computer based training;electricity supply industry;hydroelectric power stations;industrial training;interactive devices;power system control;SCADA systems;substations","VRCEMIG;virtual reality system;real time electric substation control;integrated hardware platform;integrated software platform;virtual environment;3D substation;supervision-data acquisition-control center;electric energy company;2D diagram;intuitive interactions;employee training;joystick;gamepad;VR glasses;electric substation operation;electric substation navigation;Brazilian CEMIG company","","22","","6","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"Localization Service Using Sparse Visual Information Based on Recent Augmented Reality Platforms","J. R. Puigvert; T. Krempel; A. Fuhrmann",Cologne Intelligence; Cologne Intelligence; TH Köln,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","415","416","The ability to localize a device or user precisely within a known space, would allow many use cases on the context of location-based augmented reality. We propose a localization service based on sparse visual information using ARCore [4], a state-of-the-art augmented reality platform for mobile devices. Our service is constituted by two components: front-end and back-end. On the front-end, using the point cloud generated by ARCore as feature points, a corresponding binary keypoint descriptor algorithm like ORB [6] or FREAK [1] is computed to describe the place. On the back-end, this binary descriptor is searched in a map using the bags of binary words technique [3], responding with the position of the recognized place.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699237","Augmented Reality;Localization;SLAM;Recognition","Visualization;Augmented reality;Simultaneous localization and mapping;Tracking;Three-dimensional displays;Prototypes;Computer architecture","augmented reality;mobile computing","point cloud;feature points;binary descriptor;localization service;sparse visual information;location-based augmented reality;mobile devices;augmented reality platforms;ARCore;binary keypoint descriptor algorithm","","1","","6","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"An Architecture for Capturing and Presenting Learning Outcomes using Augmented Reality Enhanced Analytics","M. SINGH; S. BANGAY; A. SAJJANHAR","School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","611","612","Augmented Reality (AR) applications have the capabilities to collect a range of sensor data that is relevant to educators. We propose a platform for using AR to enhance learning analytics by 1) Capturing information from a range of sources including directly from sensors but also from interactions and outcomes within the AR experience. 2) Deriving metrics from this sensory data to provide five categories of measure representing the quality of the learning experience: namely (a) Learning Analytics, (b) Interaction Analytics, (c) Spatial Analytics, (d) Sensory Analytics and (d) Emotion Analytics. 3) Presenting real-time information as analytics to teachers directly as an information overlay using an AR view within the classroom and customised to each student. 4) Closing the student-teacher-student feedback loop so that analytics information feeds directly into teaching in addition to assessment after the event. We evaluate the feasibility of this architecture by 1) Providing a proof-of-concept demonstration showing that the required data can be collected on the targeted platforms. 2) Identifying relevant educational metrics and relating these to the sensor data being collected. 3) Creating educational augmented reality applications and validating these with learners. 4) Identifying teacher requirements with respect to the use of analytics dashboards. The proposed architecture ensures that teachers can differentiate teaching support for each student based on individual needs across the range of learning needs.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974171","Augmented reality;analytics;education;architecture","Measurement;Feedback loop;Education;Real-time systems;Feeds;Augmented reality","augmented reality;computer aided instruction;distance learning;further education;teaching","analytics dashboards;analytics information;augmented Reality enhanced Analytics;educational augmented reality applications;Emotion Analytics;Interaction Analytics;learning analytics;learning experience;Presenting Learning outcomes;real-time information;sensor data;Sensory Analytics;sensory data;Spatial Analytics;student-teacher-student feedback loop","","","","6","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Use of Augmented Reality for Computational Thinking Stimulation through Virtual","A. M. d. S. Esteves; A. L. M. Santana; R. Lyra","Universidade do Vale do Itajaí, Itajai, Brazil; Universidade Anhembi Morumbi, Sao Paulo, Brazil; Universidade do Vale do Itajaí - UNIVALI, Itajaí, Brazil","2019 21st Symposium on Virtual and Augmented Reality (SVR)","5 Dec 2019","2019","","","102","106","Studies with augmented reality show that while the technology helps the student learn, it may end up disturbing other points, showing that more research is needed with the use of augmented reality. Also, a topic that is growing within education is Computational Thinking, which says that the thinking like computer scientists is necessary for the 21st century and should be disseminated mainly in schools during basic education. In the face of this, this work created an augmented reality android application that tracks physical tiles and creates 3D maps for the user, also giving a character that can be programmed to walk on this created map, simulating a programming toy. Finally, tests carried out with the application have shown that augmented reality currently has performance problems when multiple targets are used, so, devices with low processing have problems at map tracking. These issues affected the tests with the children, which made it difficult for them to track the map like they wanted, but they still liked the app even after it. That shows that the acceptance of the technology by the children is good, which can help developing Computational Thinking, but the technology limitation is still a problem. These obstacles while currently hindering the use of augmented reality in education may in the future be irrelevant due to the constant advancement of technology. This paper's main contribution is showing one possibility of using AR with Computational Thinking and what needs to evolve for it to be used by the usable by the children.","","978-1-7281-5434-3","10.1109/SVR.2019.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8921049","Computational Thinking;Augmented Reality;Technology in Education","Augmented reality;Education;Target tracking;Programming profession;Rendering (computer graphics);Androids","augmented reality;computer aided instruction;computer science education;educational institutions;mobile computing","map tracking;created map;augmented reality android application;computer scientists;Computational Thinking stimulation","","4","","10","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"The augmented Van Gogh's: Augmented reality experiences for museum visitors","Y. Kolstee; W. van Eck","AR Laboratory, Royal Academy of Art, The Hague, Netherlands; AR Laboratory, Royal Academy of Art, The Hague, Netherlands","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","49","52","To mark the completion of the restoration of Van Gogh's painting `The Bedroom', and as part of the Friday Evening events organised by the Van Gogh Museum, the AR Lab was asked to develop three installations dedicated to the exhibition `Paul Gauguin: The Breakthrough into Modernity'. With these installations we aimed to make it possible for visitors to discover paintings by Van Gogh in a playful and exciting way. One of the installations features the painting `The Bedroom' which is shown on a large screen, and by using a digitally modified spray-can, visitors can reveal information about the painting normally not accessible, like x-ray, infrared and ultra violet images, or even the back of the painting. We will describe and later discuss these experimental augmented reality installations, and reflect on the lessons learned in order to make interaction with cultural heritage more exciting.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093656","Augmented Reality;Cultural Heritage;Innovative Visualization Techniques;Design;Interaction","Painting;Augmented reality;Cultural differences;Monitoring;Face;Virtual environments;X-ray imaging","art;augmented reality;museums","augmented reality;museum visitor;Van Gogh painting;The Bedroom;Van Gogh Museum;AR Lab;digitally modified spray-can;cultural heritage","","15","","4","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"An augmented reality view on mirror world content, with Image Space","D. J. Murphy; M. Kähäri; V. -V. Mattila","Nokia Research Center, Helsinki, Finland; Nokia Research Center, Helsinki, Finland; Nokia Research Center, Tampere, Finland","2010 IEEE Virtual Reality Conference (VR)","8 Apr 2010","2010","","","291","292","We present a prototype mobile augmented reality client addition to the ¿Image Space¿ mixed reality media sharing service. We have explored how the real world aligned ""mirror world"" content from that service can be interacted with in-situ and identified two different use scenarios - geospatial media sharing and social connection. Since both the existing web based mirror world modality and the additional mobile augmented reality modality intersect at the common data, the combined service is as an example of how mirror worlds can be used to bridge the real and the virtual, and allow for interaction from either side of the reality continuum.","2375-5334","978-1-4244-6238-4","10.1109/VR.2010.5444761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444761","Mixed Reality;Augmented Reality;Mirror Worlds","Augmented reality;Mirrors;Virtual reality;Layout;Context-aware services;Global Positioning System;Prototypes;Bridges;Multimedia systems;Information systems","augmented reality;mobile computing","augmented reality view;mirror world content;image space;mixed reality media sharing service;geospatial media sharing;social connection;Web based mirror world modality;mobile augmented reality modality;reality continuum","","5","2","12","IEEE","8 Apr 2010","","","IEEE","IEEE Conferences"
"SnapAR: Storing snapshots for quick viewpoint switching in hand-held augmented reality","M. Sukan; S. Feiner","Columbia University, USA; Columbia University, USA","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","273","274","Many tasks require a user to move between various locations within an environment to get different perspectives. This can take significant time and effort, especially when the user must switch among those viewpoints repeatedly. We explore augmented reality interaction techniques that involve taking still pictures of a physical scene using a tracked hand-held magic lens and seamlessly switching between augmenting either the live view or one of the still views, without needing to physically revisit the snapshot locations. We describe our optical-marker-tracking-based implementation and how we represent and switch among snapshots. To determine the effectiveness of our techniques, we developed a test application that lets its user view physical and virtual objects from different viewpoints.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643603","Augmented reality;viewpoint switching","Cameras;Optical switches;Augmented reality;Visualization;Arrays;Three dimensional displays","augmented reality;computer vision;optical tracking;photographic lenses","SnapAR;quick viewpoint switching;handheld augmented reality;augmented reality interaction technique;still picture;physical scene;tracked handheld magic lens;snapshot location;optical marker tracking based implementation;virtual object","","7","3","7","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality Based on Invisible Marker","C. Lim; C. Kim; J. -I. Park; H. Park","Department of Computer and Software, Hanyang University; Department of Computer and Software, Hanyang University; Department of Computer and Software, Hanyang University; Department of Electronic Engineering, Pukyong National University","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","78","81","This paper proposes an approach for implementing marker-based augmented reality (AR) on smartphone. Specifically, to resolve the obtrusiveness of visual markers, use of infrared (IR) markers that are not visible to the human eye is studied. The main idea is to use an additional external camera with IR functionality to track IR markers that are not detectable in smartphone camera. Additionally is to put a visual fiducial object at the place where the fields of view of the external camera and the smartphone camera are overlapping, which enables the external camera to track the geometric transform between the fiducial object and the IR markers. As a result, since the fiducial object is trackable with the smartphone camera, the smartphone camera pose relative to the IR markers can be computed by using the transform. To validate the feasibility of the proposed approach, a proof-of-concept system is implemented where a visual marker is used as fiducial object for the convenience of implementation. The system accuracy mainly depends on the transform accuracy. Thus, to improve the transform accuracy, two constraints are defined and evaluated: one is that both markers lie on the same plane and the other is that the 3D marker data is available. Through experiments, with the constraints, it is verified that virtual contents can be stably augmented on IR markers in smartphone camera images.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836466","mobile augmented reality;invisible marker;fiducial object;external camera with IR functionality","Decision support systems;Augmented reality","augmented reality;cameras;smart phones","mobile augmented reality;invisible marker;marker-based augmented reality;AR;visual markers;infrared markers;IR markers;human eye;IR functionality;visual fiducial object;geometric transform;proof-of-concept system;3D marker data;smartphone camera images","","3","","10","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Intelligent Adaptive Agents and Trust in Virtual and Augmented Reality","N. Sun; J. Botev","Department of Computer Science, University of Luxembourg; Department of Computer Science, University of Luxembourg","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","303","305","Intelligent adaptive agents (IAA) are rapidly evolving due to the sharp growth in computational power and recent advances in artificial intelligence research. From chatbots, over personal virtual assistants and decision-aiding systems, to self-driving systems, they can greatly facilitate common tasks and IAA are increasingly finding their way into many aspects of daily life. However, and often against better knowledge, users remain skeptical towards IAA, in particular when critical interests are involved. Virtual and augmented reality (VR/AR), with their experiential and immersive character, particularly allow for new ways of interaction and establishing trust between users and IAA. Taking a multidisciplinary approach, the research in this PhD project revolves around the fundamental factors and techniques to establish trust in order to facilitate and systemize the design of IAA in future VR/AR settings.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288388","Human-centered computing—Human computer interaction (HCI)—HCI design and evaluation methods;Human-centered computing—Interaction design;Computing methodologies—Computer graphics—Graphics systems and interfaces—Virtual reality;Computing methodologies—Computer graphics—Graphics systems and interfaces—Mixed/augmented reality","Economics;Sociology;Psychology;Object recognition;Task analysis;Augmented reality;Guidelines","artificial intelligence;augmented reality;chatbots;medical computing;multi-agent systems;trusted computing","augmented reality;IAA;intelligent adaptive agents;artificial intelligence;personal virtual assistants;decision-aiding systems;chatbots;self-driving systems;virtual reality","","","","31","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Real Time 3D Magnetic Field Visualization Based on Augmented Reality","X. Liu; Y. Liu; Y. Wang","Beijing Institute of Technology, Beijing, Beijing, CN; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1052","1053","In physics teaching, electromagnetism is one of the most difficult concepts for students to understand. This paper proposes a real time visualization method for 3-D magnetic field based on the augmented reality technology, which can not only visualize magnetic flux lines in real time, but also simulates the approximate sparse distribution of magnetic flux lines in space. An application utilizing this method is also presented. It permits leaners to freely and interactively move the magnets in 3-D space and to observe the magnetic flux lines in real time. As a result, the proposed method visualizes the invisible factors in 3-D magnetic field, with which students will have real-life reference when studying electromagnetic.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797782","augmented reality;real time visualization;magnetic flux lines;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Visualization;Visualization application domains;Scientific visualization","Real-time systems;Magnetic fields;Visualization;Magnetic domains;Augmented reality;Magnetic flux density","augmented reality;computational electromagnetics;computer aided instruction;magnetic fields;magnetic flux;magnetic variables measurement;physics education;teaching","augmented reality technology;magnetic flux lines;real time 3D magnetic field visualization;physics teaching;electromagnetism","","6","","3","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Visitor Artwork Ambient and how Making New Functions of Cultural Heritage by Using Augmented Reality within an Ambient Intelligence","L. Carnevale; L. Damiano; A. Fleres; M. Villari","Department of Mathematical and Computer Science, Physical Science and Earth Sciences, University of Messina; Department of Communication, Arts and Media, IULM University; Department of Ancient and Modern Civilization, University of Messina; Department of Mathematical and Computer Science, Physical Science and Earth Sciences, University of Messina","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","8","12","The recent massive development of technology has radically changed the relationship between humans and their reality. Engineering sciences are literally re-shaped the world where people are living, and consequently how humans use technology. In this context, classical frameworks, and methodologies to provide Cultural Heritage experiences are poorly equipped to tackle the dynamic and heterogeneous needs of visitors. In this paper, we propose a reference framework that aims to enhance the interaction between visitors, artworks and the ambient, by the mediation of technology. Stemming from the proposed reference architecture, we also discuss a series of open challenges, which we believe represent relevant research directions in the nearest future.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585801","Cultural heritage;Augmented reality;Ambient intelligence;Epistemology;Ethics of technology;Philosophy of mixed reality","Shape;Mixed reality;Ambient intelligence;Cultural differences;Mediation;Augmented reality","augmented reality;history","visitor artwork ambient;augmented reality;ambient intelligence;engineering sciences;Cultural Heritage experiences;reference framework;reference architecture","","","","22","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Visual Hints for Tangible Gestures in Augmented Reality","S. White; L. Lister; S. Feiner","Columbia University, USA; Columbia University, USA; Columbia University, USA","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","47","50","Tangible augmented reality (AR) systems imbue physical objects with the ability to act and respond in new ways. In particular, physical objects and gestures made with them gain meaning that does not exist outside the tangible AR environment. The existence of this new set of possible actions and outcomes is not always apparent, making it necessary to learn new movements or gestures. Addressing this opportunity, we present visual hints, which are graphical representations in AR of potential actions and their consequences in the augmented physical world. Visual hints enable discovery, learning, and completion of gestures and manipulation in tangible AR. Here, we discuss our investigation of a variety of representations of visual hints and methods for activating them. We then describe a specific implementation that supports gestures developed for a tangible AR user interface to an electronic field guide for botanists, and present results from a pilot study.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538824","Tangible augmented reality;visual hints;gestures;electronic field guide","Augmented reality;Displays;User interfaces;Chromium;Multimedia systems;Virtual reality;Documentation;Morphology;Radio access networks;History","augmented reality;computer vision;user interfaces","augmented reality;tangible gestures;visual hints;graphical representations;user interface","","30","7","17","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Hear-Through and Mic-Through Augmented Reality: Using Bone Conduction to Display Spatialized Audio","R. W. Lindeman; H. Noma; P. G. de Barros","Worcester Polytechnic Institute, USA; ATR International, Japan; Worcester Polytechnic Institute, USA","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","173","176","We present a novel approach for mixing real and computer-generated audio for augmented reality (AR) applications. Analogous to optical-see-through and video-see-through techniques in the visual domain, we present Hear-Through and Mic-Through audio AR. Hear-Through AR uses a bone-conduction headset to deliver computer-generated audio, while leaving the ear canals free to receive audio from the surrounding environment. Mic-Through AR allows audio signals captured from ear-worn microphones to be mixed with computer-generated audio in the computer, and delivered to the user over headphones. We present preliminary results from an empirical user study conducted to compare a bone-conduction device, headphones, and a speaker array. The results show that subjects achieved the best accuracy using an array of speakers physically located around the listener when stationary sounds were played, but that there was no difference in accuracy between the speaker array and the bone-conduction device for sounds that were moving, and that both devices outperformed standard headphones for moving sounds.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538843","Augmented reality;audio;bone conduction","Augmented reality;Bones;Auditory displays;Headphones;Loudspeakers;Computer displays;Application software;Optical mixing;Optical computing;Ear","augmented reality;headphones;microphones","hear-through augmented reality;mic-through augmented reality;bone conduction headset;computer-generated audio;speaker array","","16","","11","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Passive Deformable Haptic glove to support 3D interactions in mobile augmented reality environments","T. N. Hoang; R. T. Smith; B. H. Thomas","University of South Australia, Wearable Computer Laboratory; University of South Australia, Wearable Computer Laboratory; University of South Australia, Wearable Computer Laboratory","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","257","258","We present a passive deformable haptic (PDH) glove to enhance mobile immersive augmented reality manipulation with a sense of computer-captured touch, responding to objects in the physical environment. We extend our existing pinch glove design with a Digital Foam sensor, placed under the palm of the hand. The novel glove input device supports a range of touch-activated, precise, direct manipulation modeling techniques with tactile feedback including hole-punching, trench cutting, and chamfer creation. The PDH glove helps improve a user's task performance time, decrease error rate and erroneous hand movements, and reduce fatigue.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671793","Passive Haptics;Augmented Reality;Pinch Gloves;Input Device;Interaction Technique","Haptic interfaces;Materials;Mobile communication;Augmented reality;Thumb;Nails","augmented reality;data gloves;mobile computing;tactile sensors","passive deformable haptic glove;3D interactions;mobile augmented reality environments;PDH glove;mobile immersive augmented reality manipulation;computer-captured touch;pinch glove design;Digital Foam sensor;glove input device;direct manipulation modeling techniques;tactile feedback;hole-punching;trench cutting;chamfer creation","","7","","10","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Giving mobile devices a SIXTH sense: Introducing the SIXTH middleware for Augmented Reality applications","A. G. Campbell; L. Görgü; B. Kroon; D. Lillis; D. Carr; G. M. P. O'Hare","CLARITY: Centre for Sensor Web Technologies, School of College Dublin, Belfield, Ireland; CLARITY: Centre for Sensor Web Technologies, School of College Dublin, Belfield, Ireland; CLARITY: Centre for Sensor Web Technologies, School of College Dublin, Belfield, Ireland; CLARITY: Centre for Sensor Web Technologies, School of College Dublin, Belfield, Ireland; CLARITY: Centre for Sensor Web Technologies, School of College Dublin, Belfield, Ireland; CLARITY: Centre for Sensor Web Technologies, School of College Dublin, Belfield, Ireland","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","245","246","With the increasing availability of sensors within smartphones and within the world at large, a question arises about how this sensor data can be leveraged by Augmented Reality (AR) devices. AR devices have traditionally been limited by the capability of a given device's unique set of sensors. Connecting sensors from multiple devices using a Sensor Web could address this problem. Through leveraging this SensorWeb existing AR environments could be improved and new scenarios made possible, with devices that previously could not have being used as part of an AR environment. This paper proposes the use of SIXTH: a middleware designed to generate a Sensor Web, which allows a device to leverage heterogeneous external sensors within its environment to help facilitate the creation of richer AR experiences. This paper will present a worst case scenario, in which the device chosen will be a see-through, Android-based Head Mounted Display that has no access to sensors. This device is transformed into an AR device through the creation of a Sensor Web allowing it to sense its environment facilitated through the use of SIXTH.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671787","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671787","Android Augmented Reality;Sensor Web;OSGi","Smart phones;Middleware;Augmented reality;Libraries;Internet;Educational institutions","Android (operating system);augmented reality;helmet mounted displays;middleware;mobile computing;smart phones","mobile devices;SIXTH middleware;augmented reality applications;smartphones;sensor data;augmented reality devices;AR devices;connecting sensors;SensorWeb;AR environments;heterogeneous external sensors;AR experiences;Android-based head mounted display","","6","","7","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Design of Paper Book Oriented Augmented Reality Collaborative Annotation System for Science Education","Y. Zhang; L. Tao; Y. Lu; Y. Li",University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","417","421","The authors designed a kind of augmented reality annotation system based on network knowledge collaboration for primary science education to expand the cognitive effect. Various types of annotations such as text, images, videos, links, 3D models, etc. can be added to the corresponding position of the paper book by multi-user and multi-device through the system. And the annotation contents could be retrieved in AR mode by other users. The connotation and dimension of scientific knowledge could be expanded through concentrating diversified annotations. The system only records the relative position of the annotation on the page by a hand-aided registration, and uploads the location information to the server without infringing the copyright of the book. The system allows users to add links as annotations, through which users could interact with social media and knowledge communities. By using this system, users' ideas could be connected thus promote the flow of knowledge between different types of readers (such as students, parents, and teachers), readers and authors and it is conducive to the exchange and inspiration of ideas, promoting the integration of knowledge and the generation of group wisdom.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951888","Collaborative-system,-knowledge-collaboration,-augmented-reality,-annotation,-science-education","Annotations;Collaboration;Databases;Augmented reality;Videos;Mobile handsets;Education","augmented reality;computer aided instruction;groupware;human computer interaction;natural sciences computing;social networking (online)","scientific knowledge;social media;knowledge communities;paper book oriented augmented reality collaborative annotation system;augmented reality annotation system;network knowledge collaboration;primary science education;annotation content retrieval","","1","","17","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"WARP: Contributional Tracking Architecture Towards a Worldwide Augmented Reality Platform","A. Sosin; Y. Itoh",University of Western Australia; Tokyo Institute of Technology,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","71","72","Ubiquitous Tracking (UT) for Augmented Reality (AR) applications shows great potential in becoming a key driving force in the wide scale adoption of AR. However, the implementation and integration of a global sensor network necessary for this technology may seem too daunting of a task to entrust in one central body. We propose an architecture designed to allow both individual and corporate bodies to equally contribute to the construction of a sensor network, providing a platform in which the growth of the AR environment is in the hands of its users. We propose a distributed blockchain based model capable of storing tracking entity pose data. The model allows users to contribute tracking entities to the blockchain and to share this data through peer-to-peer connections. We conclude with a discussion surrounding beneficial contributions and necessary future works.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951936","Ubiquitous Tracking, Blockchain, Sensor Network, Contributional Tracking, Augmented Reality","Blockchain;Augmented reality;Data structures;Peer-to-peer computing;Data models;Computational modeling;Indexes","augmented reality;cryptography;distributed databases;peer-to-peer computing;software architecture;ubiquitous computing","contributional tracking architecture;UT architecture;augmented reality information systems;data tracking;data sharing;data storage;architecture design;peer-to-peer connections;distributed blockchain based model;global sensor network;ubiquitous tracking;augmented reality;WARP","","1","","7","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Designing Augmented Reality Virtual Displays for Productivity Work","L. Pavanatto","Department of Computer Science, Center for Human-Computer Interaction, Virginia Tech, USA","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","459","460","We must consider alternative displays for supporting productivity work in the context of an increasingly work-from-home world. Augmented reality virtual monitors can fulfill these needs by equipping users with large screen real estate, while maintaining portability, cost-effectiveness, and not occupying physical space. However, there are open questions regarding how to design virtual monitors. In my dissertation, I plan to investigate the design of virtual monitors to enhance productivity everywhere. This work comprises a group of design and user study contributions. I conducted a user study to understand the feasibility of virtual monitors and their tradeoffs when compared against physical monitors. I further propose investigating the design of static properties and dynamic behaviors that cannot be achieved through physical monitors.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00107","Microsoft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585781","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Empirical studies in interaction design","Productivity;Usability;Task analysis;Monitoring;Augmented reality;Guidelines","augmented reality;computer displays","productivity work;augmented reality virtual monitors;cost-effectiveness;physical space;virtual monitors;physical monitors;augmented reality virtual displays;large-screen real estate;dynamic behaviors;static properties","","","","4","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Consistent real-time lighting for virtual objects in augmented reality","R. C. Yeoh; S. Z. Zhou","Interactive Multimedia Laboratory, Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Interactive Multimedia Laboratory, Department of Electrical and Computer Engineering, National University of Singapore, Singapore","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","223","224","We present a technique for rendering realistic shadows of virtual objects in a mixed reality environment by recovering the light source distribution of a scene in real-time, through the segmentation and analysis of a known occluding object's shadows. A fiducial marker provides information about the position of the occluding object and the plane of the surface on which shadows are cast, and serves as the origin of a marker coordinate system. A new shadow segmentation approach is carried out on the shadow image and is able to recover geometrical information on multiple faint shadows. Using normalised iterative reinforcement, noise and artifacts can be suppressed in the final shadow map. The scene's light source distribution is then extrapolated using geometrical data from both the occluding object and its cast shadows. Virtual light sources in a game engine are used to mimic real light sources and achieve consistent illumination and increase the realism of the augmented reality scene.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336453","Radiosity;illumination;shadow;augmented reality;realistic rendering","Augmented reality;Layout;Light sources;Virtual reality;Lighting;Cameras;Probes;Image edge detection;Image segmentation;Engines","augmented reality;geometry;image segmentation;lighting;rendering (computer graphics)","augmented reality;virtual object;consistent real-time lighting;realistic shadow rendering;light source distribution;shadow image segmentation approach;fiducial marker;marker coordinate system;geometrical information;normalised iterative reinforcement;game engine","","5","","6","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Influence of visual and haptic delays on stiffness perception in augmented reality","B. Knorlein; M. Di Luca; M. Harders","Computer Vision Laboratory, ETH Zurich, Switzerland; Max Planck Institute for Biological Cybernetics, MPI Tübingen, Germany; Computer Vision Laboratory, ETH Zurich, Switzerland","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","49","52","Visual delays are unavoidable in augmented reality setups and occur in different steps of the rendering pipeline. In the context of haptic interaction with virtual objects, it has been shown that delayed force feedback can alter the perception of object stiffness. We hypothesize that delays in augmented reality systems can have similar consequences. To test this, we carried out a user study to investigate the effect of visual and haptic delays on the perception of stiffness. The experiment has been performed in an optimized visuo-haptic augmented reality setup, which allows to artificially manipulate delays during visual and haptic rendering. In line with previous results, delays for haptic feedback resulted in decreased perceived stiffness. In contrast, visual delays caused an increase in perceived stiffness. However, the simultaneous occurrence of delays in both sensory channels led to a partial compensation of these effects. This could potentially help to correct stiffness perception of virtual objects in visuo-haptic augmented reality systems.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336501","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336501","augmented reality;multimodal;user evaluation;delay;haptic","Haptic interfaces;Augmented reality;Feedback;Delay effects;Displays;Cameras;Rendering (computer graphics);Synchronization;Computer vision;Laboratories","augmented reality;delays;force feedback;haptic interfaces;rendering (computer graphics)","visual delay;haptic delay;rendering pipeline;haptic interaction;virtual object;force feedback;object stiffness perception;optimized visuo-haptic augmented reality setup;visual rendering;haptic rendering;sensory channel","","36","","16","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Comparing Single-modal and Multimodal Interaction in an Augmented Reality System","Z. Wang; H. Yu; H. Wang; Z. Wang; F. Lu","State Key Laboratory of VR Technology and Systems, School of CSE, Beihang University; State Key Laboratory of VR Technology and Systems, School of CSE, Beihang University; Peng Cheng Laboratory, Shenzhen, China; State Key Laboratory of VR Technology and Systems, School of CSE, Beihang University; State Key Laboratory of VR Technology and Systems, School of CSE, Beihang University","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","165","166","Multimodal interaction is expected to offer better user experience in Augmented Reality (AR), and thus becomes a recent research focus. However, due to the lack of hardware-level support, most existing works only combine two modalities at a time, e.g., gesture and speech. Gaze-based interaction techniques have been explored for the screen-based application, but rarely been used in AR systemsy configurable augmented reality system. In this paper, we propose a multimodal interactive system that integrates gaze, gesture and speech in a flexibly configurable augmented reality system. Our lightweight head-mounted device supports accurate gaze tracking, hand gesture recognition and speech recognition simultaneously. More importantly, the system can be easily configured into different modality combinations to study the effects of different interaction techniques. We evaluated the system in the table lamps scenario, and compared the performance of different interaction techniques. The experimental results show that the Gaze+Gesture+Speech is superior in terms of performance.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00052","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288400","multimodal interaction;augmented reality;gaze;gesture;speech;AR system","Performance evaluation;Design methodology;Interactive systems;Speech recognition;Gesture recognition;User experience;Augmented reality","augmented reality;gesture recognition;helmet mounted displays;human computer interaction;interactive systems;object tracking;speech recognition","multimodal interaction;user experience;hardware-level support;gaze-based interaction techniques;screen-based application;AR systems;multimodal interactive system;flexibly configurable augmented reality system;lightweight head-mounted device;gaze tracking;hand gesture recognition;speech recognition;modality combination;single-modal interaction","","7","","6","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Owner Manual Evaluation by NASA TLX Method","L. Moreira; R. Ruschel","Pós-graduação em Arquitetura, UNICAMP, Campinas, Brasil; Departamento de Arquitetura e Construção, UNICAMP, Campinas, Brasil","2018 20th Symposium on Virtual and Augmented Reality (SVR)","19 Aug 2019","2018","","","150","156","Information is indispensable for any products and, likewise, the users expect to use all the resources offered by an artifact. In this way, the instruction manual is necessary for every product to be supplied. In turn, the building use, operation, and maintenance manual, also known as the building owner manual (BOM) is governed by rules that guide its creation, such as, items and definitions that must be followed. The building owner manual has been updated over time, but its format has not been modified. Such manuals are in most cases presented in the textual format with technical terms. A potential remedy to this situation is to enhance the traditional building owner manual format using Augmented Reality (AR) that promotes new forms of interaction between the user and the BOM. In a nutshell, AR enables the displaying of virtual (computer generated) graphics overlaid on views of the real environment. In this way, this paper is part of a Ph.D. research that aims to optimize the performance of the building owner manual through AR. Thus, the objective of this research is to evaluate the incorporation of Augmented Reality features into the BOM in order to qualify its use. The methodology adopted in this work follows the Design Science Research approach. The contribution granted presents models of insertion of the Augmented Reality technology in the building owners manual and qualifies the incorporation of the AR, through experiments with measurement method following NASA TLX protocol. This innovative study brings to the building owners manual advances in its use in terms of visualization, instruction and assembly in a qualified way, explained by the workload measured by NASA TLX method. In short, it was proved that the insertion of AR technology, regardless of the format acts favorably integrated with the BOM, optimizing its orientation role and recommending the best use of the building.","","978-1-7281-0604-5","10.1109/SVR.2018.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802488","Augmented reality;NASA TLX;Maintenance;Prototype;Building Owner Manual","Manuals;Visualization;Augmented reality;NASA;Buildings;Mars;Bills of materials","augmented reality;user manuals","NASA TLX method;BOM;instruction manual;maintenance manual;building owner manual;augmented reality owner manual evaluation;AR","","","","0","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"[Poster] QR code alteration for augmented reality interactions","H. Park; T. Kim; J. Park","Interactive Media Laboratory, Hongik University, Seoul, Korea; Interactive Media Laboratory, Hongik University, Seoul, Korea; Interactive Media Laboratory, Hongik University, Seoul, Korea","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","293","294","QR code, for its recognition robustness and data capacity, has been often used for Augmented Reality applications as well as for other commercial applications. However, it is difficult to enable tangible interactions through which users may change 3D models or animations. It is because QR codes are automatically generated by the rules, and are not easily modifiable. Our goal was to enable QR code based Augmented Reality interactions. By analysis and through experiments, we discovered that some parts of a QR code can be altered to change the text string that the QR code represents. In this paper, we introduced a prototype for QR code based Augmented Reality interactions, which allows for Rubik's cube style rolling interactions.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948456","QR code;Interaction;Augmented Reality","Augmented reality;Prototypes;Dinosaurs;Three-dimensional displays;Solid modeling;Media;Laboratories","augmented reality;bar codes","QR code alteration;augmented reality interactions;recognition robustness;data capacity;tangible interactions;3D models;animations;cube style rolling interactions","","","","6","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"A Location-Triggered Augmented Reality Walking Tour Using Snap Spectacles 2021","A. Sanchawala; M. Dimofte; S. K. Feiner","Department of Computer Science, Columbia University; Department of Computer Science, Columbia University; Department of Computer Science, Columbia University","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","840","841","We present an on-site 3D-animated audiovisual tour guide augmented reality application developed for Snap Spectacles 2021. The primary goal of this project is to explore how to use this experimental product to create an augmented reality tour guide. In addition, we present the design considerations for the user interface and the underlying system architecture. We illustrate the workflow of the tour application and discuss our experience working with Spectacles 2021 and its experimental API. We also present our design choices and directions for future work.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757416","Human-centered computing—Human Computer Interaction—(HCI) Interaction paradigms—Mixed/augmented reality;Computing methodologies—Computer graphics—Graphics systems and interfaces—Mixed/augmented reality","Legged locomotion;Three-dimensional displays;Conferences;Systems architecture;User interfaces;Augmented reality","augmented reality;computer animation;user interfaces;virtual reality","Snap Spectacles 2021;on-site 3D-animated audiovisual tour guide;reality application;experimental product;augmented reality tour guide;underlying system architecture;tour application;location-triggered augmented reality walking tour","","","","11","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Light-weight marker hiding for augmented reality","O. Korkalo; M. Aittala; S. Siltanen","VTT Technical Research Center of Finland, Finland; VTT Technical Research Center of Finland, Finland; VTT Technical Research Center of Finland, Finland","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","247","248","In augmented reality, marker-based tracking is the most common method for camera pose estimation. Most of the markers are black and white patterns that are visually obtrusive, but they can be hidden from the video using image inpainting methods. In this paper, we present a computationally efficient approach to achieve this. We use a high-resolution hiding texture, which is captured and generated only once. To capture continuous changes in illumination, reflections and exposure, we also compute a very low-resolution texture at each frame. The coarse and fine textures are combined to obtain a detailed hiding texture which reacts to changing conditions and runs efficiently in mobile phone environments.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643590","","Lighting;Image resolution;Pixel;Image color analysis;Real time systems;Augmented reality;Mobile handsets","augmented reality;computer graphics;data encapsulation;feature extraction;image resolution;image sensors;image texture;motion estimation;pose estimation;video signal processing","light weight marker hiding;augmented reality;marker based tracking;camera pose estimation;black white pattern;image inpainting method;high resolution hiding texture;mobile environment","","18","","4","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Generating vision based Lego augmented reality training and evaluation systems","T. Engelke; S. Webel; N. Gavish","Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Technion-Israel Institute of Technology, Israel","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","223","224","The creation of training applications using Augmented Reality (AR) is still a new field of research. In order to get good training results therefore evaluation should be performed. For the creation of such systems the questions arising are related to the general process of generation, visualization, evaluation and its psychological background. An important aspect of vision based AR is also the robust tracking and initialization of objects for correct augmentation. In this work we present a concept of an entire processing chain, which allows for efficient and automatic generation of such training systems that can also be used for evaluation. We do this in the context of a Lego training system. While explaining the whole process of application generation and usage, we also present a novel approach for robust marker free initialization of colored partly occluded plates and their tracking using one off the shelf monocular camera.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643578","","Training;Solid modeling;Augmented reality;Image color analysis;Cognitive science;Visualization;Robustness","augmented reality;cameras;computer vision;object detection;training","vision based Lego augmented reality training;psychological background;robust tracking;Lego training system;robust marker free initialization;colored partly occluded plate;shelf monocular camera","","5","2","7","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Augmented reality in large environments: Application to aided navigation in urban context","V. Gay-Bellile; P. Lothe; S. Bourgeois; E. Royer; S. Naudet Collette","Vision and Content Engineering Laboratory, CEA LIST, Gif-sur-Yvette, France; CEA LIST, France; CEA LIST, France; LASMEA, CNRS/UBP, France; CEA LIST, France","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","225","226","This paper addresses the challenging issue of vision-based localization in urban context. It briefly describes our contributions in large environments modeling and accurate camera localization. The efficiency of the resulting system is illustrated through Augmented Reality results on large trajectory of several hundred meters.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643579","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643579","","Three dimensional displays;Cities and towns;Databases;Image reconstruction;Solid modeling;Augmented reality;Cameras","augmented reality;computer vision;image sensors","augmented reality;urban context;vision based localization;camera localization","","4","","5","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Augmented Reality driving supported by Vehicular Ad Hoc Networking","M. Ferreira; P. Gomes; M. K. Silvéria; F. Vieira","Departamento de Ciencia de Computadores, Faculdade de Ciencias da Universidade do Porto, Porto, Portugal; Universidade do Porto, Porto, Porto, PT; Departamento de Ciencia de Computadores, Faculdade de Ciencias da Universidade do Porto, Porto, Portugal; Departamento de Ciencia de Computadores, Faculdade de Ciencias da Universidade do Porto, Porto, Portugal","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","253","254","The confined space of a car and the configuration of its controls and displays towards the driver, offer significant advantages for Augmented Reality (AR) systems in terms of the immersion level provided to the user. In addition, the inherent mobility and virtually unlimited power autonomy transform cars into perfect mobile computing platforms. However, the limited network connectivity that is currently available in automobiles leads to the design of Advanced Driver Assistance Systems (ADAS) that create AR objects based only on the information generated by on-board sensors, stored maps and databases, and eventually high-latency online content for Internet-enabled vehicles. By combining the new paradigm of Vehicular Ad Hoc Networking (VANET) with AR human machine interfaces, we show that it is possible to design novel cooperative ADAS, that base the creation of AR content on the information collected from neighbouring vehicles or roadside infrastructures. We provide a prototype implementation of a visual AR system that can significantly improve the driving experience.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671791","","Vehicles;Glass;Augmented reality;Visualization;Streaming media;Acoustics;Vehicular ad hoc networks","augmented reality;driver information systems;Internet;mobile computing;user interfaces;vehicular ad hoc networks","augmented reality driving;vehicular ad hoc networking;immersion level;mobile computing platforms;virtually unlimited power autonomy;advanced driver assistance systems;ADAS;AR objects;Internet-enabled vehicles;VANET;AR human machine interfaces;visual AR system","","4","","8","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"A user study towards understanding stereo perception in head-worn augmented reality displays","M. A. Livingston; Z. Ai; J. W. Decker","Naval Research Laboratory, Inc., USA; Naval Research Laboratory, Inc., USA; Naval Research Laboratory, Inc., USA","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","53","56","Properly perceived stereo display is often assumed to be vital in augmented reality (AR) displays used for close distances, echoing the general understanding from the perception literature. However, the accuracy of the perception of stereo in head-worn AR displays has not been studied greatly. We conducted a user study to elicit the precision of stereo perception in AR and its dependency on the size and contrast of the stimulus. We found a strong effect of contrast on the disparity users desired to make a virtual target verge at the distance of a real reference object. We also found that whether the target began behind or in front of the reference in a method of adjustments protocol made a significant difference. The mean disparity in the rendering that users preferred had a strong linear relationship with their IPD. We present our results and infer stereoacuity thresholds.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336496","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems;Artificial, augmented, and virtual realities H.5.2 [Information Interfaces and Presentation]: User Interfaces;Evaluation/Methodology; H.1.2 [Models and Principles]: User/Machine Systems;Human factors","Augmented reality;Displays;Virtual reality;Laboratories;Protocols;Rendering (computer graphics);Multimedia systems;Humans;Eyes;Stereo vision","augmented reality;helmet mounted displays","stereo perception understanding;head-worn augmented reality displays","","8","","15","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"A modernistic and contemporary mobile augmented reality erudition system","M. Durairaj; P. S. Aurelia","School of Computer Science, Engineering and Applications, Bharathidasan University, Tiruchirappalli, Tamil Nadu, India; School of Computer Science, Engineering and Applications, Bharathidasan University, Tiruchirappalli, Tamil Nadu, India","2017 International Conference on Computing Methodologies and Communication (ICCMC)","8 Feb 2018","2017","","","1109","1112","The real world with virtual data embedded in it is allowed in augmented reality. The user's understandability and perception is increased by mixed reality. Location-based services, GPS compass, portability, versatility and enhanced technology based on usability are the remarkable advantages of mobile augmented reality. The main objective of this article is to introduce an effective 4R learnability apperception for mobile augmented reality environment. The system is an effective learning framework for immersive environment. The learning environment, learning activities and multiple learning assets are examined and evaluated to determine the effectiveness of the novel approach suggested. The research, reasoning, reflection and renaissance are used to determine and analyze the learnability of the users based on the intelligent and emotional quotient. Augmented reality based learning showed significant growth than the traditional learning system.","","978-1-5090-4890-8","10.1109/ICCMC.2017.8282645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8282645","Mixed Reality;Human Computer Interaction;4R;learnability;usability;Augmented Reality;Immersive environment;Mobile Augmented Reality","Augmented reality;Mobile communication;Learning systems;Cognition;Education;Conferences;Reflection","augmented reality;computer aided instruction;mobile computing","modernistic reality erudition system;contemporary mobile augmented reality erudition system;virtual data;mixed reality;location-based services;GPS compass;enhanced technology;learnability;mobile augmented reality environment;effective learning framework;immersive environment;learning environment;multiple learning assets;augmented reality based learning;traditional learning system","","1","","15","IEEE","8 Feb 2018","","","IEEE","IEEE Conferences"
"AR4AR Based on ARVIDA Reference Architecture: Application Demonstration","F. Pankratz; G. Klinker","Fachgebiet Augmented Reality, Technische Universität München, Garching b. München, Germany; Fachgebiet Augmented Reality, Technische Universität München, Garching b. München, Germany","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","348","349","A recurring challenge when setting up any Augmented Reality system is integration as well as the correct calibration and registration of the involved devices. To gather, the input data the user has to interact with the system which requires certain knowledge on how to perform the task. It is possible the user performs the current task to the best of his knowledge and still produces suboptimal results. Augmented Reality for Augmented Reality (AR4AR) generates AR guides by using the already existing knowledge about the AR system which stems from the setup of the AR system itself. As these guides involve plenty of 3D information, it is again best presented through means of Augmented Reality, thus the name AR4AR.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836536","","Augmented reality;Target tracking;Calibration;Performance evaluation;Cameras;Three-dimensional displays","augmented reality","AR4AR;ARVIDA reference architecture;augmented reality for augmented reality;AR system;3D information","","1","","7","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Augmenting Mixed Reality Applications with the Vibro Motors Wearable","D. Rumiński; G. Klinker","Poznań University of Economics and Business, Poznań, Poland; Technical University of Munich, München, Germany","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","401","402","In this demo, we demonstrate the use of the mobile Vibro Motors Wearable device, and we explain how it can be used to enhance Mixed Reality applications with tactile human-machine hand interactions. The presented device is capable of providing tactile feedback while interacting with virtual objects, e.g., when elements of a 3D user interface are touched. The device enables to run vibro motors mounted on a user's fingers while interacting with synthetic objects. In order to control the vibe of a particular vibro motor in a wireless manner, we have developed an HTTP-based API. The API can be used to develop mobile-tactile Mixed Reality applications to enhance user experience by giving an impression of fading in/out effects when interacting with 3D objects. To show the device's capabilities, a 3D demo application has been developed in which a user can experience tactile feedback effects while interacting with a virtual object.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699297","Hardware [Communication hardware;interfaces and storage]: Wireless devices—Sensors and actuators;Human-centered computing [Mixed / augmented reality]","Tactile sensors;Three-dimensional displays;Augmented reality;Indexes;Hardware;Man-machine systems","application program interfaces;augmented reality;haptic interfaces;mobile computing","synthetic objects;particular vibro motor;HTTP-based API;user experience;tactile feedback effects;virtual object;human-machine hand interactions;mobile vibro motors wearable device;mobile-tactile mixed reality applications;augmenting mixed reality applications;tactile human-machine hand interactions;3D user interface;3D demo application","","2","","2","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"[POSTER] DotWarp: Dynamic Object Timewarping for Video See-Through Augmented Reality","P. Kim; J. Orlosky; K. Kiyokawa; P. Ratsamee; T. Mashita","Graduate School of Information Science and Technology, Osaka University; Cybermedia Center, Osaka University; Graduate School of Information Science, Nara Institute of Science and Technology; Cybermedia Center, Osaka University; Cybermedia Center, Osaka University","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","184","185","A significant issue associated with the use of video see-through head-mounted displays (VST-HMD) for augmented reality is the presence of latency between real-world images and the images displayed to the HMD. For a static scene, this latency provides no real problem, however for dynamic scenes, which arise when the HMD user moves their head, when real-world objects move, or a combination of the two, the accompanying delay may result in significant registration error. To address this issue, we present DotWarp, a novel latency reduction technique for VST-HMDs that does not rely on head motion and compensates for the delay arising from real-world object motion. The algorithm requires a two-camera setup and matches dynamic objects in both images by tracking on the faster image and warping the pixels of the slower image, with the fast and slow components being RGB and IR components, respectively, for our system. First, moving objects are extracted from the faster camera scene using a motioncompensating background subtraction algorithm and tracked using a robust correlation tracker. Then, temporal correspondence between the two camera images is computed using sensor update information and the objects' positions in the slower image are shifted to match the corresponding positions in the faster image. Finally, the gaps in the slower image left behind by the shifted objects are filled in with background pixel data from previous frames using homography from the background subtraction model. In this manner, the augmented image is more closely matched with the real-world image and the perceived registration of the camera is significantly improved, with initial results of an 81.64% reduction in registration error.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088478","Delay compensation;augmented reality;timewarping","Streaming media;Cameras;Tracking;Head;Augmented reality;Delays;Heuristic algorithms","augmented reality;cameras;helmet mounted displays;image colour analysis;image motion analysis;image recognition;image registration;image representation;image segmentation;image sequences;object detection;object tracking;video signal processing","dynamic object timewarping;displays;VST-HMD;real-world image;static scene;dynamic scenes;HMD user;real-world objects;latency reduction technique;head motion;real-world object motion;two-camera setup;moving objects;faster camera scene;motioncompensating background subtraction algorithm;camera images;shifted objects;augmented image;registration error;DotWarp;video see-through augmented reality;dynamic objects matching;video see-through head-mounted displays","","3","","6","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"An MR Remote Collaborative Platform Based on 3D CAD Models for Training in Industry","P. Wang; X. Bai; M. Billinghurst; S. Zhang; D. Han; H. Lv; W. He; Y. Yan; X. Zhang; H. Min","Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","91","92","In this paper, we describe a new Mixed Reality (MR) remote collaborative platform making use of 3D CAD models for training in the manufacturing industry. It enables a remote expert in Virtual Reality (VR) to train a local worker in a physical assembly task. For the local site, we use Spatial Augmented Reality (SAR) to enable the local worker see virtual cues without wearing any AR devices, leaving their user hands free to easily manipulate the physical parts. For the remote expert, we construct a 3D virtual environment using virtual replicas of the physical parts. We also report on the results of a usability study of the prototype.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951982","Remote collaboration;3D CAD models;training in the industry;Augmented Reality;Mixed reality","Three-dimensional displays;Training;Collaboration;Solid modeling;Task analysis;Virtual reality;Usability","augmented reality;CAD;computer based training;groupware;manufacturing industries;production engineering computing;solid modelling","MR remote collaborative platform;3D CAD models;manufacturing industry;remote expert;Virtual Reality;physical assembly task;Spatial Augmented Reality;3D virtual environment;Mixed Reality remote collaborative platform;training in industry","","9","","6","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"A mapping of visual SLAM algorithms and their applications in augmented reality","J. P. M. Covolan; A. C. Sementille; S. R. R. Sanches","Departamento de Computação, Universidade Estadual Paulista “Júlio de Mesquita Filho” - UNESP, Bauru, Brasil; Departamento de Computação, Universidade Estadual Paulista “Júlio de Mesquita Filho” - UNESP, Bauru, Brasil; Departamento Acadêmico de Computação, Universidade Tecnológica Federal do Paraná - UTFPR, Cornélio Procópio, Brasil","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","20","29","The term visual SLAM defines the problem of build a map of an environment and perform location, simultaneously. In the augmented reality experience, we can apply SLAM techniques to insert virtual elements in the user's real-world view according to their observation point (location) and environment structure (mapping). In this work, we investigated the main algorithms of visual SLAM, and its applications in augmented reality. Here, we describe the key features of these algorithms and two taxonomies for SLAM techniques are proposed.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262630","visual SLAM;augmented reality;visual SLAM techniques","Simultaneous localization and mapping;Visualization;Augmented reality;Libraries;Laser radar;Taxonomy;Solid modeling","augmented reality;SLAM (robots)","visual SLAM algorithms;augmented reality experience;SLAM techniques;virtual elements;real-world view;observation point","","10","","0","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"ARMO: Augmented Reality based Reconfigurable MOck-up","Y. -s. Jin; Y. -w. Kim; J. Park","Department of Computer Science, Hongik University, Seoul, South Korea; Department of Computer Science, Hongik University, Seoul, South Korea; Department of Computer Science, Hongik University, Seoul, South Korea","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","273","274","Rapid prototyping allows for evaluation of design product in a short period of time. Designers or CEOs may perceive the size and appearance of the product by touching the automatically constructed physical objects produced through rapid prototyping. In this paper, we introduce 'augmented reality based reconfigurable mock-up', which enables interactive changes of shapes of products as well as colors, textures, and user interfaces. The shapes of the physical objects are reconfigurable by assembling different parts to the main body of the mock-up. Augmented reality technologies were used to alter the appearance of the mock-up by rendering the 3D models, colors, and interfaces accordingly. Developed AR-based reconfigurable mock-up is expected to be used for realistic design evaluation and CEO presentations.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538863","Augmented Reality;mock-up;design evaluation","Augmented reality;Shape;User interfaces;Product design;Rendering (computer graphics);Prototypes;Assembly;Computer graphics;Design automation;Process design","augmented reality;computer graphics;computer vision;software prototyping","augmented reality;rapid prototyping;reconfigurable mock-up;interactive changes","","5","","4","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"A texture based time delay compensation method for augmented reality","J. Y. Didier; D. Roussel; M. Mallem","Laboratoire Systémes Complexes, Université ď Evry Val ďEssone, Evry, France; Laboratoire Systémes Complexes, Université ď Evry Val ďEssone, Evry, France; Laboratoire Systémes Complexes, Université ď Evry Val ďEssone, Evry, France","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","262","263","One of the key problems in augmented reality systems is registration, that is to say the synchronization of real and virtual world. Augmented reality uses a lot of different sensors in order to estimate camera or operator's point of view. These sensors could provide samples faster than mixing of virtual and real information could be displayed. We expose here a way to fake into account samples that are generated during the mixing process. This method is using a post-rendering technique involving a texture to perform this task. We expose the errors reduction obtained by performing such technique with a simulation test-bench implementing our proposal.","","0-7695-2191-6","10.1109/ISMAR.2004.7","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383067","pseudo-correction;post-rendering techniques;sensors data;augmented reality","Delay effects;Augmented reality;Chromium;Rendering (computer graphics);Cameras;Testing;Displays;Layout;Switches;Performance evaluation","rendering (computer graphics);augmented reality;image registration;cameras","texture based time delay compensation;augmented reality systems;postrendering technique;error reduction;sensor data;registration problem","","1","","4","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"XR based Interaction: Leveraging on Virtual Digital Twin for Efficient Exploration with Small FOV Augmented Reality Glass","Y. Shin; G. J. Kim","Digital Experience Laboratory, Korea University, Seoul, Korea; Digital Experience Laboratory, Korea University, Seoul, Korea","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","808","809","In this poster, we propose to take advantage of the digital twinned environment to interact more efficiently in spite of the limited sized FOV of the AR glasses. Using the digital twin of the environment, “magical” VR interaction techniques can be applied, as visualized and overlaid through the small window, while still maintaining the spatial association to the augmented real world. As an example, we consider the use of amplified movement within the corresponding VR space - in an attempt to provide effectively larger view with the same AR field of view but with less amount of physical movements. The results of the pilot experiment with the proposed method have in-dicated that the interaction performance was partly improved, while the spatial understanding with regards to the augmentation space maintained. The work illustrates the concept of and potential for XR based interaction where the user can leverage on the advantages of both VR and AR mode operations.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974456","Mixed reality;augmented reality;digital twin;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality","Visualization;Glass;Digital twins;Windows;X reality","augmented reality;human computer interaction;virtual reality","amplified movement;AR glasses;augmentation space;augmented real world;corresponding VR space;digital twinned environment;effectively larger view;interaction performance;interaction techniques;physical movements;sized FOV;small FOV augmented reality glass;spatial association;virtual digital twin;XR based interaction","","","","8","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Synesthesia AR: Creating Sound-to-Color Synesthesia in Augmented Reality","S. N; S. Feiner","Department of Computer Science, Columbia University, New York, USA; Department of Computer Science, Columbia University, New York, USA","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","874","875","Sound-to-color synesthesia is a neurological condition in which people experience different colors and shapes when listening to music. We present an augmented reality application that aims to create an interactive synesthesia experience for non-synesthetes. In this application, users can visualize colors corresponding to each unique note in the 12-tone equal-temperament tuning system, and the auditory input can be selected from audio files or real-time microphone. A gestural hand-tracking interface allows users to paint the world space in visualized synesthetic colors.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757577","Augmented Reality;Synesthesia;Chromesthesia;Computing methodologies-Computer graphics-Graphics systems and interfaces-Mixed / augmented reality;Human-centered computing-Human-computer interaction (HCI) -Interaction paradigms-Mixed / augmented reality;Human-centered computing-Human-computer interaction (HCI)-Interaction techniques-Gestural input","Visualization;Machine learning algorithms;Shape;Music;Color;Real-time systems;Augmented reality","audio signal processing;augmented reality;electronic music;gesture recognition;music;musical acoustics;neurophysiology","synesthesia AR;creating sound-to-color synesthesia;neurological condition;augmented reality application;interactive synesthesia experience;nonsynesthetes;equal-temperament tuning system;visualized synesthetic colors","","","","10","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Object Detecting Augmented Reality System","M. Hu; D. Weng; F. Chen; Y. Wang","Beijing Engineering Researcher Center of Mixed Reality and Advanced Display Beijing Institute of Technology, Beijing, China; Beijing Engineering Researcher Center of Mixed Reality and Advanced Display Beijing Institute of Technology, Beijing, China; Beijing Engineering Researcher Center of Mixed Reality and Advanced Display Beijing Institute of Technology, Beijing, China; Beijing Engineering Researcher Center of Mixed Reality and Advanced Display Beijing Institute of Technology, Beijing, China","2020 IEEE 20th International Conference on Communication Technology (ICCT)","24 Dec 2020","2020","","","1432","1438","Augmented reality technology is widely used in people's life and work, especially in visual aids. How to assist users to quickly find target objects in a complex environment is one of the problems that need to be solved in the development of augmented reality technology. To solve this problem, the paper proposes an augmented reality system based on object detection neural network and a fast method to construct specific object data set. Since it is difficult for the existing object detection network to accurately detect specific objects that are not in the data set, this paper uses the self-built data set to retrain the object detection network to ensure that the object detection network can detect specific objects. Meanwhile, we calibrate the system to ensure that the bounding box in the AR glasses output from the object detection network can accurately select the specific object. This system helps users quickly find the required items from the complex real environment and enhances the interaction efficiency between users and the real world.","2576-7828","978-1-7281-8141-7","10.1109/ICCT50939.2020.9295761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295761","augmented reality;object detection;neural network","Object detection;Real-time systems;Augmented reality;Feature extraction;Head-mounted displays;Glass;Calibration","augmented reality;neural nets;object detection;virtual reality","specific object data;object detection neural network;target objects;augmented reality technology;object detecting augmented reality system;existing object detection network","","7","","20","IEEE","24 Dec 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Application in Classroom: An Immersive Taxonomy","R. Kaviyaraj; M. Uma","School of Computing, SRM Institute of Science and Technology, Chennai, India; School of Computing, SRM Institute of Science and Technology, Chennai, India","2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT)","25 Feb 2022","2022","","","1221","1226","Innovating learning technologies and modernizing the education system can improve education. A blend of AR and VR technology improve student learning, motivation, and it also facilitates teamwork and group cooperation. Knowledge gaps and terminologies are mixed in this article on existing taxonomies of augmented reality and virtual reality and present analysis of existing taxonomies. Confusion is likely to arise among educators, researchers, and developers. A methodology for creating a taxonomy of applications related to augmented reality and virtual reality is presented. The taxonomy emphasizes the interaction between the technology that provides the augmented reality and the user's perception of the content. Because in education augmented reality is a relatively new topic and little has also been studied in STEM education, Analyses of augmented reality technologies are performed, which are applicable to teaching course material in the natural and mathematics sciences. In addition, it can accommodate a wide range devices and approaches developed over time to serve a number of purposes. This article illustrates how augmented reality can be used in the mathematical geometry lesson.","","978-1-6654-0118-0","10.1109/ICSSIT53264.2022.9716325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9716325","Augmented Reality;Augmented Reality in Education;Augmented Reality in Mathematics;Unity 3D;Augmented Reality/Virtual Reality","Performance evaluation;Geometry;Terminology;Taxonomy;Education;Teamwork;Augmented reality","augmented reality;computer aided instruction;geometry;teaching","virtual reality;STEM education;augmented reality;immersive taxonomy;innovating learning;classroom;mathematical geometry lesson;student learning;teaching course material;mathematics sciences","","6","","23","IEEE","25 Feb 2022","","","IEEE","IEEE Conferences"
"Augmented Reality Approach for Marker-based Posture Measurement on Smartphones","S. Basiratzadeh; E. D. Lemaire; N. Baddour","Department of Mechanical Engineering, University of Ottawa, Ottawa, Canada; Department of Mechanical Engineering, University of Ottawa, Ottawa, Canada; Department of Mechanical Engineering, University of Ottawa, Ottawa, Canada","2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","27 Aug 2020","2020","","","4612","4615","Marker tracking for postural and range of motion (ROM) measurements transcends multiple disciplines (e.g., healthcare, ergonomics, engineering). A viable real-time mobile application is currently lacking for measuring limb angles and body posture. To address this need, a novel Android smartphone augmented-reality-based application was developed using the AprilTag2 fiducial marker system. To evaluate the app, two markers were printed on paper and attached to a wall. A Samsung S6 mobile phone was fixed on a tripod, parallel to the wall. The smartphone app tracked and recorded marker orientation and 2D position data in the camera frame, from front and rear cameras, for different smartphone placements. The average error between mobile phone and measured angles was less than 1 degree for all test settings (back camera=0.29°, front camera=0.33°, yaw rotation=0.75°, tilt rotation=0.22°). The average error between mobile phone and measured distance was less than 4 mm for all test settings (back camera=1.8 mm, front camera=2.5 mm, yaw rotation=3 mm, tilt rotation=3.8 mm). Overall, the app obtained valid and reliable angle and distance measurements with smartphone positions and cameras that would be expected in practice. Thus, this app is viable for clinical ROM and posture assessments.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9175652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175652","measurement;markers;fiducial markers;range of motion;posture;augmented reality;healthcare;Apriltag2;mobile application;smartphone","Cameras;Smart phones;Real-time systems;Fiducial markers;Read only memory;Augmented reality;Two dimensional displays","augmented reality;cameras;ergonomics;mobile computing;pose estimation;smart phones","marker-based posture measurement;smartphones;marker tracking;postural range;motion measurements;multiple disciplines;real-time mobile application;limb angles;body posture;augmented-reality-based application;AprilTag2 fiducial marker system;Samsung S6 mobile phone;smartphone app;marker orientation;2D position data;camera frame;rear cameras;smartphone placements;test settings;yaw rotation;measured distance;reliable angle;distance measurements;smartphone positions;posture assessments;augmented reality approach","Augmented Reality;Mobile Applications;Posture;Range of Motion, Articular;Smartphone","1","","17","IEEE","27 Aug 2020","","","IEEE","IEEE Conferences"
"Optical see-through vs. spatial augmented reality simulators for medical applications","S. Daher","University of Central Florida, USA","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","417","418","Currently healthcare practitioners use standardized patients, physical mannequins, and virtual patients as surrogates for real patients to provide a safe learning environment for students. Each of these simulators has different limitation that could be mitigated with various degrees of fidelity to represent medical cues. As we are exploring different ways to simulate a human patient and their effects on learning, we would like to compare the dynamic visuals between spatial augmented reality and a optical see-through augmented reality where a patient is rendered using the HoloLens and how that affects depth perception, task completion, and social presence.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892354","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, Augmented, and Virtual Realities;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism — Virtual reality;I.3.8 [Computer Graphics]: Applications —;I.68 [Simulation and Modeling]: Types of Simulation — Combined;Visual;J.3 [Computer Applications]: Life and Medical Sciences — Medical information systems","Augmented reality;Medical services;Head;Visualization;Biomedical imaging;Solid modeling;Magnetic heads","augmented reality;biomedical education;computer aided instruction;digital simulation;health care;medical computing","spatial augmented reality simulators;medical applications;health care practitioners;virtual patients;learning environment;medical cues;dynamic visuals;optical see-through augmented reality;HoloLens;depth perception;task completion;social presence","","7","","5","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Framework for Creating Outdoors Augmented and Virtual Reality","J. Azevedo; P. Faria; L. Romero","Instituto Politécnico de Viana do Castelo, Viana do Castelo, Portugal; Instituto Politécnico de Viana do Castelo, Viana do Castelo, Portugal; Instituto Politécnico de Viana do Castelo, Viana do Castelo, Portugal","2021 16th Iberian Conference on Information Systems and Technologies (CISTI)","12 Jul 2021","2021","","","1","6","In this article we propose the architecture of a system in which its central objective is focused on creating a complete framework for creating outdoor environments of Augmented Reality (AR) and Virtual Reality (VR) allowing its users to digitize reality for hypermedia format. Subsequently, there will be an internal process with the objective of merging / grouping these 3D models, thus enabling clear and intuitive navigation within infinite virtual realities (based on the captured real world). In this way, the user is able to create points of interest within their parallel realities, being able to navigate and traverse their new worlds through these points.","2166-0727","978-989-54659-1-0","10.23919/CISTI52073.2021.9476541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476541","augmented reality;virtual reality;hypermedia","Solid modeling;Three-dimensional displays;Navigation;Merging;Hypermedia;Augmented reality;Information systems","augmented reality;hypermedia;virtual reality","hypermedia format;clear navigation;intuitive navigation;infinite virtual realities;parallel realities;creating outdoors Augmented;Virtual Reality;central objective;complete framework;outdoor environments;Augmented Reality","","1","","0","","12 Jul 2021","","","IEEE","IEEE Conferences"
"MARA - A Mobile Augmented Reality-Based Virtual Assistant","A. Schmeil; W. Broll","Collaborative Virtual and Augmented Environments Department, Fraunhofer FIT, Sankt Augustin, Germany; Collaborative Virtual and Augmented Environments Department, Fraunhofer FIT, Sankt Augustin, Germany","2007 IEEE Virtual Reality Conference","23 Apr 2007","2007","","","267","270","High-end mobile devices are becoming increasing popular in every day life. Augmented reality (AR) builds on this trend by combining mobile computing with connectivity and location-awareness. In doing so, AR can provide a very rich user experience. In this paper we discuss the approach and development of an AR-based personal assistant, combining the familiar interface of a human person with the functionality of a location-aware digital information system. The paper discusses the main components of the system, including the anthropomorphic user interface as well as the results of an initial prototype evaluation.","2375-5334","1-4244-0905-5","10.1109/VR.2007.352497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161039","Augmented Reality;Mobile Computing;Virtual Humans;Anthropomorphic User Interfaces;Digital Assistants;Environment Model;Location Based Systems","User interfaces;Anthropomorphism;Augmented reality;Multimedia databases;Mobile computing;Humans;Mobile handsets;Personal digital assistants;Computer interfaces;Pervasive computing","augmented reality;mobile computing;user interfaces","mobile augmented reality-based virtual assistant;high-end mobile devices;mobile computing;location-awareness;AR-based personal assistant;location-aware digital information system;anthropomorphic user interface","","11","1","17","IEEE","23 Apr 2007","","","IEEE","IEEE Conferences"
"Deceiving Audio Design in Augmented Environments : A Systematic Review of Audio Effects in Augmented Reality","E. H. Anne de Haas; L. -H. Lee","Korea Advanced Institute of Science and Technology, Republic of Korea; Korea Advanced Institute of Science and Technology, Republic of Korea","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","36","43","Recently, a lot of works show promising directions for audio design in augmented reality (AR). These works are mainly focused on how to improve user experience and make AR more realistic. But even though these improvements seem promising, these new possibilities could also be used as an input for manipulative design. This survey aims to analyze all recent discoveries in audio development regarding AR and argue what kind of “manipulative” effect this could have on the user. It can be concluded that even though there are many works explaining the effects of audio design in AR, very few works point out the risk of harm or manipulation toward the user. Future works could contain more awareness of this problem or maybe even systems to protect the user from any possible manipulation or harm.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974497","Persuasive technology;Augmented reality;Virtual reality;Technology addiction;User interfaces;Human-centered computing-Augmented reality-Augmented reality technologies;Human-centered computing-Augmented reality-Augmented reality design and evaluation methods","Location awareness;Systematics;Design methodology;Spatial audio;Motion sickness;Augmented reality","audio user interfaces;augmented reality;user experience","audio design;audio development;audio effects;augmented environments;augmented reality;manipulative design;manipulative effect;possible manipulation;user experience;user protection","","","","50","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Augmented Reality Search to Improve Searching Using Augmented Reality","F. S. Shaikh","Department of Computer Science and Engineering, Solapur University, Pandharpur, India","2021 6th International Conference for Convergence in Technology (I2CT)","10 May 2021","2021","","","1","5","In the current scenario we are facing the issue of real view which is object deal with image or in virtual world for such kind of difficulties the Augmented Reality has came into existence (AR). This paper deal with Augmented Reality Search (ARS). In this Augmented Reality Search (ARS) just user have to make the voice command and the Augmented Reality Search (ARS) will provide you real view of that object. Consider real world scenario where a student searched for NIT Bangalore then it will show the real view of that campus.","","978-1-7281-8876-8","10.1109/I2CT51068.2021.9417827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417827","augmented reality;head mounted display;augments scene;augmented camera;augmented reality unity","Search problems;Internet;Augmented reality;Convergence","augmented reality;Internet;search engines;virtual reality","Augmented Reality Search just user;ARS;AR","","4","","13","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"Augmented reality in a serious game for manual assembly processes","R. Woll; T. Damerau; K. Wrasse; R. Stark","Fraunhofer Institute for Production Systems and Design Technology, Technische Universität Berlin, Germany; Fraunhofer Institute for Production Systems and Design Technology, Technische Universität Berlin, Germany; Fraunhofer Institute for Production Systems and Design Technology, Technische Universität Berlin, Germany; Fraunhofer Institute for Production Systems and Design Technology, Technische Universität Berlin, Germany","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","37","39","This paper presents results from a study in which Augmented Reality (AR) technology has been employed in a serious game for teaching the assembly of a car power generator. Most used car power generators can be remanufactured in order to save material and cost. This is usually done manually and requires a mechanic who knows the different steps of disassembly, cleaning, replacement and re-assembly of the generators components. A serious game has been developed that teaches an apprentice mechanic of which components a car power generator consists and how these components have to be assembled. The game has been implemented as an application for smartphones running the Android operation system. The game employs augmented reality technology in order to let the user interactively experience the spatial arrangement of components and to support the user in validating his learning success.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093654","Augmented reality;serious game;training;assembly process","Games;Assembly;Generators;Smart phones;Augmented reality;Software;Three dimensional displays","augmented reality;computer aided instruction;computer games;operating systems (computers);user interfaces","augmented reality;serious game;manual assembly processes;car power generator assembly;apprentice mechanic;Android operation system;user experience;learning success","","14","","8","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Validating Spatial Augmented Reality for interactive rapid prototyping","S. R. Porter; M. R. Marner; R. T. Smith; J. E. Zucco; B. H. Thomas","Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","265","266","This paper investigates the use of Spatial Augmented Reality in the prototyping of new human-machine interfaces, such as control panels or car dashboards. The prototyping system uses projectors to present the visual appearance of controls onto a mock-up of a product. Finger tracking is employed to allow real-time interactions with the controls. This technology can be used to quickly and inexpensively create and evaluate interface prototypes for devices. In the past, evaluating a prototype involved constructing a physical model of the device with working components such as buttons. We have conducted a user study to compare these two methods of prototyping and to validate the use of spatial augmented reality for rapid iterative interface prototyping. Participants of the study were required to press pairs of buttons in sequence and interaction times were measured. The results indicate that while slower, users can interact naturally with projected control panels.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643599","Spatial Augmented Reality;Rapid Prototyping;Industrial Design","Prototypes;Presses;Augmented reality;Visualization;Three dimensional displays;Automotive engineering;Analysis of variance","augmented reality;man-machine systems;rapid prototyping (industrial)","spatial augmented reality;interactive rapid prototyping;human-machine interfaces;finger tracking;real-time interactions","","9","","7","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Towards Engaging Upper Extremity Motor Dysfunction Assessment Using Augmented Reality Games","M. A. Cidota; S. G. Lukosch; P. J. M. Bank; P. W. Ouwehand","Faculty of Technology, Delft University of Technology, The Netherlands; Faculty of Technology, Delft University of Technology, The Netherlands; Department of Neurology, Leiden University Medical Center, The Netherlands; Leids Universitair Medisch Centrum, Leiden, Zuid-Holland, NL","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","275","278","Advances in technology offer new opportunities for a better understanding of how different disorders affect motor function. Our aim is to explore the potential of augmented reality (AR) using free hand and body tracking to develop engaging games for a uniform, cost-effective and objective evaluation of upper extremity motor dysfunction in different patient groups. Based on the insights from a study with 20 patients (10 Parkinson’s Disease patients and 10 stroke patients) who performed hand/arm movement tasks in AR, we created a set of different augmented reality games for upper extremity motor dysfunction assessment.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088504","Augmented Reality Games;Engagement;Upper Extremity Motor Dysfunction;Assessment;Parkinson’s Disease;Stroke patients","Games;Augmented reality;Tracking;Visualization;Usability;Resists","augmented reality;biomechanics;diseases;medical computing;medical disorders;patient rehabilitation","upper extremity motor dysfunction assessment;motor function;free hand;body tracking;engaging games;medical disorders;Parkinson disease patients;stroke patients;augmented reality games;hand-arm movement tasks","","6","","20","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Integrating Building Information Modeling with Augmented Reality for Interdisciplinary Learning","S. Vassigh; A. Elias; F. R. Ortega; D. Davis; G. Gallardo; H. Alhaffar; L. Borges; J. Bernal; N. D. Rishe",Florida International University; Florida International University; Florida International University; Florida International University; Florida International University; Florida International University; Florida International University; Florida International University; Florida International University,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","260","261","Augmented Reality provides a way to enhance the classroom experience. In particular, student learning about building systems in the fields of Architecture, Civil, and Mechanical Engineering may improve, if visualization outside the classroom is provided. We propose that AR-SKOPE, an application that integrates Building Information Modelling and Augmented Reality may improve learning. This application allows students to visit specific buildings and investigate their various systems with supplementary information using a phone or tablet. We are currently testing our early prototype to conduct a semester-long study.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836510","Augmented Reality;Teaching Tools;Building Information Modelling;Architecture and Engineering Education","Buildings;Augmented reality;Solid modeling;Education;Magnetic resonance imaging;Architecture;Visualization","architecture;augmented reality;buildings (structures);computer aided instruction;education","AR-SKOPE;mechanical engineering;civil engineering;architecture;building systems;student learning;classroom experience;interdisciplinary learning;augmented reality;building information modeling integration","","6","","7","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Consolidating the Research Agenda of Augmented Reality Television with Insights from Potential End-Users","I. Popovici; R. -D. Vatavu","MintViz Lab., University Stefan cel Mare of Suceava, Suceava, Romania; MintViz Lab, University Ştefan cel Mare of Suceava, Suceava, Romania","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","73","74","We examine the research agenda proposed for Augmented Reality Television (AR-TV) through the perspective of the findings of an online study, where 172 respondents shared their understanding of Augmented Reality (AR) and their preferences for AR-TV scenarios.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951928","augmented reality, interactive TV, study, questionnaire, research agenda","Augmented reality;Visualization;Smart TV;Smart devices;Tools;Smart phones","augmented reality;human computer interaction;human factors","research agenda;Augmented Reality Television;potential end-users;AR-TV;human computer interaction","","5","","12","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Investigating Augmented Reality Animals as Companions","N. Norouzi; G. Bruder; J. Bailenson; G. Welch",University of Central Florida; University of Central Florida; Stanford University; University of Central Florida,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","400","403","Human-animal interaction has been studied in a variety of settings and for a range of populations, with some findings pointing towards its benefits for physical, mental and social human health. Technological advances opened up new opportunities for researchers to replicate human-animal interactions with robotic and graphical animals, and to investigate human-animal relationships for different applications such as mental health and education. Although graphical animals have been studied in the past in the physical health and education domains, most of the time, their realizations were bound to computer screens, limiting their full potential, especially in terms of companionship and the provision of support. In this work, we describe past research efforts investigating influences of human-animal interaction on mental health and different realization of such animals. We discuss the idea that augmented reality could offer potential for human-animal interaction in terms of mental and social health, and propose several aspects of augmented reality animals that warrant further research for such interactions.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.000-1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951890","Animal Assisted Interventions;Augmented Reality;Companion Animals;Virtual Animals","Dogs;Robots;Sociology;Statistics;Medical treatment;Augmented reality","augmented reality;biology computing;human computer interaction;zoology","human-animal interaction;physical human health;mental human health;social human health;graphical animals;human-animal relationships;mental health;physical health;education domains;social health;augmented reality animal investigation;robotic animals","","3","","27","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Window: Digital reconstruction of a historical and cultural site for smart phones","J. Kang; J. -h. Ryu","KAIST, South Korea; KAIST, South Korea","2010 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","22 Nov 2010","2010","","","67","68","Due to the city development projects in Seoul, `Pimatgol' a historical and cultural site has been disappeared and rebuilt. There have been many efforts to reconstruct this kind of historical and cultural sites by using technology. We have reconstructed `Pimatgol' with digital photos from the past taken by members of the community. Augmented Reality Window (AR Window) is an Augmented Reality application for reconstructing `Pimatgol' for smart phones. User can see the past scenes over present scenes in their phones through AR Window. User can experience multiple interactions like blowing a breath, wiping with a finger and touching buttons on a phone. We concentrated on how this case affects user's emotion. AR Window opens a new way for digital reconstruction for smart phones which can raise awareness from the members of the community.","2381-8360","978-1-4244-9342-5","10.1109/ISMAR-AMH.2010.5643289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643289","Augmented Reality;Interaction","Image reconstruction;Cultural differences;Augmented reality;Cameras;Smart phones;Fingers","augmented reality;image reconstruction;mobile computing","digital reconstruction;smart phone;augmented reality window;user emotion;digital photos;historical site;cultural site","","3","","7","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"An Evaluation of Information Connection in Augmented Reality for 3D Scenes with Occlusion","R. Dauenhauer; T. Müller",Reutlingen University; NA,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","235","237","Most augmented reality applications connect virtual information to anchors, i.e. physical places or objects, by using spatial overlays or proximity. However, for industrial use cases this is not always feasible because specific parts must remain fully visible in order to meet work or security requirements. In these situations virtual information must be displayed at alternative positions while connections to anchors must still be clearly recognizable. In our previous research we were the first to show that for simple scenes connection lines are most suitable for this. To extend these results to more complex environments, we conducted an experiment on the effects of visual interruptions in connection lines and incorrect occlusion. Completion time and subjective mental effort for search tasks were used as measures. Our findings confirm that also in 3D scenes with partial occlusion connection lines are preferable to connect virtual information with anchors if an assignment via overlay or close proximity is not feasible. The results further imply that neither incorrectly used depth cues nor missing parts of connection lines make a significant difference concerning completion time or subjective mental effort. For designers of industrial augmented reality applications this means that they can choose either visualization based on their needs.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836504","Augmented reality;perception;occlusion","Color;Visualization;Augmented reality;Three-dimensional displays;Encoding;Context;Maintenance engineering","augmented reality;data visualisation;engines;information systems","visualization;industrial augmented reality applications;partial occlusion connection lines;visual interruptions;virtual information display;security requirements;proximity;spatial overlays;anchors;3D scenes;information connection evaluation","","2","","7","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Precise Geometric Registration by Blur Estimation for Vision-based Augmented Reality","B. Okumura; M. Kanbara; N. Yokoya","Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","221","224","This paper proposes an accurate geometric registration method by estimating blur effects from a degraded image with image markers for augmented reality. A small and inexpensive camera used in augmented reality systems sometimes captures degraded images because its focus and/or iris are fixed. This degradation of a captured image affects the accuracy of the detected positions of feature points in the image. The proposed method improves the accuracy of the estimated camera position and posture by estimating blur effects from the captured image, and by correcting the detected positions of feature points through the results. The effectiveness of the method is confirmed through experiments of corner estimation from simulated images and extrinsic camera parameter estimation from real images.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538851","augmented reality;geometric registration;blur estimation;point spread function","Augmented reality;Cameras;Robustness;Degradation;Computer vision;Motion detection;Motion estimation;Focusing;Iris;Layout","augmented reality;computer vision;image registration;image sensors","geometric registration;vision-based augmented reality;image markers;blur effects","","1","","9","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Ready for Industrial Use? A User Study of Spatial Augmented Reality in Industrial Assembly","T. Zigart; S. Schlund","Institute of Management Science, TU Wien, Austria; Institute of Management Science, TU Wien, Austria","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","60","65","Spatial augmented reality (SAR) allows embedding instructions in the operator's field of view in manufacturing processes while hands-free working is possible. In this paper, we present the results of a field study in manufacturing to evaluate on the industrial readiness of SAR. We compared a worker assistance system via a tablet with a spatial augmented reality projection in a user study with skilled workers and students when assembling and wiring an industrial control panel. Human factors and process indicators are evaluated, qualitative feedback is summarized, and potential improvements are discussed.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00022","Austrian Research Promotion Agency; TU Wien; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974465","Spatial Augmented Reality;User Study;Manufacturing;Evaluation;Cognitive Assistance System;K.4.3 [COMPUTERS AND SOCIETY]: Organizational Impacts;K.6.1 [Management of Computing and Information Systems]: Project and People Management","Industries;Wiring;Manufacturing processes;Spatial augmented reality;Switches;Production;Manufacturing","assembling;augmented reality;control engineering computing;human factors;industrial control;personnel","human factors;industrial assembly;industrial control panel;industrial readiness;manufacturing processes;SAR;spatial augmented reality projection;worker assistance system","","1","","25","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"[POSTER] ARPML: The Augmented Reality Process Modeling Language","T. Müller; T. Rieger",Robert Bosch GmbH; Robert Bosch GmbH,"2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","160","163","The successful application of augmented reality as a guidance tool for procedural tasks like maintenance or repair requires an easily usable way of modeling support processes. Even though some suggestions have already been made to address this problem, they still have shortcomings and don't provide all the required features. Thus in a first step the requirements a possible solution has to meet are collected and presented. Based on these, the augmented reality process modeling language (ARPML) is developed, which consists of the four building blocks (i) templates, (ii) sensors, (iii) work steps and (iv) tasks. In contrast to existing approaches it facilitates the creation of multiple views on a single process. This makes it possible to specifically select instructions and information needed in targeted work contexts. It also allows to combine multiple variants of one process into one model with only a minimum of redundancy. The application of ARPML is shown with a practical example.","","978-1-4673-7660-0","10.1109/ISMAR.2015.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328086","Augmented reality;Authoring","Sensors;Solid modeling;Augmented reality;Maintenance engineering;Adaptation models;Plugs;Sockets","augmented reality;redundancy;Unified Modeling Language","ARPML;augmented reality process modeling language;redundancy","","","","8","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Animar: Augmenting the Reality of Storyboards and Animations","C. Lins; E. Arruda; E. Neto; R. Roberto; V. Teichrieb; D. Freitas; J. M. Teixeira","Voxar Labs, Informatics Center - UFPE; Voxar Labs, Informatics Center - UFPE; Voxar Labs, Informatics Center - UFPE; Voxar Labs, Informatics Center - UFPE; Voxar Labs, Informatics Center - UFPE; Universidade Federal de Pernambuco, Recife, PE, BR; Universidade Federal Rural de Pernambuco, Recife, PE, BR","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","106","109","This paper presents Animar, a mobile application to create short animations that uses augmented reality to aid the sketching. This application was conceived using design methods and its characteristics were used to create the interface and form of interaction. The user draws each frame on a specific paper with empty rectangles and a few patterns. The software extracts the frames and rectifies the perspective distortion using image processing techniques. To help the user, Animar tracks the pattern to show a virtual onion skin of a chosen frame over another one. The animation is generated by combining all the frames extracted from the paper. Animar was developed for Android and supports multiple screen sizes from cell phones to tablets and its concept won an international contest on problem solving with augmented reality.","","978-1-4799-4261-9","10.1109/SVR.2014.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913079","mobile augmented reality;drawing;animation","Animation;Augmented reality;Skin;Software;Art;Cameras;Androids","augmented reality;computer animation;image processing;mobile computing;object tracking;smart phones","Animar;storyboards;mobile application;short animations;augmented reality;sketching;design methods;perspective distortion;image processing techniques;pattern tracking;virtual onion skin;Android;screen sizes;cell phones;tablets","","","","15","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"Marker-less vision based tracking for mobile augmented reality","D. Beier; R. Billert; B. Bruderlin; D. Stichling; B. Kleinjohann","Computer Graphics Program, Technische Universität Illmenau, Ilmenau, Germany; Computer Graphics Program, Technische Universität Illmenau, Ilmenau, Germany; Computer Graphics Program, Technische Universität Illmenau, Ilmenau, Germany; Intelligent Mobile Systems, Universität Paderborn, Paderborn, Germany; Intelligent Mobile Systems, Universität Paderborn, Paderborn, Germany","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","258","259","In this paper an object recognition and tracking approach for the mobile, marker-less and PDA-based augmented reality system AR-PDA is described. For object recognition and localization 2D features are extracted from images and compared with a priori known 3D models. The system consists of a 2D graph matching, 3D hypothesis generation and validation and an additional texture based validation step.","","0-7695-2006-5","10.1109/ISMAR.2003.1240709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240709","","Augmented reality;Cameras;Object recognition;Feature extraction;Mobile computing;Layout;Computer graphics;Intelligent systems;Production;Shape","augmented reality;object recognition;rendering (computer graphics);image matching;mobile computing;computer vision;notebook computers;object detection","markerless vision based tracking;mobile augmented reality;object recognition;tracking approach;marker-less augmented reality;PDA-based augmented reality;AR-PDA;localization 2D features;image extraction;3D models;2D graph matching;3D hypothesis generation;texture based validation step","","12","1","3","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Setting up Virtual Reality and Augmented Reality Learning Environment in Unity","V. T. Nguyen; T. Dang",Texas Tech University; Texas Tech University,"2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","315","320","We propose a framework and a setup for presenting complex models for curriculum contents in both augmented reality and virtual reality environment. After constructing some three-dimensional models representing real world objects such as trees, stones, rivers, dams, and buildings, our workflow uses the Unity engine in combination with Virtual Reality headset devices to create interactive applications for both Virtual Reality and Augmented Reality environments to support students understanding the curriculum contents through their surrounding. Typical challenges are addressed when creating 3D curriculum contents, integrating these models into Unity and solutions are proposed where possible. The overall structure of the project is described with some functionalities added to Unity for visualization and interaction with the models.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.97","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088512","Mixed reality;computational thinking;curriculum contents;Unity engine;watershed","Solid modeling;Three-dimensional displays;Augmented reality;Games;Buildings;Google","augmented reality;computer aided instruction;data visualisation;solid modelling","Unity engine;Virtual Reality headset devices;Augmented Reality learning environment;visualization;3D curriculum contents;3D models","","25","","22","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Keynote Speaker: Wearable Haptics for Virtual and Augmented Reality","",,"2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","1 Nov 2021","2021","","","18","18","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. In the last decade, we have witnessed a drastic change in the form factor of audio and vision technologies, from heavy and grounded machines to lightweight devices that naturally fit our bodies. However, only recently, haptic systems have started to be designed with wearability in mind, which enables novel forms of interaction in virtual and augmented reality. The development of wearable haptic devices for virtual and augmented environments faces the challenge of providing users with consistent sensory inputs. The problem often stems from the compromise linked with the concept of wearability: it is fundamental to find the right equilibrium between realism of the perception and design constraints for wearability, in order to avoid that the haptic feedback quality becomes inversely proportional to the overall degree of device wearability. In this keynote, I will present a brief excursus on the most relevant challenges of haptics for AR and VR in a wearable perspective, together with a discussion on the future perspectives of haptics in virtual and augmented reality. ","1554-7868","978-1-6654-0158-6","10.1109/ISMAR52148.2021.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583827","","Haptic interfaces;Augmented reality;Robot kinematics;Wearable computers;Robot sensing systems;Patents;IEEE Fellows","augmented reality;haptic interfaces;virtual reality","keynote speaker;wearable haptics;summary form;complete presentation;conference proceedings;form factor;vision technologies;heavy grounded machines;lightweight devices;haptic systems;virtual reality;augmented reality;wearable haptic devices;virtual environments;augmented environments;haptic feedback quality;device wearability;wearable perspective","","","","","IEEE","1 Nov 2021","","","IEEE","IEEE Conferences"
"CAMAR Tag Framework: Context-Aware Mobile Augmented Reality Tag Framework for Dual-reality Linkage","H. Kim; W. Lee; W. Woo","GIST U VR Laboratory, Gwangju, South Korea; GIST U VR Laboratory, Gwangju, South Korea; GIST U VR Laboratory, Gwangju, South Korea","2009 International Symposium on Ubiquitous Virtual Reality","4 Sep 2009","2009","","","39","42","In this paper, we propose a novel tag framework for sharing information in dual-reality space, which is based on context-aware mobile augmented reality (CAMAR). When a user selects a target object to be tagged onto dual-reality, the proposed framework and procedures create CAMAR Tag with a userpsilas mobile device to be registered in virtual space. CAMAR Tag is able to play a role as a reference point, a sharing point and a key of contextual searching. We present a concept behind CAMAR Tag and how it can be generated, implemented and deployed in dual-reality.","","978-1-4244-4437-3","10.1109/ISUVR.2009.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232251","CAMAR Tag;Tag framework;mobile augmented reality;dual-reality","Augmented reality;Couplings;Context modeling;Virtual reality;Joining processes;Target recognition;Data models;RFID tags;Information retrieval;Content management","augmented reality;ubiquitous computing","CAMAR;context-aware mobile augmented reality tag;dual-reality linkage;virtual space;contextual searching","","2","4","7","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"Physical-virtual tools for spatial augmented reality user interfaces","M. R. Marner; B. H. Thomas; C. Sandor","University of South Australia, Australia; University of South Australia, Australia; University of South Australia, Australia","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","205","206","This paper presents a new user interface methodology for Spatial Augmented Reality systems. The methodology is based on a set of physical tools that are overloaded with logical functions. Visual feedback presents the logical mode of the tool to the user by projecting graphics onto the physical tools. This approach makes the tools malleable in their functionality, with this change conveyed to the user by changing the projected information. Our prototype application implements a two handed technique allowing an industrial designer to digitally airbrush onto an augmented physical model, masking the paint using a virtualized stencil.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336458","Spatial Augmented Reality;User Interfaces","Augmented reality;User interfaces;Paints;Feedback;Visualization;Large-scale systems;Shape;Lamps;Graphical user interfaces;Spraying","augmented reality;graphical user interfaces;technical drawing","spatial augmented reality;user interfaces;physical-virtual tools;visual feedback;projected information;virtualized stencil;logical functions;graphics projection","","24","1","8","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Motion Parallax Representation for Indirect Augmented Reality","F. Okura; Y. Nishizaki; T. Sato; N. Kawai; N. Yokoya",Osaka University; NAIST; NAIST; NAIST; NAIST,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","105","106","Indirect augmented reality (IAR) presents pre-generated augmented images for achieving high-quality geometric and photometric registration between pre-captured images and virtual objects. Meanwhile, IAR causes spatial inconsistency between the real world and presented images when users move from the location where the real scene was captured. This paper describes a novel way to address the spatial inconsistency; namely, enabling viewpoint change in IAR. The key idea of this study is to employ an image-based rendering technique using pre-captured multi-view omnidirectional images to provide free-viewpoint navigation. For a pilot study, we have developed an IAR system representing a motion parallax effect using an optical-flow-based camera motion estimation.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836472","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial;augmented;and virtual realities","Cameras;Three-dimensional displays;Augmented reality;Rendering (computer graphics);Optical imaging;Solid modeling;Image reconstruction","augmented reality;cameras;image capture;image motion analysis;rendering (computer graphics)","optical-flow-based camera motion estimation;free-viewpoint navigation;pre-captured multiview omnidirectional images;image-based rendering technique;photometric registration;virtual objects;IAR system;motion parallax representation;indirect augmented reality","","2","","9","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Teachers' and students' perceptions toward augmented reality materials","M. -C. Hsieh","Department of Information Management, Fortune Institute of Technology, Kaohsiung, Taiwan","2016 International Conference on Applied System Innovation (ICASI)","11 Aug 2016","2016","","","1","2","Augmented reality in learning has been widely studied, but mostly from the student's perspective and learning effectiveness. The few researches explored the instructors' and students' perceptions. In this paper, we developed an Augmented Reality English Learning System to examine teachers' and students' perceptions toward AR materials. The teachers and students were interviewed to explore their viewpoints about ARELS teaching after finishing learning the AR English course. The AR English Materials could raise the learning motivation and enhance students' concentration and affect their learning behaviors.","","978-1-4673-9888-6","10.1109/ICASI.2016.7539773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539773","augmented reality;augmented reality materials;augmented reality learning;English teaching","Decision support systems;Augmented reality;Education;Interviews","augmented reality;computer aided instruction;educational courses;human factors;natural language processing;teaching","teacher perceptions;student perceptions;augmented reality materials;student learning effectiveness;augmented reality English learning system;ARELS teaching viewpoints;AR English course;learning motivation;student concentration enhancement;learning behaviors","","","","10","IEEE","11 Aug 2016","","","IEEE","IEEE Conferences"
"Inexpensive non-sensor based augmented reality modeling of curves and surfaces in physical space","A. D. Cheok; E. Neo Weng Chuen; Ang Wee Eng","National University of Singapore, Singapore; Nat. Univ. of Singapore, Singapore; National University of Singapore, Singapore","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","273","274","Previous work in modeling curves and surfaces in augmented reality (AR) space has used expensive sensors such as magnetic sensors. In this work, we propose an augmented reality system where a user can model interesting surfaces with her hands, without expensive sensing systems. The system uses computer vision based methods for tracking the user's head and hand position. Using a glove and the tracking system, the user can draw smooth lines or surfaces with her hands in a physical space. The user can also intuitively modify the lines or surface created by pushing or pulling at the control points of lines or curves in a tangible manner.","","0-7695-1781-1","10.1109/ISMAR.2002.1115109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115109","","Augmented reality;Fingers;Magnetic sensors;Virtual reality;Sensor systems;Shape control;Color;Computer vision;Magnetic heads;Automatic control","augmented reality;data gloves;computer vision;optical tracking;CAD;engineering graphics","inexpensive nonsensor based augmented reality modeling;curves;surfaces;augmented reality;computer vision based methods;head position tracking;hand position tracking;glove","","6","","6","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Augmented reality @ Siemens: ""The Workflow Designer Project"" & ""Augmented reality PDA""","A. Raczynski; C. Reimann; P. Gussmann; C. Matysczok; A. Grow; W. Rosenbach","Siemens AG, Germany; C-LAB; Siemens AG; Heinz Nixdorf Institute, University of Paderborn, Germany; Siemens AG; C-LAB, Germany","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","2 pp.","","In this paper we describe two AR projects at Siemens: ""The Workflow Designer Project"" and ""AR-PDA - A Personal Digital Assistant for VR/AR Content"". The Workflow Designer makes use of pattern recognition and tracking to augment real-time video with 3D models, allowing a remote expert to guide a worker through a complicated workflow step-by-step. The general idea of the AR-PDA project to the development of applications for new mobile devices like 3/sup rd/ generation mobile telephones, organizer or PDA for the consumer market. In this context augmented reality is used to support efficiently final users during their daily tasks and especially in service situations. The AR-PDA enhances real camera images by virtual objects (3D-animations, 2D-graphics or text) and allows personalized user interactions with the augmented scene.","","0-7803-7680-3","10.1109/ART.2002.1106974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106974","","Augmented reality;Layout;Pattern recognition;Wireless networks;Video compression;Image coding;Prototypes;Animation;Displays;Personal digital assistants","3G mobile communication;augmented reality;workflow management software;notebook computers;pattern recognition;real-time systems;computer animation","augmented reality;Siemens;The Workflow Designer Project;Augmented reality PDA;A Personal Digital Assistant for VR/AR Content;AR-PDA;pattern recognition;pattern tracking;real-time video;3D models;3rd generation mobile telephones;virtual objects;3D animations;2D graphics;text;personalized user interactions;augmented scene","","1","3","3","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"An augmented reality system for treating psychological disorders: application to phobia to cockroaches","M. C. Juan; C. Botella; M. Alcaniz; R. Banos; C. Carrion; M. Melero; J. A. Lozano","MedICLab, Universidad Politecnica de Valencia, Spain; Universidad de Valencia, Spain; MedICLab, Universidad Politecnica de Valencia, Spain; Departmento de Psicologia Basica y Psicobiologia, UJI, Spain; MedICLab, Universidad Politecnica de Valencia, Spain; MedICLab, Universidad Politecnica de Valencia, Spain; MedICLab, Universidad Politecnica de Valencia, Spain","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","256","257","Augmented reality has been used in many fields, but it has not been used to treat psychological disorders. Augmented reality presents several advantages respect to: the traditional treatment of psychological disorders and virtual reality treatments. In this paper we present the first augmented reality system for the treatment of phobia to cockroaches. Our system has been developed using ARToolkit software. It has been tested with one patient and the results have been very satisfactory. At first of the exposure session the patient was not able to approach to a real cockroach and after the exposure session using our augmented reality system, the patient was able to approach to a real cockroach, to interact with it and to kill it by herself. This first result is very encouraging and it demonstrates that augmented reality exposure is effective for the treatment of this kind of phobias.","","0-7695-2191-6","10.1109/ISMAR.2004.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383064","","Augmented reality;Psychology;Virtual reality;Medical treatment;Animals;Cameras;Testing;Streaming media;Universal Serial Bus;Instruments","augmented reality;psychology;patient diagnosis","augmented reality system;psychological disorders;cockroach phobia;virtual reality;ARToolkit software","","18","","4","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"Why should my students use AR? A comparative review of the educational impacts of augmented-reality","I. Radu",Public Broadcasting Service (PBS) KIDS Interactive,"2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","313","314","Augmented reality is increasingly reaching young users such as elementary-school and high-school children, as their parents and teachers become aware of the technology and its potential for education. Although research has shown that AR systems have the potential to improve student learning, the educator community does not clearly understand the educational impact of AR, nor the factors which impact the educational effectiveness of AR. In this poster, we analyse 32 publications that have previously compared learning effects of AR vs non-AR applications. We identify a list of positive and negative impacts of AR on student learning, and identify potential underlying causes for these effects. Our vision is that educational initiatives will exploit these factors, in order to realize the full potential of AR to enrich learner's lives.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402590","Augmented Reality;Education;Children;Human Factors","Augmented reality;Education;Solid modeling;Media;Human factors;Computers;Machine learning","augmented reality;computer aided instruction","educational impacts;augmented-reality;elementary-school children;high-school children;parents;teachers;AR systems;student learning;educator community;educational effectiveness;AR learning effects;educational initiatives","","97","","12","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Supporting order picking with Augmented Reality","B. Schwerdtfeger; G. Klinker","Fakultät fur Informatik, Technische Universität, Garching, Germany; Fakultät fur Informatik, Technische Universität, Garching, Germany","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","91","94","We report on recent progress in the iterative process of exploring, evaluating and refining Augmented Reality-based methods to support the order picking process. We present our findings from three user studies and from demonstrations at several exhibitions. The resulting setup is a combined visualization to precisely and efficiently guide the user, even if the augmentation is not always in the field of view of the HMD.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637331","H.5.1 [ INFORMATION INTERFACES AND PRESENTATION]: Multimedia Information Systems—Artificial, augmented, and virtual realities; Evaluation/methodology;H.5.2 [ INFORMATION INTERFACES AND PRESENTATION]: User Interfaces — User-centered design","Visualization;Three dimensional displays;Navigation;Augmented reality;Fading;Distance measurement;Mobile communication","augmented reality;data visualisation;goods dispatch data processing;logistics data processing;order picking;user interfaces","order picking process;augmented reality;iterative process;data visualization;HMD;user interface;logistics","","82","4","8","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Ninja on a Plane: Automatic Discovery of Physical Planes for Augmented Reality Using Visual SLAM","D. Chekhlov; A. P. Gee; A. Calway; W. Mayol-Cuevas","Department of Computer Science, University of Bristol, UK; Department of Computer Science, University of Bristol, UK; Department of Computer Science, University of Bristol, UK; Department of Computer Science, University of Bristol, UK","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","153","156","Most work in visual augmented reality (AR) employs predefined markers or models that simplify the algorithms needed for sensor positioning and augmentation but at the cost of imposing restrictions on the areas of operation and on interactivity. This paper presents a simple game in which an AR agent has to navigate using real planar surfaces on objects that are dynamically added to an unprepared environment. An extended Kalman filter (EKF) simultaneous localisation and mapping (SLAM) framework with automatic plane discovery is used to enable the player to interactively build a structured map of the game environment using a single, agile camera. By using SLAM, we are able to achieve real-time interactivity and maintain rigorous estimates of the system's uncertainty, which enables the effects of high quality estimates to be propagated to other features (points and planes) even if they are outside the camera's current field of view.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538840","H.5.1 [Information Systems]: Multimedia Information Systems-Augmented Reality;I.4.8 [Image Processing and Computer Vision]: Scene Analysis-Tracking;Surface Fitting","Augmented reality;Simultaneous localization and mapping;Cameras;Sensor systems;Real time systems;Uncertainty;Layout;Surface fitting;Robustness;Interactive systems","augmented reality;Kalman filters;SLAM (robots)","physical planes automatic discovery;augmented reality;visual SLAM;simultaneous localisation and mapping;sensor positioning;extended Kalman filter","","56","1","16","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"KHARMA: An open KML/HTML architecture for mobile augmented reality applications","A. Hill; B. MacIntyre; M. Gandy; B. Davidson; H. Rouzati","GVU Center, Georgia Institute of Technology, USA; GVU Center, Georgia Institute of Technology; GVU Center, Georgia Institute of Technology, USA; GVU Center, Georgia Institute of Technology, USA; GVU Center, Georgia Institute of Technology, USA","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","233","234","Widespread future adoption of augmented reality technology will rely on a broadly accessible standard for authoring and distributing content with, at a minimum, the flexibility and interactivity provided by current web authoring technologies. We introduce KHARMA, an open architecture based on KML for geospatial and relative referencing combined with HTML, JavaScript and CSS technologies for content development and delivery. This architecture uses lightweight representations that decouple infrastructure and tracking sources from authoring and content delivery. Our main contribution is a re-conceptualization of KML that turns HTML content formerly confined to balloons into first-class elements in the scene. We introduce the KARML extension that gives authors increase control over the presentation of HTML content and its spatial relationship to other content.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643583","Augmented Reality;World Wide Web;Authoring","Servers;HTML;Augmented reality;Computer architecture;Browsers;Global Positioning System;Protocols","augmented reality;authoring systems;hypermedia markup languages;Internet;mobile computing;software architecture","KHARMA;open KML-HTML architecture;mobile augmented reality technology;Web authoring technologies;JavaScript technology;CSS technology;content development","","28","1","3","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"ASTOR: an autostereoscopic optical see-through augmented reality system","A. Olwal; C. Lindfors; J. Gustafsson; T. Kjellberg; L. Mattsson","Department of Numerical Analysis and Computer Science, Royal Institute of Technology, Stockholm, Sweden; Department of Production Engineering, Royal Institute of Technology, Stockholm, Sweden; Department of Production Engineering, Royal Institute of Technology, Stockholm, Sweden; Department of Production Engineering, Royal Institute of Technology, Stockholm, Sweden; Department of Production Engineering, Royal Institute of Technology, Stockholm, Sweden","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","24","27","We present a novel autostereoscopic optical see-through system for augmented reality (AR). It uses a transparent holographic optical element (HOE) to separate the views produced by two, or more, digital projectors. It is a minimally intrusive AR system that does not require the user to wear special glasses or any other equipment, since the user would see different images depending on the point of view. The HOE itself is a thin glass plate or plastic film that can easily be incorporated into other surfaces, such as a window. The technology offers great flexibility, allowing the projectors to be placed where they are the least intrusive. ASTOR's capability of sporadic AR visualization is currently ideal for smaller physical workspaces, such as our prototype setup in an industrial environment.","","0-7695-2459-1","10.1109/ISMAR.2005.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544658","augmented reality;optical see-through;autostereoscopy;holographic optical element;system;projection-based","Augmented reality;Holographic optical components;Holography;Displays;Optical films;Glass;Prototypes;Handheld computers;Mirrors;Numerical analysis","augmented reality;holographic optical elements;data visualisation;optical projectors;stereo image processing;visual perception;computer displays","ASTOR;autostereoscopic optical see-through augmented reality system;holographic optical element;intrusive AR system;sporadic AR visualization","","21","10","18","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"A Haptic Serious Augmented Reality Game for Motor Assessment of Parkinson's Disease Patients","E. van der Meulen; M. A. Cidota; S. G. Lukosch; P. J. M. Bank; A. J. C. van der Helm; V. T. Visch","Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Leiden University, Medical Center, The Netherlands; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","102","104","In the clinical community there is a need for assessment tools that allow for objective, quantitative and valid measures of motor dysfunction. In this paper, we report on the design and evaluation of a serious game that engages patients with Parkinson's disease in upper extremity (hand/arm) movements. The game employs augmented reality to show virtual movement targets, i.e. candies falling from a conveyor belt, and a haptic game controller to catch the candies, that is able to acquire quantitative data about the patient's movement. This paper first describes the design process of the game and the system components. Secondly, we present results of our small quantitative evaluation study (N11, age: 26-60, healthy persons) regarding the usability of the system, the task load and user experience of the game. Our findings show that the system has a relatively good usability and the game is engaging, but there is still need for technical improvement with regard to tracking the controller in 3D space.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836471","Augmented Reality;Optical See-Through Head Mounted Display;Haptic Device;Serious Game Design;Assessment of Upper Extremity Motor Dysfunction;Parkinson's Disease.","Games;Belts;Usability;Haptic interfaces;Tracking;Augmented reality;Extremities","augmented reality;belts;conveyors;diseases;haptic interfaces;human factors;medical computing;serious games (computing)","motor assessment;haptic serious augmented reality game;3D space;task load;user experience;conveyor belt;candies;haptic game controller;upper extremity movements;Parkinson's disease patients;motor dysfunction","","15","","13","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Designing for Engagement in Augmented Reality Games to Assess Upper Extremity Motor Dysfunctions","P. Dezentje; M. A. Cidota; R. M. S. Clifford; S. G. Lukosch; P. J. M. Bank; H. K. Lukosch","Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Leiden University Medical Center, The Netherlands; Leiden University Medical Center, The Netherlands","2015 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design","10 Dec 2015","2015","","","57","58","Currently, each medical discipline involved in assessing motor disorders in various patient groups is using subjectively scored clinical tests, qualitative video analysis, or cumbersome marker-based motion capturing. This extended abstract investigates the potential of a serious game implemented as an Augmented Reality (AR) application to facilitate objective, quantitative and valid measures of the factors contributing to upper extremity motor dysfunction. First, the design process of the game and the system architecture of the AR framework are described. Second, a study about game engagement is presented based on an experiment we conducted with eight healthy people, aged between 52-79. The results of the study show that there is potential for engagement, but the usability needs to be improved before it can emerge.","","978-1-4673-9628-8","10.1109/ISMAR-MASHD.2015.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350739","Augmented Reality;Optical See-Through Head Mounted Display;Serious Games;Engagement;Assessment of Upper Extremity Motor Dysfunction","Games;Augmented reality;Usability;Thumb;Diseases;Systems architecture","augmented reality;medical computing;motion estimation;patient diagnosis;serious games (computing);video signal processing","augmented reality games;upper extremity motor dysfunction assessment;motor disorders;patient groups;subjectively scored clinical tests;qualitative video analysis;cumbersome marker-based motion capturing;serious game;AR framework;game engagement","","15","","13","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"Making Pretense Visible and Graspable: An augmented reality approach to promote pretend play","Z. Bai; A. F. Blackwell; G. Coulouris",University of Cambridge; University of Cambridge; University of Cambridge,"2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","267","268","Children with autism are often found to lack facility for pretend play. It is believed that this deficit is linked to linguistic, social and creativity competencies in autism. We observe that both Augmented Reality (AR) and pretend play involve processing of information that is coupled with real scenes while not necessarily being directly perceived. This research therefore examines the potential of using AR technologies to promote pretend play behaviors in children with autism. As an initial outcome, we present the design and implementation of an AR system that aims to enhance the comprehension and flexibility of object substitution during pretend play.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402567","Augmented Reality;pretend play;autistic children","Autism;Augmented reality;Airplanes;Mirrors;Bridges;Educational institutions;Cotton","augmented reality;handicapped aids","augmented reality;pretend play behavior;autism;linguistic competency;social competency;creativity competency;AR technology","","13","","7","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Visualizing Occluded Physical Objects in Unfamiliar Outdoor Augmented Reality Environments","B. Avery; W. Piekarski; B. H. Thomas","Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","285","286","This paper describes techniques to allow both the visualization of hidden objects, and removal of real objects, for a mobile augmented reality user. A gesture based technique is also described which allows the user to select when to view occluded objects. By using the real-time modeling techniques of the Tinmith system, the user is able to create the required geometry to allow image based rendering techniques to be used to render corrected images on the user's display. The images of the hidden objects are captured by a mobile robot platform that is controlled by the mobile user.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538869","Outdoor Augmented Reality;Wearable Computers;Telepresence;Image-based Rendering;3D Modeling","Visualization;Augmented reality;Rendering (computer graphics);Wearable computers;Solid modeling;Computer displays;Computer graphics;Mobile computing;Mobile robots;Navigation","augmented reality;computer vision;data visualisation;rendering (computer graphics)","occluded physical objects;unfamiliar outdoor augmented reality environments;hidden objects visualization;gesture based technique;Tinmith system;real-time modeling techniques;mobile robot platform","","12","2","4","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Online environment model estimation for augmented reality","J. Ventura; T. Hollerer","University of California, Santa Barbara, USA; University of California, Santa Barbara, USA","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","103","106","Augmented reality applications often rely on a detailed environment model to support features such as annotation and occlusion. Usually, such a model is constructed offline, which restricts the generality and mobility of the AR experience. In online SLAM approaches, the fidelity of the model stays at the level of landmark feature maps. In this work we introduce a system which constructs a textured geometric model of the user's environment as it is being explored. First, 3D feature tracks are organized into roughly planar surfaces. Then, image patches in keyframes are assigned to the planes in the scene using stereo analysis. The system runs as a background process and continually updates and improves the model over time. This environment model can then be rendered into new frames to aid in several common but difficult AR tasks such as accurate real-virtual occlusion and annotation placement.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336493","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism;Augmented reality; I.4.8 [Image Processing and Computer Vision]: Scene Analysis;Stereo; I.4.8 [Image Processing and Computer Vision]: Scene Analysis;Color","Augmented reality;Layout;Image reconstruction;Simultaneous localization and mapping;Image analysis;Rendering (computer graphics);Cameras;Rough surfaces;Surface roughness;Computer graphics","augmented reality;computer graphics;stereo image processing","online environment model estimation;augmented reality;annotation;occlusion;online SLAM approach;stereo analysis;real-virtual occlusion","","11","4","17","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"TeachAR: An Interactive Augmented Reality Tool for Teaching Basic English to Non-native Children","C. S. C. Dalim; T. Piumsomboon; A. Dey; M. Billinghurst; S. Sunar","University of South Australia, Adelaide, SA, AU; Empathic Computing Lab, University of South Australia; Empathic Computing Lab, University of South Australia; Empathic Computing Lab, University of South Australia; MaGIC-X UTM-IRDA, Universiti Teknologi Malaysia","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","344","345","TeachAR is an Augmented Reality (AR) tool for teaching English colors, shapes, and spatial relationships to young children aged 4 to 6 years old who are non-native speakers of English. TeachAR utilizes the ARToolkit plugin for the Unity game engine for square marker tracking and game development. The Microsoft Kinect's microphone and speech API is used for isolated word speech recognition, a webcam for image capturing and a desktop monitor for viewing the AR scene. Previous language learning AR applications usually use audio output, however TeachAR uses speech as input for language learning. This paper describes the TeachAR demonstration and user experience with the application.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836534","Augmented Reality;Teaching and Learning;English Language;Children;Non-Native Speakers","Shape;Speech recognition;Color;Speech;Augmented reality;Education;Games","application program interfaces;augmented reality;computer aided instruction;computer games;image capture;linguistics;speech recognition;teaching","interactive augmented reality tool;basic English teaching;nonnative children;TeachAR;AR tool;English colors;English shapes;spatial relationships;young children;nonnative English speakers;ARToolkit plugin;Unity game engine;square marker tracking;game development;Microsoft Kinect microphone;speech API;isolated word speech recognition;webcam;image capturing;desktop monitor;AR scene viewing;language learning","","10","","6","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Using Augmented Reality to Promote Homogeneity in Learning Achievement","J. Zhang; T. -C. Liu; Y. -T. Sung; K. -E. Chang","Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan; Department of Educational Psychology and Counseling, National Taiwan Normal University, Taipei, Taiwan; Department of Educational Psychology and Counseling, National Taiwan Normal University, Taipei, Taiwan; Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan","2015 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design","10 Dec 2015","2015","","","1","5","The issue of individual differences among learners has thus far received the most attention from education researchers. Many teachers strive to develop a learning strategy with significant effect on the majority of learners. Through literature analysis, this study found that not only could Augmented Reality (AR) improve learning effectiveness, it could also reduce the impact of individual differences on learning outcomes. Therefore, this study designed a set of AR-aided teaching systems to help teachers supplement curriculum content using AR. Sixty-six participants from elementary schools were involved in this study. The results confirmed that AR can help learners to achieve better learning outcomes, and can effectively improve learning achievement in non-high-scoring groups, enabling them to perform closer to those in high-scoring groups and reducing the gap in overall learning level. This study also discovered that technological barriers could reduce the benefits of AR in teaching contexts. Authoring tools with low operating thresholds are valuable for AR-aided teaching systems.","","978-1-4673-9628-8","10.1109/ISMAR-MASHD.2015.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350726","Augmented Reality;Computer-assisted instruction;K-12 education","Education;Standards;Augmented reality;Computer crashes;Computers;Correlation;Visualization","augmented reality;authoring systems;computer aided instruction;educational institutions;teaching","augmented reality;learning achievement homogeneity;education researchers;learning strategy;learning effectiveness;learning outcomes;AR-aided teaching systems;curriculum content;elementary schools;nonhigh-scoring groups;authoring tools","","10","","30","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"Music-AR: Augmented Reality in Teaching the Concept of Sound Loudness to Children in Pre-School","L. Gomes; V. F. Martins; D. C. Dias; M. d. P. Guimarães","Universidade Presbiteriana Mackenzie, Sao Paulo, SP, BR; Universidade Presbiteriana Mackenzie, Sao Paulo, SP, BR; Universidade Federal de Sao Carlos, Sao Carlos, SP, BR; NA","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","114","117","Since the mass media and the lack of mandatory music education in Brazilian schools, there was a loss of perception of sound / music of Brazilian children. This fact, coupled with the lack of software for teaching and sound perception, enhances the problem. This paper presents the Music-AR, an augmented reality software for teaching sound properties such as pitch, loudness and volume. This application allows children manipulate virtual objects that are associated with sound, allowing them to learn sound bass and treble. The results of a usability test are presented.","","978-1-4799-4261-9","10.1109/SVR.2014.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913081","Music Education;Musical Perception;Augmented Reality;Serious Games","Software;Augmented reality;Education;Timbre;Visualization;Art","augmented reality;computer aided instruction;music;teaching","Music-AR;augmented reality software;sound loudness concept;teaching;preschool children;mass media;music education;Brazilian children;sound perception;pitch property;loudness property;volume property;virtual objects;usability test","","9","","12","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"Augmented Reality Applied to Health Education","M. A. Galvão; E. R. Zorzal","Instituto de Ciência e Tecnologia, Universidade Federal de São Paulo - UNIFESP, São José dos Campos, Brasil; Instituto de Ciência e Tecnologia, Universidade Federal de São Paulo - UNIFESP, São José dos Campos, Brasil","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","268","271","This short paper proposes the development of three different applications for health education with the aid of Augmented Reality. Some figures of current development prototipes are also show and future works are proposed. We expect these applications will help extend health education to students' homes from all educational stages and expect to minimize some problems related to anatomy education in college, such as costs for obtaining corpses and lack of skilled professionals.","","978-0-7695-5001-5","10.1109/SVR.2013.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655796","augmented reality;mobile devices;kinect;learning;anatomy","Software;Education;Visualization;Internet;Augmented reality;Tablet computers;Dictionaries","augmented reality;biomedical education;computer aided instruction","augmented reality;health education;student homes;educational stages;anatomy education;college;skilled professionals","","8","","17","IEEE","7 Nov 2013","","","IEEE","IEEE Conferences"
"An Augmented Reality Guide for Assisting Forklift Operation","B. Sarupuri; G. A. Lee; M. Billinghurst","The Human Interface Technology Laboratory New Zealand, University of Canterbury; School of Information Technology and Mathematical Sciences, University of South Australia; School of Information Technology and Mathematical Sciences, University of South Australia","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","59","60","Operating forklifts in warehouses is becoming an increasingly difficult task due to higher shelves and narrower aisles. We investigate how Augmented Reality (AR) could aid forklift operators in performing their pallet racking and pick up tasks by superimposing virtual guidelines over a real world camera feed. To test this, we designed and developed a prototype system based on a toy forklift and conducted a user study with it. The results showed that AR cues helped the participants to perform tasks with a higher success rate and provided better usability.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836460","Augmented Reality;Forklift;Warehouse;Logistics","Cameras;Guidelines;Augmented reality;Prototypes;Usability;Feeds;Tracking","augmented reality;warehouse automation","pick up tasks;pallet racking;virtual guidelines;AR;forklift operation;augmented reality guide","","8","","5","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Camera pose navigation using Augmented Reality","J. Shingu; E. Rieffel; D. Kimber; J. Vaughan; P. Qvarfordt; K. Tuite","Fuji Xerox Company Limited, Japan; FX Palo Alto Laboratory, Inc., Japan; FX Palo Alto Laboratory, Inc., Japan; FX Palo Alto Laboratory, Inc., Japan; FX Palo Alto Laboratory, Inc., Japan; University of Washington, USA","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","271","272","We propose an Augmented Reality (AR) system that helps users take a picture from a designated pose, such as the position and camera angle of an earlier photo. Repeat photography is frequently used to observe and document changes in an object. Our system uses AR technology to estimate camera poses in real time. When a user takes a photo, the camera pose is saved as a “view bookmark”. To support a user in taking a repeat photo, two simple graphics are rendered in an AR viewer on the camera's screen to guide the user to this bookmarked view. The system then uses image adjustment techniques to create an image based on the user's repeat photo that is even closer to the original.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643602","Augmented Reality;Repeat Photography;Rephotography;Camera Pose Navigation","Cameras;Navigation;Augmented reality;Photography;Three dimensional displays;Solid modeling","augmented reality;image sensors;pose estimation","camera pose navigation;augmented reality;photography;camera pose estimation;image adjustment technique","","7","1","4","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"TutAR: Semi-Automatic Generation of Augmented Reality Tutorials for Medical Education","D. Eckhoff; C. Sandor; D. Kalkoten; U. Eck; C. Lins; A. Hein","Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Graz University of Technology, Austria; Technical University of Munich, Germany; OFFIS - Institute for Information Technology, Oldenburg, Germany; Carl von Ossietzky University of Oldenburg, Germany","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","430","431","With Augmented Reality (AR) on Optical-See-Through-Head-Mounted Displays (OST-HMD), users can observe the real world and computer graphics at the same time. In this work, we present TutAR, a pipeline that semi-automatically creates AR tutorials out of 2D RGB videos. TutAR extracts relevant 3D hand motion from the input video. The derived motion will be displayed as an animated 3D hand relative to the human body and plays synchronously with the motion in the video on an OST-HMD.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699222","Augmented Reality;Video tutorials;Motion extraction","Three-dimensional displays;Tutorials;Two dimensional displays;Trajectory;Augmented reality;Image reconstruction;Animation","augmented reality;biomedical education;computer animation;medical image processing;video signal processing","TutAR;semiautomatic generation;Augmented Reality tutorials;medical education;Optical-See-Through-Head-Mounted Displays;OST-HMD;computer graphics;2D RGB videos;animated 3D hand;3D hand motion","","6","","6","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"[POSTER] Rubix: Dynamic Spatial Augmented Reality by Extraction of Plane Regions with a RGB-D Camera","M. Sano; K. Matsumoto; B. H. Thomas; H. Saito",Keio University; University of South Australia; University of South Australia; University of South Australia,"2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","148","151","Dynamic spatial augmented reality requires accurate real-time 3D pose information of the physical objects that are to be projected onto. Previous depth-based methods for tracking objects required strong features to enable recognition; making it difficult to estimate an accurate 6DOF pose for physical objects with a small set of recognizable features (such as a non-textured cube). We propose a more accurate method with fewer limitations for the pose estimation of a tangible object that has known planar faces and using depth data from an RGB-D camera only. In this paper, the physical object's shape is limited to cubes of different sizes. We apply this new tracking method to achieve dynamic projections onto these cubes. In our method, 3D points from an RGB-D camera are divided into a cluster of planar regions, and the point cloud inside each face of the object is fitted to an already-known geometric model of a cube. With the 6DOF pose of the physical object, SAR generated imagery is then projected correctly onto the physical object. The 6DOF tracking is designed to support tangible interactions with the physical object. We implemented example interactive applications with one or multiple cubes to show the capability of our method.","","978-1-4673-7660-0","10.1109/ISMAR.2015.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328083","Spatial Augmented Reality;Six Degree of Freedom Tracking;RGB-D Camera","Three-dimensional displays;Cameras;Iterative closest point algorithm;Augmented reality;Real-time systems;Target tracking","augmented reality;cameras;feature extraction;object tracking;pose estimation","Rubix;plane region extraction;dynamic spatial augmented reality;tangible object pose estimation;RGB-D camera;tracking method;point cloud;SAR generated imagery","","6","","9","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"[POSTER] Authoring Tools in Augmented Reality: An Analysis and Classification of Content Design Tools","R. C. Mota; R. A. Roberto; V. Teichrieb","University of Calgary; Voxar Labs, Informatics Center of UFPE; Voxar Labs, Informatics Center of UFPE","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","164","167","Augmented Reality Authoring Tools are important instruments that can help a widespread use of AR. They can be classified as programming or content design tools in which the latter completely removes the necessity of programming skills to develop an AR solution. Several solutions have been developed in the past years, however there are few works aiming to identify patterns and general models for such tools. This work aims to perform a trend analysis on content design tools in order to identify their functionalities regarding AR, authoring paradigms, deployment strategies and general dataflow models. This work is aimed to assist developers willing to create authoring tools, therefore, it focus on the last three aspects. Thus, 19 tools were analyzed and through this evaluation it were identified two authoring paradigms and two deployment strategies. Moreover, from their combination it was possible to elaborate four generic dataflow models in which every tool could be fit into.","","978-1-4673-7660-0","10.1109/ISMAR.2015.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328087","Augmented reality;authoring tools;content design tools","Design tools;Software;Augmented reality;Market research;Analytical models;Libraries","augmented reality;authoring systems;data flow computing","augmented reality authoring tools;content design tools;programming tools;AR;general dataflow models","","6","","23","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Markerless 3D gesture-based interaction for handheld Augmented Reality interfaces","Huidong Bai; Lei Gao; J. El-Sana; M. Billinghurst","HIT Lab NZ, University of Canterbury, Christchurch, New Zealand; HIT Lab NZ, University of Canterbury, Christchurch, New Zealand; The Department of Computer Science, Ben-Gurion University of the Negev, Israel; HIT Lab NZ, University of Canterbury, Christchurch, New Zealand","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","1","6","Conventional 2D touch-based interaction methods for handheld Augmented Reality (AR) cannot provide intuitive 3D interaction due to a lack of natural gesture input with real-time depth information. The goal of this research is to develop a natural interaction technique for manipulating virtual objects in 3D space on handheld AR devices. We present a novel method that is based on identifying the positions and movements of the user's fingertips, and mapping these gestures onto corresponding manipulations of the virtual objects in the AR scene. We conducted a user study to evaluate this method by comparing it with a common touch-based interface under different AR scenarios. The results indicate that although our method takes longer time, it is more natural and enjoyable to use.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671841","3D interaction technique;natural gesture interaction;fingertip detection;handheld augmented reality","Three-dimensional displays;Thumb;Augmented reality;Cameras;Educational institutions;Mobile handsets","augmented reality;gesture recognition","markerless 3D gesture-based interaction;handheld augmented reality interfaces;2D touch-based interaction methods;real-time depth information;natural interaction technique;virtual object manipulation;3D;handheld AR devices;user fingertip position identification;user fingertip movement identification;gesture mapping;touch-based interface","","6","","5","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"[POSTER] Halo3D: A Technique for Visualizing Off-Screen Points of Interest in Mobile Augmented Reality","P. Perea; D. Morand; L. Nigay","Schneider Electric, Carros, France; Schneider Electric, Carros, France; Grenoble INP, CNRS, France","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","170","175","When working with mobile Augmented Reality (AR) applications, users need to be aware of relevant points of interest (POIs) that are located off-screen. These POIs belong to the context since they are not observable in the 3D first-person AR view on screen. The context in mobile AR can include a large number of POIs including locally dense clusters as in mobile AR applications for production plant machine maintenance. Existing solutions display 3D arrows or an area on the edges of the screen to represent the POIs of the context. These techniques display the direction but not the distance of each POI. We present Halo3D, a visualization technique that conveys the 3D direction and distance of off-screen POIs while avoiding overlap and clutter in a high-POI-density AR environment.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088475","Augmented reality;mobility;visualization;off-screen point of interest;Halo","Augmented reality","augmented reality;data visualisation;industrial plants;machinery;maintenance engineering;mobile computing;production engineering computing","Halo3D;3D direction;production plant machine maintenance;mobile AR applications;locally dense clusters;mobile Augmented Reality applications;off-screen points;high-POI-density AR environment;off-screen POIs;visualization technique","","5","","14","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Pre-attentive Features in Natural Augmented Reality Visualizations","C. Barreiros; E. Veas; V. Pammer-Schindler","Graz University of Technology, Knowledge Technologies Institute; Know-Center GmbH; Know-Center GmbH","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","72","73","The movement towards cyberphysical systems and Industry 4.0 promises to imbue each and every stage of production with a myriad of sensors. The open question is how people are to comprehend and interact with data originating from industrial machinery. We propose a metaphor that compares machines with natural beings that appeal to people by representing machine states with patterns occurring in nature. Our approach uses augmented reality (AR) to represent machine states as trees of different shapes and colors (BioAR). We performed a study on pre-attentive processing of visual features in AR to determine if our BioAR metaphor conveys fast changes unambiguously and accurately. Our results indicate that the visual features in our BioAR metaphor are processed pre-attentively. In contrast to previous research, for the BioAR metaphor, variations in form induced less errors than variations in hue in the target detection task.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836464","H.1.2 [Models and Principles]: User/Machine Systems—Human information processing; H.5.1 [HCI]: Multimedia Information Systems—Artificial;augmented;and virtual reality","Vegetation;Augmented reality;Data visualization;Biological system modeling;Visualization;Real-time systems;Production facilities","augmented reality;cyber-physical systems;data visualisation;Internet","target detection task;BioAR metaphor;visual features;industrial machinery;cyberphysical systems;Industry 4.0;natural augmented reality visualizations","","5","","7","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Relationship between features of augmented reality and user memorization","Y. Fujimoto; G. Yamamoto; T. Taketomi; J. Miyazaki; H. Kato",Nara Institute of Science and Technology; Nara Institute of Science and Technology; Nara Institute of Science and Technology; Nara Institute of Science and Technology; Nara Institute of Science and Technology,"2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","279","280","The objective of this study is to investigate the relationship between the features of augmented reality (AR) and human memorization ability. The basis of this relation is derived from the following features. The AR feature is that AR can provide information associated with specific locations in the real world. The feature of human memory is that humans can easily memorize information if the information is visually associated with specific locations. To investigate this relation, we conduct a pilot user study in which blocks are picked from some drawers. As a result, significant differences are found between a situation in which visual information is displayed at the location of each drawer in the real world and that in which textual information is displayed at an unrelated location.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402573","H.1.2 [Models and Principles]: User/Machine Systems—Human factors;H.5.1 [Information Interfaces and Presentation]: User Interfaces—Artificial, augmented and virtual reality","Humans;Visualization;Augmented reality;Accuracy;Assembly;Psychology;Abstracts","augmented reality;data visualisation","augmented reality;user memorization;human memorization ability;AR feature;real world;human memory;visual information;textual information","","5","","7","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Handling Occlusions in Augmented Reality for Mobile Devices","S. R. R. Sanches; V. V. G. Silva; A. C. Sementille; C. G. Corrêa; C. Oliveira","Universidade Tecnologica Federal do Parana, Cornelio Procopio, Brazil; Universidade Tecnologica Federal do Parana, Cornelio Procopio, Brazil; Universidade Estadual Paulista “Julio de Mesquita Filho”, Bauru, Brazil; Universidade Tecnologica Federal do Parana, Cornelio Procopio, Brazil; Universidade Tecnologica Federal do Parana, Cornelio Procopio, Brazil","2019 21st Symposium on Virtual and Augmented Reality (SVR)","5 Dec 2019","2019","","","112","119","The coherent display of the spatial relationship between real and virtual elements is a desirable feature for realistic Augmented Reality (AR) systems. The system must be able to automatically estimate the depths of the real and virtual elements that compose the scene and display in the foreground of the frame the element closest to the camera. In other words, real and virtual elements must hide (totally or partially) each other according to their depths in the frame. This paper presents a method for occlusion treatment of scene elements for mobile applications. The solution presented uses pixel proportions, relative to the total pixels of the frame, occupied by the real and virtual elements to estimate their depths. Then, a skin color model based segmentation method is applied to extract the real element in frames in which it is in the foreground of the scene and, as a result, must overlap the virtual object. The results of the evaluation of the proposed method showed its superiority to those found in the literature when a set of important features are compared.","","978-1-7281-5434-3","10.1109/SVR.2019.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920930","Augmented Reality, Mobile Devices, Handling Occlusion","Three-dimensional displays;Augmented reality;Mobile handsets;Visualization;Solid modeling;Graphics processing units","augmented reality;image colour analysis;image segmentation;medical computing;mobile computing","camera;pixel proportions;mobile applications;scene elements;occlusion treatment;augmented reality systems;spatial relationship;coherent display;mobile devices;virtual object;skin color model based segmentation method;virtual elements","","4","","","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Integrating Peripheral Interaction Into Augmented Reality Applications","O. -A. Schipor; R. -D. Vatavu; W. Wu","MintViz Lab, University Ştefan cel Mare of Suceava, Suceava, Romania; MintViz Lab, University Ştefan cel Mare of Suceava, Suceava, Romania; State Key Lab of Software Development Environment, Beihang University, China","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","358","359","We address in this paper software architecture design to enable peripheral interactions in Augmented Reality applications. To this end, we rely on SAPIENS, a recently introduced software architecture for engineering peripheral interactions in smart environments, which we reuse to our purpose. Our approach can be readily tested using the online simulator available from the SAPIENS home page.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951901","Human centered computing;Human computer interaction;Interaction paradigms;Mixed / augmented reality","Augmented reality;Software architecture;Task analysis;Computer architecture;Smart glasses;Visualization;Software","augmented reality;human computer interaction;software architecture","peripheral interaction;augmented reality;software architecture design;SAPIENS software architecture;smart environments","","4","","14","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Mobile Guide to Augmented Reality for Campus of the Autonomous University of Nayarit","A. Iriarte-Solis; P. González-Villegas; R. Fuentes-Covarrubias; G. Fuentes-Covarrubias",Universidad Autónoma de Nayarit; Universidad Autónoma de Nayarit; Universidad Autónoma de Nayarit; Universidad de Colima,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","1","4","Mobile applications have become very important not only as a mean to disseminate information, but also to serve as guide in unfamiliar contexts. This guide developed with mobile Augmented Reality (AR) aims to give information on the location of points of interest within the UAN campus. The tools used were through markers with Unity3D and Vuforia Software.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836446","localization;augmented reality;murals","Two dimensional displays;Augmented reality","augmented reality;computer aided instruction;educational technology;mobile computing","mobile guide;augmented reality;Autonomous University of Nayarit;mobile applications;UAN;Unity3D;Vuforia Software","","4","","14","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"A Scalable and Long-Term Wearable Augmented Reality System for Order Picking","W. Fang; S. Zheng; Z. Liu","School of Automation, Beijing University of Posts and Telecommunications, Beijing, P.R. China; X-Lab, Beijing Seengene Technology Co., Ltd, Beijing, P.R. China; X-Lab, Beijing Seengene Technology Co., Ltd, Beijing, P.R. China","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","4","7","Order picking is one of the most important tasks in modern warehouses, while augmented reality (AR) is a friendly alternative by conveying manual picking information into visual guidance to improve the picking performance. Nevertheless, there is still a lack of scalable and systematic consensus to deploy the pick-by-AR method associated with actual warehouse workplaces. This article describes a comprehensive methodology for the use of wearable AR in the order picking process. To enable a robust AR assisted manual order picking system in a warehouse floor, the marker-based global map about the actual shelves is established automatically, empowering a scalable, low-cost and long-term tracking capacity for pick-by-AR within the warehouse floor and allowing the operator to move freely in the actual workplace. The system is evaluated in the automobile assembly line, and experimental results illustrate that the proposed work can provide a systematic solution for pick-by-AR applications in actual warehouse fields.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951956","Order picking, augmented reality, global navigation","Augmented reality","assembling;augmented reality;automobile industry;order picking;production engineering computing","long-term tracking capacity;warehouse floor;augmented reality;pick-by-AR method;order picking process;marker-based global map;automobile assembly line","","4","","16","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Augmented Reality for Easy Sailing","F. Laera","Department of Mechanics, Mathematics and Management, Polytechnic University of Bari","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","312","313","Maritime navigation, and specifically sailing, is an activity influenced by many external factors such as weather and sea conditions, the presence of near obstacles, the state of the vessel; these factors determine the complexity of navigation, making it an activity dedicated to expert enthusiasts and professionist. We believe that the use of Augmented Reality in the field of maritime navigation can greatly help experienced navigators and make this activity more accessible even to the less experienced, while still ensuring its safety. The concept of Easy Sailing thus evolves/innovates, thanks to the fundamental instrument of AR used as an amplifier of the human senses, designed to inform the navigator, compensating for his lack of experience.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287823","Augmented Reality;Nautical;Sailing;Easy Sailing;Human Computer Interaction","Visualization;Three-dimensional displays;Navigation;Layout;Data visualization;Wind forecasting;Augmented reality","augmented reality;marine engineering;marine navigation;marine safety","augmented reality;maritime navigation;weather;sea conditions;navigator;safety;easy sailing","","4","","14","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Effect of eye and body movement on augmented reality in the manufacturing domain","J. Sausman; A. Samoylov; S. H. Regli; M. Hopps",Lockheed Martin Advanced Technology Laboratories; Lockheed Martin Advanced Technology Laboratories; Lockheed Martin Advanced Technology Laboratories; Lockheed Martin Aeronautics,"2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","315","316","Understanding the eye and body movements required to perform large vehicle assembly tasks is important for developing a mobile support system for mechanics, and tracking user movements with regard to the surrounding environment is critical for designing a wearable Augmented Reality (AR) systems. This poster summarizes a study measuring the eye and body movements of mechanics performing assembly activities in a live manufacturing environment. It reviews our quantitative analysis of eye movements and qualitative analysis of body movements and describes the implications of this data in terms of the feasibility and potential utility of using a mobile AR application to support manufacturing. We found that the mechanics' eye movements ranged over a slightly larger field than the eye movements reported in previous research because of constraints imposed by some body positions required in manufacturing tasks.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402591","Augmented reality;manufacturing;production;eye tracking;saccadic eye movement;gaze shift;heads-up display;human factors","Augmented reality;Assembly;Mobile communication;Cameras;Tracking;Vehicles","assembling;augmented reality;biomechanics;computer aided manufacturing;eye;manufacturing processes;mobile computing","augmented reality system;manufacturing domain;mobile support system;user movements tracking;live manufacturing environment;body movements qualitative analysis;eye movements quantitative analysis;mobile AR application;eye movements mechanics;manufacturing tasks","","3","","6","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Mobile augmented reality based 3D snapshots","P. Keitler; F. Pankratz; B. Schwerdtfeger; D. Pustka; W. Rodiger; G. Klinker; C. Rauch; A. Chathoth; J. Collomosse; Y. -Z. Song","Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; Vodafone Group Services GmbH; Vodafone Group Research and Development; University of Bath, UK; University of Bath, UK","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","199","200","We describe a mobile augmented reality application that is based on 3D snapshotting using multiple photographs. Optical square markers provide the anchor for reconstructed virtual objects in the scene. A novel approach based on pixel flow highly improves tracking performance. This dual tracking approach also allows for a new single-button user interface metaphor for moving virtual objects in the scene. The development of the AR viewer was accompanied by user studies confirming the chosen approach.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336462","H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities—;H.5.2 [Information Interfaces and Presentation]: User Interfaces;Interaction styles","Augmented reality;Layout;Cameras;Mobile handsets;Tracking;Jitter;Algorithm design and analysis;Image reconstruction;Research and development;Usability","augmented reality;image reconstruction;mobile computing;solid modelling","mobile augmented reality;3D snapshots;multiple photographs;optical square markers;virtual object reconstruction;pixel flow;tracking performance;dual tracking;single-button user interface;AR viewer","","3","","7","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Social semiotic analysis of the design space of augmented reality","B. Cameron; C. Sandor; P. Mickan","Discipline of Linguistics, University of Adelaide, Australia; Magic Vision Lab, University of South Australia, Australia; Discipline of Linguistics, University of Adelaide, Australia","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","105","106","Text is one of the multimodal components used in many augmented reality (AR) applications. Fulfilling the design goals of an application depends, to a large extent, on the successful design of these components. This paper examines the role of text in AR user interfaces from a social semiotic and linguistic perspective. Since analysis of the text in AR applications has mostly focused on aspects such as legibility, placement, occlusion-related issues and exploration of methods to overcome other visual challenges, we suggest that such a social semiotic and linguistic analysis of the textual content can provide insights into user interface and application design for AR researchers and developers. Our analysis suggests that the role of text in AR can differ, and depends, at least in part, on the type of text-image interaction of which it is a part.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093666","Augmented Reality;Social Semiotics;Multimodality;User Interface Design","Augmented reality;Prototypes;Maintenance engineering;Pragmatics;User interfaces;Navigation","augmented reality;text analysis;user interfaces","social semiotic analysis;augmented reality design space;AR user interface;social semiotic perspective;linguistic perspective;textual content;text-image interaction","","3","","10","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"[Poster] Using augmented reality to support information exchange of teams in the security domain","D. Datcu; M. Cidota; H. Lukosch; S. Lukosch","Delft University of Technology, The Netherlands; Technische Universiteit Delft, Delft, Zuid-Holland, NL; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","263","264","For operational units in the security domain that work together in teams it is important to quickly and adequately exchange context-related information. This extended abstract investigates the potential of augmented reality (AR) techniques to facilitate information exchange and situational awareness of teams from the security domain. First, different scenarios from the security domain that have been elicited using an end-user oriented design approach are described. Second, a usability study is briefly presented based on an experiment with experts from operational security units. The results of the study show that the scenarios are well-defined and the AR environment can successfully support information exchange in teams operating in the security domain.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948441","Augmented reality;information exchange;usability","Security;Augmented reality;Usability;Information exchange;Abstracts;Forensics;Three-dimensional displays","augmented reality;security of data;team working","augmented reality;security domain;context-related information exchange;AR techniques;team situational awareness;end-user oriented design approach","","3","","10","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"EyeAR: Refocusable Augmented Reality Content through Eye Measurements","D. C. Rompapas; A. Rovira; S. Ikeda; A. Plopski; T. Taketomi; C. Sandor; H. Kato","Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Mobile Computing Laboratory Ritsumeikan University; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","334","335","The human visual system always focuses at a distinct depth. Therefore, objects that lie at different depths appear blurred, a phenomenon known as Depth of Field (DoF); as the user's focus depth changes, different objects come in and out of focus. Augmented Reality (AR) is a technology that superimposes computer graphics (CG) images onto a user's view of the real world. A commonly used AR display device is an Optical See-Through Head-Mounted Display (OST-HMD), enabling users to observe the real-world directly, with CG added to it. A common problem in such systems is the mismatch between the DoF properties of the user's eyes and the virtual camera used to generate CG.In this demonstration, we present an improved version of the system presented in [11] as two implementations: The first as a high quality tabletop system, the second as a component which has been integrated into the Microsoft Hololens [18].","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836529","Raytracing;Physically Based AR;Augmented Reality;Depth of Field;Optical Defocus","Encyclopedias;Electronic publishing;Internet;Augmented reality;Cameras;Three-dimensional displays","augmented reality;computer graphics;helmet mounted displays","EyeAR;refocusable augmented reality content;eye measurements;human visual system;depth of field;computer graphics images;AR display device;optical see-through head-mounted display;OST-HMD;virtual camera;high quality tabletop system;Microsoft Hololens","","3","","18","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"[Poster] Indirect augmented reality considering real-world illumination change","F. Okura; T. Akaguma; T. Sato; N. Yokoya",Nara Institute of Science and Technology (NAIST); Nara Institute of Science and Technology (NAIST); Nara Institute of Science and Technology (NAIST); Nara Institute of Science and Technology (NAIST),"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","287","288","Indirect augmented reality (IAR) utilizes pre-captured omnidirectional images and offline superimposition of virtual objects for achieving high-quality geometric and photometric registration. Meanwhile, IAR causes inconsistency between the real world and the pre-captured image. This paper describes the first-ever study focusing on the temporal inconsistency issue in IAR. We propose a novel IAR system which reflects real-world illumination change by selecting an appropriate image from a set of images pre-captured under various illumination. Results of a public experiment show that the proposed system can improve the realism in IAR.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948453","H.5.1 [Information Interfaces and Presentation];Multimedia Information Systems — Artificial, augmented, virtual realities","Lighting;Histograms;Mobile communication;Mobile handsets;Clouds;Augmented reality;Databases","augmented reality;image registration;lighting","indirect augmented reality;real-world illumination change;pre-captured omnidirectional image;virtual objects superimposition;geometric registration;photometric registration;IAR system","","3","","4","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"[Poster] Combining multi-touch and device movement in mobile augmented reality manipulations","A. Marzo; B. Bossavit; M. Hachet","public University of Navarre, Pamplona, Spain; public University of Navarre, Pamplona, Spain; INRIA Bordeaux, Talence, France","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","281","282","Three input modalities for manipulation techniques in Mobile Augmented Reality have been compared. The first one employs only multi-touch input. The second modality uses the movements of the device. Finally, the third one is a hybrid approach based on a combination of the two previous modalities. A user evaluation (N=12) on a 6 DOF docking task suggests that combining multi-touch input and device movement offers the best results in terms of task completion time and efficiency. Nonetheless, using solely the device is more intuitive and performs worse only in large rotations. Given that mobile devices are increasingly supporting movement tracking, the presented results encourage the addition of device movement as an input modality.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948450","Mobile Augmented Reality;Manipulation;Multi-touch","Performance evaluation;Thumb;Augmented reality;Mobile communication;Three-dimensional displays;Grasping","augmented reality;mobile computing;user interfaces","multitouch input;device movement input;mobile augmented reality;manipulation techniques;user evaluation;task completion time;mobile devices;movement tracking;input modality","","2","","6","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"An interactive Augmented Reality system for exposure treatment","S. Corbett-Davies; A. Dünser; A. Clark","The Human Interface Technology Laboratory NZ, University of Canterbury, New Zealand; The Human Interface Technology Laboratory NZ, University of Canterbury, New Zealand; The Human Interface Technology Laboratory NZ, University of Canterbury, New Zealand","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","95","96","In this poster we describe an Augmented Reality (AR) system we are developing for exposure treatment. AR has great potential for phobia treatment because virtual fear stimuli can be shown in the real world and the client can see their own body and interact naturally with the stimuli. However, advanced natural interactivity has so far not been fully implemented in AR based exposure therapy systems. The novelty of our approach is based on better integrating the real environment and the user into the system, and in recognising natural user actions as system input. Using the Microsoft Kinect device, we create a model of the therapy environment and the user's body. This information is used in conjunction with a physics simulation engine to create a virtual spider that reacts to the real environment in a realistic manner. The virtual spider can walk up, around, or behind real objects and can be carried, prodded and occluded by the user. We present the most recent prototype of the system and discuss the improvements we continue to make.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483998","Phobia;exposure treatment;augmented reality;depth sensing","Medical treatment;Augmented reality;Solid modeling;Prototypes;Object segmentation;Data mining","augmented reality;medical computing;patient treatment;user interfaces","interactive augmented reality system;exposure treatment;AR system;phobia treatment;exposure therapy systems;Microsoft Kinect device","","2","","5","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Real-Time Hand Model Estimation from Depth Images for Wearable Augmented Reality Glasses","B. Zhou; A. Yu; J. Menke; A. Yang","University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley, Berkeley, CA, USA","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","269","273","This work presents a hand model estimation method designed specifically with augmented reality (AR) glasses and 3D AR interface in mind. The proposed work is capable of estimating the 3D positions of all ten finger from a single depth image. By leveraging a low-dimensional hand model and exploiting hand geometries from an ego-centric view, we build a lightweight algorithm that is accurate, environment agnostic, and runs in real time on mobile hardware. One major consideration in our design for AR is that the user's hand is likely to interact with planar surfaces since they serve as ideal ""touchscreens"". As a result, our method will not fail to detect the hand even when the hand is in physical contact with a surface such as a table, wall, or even another palm. Our experiment shows using the CVAR database that the accuracy with clear background at 98% and with cluttered background at around 85%","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951959","Human-centered computing;human computer interaction (HCI);interaction paradigms;Mixed/augmented reality;computing methologies;artificial intelligence;computer vision;computer vision problems","Three-dimensional displays;Augmented reality;Cameras;Support vector machines;Hardware;Pipelines;Estimation","augmented reality;human computer interaction;palmprint recognition","depth images;wearable augmented reality glasses;hand model estimation method;single depth image;low-dimensional hand model;ego-centric view;real-time hand model estimation;hand geometries;3D AR interface;3D position estimation;mobile hardware;planar surfaces;touch screens;CVAR database","","2","","16","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Exploring Design Strategies for Augmented Reality Learning Experience in Classrooms","P. Sarkar","IDC School of Design, Indian Institute of Technology Bombay","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","314","316","The use of ICT mediums is prevalent in schools nowadays. Augmented Reality (AR) is an emerging technology that can provide fun and learner-centric ways of teaching in classrooms. The objective thus lie in the appropriate translation of the textbook content to support learning through AR using tablets or mobiles in the classroom. In the process, it's also required to define the smooth transition from instructor-mediated to learner-centric design for providing AR as a teaching-aid. The research thus focuses on identifying the design strategies and considerations in the form of a framework that are required to design such AR learning experiences for middle school students in a classroom scenario.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288452","Augmented reality;design strategies;design guidelines;classroom","Education;Medical services;IEEE Fellows;Augmented reality;Information systems","augmented reality;computer aided instruction;educational institutions;mobile learning;teaching","learner centric design;middle school students;teaching aid;mobiles;tablets;ICT mediums;augmented reality learning experience","","2","","13","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"DroneCamo: Modifying Human-Drone Comfort via Augmented Reality","A. Mori; Y. Itoh",Tokyo Institute of Technology; Tokyo Institute of Technology,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","167","168","We present an augmented reality (AR) system for drones to improve people's comfort by camouflaging the appearance of the drones via optical see-through AR visualization. Given the growing social use of autonomous robots such as self-driving vehicles and delivery drones, a comfortable coexistence of human and robot is becoming an increasingly important topic. In this work, we explore how AR technology could improve human-robot comfort. Specifically, we demonstrated an AR system and conducted a user study (N=14) on a proof-of-concept AR system consisting of a HoloLens, OptiTrack, and a toy drone. While showing AR avatars with seemingly positive or negative appearances, we collected both objective and subjective measures of the subjects' comfort. Our results show that subjects were more comfortable when the drone was camouflaged with a positive avatar and less comfortable for the negative avatar.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951985","Computingmethodologies;Computergraphics;Graphics systems and interfaces;Mixed / augmented reality","Drones;Avatars;Augmented reality;Autonomous robots;Visualization;Current measurement","augmented reality;autonomous aerial vehicles;avatars;data visualisation;human factors;human-robot interaction;mobile robots","augmented reality system;autonomous robots;delivery drones;human-robot comfort;AR system;toy drone;negative appearances;positive appearances;human-drone comfort;DroneCamo;optical see-through AR visualization;self-driving vehicles;HoloLens;OptiTrack;AR avatars;positive avatar;negative avatar","","2","","12","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Reproducing Material Appearance of Real Objects Using Mobile Augmented Reality","S. Tsunezaki; R. Nomura; T. Komuro; S. Yamamoto; N. Tsumura",Saitama University; Saitama University; Saitama University; Tokyo Metropolitan College of Industrial Technology; Chiba University,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","196","197","In this paper, we propose a system that can reproduce the material appearance of real objects using mobile augmented reality (AR). Our proposed system allows a user to manipulate a virtual object, whose model is generated from the shape and reflectance of a real object, using the user's own hand. The shape of the real object is reconstructed by integrating depth images of the object, which are captured using an RGB-D camera from different directions. The reflectance of the object is obtained by estimating the parameters of a reflectance model from the reconstructed shape and color images, assuming that a single light source is attached to the camera. We measured the shape and reflectance of some real objects and presented the material appearance of the objects using mobile AR. It was confirmed that users were able to obtain the perception of materials from changes in gloss and burnish of the objects by rotating the objects using their own hand.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699176","Reflectance property;reflectance measurement;object manipulation;mobile display;RGB-D camera;Human-centered computing;Human conputer interaction (HCI);Interaction paradigms;Mixed / augmented reality","Shape;Cameras;Shape measurement;Augmented reality;Image reconstruction;Light sources;Color","augmented reality;image colour analysis;image reconstruction;mobile computing","object reflectance;RGB-D camera;shape reconstruction;depth images;color images;reflectance model;virtual object;mobile augmented reality;reproducing material appearance","","1","1","9","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Volume Rendering: An Analysis based on the HoloLens Augmented Reality Device","L. S. O. Rezende; P. H. M. Sá; M. C. F. Macedo; A. L. Apolinário; I. Winkler; M. A. Moret S. G.","Grad. de Engenharia da Computação, Centro Universitário SENAI CIMATEC, Salvador; Grad. de Engenharia da Computação, Centro Universitário SENAI CIMATEC, Salvador; Dpto. de Ciência da Computação, Universidade Federal da Bahia, Salvador, Brasil; Dpto. de Ciência da Computação, Universidade Federal da Bahia, Salvador, Brasil; Dpto. de Modelagem Computacional, Centro Universitário SENAI CIMATEC, Salvador, Brasil; Dpto. de Modelagem Computacional, Centro Universitário SENAI CIMATEC, Salvador, Brasil","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","35","38","This study aims to analyze the feasibility of the HoloLens Augmented Reality device through the development of a prototype that renders volumetric data in a holographic environment. The prototype was developed with the Unity3D game engine. The results indicate that it is possible to perform the visualization of volumetric data, using classic techniques of Volume Rendering in HoloLens. However, the limitations of the device, mainly in relation to the memory space, restricted the size of the tested models. On this basis, real-time display rates were only achieved for low-resolution models, which points to the possibility of optimizations in the prototype to reduce memory consumption and processing costs.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262664","Augmented Reality;Volumetric Data;HoloLens;Volumetric Rendering","Visualization;Augmented reality;Three-dimensional displays;Rendering (computer graphics);Data visualization;Computational modeling;Prototypes","augmented reality;data visualisation;rendering (computer graphics)","optimization;low-resolution models;memory space;holographic environment;HoloLens augmented reality device;Unity3D game engine;volumetric data;volume rendering","","1","","0","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"Crowd Simulation with Augmented Reality","G. Noronha; G. Batista; L. P. Soares","UniverCidade (Centro Universitário da Cidade do Rio de Janeiro), Núcleo de Projetos e Pesquisa em Aplicações Computacionais; UniverCidade (Centro Universitário da Cidade do Rio de Janeiro), Núcleo de Projetos e Pesquisa em Aplicações Computacionais; Escola de Engenharia Tnsner, Instituto de Ensino o Pesauisa","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","228","231","In situations where crowds are expected, such as big sport events, musical events, among others, the unpredictability of incidents is always present. In order to prevent accidents and tragedies, understanding how crowds behave is crucial. This research project has developed an augmented reality system with agents to simulate crowds in real locations using artificial intelligence, thereby providing a way for scientific study of the behavior of crowds, thus leading to better plan the organization of such events, avoiding critical situations.","","978-0-7695-5001-5","10.1109/SVR.2013.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655786","Augmented Reality;Agents","Visualization;Three-dimensional displays;Augmented reality;Computational modeling;Electronic mail;Artificial intelligence;Solid modeling","accident prevention;augmented reality;behavioural sciences computing;software agents","artificial intelligence;agents;augmented reality system;crowd behaviour;tragedies prevention;accident prevention;incidents unpredictability;musical events;big sport events;crowd simulation","","1","","10","IEEE","7 Nov 2013","","","IEEE","IEEE Conferences"
"Use of Random Dot Pattern for Achieving X-Ray Vision with Stereoscopic Augmented Reality Displays","S. Ghasemi; M. Otsuki; P. Milgram",University of Tsukuba; NA; University of Tsukuba,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","250","251","This paper presents a possible solution to some of the challenges involved with creating a stereoscopic augmented reality ‘X-ray vision‘ display, which enables presentation of computer generated (virtual) objects as if they lie behind a real object surface, while maintaining the ability to effectively perceive any information that might be present on that surface. The method involves overlaying random dot patterns onto a real object surface prior to rendering a virtual object. Results from preliminary experiments have shown that the use of random dot patterns can be effective in contributing to the percept of transparency for the case of flat real surfaces with subtle textures. This suggests that the addition of such patterns may also help in perceiving the correct depth order of virtual objects in such images. Moreover, experimental results indicate that, by controlling the relative dot size and dot density of the patterns, it should be possible also to retain sufficient information about the real surface. Future research should be aimed towards the feasibility and effectiveness of applying this method to more realistic AR conditions.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836507","stereoscopic augmented reality;x-ray vision","Augmented reality;Surface texture;Stereo image processing;Three-dimensional displays;Surface treatment;X-ray imaging;Observers","augmented reality;computer displays;rendering (computer graphics);X-rays","random dot pattern;stereoscopic augmented reality X-ray vision display;computer generated virtual objects;rendering","","1","1","10","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Anon-Emoji: An Optical See-Through Augmented Reality System for Children with Autism Spectrum Disorders to promote Understanding of Facial Expressions and Emotions","R. Sun; H. Haraldsson; Y. Zhao; S. Belongie",Comell Tech; Comell Tech; Comell Tech; Comell Tech,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","448","450","Facial expressions are an important part of human communication. However, children with autism spectrum disorders (ASD) are often suffering from difficulties of understanding non-verbal cues and form appropriate responses. Traditional approaches including labeling formatted photographs of human facial expressions from a third person's perspective could help them learn and improve such skills. Yet such training systems are often in lack of real time feedback. As Optical See-Through (OST) Augmented Reality (AR) headsets possess the advantages of near-eyes display and better depth alignment between virtual renderings and the environment, we decided on an OST AR approach for the system. In this paper, we present a system designed for OST AR headsets that occludes the subject's facial expressions with an emotion-presenting 3D emoji model. We hope this system could help us understand how children with ASD perceive emotions through standard emotion presenting systems and help them enhance their skills of understanding facial expressions.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951905","Augmented-Reality;Optical-see-through;Head-pose-tracking;Autism-spectrum-disorders;Emotion-understanding;Emoji","Rendering (computer graphics);Headphones;Head;Autism;Image color analysis;Augmented reality;Three-dimensional displays","augmented reality;emotion recognition;face recognition;handicapped aids;solid modelling","children with autism spectrum disorders;human communication;children with ASD;human facial expressions;OST AR headsets;anon-emoji;facial emotions;emotion-presentation 3D emoji model;optical see-through augmented reality headsets","","1","","12","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Low-Cost Real-Time Mental Load Adaptation for Augmented Reality Instructions - A Feasibility Study","D. Wolf; T. Wagner; E. Rukzio","Ulm University, Ulm, Germany; Ulm University, Ulm, Germany; Ulm University, Ulm, Germany","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","1","3","Since the introduction of augmented reality (AR) technology, in-situ instructions for manual tasks have been a central use case for a large body of previous work. However, most implementations provide identical sets of instructions to each user disregarding the user's current mental load. This is a major issue since previous work has shown the importance and potential of an adapted instruction fidelity for manual tasks such as playing an instrument. To implement a low-cost mental load adaptation for AR instructions, we evaluated a mobile off-the-shelf electroencephalographic (EEG) device for its suitability and feasibility to measure mental load while wearing a video see-through AR head-mounted display (HMD). In a first user experiment (n=12), data of EEG power band values and proprietary performance metrics of the manufacturer were collected and analysed regarding their validity to estimate the user's mental load. Our results indicate that our setup successfully induced different levels of mental effort. The proprietary performance metrics, however, only partially reflected the participants' current mental effort and require further analysis.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951944","eeg;augmented reality;in situ instructions;user adaptation","Task analysis;Electroencephalography;Resists;Real-time systems;Augmented reality;Human computer interaction","augmented reality;computer aided instruction;electroencephalography;helmet mounted displays;human computer interaction;medical signal processing;neurophysiology","mental effort;proprietary performance metrics;low-cost real-time mental load adaptation;augmented reality instructions;in-situ instructions;manual tasks;central use case;current mental load;adapted instruction fidelity;low-cost mental load adaptation;AR instructions;off-the-shelf electroencephalographic device;user experiment","","1","","12","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Narratives for Post-Traumatic Stress Disorder Treatment","L. Chang; A. Cassinelli; C. Sandor","School of Creative Media, City University of Hong Kong; School of Creative Media, City University of Hong Kong; School of Creative Media, City University of Hong Kong","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","306","309","Globally, it is estimated that up to 1 billion children aged 2-17 years, have experienced physical, sexual, or emotional violence in the past year [1], and 30% of the abused child is likely to develop Post-traumatic stress disorder (PTSD) [2]; 354 million adult war survivors are suffering from PTSD [3]; At where the natural disaster occurred, 70.7% of the survivor will suffer from acute PTSD [4]. PTSD has not only high prevalence but also high lethality, which is accompanied by multiple physical and mental comorbidities as well as strong suicidal tendencies [5]-[7]. This doctoral research aims to contribute to the development of PTSD treatment by investigating the possibility of adopting Augmented Reality (AR) narrative in treating PTSD. This four-year research project consists of three steps. In the first stage of research, we will conduct a comparative study between AR and VR narratives with healthy participants to verify whether AR narratives work better in eliciting the emotional engagement of the participants than VR narratives. In the second stage, we will create a system that integrates AR narratives with prolonged exposure (PE) treatment and experiment it with PTSD patients to verify its treatment efficacy. In the final stage, a semi-automatic and patient-authored AR system is expected to be achieved, through which the patients can design their own exposure environment via voice input. This project will provide valuable experimental samples and scientific analysis for the research of psychotherapy, narrative studies, and AR application.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288433","Augmented Reality;Narrative Exposure;Post-Traumatic Stress Disorder;Prolong Exposure;Patient-authored AR narrative","Three-dimensional displays;Tracking;Virtual environments;Medical services;Stress;Augmented reality;Biomedical imaging","augmented reality;human computer interaction;injuries;medical computing;medical disorders;patient treatment;psychology;serious games (computing)","VR narratives;PTSD patients;post-traumatic stress disorder treatment;physical violence;sexual violence;emotional violence;mental comorbidities;suicidal tendencies;PTSD treatment;adult war survivors;AR narratives;augmented reality narrative;time 2.0 year to 17.0 year","","1","","27","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Augmented Reality for Pack Optimization using Video and Depth Data","M. Lorenz; F. Pfeiffer; P. Klimant","Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology; Institute for Machine Tools and Production Processes, Chemnitz University of Technology","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","21","23","Augmented Reality (AR) can be used in intra-logistics to optimize packing processes towards shipping less unused space by calculating and visualizing efficient pack schemas. This work describes the prototype of such a system using a Kinect v2. Based on the delivered RGB-D stream detection and tracking algorithm applied particle filters, tracks boxes and articles. Further, the tracking approach can check if an article is placed correctly in the box. A qualitative assessment of the prototype in a warehouse revealed that such a system only useful for unexperienced packers.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00021","Ministry of Economic Affairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288441","Augmented Reality;Heuristics;Packing;Warehouse;Particle filter","Industries;Prototypes;Particle filters;Manufacturing;Augmented reality;Optimization;Monitoring","augmented reality;data visualisation;image colour analysis;logistics;object detection;object tracking;particle filtering (numerical methods);production engineering computing;video signal processing;warehousing","augmented reality;pack optimization;depth data;intra-logistics;Kinect v2;tracking algorithm;particle filters;video;packing processes;pack schemas;RGB-D stream detection;warehouse;visualization","","1","","8","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Depth Perception and Action in Wearable Augmented Reality: A Pilot Study","S. Baldassi",Meta Company,"2015 IEEE International Symposium on Mixed and Augmented Reality Workshops","3 Dec 2015","2015","","","12","14","Wearable Augmented Reality (AR) is arguably closing the gaps of interaction of user with computers, and computers with the real world. This generates a strong need to understand the neural, cognitive and perceptual mechanisms leveraged by this technology. Because the most advanced wearable AR technologies support gestural interaction with real content, in our study we exploit the well known dissociation between vision-for-perception and vision-for-action to understand how the user's cognitive systems encode the AR space, to introduce novel methodologies to support UI design in AR, and to provide general guidelines for designing visual and interactive spaces in AR. In two experiments we find a dissociation between visual-only estimates of depth and motor finger-reaching to similar elements, supporting the idea that AR space leverages similar mechanisms as the real world, and can be designed accordingly.","","978-1-4673-8471-1","10.1109/ISMARW.2015.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344748","Mixed/Augmented Reality;Psychophysics;Depth Perception;Gestural Interactions","Visualization;Sensitivity;Three-dimensional displays;Context;Yttrium;Augmented reality;Presses","augmented reality;cognitive systems;gesture recognition;wearable computers","depth perception;wearable augmented reality;AR;user interaction;neural mechanisms;cognitive mechanisms;perceptual mechanisms;gestural interaction;vision-for-perception;vision-for-action;UI design","","1","","5","IEEE","3 Dec 2015","","","IEEE","IEEE Conferences"
"ViCollAR: A Novel System for 3D Data Visualization using Collaborative Augmented Reality","D. Qiu; C. Ow; X. Xia; J. Q. Yeo; J. Xia; M. Y. Hean Low; Z. Wang; A. T. Shoon Chan; F. Y. Guan","InfoComm Technology Cluster, Singapore Institute of Technology, Singapore; InfoComm Technology Cluster, Singapore Institute of Technology, Singapore; School of Computer Science and Engineering, Central South University, China; InfoComm Technology Cluster, Singapore Institute of Technology, Singapore; School of Computer Science and Engineering, Central South University, China; InfoComm Technology Cluster, Singapore Institute of Technology, Singapore; InfoComm Technology Cluster, Singapore Institute of Technology, Singapore; InfoComm Technology Cluster, Singapore Institute of Technology, Singapore; InfoComm Technology Cluster, Singapore Institute of Technology, Singapore","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","907","908","Data visualization refers to the presentation of data in a pictorial or graphical format and it can significantly help users, e.g., decision makers, to see the analytics presented visually, such that they can grasp key concepts or identify new patterns rapidly. Various tools and systems have been developed towards data visualization, but they all suffer from different limitations towards immersive and interactive data visualization. In this paper, we presented our developed system, ViCollAR, which aims to achieve immersive, interactive and collaborative 3D data visualization leveraging Augmented Reality (AR) technologies. ViCollAR allows multiple users to simultaneously and collaboratively view and interact with the visualized data using their bare hands in 3D space, and it allows the users to freely navigate through the real spatial environment during interactions. A prototype has been successfully developed for the targeted system and tested by users.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974241","Augmented Reality;Data Visualization;User Interaction;Immersion","Productivity;Three-dimensional displays;Navigation;Data visualization;Collaboration;Prototypes;Augmented reality","augmented reality;data visualisation;groupware;interactive systems","3D space;AR technologies;collaborative 3D data visualization;collaborative augmented reality;immersive data visualization;interactive data visualization;ViCollAR","","","","5","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"[Poster] Representing degradation of real objects using augmented reality","T. Ogawa; Y. Manabe; N. Yata",Chiba University; Chiba University; Chiba University,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","285","286","Much research in augmented reality (AR) technology attempts to match the textures of virtual objects with real world. However, the textures of real objects must also be rendered consistent with virtual information. This paper proposes a method for representing the degradation of real objects in virtual time. Real-world depth information, used to build three-dimensional models of real objects, is captured by a RGB-D camera. The degradation of real objects is then represented by superimposing the degradation texture onto the real object.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948452","Augmented Reality;RGB-D Camera;Degradation","Degradation;Cameras;Solid modeling;Visualization;Real-time systems;Shape;Augmented reality","augmented reality;image representation","real object degradation representation;augmented reality;AR technology;virtual objects;real-world depth information;three-dimensional model;RGB-D camera;red-green-blue-depth camera","","","1","3","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"ARtisan Bistro: A Cooking Task Environment to Conduct Studies in Augmented Reality","A. Raikwar; L. Plabst; F. R. Ortega","NUILab Colorado State University; HCI Group, University of Würzburg; NUILab Colorado State University","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","909","910","With the increasing popularity of Augmented Reality (AR) and newer emerging technologies for normal consumers there is an in-creasing need to research AR applications in more general everyday settings. ARtisan Bistro is an attempt to create a base layer environment that other researchers can build on. Our effort is to save researchers the time of developing an environment from scratch and focus more on the core part of their research.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00200","NSF(grant numbers:1948254,2037417,2016714,2106590); ONR(grant numbers:N00014-21-1-2580,00014-21-1-2949N); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974263","Human-centered computing-Human computer interaction (HCI)-Interaction paradigms -Mixed / augmented reality;Human-centered computing- Visualization-Visualization design and evaluation methods","Visualization;Design methodology;Task analysis;Augmented reality","augmented reality;catering industry;computer games","ARtisan Bistro;augmented reality;base layer environment;cooking task environment;emerging technologies","","","","4","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Painterly rendering with coherence for augmented reality","J. Chen; G. Turk; B. MacIntyre","Georgia Institute of Technology, USA; Georgia Institute of Technology, USA; Georgia Institute of Technology, USA","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","217","218","A seamless blending of the real and virtual worlds is key to increased immersion and improved user experiences for augmented reality (AR). Photorealistic and non-photorealistic rendering (NPR) are two ways to achieve this goal. Non-photorealistic rendering creates an abstract version of both the real and virtual world by stylization to make them indistinguishable. We presented a painterly rendering algorithm for AR applications. This algorithm paints composed AR video frames with bump-mapping curly brushstrokes. Tensor fields are created for each frame to define direction for brushstrokes. The anchor point of a brushstroke is tracked or warped from frame to frame. Brushstrokes are also reshaped to provide better temporal coherence. The major difference between our algorithm and existing NPR work in general graphics and AR/VR areas is we use feature points across composed AR video frames to maintain coherence in the rendering.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643575","Non-photorealistic rendering;augmented reality;painterly rendering;temporal coherence","Rendering (computer graphics);Coherence;Tensile stress;Augmented reality;Pixel;Streaming media;Paints","augmented reality;rendering (computer graphics);video signal processing","painterly rendering;augmented reality;nonphotorealistic rendering;abstract version;virtual world;AR video frame;bump mapping;brushstroke;temporal coherence;feature point","","","","16","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"KITE: Platform for mobile Augmented Reality gaming and interaction using magnetic tracking and depth sensing","T. Piumsomboon; A. Clark; M. Billinghurst","University of Canterbury, Christchurch, NZ; HIT Lab NZ, University of Canterbury, Christchurch, New Zealand; HIT Lab NZ, University of Canterbury, Christchurch, New Zealand","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","289","290","In this paper, we describe the KITE, a mobile Augmented Reality (AR) platform that uses a magnetic tracker and a depth sensor for games and interaction development that is typically only available on a desktop system. We have achieved this using off-the-shelf hardware and efficient software that can be easily assembled and executed. We demonstrate four possible modalities based on hand input to provide a platform that game and interaction designers can use to explore new possibilities for gaming in AR.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671809","Augmented reality;gaming platform;magnetic tracking;depth sensing","Hardware;Games;Cameras;Mobile communication;Augmented reality;Software;Transmitters","augmented reality;computer games;mobile computing","KITE;mobile augmented reality gaming;interaction development;magnetic tracking;depth sensing;AR platform;magnetic tracker;depth sensor;desktop system","","","","2","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"[POSTER] Consistency between Reflection on the Glass and Virtual Object in Augmented Reality","N. Shinozuka; Y. Manabe; N. Yata",Chiba University; Chiba University; Chiba University,"2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","162","165","Augmented Reality (AR) technology is often used for arrangement simulation such as furniture before purchasing. This study focuses on the simulation of product layout in stores and exhibits in museums with show-window. Displaying the virtual information with correct position against real objects is important for realistic experience in AR applications. In this study, we keep the consistency between reflection on the glass and virtual object. Consequently, we extract the reflections on the glass using stereo images according to disparity, and represent it on the superimposed CG object in real-time. Experimental result shows the appearance of the CG object compared with that of the real object in show-window.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088472","Augmented Reality;Stereo Camera;Arrangement Simulation;Show-window;Reflection Removing","Reflection;Cameras;Handheld computers;Augmented reality;Human computer interaction;Visualization","augmented reality;stereo image processing","virtual object;product layout;virtual information;augmented reality technology","","","","10","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"An Empirical Study of Size Discrimination in Augmented Reality","L. Wang; C. Sandor","School of Creative Media, City University of Hong Kong; School of Creative Media, City University of Hong Kong","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","384","386","Existing psychophysical experiments show that size perception can influence the human identification of object properties (e.g., shape or weight) in augmented reality (AR). Some recent studies have revealed the detection threshold of object size in real physical objects. However, the users’ absolute detection threshold of object size augmentation is not clear, which limits the further evaluation of AR design. In this paper, we present two two-alternative forced-choice-based experiments on size perception of virtual objects in AR to explore the detection threshold of size difference in object augmentation. Our experimental results demonstrate that the user’s point of subjective equality (PSE) is 4.00%, and the size difference could be easily detected when the virtual object is larger than 5.18%.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585787","Augmented Reality;Size discrimination","Shape;Haptic interfaces;Object recognition;Augmented reality","augmented reality;object detection;visual perception","size discrimination;augmented reality;psychophysical experiments;human identification;object properties;object size augmentation;two-alternative forced-choice-based experiments;virtual object;object augmentation;real physical objects;users' absolute detection threshold;AR design;users point of subjective equality","","","","12","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"[POSTER] Manipulating Haptic Shape Perception by Visual Surface Deformation and Finger Displacement in Spatial Augmented Reality","T. Kanamori; D. Iwai; K. Sato","Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","190","191","Many researchers are trying to realize a pseudo-haptic system which can visually manipulate a user's haptic shape perception when touching a physical object. In this paper, we focus on manipulating the perceived surface shape of a curved object when touching it with an index finger, by visually deforming it's surface shape and displacing the visual representation of the user's index finger as like s/he is touching the deformed surface, using spatial augmented reality. Experiments were conducted with a projection system to confirm the effect of the visual feedback for manipulating the perceived shape of curved surface. The results supported the proposed concept.","","978-1-4673-7660-0","10.1109/ISMAR.2015.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328099","Spatial augmented reality;pseudo-haptics;shape perception","Shape;Haptic interfaces;Visualization;Augmented reality;Indexes;Electronic mail;Cameras","augmented reality;haptic interfaces;human computer interaction","haptic shape perception;visual surface deformation;finger displacement;spatial augmented reality;visual feedback","","","","4","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Reproducing Material Appearance of Real Objects Using Mobile Augmented Reality","S. Tsunezaki; R. Nomura; T. Komuro; S. Yamamoto; N. Tsumura",Saitama University; Saitama University; Saitama University; Tokyo Metropolitan College of Industrial Technology; Chiba University,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","421","422","In this paper, we propose a system that can reproduce the material appearance of real objects using mobile augmented reality (AR). Our proposed system allows a user to manipulate a virtual object, whose model is generated from the shape and reflectance of a real object, using the user's own hand. The shape of the real object is reconstructed by integrating depth images of the object, which are captured using an RGB-D camera from different directions. The reflectance of the object is obtained by estimating the parameters of a reflectance model from the reconstructed shape and color images, assuming that a single light source is attached to the camera. We measured the shape and reflectance of some real objects and presented the material appearance of the objects using mobile AR. It was confirmed that users were able to obtain the perception of materials from changes in gloss and burnish of the objects by rotating the objects using their own hand.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699239","reflectance property;reflectance measurement;object manipulation;mobile display;RGB-D camera;Human-centered computing—Human conputer interaction (HCI)—Interaction paradigms—Mixed / augmented reality","Shape;Cameras;Augmented reality;Image reconstruction;Light sources;Shape measurement;Color","augmented reality;cameras;image colour analysis;image reconstruction;mobile computing","reproducing material appearance;mobile augmented reality;virtual object;integrating depth images;reflectance model;reconstructed shape;color images;RGB-D camera;AR","","","","9","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"An Information Architecture for Augmented Reality Browsers","J. Oliveira; L. Botega; R. Chiaramonte","Computing and Information Systems Research Lab, Centro Universitário Eurípides de Marília, Mirante, Marília - SP, Brasil; Computing and Information Systems Research Lab, Centro Universitário Eurípides de Marília, Mirante, Marília - SP, Brasil; Computing and Information Systems Research Lab, Centro Universitário Eurípides de Marília, Mirante, Marília - SP, Brasil","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","102","105","The evolution of the several sensors embedded in mobile devices and the massive availability of information indexed on the Internet has provided a bright environment for the development of innovative applications of Augmented Reality (AR ) in areas such as geolocation and navigation. In this scenario with several sources of information, the obtaining of relevant and timely information has become primordial to ensure the effectiveness of mobile solutions that help the user to locate and identify points of interest (POI ) on demand. Thus, this paper presents a layered architecture for the structural organization of information consumed by mobile navigation applications, providing a personalized on-demand by user about what information on points of interest should be displayed in the AR application interface. The layers are presented and their performance in a situation of POI search is discussed in details. Finally, it is presented the result of a quantitative analysis performed with users in order to verify the applicability of the architecture.","","978-1-4799-4261-9","10.1109/SVR.2014.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913078","Augmented Reality Browser;Architecture;Point of Interest","Visualization;Augmented reality;Google;Mobile communication;Browsers;Internet;Geology","augmented reality;mobile computing;online front-ends;software architecture","information architecture;augmented reality browsers;information structural organization;mobile navigation applications;AR application interface;POI search;points of interest search;quantitative analysis;layered architecture","","","","12","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality","C. Bichlmeier; F. Wimmer; S. M. Heining; N. Navab","Computer Aided Medical Procedures & Augmented Reality(CAMP), TUM, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality(CAMP), TUM, Munich, Germany; Trauma Surgery Department, Klinikum Innenstadt, LMU, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality(CAMP), TUM, Munich, Germany","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","129","138","The need to improve medical diagnosis and reduce invasive surgery is dependent upon seeing into a living human system. The use of diverse types of medical imaging and endoscopic instruments has provided significant breakthroughs, but not without limiting the surgeon's natural, intuitive and direct 3D perception into the human body. This paper presents a method for the use of augmented reality (AR) for the convergence of improved perception of 3D medical imaging data (mimesis) in context to the patient's own anatomy (in-situ) incorporating the physician's intuitive multi- sensory interaction and integrating direct manipulation with endoscopic instruments. Transparency of the video images recorded by the color cameras of a video see-through, stereoscopic head- mounted-display (HMD) is adjusted according to the position and line of sight of the observer, the shape of the patient's skin and the location of the instrument. The modified video image of the real scene is then blended with the previously rendered virtual anatomy. The effectiveness has been demonstrated in a series of experiments at the Chirurgische Klinik in Munich, Germany with cadaver and in-vivo studies. The results can be applied for designing medical AR training and educational applications.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538837","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;augmented;and virtual realities;H.5.2 [Information Interfaces and Presentation]: User Interfaces-Interaction styles;I.3.6 [Computer Graphics]: Methodology and Techniques-Interaction techniques;J.3 [Life and Medical Sciences]","Visualization;Augmented reality;Biomedical imaging;Instruments;Medical diagnostic imaging;Humans;Anatomy;Medical diagnosis;Surgery;Surges","augmented reality;computer vision;data visualisation;endoscopes;helmet mounted displays;medical diagnostic computing;medical image processing;video signal processing","contextual anatomic mimesis hybrid in-situ visualization method;multi-sensory depth perception;medical augmented reality;medical diagnosis;invasive surgery;medical imaging;endoscopic instruments;3D medical imaging data;stereoscopic head- mounted-display","","116","23","27","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"An Explanatory Windshield Display Interface with Augmented Reality Elements for Urban Autonomous Driving","P. Lindemann; T. -Y. Lee; G. Rigoll","Chair of Human-Machine-Communication, Technical University of Munich; Chair of Human-Machine-Communication, Technical University of Munich; Chair of Human-Machine-Communication, Technical University of Munich","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","36","37","One of the challenges in reaching wide-spread autonomous driving is the establishment of driver trust in the technology. We suggest a windshield display interface showing the perceptive abilities and decision-making of an automated car while driving. We took a human-centered design approach to determine user expectations and requirements. We present our resulting interface prototype which runs in a mixed-reality environment. We plan to evaluate its impact on situation awareness and trust in hard-to-predict urban scenarios.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699300","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality;Human-centered computing—Interaction design","Meteorology;Automobiles;Hazards;Prototypes;Automation;Augmented reality","augmented reality;automobiles;decision making;driver information systems;road vehicles;user centred design;user interfaces","human-centered design;user requirements;windshield display interface;mixed-reality environment;user expectations;automated car;decision-making;driver trust;urban autonomous driving;augmented reality elements","","4","","1","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"A wearable augmented reality system for navigation using positioning infrastructures and a pedometer","R. Tenmoku; M. Kanbara; N. Yokoya","Nara Institute of Science and Technology, Nara, Japan; Nara Institute of Science and Technology, Nara, Japan; Nara Institute of Science and Technology, Nara, Japan","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","344","345","This paper describes a wearable augmented reality system using positioning infrastructures and a pedometer. To realize augmented reality systems, the position and orientation of user's viewpoint should be obtained in real time. The proposed system measures the orientation of user's viewpoint by an inertial sensor and the user's position using positioning infrastructures in environments and a pedometer. The system specifies the user's position using the position ID received from RFID tags or IrDA markers which are the components of positioning infrastructures. When the user goes away from them, the user's position is alternatively estimated by using a pedometer. We have developed a navigation system using the proposed techniques and have proven the feasibility of the system with experiments.","","0-7695-2006-5","10.1109/ISMAR.2003.1240752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240752","","Augmented reality;Navigation;Wearable sensors;Sensor systems;Wearable computers;Layout;Computer displays;Position measurement;Hardware;Image databases","augmented reality;wearable computers;navigation;image sensors;position measurement","wearable augmented reality;augmented reality system;navigation;positioning infrastructures;pedometer;user viewpoint;real time;inertial sensor;user position;position ID;RFID tags;IrDA markers","","13","2","3","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Diminished Reality as Challenging Issue in Mixed and Augmented Reality (IWDR2015) Summary","H. Tamura; H. Saito; F. Shibata; Y. Kameda",Ritsumeikan University; Ritsumeikan University; Ritsumeikan University; Ritsumeikan University,"2015 IEEE International Symposium on Mixed and Augmented Reality Workshops","3 Dec 2015","2015","","","25","25","Diminished Reality (DR) has been considered as a sub-technology of Mixed and Augmented Reality (MR/AR). While MR/AR means technologies that add and/or overlay visual information onto images of real scene for providing users to enhance their visual experiences with the added/overlaid information, DR aims the similar enhanced visual experiences by deleting visual information from the images of real scene. Adding and deleting visual information might be considered as same technical issues, but they are actually totally different. In DR, visual information that is hidden by the deleted object should be recovered for filling into the deleted area. This recovery of the hidden area is not required for general adding/overlaying based MR/AR, but should be one of the typical issues for achieving DR. Camera pose estimation and tracking is a typical issue in MR/AR, but the condition of the scene and required performance for DR are not always the same as MR/AR. For example, the object to be diminished/removed should be detected and tracked while the camera is freely moving for DR.In this workshop, 7 papers related to various aspect on DR, such as technical issues for DR, examples of applications of DR, expected futures with DR, and human factors of DR.  After review by the program committees, we are happy to accept all 7 papers because of high evaluation scores for all 7 papers.","","978-1-4673-8471-1","10.1109/ISMARW.2015.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344752","","Visualization;Augmented reality;Conferences;Cameras;Electrical engineering","augmented reality","diminished reality;mixed reality;augmented reality;MR/AR;visual information;real scene image;visual experiences;camera pose estimation;object tracking;object detection;human factors","","","","","IEEE","3 Dec 2015","","","IEEE","IEEE Conferences"
"Prototype of Force Feedback Tool for Mixed Reality Applications","I. Gonsher; Z. Lei",Brown University; Rhode Island School of Design,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","508","509","This prototype demonstrates the viability of manipulating both physical and virtual objects with the same tool in order to maintain object permanence across both modes of interaction. Using oppositional force feedback, provided by a servo, and an augmented visual interface, provided by the user’s smartphone, this tool simulates the look and feel of a physical object within an augmented environment. Additionally, the tool is also able to manipulate physical objects that are not part of the augmented reality, such as a physical nut. By integrating both modes of interaction into the same tool, users can fluidly move between these different modes of interaction, manipulating both physical and virtual objects as the need arises. By overlaying this kind of visual and haptic augmentation onto a common tool such as a pair of pliers, we hope to further explore scenarios for collaborative telepresence in future work.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585868","Mixed Reality;Haptic Feedback;Virtual Reality;Augmented Reality","Visualization;Telepresence;Force feedback;Prototypes;Mixed reality;Tools;Fasteners","augmented reality;force feedback;haptic interfaces;virtual reality","force feedback tool;mixed reality applications;physical objects;virtual objects;object permanence;oppositional force feedback;augmented visual interface;user;physical object;augmented environment;augmented reality;physical nut;visual augmentation;haptic augmentation;common tool","","1","","8","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Content first - A concept for industrial augmented reality maintenance applications using mobile devices","T. Engelke; J. Keil; P. Rojtberg; F. Wientapper; S. Webel; U. Bockholt","Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","251","252","Although AR has a long history in the area of maintenance and service-support in industry, there still is a lack of lightweight, yet practical solutions for handheld AR systems in everyday workflows. Attempts to support complex maintenance tasks with AR still miss reliable tracking techniques, simple ways to be integrated into existing maintenance environments, and practical authoring solutions, which minimize costs for specialized content generation. We present a general, customisable application framework, allowing to employ AR and VR techniques in order to support technicians in their daily tasks. In contrast to other systems, we do not aim to replace existing support systems such as traditional manuals. Instead we integrate well-known AR- and novel presentation techniques with existing instruction media. To this end practical authoring solutions are crucial and hence we present an application development system based on web-standards such as HTML,CSS and X3D.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671790","","Three-dimensional displays;Maintenance engineering;Solid modeling;Augmented reality;Context;Media;Documentation","augmented reality;maintenance engineering;mobile handsets","X3D;CSS;HTML;Web standards;application development system;VR techniques;customisable application framework;specialized content generation;maintenance environments;tracking techniques;complex maintenance tasks;handheld AR systems;service support;mobile devices;industrial augmented reality maintenance applications","","16","","6","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"MoleARlert - an augmented reality game based on Lemmings","S. Engelhardt; A. Langs; G. Lochmann; I. Schmidt; S. Muller","University of Koblenz, Germany; University of Koblenz, Germany; University of Koblenz, Germany; University of Koblenz, Germany; University of Koblenz, Germany","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","183","184","In this poster, we present our outdoor AR game MoleARlert. The idea behind this research prototype was to exploit the enormous potential of AR in combination with classical game play based on the well-known game Lemmings by Psygnosis. Real players interact with virtual moles on a real playing field. The moles are guided through the hazardous environment to their final goal. The multiplayer game is observed through a stationary video see-through monitor. The team leader directs the real players around the field in order for them to steer the game with special markers and human gestures. Thus, the game requires a lot of action from players and is very entertaining.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336473","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems;Artificial, augmented, and virtual realities; K.8.0 [Personal Computing]: General;Games","Augmented reality;Games;Tiles;Humans;Hazards;Cameras;Prototypes;Multimedia systems;Multimedia computing;Virtual reality","augmented reality;computer displays;computer games;gesture recognition","MoleARlert;augmented reality game;Lemmings;Psygnosis;virtual moles;real playing field;multiplayer game;human gestures;video see-through monitor;special markers","","","","5","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"A Context-Aware Technical Information Manager for Presentation in Augmented Reality","M. Gattullo; V. Dalena; A. Evangelista; A. E. Uva; M. Fiorentino; A. Boccaccio; M. Ruta; J. L. Gabbard","Department of Mechanics, Mathematics and Management Polytechnic Institute of Bari; Department of Mechanics, Mathematics and Management Polytechnic Institute of Bari; Department of Mechanics, Mathematics and Management Polytechnic Institute of Bari; Department of Mechanics, Mathematics and Management Polytechnic Institute of Bari; Department of Mechanics, Mathematics and Management Polytechnic Institute of Bari; Department of Mechanics, Mathematics and Management Polytechnic Institute of Bari; Department of Electrical and Information, Engineering Polytechnic Institute of Bari; Virginia Polytechnic Institute and State University, Blacksburg, VA, US","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","939","940","Technical information presentation is evolving from static contents presented on paper or via digital publishing to real-time context-aware contents displayed via virtual and augmented reality devices. We present a Context-Aware Technical Information Management system (CATIM), that dynamically manages (1) what information as well as (2) how information is presented in an augmented reality interface. CATIM acquires context data about activity, operator, and environment, and then based on these data, proposes a dynamic augmented reality output tailored to the current context. The system was successfully implemented and preliminarily evaluated in a case study regarding the maintenance of a hydraulic valve.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798262","Industrial Augmented Reality;Technical Information Manager;Context-aware information;Augmented Reality;Context Aware;Visualization","Augmented reality;User interfaces;Task analysis;Mathematics;Maintenance engineering;Ontologies;Layout","augmented reality;information management;ubiquitous computing","digital publishing;real-time context-aware contents;CATIM;augmented reality interface;context data;dynamic augmented reality output;Technical information presentation;static contents;context-aware technical information manager;context-aware technical information management system;hydraulic valve","","3","","9","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Mobile web augmented reality in 5G and beyond: Challenges, opportunities, and future directions","X. Qiao; P. Ren; G. Nan; L. Liu; S. Dustdar; J. Chen","Beijing University of Posts and Telecommunications, Beijing, Beijing, CN; Beijing University of Posts and Telecommunications, Beijing, Beijing, CN; Beijing University of Posts and Telecommunications, Beijing, Beijing, CN; Georgia Institute of Technology, Atlanta, GA, US; Technische Universitat Wien, Wien, Wien, AT; Beijing University of Posts and Telecommunications, Beijing, Beijing, CN","China Communications","27 Sep 2019","2019","16","9","141","154","The popularity of wearable devices and smartphones has fueled the development of Mobile Augmented Reality (MAR), which provides immersive experiences over the real world using techniques, such as computer vision and deep learning. However, the hardware-specific MAR is costly and heavy, and the App-based MAR requires an additional download and installation and it also lacks cross-platform ability. These limitations hamper the pervasive promotion of MAR. This paper argues that mobile Web AR (MWAR) holds the potential to become a practical and pervasive solution that can effectively scale to millions of end-users because MWAR can be developed as a lightweight, cross-platform, and low-cost solution for end-to-end delivery of MAR. The main challenges for making MWAR a reality lie in the low efficiency for dense computing in Web browsers, a large delay for real-time interactions over mobile networks, and the lack of standardization. The good news is that the newly emerging 5G and Beyond 5G (B5G) cellular networks can mitigate these issues to some extent via techniques such as network slicing, device-to-device communication, and mobile edge computing. In this paper, we first give an overview of the challenges and opportunities of MWAR in the 5G era. Then we describe our design and development of a generic service-oriented framework (called MWAR5) to provide a scalable, flexible, and easy to deploy MWAR solution. We evaluate the performance of our MWAR5 system in an actually deployed 5G trial network under the collaborative configurations, which shows encouraging results. Moreover, we also share the experiences and insights from our development and deployment, including some exciting future directions of MWAR over 5G and B5G networks.","1673-5447","","10.23919/JCC.2019.09.010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851462","5G;edge computing;augmented reality;mobile augmented reality;Web augmented reality","5G mobile communication;Browsers;Cloud computing;Task analysis;Augmented reality;Edge computing;Smart phones","5G mobile communication;augmented reality;groupware;Internet;mobile computing;smart phones","mobile Web AR;low-cost solution;dense computing;Web browsers;mobile networks;device-to-device communication;mobile edge computing;MWAR5 system;wearable devices;computer vision;hardware-specific MAR;cross-platform ability;B5G networks;mobile augmented reality;mobile Web augmented reality;5G trial network;app-based MAR;collaborative configurations","","37","","","","27 Sep 2019","","","IEEE","IEEE Magazines"
"A Quick Algorithm for Snapping 3D Objects in Augmented Reality","T. V. Do; J. -W. Lee","Game Interface Research Center, Sejong University, Seoul, South Korea; Mixed Reality & Interaction Laboratory, Sejong University, Seoul, South Korea","2009 International Symposium on Ubiquitous Virtual Reality","4 Sep 2009","2009","","","61","63","This paper describes a quick algorithm for snapping a moving object (being moved by a user) to existing objects in Augmented Reality (AR) environment. Because in AR, human-computer interactions are in the real time mode, the algorithm should be fast enough not to affect the scene rendering but still assure accuracy. It is currently designed to deal with primitive geometries such as cubes, cones, cylinders, spheres. And it should work well even after these geometries are transformed with scaling, rotating, moving operations. The main idea of the algorithm is that for each kind of geometry, some ldquohot spotsrdquo are defined. Each hot spot is a sphere with a certain radius. If the center point of the moving object is within a hot spot of any existing geometry it will be snapped to this geometry at that hot spot. This algorithm is already employed in an AR modeling system to evaluate its efficiency.","","978-1-4244-4437-3","10.1109/ISUVR.2009.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232256","3D snapping;Hot spot;Real time Algorithm;Augmented Reality","Augmented reality;Geometry;Virtual reality;Layout;Real time systems;Laboratories;Object detection;Solid modeling;Cameras;Computer displays","augmented reality;computational geometry;human computer interaction;rendering (computer graphics);solid modelling","quick algorithm;3D object snapping;augmented reality;human-computer interaction;real time mode;scene rendering;primitive geometry;hot spot","","","","11","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"Using augmented reality to improve dismounted operators' situation awareness","W. L. Brandão; M. S. Pinho","Virtual Reality Group - Computer Science School - PUCRS, Brazil; Virtual Reality Group - Computer Science School - PUCRS, Brazil","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","297","298","Whether it in the military, law enforcement or private security, dismounted operators tend to deal with a large amount of volatile information that may or may not be relevant according to a variety of factors. In this paper we draft some ideas on the building blocks of an augmented reality system aimed to improve the situational awareness of dismounted operators by filtering, organizing, and displaying this information in a way that reduces the strain over the operator.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892294","Situation Awareness;Augmented Reality","Augmented reality;Navigation;Machine vision;Time measurement;Position measurement;Hardware","augmented reality","augmented reality;dismounted operator situation awareness;volatile information","","5","","10","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"User evaluation of see-through vision for mobile outdoor augmented reality","B. Avery; B. H. Thomas; W. Piekarski","Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","69","72","We have developed a system built on our mobile AR platform that provides users with see-through vision, allowing visualization of occluded objects textured with real-time video information. We present a user study that evaluates the userpsilas ability to view this information and understand the appearance of an outdoor area occluded by a building while using a mobile AR computer. This understanding was compared against a second group of users who watched video footage of the same outdoor area on a regular computer monitor. The comparison found an increased accuracy in locating specific points from the scene for the outdoor AR participants. The outdoor participants also displayed more accurate results, and showed better speed improvement than the indoor group when viewing more than one video simultaneously.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637327","Outdoor Augmented Reality;Wearable Computers;Telepresence;Image-based Rendering;Occlusion;I.3.6 [Computer Graphics]: Methodology and Techniques — Interaction Techniques;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism — Virtual Reality","Augmented reality;Visualization;Accuracy;Streaming media;Cameras;Three dimensional displays;Buildings","augmented reality;computer vision;data visualisation;mobile computing;video signal processing","user evaluation;see-through vision;mobile outdoor augmented reality;object visualization;occluded object;real-time video information","","24","1","12","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"[Poster] Motion detection based ghosted views for occlusion handling in augmented reality","A. Padilha; V. Teichrieb","Voxar Labs, Federal University of Pernambuco; Voxar Labs, Federal University of Pernambuco","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","291","292","This work presents an improvement to the scene analysis pipeline of a visualization technique called Ghosting. Computer vision and image processing techniques are used to extract natural features, from each video frame. These features will guide the assignment of transparency to pixels, in order to give the ghosting effect, while blending the virtual object into the real scene. Video sequences were obtained from traditional RGB cameras. The main contribution of this work is the inclusion of a motion detection technique to the scene feature analysis step. This procedure leads to a better perception of the augmented scene because the proper ghosting effect is achieved when a moving natural salient object, that catches users attention, passes in front of an augmented one.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948455","H.5.1 [Information Interfaces and Presentation Systems]: Multimedia Information Systems — Artificial, augmented, virtual realities;I.4.8 [Image Processing and Computer Vision]: Scene Analysis — Depth cues","Motion detection;Augmented reality;Visualization;Pipelines;Image analysis;Computer vision;Feature extraction","augmented reality;computer vision;feature extraction;image motion analysis;image sequences;object detection;video signal processing","motion detection based ghosted view;occlusion handling;augmented reality;scene analysis pipeline;visualization technique;ghosting technique;computer vision;image processing techniques;feature extraction;video sequences;scene feature analysis;moving natural salient object","","3","","9","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Third person perspective augmented reality for high accuracy applications","S. Côté; P. Trudel","Bentley Systems, Inc., Québec, QC, Canada; Dept. Electrical & Computer Engineering, Sherbrooke University, Sherbrooke, QC, Canada","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","247","248","We proposed a 6 degrees of freedom augmentation system aimed at meeting the high accuracy requirements of engineering tasks. A stationary panoramic video camera captures a stream that is augmented by a portable computer. A handheld tablet device located in the same area broadcasts its instantaneous orientation, and receives the augmented view in the corresponding orientation, in real time. The panoramic camera can also be moved to other locations and simultaneously tracked by the system, providing 6 degrees of freedom augmentation. This gives the user a third person perspective augmentation, which is very precise and potentially more accurate than handheld augmentation.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671788","Augmented reality;third person perspective;accuracy;3D model;engineering","Cameras;Solid modeling;Augmented reality;Accuracy;Portable computers;Tracking;Design automation","augmented reality;tracking","third person perspective augmented reality;6 degrees of freedom augmentation system;engineering tasks;stationary panoramic video camera;portable computer;handheld tablet device;panoramic camera","","1","","7","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Scene augmentation via the fusion of industrial drawings and uncalibrated images with a view to marker-less calibration","N. Navab; B. Bascle; M. Appel; E. Cubillo","Industrial Augmented Reality Group, Imaging & Visualization Department, Siemens Corporate Research, Inc., Princeton, NJ, USA; Industrial Augmented Reality Group, Imaging & Visualization Department, Siemens Corporate Research, Inc., Princeton, NJ, USA; Industrial Augmented Reality Group, Imaging & Visualization Department, Siemens Corporate Research, Inc., Princeton, NJ, USA; Industrial Augmented Reality Group, Imaging & Visualization Department, Siemens Corporate Research, Inc., Princeton, NJ, USA","Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99)","6 Aug 2002","1999","","","125","133","The application presented augments uncalibrated images of factories with industrial drawings. Industrial drawings are among the most important documents used during the lifetime of industrial environments. They are the only common documents used during design, installation, monitoring and control, maintenance, update and finally dismantling of industrial units. Leading traditional industries towards the full use of virtual and augmented reality technology is impossible unless industrial drawings are integrated into our systems. We provide the missing link between industrial drawings and digital images of industrial sites. On one hand, this could enable us to calibrate cameras and build a 3D model of the scene without using any calibration markers. On the other hand it brings industrial drawings, floor map, images and 3D models into one unified framework. This provides a solid foundation for building efficient enhanced virtual industrial environments. The augmented scene is obtained by perspective warping of an industrial drawing of the factory onto its floor, wherever the floor is visible. The visibility of the floor is determined using probabilistic reasoning over a set of clues including (1) floor color/intensity (2) image warping and differencing between an uncalibrated stereoscopic image pair using the ground plane homography. Experimental results illustrate the approach.","","0-7695-0359-4","10.1109/IWAR.1999.803813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=803813","","Layout;Electrical equipment industry;Floors;Production facilities;Industrial control;Augmented reality;Digital images;Cameras;Calibration;Solids","augmented reality;image matching;stereo image processing;production engineering computing","scene augmentation;industrial drawings;uncalibrated image;marker-less calibration;factories;industrial environments;industrial units;augmented reality;digital images;3D model;virtual industrial environments;perspective warping;probabilistic reasoning;floor color;image warping;uncalibrated stereoscopic image pair;ground plane homography","","28","","16","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Reality and perception: Utilization of many facets of augmented reality","Z. Taqvi","State Key Laboratory of Advanced Optical Communication Systems and Networks, Peking University, Beijing, China","2013 23rd International Conference on Artificial Reality and Telexistence (ICAT)","30 Jan 2014","2013","","","11","12","What we perceive with our senses becomes the basic real time information that directs and helps with the tasks we do. Our perception may represent the real world environment or what is perceived is a view of the real world modified with simulated elements of the environment. Augmented reality (AR) represents a system where a view of a live real physical environment is supplemented by computer-generated elements such as sound, video, graphic or location data. Development of AR systems has been facilitated by the advancement in both hardware and software technologies, making it easier to implement all functionalities in real time. Such real time enhancements have been helped by new techniques in such areas as computer vision, object recognition, and registration methodologies which enable user to interact with and manipulate the real world environment effectively. AR advanced computer graphics is integrated to real world data and viewed by the user using see-through head mounted display (HMD). This immersion of the integrated real and simulated world provides a unique perception to users. What he sees, feels, hears, and smells is indistinguishable between what is real and what is computer-generated. Technology has propelled AR systems from experimental laboratories to the marketplace demonstrating great promise in the fields of arts, architecture, archaeology, commerce, construction, education, entertainment, gaming, system maintenance, medical and military applications.","","978-4-904490-11-2","10.1109/ICAT.2013.6728899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728899","Virtual reality;Augmented reality;Simulated reality;Displays","Glass;Three-dimensional displays;Augmented reality;Solid modeling;Real-time systems;Computational modeling;Google","augmented reality;computer graphics","augmented reality;real time information;real world environment;simulated elements;AR;physical environment;computer generated elements;software technologies;hardware technologies;advanced computer graphics;head mounted display;HMD","","5","","8","","30 Jan 2014","","","IEEE","IEEE Conferences"
"Augmented Reality Based Interactive Text Book: An Assistive Technology for Students with Learning Disability","K. P. Vinumol; A. Chowdhury; R. Kambam; V. Muralidharan","Center for Dev. of Adv. Comput., Hyderabad, India; Center for Dev. of Adv. Comput., Hyderabad, India; Center for Development of Advanced Computing, Hyderabad, India; Center for Development of Advanced Computing, Hyderabad, India","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","232","235","Statistics based on research reveals that India has approximately ninety million people with varying degrees of Learning Disabilities (LD) and an average class in schools has about five students with learning disabilities. Epidemiological studies of learning disabilities in India are burdened by problems ranging from identification, assessment, to socio-cultural factors unique to India. Therefore, it is believed that number of children with LD may be much larger than five to a class of fifty students. Hence it is necessary for us to develop suitable technologies to assist the education of these learning disabilities children. This paper presents a PROTYPE called Interactive Text book for assisting students with learning disability. Here the book will be same as normal text book with out any special markers and identifiers. Once the children focus on a text, the 3D images, audio and videos that explains the text more graphically will be augmented on that page. This enhances the students understanding and makes the learning process easier for them.","","978-0-7695-5001-5","10.1109/SVR.2013.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655787","Augmented Reality;Learning disability;OCR","Videos;Optical character recognition software;Augmented reality;Text recognition;Educational institutions;Databases","augmented reality;computer aided instruction;handicapped aids;medical disorders","augmented reality based interactive text book;assistive technology;learning disability;India;epidemiological study;identification;assessment;socio-cultural factors;children;PROTYPE;3D images;student understanding;learning process","","15","","9","IEEE","7 Nov 2013","","","IEEE","IEEE Conferences"
"Blurry (Sticky) Finger: Proprioceptive Pointing and Selection of Distant Objects for Optical See-Through Based Augmented Reality","J. E. Yu; G. J. Kim","Dept. of Computer Science and Engineering, Korea University; Dept. of Computer Science and Engineering, Korea University","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","336","337","We demonstrate “Blurry (Sticky) Finger” in which one uses the unfocused blurred finger, sense of proprioception, to aim, point and directly select a distant object in the real world with both eyes open. We showcase two demo applications. The first illustrates the accuracy and usability of the proposed method with the target objects lying at a fixed depth on a monitor. The second is an AR based object inquiry system, a more practical application. The user aims and encircles a real 3D object whose image is captured with the eye-to-camera offset compensated. The image is searched through the data base with the result augmented on an OST display.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836530","AR;augmented reality;interface;pointing gesture;proprioception;hand-eye coordination","Cameras;Thumb;Glass;Augmented reality;Monitoring;Three-dimensional displays","augmented reality;mechanoception","OST display;blurry (sticky) finger;optical see-through based augmented reality;distant objects;proprioceptive selection;proprioceptive pointing","","2","","10","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Towards a usable stereoscopic augmented reality interface for the manipulation of virtual cursors","J. Sands; S. W. Lawson","School of Computing, Napier University, Edinburgh, UK; School of Computing, Napier University, Edinburgh, UK","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","280","281","The combination of augmented reality (AR) systems and stereoscopic display devices has created a powerful tool with which to ""supplement"" our view. One application for such systems is for the augmented teleoperation of unmanned vehicles, deployed in remote or hazardous environments. Research in this area has highlighted the need for accurate 3D measurement techniques - such as through the use of virtual cursors. This paper describes our work in the development of an AR interface designed to assist the accurate selection of position in 3D space. We describe some preliminary experimental work using virtual cursors before discussing how we believe depth cues can be utilized to allow a user to make a more informed judgment of depth in unprepared environments. It is expected that the guidelines outlined in this report will be used as a benchmark for the development of further 3D ARA cursors.","","0-7695-2006-5","10.1109/ISMAR.2003.1240720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240720","","Augmented reality;Computer displays;Computer interfaces;Surface texture;Vehicles;Measurement techniques;Guidelines;Layout;Three dimensional displays;Mice","stereo image processing;augmented reality;graphical user interfaces","stereoscopic augmented reality;augmented reality interface;virtual cursors;AR systems;stereoscopic display devices;augmented teleoperation;unmanned vehicles;remote environments;3D measurement techniques;AR interface;3D space;depth cues;benchmark;3D ARA cursors","","2","2","6","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Virtual Reality and Augmented reality applications in agriculture: a literature review","M. E. de Oliveira; C. G. Corrêa","Departamento Acadêmico de Computação, Universidade Tecnológica Federal do Paraná (UTFPR), Cornélio Procópio, Brasil; Departamento Acadêmico de Computação, Universidade Tecnológica Federal do Paraná (UTFPR), Cornélio Procópio, Brasil","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","1","9","Virtual Reality (VR) and Augmented Reality (AR) based technologies can be applied in several areas, such as: science, services, education, medicine and military. On the other hand, agriculture is an area that has benefited from computer systems, with technological advances that have culminated in fields of study such as Agriculture 4.0, Digital Agriculture and Precision Agriculture, providing an increase in food production in a sustainable way. Thus, the agricultural area can be a target for professionals and researchers in VR and AR. In this article a literature review is presented with the objective of showing why VR and AR technologies are beneficial to the agricultural sector. The searches were conducted on Google Scholar, ACM Digital Library, Elsevier, IEEE Xplore, MDPI and Springer. After searching and selecting, twenty articles were analyzed. The review describes the main input and output devices used, the main crops, the objectives of the applications, the users, the countries where the studies were conducted. The results show that digital agriculture is able to help users to increase productivity in a sustainable way. The review identified trends, challenges and opportunities for improving these technologies applied to agriculture.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262674","agriculture;applications;literature review","Agriculture;Visualization;Monitoring;Augmented reality;Libraries;Internet;Drones","agriculture;augmented reality;crops","VR;digital agriculture;precision agriculture;agricultural sector;augmented reality;virtual reality","","5","","0","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"Multi-dimensional Interactive City Exploration through Mixed Reality","I. Herbst; A. -K. Braun; R. McCall; W. Broll","Collaborative Virtual and Augmented Environments Department, Fraunhofer FIT, Sankt Augustin, Germany; Collaborative Virtual and Augmented Environments Department, Fraunhofer FIT, Sankt Augustin, Germany; Collaborative Virtual and Augmented Environments Department, Fraunhofer FIT, Sankt Augustin, Germany; Collaborative Virtual and Augmented Environments Department, Fraunhofer FIT, Sankt Augustin, Germany","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","259","260","In this paper we present a pervasive outdoor mixed reality edutainment game for exploring the history of a city in the spatial and the temporal dimension, which will closely couple the real environment with the virtual content. The game provides a new and unique user experience, which links rich interactive content to time and places. We introduce the development of such a game, including a universal mechanism to define and setup multi-modal user interfaces for game challenges.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480790","Augmented Reality (AR);Multimodal Interfaces;Pervasive Gaming;Mixed Reality (MR);Presence;H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities - Audio input/output;H.5.2 [User Interfaces]: Input devices and strategies;I.3.1 [Hardware Architecture]: Input devices;I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction Techniques;K.8.0 [Personal Computing]: General - Games","Cities and towns;Virtual reality;User interfaces;Displays;Multimedia systems;Bluetooth;Optical receivers;Optical sensors;Mice;Iris","augmented reality;computer games;interactive systems;ubiquitous computing;user interfaces","multidimensional interactive city exploration;pervasive outdoor mixed reality edutainment game;virtual content;multimodal user interface;augmented reality;multimodal interface;pervasive gaming","","1","","3","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"An adaptive thresholding algorithm for the augmented reality toolkit","T. Pintaric","University of Technology, Vienna, Austria","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","71","","It is well known that fixed global thresholds have adverse effects on the reliability of marker-based optical trackers under non-uniform lighting conditions. Mobile augmented reality applications, by their very nature, demand a certain level of robustness against varying external illumination from visual tracking algorithms. Currently, ARToolKit depends on fixed-threshold image-binarization in order to detect candidate fiducials for further processing. In an effort to minimize tracking failure due to uniform shadows and reflections on a marker surface, we propose a fast algorithm for selecting adaptive threshold values, based on the arithmetic mean of pixel intensities over a region-of-interest around candidate fiducials.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320431","","Augmented reality;Robustness;Optical reflection;Testing;Lighting;Cameras;Virtual reality;Libraries;Tracking;Workstations","augmented reality;computer vision;mobile computing;optical tracking","ARToolKit;adaptive thresholding algorithm;augmented reality toolkit;marker-based optical tracker;mobile augmented reality;visual tracking;fixed-threshold image-binarization;pixel intensity","","12","1","3","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"Investigating Visualization Techniques for Observing a Group of Virtual Reality Users Using Augmented Reality","S. Thanyadit; P. Punpongsanon; T. -C. Pong","Hong Kong University of Science and Technology, Kowloon, HK; Hong Kong University of Science and Technology, Kowloon, HK; Osaka Daigaku, Suita, Osaka, JP","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1189","1190","As an emerging technology, virtual reality (VR) has been used increasingly as a learning tool to explore “outside the classroom experiences” inside the classroom. While VR provides an immersive experience to the students, it is difficult for the instructor to monitor the students' activities in the VR. Thus, it hinders interactions between the instructor and students. To solve this challenge, we investigated a technique that allows the instructor to observe VR users at scale using Augmented Reality. Augmented Reality techniques are used to visualize the gazes of the VR users in the virtual environment, and improve the instructor's awareness.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798123","Visualization;Virtual Reality;Education;User Experience;Human-centered computing;Visualization design and evaluation methods;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality","Visualization;Virtual environments;Augmented reality;Three-dimensional displays;Tools;Monitoring","augmented reality;computer aided instruction;data visualisation;user interfaces","visualization techniques;learning tool;classroom experiences;immersive experience;VR users;virtual environment;virtual reality users;augmented reality techniques","","3","","4","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Symmetrical Reality: Toward a Unified Framework for Physical and Virtual Reality","Z. Zhang; C. Wang; D. Weng; Y. Liu; Y. Wang","Beijing Institute of Technology, Beijing, Beijing, CN; China Electronics Standardization Institute, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology, Beijing, China","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1275","1276","In this paper, we review the background of physical reality, virtual reality, and some traditional mixed forms of them. Based on the current knowledge, we propose a new unified concept called symmetrical reality to describe the physical and virtual world in a unified perspective. Under the framework of symmetrical reality, the traditional virtual reality, augmented reality, inverse virtual reality, and inverse augmented reality can be interpreted using a unified presentation. We analyze the characteristics of symmetrical reality from two different observation locations (i.e., from the physical world and from the virtual world), where all other forms of physical and virtual reality can be treated as special cases of symmetrical reality.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797970","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed/augmented reality","Augmented reality;Virtual environments;User interfaces;Conferences;Three-dimensional displays;Solids","virtual reality","symmetrical reality;physical reality;physical world;virtual world;inverse virtual reality;inverse augmented reality","","6","","9","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"HoloLucination: A Framework for Live Augmented Reality Presentations Across Mobile Devices","A. Bahremand; L. Nguyen; T. Harrison; R. LiKamWa","School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, Arizona; School of Arts, Media, and Engineering, Arizona State University, Tempe, Arizona; Professional Martian, LLC, Washington, DC; School of Arts, Media, and Engineering, Arizona State University, Tempe, Arizona","2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","243","2431","We envision that in the future, presentations for business, education, and scientific dissemination can invoke 3D spatial content to immersively display and discuss animated 3-dimensional models and spatial data visualizations to large audiences. At the moment, current frameworks have targeted a highly technical user base, prohibiting the widespread curation of immersive presentations. Furthermore, solutions for real-time multi-user interactions have focused on multiplayer gaming, rather than large format immersive presentation. However, modern mobile devices (smartphones, tablets, headsets) have the capability of rendering virtual models over the physical environment through visual anchors for Augmented Reality (AR). Our ongoing research thrust is to leverage contemporary AR infrastructure to develop an easy-to use tool for users to curate and spatially present augmented presentations to large audiences. In this demo, we have built an Augmented Reality framework that allows users to curate mixed reality presentations. Our framework allows users to prepare a sequential state of animations. At the time of presentation, presenters can invoke the animations to simultaneously occur on HMDs and mobile devices.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942234","augmented reality;visualization;presentation","Animation;Three-dimensional displays;Mobile handsets;Visualization;Synchronization;Augmented reality;Solid modeling","augmented reality;computer animation;data visualisation;human computer interaction;mobile computing;rendering (computer graphics);user interfaces","augmented reality presentation;3D spatial content;spatial data visualizations;real-time multiuser interactions;multiplayer gaming;mobile devices;visual anchors;augmented reality framework;mixed reality presentations;3-dimensional models animation;virtual models rendering","","1","","5","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"[DEMO] On the use of augmented reality techniques in a telerehabilitation environment for wheelchair users' training","D. Caetano; F. Mattioli; E. Lamounier; A. Cardoso",Virtual and Augmented Reality Research Group Faculty of Electrical Engineering - Federal University of Uberlândia - Brazil; Virtual and Augmented Reality Research Group Faculty of Electrical Engineering - Federal University of Uberlândia - Brazil; Virtual and Augmented Reality Research Group Faculty of Electrical Engineering - Federal University of Uberlândia - Brazil; Virtual and Augmented Reality Research Group Faculty of Electrical Engineering - Federal University of Uberlândia - Brazil,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","329","330","This work's purpose is to investigate the use of Augmented Reality techniques on telerehabilitation, applied to wheelchair users training. In this scenario, using a computer with unconventional devices, the user will be connected to a remote training space and will be able to issue commands, in order to accomplish the execution of training exercises. The telerehabilitation environment should reproduce the main challenges faced by wheelchair users in their daily activities.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948473","Augmented Reality;Telerehabilitation;Wheelchair Training","","","","","4","","","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"ARWin - a desktop augmented reality Window Manager","S. Di Verdi; D. Nurmi; T. Hollerer","Department of Computer Science, University of California, Santa Barbara, CA, USA; Department of Computer Science, University of California, Santa Barbara, CA, USA; Department of Computer Science, University of California, Santa Barbara, CA, USA","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","298","299","We present ARWin, a single user 3D augmented reality desktop. We explain our design considerations and system architecture and discuss a variety of applications and interaction techniques designed to take advantage of this new platform.","","0-7695-2006-5","10.1109/ISMAR.2003.1240729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240729","","Augmented reality;Application software;Computer displays;Cameras;Clocks;Computer architecture;Keyboards;Mice;Computer science;Computer graphics","augmented reality;graphical user interfaces","ARWin;desktop augmented reality;Window Manager;user 3D augmented reality;system architecture;interaction techniques;desktop computer;graphical user interface","","15","3","7","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Enhancing Rock Painting Tour Experience with Outdoor Augmented Reality","Q. Zhang; X. Zhu; H. Yu; Y. Jiang","Institute of Automation, University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","118","121","The use of augmented reality technology is becoming a necessity of many cultural heritage sites to stay competitive and attractive to tourists. In this paper, we present an outdoor augmented reality guidance system for ancient rock painting aiming to enhance tourist experience and introduce the culture and historical background. We propose a two-stage approach that combines GPS and feature-based recognition methods. In the first stage, we build a navigation map in advance, which consists of the distribution information of major scenic spots, then visit these spots guided by GPS data on the standard smartphone. In the second stage, we adopt a feature-based recognition and tracking method to identify rock painting accurately and augment them with interactive contextual annotations like 3D textual labels, images, and videos. The reliability of this system is verified through on-site demonstrations - RockArt of the Helan Mountain, which is one of National Key Historical and Cultural Sites in China.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951939","ugmented reality;historic sites;outdoor tour guiding","Painting;Rocks;Feature extraction;Cultural differences;Navigation;Augmented reality","augmented reality;Global Positioning System;history;human computer interaction;image annotation;image recognition;interactive systems;object tracking;travel industry","augmented reality technology;cultural heritage sites;outdoor augmented reality guidance system;ancient rock painting;historical background;two-stage approach;feature-based recognition methods;navigation map;distribution information;scenic spots;GPS data;tracking method;Cultural Sites;on-site demonstrations;rock painting tour experience enhancement;standard smartphone;interactive contextual annotations;3D textual labels;RockArt;Helan mountain","","1","","15","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Laparoscopic Virtual Mirror New Interaction Paradigm for Monitor Based Augmented Reality","N. Navab; M. Feuerstein; C. Bichlmeier","Chair for Computer Aided Medical Procedures and Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality (CAMP), Technische Universität München, Munich, Germany","2007 IEEE Virtual Reality Conference","23 Apr 2007","2007","","","43","50","A major roadblock for using augmented reality in many medical and industrial applications is the fact that the user cannot take full advantage of the 3D virtual data. This usually requires the user to move the virtual object, which disturbs the real/virtual alignment, or to move his head around the real objects, which is not always possible and/or practical. This problem becomes more dramatic when a single camera is used for monitor based augmentation, such as in augmented laparoscopic surgery. In this paper we introduce an interaction and 3D visualization paradigm, which presents a new solution to this old problem. The interaction paradigm uses an interactive virtual mirror positioned into the augmented scene, which allows easy and complete interactive visualization of 3D virtual data. This paper focuses on the exemplary application of such visualization techniques to laparoscopic interventions. A large number of such interventions aims at regions inside a specific organ, e.g. blood vessels to be clipped for tumor resection. We use high-resolution intra-operative imaging data generated by a mobile C-arm with cone-beam CT imaging capability. Both the C-arm and the laparoscope are optically tracked and registered in a common world coordinate frame. After patient positioning, port placement, and carbon dioxide insufflation, a C-arm volume is reconstructed during patient exhalation and superimposed in real time on the laparoscopic live video without any need for an additional patient registration procedure. To overcome the missing perception of 3D depth and shape when rendering virtual volume data directly on top of the organ's surface view, we introduce the concept of a laparoscopic virtual mirror: A virtual reflection plane within the live laparoscopic video, which is able to visualize a reflected side view of the organ and its interior. This enables the surgeon to observe the 3D structure of, for example, blood vessels by moving the virtual mirror within the augmented monocular view of the laparoscope.","2375-5334","1-4244-0905-5","10.1109/VR.2007.352462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161004","Interactive AR Visualization;Depth Perception;Medical Augmented Reality;Laparoscopic Surgery;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;augmented;and virtual realities;H.5.2 [Information Interfaces and Presentation]: User Interfaces-Interaction styles;I.3.6 [Computer Graphics]: Methodology and Techniques-Interaction techniques;J.3 [Life and Medical Sciences]","Laparoscopes;Mirrors;Augmented reality;Data visualization;Biomedical imaging;Blood vessels;High-resolution imaging;Optical imaging;Biomedical monitoring;Head","augmented reality;computerised tomography;data visualisation;medical computing;rendering (computer graphics);surgery;user interfaces","laparoscopic virtual mirror;interaction paradigm;monitor-based augmented reality;3D virtual data;virtual objects;3D visualization;mobile C-arm;cone-beam CT imaging;carbon dioxide insufflation;virtual volume data rendering","","27","1","26","IEEE","23 Apr 2007","","","IEEE","IEEE Conferences"
"Haptic simulation of breast cancer palpation: A case study of haptic augmented reality","S. Jeon; B. Knoerlein; M. Harders; S. Choi","Haptics and Virtual Reality Laboratory, Postech, South Korea; Computer Vision Laboratory, ETH Zurich, Switzerland; Computer Vision Laboratory, ETH Zurich, Switzerland; Haptics and Virtual Reality Laboratory, Postech, South Korea","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","237","238","Haptic augmented reality (AR) allows to modulate the haptic properties of a real object by providing virtual haptic feedback. We previously developed a haptic AR system wherein the stiffness of a real object can be augmented with the aid of a haptic interface. To demonstrate its potential, this paper presents a case study for medical training of breast cancer palpation. A real breast model made of soft silicone is augmented with a virtual tumor rendered inside. Haptic stimuli for the virtual tumor are generated based on a contact dynamics model identified via real measurements, without the need of geometric information on the breast. A subjective evaluation confirmed the realism and fidelity of our palpation system.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643585","","Tumors;Haptic interfaces;Breast;Biological system modeling;Solid modeling;Data models;Force","augmented reality;cancer;haptic interfaces;silicones","breast cancer palpation;haptic augmented reality;virtual haptic feedback;haptic interface;soft silicone;virtual tumor","","16","","4","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"[DC] Dimensionality of Augmented Reality Spatial Interfaces","A. Vovk","Oxford Brookes University, Oxford, Oxfordshire, GB","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1377","1378","The next wave of computing is visible on the horizon, heralding the widespread adoption of augmented reality spatial information manipulation on wearable and environment integrated form factors such as head-worn displays. This application for the doctoral consortium at IEEE VR 2019 describes the research conducted and planned in the context of a PhD thesis, which aims at determining a multidimensional model of user performance in spatial user interaction in augmented reality for training.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798171","Augmented reality;spatial user interface;trainings;[Human-centered computing]: Human computer interaction;Interaction paradigms;Mixed/Augmented reality","Training;Augmented reality;Task analysis;Usability;Ergonomics;User interfaces","augmented reality;helmet mounted displays","augmented reality spatial interfaces;augmented reality spatial information manipulation;wearable environment integrated form factors;head-worn displays;IEEE VR;spatial user interaction;multidimensional model","","","","7","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Sharing and Augmenting Emotion in Collaborative Mixed Reality","J. D. Hart; T. Piumsomboon; G. Lee; M. Billinghurst","School of Information Technology & Mathematical Sciences, University of South Australia; School of Information Technology & Mathematical Sciences, University of South Australia; School of Information Technology & Mathematical Sciences, University of South Australia; School of Information Technology & Mathematical Sciences, University of South Australia","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","212","213","We present a concept of emotion sharing and augmentation for collaborative mixed-reality. To depict the ideal use case of such system, we give two example scenarios. We describe our prototype system for capturing and augmenting emotion through facial expression, eye-gaze, voice, physiological data and share them through their virtual representation, and discuss on future research directions with potential applications.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699245","Mixed reality;avatars;emotion sharing;emotion augmentation;facial expression;remote collaboration;H.5.1 Information interfaces and presentation (e.g., HCI): Multimedia Information Systems—Artificial, augmented, and virtual realities","Augmented reality","augmented reality;emotion recognition;face recognition;gaze tracking;groupware;voice activity detection","prototype system;collaborative mixed reality;emotion sharing;emotion augmentation;facial expression;eye-gaze;voice;physiological data;virtual representation","","4","","8","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Depth judgments by reaching and matching in near-field augmented reality","G. Singh; J. E. Swan; J. A. Jones; S. R. Ellis","Mississippi State University, USA; Mississippi State University, USA; Mississippi State University, USA; NASA Ames Research Center, USA","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","165","166","In this abstract we describe an experiment that measured depth judgments in optical see-through augmented reality (AR) at near-field reaching distances of ~ 24 to ~ 56 cm. The 2×2 experiment crossed two depth judgment tasks, perceptual matching and blind reaching, with two different environments, a real-world environment and an augmented reality environment. We designed a task that used a direct reaching gesture at constant percentages of each participant's maximum reach; our task was inspired by previous work by Tresilian and Mon-Williams [6] that found very accurate blind reaching results in a real-world environment.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180933","depth perception;augmented reality;optical see-through display;x-ray vision","Augmented reality;Atmospheric measurements;Particle measurements;Optical variables measurement;Accuracy;Optics;Visualization","augmented reality;computer graphics","depth judgments;near-field augmented reality;optical see-through augmented reality environment;near field reaching distance;perceptual matching;direct reaching gesture;blind reaching result;real-world environment","","14","","6","IEEE","12 Apr 2012","","","IEEE","IEEE Conferences"
"Tinmith-Hand: unified user interface technology for mobile outdoor augmented reality and indoor virtual reality","W. Piekarski; B. H. Thomas","University of South Australia, Mawson Lakes, SA, Australia; University of South Australia, Mawson Lakes, SA, Australia","Proceedings IEEE Virtual Reality 2002","7 Aug 2002","2002","","","287","288","This paper presents a unified user interface technology, using 3D interaction techniques, constructive solid geometry and a glove-based menuing system, known as Tinmith-Hand, to support mobile outdoor augmented reality (AR) applications and indoor virtual reality (VR) applications. Tinmith-Hand uses similar concepts for both domains, so that AR and VR applications are consistent and simple to use. The future goal of this user interface is to allow collaboration between outdoor AR and indoor VR systems.","1087-8270","0-7695-1492-8","10.1109/VR.2002.996542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=996542","","User interfaces;Augmented reality;Virtual reality;Mobile computing;Wearable computers;Solids;Collaboration;Switches;Arm;Laboratories","data gloves;virtual reality;augmented reality;graphical user interfaces;solid modelling","Tinmith-Hand;unified user interface technology;mobile outdoor augmented reality applications;indoor virtual reality applications;3D interaction techniques;constructive solid geometry;glove-based menuing system;consistent applications;ease of use;systems collaboration","","13","","5","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Interaction of Spatial Computing In Augmented Reality","S. Balakrishnan; M. S. S. Hameed; K. Venkatesan; G. Aswin","Dept. of Computer Science and Business Systems, Sri Krishna College of Engg. and Technology, Coimbatore, Tamilnadu, India; University of Technology and Applied Sciences - SUR, PO BOX: 484, PC 411, SUR, The Sultanate of Oman; Department of ECE, St. Josephs college of engineering; Full stack software developer zealbots in chadura Tech, Tiruchirapalli, Tamilnadu, India","2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS)","3 Jun 2021","2021","1","","1900","1904","In the above certain years, the technology of spatial computing has recognized the environment growth of simulated reality by user interaction and extensive knowledge which assist the 3D canvas used space for user interfaces. Spatial computing is widely compatible with XR which is an Extended Reality. This acts itself as an umbrella phase for Augmented Reality (AR), Mixed Reality (MR) and Virtual Reality (VR). Moreover, we are looking into the deep concepts of AR in spatial computing. Augmented reality is a new medium of laminating and merging digital contents towards the real world. This medium provides individual assets connecting the physical-virtual world with steady control and enhances the overall environment reality of user’s information. These are obtained based on mobile devices, projection devices and mounted displays that help in augmenting the information over real-life. In advance, AR is part of spatial augmented reality which is an assistive technology tool used for determining the completion time of task, speed range and quality of interactive computation. This paper delivers the effectiveness of Augmented Reality (AR) with possible combination of technologies and applications from a user’s point of view.","2575-7288","978-1-6654-0521-8","10.1109/ICACCS51430.2021.9442010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442010","Spatial computing;augmented reality;virtual reality;mixed reality","Three-dimensional displays;Spatial augmented reality;Glass;User interfaces;Tools;Internet;X reality","augmented reality;user interfaces","user interfaces;spatial computing;extended reality;virtual reality;environment reality;spatial augmented reality;interactive computation;user interaction;mixed reality","","28","","10","IEEE","3 Jun 2021","","","IEEE","IEEE Conferences"
"[Poster] classifications of augmented reality uses in marketing","A. Javornik",Università della Svizzera italiana,"2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design (ISMAR-MASH'D)","27 Oct 2014","2014","","","67","68","This research investigates which uses of AR have emerged so far in marketing and proposes classification schemas for them, based on the intensity of the augmentation, different contexts of consumption and on marketing functions. Such differentiation is needed in order to better understand the dynamics of augmentation of physical surroundings for commercial purposes and consequently to distinguish between consumer experiences.","2381-8360","978-1-4799-6887-9","10.1109/ISMAR-AMH.2014.6935441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935441","Augmented reality;Marketing;Typology;Augmentation of consumption","Augmented reality;Advertising;Context;Customer services;Real-time systems;Media;Visualization","augmented reality;marketing","augmented reality;classification schema;marketing function","","18","","6","IEEE","27 Oct 2014","","","IEEE","IEEE Conferences"
"InspectAR: An Augmented Reality Inspection Framework for Industry","R. Perla; G. Gupta; R. Hebbalaguppe; E. Hassan","TCS Research, Delhi, India; TCS Research, Delhi, India; TCS Research, Delhi, India; TCS Research, Delhi, India","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","355","356","With the advancement in camera technologies and data streaming protocols, AR based applications are proving to be an important aid for inspection, training and supervision tasks in various operations including automotive industry, education etc. We demonstrate an AR based re-configurable inspection framework that can be utilized in cross-domain applications such as maintenance and repair assistance in industrial inspection and automotive/avionics domain inspection, amongst others. A deep learning component detects parts viewed in inspector's Field-of-View (FoV) accurately and the corresponding inspection check-list can be prioritized based on detection results. The back-end of the framework is easily configurable for different applications where instructions can be directly imported and visually integrated with inspection type. Accurate recording of status of inspection is provided through evidence capturing of images, notes and videos. Our current framework supports all the Android based devices and will be demonstrated on Google Glass, Google Cardboard with smartphone, and Tablet with the help of 3D printer inspection use-case.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836540","H.5.1 [Information Interfaces and Presentation]: Artificial;Augmented;and Virtual Realities—; [Human-centered computing]: Ubiquitous and mobile computing—Ambient Intelligence I.4.8 [Computing Methodologies]: Image Processing and Computer Vi","Inspection;Google;Servers;Glass;Object detection;Augmented reality;Printers","Android (operating system);augmented reality;automatic optical inspection;image capture;learning (artificial intelligence);printers;production engineering computing;smart phones;three-dimensional printing","augmented reality inspection;InspectAR;camera technologies;data streaming protocols;AR based applications;AR based reconfigurable inspection;cross-domain applications;deep learning component;inspector field-of-view;inspection check-list;part detection;inspection type;evidence image capturing;Android based devices;Google Glass;Google Cardboard;smartphone;Tablet;3D printer inspection use-case","","12","1","3","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"[Poster] Non-parametric camera-based calibration of optical see-through glasses for augmented reality applications","M. Klemm; H. Hoppe; F. Seebacher",University of Applied Sciences Offenburg; University of Applied Sciences Offenburg; University of Applied Sciences Offenburg,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","273","274","This work describes a camera-based method for the calibration of optical See-Through Glasses (STGs). A new calibration technique is introduced for calibrating every single display pixel of the STGs in order to overcome the disadvantages of a parametric model. A non-parametric model compared to the parametric one has the advantage that it can also map arbitrary distortions. The new generation of STGs using waveguide-based displays [5] will have higher arbitrary distortions due to the characteristics of their optics. First tests show better accuracies than in previous works. By using cameras which are placed behind the displays of the STGs, no error prone user interaction is necessary. It is shown that a high accuracy tracking device is not necessary for a good calibration. A camera mounted rigidly on the STGs is used to find the relations between the system components. Furthermore, this work elaborates on the necessity of a second subsequent calibration step which adapts the STGs to a specific user. First tests prove the theory that this subsequent step is necessary.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948446","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems —Artificial;augmented;virtual realities;I.4.9 [Image Processing and Computer Vision]: Applications;I.4.m [Image Processing and Computer Vision];Miscellaneous","Calibration;Cameras;Optical distortion;Accuracy;Adaptive optics;Three-dimensional displays;Augmented reality","augmented reality;computer displays;optical glass;user interfaces","nonparametric camera-based calibration;optical see-through glass;augmented reality;STG;camera-based method;calibration technique;nonparametric model;waveguide-based display;user interaction","","9","","7","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Robust Keyframe-Based Monocular SLAM for Augmented Reality","H. Liu; G. Zhang; H. Bao","State Key Lab of CAD&CG, Zhejiang University; The Collaborative Innovation Center for Industrial Cyber-Physical System, Zhejiang University; The Collaborative Innovation Center for Industrial Cyber-Physical System, Zhejiang University","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","340","341","In this demo, we present RKSLAM, a robust keyframe-based monocular SLAM system that can reliably handle fast motion with strong rotation and ensure good AR experiences. We contribute two key technical contributions: a novel multi-homography based feature tracking method which is very robust and efficient, and a sliding-window based camera pose optimization scheme which imposes the motion prior constraints between consecutive frames through simulated or real IMU data. Based on RKSLAM, we develop an AR App on a mobile device, which allows the user to freely insert 3D furniture models into the scene to see the AR effect without imagination.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836532","SLAM;augmented reality;tracking;multiple homography representation;mapping","Three-dimensional displays;Simultaneous localization and mapping;Cameras;Robustness;Solid modeling;Mobile handsets;Augmented reality","augmented reality;feature extraction;mobile computing;object tracking;pose estimation;SLAM (robots);solid modelling","robust keyframe-based monocular SLAM;augmented reality;RKSLAM;AR experiences;multihomography based feature tracking method;sliding-window based camera pose optimization scheme;motion prior constraints;IMU data;AR app;mobile device;3D furniture models","","7","1","5","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Robust pose estimation in untextured environments for augmented reality applications","W. Guan; L. Wang; J. Mooser; S. You; U. Neumann","Computer Graphics and Immersive Technologies Laboratory, University of Southern California, USA; Computer Graphics and Immersive Technologies Laboratory, University of Southern California, USA; Computer Graphics and Immersive Technologies Laboratory, University of Southern California, USA; Computer Graphics and Immersive Technologies Laboratory, University of Southern California, USA; Computer Graphics and Immersive Technologies Laboratory, University of Southern California, USA","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","191","192","We present a robust camera pose estimation approach for stereo images captured in untextured environments. Unlike most of existing registration algorithms which are point-based and make use of intensities of pixels in the neighborhood, our approach imports line segments in registration process. With line segments as primitives, the proposed algorithm is capable to handle untextured images such as scenes captured in man-made environments, as well as the cases when there are large viewpoint changes or illumination changes. Furthermore, since the proposed algorithm is robust to large base-line stereos, there are improvements on the accuracy of 3D points reconstruction. With well-calculated camera pose and object positions in 3D space, we can embed virtual objects into existing scene with higher accuracy for realistic effects. In our experiments, 2D labels are embedded in the 3D scene space to achieve annotation effects as in AR.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336470","augmented reality;pose estimation;image registration","Robustness;Augmented reality;Image segmentation;Cameras;Layout;Lighting;Application software;Image registration;Stereo vision;Computer graphics","augmented reality;cameras;image registration;image segmentation;pose estimation;stereo image processing","robust camera pose estimation;untextured environments;augmented reality;stereo images;point-based algorithm;image registration;man-made environments;3D points reconstruction;annotation effect;line segments","","3","","6","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Using Augmented Reality to overlapping information in live airport cameras","E. R. Zorzal; A. Fernandes; B. Castro","Instituto de Ciência e Tecnologia, Universidade Federal de São Paulo, São José dos Campos, SP, Brasil; Instituto de Ciência e Tecnologia, Universidade Federal de São Paulo, São José dos Campos, SP, Brasil; Instituto de Ciência e Tecnologia, Universidade Federal de São Paulo, São José dos Campos, SP, Brasil","2017 19th Symposium on Virtual and Augmented Reality (SVR)","20 Nov 2017","2017","","","253","256","IP cameras are used in various parts of an aerodrome to help manage and control aircraft on the ground. This paper describes the implementation of a prototype that intersects the feed of these cameras and apply relevant information to aircraft on the actual captured image using real-time data from a ground radar.","","978-1-5386-3588-9","10.1109/SVR.2017.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114445","augmented reality;overlapping information;cameras;airport","Radar imaging;Augmented reality;IP networks;Poles and towers;Airports;Cameras","airports;augmented reality;cameras;object detection","augmented reality;overlapping information;live airport cameras;IP cameras;aerodrome;aircraft;actual captured image;ground radar","","2","","11","IEEE","20 Nov 2017","","","IEEE","IEEE Conferences"
"Distributed Optimization for Shadow Removal in Spatial Augmented Reality","J. Tsukamoto; D. Iwai; K. Kashima",Kyoto University; Osaka University; Kyoto University,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","147","148","This paper proposes a novel shadow removal technique for cooperative projection system based-on spatio-temporal prediction. In our previous work, we proposed a distributed feedback algorithm, which is implementable in cooperative projection environments subject to data transfer constraints between components. A weakness of this scheme is that the compensation is conducted in each pixel independently. As a result, spatio-temporal information of the environmental change cannot be utilized even if it is available. In view of this, we specifically investigate the situation where some of projectors are occluded by a moving object whose oneframe-ahead behavior is predictable. In order to remove the resulting shadow, we propose a novel error propagating scheme that is still implementable in a distributed manner, and enables us to incorporate the prediction information of the obstacle. It is demonstrated experimentally that the proposed method significantly improves the shadow removal performance comparison to the previous work.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836483","Computing methodologies [Computer graphics]: Graphics systems and interfaces—Mixed/augmented reality","Robustness;Radiometry;Cameras;Augmented reality;Optimization;Electronic mail;Heuristic algorithms","augmented reality;image motion analysis;optimisation;spatiotemporal phenomena","shadow removal performance improvement;obstacle prediction information;error propagating scheme;one-frame-ahead behavior;environmental change;spatiotemporal information;spatiotemporal prediction;cooperative projection system;spatial augmented reality;distributed optimization","","1","","4","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"[Poster] Visualization of solar radiation data in augmented reality","M. Beatriz Carmo; A. P. Cláudio; A. Ferreira; A. P. Afonso; P. Redweik; C. Catita; M. C. Brito; J. N. Pedrosa","Faculty of Sciences, University of Lisbon, Lisbon, Portucal; Faculty of Sciences, University of Lisbon, Lisbon, Portucal; Faculty of Sciences, University of Lisbon, Lisbon, Portucal; Faculty of Sciences, University of Lisbon, Lisbon, Portucal; Instituto Dom Luiz, University of Lisbon, Portugal; Instituto Dom Luiz, University of Lisbon, Portugal; Instituto Dom Luiz, University of Lisbon, Portugal; Faculty of Sciences, University of Lisbon, Lisbon, Portucal","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","255","256","We present an AR application for visualizing solar radiation data on facades of buildings, generated from LiDAR data and climatic observations. Data can be visualized using colored surfaces and glyphs. A user study revealed the proposed AR visualizations were easy to use, which can lead to leverage the potential benefits of AR visualizations: to detect errors in the simulated data, to give support to the installation of photovoltaic equipment and to raise public awareness of the use of facades for power production.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948437","augmented reality;scientific data visualization;solar radiation;photovoltaic potential","Data visualization;Solar radiation;Augmented reality;Buildings;Image color analysis;Three-dimensional displays","augmented reality;building integrated photovoltaics;data visualisation;power engineering computing;solar power;solar radiation","solar radiation data visualization;augmented reality;AR application;LiDAR data;climatic observation;light detection and ranging;colored surface;glyph;user study;photovoltaic equipment;power production;building facade","","1","","7","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"[Poster] Towards user perspective augmented reality for public displays","J. Grubert; H. Seichter; D. Schmalstieg",Graz University of Technology; University of Applied Sciences Schmalkalden; Graz University of Technology,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","267","268","We work towards ad-hoc augmentation of public displays on handheld devices, supporting user perspective rendering of display content. Our prototype system only requires access to a screencast of the public display, which can be easily provided through common streaming platforms and is otherwise self-contained. Hence, it easily scales to multiple users.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948443","user perspective rendering;public displays;augmented reality","Cameras;Three-dimensional displays;Rendering (computer graphics);Face;Augmented reality;Handheld computers;Visualization","augmented reality;rendering (computer graphics)","user perspective augmented reality;public displays;handheld devices;user perspective rendering;screencast;streaming platform","","1","","4","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Fisheye vs Rubber Sheet: Supporting Visual Search and Fine Motor Skills in Augmented Reality","Q. Wang; C. Sandor","School of Creative Media, City University of Hong Kong; School of Creative Media, City University of Hong Kong","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","389","390","Fisheye and rubber sheet are common magnifying methods in information visualization. In this paper, we present two experiments about their performance in AR scenarios: visual search and fine motor manipulation. We also included baseline conditions without any magnification. For all magnified views, the size and shape of the magnified region were constant and we evaluated performance based on completion time and accuracy. Our results show that visual distortions of our magnifiers do not significantly decrease performance; our insights will be a reference for projects that require magnified AR views.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585898","Computing methodologies;Computer graphics;Graphics systems and interfaces;Mixed/augmented reality","Visualization;Shape;Distortion;Rubber;Augmented reality","augmented reality;data visualisation","visual distortions;fisheye;rubber sheet;visual search;fine motor skills;augmented reality;information visualization;fine motor manipulation;magnifying methods;AR view","","","","6","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"EyeAR: Empiric Evaluation of a Refocusable Augmented Reality System","A. Rovira; T. Taketomi; R. D. Constantine; H. Kato; C. Sandor; S. Ikeda","Interactive Media Design Laboratory, Nara institute of Science and Technology; Interactive Media Design Laboratory, Nara institute of Science and Technology; NA; Interactive Media Design Laboratory, Nara institute of Science and Technology; Interactive Media Design Laboratory, Nara institute of Science and Technology; Mobile Computing Laboratory Ritsumeikan University","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","11","12","We present the evaluation of EyeAR, a display with refocusable content based on user's eyes measurements. We carried out a user study to validate the prototype to verify that participants cannot distinguish between real and virtual objects. Participants looked at three pillars (one of which was virtual) placed at different distances from the user. They had to guess which pillar was the virtual one while freely refocusing. The results partially confirmed that our prototype creates virtual objects that are indistinguishable from real objects.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836448","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial;augmented;and virtual realities; I.3.3 [Computing Methodologies]: Picture/Image Generation—Display Methods; H.1.2 [Models and Principles]: User/Machine","Prototypes;Visualization;Three-dimensional displays;Augmented reality;Visual systems;Shape","augmented reality;human factors","refocusable augmented reality system;EyeAR evaluation;refocusable content;virtual objects;real objects","","","","8","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Augmented Reality Animals: Are They Our Future Companions?","N. Norouzi",University of Central Florida,"2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","11 May 2020","2020","","","563","564","Previous research in the field of human-animal interaction has captured the multitude of benefits of this relationship on different aspects of human health. Existing limitations for accompanying pets/animals in some public spaces, allergies, and inability to provide adequate care for animals/pets limits the possible benefits of this relationship. However, the increased popularity of augmented reality and virtual reality devices and the introduction of new social behaviors since their utilization offers the opportunity of using such platforms for the realization of virtual animals and investigation of their influences on human perception and behavior.In this paper, one prior experiment is presented, which was designed to provide a better understanding of the requirements of virtual animals in augmented reality as companions. Through these findings, future research directions are identified and discussed.","","978-1-7281-6532-5","10.1109/VRW50115.2020.00133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090664","Human-centered computing;Interaction paradigms;Mixed / augmented reality;Human-centered computing;Human computer interaction (HCI);HCI design and evaluation methods;User studies;Computer graphics;Graphics systems and interfaces;Mixed / augmented reality","Dogs;Augmented reality;Games;Stress;Pediatrics","augmented reality;computer animation;medical image processing;positron emission tomography","human-animal interaction;human health;public spaces;virtual reality devices;virtual animals;human perception;augmented reality animals","","","","14","IEEE","11 May 2020","","","IEEE","IEEE Conferences"
"Augmented Reality and Virtual Reality in Cultural Tourism: ‘Ara as it Was’","M. M. De Andrade; V. J. D. Mendonça; R. F. Correia; J. Franco","Campus de Santa Apolónia, Instituto Politécnico de Bragança, Bragança, Portugal; Campus de Santa Apolónia, Instituto Politécnico de Bragança, Bragança, Portugal; Campus de Santa Apolónia, Instituto Politécnico de Bragança, Bragança, Portugal; Campus de Santa Apolónia, Instituto Politécnico de Bragança, Bragança, Portugal","2022 17th Iberian Conference on Information Systems and Technologies (CISTI)","14 Jul 2022","2022","","","1","6","With the permanent development of technology, constant modernization and adaptation to new paradigms is imperative so that tourist experiences can maintain their competitiveness. Cultural tourism, one of the most competitive sectors of the tourist industry, has been adapting to global changes through the use of interactive technologies as a differentiating mechanism. Augmented Reality and Virtual Reality are two tools that enhance modernization and competitiveness, which are able to respond to the increasingly demanding needs of consumers. These technological innovations applied to a cultural experience manage to create a more immersive and interactive experience that attracts and satisfies the needs of tourists. This article aims to show the impact of Augmented Reality and Virtual Reality on the cultural offer through the analysis of the 'Ara as it Was' experience, which is considered a good example of the application of technology in the recreation of past real events while enhancing interactive learning.","2166-0727","978-9-8933-3436-2","10.23919/CISTI54924.2022.9820527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9820527","Augmented Reality;Virtual Reality;Cultural Tourism;Technology;Museums","Industries;Technological innovation;Cultural differences;Augmented reality;Information systems","augmented reality;computer aided instruction;cultural aspects;travel industry","augmented reality;virtual reality;cultural tourism;tourist experiences;tourist industry;interactive technologies;technological innovations;cultural experience;immersive experience;interactive experience;Ara as it Was'experience;interactive learning","","","","0","","14 Jul 2022","","","IEEE","IEEE Conferences"
"3DColAR: Exploring 3D Color Selection and Surface Painting for Head Worn Augmented Reality using Hand Gestures","L. M. Lawrence; G. Lee; M. Billinghurst; D. Rompapas",University of South Australia; University of South Australia; Brewed Engagement Extended Reality Labs; University of South Australia,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","974","975","Color selection and surface painting has been largely unexplored in head-worn Augmented Reality (AR) using hand gestures. In this demonstration we present 3DColAR: A system that implements several 2D and 3D techniques for color selection. We also implement two key approaches for painting a virtual 3D model using mid-air hand gestures. This includes a virtual pen which the user can grasp using their hand, akin to a real pen and the use of the user's fingertip directly on the virtual 3D model. We hope to explore how these various techniques effect user's efficiency and accuracy when performing surface painting of virtual objects using mid-air hand gestures via. several user studies.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757580","Augmented Reality;Human Computer Interaction","Solid modeling;Three-dimensional displays;Conferences;Color;User interfaces;Augmented reality;Painting","augmented reality;gesture recognition;helmet mounted displays","color selection;head-worn augmented reality;3DColAR;virtual 3D model;mid-air hand gestures;virtual pen;3D color selection;surface painting;user fingertip;user efficiency","","1","","10","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Gaze-Pinch Menu: Performing Multiple Interactions Concurrently in Mixed Reality","L. Lu; P. Duan; X. Shen; S. Zhang; H. Feng; Y. Flu","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","536","537","Performing an interaction using gaze and pinch has been certified as an efficient interactive method in Mixed Reality, for such techniques can provide users concise and natural experiences. However, executing a task with individual interactions gradually is inefficient in some application scenarios. In this paper, we propose the Hand-Pinch Menu, which core concept is to reduce unnecessary operations by combining several interactions. Users can continuously perform multiple interactions on a selected object concurrently without changing gestures by using this technique. The user study results show that our Gaze-Pinch Menu can improve operational efficiency effectively.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00150","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419267","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality","Three-dimensional displays;Conferences;Mixed reality;User interfaces;Task analysis;Augmented reality","augmented reality;gesture recognition;human computer interaction;virtual reality","Gaze-Pinch Menu;performing multiple interactions;Mixed Reality;efficient interactive method;natural experiences;individual interactions;Hand-Pinch Menu;user study results;operational efficiency","","","","6","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Bezier Surface Editing Using Marker-based Augmented Reality","D. O'Gwynn; J. Johnstone","University of Alabama, Birmingham; University of Alabama, Birmingham, USA","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","279","280","This paper describes a marker-based Augmented Reality system for editing tensor-product Bezier surfaces. It uses both a small- scale multi-marker mat and a two-marker wand as its interactive elements. The multi-marker mat establishes a coordinate frame for the display of the surface. Because of its size, it allows the user to rotate and translate the mat physically, even while editing it. The wand is used to select individual control points and edit their 3D position with respect to the surface's coordinate frame. Differentiation between selection and modification is accomplished through a bimodal association of two markers at the end of the wand. The wand's mode is switched by rolling it between the fingers.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480800","Augmented Reality;Marker-based Augmented Reality;Tangible User Interface;3D User Interface;3D Surface Design;Bezier Surface;H.5.2 [User Interfaces]: Input devices and strategies-Interaction styles;H.5.1 [Multimedia Information Systems]: Artificial;augmented;and virtual realities","Augmented reality;User interfaces;Displays;Fingers;Virtual reality;Switches;Control systems;Power system modeling;Multimedia systems;Information systems","user interfaces;virtual reality","Bezier surface editing;tensor-product Bezier surfaces editing;marker-based augmented reality system;small-scale multimarker;surface display;bimodal association","","","","7","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"Deepfake Portraits in Augmented Reality for Museum Exhibits","N. Wynn; K. Johnsen; N. Gonzalez",University of Georgia; University of Georgia; University of Georgia,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","513","514","In a collaboration with the Georgia Peanut Commission’s Education Center and museum in Georgia, USA, we developed an augmented reality app to guide visitors through the museum and offer immersive educational information about the artifacts, exhibits, and artwork displayed therein. Notably, our augmented reality system applies the First Order Motion Model for Image Animation to several portraits of individuals influential to the Georgia peanut industry to provide immersive animated narration and monologue regarding their contributions to the peanut industry. [4]","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585822","Augmented Reality;Museum;Agriculture;Education;Virtual Human;Deepfake","Industries;Engineering profession;Education;Buildings;Collaboration;Tablet computers;Animation","augmented reality;computer animation;mobile computing;museums;virtual reality","First Order Motion Model;Image Animation;Georgia peanut industry;immersive animated narration;monologue;deepfake portraits;museum exhibits;Georgia Peanut Commission's Education Center;USA;augmented reality app;offer immersive educational information;augmented reality system","","3","","5","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"ARWeather — An Augmented Reality Weather ystem","M. Heinrich; B. H. Thomas; S. Mueller","Universitaet Koblenz-Landau, Germany; University of South Australia, Australia; Universitaet Koblenz-Landau, Germany","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","187","188","This paper presents the design and development of an ARWeather simulation application, which can simulate various types of precipitation: rain, snow, and hail. We analysed various real occurrences weather types and how they could be simulated in a mobile Augmented Reality system. The Tinmith system is wearable computer system for the development and deployment of the final ARWeather system that allows for autonomous and free movement for the user. The users can move freely inside the simulated weather without limitation.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637359","I.3.7 [Three-Dimensional Graphics and Realism]: Virtual reality—Animation;I.6.8 [Types of Simulation]: Animation—Visual","Meteorology;Rain;Snow;Atmospheric modeling;Augmented reality;Solid modeling;Computational modeling","augmented reality;mobile computing;wearable computers","augmented reality weather system;ARWeather simulation application;weather types;mobile augmented reality system;Tinmith system;wearable computer system;ARWeather system;simulated weather","","3","2","6","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Exploration of spatial augmented reality on person","A. S. Johnson; Y. Sun","University of South Florida, USA; University of South Florida, USA","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","59","60","Spatial Augmented Reality (SAR) allows users to collaborate without need for see-through screens or head-mounted displays. We explore natural on-person interfaces using SAR. Spatial Augmented Reality on Person (SARP) leverages self-based psychological effects such as Self-Referential Encoding (SRE) and ownership by intertwining augmented body interactions with the self. Applications based on SARP could provide powerful tools in education, health awareness, and medical visualization. The goal of this paper is to explore benefits and limitations of generating ownership and SRE using the SARP technique. We implement a hardware platform which provides a Spatial Augmented Game Environment to allow SARP experimentation. We test a STEM educational game entitled `Augmented Anatomy' designed for our proposed platform with experts and a student population in US and China. Results indicate that learning of anatomy on-self does appear correlated with increased interest in STEM and is rated more engaging, effective and fun than textbook-only teaching of anatomical structures.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549362","augmented reality;self-referential encoding","Augmented reality;Anatomical structure;Psychology;Education;Encoding;Games;Sun","augmented reality;computer aided instruction;computer games;teaching","spatial augmented reality on person;natural on-person interface;self-referential encoding effect;ownership effect;self-based psychological effect;SARP technique;spatial augmented game environment;STEM educational game;Augmented Anatomy game;anatomy learning;science-technology-engineering-mathematics education;anatomical structure teaching","","5","1","16","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"LunAR Park: Augmented reality, retro-futurism & a ride to the moon","A. Betts; B. A. L. Silva; P. Oikonomou","University of Illinois at Chicago; University of Illinois at Chicago, Chicago, IL, US; Columbia University","2014 IEEE Virtual Reality (VR)","24 Apr 2014","2014","","","143","143","Museum spaces are ideal settings for interactive experiences that combine entertainment, education and innovative technologies. LunAR Park is an augmented reality application designed for a planetarium setting that utilizes existing lunar exhibits to immerse the visitor in an enhanced world of interactive lunar exploration referencing amusement park experiences. The application was originally presented as part of Moon Lust, an exhibition at the Adler Planetarium and Astronomical Museum in Chicago that explored global interests on lunar exploration and habitation through interactive technologies. The content of LunAR Park was inspired by pre-space age depictions of the lunar landscape at the original Luna Park in Coney Island, the advancement of lunar expeditions of the past century, and the romantic notions of future colonization of the moon. LunAR Park transforms four lunar themed exhibits into a virtual amusement park that brings the surface of the moon to life. The users interact with the augmented environment through iPads and navigate the virtual landscape by physically traversing the space around the four exhibits.","2375-5334","978-1-4799-2871-2","10.1109/VR.2014.6802092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802092","Augmented Reality;interaction;mixed reality;virtual reality","Moon;Augmented reality;Tablet computers;Space exploration;Educational institutions;Navigation","astronomy computing;augmented reality;education;entertainment;innovation management;museums","LunAR Park;augmented reality;retro-futurism;museum spaces;interactive experiences;entertainment;education;innovative technologies;planetarium setting;lunar exhibits;interactive lunar exploration;amusement park experiences;Moon Lust;lunar habitation;interactive technologies;prespace age depictions;lunar expeditions;virtual amusement park;iPads","","","","3","IEEE","24 Apr 2014","","","IEEE","IEEE Conferences"
"From Interactive to Adaptive Augmented Reality","D. Stricker; G. Bleser","German Research Center for Artificial Intelligence, University of Kaiserslautern, Kaiserslautern, Germany; German Research Center for Artificial Intelligence, University of Kaiserslautern, Kaiserslautern, Germany","2012 International Symposium on Ubiquitous Virtual Reality","10 Sep 2012","2012","","","18","21","This paper presents several results from the research department ""Augmented Vision"" of the German Research Center for Artificial Intelligence. The driving idea of this work is to move from traditional Augmented Reality (AR) systems, which are often limited to visualization and tracking components, to AR cognitive systems, which have or gradually build knowledge about the situation and intentions of the user. Such systems will basically be much more unobtrusive and adapt the information presentation to the users' actual needs. To reach this goal, strong progress must be done in several areas, starting with 3D scene digitalization and analysis, body modeling and motion capturing, and action and workflow recognition. An overview of current results and work-in-progress of the Augmented Vision group in those areas is presented and finally discussed.","","978-1-4673-2258-4","10.1109/ISUVR.2012.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6296800","adaptive augmented reality;3D scene reconstruction;on-body sensor network;task recognition","Cameras;Tracking;Augmented reality;Image reconstruction;Robustness;Videos;Solid modeling","artificial intelligence;augmented reality;cognitive systems;computer vision;knowledge engineering;natural scenes;solid modelling","interactive augmented reality;adaptive augmented reality;Augmented Vision;AR cognitive systems;3D scene digitalization;3D scene analysis;body modeling;motion capturing;action recognition;workflow recognition;augmented vision group work-in-progress;information presentation;user intentions;German Research Center for Artificial Intelligence","","3","","19","IEEE","10 Sep 2012","","","IEEE","IEEE Conferences"
"Haptically extended augmented prototyping","M. Dima; D. K. Arvind; J. Lee; M. Wright","University of Edinburgh, UK; University of Edinburgh, UK; University of Edinburgh, UK; University of Edinburgh, UK","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","169","170","This project presents a new display concept, which brings together haptics, augmented and mixed reality and tangible computing within the context of an intuitive conceptual design environment. The project extends the paradigm of augmented prototyping by allowing modelling of virtual geometry on the physical prototype, which can be touched by means of a haptic device. Wireless tracking of the physical prototype is achieved in three different ways by attaching to it a 'Speck', a tracker and Nintendo Wii Remote and it provides continuous tangible interaction. The physical prototype becomes a tangible interface augmented with mixed reality and with a novel 3D haptic design system.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637350","Tangible Computing;Mixed Reality;Augmented Reality;Product Design;Tactile & Haptic UIs;H.5.2 User Interfaces","Prototypes;Haptic interfaces;Mirrors;Augmented reality;Three dimensional displays;Geometry;Glass","augmented reality;haptic interfaces;software prototyping","extended haptic augmented prototyping;augmented reality;mixed reality;tangible computing;intuitive conceptual design environment;virtual geometry modelling;haptic device;wireless tracking;3D haptic design system","","2","","7","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"First Steps Towards Augmented Reality Interactive Electronic Music Production","V. Bauer; T. Bouchara","Université Paris-Saclay CNRS, LISN; Université Paris-Saclay CNRS, LISN","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","90","93","Immersive music production starts to integrate Virtual Reality (VR) and Augmented Reality (AR) technologies. VR creates virtual spaces separated from real-life, often based on the performer-audience relationship. AR goes further by expanding the usual user listening experience over headphones but remains unexplored. The paper presents a work in progress of an AR compositional platform which allows to create interactive music experiences, through the use case of an electronic music creation.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419126","Spatialized music production;Augmented reality;New interface for musical expression;Applied computing—Arts and humanities—Media arts;Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality","Headphones;Three-dimensional displays;Conferences;Production;User interfaces;Electronic music;Augmented reality","augmented reality;electronic music;music;virtual reality","VR;virtual spaces;performer-audience relationship;usual user listening experience;interactive music experiences;electronic music creation;steps towards Augmented Reality interactive electronic music production;immersive music production","","1","","31","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Autocalibration of an electronic compass for augmented reality","Xiaoming Hu; Yue Liu; Yongtian Wang; Yanling Hu; Dayuan Yan","School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","182","183","Electronic compass is often used to provide the absolute heading reference for tracking the user's head and hands in virtual reality (VR) and augmented reality (AR), especially for outdoor AR applications. However, compass is vulnerable to environment magnetism disturbance. Existing compass calibration methods require complex steps and true heading reference which is often impossible to be obtained in outdoor AR applications, and is useful only when compass is in horizontal plane. An autocalibration method without the need of heading reference and redundant sensors is proposed in This work. First the compass error model based on physical principle is presented, then the algorithm to calculate the compensation coefficients with a set of sample measurements of the sensors in the compass is described. Because the influence of the environmental disturbance has been effectively compensated, the calibrated compass can provided accurate heading even when it is under large tilt attitude.","","0-7695-2459-1","10.1109/ISMAR.2005.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544684","","Augmented reality;Calibration;Magnetic sensors;Magnetometers;Magnetic heads;Virtual reality;Control systems;Table lookup;Gravity;Accelerometers","augmented reality;compasses;calibration;sensors","electronic compass autocalibration;augmented reality;absolute heading reference;virtual reality;sensors","","2","","3","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Depth judgment tasks and environments in near-field augmented reality","G. Singh; J. E. Swan; J. A. Jones; S. R. Ellis","Mississippi State University, USA; Mississippi State University, USA; Mississippi State University, USA; NASA Ames Research Center, USA","2011 IEEE Virtual Reality Conference","29 Apr 2011","2011","","","241","242","In this poster abstract we describe an experiment that measured depth judgments in optical see-through augmented reality at near-field distances of 34 to 50 centimeters. The experiment compared two depth judgment tasks: perceptual matching, a closed-loop task, and blind reaching, a visually open-loop task. The experiment tested each of these tasks in both a real-world environment and an augmented reality environment, and used a between-subjects design that included 40 participants. The experiment found that matching judgments were very accurate in the real world, with errors on the order of millimeters and very little variance. In contrast, matching judgments in augmented reality showed a linear trend of increasing overestimation with increasing distance, with a mean overestimation of ~1 cm. With reaching judgments participants underestimated ~4.5 cm in both augmented reality and the real world. We also discovered and solved a calibration problem that arises at near-field distances.","2375-5334","978-1-4577-0038-5","10.1109/VR.2011.5759488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759488","depth perception;augmented reality;optical see-through display;x-ray vision","Calibration;Augmented reality;Observers;Visualization;Adaptive optics;Solid modeling","augmented reality;calibration;rendering (computer graphics);visual perception","near-field augmented reality;depth judgments;optical see-through augmented reality;perceptual matching;blind reaching;visually open-loop task;closed-loop task;calibration problem","","4","","4","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"Augmented Reality-Based Personalized Virtual Operative Anatomy for Neurosurgical Guidance and Training","W. Si; X. Liao; Q. Wang; P. -A. Heng","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Department of Computer Science and Engineering, The Chinese University of Hong Kong","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","683","684","This paper presents a novel augmented reality (AR) interactive environment for neurosurgical training. Comparing with traditional virtual reality based neurosurgical simulator, our system provides a more natural and intuitive fashion for surgeons. To achieve holographic visualization of virtual brain on 3D-printed skull (workspace), the first step is to reconstruct the personalized anatomy structure from segmented MR imaging. Then, tailored to the computational power of HoloLens, we employ the mass-spring method to model the mechanical response of brain. After that, a precise registration method is employed to map the virtual-real spatial information, which can overlay the virtual operative brain on workspace. In addition, bimanual haptic interface is also integrated into our simulator, which is more similar with real neurosurgery. In experiments, we conduct accuracy validation on our registration method, as well as the validity test on the developed simulators. The results demonstrate that our simulator can provide high-accuracy augmented visualization effects and deep immersion for novice surgeons.","","978-1-5386-3365-6","10.1109/VR.2018.8446450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446450","Human-centered computing-Visualization-Visualization techniques-Augmented reality;Human-centered computing-Visualization-Surgical simulation","Neurosurgery;Training;Augmented reality;Brain modeling;Solid modeling;Three-dimensional displays","augmented reality;biomedical education;biomedical MRI;brain;computer based training;haptic interfaces;image registration;image segmentation;medical image processing;neurophysiology;surgery","augmented reality-based personalized virtual operative anatomy;neurosurgical guidance;augmented reality interactive environment;neurosurgical training;neurosurgical simulator;holographic visualization;virtual brain;3D-printed skull;personalized anatomy structure;mass-spring method;virtual-real spatial information;virtual operative brain;virtual reality;segmented MR imaging;HoloLens;validity test","","12","","3","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Enabling Rapid Creation of Content for Consumption in Mobile Augmented Reality","P. Belimpasakis; Y. You; P. Selonen","Mixed Reality Solutions, Nokia Research Center, Finland; Mixed Reality Solutions, Nokia Research Center, Finland; Mixed Reality Solutions, Nokia Research Center, Finland","2010 Fourth International Conference on Next Generation Mobile Applications, Services and Technologies","26 Aug 2010","2010","","","1","6","As smart phones are getting powerful multimedia devices, with a plethora of sensors, they are the perfect enablers for Augmented Reality, allowing users to see the real world through a magic lens. Augmented Reality applications and services have been typically utilized in a limited number of domains, while adding new content is typically a privilege of developers, as programming skills are required for linking to existing clients or systems. In this paper we study how power users and small businesses can bring their content, advertizing and general data to an Augmented Reality view, with minimal effort. We present three prototyped approaches based on the Image Space mirror world service.","2161-2897","978-1-4244-7648-0","10.1109/NGMAST.2010.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558248","Mixed Reality;Augmented Reality;Content Creation","Augmented reality;Business;Mobile communication;Visualization;Three dimensional displays;Browsers","augmented reality;image processing;mobile computing","content creation;mobile augmented reality;smart phone;multimedia device;sensor plethora;magic lens;image space mirror world service","","8","16","15","IEEE","26 Aug 2010","","","IEEE","IEEE Conferences"
"An event-based data distribution mechanism for collaborative mobile augmented reality and virtual environments","D. Brown; S. Julier; Y. Baillot; M. A. Livingston","ITT Advanced Engineering and Sciences, Alexandria, VA, USA; ITT Advanced Engineering and Sciences, Alexandria, VA, USA; ITT Advanced Engineering and Sciences, Alexandria, VA, USA; Naval Research Laboratory, Inc., DC, USA","IEEE Virtual Reality, 2003. Proceedings.","2 Apr 2003","2003","","","23","29","The full power of mobile augmented and virtual reality systems is realized when these systems are connected to one another to immersive virtual environments, and to remote information servers. Connections are usually made through wireless networks. However, wireless networks cannot guarantee connectivity and their bandwidth can be highly constrained. The authors present a robust event-based data distribution mechanism for mobile augmented reality and virtual environments. It is based on replicated databases, pluggable networking protocols, and communication channels. We demonstrate the mechanism in the Battlefield Augmented Reality System (BARS) situation awareness system, which is composed of several mobile augmented reality systems, immersive and desktop-based virtual reality systems, a 2D map-based multi-modal system, handheld PCs, and other sources of information.","1087-8270","0-7695-1882-6","10.1109/VR.2003.1191117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191117","","Collaboration;Augmented reality;Virtual environment;Virtual reality;Wireless networks;Network servers;Bandwidth;Robustness;Databases;Protocols","augmented reality;groupware;mobile computing;replicated databases;notebook computers","event-based data distribution mechanism;collaborative mobile augmented reality;virtual environments;mobile augmented systems;virtual reality systems;remote information servers;wireless networks;connectivity;robust event based data distribution mechanism;mobile augmented reality;replicated databases;pluggable networking protocols;communication channels;Battlefield Augmented Reality System;BARS situation awareness system;mobile augmented reality systems;immersive virtual reality systems;desktop-based virtual reality systems;2D map-based multi-modal system;handheld PCs","","6","1","17","IEEE","2 Apr 2003","","","IEEE","IEEE Conferences"
"Optical occlusion and shadows in a 'see-through' augmented reality display","E. W. Tatham","Augmented Reality Research Group, Faculty of Mathematics and Computing, Open University, Milton Keynes, UK","1999 IEEE International Conference on Information Visualization (Cat. No. PR00210)","6 Aug 2002","1999","","","128","131","As distinct from virtual reality, which seeks to immerse the user in a fully synthetic world, computer-augmented reality systems supplement sensory input with computer-generated information. The principle has, for a number of years, been employed in the head-up display systems used by military pilots and usually comprises an optical display arrangement based on part-silvered mirrors that reflect computer graphics into the eye in such a way that they appear superimposed on the real-world view. Compositing real and virtual worlds offers many new and exciting possibilities but also presents some significant challenges, particularly with respect to applications for which the real and virtual elements need to be integrated convincingly. Unfortunately, the inherent difficulties are compounded further in situations where a direct, unpixellated view of the real world is desired, since current optical systems do not allow real-virtual occlusion, nor a number of other essential visual interactions. The paper presents a generic model of augmented reality as a context for discussion, and then describes a simple but effective technique for providing a significant degree of control over the visual compositing of real and virtual worlds.","1093-9547","0-7695-0210-5","10.1109/IV.1999.781548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=781548","","Augmented reality;Computer displays;Military computing;Lenses;Keyboards;Application software;Mathematics;Optical computing;Context modeling;Identity-based encryption","augmented reality;computer displays;computer graphics","optical occlusion;see-through augmented reality display;virtual reality;computer-augmented reality systems;computer-generated information;head-up display systems;optical display arrangement;part-silvered mirrors;computer graphics;real-world view;virtual worlds;virtual elements;unpixellated view;real-virtual occlusion;augmented reality;visual compositing","","1","4","11","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Haptic augmented reality: Modulation of real object stiffness","S. Jeon; S. Choi","Haptics and Virtual Reality Laboratory, Department of Computer Science and Engineering, POSTECH, South Korea; Haptics and Virtual Reality Laboratory, Department of Computer Science and Engineering, POSTECH, South Korea","World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","3 Apr 2009","2009","","","384","385","Haptic augmented reality allows a user to feel the sensation of a real object augmented with synthetic haptic stimuli created by a haptic interface. For example, the user feels a soft sponge as if it is a stiffer rubber. This demonstration presents a haptic augmented reality framework in which the stiffness of a real object is modulated with additional virtual haptic feedback. A haptic interface is extended with a force sensor, and efficient and effective algorithms for contact detection and stiffness modulation are implemented with closed-loop control. This work can serve as an initial building block towards a general haptic augmented reality system.","","978-1-4244-3858-7","10.1109/WHC.2009.4810907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810907","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces and Presentation]: User Interfaces—Haptic I/O","Haptic interfaces;Augmented reality;Virtual reality;Rubber;Shape control;Rendering (computer graphics);Virtual environment;Teleoperators;Cities and towns;Computer science","augmented reality;force sensors;haptic interfaces","haptic augmented reality;real object stiffness;object augmentation;synthetic haptic stimuli;haptic interface;virtual haptic feedback;force sensor;contact detection;stiffness modulation;closed-loop control","","3","","4","IEEE","3 Apr 2009","","","IEEE","IEEE Conferences"
"Semantic Labeling and Object Registration for Augmented Reality Language Learning","B. Huynh; J. Orlosky; T. Höllerer","University of California Santa Barbara, Santa Barbara, CA, US; Osaka Daigaku, Suita, Osaka, JP; University of California Santa Barbara, Santa Barbara, CA, US","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","986","987","We propose an Augmented Reality vocabulary learning interface in which objects in a user's environment are automatically recognized and labeled in a foreign language. Using AR for language learning in this manner is still impractical for a number of reasons. Scalable object recognition and consistent labeling of objects is still a significant challenge, and interaction with arbitrary physical objects in AR scenes has consequently not been well explored. To help address these challenges, we present a system that utilizes real-time object recognition to perform semantic labeling and object registration in Augmented Reality. We discuss its implementation, our motivations in designing it, and how it can be applied to AR language learning applications.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797804","Human-centered computing—Mixed and augmented reality;Theory and algorithms for application domains—Semi-supervised learning","Calibration;Gaze tracking;Labeling;Augmented reality;Object recognition;Three-dimensional displays;Cameras","augmented reality;computer aided instruction;learning (artificial intelligence);object recognition;user interfaces;virtual reality languages;vocabulary","real-time object recognition;semantic labeling;object registration;augmented reality language learning;foreign language;scalable object recognition;arbitrary physical objects;augmented reality vocabulary learning interface;AR language learning applications;user environment","","1","","5","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Augmented Reality Technology: Current Applications, Challenges and its Future","J. Singh; Urvashi; G. Singh; S. Maheshwari","Department of CSE, Chandigarh University, Mohali, India; Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Department of Applied Science, ABES Engineering College, Uttar Pradesh, India","2022 4th International Conference on Inventive Research in Computing Applications (ICIRCA)","29 Dec 2022","2022","","","1722","1726","The term augmented reality (AR) refers to a technology that unites virtual things with the actual environment and communicate directly with one another. Nowadays, augmented reality is receiving a lot of study attention. It is one of the few ideas that, though formerly deemed impractical and unattainable and can today be used quite successfully. Research and development on the AR are still in their early stages at many colleges and high-tech enterprises. Like our smart phones and laptops, many researchers predict that it will be one of the most popular technologies in the future. This paper provides a comprehensive study of AR including its working, applications, current challenges and future trends.Although augmented reality applications are used in many areas, the most important areas are focused in this paper. In the light of all these, this study is a compilation study and in the context attention is drawn to usage of augmented reality in current life scenario.","","978-1-6654-9707-7","10.1109/ICIRCA54612.2022.9985665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985665","Augmented Reality;Applications of Augmented Reality;Challenges of Augmented Reality;Future of Augmented Reality","Portable computers;Market research;Augmented reality;Smart phones;Research and development","augmented reality","AR;augmented reality applications;high-tech enterprises;laptops;smart phones;virtual things","","3","","27","IEEE","29 Dec 2022","","","IEEE","IEEE Conferences"
"IEEE Draft Standard for an Augmented Reality Learning Experience Model","",,"IEEE P1589/D3, October 2019","1 Nov 2019","2019","","","1","67","Augmented Reality (AR) promises to provide significant boosts in operational efficiency by making information available to employees needing task support in context in real time. To support according implementations of AR training systems,this document proposes an overarching integrated conceptual model that describes interactions between the physical world, the user, and digital information, the context for AR-assisted learning and other parameters of the environment. It defines two data models and their binding to XML and JSON for representing learning activities (also known as employee tasks and procedures) and the learning environment in which these tasks are performed (also known as the workplace). The interoperability specification and standard is presented in support of an open market where interchangeable component products provide alternatives to monolithic Augmented Reality-assisted learning systems. Moreover, it facilitates the creation of experience repositories and online marketplaces for Augmented Reality-enabled learning content. Specific attention was given to reuse and repurposing of existing learning content and catering to ‘mixed’ experiences combining real world learner guidance with the consumption (or production) of traditional contents such as instructional video material or learning apps and widgets.","","978-1-5044-6238-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890049","Augmented Reality;E-Learning;Workplace Training;Learning Activity;Learning Experience;Performance Support;Immersive Learning Environment;Mixed Reality","IEEE Standards;Augmented reality;Machine learning;Training data;Immersive learning;Virtual reality","","","","","","","","1 Nov 2019","","","IEEE","IEEE Standards"
"[POSTER] CoVAR: Mixed-Platform Remote Collaborative Augmented and Virtual Realities System with Shared Collaboration Cues","T. Piumsomboon; A. Dey; B. Ens; G. Lee; M. Billinghurst","School of Information Technology and Mathematical Science, University of South Australia; School of Information Technology and Mathematical Science, University of South Australia; School of Information Technology and Mathematical Science, University of South Australia; School of Information Technology and Mathematical Science, University of South Australia; University of South Australia, Adelaide, SA, AU","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","218","219","We present CoVAR, a novel Virtual Reality (VR) and Augmented Reality (AR) system for remote collaboration. It supports collaboration between AR and VR users by sharing a 3D reconstruction of the AR user's environment. To enhance this mixed platform collaboration, it provides natural inputs such as eye-gaze and hand gestures, remote embodiment through avatar's head and hands, and awareness cues of field-of-view and gaze cue. In this paper, we describe the system architecture, setup and calibration procedures, input methods and interaction, and collaboration enhancement features.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.72","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088489","mixed reality;remote collaboration;eye tracking","Collaboration;Augmented reality;Calibration;Image reconstruction;Three-dimensional displays;Tracking","augmented reality;avatars;calibration;groupware","shared collaboration;VR;remote collaboration;mixed platform collaboration;remote embodiment;awareness cues;gaze cue;collaboration enhancement features;CoVAR;mixed-platform remote collaborative augmented reality system;mixed-platform remote collaborative virtual reality system;AR user environment;3D reconstruction","","28","2","6","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Reality tooning: fast non-photorealism for augmented video streams","J. Fischer; D. Bartz; W. Strasser","WSI/GRIS-VCM, University of Tübingen, Germany; WSI/GRIS-VCM, University of Tübingen, Germany; WSI/GRIS-VCM, University of Tübingen, Germany","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","186","187","Recently, we have proposed a novel approach to generating augmented video streams. The output images are a non-photorealistic reproduction of the augmented environment. Special stylization methods are applied to both the background camera image and the virtual objects. This way, the graphical foreground and the real background images are rendered in a similar style, so that they are less distinguishable from each other. Here, we present a new algorithm for the cartoon-like stylization of augmented reality images, which uses a novel post-processing filter for cartoon-like color segmentation and high-contrast silhouettes. In order to make a fast post-processing of rendered images possible, the programmability of modern graphics hardware is exploited. The system is capable of generating a stylized augmented video stream of high visual quality at real-time frame rates.","","0-7695-2459-1","10.1109/ISMAR.2005.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544686","","Streaming media;Filters;Augmented reality;Color;Rendering (computer graphics);Graphics;Image edge detection;Cameras;Real time systems;Pipelines","video streaming;augmented reality;rendering (computer graphics);image colour analysis;image segmentation;realistic images;computer graphic equipment","reality tooning;augmented video streams;nonphotorealistic reproduction;special stylization method;background camera image;virtual object;augmented reality images;cartoon-like color segmentation;rendered images;graphics hardware","","4","2","2","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Testing information delivery methods using augmented reality","P. Jackson; J. Ealey-Sawyer; I-Li Lu; S. Jones","Boeing Aerospace Company, Bellevue, WA, USA; Morris Brown College, Atlanta, GA, USA; Boeing Aerospace Company, Bellevue, WA, USA; Boeing Aerospace Company, Bellevue, WA, USA","Proceedings IEEE and ACM International Symposium on Augmented Reality","6 Aug 2002","2001","","","171","172","This paper describes an experiment conducted to compare three technologies in delivering a multi-step maintenance procedure to a factory worker. Optical see-through augmented reality, a web browser and a traditional paper-based manual used as control were the three technologies. Both augmented reality and the web browser expoited voice recognition and text to speech capability thus enabling a hands free user interface. The measure of the experiment was time to completion. An entrance and exit questionnaire were given to subjects to obtain qualitative measurements. Thirty-six individuals participated in a randomized block experiment design with repeated measures.","","0-7695-1375-1","10.1109/ISAR.2001.970527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=970527","","Testing;Augmented reality;Production facilities;Manuals;Optical control;Paper technology;Speech recognition;Text recognition;Speech synthesis;User interfaces","augmented reality;maintenance engineering","multi-step maintenance;augmented reality;web browser;factory worker;voice recognition;text to speech;handsfree user interface;optical see-through augmented reality;maintenance","","","6","","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Evaluating User Acceptance using WebXR for an Augmented Reality Information System","F. Meyer; C. Gehrke; M. Schäfer","Institute of Computer Science, Hochschule Ruhr West; Institute of Computer Science, Hochschule Ruhr West; Institute of Computer Science, Hochschule Ruhr West","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","418","419","Augmented Reality has a long history and has seen major technical advantages in the last years. With WebXR, a new web standard, Mobile Augmented Reality (MAR) applications are now available in the web browser. With our work, we implemented an Augmented Reality Information System and conducted a case study to evaluate the user acceptance of such an application build with WebXR. Our results indicate that the user acceptance regarding web-based MAR applications for our specific use case seems to be given. With our proposed architecture we also lay the foundation for other AR information systems.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419122","User Accpetance;Augmented Reality;WebXR;Information System","Three-dimensional displays;Tracking;Conferences;User interfaces;Browsers;History;Augmented reality","augmented reality;mobile computing;online front-ends","augmented reality information system;user acceptance;WebXR;AR information systems;Web standard;mobile augmented reality applications;Web browser;Web-based MAR applications","","1","","5","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Mobile Technology and Extended Reality for Deaf People: A systematic review of the open access literature","E. Del Pezo Izaguirre; M. J. Abásolo; C. A. Collazos","Ingeniería Informática, Universidad Santa María, Guayaquil, Ecuador; Facultad de Informática, Universidad Nacional de La Plata CICPBA, La Plata, Argentina; Departamento de Sistemas, Universidad del Cauca, Popayán, Cauca, Colombia","2020 XV Conferencia Latinoamericana de Tecnologias de Aprendizaje (LACLO)","19 Mar 2021","2020","","","1","8","The present study is a systematic review of the scientific literature, published between 2006 and early 2020 with open access, which aims to know the use, by non-hearing people, of mobile technology and Extended Reality, encompassing this term to Virtual Reality, Augmented Reality and Mixed Reality applications that seek to improve human-computer interaction through sensory experiences. Particularly, applications used for teaching-learning are analyzed, inquiring, among other questions, what are the didactic themes, the target groups and the sign language used. The results show a high predisposition to the use of mobile technology due to the ease of use of visual / tactile resources. There is still a reduced but promising use of Extended Reality, which allows a field of application of new contributions for the development of the deaf community.","","978-1-7281-9268-0","10.1109/LACLO50806.2020.9381186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381186","deaf;hearing impaired;Extended Reality;Augmented Reality;Virtual Reality;Mobile Technology;education","Visualization;Systematics;Extended reality;Open Access;Mixed reality;Gesture recognition;Augmented reality","augmented reality;computer aided instruction;handicapped aids;mobile computing;teaching;virtual reality","human-computer interaction;mobile technology;Extended Reality;deaf people;systematic review;open access literature;scientific literature;nonhearing people;Virtual Reality;Augmented Reality;Mixed Reality applications","","1","","0","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"Augmented reality kanji learning","D. Wagner; I. Barakonyi","University of Technology, Vienna, Vienna, Austria; University of Technology, Vienna, Vienna, Austria","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","335","336","ARToolKit programmers are familiar with the kanji symbols supplied with the distribution. Most of them do not know what these kanji symbols mean. We propose a piece of educational software that uses collaborative augmented reality (AR) to teach users the meaning of kanji symbols. The application is laid out as a two player augmented reality computer game. The novelty of our approach is that we do not use regular workstations or laptops to host the AR (augmented reality) application. Instead we use fully autonomous PDAs, running the application together with an optical marker-based tracking module that makes this application not only available for a broad audience but also optimally mobile.","","0-7695-2006-5","10.1109/ISMAR.2003.1240747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240747","","Augmented reality;Application software;Personal digital assistants;Collaborative software;Workstations;Libraries;Cameras;Programming profession;Collaborative work;Portable computers","augmented reality;courseware;notebook computers;entertainment;computer games","augmented reality;kanji learning;ARToolKit programmers;kanji symbols;educational software;collaborative AR;AR computer game;workstations;laptops;AR application;PDA;optical marker-based tracking;tracking module;broad audience","","31","6","6","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"A city-planning system based on augmented reality with a tangible interface","H. Kato; K. Tachibana; M. Tanabe; T. Nakajima; Y. Fukuda","Osaka University, Japan; Hiroshima City University, Japan; Knack Images Production Center; Hiroshima City University, Japan; Hiroshima Institute of Technology, Japan","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","340","341","This demonstration shows a city-planning system based on augmented reality with tangible user interface. Miniature models, illustrations and graphical computer displays have been used for the comparison and consideration in city-planning process. Augmented reality technology enables users to consider city plans more effectively and easily. One important issue of the augmented reality environment is how user can manipulate 3D structures that are displayed as virtual objects. It has to be intuitive and easy so that it may not disturb user's thought. We propose a new direct manipulation method based on the concept called tangible user interface. User holds a transparent cup upside down and can pick up, move or delete a virtual object by using it.","","0-7695-2006-5","10.1109/ISMAR.2003.1240750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240750","","Augmented reality;Computer displays;Urban planning;Computational modeling;Cameras;User interfaces;Production systems;Cities and towns;Computer simulation;Shape","town and country planning;augmented reality;computer displays;haptic interfaces","city-planning system;augmented reality;tangible interface;user interface;miniature models;computer graphics;computer displays;city-planning process;3D manipulation;3D structures;virtual objects;manipulation method","","15","4","3","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Hotspots and Trends of Virtual Reality, Augmented Reality and Mixed Reality in Education Field","H. Zhang; Y. Cui; H. Shan; Z. Qu; W. Zhang; L. Tu; Y. Wang","School of Media Science / School of Journalism, Northeast Normal University, Changchun, China; School of Information Science and Technology, Northeast Normal University, Changchun, China; School of Information Science and Technology, Northeast Normal University, Changchun, China; School of Information Science and Technology, Northeast Normal University, Changchun, China; School of Media Science / School of Journalism, Northeast Normal University, Changchun, China; School of Information Science and Technology, Northeast Normal University, Changchun, China; School of Media Science / School of Journalism, Northeast Normal University, Changchun, China","2020 6th International Conference of the Immersive Learning Research Network (iLRN)","4 Aug 2020","2020","","","215","219","With developments in computer graphics and simulation technology, virtual reality (VR), augmented reality (AR) and mixed reality (MR) have been more widely used in several areas of education. To explore and predict hotspots and research trends of VR, AR and MR in education, knowledge mapping is used to provide visualizations of publishing trends, countries, institutions and author co-citations based on Web of Science database in the last ten years. Nine hotspots and trends, including cognitive load, learning environment, knowledge acquisition, training, gamification, assessment, children education, engineering education, and higher medical education, are discovered in the study to show us future research directions in the education field.","","978-1-7348995-0-4","10.23919/iLRN47897.2020.9155170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155170","virtual reality;augmented reality;mixed reality;educational research;citespace;knowledge mapping","Training;Market research;Games;Augmented reality;Visualization","augmented reality;biomedical education;computer based training;knowledge acquisition;serious games (computing)","education field;virtual reality;augmented reality;mixed reality;computer graphics;simulation technology;engineering education;higher medical education;VR","","7","","32","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Virtual reality and augmented reality in digestive surgery","L. Soler; S. Nicolau; J. Schmid; C. Koehl; J. Marescaux; X. Pennec; N. Ayache","Virtual-surg, IRCAD, Strasbourg, France; Virtual-surg, IRCAD, Strasbourg, France; Virtual-surg, IRCAD, Strasbourg, France; Virtual-surg, IRCAD, Strasbourg, France; Virtual-surg, IRCAD, Strasbourg, France; INRIA-Epidaure, Sophia-Antipolis, France; INRIA-Epidaure, Sophia-Antipolis, France","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","278","279","Medical image processing led to a major improvement of patient care: the 3D modeling of patients from their CT-scan or MRI provides an improved surgical planning and simulation allows to train the surgical gesture before carrying it out. These two preoperative steps can be used intra-operatively with the development of augmented reality (AR). In this paper, we present the tools we developed to provide our first prototypal AR guiding system for abdominal surgery.","","0-7695-2191-6","10.1109/ISMAR.2004.64","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383075","","Virtual reality;Augmented reality;Surgery;Abdomen;Pathology;Biomedical imaging;Magnetic resonance imaging;Liver neoplasms;Visualization;Medical simulation","augmented reality;surgery;medical image processing;patient care","virtual reality;augmented reality;digestive surgery;medical image processing;patient care;3D modeling;surgical planning;surgical simulation;AR guiding system","","18","3","10","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"[POSTER] The Augmented Library: An Approach for Improving Users Awareness in a Campus Library","A. A. Cervera-Uribe","Facultad de Matemáticas, Universidad Autónoma de Yucatán","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","15","19","Most existing libraries use floor plans and call numbers in order to locate books rather than providing truly user's awareness of the extensive collections and services for students in the library context. With a collection of more than 48,568 volumes at the Engineering and Exact Sciences library of the Universidad Autónoma de Yucatán (UADY), the task of looking for a book can be really a time-consuming and frustrating task, specially for newcomers. This paper proposes an Augmented Reality (AR) based application which aims to solve users spatial unawareness at library by providing an AR shelf searching system, and to assist students and newcomers by providing a mobile guide with library information services into library. In this work, the results of a pilot study are presented demonstrating that user's experiences and performance at library were enhanced through the use of augmented reality technology.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088439","library;augmented reality;mobile guide;localization","Libraries;Augmented reality;Cameras;Mobile communication;User interfaces;Mobile handsets","academic libraries;augmented reality;educational institutions;information services;library automation;mobile computing","campus library;floor plans;book;extensive collections;library context;users spatial unawareness;library information services;augmented reality technology;augmented library;call numbers;Engineering and Exact Sciences library;Universidad Autónoma de Yucatán;UADY;augmented reality based application;AR shelf searching system;mobile guide","","3","","8","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"In your hand computing: tangible interfaces for mixed reality","J. M. S. Dias; N. Barata; P. Santos; A. Correia; P. Nande; R. Bastos","Edificio ISCTE, ADETTI, Portugal; Edificio ISCTE, ADETTI, Portugal; Edificio ISCTE, ADETTI, Portugal; Edificio ISCTE, ADETTI, Portugal; Edificio ISCTE, ADETTI, Portugal; Edificio ISCTE, ADETTI, Portugal","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","29","31","In this paper, mixed reality (MR) is proposed as a new framework that supplements the definition of augmented reality (AR). MR includes the continuum transitions from real environments (RE), to AR, passing through augmented virtuality (AV) towards fully virtual environments (VE). In the context of MR and according to H. Kato et al. (2001), tangible interfaces are those in which: 1) each virtual object is registered to a (tangible) physical object; and 2) the user interacts with virtual objects by manipulating the corresponding tangible object. Tangible interfaces are described in the literature as being intuitive, since physical object manipulations are mapped to virtual object operations. Users generally require intuitive real-time interaction in MR. Having this in mind, we have come up with a series of novel sensor-less and cable-less tangible interfaces. In the present work, we add novel uses for these interfaces since they are the only physical means of user interaction that triggers the functionalities of the system.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320422","","Computer interfaces;Virtual reality;Augmented virtuality;Visualization;Fingers;Trajectory;Cameras;Augmented reality;Virtual environment;User interfaces","augmented reality;gesture recognition","mixed reality;augmented reality;real environments;augmented virtuality;virtual environments;tangible interfaces;user interaction;virtual objects;real-time interaction;in-your-hand computing","","2","","6","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"An Extended Marker-Based Tracking System for Augmented Reality","J. Jun; Q. Yue; Z. Qing","State Key Lab of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Lab of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Lab of Virtual Reality Technology and Systems, Beihang University, Beijing, China","2010 Second International Conference on Modeling, Simulation and Visualization Methods","26 Aug 2010","2010","","","94","97","Fiducial marker systems consist of unique patterns mounted in the environment and computer vision algorithms that help automatically find features in digital camera images. They are useful for Augmented Reality (AR), robot navigation, 3D modeling, and other applications. In this paper we introduce an extension of marker-based approaches. For some applications which need a large working space, we mounted markers onto the ceiling. Two cameras are fixed onto the head-mounted displays (one captures the markers and the other captures the real scene). After calibration of the two cameras, the pose of the camera captures the real scene can be obtained to merge virtual scene.","","978-1-4244-7078-5","10.1109/WMSVM.2010.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558353","Augmented Reality;Tracking;Marker-based Calibration;ARToolkitPlus","Cameras;Augmented reality;Calibration;Image edge detection;Three dimensional displays;Tracking;Transmission line matrix methods","augmented reality;calibration;cameras;image processing","extended marker-based tracking system;augmented reality;fiducial marker systems;head-mounted displays;camera pose;camera calibration","","3","1","10","IEEE","26 Aug 2010","","","IEEE","IEEE Conferences"
"Teachers' and Students' Perceptions toward Augmented Reality Materials","M. -C. Hsieh","Department of Information Management, Fortune Institute of Technology, Kaohsiung, Taiwan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","1 Sep 2016","2016","","","1180","1181","Augmented reality in learning has been widely studied, but mostly from the student's perspective and learning effectiveness. The few researches explored the instructors' and students' perceptions. In this paper, we developed an Augmented Reality English Learning System to examine teachers' and students' perceptions toward AR materials. The teachers and students were interviewed to explore their viewpoints about ARELS teaching after finishing learning the AR English course. The AR English Materials could raise the learning motivation and enhance students' concentration and affect their learning behaviors.","","978-1-4673-8985-3","10.1109/IIAI-AAI.2016.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557795","augmented reality;augmented reality materials;augmented reality learning;English teaching","Education;Augmented reality;Three-dimensional displays;Interviews;Multimedia communication;Learning systems","augmented reality;teaching","student perceptions;teacher perceptions;augmented reality english learning system;ARELS teaching;AR english materials;learning motivation;learning behaviors;student concentration enhancement","","4","","10","IEEE","1 Sep 2016","","","IEEE","IEEE Conferences"
"The effects of shadow representation of virtual objects in augmented reality","N. Sugano; H. Kato; K. Tachibana","Hiroshima City University, Japan; Graduate School of Engineering Science, Osaka University, Japan; Hiroshima City University, Japan","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","76","83","In this paper, we describe the effects of shadow representation of virtual objects in augmented reality. Optical consistency is important in order to create realistic augmented reality environments. We focus on providing accurate shadows and made two assumptions about the effects of shadow representation of virtual objects. First, that the shadow of virtual objects provides a stronger connection between the real world and virtual objects and so increases virtual object presence. Second, that the shadow of virtual objects provides depth cues and so makes three-dimensional perceptions easier for the users of the interface. We report on two experiments that show that these assumptions are correct. We also find that users report that a characteristic shadow shape provides more virtual object presence in spite of incorrect virtual light direction.","","0-7695-2006-5","10.1109/ISMAR.2003.1240690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240690","","Augmented reality;Layout;Geometrical optics;Rendering (computer graphics);Shadow mapping;Light sources;Material properties;Lighting;Shape;Cameras","augmented reality;image representation;lighting;rendering (computer graphics);user interfaces","shadow representation;virtual objects;augmented reality;optical consistency;real world;object presence;three-dimensional perceptions;user interface;virtual light direction;virtual reality;virtual environment","","45","7","7","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Geometric Modifications Applied to Real Elements in Augmented Reality","C. W. M. Leão; J. P. Lima; V. Teichrieb; J. Kelner; E. S. Albuquerque","Virtual Reality and Multimedia Research Group, Federal University of Pernambuco (UFPE), Recife, Brazil; Virtual Reality and Multimedia Research Group, Federal University of Pernambuco (UFPE), Recife, Brazil; Virtual Reality and Multimedia Research Group, Federal University of Pernambuco (UFPE), Recife, Brazil; Virtual Reality and Multimedia Research Group, Federal University of Pernambuco (UFPE), Recife, Brazil; Informatics Institute, Federal University of Goiás, Goiania, Brazil","2011 XIII Symposium on Virtual Reality","14 Jul 2011","2011","","","96","101","augmented reality applications overlap virtual objects over a real scene considering the context. Today, more advanced applications also make use of diminished reality, which removes real objects from a scene. This paper describes a novel approach that combines augmented reality and diminished reality techniques to modify real objects in augmented reality applications. The proposed approach removes an object and replaces it with its purposely-modified replica. The solution uses dynamic texture techniques and inpaint to enhance the visual response of the performed modification. The results are promising considering both realism of the modified real object and performance of the application.","","978-0-7695-4445-8","10.1109/SVR.2011.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5951840","augmented reality;mixed reality;physically-based simulation","Pixel;Solid modeling;Lighting;Three dimensional displays;Real time systems;Cameras;Image color analysis","augmented reality;realistic images","geometric modification;augmented reality;diminished reality technique;dynamic texture technique","","","1","20","IEEE","14 Jul 2011","","","IEEE","IEEE Conferences"
"An Augmented Reality X-Ray system based on visual saliency","C. Sandor; A. Cunningham; A. Dey; V. -V. Mattila","Magic Vision Laboratory, University of South Australia, Australia; Magic Vision Laboratory, University of South Australia, Australia; Magic Vision Laboratory, University of South Australia, Australia; Nokia Research Center, Nokia Research Center, China","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","27","36","In the past, several systems have been presented that enable users to view occluded points of interest using Augmented Reality X-ray visualizations. It is challenging to design a visualization that provides correct occlusions between occluder and occluded objects while maximizing legibility. We have previously published an Augmented Reality X-ray visualization that renders edges of the occluder region over the occluded region to facilitate correct occlusions while providing foreground context. While this approach is simple and works in a wide range of situations, it provides only minimal context of the occluder object. In this paper, we present the background, design, and implementation of our novel visualization technique that aims at providing users with richer context of the occluder object. While our previous visualization only employed one salient feature (edges) to determine which parts of the occluder to display, our novel visualization technique is an initial attempt to explore the design space of employing multiple salient features for this task. The prototype presented in this paper employs three additional salient features: hue, luminosity, and motion. We have conducted two evaluations with human participants to investigate the benefits and limitations of our prototype compared to our previous system. The first evaluation showed that although our novel visualization provides a richer context of the occluder object, it does not impede users to select objects in the occluded area; but, it also indicated problems in our prototype. In the second evaluation, we have investigated these problems through an online survey with systematically varied occluder and occluded scenes, focussing on the qualitative aspects of our visualizations. The results were encouraging, but pointed out that our novel visualization needs a higher level of adaptiveness.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643547","augmented reality;visualization;evaluation;augmented reality X-ray;saliency","Visualization;Context;Rendering (computer graphics);Image color analysis;X-ray imaging;Image edge detection;Prototypes","augmented reality;data visualisation;X-ray imaging","visual saliency;augmented reality x-ray visualizations;occluder object","","60","1","","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"A bird's-eye view system using augmented reality","Haedong Kim; Juwan Kim; Sanggyu Park","Augmented Reality Research Team, Electronics and Telecommunications Research Institute, Taejon, South Korea; Augmented Reality Research Team, Electronics and Telecommunications Research Institute, Taejon, South Korea; Augmented Reality Research Team, Electronics and Telecommunications Research Institute, Taejon, South Korea","Proceedings 32nd Annual Simulation Symposium","6 Aug 2002","1999","","","126","131","Augmented reality (AR) is the technology that provides users with real time helpful information on the real scenes as the users' requirement. The AR system supplies helpful information for user by using user interfaces and systematical combination between real scenes and related information. We present our bird's eye view system to look at virtual buildings with the harmony of environment in civil architecture. We can intuitively look at the harmony among virtual buildings and the current environment and navigate in the environment with this system. The system consists of two parts. One is the construction part of aid information and the other is the navigation part of pilot environment. The first part systematically combines contour data, 3D modeling data for buildings, road and river data and text information, and so forth. The other part provides users with aid information on the real scenes by user interface while they navigate in the real scenes. As mentioned above, we can easily and quickly get helpful information on the real scenes. The system can be widely used in various applications, such as urban planning, construction planning, virtual studios, movies, military, education, and so on.","1080-241X","0-7695-0128-1","10.1109/SIMSYM.1999.766463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=766463","","Augmented reality;Layout;Buildings;Navigation;User interfaces;Urban planning;Architecture;Roads;Rivers;Motion pictures","augmented reality;user interfaces;real-time systems;human factors;computerised navigation","augmented reality;real time helpful information;real scenes;AR system;user interfaces;birds eye view system;virtual buildings;civil architecture;contour data;3D modeling data;river data;text information;user interface;urban planning;construction planning;virtual studios","","","","12","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Performance evaluation method for mobile computer vision systems using augmented reality","J. Nilsson; A. C. E. Ödblom; J. Fredriksson; A. Zafar; F. Ahmed","Department of Signals and Systems, Chalmers University of Technology, Goteborg, Sweden; Department of Vehicle Dynamics and Active Safety, Volvo Car Corporation, Goteborg, Sweden; Department of Signals and Systems, Chalmers University of Technology, Goteborg, Sweden; Department of Signals and Systems, Chalmers University of Technology, Goteborg, Sweden; Department of Signals and Systems, Chalmers University of Technology, Goteborg, Sweden","2010 IEEE Virtual Reality Conference (VR)","8 Apr 2010","2010","","","19","22","This paper describes a framework which uses augmented reality for evaluating the performance of mobile computer vision systems. Computer vision systems use primarily image data to interpret the surrounding world, e.g to detect, classify and track objects. The performance of mobile computer vision systems acting in unknown environments is inherently difficult to evaluate since, often, obtaining ground truth data is problematic. The proposed novel framework exploits the possibility to add virtual agents into a real data sequence collected in an unknown environment, thus making it possible to efficiently create augmented data sequences, including ground truth, to be used for performance evaluation. Varying the content in the data sequence by adding different virtual agents is straightforward, making the proposed framework very flexible. The method has been implemented and tested on a pedestrian detection system used for automotive collision avoidance. Preliminary results show that the method has potential to replace and complement physical testing, for instance by creating collision scenarios, which are difficult to test in reality.","2375-5334","978-1-4244-6238-4","10.1109/VR.2010.5444821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444821","Augmented reality;computer vision;performance evaluation;active safety;collision avoidance","Mobile computing;Computer vision;Augmented reality;Virtual reality;System testing;Vehicle safety;Road safety;Application software;Road vehicles;Remotely operated vehicles","augmented reality;collision avoidance;computer vision;mobile computing;road safety","performance evaluation method;mobile computer vision systems;augmented reality;object detection;ground truth data;virtual agents;augmented data sequences;pedestrian detection system;automotive collision avoidance;road vehicles active safety","","6","2","15","IEEE","8 Apr 2010","","","IEEE","IEEE Conferences"
"Texturing of augmented reality character based on colored drawing","H. Zhao; P. Huang; J. Yao","Research Center of Digital Media Technology, Xiamen University; Research Center of Digital Media Technology, Xiamen University; Research Center of Digital Media Technology, Xiamen University","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","355","356","Coloring book can inspire imaginary and creativity of children. However, with the rapid development of digital devices and internet, traditional coloring book tends to be not attractive for children any more. Thus, we propose an idea of applying augmented reality technology to traditional coloring book. After children finish coloring characters in the printed coloring book, they can inspect their work using a mobile device. The drawing is detected and tracked so that the video stream is augmented with a 3D character textured according to their coloring. This is possible thanks to several novel technical contributions. We present a texture process that generates texture map for 3D augmented reality character from 2D colored drawing using a lookup map. Considering the movement of the mobile device and drawing, we give an efficient method to track the drawing surface.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892323","H.5.1 [Information interfaces and presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;K.3.1 [Computers and education]: Computer Uses in Education — Computer-assisted instruction","Three-dimensional displays;Augmented reality;Mobile handsets;Streaming media;Real-time systems;Solid modeling;Two dimensional displays","augmented reality;computer graphics;image colour analysis;image texture;mobile computing;video signal processing","augmented reality character texturing;colored drawing;coloring book;printed coloring book;mobile device;video stream;3D character textured;3D augmented reality character;2D colored drawing;lookup map;drawing surface","","2","","7","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Hands-Free Interaction for Augmented Reality in Vascular Interventions","A. Grinshpoon; S. Sadri; G. J. Loeb; C. Elvezio; S. K. Feiner","Columbia University, USA; Columbia University, USA; Columbia University, USA; Columbia University, USA; Columbia University, USA","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","751","752","Vascular interventions are minimally invasive surgical procedures in which a physician navigates a catheter through a patient's vasculature to a desired destination in the patient's body. Since perception of relevant patient anatomy is limited in procedures of this sort, virtual reality and augmented reality systems have been developed to assist in 3D navigation. These systems often require user interaction, yet both of the physician's hands may already be busy performing the procedure. To address this need, we demonstrate hands-free interaction techniques that use voice and head tracking to allow the physician to interact with 3D virtual content on a head-worn display while making both hands available intraoperatively. Our approach supports rotation and scaling of 3D anatomical models that appear to reside in the surrounding environment through small head rotations using first-order control, and rigid body transformation of those models using zero-order control. This allows the physician to easily manipulate a model while it stays close to the center of their field of view.","","978-1-5386-3365-6","10.1109/VR.2018.8446259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446259","Hands-free interaction;augmented reality;vascular interventions;head tracking;head-worn display","Head;Three-dimensional displays;Solid modeling;Surgery;Cameras;Augmented reality","augmented reality;biomedical equipment;catheters;computer graphics;medical computing;medical robotics;surgery","augmented reality;vascular interventions;minimally invasive surgical procedures;physician;catheter;relevant patient anatomy;virtual reality;reality systems;user interaction;hands-free interaction techniques;head tracking;3D virtual content;head-worn display;3D anatomical models;head rotations;rigid body transformation","","7","","12","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Shared reality meeting - a collaborative augmented reality environment","M. T. Wagner; H. T. Regenbrecht","Heilrneyersteige, Ulm, Germany; Daimler Chrysler AG, Virtual Reality Competence Center, Ulm, Germany","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","2 pp.","","In this demonstration, we present an augmented reality (AR) system which allows multiple participants to interact with two- and three-dimensional data using tangible user interfaces. Interactively controllable 2D and 3D information are seamlessly integrated into the system. The system is based on earlier research work of the authors and is now commercially available for industrial use.","","0-7803-7680-3","10.1109/ART.2002.1106970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106970","","Collaboration;Augmented reality;User interfaces;Personal digital assistants;Collaborative work;Space technology;Control systems;Electrical equipment industry;Displays;Joining processes","augmented reality;interactive devices;groupware;haptic interfaces","shared reality meeting;collaborative augmented reality environment;AR system;two-dimensional data;three-dimensional data;tangible user interfaces;interactively controllable information;2D information;3D information","","2","2","8","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Visualizing and navigating complex situated hypermedia in augmented and virtual reality","S. Guven; S. Feiner","Department of Computer Science, Columbia University, USA; Department of Computer Science, Columbia University, USA","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","155","158","We present a set of techniques that enable mobile users to visualize and navigate complex hypermedia structures embedded in the real world, through augmented reality or virtual reality. Situating hypermedia in the 3D physical environment makes it possible to represent information about users' surroundings in context. However, it requires addressing a new set of problems beyond those of visualizing hypermedia on a 2D display: Nodes and links can potentially be distributed across large distances, and may be occluded by other objects, both real and virtual. Our techniques address these issues by enabling mobile users to select and manipulate portions of the hypermedia structure by tilting, lifting and shifting them, to view more clearly links and nodes that would otherwise be occluded or ambiguously connected.","","1-4244-0650-1","10.1109/ISMAR.2006.297807","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079269","","Visualization;Navigation;Virtual reality;Augmented reality;User interfaces;Buildings;Computer science;Computer displays;Two dimensional displays;Chromium","augmented reality;virtual reality","complex situated hypermedia;augmented reality;virtual reality;mobile users;complex hypermedia structures","","7","1","11","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Pre-patterns for designing embodied interactions in handheld augmented reality games","Y. Xu; E. Barba; I. Radu; M. Gandy; R. Shemaka; B. Schrank; B. MacIntyre; T. Tseng","Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Savannah College of Art and Design","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","19","28","The game industry and related research communities have shown a surge of interest in reality-based interfaces that create “embodied” game play experiences. Handheld AR (HAR) is a reality-based interface that renders digital objects onto a player's perception of the physical world. HAR creates a hybrid space in which players can leverage their existing physical and social skills to interact with the game system and with each other. Although HAR has received some attention in the world of handheld gaming, there is little research that summarizes and communicates design principles and implications across multiple examples. In this paper, we analyze and generate design lessons from dozens of HAR games, drawn from academic and commercial AR games, and also our years of experience designing and teaching HAR game design. We summarize our experience in this new field into a set of design “pre-patterns” as a means of formalizing significant design lessons derived from these existing practices into repeatable principles and solutions. We contribute to both the game and interaction design communities with pre-patterns that support embodied game play.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093652","Handheld augmented reality interface;design patterns;game design;game interface","Games;Communities;Augmented reality;Physics;Handheld computers;Smart phones;Lenses","augmented reality;computer games;human computer interaction;social aspects of automation;user interfaces","embodied interactions;handheld augmented reality games;game industry;reality-based interfaces;embodied game play experiences;physical skills;social skills;game system;HAR game design","","25","","65","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Augmented reality live-action compositing","T. Pintaric","University of Technology, Vienna, Austria","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","337","","This report describes a system that performs live-action compositing of physical and virtual objects to a panoramic background image in real-time at interactive rates. A static camera is directed towards a 40 cm/sup 3/ miniature stage, whose backdrop has been colored in chromatic green. Users can add virtual objects and manipulate their parameters within the scene by using a proxy device that consists of a small rod attached to a fiducial marker. Our system runs on commodity hardware such as a notebook equipped with a firewire video camera. The necessary chroma-keying and adaptive difference-matting algorithms have been implemented on a GPU using fragment shading.","","0-7695-2006-5","10.1109/ISMAR.2003.1240748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240748","","Augmented reality;Contracts;Real time systems;Cameras;Layout;Hardware;Firewire;Streaming media;Virtual reality;Multimedia systems","augmented reality;video cameras;optical tracking;rendering (computer graphics);notebook computers","augmented reality;live-action compositing;physical objects;virtual objects;background image;interactive rates;chromatic green;proxy device;fiducial marker;commodity hardware;notebook computer;firewire video camera;chroma keying;adaptive difference matting;difference-matting algorithms;GPU;fragment shading;programmable shading","","","","3","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Augmented reality for programming industrial robots","T. Pettersen; J. Pretlove; C. Skourup; T. Engedal; T. Lokstad","Corporate Research Center, ABB AS, Norway; Corporate Research Center, ABB AS, Norway; Corporate Research Center, ABB AS, Norway; Corporate Research Center, ABB AS, Norway; Corporate Research Center, ABB AS, Norway","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","319","320","Existing practice for programming robots involves teaching it a sequence of waypoints in addition to process-related events, which defines the complete robot path. The programming process is time consuming, error prone and, in most cases, requires several iterations before the program quality is acceptable. By introducing augmented reality technologies in this programming process, the operator gets instant real-time, visual feedback of a simulated process in relation to the real object, resulting in reduced programming time and increased quality of the resulting robot program. This paper presents a demonstrator of a standalone augmented reality pilot system allowing an operator to program robot waypoints and process specific events related to paint applications. During the programming sequence, the system presents visual feedback of the paint result for the operator, allowing him to inspect the process result before the robot has performed the actual task.","","0-7695-2006-5","10.1109/ISMAR.2003.1240739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240739","","Augmented reality;Robot programming;Service robots;Educational robots;Paints;Robot kinematics;Feedback;Application software;Design automation;Cameras","augmented reality;industrial robots;robot programming;path planning","augmented reality;industrial robots;programming robots;process-related events;robot path;programming process;time consuming;error prone;program quality;real-time feedback;visual feedback;simulated process;real object;programming time;robot program;AR pilot system;robot waypoints;process specific events;paint applications;programming sequence;process inspection;computer-animated design","","31","6","3","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"WireAR - legacy applications in augmented reality","G. Reitmayr; M. Billinghurst; D. Schmalstieg","University of Technology, Vienna, Austria; The HIT Laboratory NZ, New Zealand; University of Canterbury, New Zealand","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","331","332","Current augmented reality (AR) applications require that the application software be written to support a specific AR interface set up. WireAR was developed to enable output from any OpenGL application to be viewed in an AR fashion. This enables the output from any legacy graphical or scientific visualization applications to be viewed in a collaborative AR setting. This demonstration shows how the output of standard desktop visualization programs can be embedded into an augmented reality experience.","","0-7695-2006-5","10.1109/ISMAR.2003.1240745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240745","","Augmented reality;Application software;Rendering (computer graphics);Visualization;User interfaces;Geometry;Chromium;Layout;Collaborative work;Computer interfaces","augmented reality;user interfaces;groupware","WireAR;legacy applications;augmented reality;AR applications;application software;AR interface;OpenGL;graphical applications;scientific applications;visualization applications;collaborative AR;desktop programs;visualization programs;Computer Supported Collaborative Work","","","","5","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Augmented Reverse-Origami: from 3D model to square paper","S. M. Banu","Transilvania University, Brasov, Romania","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","101","102","This paper describes an interactive system that animates the process of unfolding origami models back to their original square papers. On developing the animation Computer Vision and Augmented Reality techniques are used. In order to augment the virtual animated origami model onto the real scene we use a picture of the real origami model instead of a conventional marker. Since Head-Mounted Displays can be cumbersome, the visualization is done on a computer screen.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6484001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6484001","","Solid modeling;Computational modeling;Art;Animation;Augmented reality;Videos;Computer vision","augmented reality;computer animation;computer vision;data visualisation;helmet mounted displays","augmented reverse-origami;3D model;square paper;interactive system;origami model unfolding process;augmented reality techniques;computer vision techniques;computer animation;virtual animated origami model;real origami model;head-mounted displays;computer screen","","","","4","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Trends and Vision of Head Mounted Display in Augmented Reality","K. Kiyokawa","Cybermedia Center, Osaka University, Osaka, Japan","2012 International Symposium on Ubiquitous Virtual Reality","10 Sep 2012","2012","","","14","17","This article introduces research trends and future visions of head mounted displays (HMDs) for mixed and augmented reality. Specifically, studies on head mounted visual displays, head mounted multi-modal displays, and head mounted sensing technologies for mixed and augmented reality are introduced, and challenges and visions are discussed for the realization of better MR/AR experience.","","978-1-4673-2258-4","10.1109/ISUVR.2012.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6296799","augmented reality;mixed reality;head mounted display","Visualization;Head;Optical imaging;Cameras;Augmented reality;Educational institutions","augmented reality;computer displays;helmet mounted displays","head mounted display;augmented reality;mixed reality;head mounted visual display;head mounted multimodal display;head mounted sensing technology;MR;AR;HMD","","26","2","17","IEEE","10 Sep 2012","","","IEEE","IEEE Conferences"
"Introduction of Physics Simulation in Augmented Reality","C. Chae; K. Ko","GIST Modeling and Simulation Laboratory, Gwangju, South Korea; GIST Modeling and Simulation Laboratory, Gwangju, South Korea","2008 International Symposium on Ubiquitous Virtual Reality","18 Jul 2008","2008","","","37","40","In 3D computer graphics, it has been an important issue to describe a virtual object realistically and show it in a physically correct manner. Unlike the virtual reality(VR), the augmented reality (AR) is an environment containing virtual and real objects simultaneously. However, the difference in motion between the virtual and real objects is obvious, which makes it hard for AR to be realistic and attractive. To reduce this gap, we propose to apply physical attributes to each virtual object, which can be done by using a physics engine, a software library containing functions related with physics. For this purpose, an ODE (open dynamics engine) library is used. However, the direct use of the library in the AR environment poses a lot of problems. Most of all, the coordination of the coordinate systems between OSG (OpenSceneGraph) and ODE must be taken care of. Next the positions of markers are also needed to be considered. In this paper, such problems are addressed and solutions to them are discussed.","","978-0-7695-3259-2","10.1109/ISUVR.2008.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568641","Physics Simulation;Augmented Reality;OSG;ODE;Transformation","Augmented reality;Engines;Computational modeling;Software libraries;Virtual reality;Computer simulation;Gravity;Physics computing;Computer graphics;Equations","augmented reality;physics computing","augmented reality;Physics simulation;3D computer graphics;virtual object;virtual reality;software library;open dynamics engine library;OpenSceneGraph","","15","1","6","IEEE","18 Jul 2008","","","IEEE","IEEE Conferences"
"Measuring Perception of Realism in Mixed and Augmented Reality Summary","I. Williams; A. Dolhasz; N. Monnoyer","DMT Lab, University (http://dmtlab.bcu.ac.uk), 144 Picture, Sound & Music, Nicholas Monnoyer, 3 Little Pix (http://www.3lp.be/) Big Bad Wolf (http://www.bigbadwolf.be/en/); NA; NA","2015 IEEE International Symposium on Mixed and Augmented Reality Workshops","3 Dec 2015","2015","","","24","24","This half day workshop will be an informal platform to promote new methods, ideas and standards for quantifying perceptual realism in both mixed and augmented reality. The workshop will explore emerging methods for capturing the perceived accuracy of mixed and augmented reality systems, highlighting approaches for, measuring visual realism, interaction quality perception, observer experience and the methods for quantifying perceptual quality. The workshop will appeal to researchers wanting to analyse and develop mixed reality and augmented reality systems. It will provide a forum for discussion and interdisciplinary investigation of the tools and measures for ensuring a quality perceptual experience.The workshop will consist of three seminars: The first highlighting the current problems faced by the MR/AR development industry, the second detailing standards in video analysis, showing how they can be adapted to MR/AR evaluation and the third presenting the current developments towards measuring human perceptual tolerances for MR/AR systems. Attendees will also be invited to discuss and present their ongoing work in two page positioning papers.","","978-1-4673-8471-1","10.1109/ISMARW.2015.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344751","","Augmented reality;Conferences;Production;Standards;Current measurement;Visual effects","augmented reality;visual perception","realism perception measurement;mixed reality;augmented reality;perceptual realism quantification;visual realism measurement;interaction quality perception;observer experience;perceptual quality;video analysis;human perceptual tolerance","","","","","IEEE","3 Dec 2015","","","IEEE","IEEE Conferences"
"Grey Island: Immersive tangible interaction through augmented reality","Z. Gong; G. Wang; Q. Wu","Info Art Design, Tsinghua University, Beijing, China; Info Art Design, Tsinghua University, Beijing, China; Info Art Design, Tsinghua University, Beijing, China","2019 IEEE Fourth International Conference on Data Science in Cyberspace (DSC)","20 Apr 2020","2019","","","656","661","Along with augmented reality maturing, there have been more possibilities about digital space and real space. By recognizing real space, augmented reality appends virtual objects and information to the recognized real space. However, most of today's augmented reality interactive narrative models are still in the stage of ""recognize space - append information"". What users can do is only to watch a space with virtual information appended, or to interact with virtual objects through screens or gestures. This paper proposed a new interactive narrative design method in augmented reality, which means that the audience can simultaneously manipulate both tangible props and virtual avatar, and the augmented reality environment responds to the audience's interaction behavior through virtual and physicallybased feedback. An interactive installation ""Grey Island"" was built in this paper, by which the user can see a floating island on the augmented reality screen. On the plane of the floating island stands a virtual avatar that has been given the gravity property. When the user manipulates the avatar to walk to a different position, the floating island will be inclined at a relative angle. The user can guide the virtual ball to the scoring area by moving the avatar and the tangible props. This augmented reality interactive narrative is preferable for its direct interactive feedback, intuitive interactive feedforward stimuli and richer narrative methods.","","978-1-7281-4528-0","10.1109/DSC.2019.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9069366","interactive narrative;augmented reality;tangible interaction;physically-based feedback","Augmented reality;Avatars;Games;Aerospace electronics;Gravity;Image recognition","augmented reality;avatars;human computer interaction;interactive systems","augmented reality environment;intuitive interactive feedforward stimuli;direct interactive feedback;virtual ball;augmented reality screen;interactive installation;virtual feedback;augmented reality environment;virtual avatar;interactive narrative design method;virtual information;augmented reality interactive narrative models;virtual objects;digital space;immersive tangible interaction;Grey Island","","","","","IEEE","20 Apr 2020","","","IEEE","IEEE Conferences"
"The design of a mixed-reality book: Is it still a real book?","R. Grasset; A. Dunser; M. Billinghurst","HIT Laboratory NZ, University of Canterbury, Christchurch, New Zealand; HIT Laboratory NZ, University of Canterbury, Christchurch, New Zealand; HIT Laboratory NZ, University of Canterbury, Christchurch, New Zealand","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","99","102","In this paper we present the results of our long term development of a mixed reality book. Most previous work in the area has focused on the technology of augmented reality books, such as providing registration using fiducial markers. In this work, however, we focused on exploring the design and development process of this type of application in a broader sense. We studied the semantics of a mixed reality book, the design space and the user experience with this type of interface.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637333","H.5.1 [Information interfaces and presentation]: Multimedia Information systems—Artificial, augmented, and virtual realities","Books;Three dimensional displays;Virtual reality;Augmented reality;Visualization;USA Councils;Layout","augmented reality","mixed-reality book design;augmented reality books;user experience","","38","15","24","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Augmented Reality for Construction Control","K. Kirchbach; C. Runde","Institute for Technology and Management in Construction (TMB), Karlsruhe Institute of Technology, Karlsruhe, Germany; Competence Center for Virtual Reality, Virtual Dimension Center (VDC), Fellbach, Germany","2012 16th International Conference on Information Visualisation","6 Sep 2012","2012","","","440","444","The development of a physical building control center has got the purpose of supporting the management and control of a project to optimize the flow of the complex processes at a construction site. The concept consists of equipping vehicles with sensors, using virtual reality and augmented reality-techniques to visualize these realtime information and allow an optical adaption to current circumstances. A more efficient utilization and enhanced cost effectiveness will be the result. Based on a previous performed requirement analysis a software architecture (AR4CC, ""Augmented Reality for Construction Control"") has been developed, which allows the use of virtual reality (vr) and augmented reality (ar) at a construction site. The basic idea of information transparency and the generated software is introduced. Two test-phases were performed and will be presented, one of them in a computer on a virtual construction site and the other one on a construction site mock-up, which was built especially for this purpose.","2375-0138","978-1-4673-2260-7","10.1109/IV.2012.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6295851","virtual reality;augmented reality;control center;information transparency;process optimization;construction site;information visualization","Buildings;Vehicles;Augmented reality;Cameras;Argon;Planning","augmented reality;civil engineering computing;construction industry;data visualisation;formal specification;project management;real-time systems;software architecture","physical building control center;project control;project management;complex process flow optimization;virtual reality;real-time information visualization;sensors-equipped vehicles;requirement analysis;software architecture;AR4CC;augmented reality for construction control;information transparency;virtual construction site;construction site mock-up","","1","","15","IEEE","6 Sep 2012","","","IEEE","IEEE Conferences"
"Augmenting a Cardiology-Patient Doctor-Dialogue Through Integrated Heartbeat-Activated Holographic Display","R. Dukalski; D. Aschenbrenner; M. Dieben; M. Jongbloed; J. Verlinden",Delft University of Technology; Delft University of Technology; Leiden University Medical Center; Leiden University Medical Center; University of Antwerp,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","40","44","The causes and treatment solutions of congenital heart defects are difficult to address and discuss between patient and doctor. This is mainly due to the complex spatial nature of congenital cardiac defects, which makes it difficult for the patients to envision the defect without prior anatomical knowledge and renders the comprehension largely dependent on doctors' (variable) skills to describe the anomaly. To improve communication, 3D printed hearts have been developed, yet these are expensive, difficult to manage for the large collection of defects, and require substantial oral explanation. In addition, the correlation with cardiac function remains rather abstract. Instead, we propose an augmented reality solution, involving a see-through head-mounted display (HMD) extended with a built-in heart rate monitor. In order to increase the presence and the conversational power, the heartbeat of the patient is used to drive an animation of a supersized, floating heart visualisation; enabling the user to inspect a specific heart condition from all sides. To enable this, a universal add-on casing was developed for the HoloLens. Heuristic analysis and pilot tests with 6+15 participants reveal limitations of the implementation and show that the solution does increase comprehension, although more has to be done to enable a robust system.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699244","Augmented Reality;heart;heartbeat;Human-centered computing ∼ Mixed / augmented reality;Applied computing ∼ Consumer health;Computing methodologies ∼ Simulation tools","Heart beat;Medical services;Bluetooth;Thumb;Augmented reality;Three-dimensional displays","augmented reality;cardiology;data visualisation;diseases;helmet mounted displays;holography;medical signal processing;patient monitoring","cardiology-patient doctor-dialogue;integrated heartbeat-activated holographic display;treatment solutions;congenital heart defects;congenital cardiac defects;3D printed hearts;substantial oral explanation;cardiac function;augmented reality solution;specific heart condition;see-through head-mounted display;built-in heart rate monitor;floating heart visualisation;Heuristic analysis;pilot tests;HoloLens","","","","13","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Guiding People in Complex Indoor Environments Using Augmented Reality","G. Gerstweiler","Department of Information and Communications Engineering, Tokyo Institute of Technology, 2-12-1-S3-60 Ookayama, Meguro-ku, Tokyo, Japan","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","801","802","Complex public buildings like airports use various systems to guide people to a certain destination. Such approaches are usually implemented by showing a floor plan, having guiding signs or color coded lines on the floor. With a technology that supports 6DOF tracking in indoor environments it is possible to guide people individually by using augmented reality guiding visualizations. The proposed research concentrates on three topics which are the main reason, why such a guiding system is still not available in real world situations. At first a tracking solution HyMoTrack is presented, based on a visual hybrid tracking approach for smart phones and tested in a real world airport scenario. The tracking and the guiding part of a reliable indoor navigation requests a 3D model of the environment. For that reason a 3D model generation algorithm was implemented, which automatically creates a 3D mesh out of a vectorized 2D floor plan. Finally the human aspect of an AR guiding system is researched and a novel AR path concept is presented for guiding people with AR devices. This FOVPath is designed to react not only to the position of the user and the target, but is also dependent on the view direction and the field of view (FOV) capabilities of the used device. This ensures that the user always gets reasonable information within the current FOV. To evaluate the concept technical evaluations and user studies were and will be performed.","","978-1-5386-3365-6","10.1109/VR.2018.8446138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446138","indoor tracking;navigation;augmented reality;Path Planning;Path Visualization;3D Model Generation;CAD;Human-centered computing-Mixed / augmented reality;Computing methodologies~ Tracking","Solid modeling;Three-dimensional displays;Floors;Augmented reality;Indoor environments;Airports","augmented reality;indoor environment;indoor navigation;indoor radio;mobile computing;tracking","HyMoTrack;indoor navigation;public buildings;indoor environments;floor plan;3D model generation algorithm;world airport scenario;visual hybrid tracking approach;augmented reality guiding visualizations;6DOF tracking;color coded lines;AR guiding system","","5","","7","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Multi-view augmented reality for underground exploration","M. T. Eren; M. Cansoy; S. Balcisoy","Sabanci University, Turkey; Sabanci University, Turkey; Sabanci University, Turkey","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","117","118","We propose a novel multi-view visualization technique, which allows effortless interaction with subterranean data and tries to maximize spatial perception whilst minimizing view clutter. The multi-view augmented reality technique introduces two correlating displays; i) a perspective egocentric view with focused edge overlay and focused geometry clipping and ii) an orthographic cut-away display that visualizes a thin slice of subterranean data intersecting a user controlled anchor.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549390","Outdoor Augmented Reality;Underground Visualization;X-Ray Visualization;Multi-View Augmented Reality","Augmented reality;Data visualization;Geometry;Visualization;Image edge detection;Educational institutions","augmented reality;computational geometry;data visualisation","multiview augmented reality technique;underground exploration;multiview visualization technique;correlating displays;perspective egocentric view;focused edge overlay;focused geometry clipping;orthographic cut-away display;subterranean data;user controlled anchor;view clutter minimization","","4","","7","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"Using Marker Based Augmented Reality to teach autistic eating skills","R. Bouaziz; M. Alhejaili; R. Al-Saedi; A. Mihdhar; J. Alsarrani","Computer Science Department, Taibah University, Al Madinah, Saudi Arabia; Computer Science Department, Taibah University, Al Madinah, Saudi Arabia; Computer Science Department, Taibah University, Al Madinah, Saudi Arabia; Computer Science Department, Taibah University, Al Madinah, Saudi Arabia; Computer Science Department, Taibah University, Al Madinah, Saudi Arabia","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","239","242","Autistic children suffer from distraction and difficulty in learning. The research is still ongoing continues to find suitable ways to help autistic children learn and live normally. Recently, the use of digital technologies in supporting children with Autism has increased dramatically. We focus on problems that autistic children face in the learning process. We propose a new learning system based on Augmented Reality overlie digital objects on top of physical cards and rendering them as a 3D object on mobile devices to help in teaching eating food skills using related phrases and sounds. We aim to improve the learning abilities to repeat the correct behavior.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319077","Autism Spectrum Disorders (ASD);Augmented Reality;marker-based augmented reality;mobile device;android application","Augmented reality;Autism;Cameras;Mobile handsets;Three-dimensional displays;Computer science;Animation","augmented reality;computer aided instruction;handicapped aids;medical disorders;mobile computing;paediatrics;rendering (computer graphics);teaching","autistic eating skills;autistic children;digital technologies;learning process;learning system;marker based augmented reality;learning abilities;eating food skills teaching;digital objects;rendering;3D object;mobile devices","","3","","12","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"Evaluation of Environment-Independent Techniques for 3D Position Marking in Augmented Reality","W. S. Lages; Y. Li; D. A. Bowman","Department of Computer Science, Virginia Tech; Department of Computer Science, Virginia Tech; Department of Computer Science, Virginia Tech","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","615","616","Specifying 3D positions in the real world is an essential step to create augmented reality content. However, this task can be challenging when information about the depth or geometry of the target location is not available. In this paper, we evaluate alternative techniques for 3D pointing at a distance without knowledge about the environment. We present the results of two studies evaluating the accuracy of techniques based on geometry and human depth perception. We find that geometric methods provide higher accuracy but may suffer from low precision due to pointing errors. We propose a solution that increases precision by combining multiple samples to obtain a better estimate of the target position.","","978-1-5386-3365-6","10.1109/VR.2018.8446055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446055","Augmented reality;interaction;marker placement;H5.1 [Information interfaces and presentation]: Multimedia Information Systems. - Artificial augmented and virtual realities;H.5.2: User Interfaces-Pointing","Three-dimensional displays;Standards;Meters;Augmented reality;Task analysis;Geometry","augmented reality;geometry","environment-independent techniques;3D position marking;target location;human depth perception;geometric methods;target position;augmented reality","","1","","4","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Considerations on the use of virtual and augmented reality technologies in music education","S. Serafin; A. Adjorlu; N. Nilsson; L. Thomsen; R. Nordahl",Aalborg University Copenhagen; Aalborg University Copenhagen; Aalborg University Copenhagen; Aalborg University Copenhagen; Aalborg University Copenhagen,"2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual & Augmented Reality (KELVAR)","29 Jun 2017","2017","","","1","4","Learning to play an instrument is challenging for both children and adults. Adding to this music education in K-12 oftentimes is subject to budget cuts. In this paper, we propose that virtual reality may offer children with an alternative approach to acquiring musical skills. Initially we present an overview of the state of the art software and technology for virtual and augmented reality in music, and then we outline a series of considerations on how virtual and augmented reality can help music education.","","978-1-5386-1892-9","10.1109/KELVAR.2017.7961562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961562","","Instruments;Music;Visualization;Augmented reality;Training","augmented reality;computer aided instruction;music","virtual reality technologies;augmented reality technologies;music education;K-12 education","","28","","20","IEEE","29 Jun 2017","","","IEEE","IEEE Conferences"
"[POSTER] Design Guidelines for Generating Augmented Reality Instructions","C. Rolim; D. Schmalstieg; D. Kalkofen; V. Teichrieb","Voxar Labs, Federal University of Pernambuco; Institute for Computer Graphics and Vision, Graz University of Technology; Institute for Computer Graphics and Vision, Graz University of Technology; Voxar Labs, Federal University of Pernambuco","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","120","123","Most work about instructions in Augmented Reality (AR) does not follow established patterns or design rules -- each approach defines its own method on how to convey instructions. This work describes our initial results and experiences towards defining design guidelines for AR instructions. The guidelines were derived from a survey of the most common visualization techniques and instruction types applied in AR. We studied about how 2D and 3D instructions can be applied in the AR context.","","978-1-4673-7660-0","10.1109/ISMAR.2015.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328076","Visualization;Mixed Reality;Instructions","Augmented reality;Visualization;Three-dimensional displays;Real-time systems;Assembly;Guidelines","augmented reality","augmented reality instructions;design rules;3D instructions;2D instructions","","10","","67","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Augmented Reality Tool for Markerless Virtual Try-on around Human Arm","S. Günes; O. Sanli; Ö. Ö. Ergün",SUNAGU Engineering Consultancy Education Ltd; SUNAGU Engineering Consultancy Education Ltd; Bahçeşehir University,"2015 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design","10 Dec 2015","2015","","","59","60","We present a Markerless 3D Augmented Reality Application for virtual accessory try-on applications around human arm. The system is based on a Kinect sensor and a multi-layer rendering framework to render RGB, depth data and 3D model of accessories simultaneously. The aim is to support realistic visualization of virtual objects around human arm, by detecting wrist pose and handling occlusion for various interactive marketing and retail applications, such as virtual watch try-on.","","978-1-4673-9628-8","10.1109/ISMAR-MASHD.2015.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350740","virtual try-on;Kinect;markerless;3D visualization;multi-layer rendering;pose estimation;interactive retail","Three-dimensional displays;Solid modeling;Wrist;Rendering (computer graphics);Data visualization;Augmented reality;Quaternions","augmented reality;data visualisation;image sensors;pose estimation;rendering (computer graphics)","augmented reality tool;markerless virtual try-on;human arm;markerless 3D augmented reality application;virtual accessory try-on applications;Kinect sensor;multilayer rendering framework;depth data;3D model;virtual object visualization;wrist pose detection;interactive marketing","","3","","6","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"Augmented Reality meets Non-Fungible Tokens: Insights Towards Preserving Property Rights","M. Duguleană; F. Gîrbacia",University Transilvania of Brașov; University Transilvania of Brașov,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","359","361","Non-fungible tokens are one of the newest use-cases of blockchain technology. Ethereum Virtual Machine (EVM)-based blockchains such as Ethereum, Binance Smart Chain (BSC), or Polygon/Matic have standardized this type of tokens using interfaces such as ERC721 and ERC1155. This development fostered a connection between blockchain and Mixed Reality technologies, which can now coexist in cohesive applications. In this paper, we present the opportunities and challenges resulting from using Augmented Reality NFTs, with a particular focus on the preservation of property, whether it is physical or purely digital. We present a methodology that can ensure the protection of privacy and the preservation of intellectual property when transitioning assets from the virtual to the physical world.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00081","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585784","augmented reality;blockchain;property rights","Privacy;Law;Scalability;Mixed reality;Intellectual property;Software;Virtual machining","augmented reality;blockchains;industrial property;virtual machines","ERC1155;mixed reality technologies;intellectual property;nonfungible tokens;property rights;blockchain technology;Ethereum virtual machine;ERC721;augmented reality NFT","","6","","17","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Augmented reality: Principles and practice","D. Schmalstieg; T. Höllerer","Graz University of Technology, Austria; University of California, Santa Barbara, CA, USA","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","425","426","This tutorial will provide a detailed introduction to Augmented Reality (AR). AR is a key user-interface technology for personalized, situated information delivery, navigation, on-demand instruction and games. The widespread availability and rapid evolution of smartphones and new devices such as Hololens enables software-only solutions for AR, where it was previously necessary to assemble custom hardware solutions. However, ergonomic and technical limitations of existing devices make this a challenging endeavor. In particular, it is necessary to design novel efficient real-time computer vision and computer graphics algorithms, and create new lightweight forms of interaction with the environment through small form-factor devices. This tutorial will present selected technical achievements in this field and highlight some examples of successful application prototypes.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892358","Augmented Reality;mixed reality","Tutorials;Augmented reality;Solid modeling;Optical sensors;Smart phones;Computer vision","augmented reality;computer graphics;computer vision;smart phones;user interfaces","augmented reality;AR;user-interface technology;situated information delivery;on-demand instruction;games;smartphones;Hololens;software-only solutions;computer vision;computer graphics;small form-factor devices","","37","","2","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Pocket-size augmented reality system for flight control","A. L. Gorbunov; A. Terenzi; G. Terenzi","Moscow State Technical University of Civil Aviation, Russia; Inglobe Technologies S.r.l., Italy; Inglobe Technologies S.r.l., Italy","2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","369","369","Head-up displays (HUDs) have become common equipment in aircraft cockpits. One of the uses of HUDs is to provide a specific visual interface for pilots in the form of what is called a ""tunnel-in-the-sky"" (i.e. 3D geometry for the navigation path displayed on a flat screen). According to recent studies the ""tunnel-in-the-sky"" approach does not provide crucial advantages in comparison with more traditional methods of presenting navigation information to pilots. Our research considers a stereoscopic version of the 3D ""tunnel-in-the-sky"" realized as an augmented reality (AR) pocket-size system with see-through light-weight AR glasses. The system consists of low-cost items and does not suffer from the drawbacks tied with existing synthetic/enhanced vision systems for pilots. The results of the experiments with desktop simulators of different AR pilot's interfaces (2D, 3D and stereo 3D conditions) proved the effectiveness of the proposed stereo AR solution. A flight test of the prototype of the developed AR system was carried out on Cessna 172 aircraft and is showed in the accompanying video.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223449","Augmented reality;virtual reality;flight safety","Augmented reality;Aircraft;Three-dimensional displays;Electronic mail;Aerospace control;Aircraft navigation","aerospace simulation;aircraft navigation;aircraft testing;augmented reality;head-up displays;stereo image processing","pocket-size augmented reality system;flight control;head-up displays;HUD;aircraft cockpits;visual interface;tunnel-in-the-sky;navigation information;stereoscopic version;AR pocket-size system;see-through light-weight AR glasses;low-cost items;synthetic/enhanced vision systems;desktop simulators;AR pilot interfaces;stereo 3D conditions;stereo AR solution;flight test;Cessna 172 aircraft","","","","12","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Gesture-based augmented reality annotation","Y. S. Chang; B. Nuernberger; B. Luan; T. Höllerer; J. O'Donovan","University of California Santa Barbara, Santa Barbara, CA, US; University of California, Santa, Barbara, USA; University of California, Santa, Barbara, USA; University of California Santa Barbara, Santa Barbara, CA, US; University of California Santa Barbara, Santa Barbara, CA, US","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","469","470","Drawing annotations with 3D hand gestures in augmented reality is useful for creating visual and spatial references in the real world, especially when these gestures can be issued from a distance. Different techniques exist for highlighting physical objects with hand-drawn annotations from a distance, assuming an approximate 3D scene model (e.g., as provided by the Microsoft HoloLens). However, little is known about user preference and performance of such methods for annotating real-world 3D environments. To explore and evaluate different 3D hand-gesture-based annotation drawing methods, we have developed an annotation drawing application using the HoloLens augmented reality development platform. The application can be used for highlighting objects at a distance and multi-user collaboration by annotating in the real world.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892383","Augmented Reality;Annotations;Spatial Referencing;HoloLens","Three-dimensional displays;Augmented reality;Transforms;Solid modeling;Surface treatment;User interfaces","augmented reality;computer graphics;gesture recognition","gesture-based augmented reality annotation;drawing annotations;3D hand gestures;visual references;spatial references;hand-drawn annotations;3D scene model;user preference;3D environments;3D hand-gesture-based annotation drawing methods;annotation drawing application;HoloLens augmented reality development platform;multiuser collaboration","","9","2","3","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"HARP: A framework for visuo-haptic augmented reality","U. Eck; C. Sandor","Magic Vision Lab, University of South Australia, Australia; Magic Vision Lab, University of South Australia, Australia","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","145","146","Visuo-Haptic Augmented Reality (VHAR) is a technology, which enables users to see and touch virtual objects. It poses unique problems to developers, including the need for precise augmentations, accurate colocation of haptic devices, and efficient processing of multiple, realtime sensor inputs to achieve low latency. We have designed and implemented the software framework HARP, which addresses these issues and simplifies the creation of haptic-enabled Augmented Reality (AR) applications. It allows developers to compose their applications on a high level of abstraction and hides most of the complexity of VHAR. Our contribution is the initial design and implementation of the framework, which we have validated in nine VHAR research projects ranging from simple interaction design to psychophysical experiments. We discuss limitations of our approach and future developments. These insights will be helpful to researchers and framework designers in the field of VHAR.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549404","H.5.1. [Information Interfaces and Presentation]: Multimedia Information Systems-[Artificial, augmented and virtual realities];H.5.2. [Information Interfaces and Presentation]: User Interfaces-[Haptic I/O];D.3.2 [Language Classifications]: Python, C, C++;D.3.3 [Language Constructs and Features]: Frameworks;D.2.1O [Design]: Rapid Prototyping","Haptic interfaces;Rendering (computer graphics);Visualization;Augmented reality;Streaming media;Australia","augmented reality;haptic interfaces","HARP software framework;visuo-haptic augmented reality;virtual object;sensor input;haptic-enabled augmented reality;abstraction level;interaction design;psychophysical experiment","","7","","9","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"A Framework for Service Based Composite Augmented Reality Applications","M. Chouiten; J. -Y. Didier; M. Mallem","Laboratoire Informatique Biologie Intégrative et Systèmes Complexes, Université dEvry, France; Laboratoire Informatique Biologie Intégrative et Systèmes Complexes, Université dEvry, France; Laboratoire Informatique Biologie Intégrative et Systèmes Complexes, Université dEvry, France","2013 International Symposium on Ubiquitous Virtual Reality","16 Sep 2013","2013","","","19","22","This work's starting point is the observation of the heterogeneity of algorithms and data sources involved in Augmented Reality (AR) applications. The idea is to be able to design AR applications taking advantage of modules offered as services from different developers and using data from different sources. In addition, an increasing number of AR applications is deployed within mobile devices and involve pervasive computing. Thus, a framework aiming to allow developers to create state of the art applications should also offer the built-in ability to develop transparently distributed applications and pervasive services. This paper presents the design of a framework to create AR applications using services and data from different sources in a transparent and efficient way. The goal of the framework is to offer ability to build composite applications combining locally running functionality and remote AR services. This framework is the result of the extension of a previously developed component based framework named ARCS (Augmented Reality Component System). With this extension, any component of ARCS (eg. feature detection, matching, rendering) becomes accessible to any non-ARCS application and any ARCS based application has transparent access to available web services and data sources. The framework design goals and assessment criteria are based on AR applications requirements defined through a dedicated methodology. Proof applications are also presented to show how the framework answers state of the art AR applications needs.","","978-0-7695-5084-8","10.1109/ISUVR.2013.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597725","Augmented reality;software architecture;Web services;development frameworks;composite applications","Augmented reality;XML;Libraries;Web services;Estimation;Feature extraction","augmented reality;mobile computing;Web services","service based composite augmented reality applications;AR application design;algorithm heterogeneity;data sources;mobile devices;pervasive computing;distributed applications;pervasive services;locally running functionality services;remote AR services;component based framework;ARCS;augmented reality component system;Web services;framework design goals;assessment criteria","","","","15","IEEE","16 Sep 2013","","","IEEE","IEEE Conferences"
"Augmented reality maintenance demonstrator and associated modelling","V. Havard; D. Baudry; A. Louis; B. Mazari","LUSINE and IRISE laboratories, CESI; LUSINE and IRISE laboratories, CESI; LUSINE and IRISE laboratories, CESI; LUSINE and IRISE laboratories, CESI","2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","329","330","Augmented reality allows to add virtual object in real scene. It has an increasing interest last years since mobile device becomes performant and cheap. The augmented reality is used in different domains, like maintenance, training, education, entertainment or medicine. The demonstrator we show is focused on maintenance operations. A step by step process is presented to the operator in order to maintain an element of a system. Based on this demonstration, we will explain the modelling we propose allowing describing an entire maintenance process with augmented reality. Indeed it is still difficult creating augmented reality application without computer programming skills. The proposed model will allow to create an authoring tool - or to plug to an existing one - in order to create augmented reality process without deep computer programming skills.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223429","Augmented Reality;modelling;maintenance;training","Maintenance engineering;Augmented reality;Unified modeling language;Animation;Training;Computational modeling;Laboratories","augmented reality;authoring systems;software maintenance","augmented reality maintenance demonstrator;virtual object;real scene;mobile device;training;education;entertainment;medicine;authoring tool","","10","","5","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"A Viewpoint about Diminished Reality: Is it Possible Remove Objects in Real Time from Scenes?","C. Rolim; V. Teichrieb","Voxar Laboratories, Informatic Center, Federal University of Pernambuco (UFPE), Recife, Brazil; Voxar Laboratories, Informatic Center, Federal University of Pernambuco (UFPE), Recife, Brazil","2012 14th Symposium on Virtual and Augmented Reality","10 Sep 2012","2012","","","141","146","This work aims to present an overview about how to generate a Diminished Reality scene. Diminished Reality is seen as part of the Augmented Reality research area and there are only a few related works available in the literature about this subject. The main concepts, possible applications and works related are presented. Besides, an approach to remove objects from real scenes is presented, showing preliminary results.","","978-1-4673-1929-4","10.1109/SVR.2012.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6297570","Augmented reality;diminished reality;image completion techniques","Gold;Augmented reality","augmented reality","diminished reality scene;augmented reality;object removal","","1","","16","IEEE","10 Sep 2012","","","IEEE","IEEE Conferences"
"Egocentric space-distorting visualizations for rapid environment exploration in mobile mixed reality","C. Sandor; A. Cunningham; U. Eck; D. Urquhart; G. Jarvis; A. Dey; S. Barbier; M. R. Marner; S. Rhee","Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Department of Computer Science and Engineering, Kyungnam University, South Korea","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","211","212","Throughout the last decade, mobile information browsing has become a widely-adopted practice. Most of today's mobile Internet devices contain facilities to display maps of the user's surroundings with points of interest embedded into the map. Other researchers have already explored complementary, egocentric visualizations of these points of interest using mobile mixed reality. However, it is challenging to display off-screen or occluded points of interest. We have designed and implemented space-distorting visualizations to address these situations. Based on the informal user feedback that we have gathered, we have performed several iterations on our visualizations. We hope that our initial results can inspire other researchers to also investigate space-distorting visualizations for mixed and augmented reality.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336461","H.5.1. [Information Interfaces and Presentation]: Multimedia Information Systems;[Artificial, augmented and virtual realities] I.3.6 [Computer Graphics]: Methodology and Techniques;[Interaction Techniques]","Visualization;Virtual reality;Cameras;Uncertainty;Wire;Mice;Augmented reality;User interfaces;Usability;Yarn","augmented reality;data visualisation;Internet;iterative methods;mobile computing","egocentric space-distorting visualizations;rapid environment exploration;mobile mixed reality;mobile Internet devices;iterations;augmented reality","","8","1","6","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Enhancing Tourism Experiences Via Mobile Augmented Reality by Superimposing Virtual Information on Artefacts","N. H. M. Ariffin; Z. A. Nasrudin; A. R. H. M. Khair","Faculty of Computer and Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Selangor, Malaysia; Faculty of Computer and Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Selangor, Malaysia; Faculty of Computer and Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Selangor, Malaysia","2022 9th International Conference on Electrical and Electronics Engineering (ICEEE)","16 May 2022","2022","","","330","334","These interactive, attentive, and adaptable technologies that give visitors relevant services and information at any time and from any location in the actual world were something that can only be regarded as a view of the future, some place unattainable but present. The introduction of new technology has resulted in a paradigm change in display. It is the result of the convergence of modern smart mobile devices, contextual awareness, and augmented reality, which may enhance visitors' experiences and give them the sense of having accomplished something more. The introduction of new technology has resulted in a paradigm change in display. It is the result of the convergence of modern smart mobile devices, contextual awareness, and augmented reality, which may enhance visitors' experiences and give them the sense of having accomplished something more. The study on Enhancing Tourism Experiences via Mobile Augmented Reality by Superimposing Virtual Information on Artefacts (MARVIA) aims to enhance the user's experience aside from giving the user additional value when visiting the museum. A tracker or a marker that will be the trigger is the artefacts on the museum itself. The application will use the superimposition-based technique in augmented reality. It will superimpose several parts of the artefacts and overlay them with augmented objects, creating an augmented reality environment. This study focuses on augmented reality as it can be used without additional hardware that might incur more cost. It only needs a piece of software technology and a device that can be used alongside the software. Whilst virtual reality requires additional items and hardware such as goggles, and not only that, with the usage of different hardware, it will limit the movement of the tourists and thus will decrease the value of the tourist that comes to the museum.","","978-1-6654-6754-4","10.1109/ICEEE55327.2022.9772569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772569","augmented reality;tourism;mobile application;museum","Costs;Hardware;Software;Mobile handsets;User experience;Eye protection;Augmented reality","augmented reality;mobile computing;museums;travel industry;virtual reality","Mobile Augmented Reality;Superimposing Virtual Information;interactive technologies;attentive, technologies;adaptable technologies;visitors relevant services;paradigm change;modern smart mobile devices;contextual awareness;Enhancing Tourism Experiences;user;augmented objects;augmented reality environment;virtual reality","","","","26","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"DART: the Designer's Augmented Reality Toolkit","B. MacIntyre; M. Gandy; J. Bolter; S. Dow; B. Hannigan","GVU Center, Georgia Institute of Technology, Atlanta, GA, USA; GVU Center, Georgia Institute of Technology, Atlanta, GA, USA; GVU Center, Georgia Institute of Technology, Atlanta, GA, USA; GVU Center, Georgia Institute of Technology, Atlanta, GA, USA; GVU Center, Georgia Institute of Technology, Atlanta, GA, USA","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","329","330","This demonstration highlights the Designer's Augmented Reality Toolkit (DART), a system that allows users to easily create augmented reality (AR) experiences. Over the past year our research has focused on the creation of this toolkit that can be used by technologists, designers, and students alike to rapidly prototype AR applications. Current approaches to AR development involve extensive programming and content creation as well as knowledge of technical topics involving cameras, trackers, and 3D geometry. The result is that it is very difficult even for technologists to create AR experiences. Our goal was to eliminate these obstacles that prevent such users from being able to experiment with AR. The DART system is based on the Macromedia Director multimedia-programming environment, the de facto standard for multimedia content creation. DART uses the familiar Director paradigms of a score, sprites and behaviors to allow a user to visually create complex AR applications. DART also provides low-level support for the management of trackers, sensors, and camera via a Director plug-in Xtra. This demonstration will show the wide range of AR and other types of multimedia applications that can be created with DART, and visitors will have the opportunity to use DART to create their own experiences.","","0-7695-2006-5","10.1109/ISMAR.2003.1240744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240744","","Augmented reality;Prototypes;Testing;Cameras;Programming profession;Geometry;Multimedia systems;Sprites (computer);Human computer interaction","augmented reality;software tools;multimedia computing;visual programming;programming environments","Designer Augmented Reality Toolkit;application prototyping;AR application;AR development;extensive programming;content creation;cameras;trackers;3D geometry;DART system;Macromedia Director;multimedia-programming environment;multimedia content;Director paradigms;low-level support;Director plug-in Xtra;multimedia applications","","8","","","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"[Poster] An augmented and virtual reality system for training autistic children","N. S. Lakshmiprabha; A. Santos; D. Mladenov; O. Beltramello","European Organization for Nuclear Research, Switzerland; European Organization for Nuclear Research, Switzerland; European Organization for Nuclear Research, Switzerland; European Organization for Nuclear Research, Switzerland","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","277","278","Autism or Autism Spectrum disorder (ASD) is a pervasive development disorder causing impairment in thinking, feeling, hearing, speaking and social interaction. For this reason, children suffering from autism need to follow special training in order to increase their ability to learn new skills and knowledge. These children have propensity to be attracted by the technology devices especially virtual animations. The interest of this research work is to explore and study the use of Augmented and Virtual Reality (AR/VR) system for training the children with ASD based on Applied Behavior Analysis (ABA) techniques. This system assists in teaching children about new pictures or objects along with the associated keyword or matching sentence in an immersive way with fast interaction. The preliminary prototype demonstrates satisfactory performance of the proposed AR/VR system working in laboratory conditions.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948448","H.5.1 [Information Interfaces and Presentation];Multimedia Information Systems — Artificial, Augmented, Virtual Realities","Training;Variable speed drives;Psychology;Autism;Cameras;Monitoring;Virtual reality","augmented reality;computer animation;computer based training","augmented reality system;virtual reality system;autistic children training;autism spectrum disorder;virtual animation;AR-VR system;applied behavior analysis;ABA technique","","20","","5","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Effects of Augmented Content’s Placement and Size on User’s Search Experience in Extended Displays","S. Bang; H. Lee; W. Woo",KAIST UVR Lab; KAIST UVR Lab; KAIST UVR Lab,"2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","184","188","Using an augmented reality head-mounted display(HMD) to extend the display of smartphone could open up new user interface solutions, benefiting users with an increased screen real-estate and visualizations that leverage each device's capabilities. Some previous works have explored the viability of extended displays, but knowledge regarding considerable design factors and constraints for such displays is still very limited. In our work, we conducted an exploratory study to investigate how different properties of augmented content in extended displays affect the user's task performance and subjective workload in an image comparison task. Through an experiment with 24 participants, we compared four augmented content placements (top, right, left, and bottom) and two augmented content sizes (small and large). The study results demonstrated that there are significant effects of both placement and size of augmented content on task performance and subjective workload. Based on the findings of our study, we propose some recommendations for the future design of extended displays.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288445","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed/augmented reality;Human-centered computing;Human computer interaction (HCI);HCI design and evaluation methods;User studies","Performance evaluation;Visualization;Design methodology;User interfaces;Task analysis;Augmented reality","augmented reality;data visualisation;helmet mounted displays;mobile computing;smart phones;user experience;user interfaces;wearable computers","extended displays;user interface solutions;augmented content placements;user search experience;augmented reality head mounted display;smartphone display;visualizations","","3","","18","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"The House of Olbrich — An Augmented Reality tour through architectural history","J. Keil; M. Zollner; M. Becker; F. Wientapper; T. Engelke; H. Wuest","Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","15","18","With ”House of Olbrich” we present an iPhone Augmented Reality (AR) app that visualizes the compelling history of Darmstadt's unique Jugendstil (Art Nouveau) quarter with video-see through Augmented Reality. We propose methods for enabling high performance computer vision algorithms to deploy sophisticated AR visuals on current generation Smartphones by outsourcing resource intensive tasks to the cloud. This allows us to apply methods on 3D feature recognition for even complex tracking situations outdoors, where lightning conditions change and tracked objects are often occluded. By taking a snapshot of the building, the user learns about the architect, design and history of the building. Historical media, like old photographs and blueprints are superimposed on the building's front, depicting the moved history of the famous House of Olbrich, which was destroyed during World War II and has been only rudimentary restored. Augmented Reality technology allows tourists to jump back in time visually by using their Smartphones: Mixing Realities emphasizes the user's experience and leads his attention to the impressive historical architecture of the Art Nouveau. In addition, we ease interaction means by superimposing snapshots. Tourists may view and read information also in a relaxed position without the need to front-up their mobiles all the time.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093651","K.3.1 [Computing Milieux]: Computers and Education-Computer Uses in Education;H.4.m [InformationSystem Profession]: Miscellaneous","Three dimensional displays;Buildings;Engines;Augmented reality;Mobile communication;Solid modeling;History","architecture;augmented reality;computer vision;history;smart phones;travel industry","Olbrich house;architectural history;iPhone augmented reality tour;Darmstadt unique Jugendstil quarter;Art Nouveau;video-see through augmented reality;computer vision algorithms;smartphones;3D feature recognition;historical media","","31","1","18","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"In-Place Sketching for content authoring in Augmented Reality games","N. Hagbi; R. Grasset; O. Bergig; M. Billinghurst; J. El-Sana","The Visual Media Laboratory, Ben-Gurion University of the Negev, Beersheba, Israel; The HIT Laboratory NZ, University of Canterbury, New Zealand; The Visual Media Laboratory, Ben-Gurion University of the Negev, Beersheba, Israel; The HIT Laboratory NZ, University of Canterbury, New Zealand; The Visual Media Laboratory, Ben-Gurion University of the Negev, Beersheba, Israel","2010 IEEE Virtual Reality Conference (VR)","8 Apr 2010","2010","","","91","94","Sketching leverages human skills for various purposes. In-Place Augmented Reality Sketching experiences build on the intuitiveness and flexibility of hand sketching for tasks like content creation. In this paper we explore the design space of In-Place Augmented Reality Sketching, with particular attention to content authoring in games. We propose a contextual model that offers a framework for the exploration of this design space by the research community. We describe a sketch-based AR racing game we developed to demonstrate the proposed model. The game is developed on top of our shape recognition and 3D registration library for mobile AR.","2375-5334","978-1-4244-6238-4","10.1109/VR.2010.5444806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444806","In-Place Augmented Reality Sketching;Tangible Interaction;User Interface;Sketch Interaction","Augmented reality;User interfaces;Virtual reality;Humans;Space technology;Space exploration;Image reconstruction;Context modeling;Shape;Software libraries","augmented reality;authoring systems;computer games;shape recognition;user interfaces","in-place sketching;content authoring;augmented reality games","","23","3","28","IEEE","8 Apr 2010","","","IEEE","IEEE Conferences"
"A Survey on Future of Augmented Reality with AI in Education","R. Kaviyaraj; M. Uma","Department of Computer Science and Engineering, SRM Institute of science and Technology, Kattankulathur, Chengalpattu; Department of Software Engineering, SRM Institute of science and Technology, Kattankulathur, Chengalpattu","2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)","12 Apr 2021","2021","","","47","52","Augmented reality now has reached the stage in real time simulations which needed and contemplated. In the year 2020 and forthcoming years to 2030 augmented reality is going to play a lead role in most of industries, which includes military, education, medical, manufacturing industries, training and remote assistant, navigation, and gaming to name a few. This all-new entire article brings out the broad meaning of augmented reality sorted into a detailed survey of how it's going to be a cornerstone of the new education system and how this can used in other sectors too. The core contribution of this entire article is the discussion of recent studies on represents of the present state of field, which seek to inspire educators to improve mixed reality experiences and to carry out further more research in favor of interactive learning environments.","","978-1-7281-9537-7","10.1109/ICAIS50930.2021.9395838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395838","Augmented Reality;AR;Augmented Reality in Education;AR with AI","Training;Manufacturing industries;Remote laboratories;Navigation;Mixed reality;Real-time systems;Augmented reality","augmented reality;computer aided instruction;virtual reality","2030 augmented reality;manufacturing industries;entire article;mixed reality experiences","","13","","30","IEEE","12 Apr 2021","","","IEEE","IEEE Conferences"
"An Augmented Reality Design Method Based on ARKit for the Fusion of Hierarchical Traditional Media and Real Scenes","G. Di; H. Li; J. Xu","School of Information and Telecommunications Engineering, Communication University of China, Beijing, China; School of Information and Telecommunications Engineering, Communication University of China, Beijing, China; Academy of broadcasting Science, Beijing, China","2021 International Conference on Culture-oriented Science & Technology (ICCST)","13 Dec 2021","2021","","","67","71","Augmented reality (AR) has entered our lives, and it is likely to become the next generation of human-computer interaction technology. In order to bring a more immersive augmented reality experience, this paper introduces an augmented reality method that can integrate traditional media with real scenes based on ARKit. Through scene recognition, plane detection, 3D modeling and other technologies, traditional media is integrated into the real scenes to give users an immersive feeling. In addition, this paper designs a hierarchical augmented reality experience based on the processing capabilities of different devices and scene information, avoiding the impact of device differences and lack of scene information on the augmented reality experience.","","978-1-6654-4254-1","10.1109/ICCST53801.2021.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637591","Augmented reality;ARKit;human-computer interaction","Human computer interaction;Three-dimensional displays;Design methodology;Media;Augmented reality;Next generation networking;Global Positioning System","augmented reality;solid modelling","scene information;augmented reality design method;ARKit;hierarchical traditional media;human-computer interaction technology;immersive augmented reality experience;augmented reality method;scene recognition;immersive feeling;hierarchical augmented reality experience;3D modeling","","1","","14","IEEE","13 Dec 2021","","","IEEE","IEEE Conferences"
"SimpleAR: Augmented Reality high-level content design framework using visual programming","Y. Apaza-Yllachura; A. Paz-Valderrama; C. Corrales-Delgado","Universidad Nacional de San Agustín de Arequipa, Arequipa, Perú; Universidad Nacional de San Agustín de Arequipa, Arequipa, Perú; Universidad Nacional de San Agustín de Arequipa, Arequipa, Perú","2019 38th International Conference of the Chilean Computer Science Society (SCCC)","23 Jan 2020","2019","","","1","7","This research work proposes a new augmented reality high-level content design framework, this is, a tool to create augmented reality applications aimed at staff with basic or no programming knowledge. The proposed framework summarizes the experience gathered from a systematic mapping study carried out on similar frameworks. Our proposal has a flexible approach regarding its ability to be adapted to any augmented reality programming framework. We demonstrate its viability with an implementation of our framework with Vuforia for the creation of marker-based augmented reality applications. The results of usability tests based on ISO 9241-11 show that our proposal is effective because all users were able to complete all tasks, it is efficient because users were able to create augmented reality applications in less than 5 minutes and it satisfies the user by qualifying as “Highly acceptable” according to the average score of the System Usability Scale questionnaire.","1522-4902","978-1-7281-5613-2","10.1109/SCCC49216.2019.8966427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966427","augmented reality;usability;authoring tool","Three-dimensional displays;Solid modeling;Programming profession;Augmented reality;Task analysis;Usability","augmented reality;authoring systems;software engineering;visual programming","marker-based augmented reality applications;augmented reality high-level content design;augmented reality programming;SimpleAR;visual programming;Vuforia;usability tests;ISO 9241-11;augmented reality authoring tools","","1","","21","IEEE","23 Jan 2020","","","IEEE","IEEE Conferences"
"Work-in-Progress-Augmented Reality Enriched Project Guide for Mechanical Engineering Students","R. Comes; C. Neamtu; Z. L. Buna","Department of Design Engineering and Robotics, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Department of Design Engineering and Robotics, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Department of Design Engineering and Robotics, Technical University of Cluj-Napoca, Cluj-Napoca, Romania","2021 7th International Conference of the Immersive Learning Research Network (iLRN)","28 Jun 2021","2021","","","1","3","This work-in-progress paper describes a case study of an augmented reality enriched learning material, created for mechanical engineering students that learn computer aided design. The case study learning material details the systematic process of designing a 5 degree of freedom robotic arm. The purpose of this research is to highlight the advantages of immersive learning experiences based on augmented reality in engineering. The augmented reality application is designed as a complementary class material along with the project guide. Augmented reality elements tracked directly on top of the existing project guide has the potential to make both teaching and learning more effective.","","978-1-7348995-2-8","10.23919/iLRN52045.2021.9459247","European Social Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459247","augmented reality;learning;computer aided design;mechanical engineering;visualization","Systematics;Design automation;Education;Manipulators;Mechanical engineering;Augmented reality","augmented reality;CAD;computer aided instruction;engineering education;manipulators;mechanical engineering computing;teaching","augmented reality application;complementary class material;augmented reality elements;work-in-progress-augmented reality enriched project guide;mechanical engineering students;computer aided design;material details;immersive learning experiences;5 DoF robotic arm;teaching","","","","5","","28 Jun 2021","","","IEEE","IEEE Conferences"
"Look Inside: Understanding Thermal Flux Through Augmented Reality","P. Knierim; F. Kiss; A. Schmidt","Human-Centered Ubiquitous Media, Ludwig-Maximilians University Munich; VIS, University of Stuttgart; Human-Centered Ubiquitous Media, Ludwig-Maximilians University Munich","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","170","171","The transition from high school to university is an exciting time for students including many new challenges. Particularly in the field of science, technology, engineering, and mathematics, the university dropout rate may reach up to 40%. The studies of physics rely on many abstract concepts and quantities that are not directly visible like energy or heat. We developed a mixed reality application for education, which augments the thermal conduction of metal by overlaying a representation of temperature as false-color visualization directly onto the object. This real-time augmentation avoids attention split and overcomes the perception gap by amplifying the human eye. Augmented and Virtual Reality environments allow students to perform experiments that were impossible to conduct for security or financial reasons. With the application, we try to foster a deeper understanding of the learning material and higher engagement during the studies.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699216","H.5.m [Information Interfaces and Presentation]: Miscellaneous","Augmented reality;Data visualization;Physics;Prototypes;Heating systems;Real-time systems","augmented reality;computer aided instruction;data visualisation;engineering education;physics computing","thermal flux;high school;university dropout rate;mixed reality application;false-color visualization;real-time augmentation;attention split;perception gap;augmented reality environment;virtual reality environment;science technology engineering mathematics field;learning material","","11","","7","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Amplifying Realities: Gradual and Seamless Scaling of Visual and Auditory Stimuli in Extended Reality","Z. Choudhary",University of Central Florida,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","465","468","Existing literature in the field of extended reality has demonstrated that visual/auditory manipulations can change a person’s perception and behavior. For example, a mismatch between the physical self and the virtual self can have psychological and behavioral implications. There are many different approaches that can incur a perceptual change. An under-explored field of research are gradual and subtle manipulations, such as scaling the food one eats or scaling the heads of people one sees. In this position paper, I provide an overview of my prior PhD research focusing on means to gradually and seamlessly scale visual and auditory stimuli in extended reality, and investigations of the corresponding changes in human perception.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585893","Computing methodologies;Computer graphics;Graphics systems and interfaces;Virtual reality;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Augmented reality;HCI design and evaluation methods;User studies","Visualization;Extended reality;Design methodology;Psychology;Focusing;Medical services;Augmented reality","augmented reality;hearing;psychology;visual perception","auditory stimuli;extended reality;psychological implications;behavioral implications;perceptual change;under-explored field;amplifying realities;visual stimuli;human perception","","","","14","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Augmented Reality Laboratory for High School Electrochemistry Course","M. -P. Chen; B. -C. Liao","Graduate Institute of Information and Computer Education National Taiwan Normal University, Taipei, Taiwan; Graduate Institute of Information and Computer Education National Taiwan Normal University, Taipei, Taiwan","2015 IEEE 15th International Conference on Advanced Learning Technologies","17 Sep 2015","2015","","","132","136","The purpose of this study was to investigate the effects of types of augmented reality and guiding strategy on senior high school students' performance and motivation of electrochemistry concepts. The participants were 152 freshmen of senior high school. A 2X2 quasi-experimental design was employed and the independent variables were type of augmented reality (static-AR vs. Dynamic-AR) and type of guiding strategy (procedure-guided vs. Question-guided). Two types of augmented reality were employed, including the static augmented reality and the dynamic augmented reality, and two types of guiding strategies were cooperated, including procedure-guided strategy and question-guided strategy. The dependent variables were learning performance and motivation. The results revealed that (a) while receiving the static augmented reality learning, the procedural guidance group achieved better learning application performance than the question guidance group, (b) as for the knowledge understanding performance, the static augmented reality group outperformed the dynamic augmented reality group, and the procedural guidance group outperformed the question guidance group, and (c) students showed positive motivation toward learning Chemistry no matter which augmented reality type they used, especially students who used the static augmented reality revealed higher motivation than those who used the dynamic augmented reality.","2161-377X","978-1-4673-7334-0","10.1109/ICALT.2015.105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7265286","augmented reality;gamification;learning strategies;experiential learning","Augmented reality;Chemicals;Ions;Games;Education;Animation","augmented reality;computer aided instruction;educational courses;electrochemistry","augmented reality laboratory;high school electrochemistry course;electrochemistry concepts;senior high school;independent variables;static augmented reality;dynamic augmented reality;procedure guided strategy;question guided strategy;procedural guidance group","","11","","14","IEEE","17 Sep 2015","","","IEEE","IEEE Conferences"
"Exploring the perception of co-location errors during tool interaction in visuo-haptic augmented reality","U. Eck; L. Hoang; C. Sandor; G. Yamamoto; T. Taketom; H. Kato; H. Laga","PBRC, University of South Australia; IMDLab, Nara Institute of Science and Technology; IMDLab, Nara Institute of Science and Technology; IMDLab, Nara Institute of Science and Technology; IMDLab, Nara Institute of Science and Technology; IMDLab, Nara Institute of Science and Technology; PBRC, University of South Australia","2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","171","172","Co-located haptic feedback in mixed and augmented reality environments can improve realism and user performance, but it also requires careful system design and calibration. In this poster, we determine the thresholds for perceiving co-location errors through two psychophysics experiments in a typical fine-motor manipulation task. In these experiments we simulate the two fundamental ways of implementing VHAR systems: first, attaching a real tool; second, augmenting a virtual tool. We determined the just-noticeable co-location errors for position and orientation in both experiments and found that users are significantly more sensitive to co-location errors with virtual tools. Our overall findings are useful for designing visuo-haptic augmented reality workspaces and calibration procedures.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504708","H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems — Artificial, augmented and virtual realities","Haptic interfaces;Augmented reality;Visualization;Calibration;Performance evaluation;Rendering (computer graphics);Australia","augmented reality;feedback;haptic interfaces;human computer interaction","colocation error perception;tool interaction;colocated haptic feedback;mixed reality environment;realism;system design;system calibration;psychophysics experiment;fine-motor manipulation task;VHAR system;virtual tool;position error;orientation error;visuo-haptic augmented reality workspace","","1","","4","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Augmented and Virtual Reality Web Applications for Music Stage Performance","N. Petrović","Faculty of Electronic Engineering, University of Niš, Niš, Serbia","2020 55th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)","20 Oct 2020","2020","","","33","36","In this paper, it is explored how augmented and virtual reality web applications can contribute to stage performance in audio-visual arts. As outcome, application case study is presented: augmented reality loop sampler interface integrated with virtual reality song visualizer. Moreover, a modelling tool leveraging metamodel and code generation for rapid creation of custom augmented/virtual reality applications is introduced. According to the achieved results, the proposed approach significantly speeds up the development of such applications.","","978-1-7281-7143-2","10.1109/ICEST49890.2020.9232713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232713","Augmented reality (AR);Metamodeling;Media arts;Music;Virtual reality (VR)","Solid modeling;Three-dimensional displays;Music;Unified modeling language;Augmented reality;Load modeling;Servers","art;augmented reality;music","augmented reality Web applications;audio-visual arts;virtual reality Web applications;music stage performance;virtual reality song visualizer;augmented reality loop sampler interface;application case study","","7","","15","IEEE","20 Oct 2020","","","IEEE","IEEE Conferences"
"The Effects of Virtual Reality, Augmented Reality, and Motion Parallax on Egocentric Depth Perception","A. Jones; J. E. Swan; G. Singh; E. Kolstad","Mississippi State University, MI, USA; Mississippi State University, MI, USA; Mississippi State University, MI, USA; Mississippi State University, MI, USA","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","267","268","A large number of previous studies have shown that egocentric depth perception tends to be underestimated in virtual reality (VR) - objects appear smaller and farther away than they should. Various theories as to why this might occur have been investigated, but to date the cause is not fully understood. A much smaller number of studies have investigated how depth perception operates in augmented reality (AR), and some of these studies have also indicated a similar underestimation effect. In this paper we report an experiment that further investigates these effects. The experiment compared VR and AR conditions to two real-world control conditions, and studied the effect of motion parallax across all conditions. Our combined VR and AR head-mounted display (HMD) allowed us to develop very careful calibration procedures based on real-world calibration widgets, which cannot be replicated with VR-only HMDs. To our knowledge, this is the first study to directly compare VR and AR conditions as part of the same experiment.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480794","","Virtual reality;Augmented reality;Error correction;Calibration;Legged locomotion;Protocols;Optical sensors;Centralized control;USA Councils;Foot","augmented reality;helmet mounted displays","virtual reality;augmented reality;motion parallax;egocentric depth perception;head-mounted display;real-world calibration widgets","","21","1","2","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"Mobile augmented reality interaction techniques for authoring situated media on-site","S. Guven; S. Feiner; O. Oda","Department of Computer Science, Columbia University, USA; Department of Computer Science, Columbia University, USA; Department of Computer Science, Columbia University, USA","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","235","236","We present a set of mobile augmented reality interaction techniques for authoring situated media: multimedia and hypermedia that are embedded within the physical environment. Our techniques are designed for use with a tracked hand-held tablet display with an attached camera, and rely on ""freezing"" the frame for later editing.","","1-4244-0650-1","10.1109/ISMAR.2006.297821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079283","","Augmented reality;Cameras;Virtual reality;Mars;Layout;Organizing;Books;Scattering;Mobile computing;Computer science","augmented reality;hypermedia;interactive systems;mobile computing","mobile augmented reality interaction technique;authoring situated media;multimedia;hypermedia;physical environment;hand-held tablet display","","29","","8","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Rendering of highly polygonal augmented reality applications on a scalable PC-cluster architecture","C. Matysczok; A. Wojdala","Heinz Nixdorf Institute, Germany; ORAD Hi-Tech Systems Limited, Poland","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","254","255","In the automobile industry virtual prototypes are often used within the product development process. Here computer models of cars which are still under development are generated and analyzed to reduce the time and costs for building and testing real prototypes. In this context the technology of augmented reality offers a new perspective. In this paper we describe a system architecture for a PC-cluster consisting of AR nodes for the image processing and VR nodes for the parallel rendering. The AR nodes analyze the live video coming from two cameras and calculate the tracking data for the VR nodes. According to the tracking data the VR nodes render the 3D objects in parallel. The rendered images are sent back to the AR nodes where they are mixed with the life video. The proposed scalable architecture provides a very high image quality and rendering performance. This allows the superimposing of highly polygonal 3D models at high frame rates and excellent image quality.","","0-7695-2191-6","10.1109/ISMAR.2004.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383063","","Augmented reality;Rendering (computer graphics);Virtual reality;Computer architecture;Image quality;Application software;Automobiles;Virtual prototyping;Product development;Costs","mechanical engineering computing;virtual prototyping;rendering (computer graphics);augmented reality;workstation clusters;automobile industry;video signal processing","highly polygonal augmented reality;scalable PC-cluster architecture;automobile industry virtual prototypes;system architecture;image processing;parallel rendering","","2","","4","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"A New Architecture of Augmented Reality Engine","Z. Xu; S. Wu; L. Zhang","Augmented Reality Laboratory, China Nanhu Academy of Electronics and Information Technology(CNAEIT), Jiaxing, China; Augmented Reality Laboratory, China Nanhu Academy of Electronics and Information Technology(CNAEIT), Jiaxing, China; Augmented Reality Laboratory, China Nanhu Academy of Electronics and Information Technology(CNAEIT), Jiaxing, China","2023 2nd International Conference on Mechatronics and Electrical Engineering (MEEE)","24 May 2023","2023","","","64","68","Augmented reality (AR) technology has been a rapidly developing research hotspot in the past ten years. AR combines computer-generated virtual scenes with the real world to achieve sensory enhancements beyond reality. As the middleware between the operating system layer and the application layer, the AR engine is a platform-based underlying technology and the cornerstone of building an augmented reality ecosystem. In this paper, a new AR engine architecture is proposed, and the core modules such as architecture composition, data management, algorithm integration, and multi-platform support interfaces are described in detail. Also, Nanhu AR engine (NHAR) is developed based on the new architecture. And an application is developed using NHAR to test marker-based tracking and marker-less tracking function of the developed engine.","","978-1-6654-7445-0","10.1109/MEEE57080.2023.10127071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127071","augmented reality;system architecture;date management;multi-platform support;virtual object tracking","Architecture;Operating systems;Semantics;Process control;Computer architecture;Robustness;Security","augmented reality;middleware;operating systems (computers)","application layer;AR engine architecture;architecture composition;augmented reality engine;computer-generated virtual scenes;marker-based tracking;marker-less tracking function;multiplatform support interfaces;Nanhu AR engine;operating system layer;platform-based underlying technology;sensory enhancements","","","","15","IEEE","24 May 2023","","","IEEE","IEEE Conferences"
"Video based augmented reality for immersive virtual reality system","Young-Yong Kim; Jun-Sik Kim; Jung-Min Park","Korea Institute of Science and Technology, Seongbuk-gu, Seoul, KR; Center for Robotics Research, Korea Institute of Science and Technology, Seoul, Korea; Center for Robotics Research, Korea Institute of Science and Technology, Seoul, Korea","2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","17 Dec 2015","2015","","","177","181","We presented a method to configure a video based augmented reality system for an immersive virtual reality. Since an audience can not observe 3D user interaction processes in the personalized immersive virtual reality, we need a system to share 3D interaction to the audience like an augmented reality system. Building on the augmented reality system using an RGBD sensor, we refine unstable depth measurements in front of non-Lambertian objects by filtering the image in two-steps and removing the shadow effect. Finally, we showed depth-aware augmented reality images to demonstrate our system.","","978-1-4673-7971-7","10.1109/URAI.2015.7358859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358859","Virtual Reality;Augmented Reality;Camera Calibration;3D Human Interaction","Three-dimensional displays;Augmented reality;Reactive power;Cameras;Image color analysis;Calibration","augmented reality;image colour analysis;image filtering;interactive systems;user interfaces;video signal processing","immersive virtual reality system;video based augmented reality system;3D user interaction;personalized immersive virtual reality;RGBD sensor;non-Lambertian objects;image filtering","","","","7","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"A day at the museum: An augmented fine-art exhibit","A. B. Tillon; E. Marchand; J. Laneurit; F. Servant; I. Marchal; P. Houlier","Orange Laboratories-INRIA Rennes, Université de Rennes, France; Orange Laboratories-INRIA Rennes, Université de Rennes, France; Orange Laboratories-INRIA Rennes, Université de Rennes, France; Orange Laboratories-INRIA Rennes, Université de Rennes, France; Orange Laboratories-INRIA Rennes, Université de Rennes, France; Orange Laboratories-INRIA Rennes, Université de Rennes, France","2010 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","22 Nov 2010","2010","","","69","70","This paper examines how an augmented reality guide can enrich museum visits. The results we obtained form an experiment conducted for a museum exhibit. An ergonomic experimentation has been conducted where real visitors use our augmented reality prototype. We collected feedback from these users, helping us to identify the usefulness of AR for museum visits or appreciation of art work. We conclude this paper by proposing some implications about the future usage of augmented reality in a museum context.","2381-8360","978-1-4244-9342-5","10.1109/ISMAR-AMH.2010.5643290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643290","museum education;experiments;augmented reality handheld device","Art;Painting;Image color analysis;Augmented reality;Games;Prototypes;Context","augmented reality;ergonomics;museums","museum;augmented reality;ergonomic experimentation","","9","","6","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"A Hybrid RTK GNSS and SLAM Outdoor Augmented Reality System","F. F. Ling; C. Elvezio; J. Bullock; S. Henderson; S. Feiner",Columbia University; Columbia University; Columbia University; Enlighten IT Consulting; Columbia University,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1044","1045","In the real world, we are surrounded by potentially important data. For example, military personnel and first responders may need to understand the layout of an environment, including the locations of designated assets, specified in latitude and longitude. However, many augmented reality (AR) systems cannot associate absolute geographic coordinates with the coordinate system in which they track. We describe a simple approach for developing a wide-area outdoor wearable AR system that uses RTK GNSS position tracking to align together and georegister multiple smaller maps from an existing SLAM tracking system.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798315","Human-centered computing;Human-computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Computing methodologies;Computer Graphics;Graphics systems and interfaces","Global navigation satellite system;Simultaneous localization and mapping;Augmented reality;Servers;Cameras;Global Positioning System;Base stations","augmented reality;robot vision;SLAM (robots)","wide-area outdoor wearable AR system;RTK GNSS position tracking;hybrid RTK GNSS;SLAM outdoor augmented reality system;augmented reality systems;SLAM tracking system","","6","","7","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"[DC] Glanceable AR: Towards an Always-on Augmented Reality Future","F. Lu","Department of Computer Science, Center for Human-Computer Interaction, Virginia Tech, USA","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","717","718","Augmented Reality (AR) glasses are widely believed to become the next-generation personal computing platform. They could be worn all-day, displaying everyday information continuously and pervasively to users. However, design and validation challenges remain unaddressed to resolve distractions, occlusions, and privacy concerns of applying AR in all sorts of everyday scenarios. This paper proposes a research agenda that aims at addressing these challenges to design for an always-on yet unobtrusive AR future.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419196","Human-centered computing;Mixed / augmented reality;Interaction techniques;User interface design","Privacy;Three-dimensional displays;Conferences;Glass;User interfaces;Augmented reality;Next generation networking","augmented reality;data privacy;interactive devices;ubiquitous computing","augmented reality glasses;next-generation personal computing platform;privacy concerns;AR future;augmented reality future;glanceable AR","","2","","4","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"A proof-of-concept study on the impact of artificial hypergravity on force-adapted target sizing for direct Augmented Reality pointing","D. Markov-Vetter; V. Zander; J. Latsch; O. Staadt",German Aerospace Center; German Sport University Cologne; German Sport University Cologne; University of Rostock,"2014 IEEE Virtual Reality (VR)","24 Apr 2014","2014","","","95","96","The performance of Augmented Reality (AR) direct object selection coded outside of the human egocentric body frame of reference is decreased under short-term altered gravity. Therefore an adequate countermeasure is required. This paper presents the results of a proof-of-concept (POC) study to investigate the impact of simulated hypergravity on target's size and distance. For gravity-dependent resizing and -positioning we used Hooke's law for the target deformation. The POC study was divided in two experiments, whereby hypergravity was induced by a long-arm human centrifuge and by weights attached to subjects' dominant arm. The study showed that at higher gravity levels larger target size and larger distance between the targets led to increased performance.","2375-5334","978-1-4799-2871-2","10.1109/VR.2014.6802068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802068","Augmented Reality;interaction;usability","Gravity;Augmented reality;Physiology;Heart rate variability;Visualization;Optical sensors;Educational institutions","augmented reality;human factors;user interfaces","artificial hypergravity;force-adapted target sizing;direct augmented reality pointing;augmented reality direct object selection;AR direct object selection;human egocentric body frame;short-term altered gravity;proof-of-concept study;POC study;gravity-dependent resizing;gravity-positioning;Hooke's law;target deformation;long-arm human centrifuge","","","","5","IEEE","24 Apr 2014","","","IEEE","IEEE Conferences"
"The Kuroko Paradigm: The Implications of Augmenting Physical Interaction with AR Avatars","T. Gao; Y. Itoh",Tokyo Institute of Technology; Tokyo Institute of Technology,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","26","27","We propose a concept in this poster paper, the Kuroko Paradigm, which is able to enhance user engagement during interaction with an augmented reality (AR) avatar by adding a physical object to the interaction with the avatar. With the development of AR and VR, interactions between users and AR avatars have been realized with different approaches. However, most of such interactions and experiences are passive, from which users do not expect a high level of engagement. We hypothesize that by introducing a reality actuator, such as a robot or a drone, to handle a physical object triggered by the user without being noticed, and rendering AR avatars as interacting with the physical object at the same time, user engagement during the experience will be enhanced. To prove this concept, we conducted an experiment emulating a classic game of catch. In the experiment, a user will try to throw a ball to an AR avatar, and the ball will be caught by a reality actuator. From the user's perspective, the ball is caught by the AR avatar. In the future, we plan to extend the experiment by adding control groups with differing conditions.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951780","Computing methodologies;Computer graphics;Mixed / augmented reality;Graphics systemsand interface","Avatars;Actuators;Augmented reality;Resists;Manipulators","augmented reality;avatars;human computer interaction;rendering (computer graphics)","physical interaction;AR avatar;user engagement;augmented reality avatar;physical object;reality actuator;Kuroko paradigm;AR avatars;rendering","","1","","7","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Implementation of the Framework to Heritage Education Supported in Augmented Reality","R. Mendoza; A. Cabarcas; R. Fabregat; S. Baldiris",Universitat de Girona; Universidad de Cartagena; Universitat de Giron; Universidad Internacional de la Rioja,"2019 International Conference on Virtual Reality and Visualization (ICVRV)","6 Oct 2020","2019","","","154","157","Heritage education is a process that traditionally has been implemented in a similar way to how schools work, a teacher transmits certain knowledge to a student. Nevertheless, lately, there have been new experiences that integrate Augmented Reality into the processes of heritage education. This paper describes an experience of an Augmented Reality application called “Social Heritage” that supports heritage education processes, and is based on a framework called “Framework to Heritage Education supported in Augmented Reality”. This work presents the results of the application of the framework in the city of Cartagena - Colombia, where positive results were obtained with citizens and visitors. These Results are related to positive experiences and motivation when users use Augmented Reality technologies to develop heritage education processes.","2375-141X","978-1-7281-4752-9","10.1109/ICVRV47840.2019.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212813","Heritage Education;Framework for Heritage Education;Augmented Reality","Education;Augmented reality;Visualization;Urban areas;Electronic mail;Sociology;Statistics","augmented reality;computer aided instruction;history","Colombia;Cartagena city;augmented reality technologies;heritage education;social heritage","","","","13","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"Development and preliminary investigation of Augmented Reality Experiment Simulation (AReX) interface","W. Matcha; D. R. A. Rambli","Computer and Information Science Department, Universiti Teknologi Petronas, Bandar Seri Iskandar, Tronoh, Perak, Malaysia; Computer and Information Science Department, Universiti Teknologi Petronas, Bandar Seri Iskandar, Tronoh, Perak, Malaysia","2011 National Postgraduate Conference","23 Jan 2012","2011","","","1","5","This paper presents the design and development of Augmented Reality Experiment Simulation (AReX) prototype as well as the preliminary user study based on the Augmented Reality (AR) interface. AR is an emerging technology which takes advantages of coexistence of physical world and richness of multimedia supported. AReX was developed to facilitate group learning through science experiment. The preliminary study on the prototype has been conducted. The initial results show that students worked collaboratively on the experiment and they were enjoy doing experiment through AR interface. However, the prototype required more improvement on the physical lab worksheet and the simulation part.","","978-1-4577-1884-7","10.1109/NatPC.2011.6136305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6136305","Augmented Reality;Computer-Supported Collaborative Learning;Collaborative Augmented Reality;Augmented Reality Interface","Collaboration;Augmented reality;Prototypes;Collaborative work;Dispersion;Education;Monitoring","augmented reality;computer aided instruction;groupware;user interfaces","augmented reality experiment simulation interface;augmented reality experiment simulation prototype;emerging technology;group learning;physical lab worksheet","","","","16","IEEE","23 Jan 2012","","","IEEE","IEEE Conferences"
"The Trouble with Augmented Reality/Virtual Reality Authoring Tools","M. Nebeling; M. Speicher",University of Michigan School of Information; University of Michigan School of Information,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","333","337","There are many technical and design challenges in creating new, usable and useful AR/VR applications. In particular, non-technical designers and end-users are facing a lack of tools to quickly and easily prototype and test new AR/VR user experiences. We review and classify existing AR/VR authoring tools and characterize three primary issues with these tools based on our review and a case study. To address the issues, we discuss two new tools we designed with support for rapid prototyping of new AR/VR content and gesture-based interactions geared towards designers without technical knowledge in gesture recognition, 3D modeling, and programming.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699236","augmented reality;virtual reality;authoring;design;rapid prototyping;3D modeling;gestures;Wizard of Oz;Human-centered computing;Interaction paradigms;Mixed / augmented reality","Tools;Three-dimensional displays;Solid modeling;Animation;Programming;Authoring systems;Tracking","augmented reality;authoring systems;gesture recognition;human computer interaction;software prototyping;user experience","rapid prototyping;gesture-based interactions;virtual reality authoring tools;augmented reality authoring tools;VR authoring tools;AR authoring tools;VR user experiences;AR user experiences","","48","","34","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Designing and comparing two-handed gestures to confirm links between user controlled objects","P. Maier; M. Tönnis; G. Klinker","Fachgebiet Augmented Reality (FAR), Fakultät für Informatik, Technische Universität München, Munchen, Germany; Fachgebiet Augmented Reality (FAR), Fakultät für Informatik, Technische Universität München, Munchen, Germany; Fachgebiet Augmented Reality (FAR), Fakultät für Informatik, Technische Universität München, Munchen, Germany","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","251","252","Systems using two-handed spatial manipulation techniques also require strategies to enable system control tasks. These strategies make it possible to interact with the system comfortably while controlling two hand-held objects simultaneously. The Augmented Chemical Reactions project makes intense use of such two-handed interaction tasks. Users control virtual molecules and subsets that are registered to physical markers and try to combine those by selecting and then confirming a specific bond. When a desired bond has been selected, the user needs a way to confirm that bond without letting an atom go out of position. We developed and investigated two separate methods of confirming a selected bond when both hands are already doing a two-handed symmetric interaction task. The first method is a waiting method and the second method is a back&forth motion gesture. We evaluated the two methods in a user study, showing that the first technique, holding still, outperforms the other technique.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643592","","Visualization;Chemicals;Jitter;Time measurement;Augmented reality;Three dimensional displays;Interviews","augmented reality;chemical reactions;gesture recognition","two handed gesture;user controlled object;spatial manipulation technique;augmented chemical reaction;symmetric interaction task","","","","6","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"SenseShapes: using statistical geometry for object selection in a multimodal augmented reality","A. Olwal; H. Benko; S. Feiner","Department of Computer Science, Columbia University, NY, USA; Department of Computer Science, Columbia University, NY, USA; Department of Computer Science, Columbia University, NY, USA","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","300","301","We introduce a set of statistical geometric tools designed to identify the objects being manipulated through speech and gesture in a multimodal augmented reality system. SenseShapes are volumetric regions of interest that can be attached to parts of the user's body to provide valuable information about the user's interaction with objects. To assist in object selection, we generate a rich set of statistical data and dynamically choose which data to consider based on the current situation.","","0-7695-2006-5","10.1109/ISMAR.2003.1240730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240730","","Geometry;Augmented reality;Head;Computer science;Buildings;Fusion power generation;Microphones;Monitoring;Speech recognition;Optical sensors","augmented reality;speech recognition;audio user interfaces;computational geometry;haptic interfaces;speech-based user interfaces","SenseShapes;statistical geometry;object selection;multimodal augmented reality;geometric tools;speech identification;gesture identification;volumetric regions;user body;user interaction;statistical data","","31","5","5","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"3D audio augmented reality: implementation and experiments","V. Sundareswaran; K. Wang; S. Chen; R. Behringer; J. McGee; C. Tam; P. Zahorik","Rockwell Scientific Company Limited Liability Company, Thousand Oaks, CA, USA; Rockwell Scientific Company Limited Liability Company, Thousand Oaks, CA, USA; Rockwell Scientific Company Limited Liability Company, Thousand Oaks, CA, USA; Rockwell Scientific Company Limited Liability Company, Thousand Oaks, CA, USA; Rockwell Scientific Company Limited Liability Company, Thousand Oaks, CA, USA; Rockwell Scientific Company Limited Liability Company, Thousand Oaks, CA, USA; Waisman Center, University of Wisconsin, Madison, WI, USA","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","296","297","Augmented reality (AR) presentations may be visual or auditory. Auditory presentation has the potential to provide hands-free and visually non-obstructing cues. Recently, we have developed a 3D audio wearable system that can be used to provide alerts and informational cues to a mobile user in such a manner as to appear to emanate from specific locations in the user's environment. In order to study registration errors in 3D audio AR representations, we conducted a perceptual training experiment in which visual and auditory cues were presented to observers. The results of this experiment suggest that perceived registration errors may be reduced through head movement and through training presentations that include both visual and auditory cues.","","0-7695-2006-5","10.1109/ISMAR.2003.1240728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240728","","Augmented reality;Magnetic heads;Navigation;Position measurement;Global Positioning System;Engines;Auditory displays;Feedback;Three dimensional displays;Application software","augmented reality;audio-visual systems;user modelling;three-dimensional displays","3D audio augmented reality;auditory presentation;nonobstructing cues;3D audio wearable system;informational cues;mobile user;user environment;registration errors;audio AR representations;perceptual training experiment;visual cues;auditory cues;head movement;training presentations","","8","3","3","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"A wearable augmented reality system with personal positioning based on walking locomotion analysis","M. Kourogi; T. Kurata","National Institute for Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; University of Washington, USA","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","342","343","In this paper, we present a wearable augmented reality (AR) system with personal positioning based on walking locomotion analysis that allows a user to freely mover around indoors and outdoors. The user is equipped with self-contained sensors, a wearable camera, an inertial head tracker and display. The system is based on the sensor fusion of estimates for relative displacement caused by human walking locomotion and estimates for absolute position and orientation within a Kalman filtering framework. The former is based on intensive analysis of human walking behavior using self-contained sensors. The latter is based on image matching of video frames from a wearable camera with an image database that was prepared beforehand.","","0-7695-2006-5","10.1109/ISMAR.2003.1240751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240751","","Augmented reality;Legged locomotion;Wearable sensors;Cameras;Humans;Head;Displays;Sensor fusion;Kalman filters;Filtering","cameras;augmented reality;Kalman filters;position measurement;sensor fusion;image matching;gesture recognition;wearable computers","wearable augmented reality;personal positioning;walking locomotion analysis;self-contained sensors;wearable camera;inertial head tracker;inertial head display;sensor fusion;relative displacement;human walking locomotion;absolute position;Kalman filtering framework;intensive analysis;human walking behavior;image matching;video frames;image database","","3","1","4","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Case studies in application of augmented reality in future media production","A. Woolard; V. Laliodati; N. Hedley; N. Carrigan; M. Hammond; J. Julien","BBC Creative R&D, UK; NA; ARToolworks Inc., USA; BBC Creative R&D, UK; BBC Research & Development, UK; BBC Creative R&D, UK","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","294","295","In this application-based poster, we describe three case studies about potential application of augmented reality (AR) in the broadcasting and entertainment industry. The poster covers the potential impact on BBC's principal objectives to ""entertain, educate and inform"" in a variety of environments such as broadcast studios, classrooms and in the home.","","0-7695-2006-5","10.1109/ISMAR.2003.1240727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240727","","Computer aided software engineering;Augmented reality;Production;Broadcasting;Multimedia communication;Animation;Displays;Broadcast technology;Research and development;Textile industry","augmented reality;multimedia computing;entertainment;broadcasting;educational computing","case studies;augmented reality;media production;application-based poster;broadcasting industry;entertainment industry;BBC;principal objectives;news information;science education;broadcast studios;classrooms;home","","2","","8","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Collaborative work with volumetric data using augmented reality","I. Barakonyi; T. Fahmy; D. Schmalstieg; K. Kosina","University of Technology, Vienna, Austria; University of Technology, Vienna, Austria; University of Technology, Vienna, Austria; Systems in Motion, Norway","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","333","334","The augmented reality videoconferencing system is a novel remote collaboration tool combining a desktop-based AR system and a videoconferencing module. The novelty of our system is the combination of these tools i.e. superimposing AR applications on live video background displaying the conference parties' real environment, thus merging the advantages of videoconferencing (natural face-to-face communication) and AR (interaction with distributed virtual objects using tangible physical artifacts). We demonstrate the system's collaborative features with a volume rendering application that allows users to display and examine volumetric data simultaneously and to highlight or explore slices of the volume by manipulating an optical marker as a cutting plane interaction device.","","0-7695-2006-5","10.1109/ISMAR.2003.1240746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240746","","Collaborative work;Augmented reality;Teleconferencing;Videoconference;Application software;Computer displays;Collaboration;Data mining;Collaborative tools;Biomedical optical imaging","groupware;teleconferencing;augmented reality;software tools;data visualisation;rendering (computer graphics)","collaborative work;volumetric data;augmented reality;videoconferencing system;remote collaboration tool;desktop-based AR system;videoconferencing module;AR applications;live video background;face-to-face communication;distributed virtual objects;tangible physical artifacts;collaborative features;volume rendering application;optical marker;interaction device;Computer Supported Collaborative Work","","","3","5","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Problems Arising in the Design of Workstations Based on Augmented Reality","V. L. Averbukh; N. V. Averbukh; I. Gajniyarov","Institute of Mathematics and Mechanics Ural Branch of Russian Academy of Sciences, IMCS Ural Federal University, Yekaterinburg, Russia; Department of Psychology, Ural Federal University, Yekaterinburg, Russia; Institute of Mathematics and Mechanics Ural Branch of Russian Academy of Sciences, Yekaterinburg, Russia","2020 Global Smart Industry Conference (GloSIC)","30 Nov 2020","2020","","","55","59","Recently, workstations have been designed and developed based on augmented reality, for assembly/disassembly of complex devices and mechanisms. Augmented reality should help operators by outputting visual information regarding the device structure, action and operation tips. Augmented reality can also be used to inform vehicle drivers and aviation pilots. For example, a pilot will see itinerary and airspeed data on an augmented reality headset, without looking at displays and indicators in the cockpit. These developments are relevant, but for them to be efficient, rigorous research is needed. First, a full-scale description of an operator's (worker's, driver's or pilot's) activity is necessary. This description includes defining goals, setting tasks, describing conditions, actions and operations. Further, augmented reality devices, suitable for the specific operator, should be chosen. Necessary types of visual information display should be described: for example, displaying the inner structure of mechanisms or their images from different angles. An important aspect of design is the choice of methods for system interactions. One should remember that, at work, an operator's hands are busy. That is why the interfaces should not interfere with their main activity. Thus, design and development of workstations based on augmented reality should be conducted together with experts in specific fields, including the operators themselves. One should note the insufficiency of knowledge regarding an augmented reality user's state when he or she is carrying out serious activities. Theoretical and experimental research is required. All this is necessary for the developed systems to be efficient, comfortable and safe.","","978-1-7281-8075-5","10.1109/GloSIC50886.2020.9267817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9267817","augmented reality;workstations;interfaces;user state in augmented reality","Augmented reality;Workstations;Sensors;Headphones;Visualization;Task analysis;Micromechanical devices","augmented reality;user interfaces","augmented reality headset;augmented reality devices;workstations design;user interfaces","","","","16","IEEE","30 Nov 2020","","","IEEE","IEEE Conferences"
"The Paranoid Interface","H. Davies",La Trobe University,"2015 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design","10 Dec 2015","2015","","","27","29","This paper explores the rise of paranoid perception. It reasons that in recent years, a distinctly paranoid and conspiratorial understanding of reality has emerged in mainstream society, one that brings opportunities and implications for mixed, alternate and augmented reality experiences, particularly in the realm of games. In discussing paranoia, this paper does not denote clinical paranoia, but rather the widely observed cultural tendency towards conspiracy thinking that has influenced mainstream understandings of reality, and in turn, represents opportunities for hybrid reality experiences. This paper does not aim to explain the reasons behind the presence of paranoid perception or to assess its validity or truth-value, but instead aims to recognise the pervasiveness of the phenomenon and to explore how it is being applied in hybrid reality games.","","978-1-4673-9628-8","10.1109/ISMAR-MASHD.2015.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350731","Paranoia;Hybrid Reality;Augmented Reality;Alternate Reality Games;Interaction","Games;Augmented reality;Art;Terrorism;Entertainment industry;Google;Media","augmented reality;computer games;ubiquitous computing;user interfaces","paranoid interface;paranoid perception;paranoid reality;augmented reality experiences;clinical paranoia;cultural tendency;hybrid reality experiences;pervasiveness;hybrid reality games","","","","11","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"Medical augmented reality for craniofacial application using surface deformation correction","H. -C. Lee; J. -D. Lee; S. -T. Lee; C. -T. Wu","Department of Electrical Engineering, Chang Gung University, Taoyuan, Taiwan; Department of Electrical Engineering, Chang Gung University, Taoyuan, Taiwan; Department of Neurosurgery and Medical Augmented Reality Research Center, Chang Gung Memorial Hospital, Tao-Yuan, Taiwan; Department of Neurosurgery and Medical Augmented Reality Research Center, Chang Gung Memorial Hospital, Tao-Yuan, Taiwan","2015 IEEE International Conference on Consumer Electronics - Taiwan","24 Aug 2015","2015","","","234","235","The paper presents a novel scheme that uses a projector to project a corrected CT image on the craniofacial surface for augmented reality visualization. The deformation of the projected image due to curved surface can be successful recovered via homography projection correction. The experimental result that shows the superior performance of this work is also included.","","978-1-4799-8745-0","10.1109/ICCE-TW.2015.7216873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7216873","","Computed tomography;Augmented reality;Biomedical imaging;Cameras;Visualization;Surgery","augmented reality;computerised tomography;data visualisation;medical image processing","medical augmented reality;craniofacial application;surface deformation correction;corrected CT image;augmented reality visualization;homography projection correction","","","","5","IEEE","24 Aug 2015","","","IEEE","IEEE Conferences"
"Human-centered Augmented Reality Guidance for Industrial Maintenance with Digital Twins: A Use-Case Driven Pilot Study","A. Büchner; G. Micheli; J. Gottwald; L. Rudolph; D. Pantförder; G. Klinker; B. Vogel-Heuser",Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","74","76","Industrial augmented reality research depends on precise use case descriptions and close communication with specialists from the field. Therefore, user-centered methods should lead this research. This work describes the use case of corrective maintenance in chemical industries. This is done by presenting a use case description as well as extracting and discussing augmented reality functionalities in the context of existing research and emerging digital twin platforms. Additionally, the work provides insights into the first iteration of pro-totyping for the use case. The results offer future research directions and indicate how augmented reality might become a beneficial and accepted technology for maintenance in chemical industries.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974558","Scenario-based design;Mixed / augmented reality","Chemical industry;Solid modeling;Three-dimensional displays;Documentation;Maintenance engineering;Lead;Hardware","augmented reality;industrial engineering;maintenance engineering","augmented reality guidance;chemical industries;chemical industries;corrective maintenance;digital twins;human-centered augmented reality guidance;industrial augmented reality;industrial maintenance;use case description;user-centered methods","","1","","13","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Unified Context-Aware Augmented Reality Application Framework for User-Driven Tour Guides","C. Shin; H. Kim; C. Kang; Y. Jang; A. Choi; W. Woo","U-VR Laboratory, GIST, Gwangju, South Korea; U-VR Laboratory, GIST, Gwangju, South Korea; U-VR Laboratory, GIST, Gwangju, South Korea; U-VR Laboratory, GIST, Gwangju, South Korea; U-VR Laboratory, GIST, Gwangju, South Korea; U-VR Laboratory, GIST, Gwangju, South Korea","2010 International Symposium on Ubiquitous Virtual Reality","26 Aug 2010","2010","","","52","55","We propose a unified context-aware augmented reality application framework that supports intelligent guidance and enables users to participate in content generation in museum guidance. It helps a user find personal interesting artifacts in art galleries by exploiting context-based behavior generation. The framework also enables them to combine augmented contents with different information to change the shape of content according to their preferences. Furthermore, it allows the users to label real objects for attaching new contents over the objects. Through demonstration in an art gallery, we found that the resulting system effectively guided users to visit and enabled them to participate in tour guidance.","","978-1-4244-7702-9","10.1109/ISUVR.2010.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557930","Augmented Reality;Context-Awareness;Mobile Computing;Ubiquitous Virtual Reality","Context;Augmented reality;Mobile communication;Visualization;Mashups;Object recognition","augmented reality;museums;ubiquitous computing","unified context aware augmented reality application;user driven tour guides;content generation;intelligent guidance;museum guidance;art galleries","","9","3","18","IEEE","26 Aug 2010","","","IEEE","IEEE Conferences"
"3rd Virtual and Augmented Reality for Good (VAR4Good) Workshop","A. Dey; M. Billinghurst; G. Welch; E. Rojas-Muñoz",NA; NA; NA; NA,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","364","364","Virtual Reality (VR) and Augmented Reality (AR) are becoming mainstream. With the research and technological advances, it is now possible to use these technologies in almost all domains and places. This provides a bigger opportunity to create applications that intend to impact society in greater ways than beyond just entertainment. Today the world is facing different challenges including healthcare, environment, and education. Now is the time to explore how VR/AR might be used to solve widespread societal challenges. The third Virtual and Augmented Reality for Good (VAR4Good) workshop will bring together researchers, developers, and industry partners in presenting and promoting research that intends to solve real-world problems using VR/AR. The workshop will provide a platform to grow a research community that discusses challenges and opportunities to create Virtual and Augmented Reality for Good. We invite application and position papers (2-4 pages, excluding references), that address the way that VR/AR technologies can solve real-world problems in various application domains including, but not limited to, health, the environment, education, sports, the arts, and applications in support of special needs such as assistive, adaptive, and rehabilitative applications. Our focus and preference will be on applications that are beyond general uses of VR/AR. Please see full CFP on our website.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699256","","Augmented reality;Conferences;Australia;Education;Entertainment industry;Medical services","augmented reality;human computer interaction;technology management","VAR4Good;technological advances;Virtual and Augmented Reality for Good workshop;VR/AR technologies","","1","","","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Simulation of Augmented Reality Systems in Purely Virtual Environments","E. Ragan; C. Wilkes; D. A. Bowman; T. Hollerer","Department of Computer Science, Virginia Technology, Blacksburg, VA, USA; Department of Computer Science, Virginia Technology, Blacksburg, VA, USA; Department of Computer Science, Virginia Technology, Blacksburg, VA, USA; Department of Computer Science, University of California,슠Santa Barbara, Santa Barbara, CA, USA","2009 IEEE Virtual Reality Conference","7 Apr 2009","2009","","","287","288","We propose the use of virtual environments to simulate augmented reality (AR) systems for the purposes of experimentation and usability evaluation. This method allows complete control in the AR environment, providing many advantages over testing with true AR systems. We also discuss some of the limitations to the simulation approach. We have demonstrated the use of such a simulation in a proof of concept experiment controlling the levels of registration error in the AR scenario. In this experiment, we used the simulation method to investigate the effects of registration error on task performance for a generic task involving precise motor control for AR object manipulation. Isolating jitter and latency errors, we provide empirical evidence of the relationship between accurate registration and task performance.","2375-5334","978-1-4244-3943-0","10.1109/VR.2009.4811058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811058","Augmented reality;AR simulation;registration error","Augmented reality;Virtual environment;Virtual reality;System testing;Error correction;Displays;Computational modeling;Computer simulation;Computer science;Usability","augmented reality;digital simulation","augmented reality system;virtual environment;usability evaluation;system simulation;registration error;task performance;motor control;object manipulation","","50","2","3","IEEE","7 Apr 2009","","","IEEE","IEEE Conferences"
"History and Future of Tracking for Mobile Phone Augmented Reality","D. Wagner; D. Schmalstieg","Graz University of Technology, Austria; Graz University of Technology, Austria","2009 International Symposium on Ubiquitous Virtual Reality","4 Sep 2009","2009","","","7","10","We present an overview on the history of tracking for mobile phone augmented reality. We present popular approaches using marker tracking, natural feature tracking or offloading to nearby servers. We then outline likely future work.","","978-1-4244-4437-3","10.1109/ISUVR.2009.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232244","Augmented Reality;Mobile Phones;Pose Tracking","History;Mobile handsets;Augmented reality;Virtual reality;Displays;Robustness;Cameras;Computer vision;Personal communication networks;Personal digital assistants","augmented reality;mobile computing","mobile phone augmented reality;marker tracking;natural feature tracking","","22","3","20","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"On Computer Vision for Augmented Reality","V. Lepetit","Computer Vision Laboratory, Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland","2008 International Symposium on Ubiquitous Virtual Reality","18 Jul 2008","2008","","","13","16","We review some recent techniques for 3D tracking and occlusion handling for computer vision-based augmented reality. We discuss what their limits for real applications are, and why object recognition techniques are certainly the key to further improvements.","","978-0-7695-3259-2","10.1109/ISUVR.2008.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568635","Augmented Reality;Computer Vision","Computer vision;Augmented reality;Cameras;Application software;Target tracking;Robustness;Object recognition;Registers;Magnetic sensors;Virtual reality","augmented reality;computer vision;object recognition","augmented reality;computer vision;3D tracking;occlusion;object recognition techniques","","10","","6","IEEE","18 Jul 2008","","","IEEE","IEEE Conferences"
"Exploiting Context-Awareness in Augmented Reality Applications","W. Lee; W. Woo","Gwangju, GIST U VR Laboratory, Gwangju, South Korea; Gwangju, GIST U VR Laboratory, Gwangju, South Korea","2008 International Symposium on Ubiquitous Virtual Reality","18 Jul 2008","2008","","","51","54","In this paper, we study how to exploit the context-awareness in augmented reality (AR) applications to take advantage of the context in both the high-level and low-level processing. We propose an AR system architecture that works with a context-awareness framework. In the system, both the preliminary and the final context is provided to the process that needs the context. We provide two scenarios that exploit the context in AR applications in the low-level processing and show implementation results with the proposed system. In the first scenario, we adopt a light sensor to enhance the marker detection performance under the varying lighting condition. In the second scenario, we exploit the context in the marker recognition stage where a single color marker is recognized as several different sub-markers based on the context. By adopting the context in the low-level processing, it is possible to address the problems that are hard to be solved by the computer vision techniques only.","","978-0-7695-3259-2","10.1109/ISUVR.2008.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568645","Context-awareness;augmented reality;smart marker;personalization","Augmented reality;Computer vision;Control systems;Context-aware services;Data mining;Ubiquitous computing;Virtual reality;User interfaces;Home appliances;Sensor systems","augmented reality;software architecture;ubiquitous computing","context-awareness;augmented reality;system architecture;marker recognition stage","","4","","6","IEEE","18 Jul 2008","","","IEEE","IEEE Conferences"
"Support on the Remote Interaction for Augmented Reality System","E. Parra Affonso; A. C. Sementille","Programa de Pós Graduação em Ciência da Computação, Centro Universitário Eurípides de Marília, Marilia, Santa Catarina, Brazil; Laboratório de Sistemas de Tempo Real (LSTR), Departamento de Computação (Dco), Universidade Estadual Paulista (Unesp), Bauru, Santa Catarina, Brazil","17th International Conference on Artificial Reality and Telexistence (ICAT 2007)","2 Jan 2008","2007","","","190","196","This article presents a support on the remote interaction for utilization in augmented reality systems based on ARToolkit. It utilizes the multicast communication in order to improve the scalability of distributed environment. This support may be utilized in production of specific applications pointed to distance education, training and entertainment. The validity of support happened with the implementation of a prototype and realization of tests for communication latency analysis and frames per second rate.","","0-7695-3056-7","10.1109/ICAT.2007.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414633","Augmented Reality;Communication and Interaction","Augmented reality;Multicast communication;Application software;Libraries;Virtual reality;Computer networks;Sockets;Layout;Books;Collaboration","augmented reality;human computer interaction","remote interaction;augmented reality system;multicast communication;distance education;entertainment","","1","","11","IEEE","2 Jan 2008","","","IEEE","IEEE Conferences"
"Augmented reality speech recognition for the hearing impaired","I. Dabran; T. Avny; E. Singher; H. Ben Danan","Faculty of Computer Science, The Laboratory of Systems and Software Development, Technion, Haifa, Israel; Faculty of Computer Science, The Laboratory of Systems and Software Development, Technion, Haifa, Israel; Faculty of Computer Science, The Laboratory of Systems and Software Development, Technion, Haifa, Israel; Faculty of Computer Science, The Laboratory of Systems and Software Development, Technion, Haifa, Israel","2017 IEEE International Conference on Microwaves, Antennas, Communications and Electronic Systems (COMCAS)","4 Jan 2018","2017","","","1","4","Our paper presents a novel Speech Recognition Augmented Reality tool for hearing impaired people, based on a case study of a simple Domain Based Speech Recognition approach. Choosing the correct word out of samples with similar acoustic structure is an important challenge in Speech Recognition research. Our scheme improves transcription accuracy in local vocabulary environments, such as in meetings, lectures etc. We developed a tool that combines our approach in an Augmented Reality environment in order to create real-time “live subtitles” using our unique Speech Recognition process. This tool enables hearing impaired and deaf people to see real-time Augmented Reality subtitles while hearing a talk on a specific subject.","","978-1-5386-3169-0","10.1109/COMCAS.2017.8244731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8244731","Smart Devices;Internet of Things;Social Computing;Speech Recognition;Augmented Reality","Speech recognition;Augmented reality;Tools;Auditory system;Solid modeling;Microwave antennas;Real-time systems","augmented reality;handicapped aids;hearing;speech recognition","hearing impaired people;correct word;similar acoustic structure;Speech Recognition research;local vocabulary environments;Augmented Reality environment;unique Speech Recognition process;real-time Augmented Reality subtitles;Speech Recognition Augmented Reality tool;Domain Based Speech Recognition approach;deaf people","","9","","12","IEEE","4 Jan 2018","","","IEEE","IEEE Conferences"
"Augmented Reality and its effect on our life","R. Aggarwal; A. Singhal","ASET, Amity University Uttar Pradesh, Noida, India; ASET, Amity University Uttar Pradesh, Noida, India","2019 9th International Conference on Cloud Computing, Data Science & Engineering (Confluence)","29 Jul 2019","2019","","","510","515","Augmented Reality is a combination of a real and a computer-generated or virtual world. It is achieved by augmenting computer-generated images on real world. It is of four types namely marker based, marker less, projection based and superimposition based augmented reality. It has many applications in the real world. AR is used in various fields such as medical, education, manufacturing, robotics and entertainment. Augmented reality comes under the field of mixed reality. It can be considered as an inverse reflection of Virtual Reality. They both have certain similarities and differences. This paper gives information about Augmented Reality and how it started. It analyses various types of augmented reality, its applications and its advantages and disadvantages. This paper also gives us knowledge regarding those major threats that augmented reality will face in the near future and about its current and future applications. It gives us a comparison between the two related topics, Augmented reality and Virtual reality. The following paper also helps us know about the effect of Augmented Reality on the human life.","","978-1-5386-5933-5","10.1109/CONFLUENCE.2019.8776989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8776989","Augmented Reality;Virtual reality;Mixed Reality;Real World;Virtual World","Augmented reality;Biomedical imaging;Education;Three-dimensional displays;User experience","augmented reality","augmented reality;virtual reality;AR","","37","","19","IEEE","29 Jul 2019","","","IEEE","IEEE Conferences"
"Designing and conducting research using immersive technologies in schools: Seven observations","E. Southgate; S. P. Smith","School of Education, University of Newcastle, Australia; School of Electrical Engineering and Computing, University of Newcastle, Australia","2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual & Augmented Reality (KELVAR)","29 Jun 2017","2017","","","1","3","This paper documents seven key areas for consideration when designing and conducting research using immersive virtual, augmented and mixed reality technologies in school settings. We provide seven observations drawn from the literature, theory and research experience to offer initial methodological, ethical and practical advice on such research. These observations are designed to prompt a broader interdisciplinary conversation and knowledge-base on school-based research using immersive technologies, so that the educational benefits of the technologies can be fuller realised.","","978-1-5386-1892-9","10.1109/KELVAR.2017.7961564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961564","Virtual reality;augmented reality;mixed reality;methodology;children;adolescents;K-12 education;learning;ethics;teachers;school","Augmented reality;Educational technology;Ethics;Computers;Pediatrics","augmented reality;computer aided instruction;educational institutions;knowledge based systems","research designing;research conducting;immersive technologies;virtual reality;augmented reality;mixed reality;school settings","","5","","26","IEEE","29 Jun 2017","","","IEEE","IEEE Conferences"
"Coordinate: A Spreadsheet-Programmable Augmented Reality Framework for Immersive Map-Based Visualizations","A. Shaikh; L. Nguyen; A. Bahremand; H. Bartolomea; F. Liu; V. Nguyen; D. Anderson; R. LiKamWa","School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA; School of Arts, Media and Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; Department of Psychology, Arizona State University, Tempe, AZ, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA; School of Public Affairs, Arizona State University, Tempe, AZ, USA; School of Arts, Media and Engineering, Arizona State University, Tempe, AZ, USA","2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","134","1343","Augmented reality devices are opening up a new design space for immersive visualizations. 3D spatial content can be overlaid onto existing physical visualizations for new insights into the data. We present Coordinate, a collaborative analysis tool for augmented reality visualizations of map-based data designed for mobile devices. Coordinate leverages a spreadsheet-programmable web interface paired with a contemporary augmented reality infrastructure for an easy-to-use tool that can provide spatial information to multiple users. It also offers an immersive visualization experience that seeks to enrich presentations for business, educational, and scientific discussions.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942377","augmented reality;map based visualization;data visualization;mobile devices","Conferences;Artificial intelligence;Virtual reality;6G mobile communication;Integrated circuits","augmented reality;cartography;data visualisation;Internet;mobile computing;spreadsheet programs","spreadsheet-programmable augmented reality framework;immersive map-based visualizations;augmented reality devices;design space;immersive visualizations;3D spatial content;physical visualizations;collaborative analysis tool;augmented reality visualizations;map-based data;mobile devices;contemporary augmented reality infrastructure;easy-to-use tool;spatial information;immersive visualization experience;spreadsheet-programmable Web interface;Coordinate","","2","","6","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"Investigation of Microcirculatory Effects of Experiencing Burning Hands in Augmented Reality","D. Eckhoff; C. Li-Tsang; G. Cheing; A. Cassinelli; C. Sandor","School of Creative Media City University of Hong Kong, Hong Kong; Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong; Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong; School of Creative Media City University of Hong Kong, Hong Kong; School of Creative Media City University of Hong Kong, Hong Kong","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","569","570","In this paper, we report on our experiment to investigate the extent to which the human body reacts to virtual thermal stimuli presented in Augmented Reality (AR). Our AR experience enables users to see and hear their own hands burning while looking through a Video SeeThrough Head-Mounted Display (VST-HMD). We hypothesized that this AR experience can lead to a change in Skin Blood Flow (SkBF). Our results show that the SkBF in the affected hand did change significantly on some participants. They experienced a change of blood flow similarly to real thermal stimulation.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419295","Human-centered computing;Mixed / augmented reality Applied computing;Psychology","Three-dimensional displays;Head-mounted displays;Conferences;User interfaces;Skin;Augmented reality;Blood flow","augmented reality;biomedical measurement;biothermics;haemodynamics;helmet mounted displays;human computer interaction;medical computing;skin;virtual reality","AR experience;skin blood flow;thermal stimulation;microcirculatory effects;burning hands;augmented reality;virtual thermal stimuli;video seethrough head-mounted display;human body","","1","","12","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Model-based visual tracking for outdoor augmented reality applications","R. Behringer; Jun Park; V. Sundareswaran","Rockwell Science Center, South Korea; Rockwell Science Center, South Korea; Rockwell Science Center, South Korea","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","277","322","Outdoor augmented reality (AR) applications rely on hybrid tracking (GPS, digital compass, visual) for registration. RSC has developed a real-time visual tracking system that uses visual cues of buildings in an urban environment for correcting the results of a conventional tracking system. This approach relies on knowledge of a CAD model of the building. It not only provides motion estimation, but also absolute orientation/position. It is based on the ""visual servoing"" approach, originally developed for robotics tasks. We have demonstrated this approach in real-time at a building on the NRL campus This poster shows the approach and results. The concept can be generalized to any scenario where a CAD model is available. This system is being prepared for integration into the NRL system BARS (Battlefield Augmented Reality System).","","0-7695-1781-1","10.1109/ISMAR.2002.1115111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115111","","Augmented reality;Cameras;Image processing;Global Positioning System;Bars;Visual servoing;Real time systems;Motion estimation;Robots;Minimization methods","augmented reality;optical tracking;CAD;motion estimation;real-time systems;military computing;military systems","model-based visual tracking;outdoor augmented reality applications;hybrid tracking;digital compass;GPS;registration;real-time visual tracking system;visual cues;buildings;urban environment;CAD model;motion estimation;absolute orientation;absolute position;visual servoing;Battlefield Augmented Reality System","","12","","7","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"[POSTER] Transforming Your Website to an Augmented Reality View","D. Ververidis; S. Nikolopoulos; I. Kompatsiaris","Centre for Research and Technology Hellas (CERTH), Greece; Centre for Research and Technology Hellas (CERTH), Greece; Centre for Research and Technology Hellas (CERTH), Greece","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","108","111","In this paper we present FastAR, a software component capable of transforming Joomla based websites into AR-channels compatible with the most popular augmented reality browsers (i.e. Junaio, Layar, Wikitude). FastAR exploits the consistency of the data structure across multiple sites that have been developed using the same content management system, so as to automate the transformation process of an internet website to an augmented reality channel. The proposed component abstracts all related programming tasks and significantly reduces the time required to generate and publish AR-content, making the entire process manageable by non-experts. In verifying the usefulness and effectiveness of FastAR, we conducted a survey to solicit the opinion of users who carried out the installation and transformation process.","","978-1-4673-7660-0","10.1109/ISMAR.2015.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328073","","Browsers;Databases;Companies;Servers;HTML;Google;Augmented reality","augmented reality;user interfaces;Web sites","Web site transformation;augmented reality view;FastAR software component;augmented reality browsers;content management system;user installation process;user transformation process","","","","11","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Exploring non-reversing magic mirrors for screen-based augmented reality systems","F. Bork; R. Barmaki; U. Eck; P. Fallavolita; B. Fuerst; N. Navab","Technische Universität München, Munich, Germany; Johns Hopkins University, Baltimore, MD, US; Technische Universität München, Munich, Germany; University of Ottawa, Ottawa, Canada; Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","373","374","Screen-based Augmented Reality (AR) systems can be built as a window into the real world as often done in mobile AR applications or using the Magic Mirror metaphor, where users can see themselves with augmented graphics on a large display. The term Magic Mirror implies that the display shows the users enantiomorph, i.e. the mirror image, such that the system mimics a real-world physical mirror. However, the question arises whether one should design a traditional mirror, or instead display the true mirror image by means of a non-reversing mirror? We discuss the perceptual differences between these two mirror visualization concepts and present a first comparative study in the context of Magic Mirror anatomy teaching.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892332","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces and Presentation]: User Interfaces — Ergonomics","Mirrors;Augmented reality;Education;Biomedical imaging;Psychology;Context","augmented reality;computer graphics","nonreversing magic mirrors;screen-based augmented reality systems;screen-based AR systems;mobile AR applications;Magic Mirror metaphor;augmented graphics;mirror image;mirror visualization;Magic Mirror anatomy teaching","","8","","7","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Attention Guiding Using Augmented Reality in Complex Environments","P. Renner; T. Pfeiffer","Center of Excellence Cognitive Interaction Technology, Bielefeld University; Center of Excellence Cognitive Interaction Technology, Bielefeld University","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","771","772","The localization of objects or locations in an environment is an essential task relevant for many work processes. An augmented reality (AR)-based assistance system may support users by guiding their attention towards the relevant targets. This will reduce the time needed for visual search and reduce errors, such as wrongly picked items or false placements. The design of proper attention guiding techniques is thus one area of research in augmented assistance. We developed a number of new attention guiding techniques and evaluated them in several experiments together with recent or classic existing techniques in varying picking scenarios. In our current work, we adapted a standardized assembly scenario to a more complex environment including occlusions to provide a scenario supporting reproducibility of our results. In the research demo, a number of visual and acoustic guiding techniques can be tested and combined. The demonstration is implemented on the Microsoft HoloLens.","","978-1-5386-3365-6","10.1109/VR.2018.8446396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446396","Attention guiding;augmented reality assistance;evaluation: H.5.2 [Information Interfaces and Presentation (e.g. HCI)]: User Interfaces-Miscellaneous","Three-dimensional displays;Augmented reality;Task analysis;Visualization;Glass;Maintenance engineering;User interfaces","augmented reality;handicapped aids","work processes;augmented reality-based assistance system;visual search;wrongly picked items;false placements;proper attention guiding techniques;augmented assistance;picking scenarios;standardized assembly scenario;complex environment including occlusions;scenario supporting reproducibility;visual guiding techniques;acoustic guiding techniques;complex environments","","6","","10","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"[Poster] Smartwatch-aided handheld augmented reality","D. Stanimirovic; D. Kurz",Metaio GmbH; Metaio GmbH,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","307","308","We propose a novel method for interaction of humans with real objects in their surrounding combining Visual Search and Augmented Reality (AR). This method is based on utilizing a smartwatch tethered to a smartphone, and it is designed to provide a more user-friendly experience compared to approaches based only on a handheld device, such as a smartphone or a tablet computer. The smart-watch has a built-in camera, which enables scanning objects without the need to take the smartphone out of the pocket. An image captured by the watch is sent wirelessly to the phone that performs Visual Search and subsequently informs the smartwatch whether digital information related to the object is available or not. We thereby distinguish between three cases. If no information is available or the object recognition failed, the user is notified accordingly. If there is digital information available that can be presented using the smartwatch display and/or audio output, it is presented there. The third case is that the recognized object has digital information related to it, which would be beneficial to see in an Augmented Reality view spatially registered with the object in realtime. Then the smartwatch informs the user that this option exists and encourages using the smartphone to experience the Augmented Reality view. Thereby, the user only needs to take the phone out of the pocket in case Augmented Reality content is available, and when the content is of interest for the user.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948463","","Visualization;Augmented reality;Search problems;Cameras;Three-dimensional displays;Watches;Prototypes","augmented reality;mobile computing;object recognition;user interfaces","smartwatch-aided handheld augmented reality;human interaction;visual search;AR;smart phone;user-friendly experience;tablet computer;digital information;object recognition","","2","4","5","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Augmented Reality and Autism Spectrum Disorder Rehabilitation: Scoping review","H. A. Almurashi; R. Bouaziz","Computer Science Department, Taibah University, Saudi Arabia, Al Madinah, Saudi Arabia; Computer Science Department, Taibah University, Saudi Arabia","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","243","246","Currently, augmented reality is integrated into several areas (medical, therapeutic, educational, entertainment,). One of these important areas in which the augmented reality has been incorporated in the field of rehabilitation for autism spectrum disorder (ASD) children, but it does not serve the field well. This report will provide an overview of how to use AR technology in the field of autism spectrum disorder (ASD), from an entertainment perspective to develop their communication skills. Where solutions to the problems suggested in previous research will be discussed and attempted to develop them to reach new hypotheses that serve the use of augmented reality AR to better rehabilitate the behavior of autistic children. The report proposes a future hypothesis and a research plan to solve the problem.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319123","autism spectrum disorder (ASD);augmented reality (AR);and entertainment","Variable speed drives;Pediatrics;Autism;Augmented reality;Training;Task analysis;Smart phones","augmented reality;handicapped aids;medical disorders;patient rehabilitation","autism spectrum disorder rehabilitation;scoping review;medical entertainment;therapeutic entertainment;educational entertainment;autism spectrum disorder children;ASD;augmented reality AR","","1","","30","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"Development of a Gait Recognition Visualization System Using Augmented Reality","J. Hurtado; Y. Saint-Priest; E. Caicedo",Universidad Santiago de Cali; Universidad Santiago de Cali; Universidad Santiago de Cali,"2019 International Conference on Virtual Reality and Visualization (ICVRV)","6 Oct 2020","2019","","","196","199","The gait rehabilitation is generally done through the traditional way, the diagnostics are only made according to the eye of the person who is doing the treatment for identifying the places where the people feel any kind of pain. This project wants to develop a system that uses augmented reality for visualizing the cinematics of the human gait to help experts to give diagnostics. The Opencv library was used as a tool to implement the augmented reality, providing functions such as the calibration of the camera, the detection and the tracking of the objects that will be the markers located between the joint segments of the legs (hip, knee and ankle), through this, the tracking of the displacement of the person and the angle formed can be visualized. This system, that uses augmented reality, gives support to the diagnostic of the gait through technological tools which will help the experts to get a highest precision for making this kind of analysis.","2375-141X","978-1-7281-4752-9","10.1109/ICVRV47840.2019.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212934","Human gait;Augmented reality;Artificial vi sion;Opencv","Cameras;Augmented reality;Kinematics;Visualization;Legged locomotion;Tools;Image color analysis","augmented reality;gait analysis;image recognition;medical image processing;medical robotics;patient rehabilitation","technological tools;gait diagnostic;person displacement tracking;joint segments;object tracking;object detection;camera calibration;Opencv library;cinematics visualization;place identification;human gait;gait rehabilitation;augmented reality;gait recognition visualization system","","1","","14","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"A Mobile Augmented Reality Approach for Creating Dynamic Effects with Controlled Vector Fields","L. Zhu; X. Liu",Southeast University; Northwestern University,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1283","1284","Dynamic effects are commonly added offline to pre-recorded videos. In this work, we propose to synthesize online dynamic effects with controlled vector fields by using mobile augmented reality. By modelling typical primitives of a flow field to oriented markers, we use image detection and tracking techniques to build and control a virtual vector field in the real world. Virtual objects are then added and animated in real time. We prototype our system and the results show the possibility that dynamic effects can be created in mobile augmented reality to enhance the visual communication with the real world.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797735","[Graphics systems and interfaces]: Mixed / augmented reality;[Human-centered computing]: Human computer interaction (HCI)","Mobile handsets;Aerodynamics;Augmented reality;Three-dimensional displays;Real-time systems;Videos;User interfaces","augmented reality;mobile computing;object detection;object tracking","virtual vector field;mobile augmented reality approach;controlled vector fields;pre-recorded videos;online dynamic effects;flow field;image detection techniques;image tracking techniques","","","","6","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"An implementation of generic augmented reality in mobile devices","Q. Zhang; W. Chu; C. Ji; C. Ke; Y. Li","Dep. CS, Jinan Univ., Guangzhou, P.R.C.; Dep. CS, Jinan Univ., Guangzhou, P.R.C.; SANGFOR Inc., Shenzhen, P.R.C.; Gree Electric Appliances, Zhuhai, P.R.C.; Dep. CS, Jinan Univ., Guangzhou, P.R.C.","2014 IEEE 7th Joint International Information Technology and Artificial Intelligence Conference","23 Mar 2015","2014","","","555","558","There are two problems in the existing mobile augmented reality (MAR) system, one is the difficulty in developing and the other is the lack of versatile AR observer. To address them, a generic MAR framework was proposed in the paper, which contains three components: a versatile observer which is run on smart mobile device to see the AR effect produced by MAR application, an MAR server that provides network and data service for the MAR application, and an MAR application customizer which is used by developers to tailor their desired applications. The Vuforia SDK is used to implement the observer, and the XML technology is applied to achieve the goal of customizing MAR application. The generic framework enables developers to do code-free development, and provides the convenience of observing different MAR applications by one MAR observer. The experimental results show that this framework reduces the difficulty and time in developing AR application and makes it easy to observing AR effects by users.","","978-1-4799-4419-4","10.1109/ITAIC.2014.7065112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065112","Mobile Augmented Reality;Augmented Reality Framework;Vuforia SDK;Augmented Reality Observer","Observers;Augmented reality;Servers;Videos;Mobile handsets;Mobile communication;XML","augmented reality;mobile computing;XML","generic augmented reality;mobile augmented reality;generic MAR framework;versatile observer;smart mobile device;MAR server;data service;network service;MAR application customizer;Vuforia SDK;XML technology;code-free development","","3","","16","IEEE","23 Mar 2015","","","IEEE","IEEE Conferences"
"Civil War Battlefield Experience: Historical Event Simulation using Augmented Reality Technology","V. T. Nguyen; K. Jung; S. Yoo; S. Kim; S. Park; M. Currie","Dept. of Computer Science, Texas Tech University, Texas, United States; Dept. of Edu. Psychology&Leadership, Texas Tech University, Texas, United States; Division of Communication&Media, Ewha Womans University, Seoul, South Korea; Dept. of Edu. Psychology&Leadership, Texas Tech University, Texas, United States; Dept. of PSLA, University of Connecticut, Connecticut, United States; Dept. of Landscape Architecture, Texas Tech University, Texas, United States","2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","294","2943","In recent years, with the development of modern technology, Virtual Reality (VR) has been proven as an effective means for entertaining and encouraging learning processes. Users immerse themselves in a 3D environment to experience situations that are very difficult or impossible to encounter in real life, such as volcanoes, ancient buildings, or events on a battlefield. Augmented Reality (AR), on the other hand, takes a different approach by allowing users to remain in their physical world while virtual objects are overlaid on physical ones. In education and tourism, VR and AR are becoming platforms for student learning and tourist attractions. Although several studies have been conducted to promote cultural preservation, they are mostly focused on VR for historical building visualization. The use of AR for simulating an event is relatively uncommon, especially for a battlefield simulation. This paper presents a work-in-progress, specifically a web-based AR application that enables both students and tourists to witness a series of battlefield events occurring at the Battle of Palmito Ranch, located near Brownsville, Texas. With markers embedded directly into the printed map, users can experience the last battle of the Civil War in the US.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942248","Palmito Ranch, Augmented Reality, AFrame, Simulation, Animations","Three-dimensional displays;Solid modeling;Cultural differences;Augmented reality;Animation;Buildings;Visualization","augmented reality;computer aided instruction;computer simulation;data visualisation;history;travel industry","Civil War battlefield experience;historical event simulation;augmented reality technology;virtual reality;VR;student learning;tourist attractions;cultural preservation;historical building visualization;battlefield simulation;Web-based AR application","","5","","16","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"2D LIDAR as a distributed interaction tool for virtual and augmented reality video games","J. McCormack; J. Prine; B. Trowbridge; A. C. Rodriguez; R. Integlia","College of Engineering; College of Engineering; College of Information and Technology, Florida Polytechnic University, Lakeland, Florida, USA; College of Engineering; College of Engineering, Florida Polytechnic University, Lakeland, Florida, USA","2015 IEEE Games Entertainment Media Conference (GEM)","11 Jan 2016","2015","","","1","5","The current rise in augmented and virtual reality video games has created a need for immersive interactivity devices that do not interfere with game play. Light Detection and Ranging (LIDAR) systems can be used to create very accurate 2D or 3D representations of an area. We propose using an affordable 2D LIDAR system operating over a network as a method for interacting with a virtual or augmented reality environment. A distributed haptic feedback system is also designed in order to provide feedback to the user of the system. Both sets of devices communicate wirelessly with a central game server. This allows the user to reach into a real world environment, and feel a response based upon interactions in the virtual environment in near real time.","","978-1-4673-7452-1","10.1109/GEM.2015.7377221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377221","LIDAR;Unity3D;Human Computer Interaction;Haptic Feedback;Virtual Reality;Augmented Reality","Laser radar;Games;Haptic interfaces;Augmented reality;Human computer interaction;IEEE 802.11 Standard","augmented reality;computer games;haptic interfaces;optical radar;virtual reality","distributed interaction tool;augmented reality video games;virtual reality video games;immersive interactivity devices;game play;light detection and ranging systems;2D LIDAR system;augmented reality environment;virtual reality environment;distributed haptic feedback system;central game server","","7","2","18","IEEE","11 Jan 2016","","","IEEE","IEEE Conferences"
"Towards Pervasive Augmented Reality: Context-Awareness in Augmented Reality","J. Grubert; T. Langlotz; S. Zollmann; H. Regenbrecht","Chair of Embedded Systems, University of Passau, Passau, Germany; Department of Information Science, University of Otago, Dunedin, New Zealand; Animation Research Ldt., Dunedin, New Zealand; Department of Information Science, University of Otago, Dunedin, New Zealand","IEEE Transactions on Visualization and Computer Graphics","28 Apr 2017","2017","23","6","1706","1724","Augmented Reality is a technique that enables users to interact with their physical environment through the overlay of digital information. While being researched for decades, more recently, Augmented Reality moved out of the research labs and into the field. While most of the applications are used sporadically and for one particular task only, current and future scenarios will provide a continuous and multi-purpose user experience. Therefore, in this paper, we present the concept of Pervasive Augmented Reality, aiming to provide such an experience by sensing the user's current context and adapting the AR system based on the changing requirements and constraints. We present a taxonomy for Pervasive Augmented Reality and context-aware Augmented Reality, which classifies context sources and context targets relevant for implementing such a context-aware, continuous Augmented Reality experience. We further summarize existing approaches that contribute towards Pervasive Augmented Reality. Based our taxonomy and survey, we identify challenges for future research directions in Pervasive Augmented Reality.","1941-0506","","10.1109/TVCG.2016.2543720","European Commission(grant numbers:ICT-FP7-611526); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435333","Augmented reality;pervasive augmented reality;context-awareness;adaptivity;context;taxonomy;survey;mixed reality","Augmented reality;Context awareness;Mobile communication;User interfaces;Three-dimensional displays;Tracking;Ontologies","augmented reality;ubiquitous computing","pervasive augmented reality;physical environment interaction;digital information;AR system;context sources;context targets;context-aware continuous augmented reality experience","","155","","148","IEEE","17 Mar 2016","","","IEEE","IEEE Journals"
"Augmented and Virtual Reality Technologies in Education","I. Muzyleva; L. Yazykova; A. Gorlach; Y. Gorlach","Automation and computer science faculty, Lipetsk State Technical University, Lipetsk, Russian; Automation and computer science faculty, Lipetsk State Technical University, Lipetsk, Russian; Automation and computer science faculty, Lipetsk State Technical University, Lipetsk, Russian; Automation and computer science faculty, Lipetsk State Technical University, Lipetsk, Russian","2021 1st International Conference on Technology Enhanced Learning in Higher Education (TELE)","26 Jul 2021","2021","","","99","103","The article examines the technologies of industrial revolution 4.0 - augmented reality and virtual reality. A detailed numerical analysis of known examples of the application of these technologies in the form of registered programs has been carried out. The possibilities of optimization of organizational and educational processes in higher technical education are analyzed. The methodology of using augmented reality in the organizational and educational process of a technical university is presented. A variant of augmented reality is proposed that allows you to “examine” a 3D model of an object by turning a paper marker. To implement it, the EV Toolbox augmented and virtual reality constructor is used.","","978-1-6654-4396-8","10.1109/TELE52840.2021.9482568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9482568","information technology;augmented reality;virtual reality;3D model;EV Toolbox;methodology of using augmented reality;virtual labs;QR code","Solid modeling;Three-dimensional displays;Numerical analysis;Education;Turning;Augmented reality;Optimization","augmented reality;computer aided instruction;further education;solid modelling","augmented reality;detailed numerical analysis;higher technical education;organizational process;virtual reality constructor;industrial revolution 4.0;registered programs;technical university;3D model;paper marker;EV toolbox","","1","","14","IEEE","26 Jul 2021","","","IEEE","IEEE Conferences"
"ARTFM: Augmented Reality Visualization of Tool Functionality Manuals in Operating Rooms","C. Kleinbeck; H. Schieber; S. Andress; C. Krautz; D. Roth","Human-Centered Computing and Extended Reality, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany; Human-Centered Computing and Extended Reality, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany; Klinik für Allgemeine Unfall- und Wiederherstellungschirurgie, Ludwig-Maximilians-Universität München, Munich, Germany; Chirurgische Klinik, Universitätsklinikurn Erlangen, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany; Human-Centered Computing and Extended Reality, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","736","737","Error-free surgical procedures are crucial for a patient's health. However, with the increasing complexity and variety of surgical instruments, it is difficult for clinical staff to acquire detailed assembly and usage knowledge leading to errors in process and preparation steps. Yet, the gold standard in retrieving necessary information when problems occur is to get the paperbased manual. Reading through the necessary instructions is time-consuming and decreases care quality. We propose ARTFM, a process integrated manual, highlighting the correct parts needed, their location, and step-by-step instructions to combine the instrument using an augmented reality head-mounted display.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757491","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality","Solid modeling;Adaptation models;Visualization;Three-dimensional displays;Instruments;Conferences;Surgery","augmented reality;helmet mounted displays;surgery","step-by-step instructions;augmented reality head-mounted display;ARTFM;augmented reality visualization;tool functionality manuals;error-free surgical procedures;patient;surgical instruments;clinical staff;detailed assembly;usage knowledge;preparation steps;gold standard;retrieving necessary information;paperbased manual;necessary instructions;care quality;process integrated manual","","","","7","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"The Future of Learning at the Workplace Is Augmented Reality","F. Wild",Oxford Brookes University,"Computer","19 Oct 2016","2016","49","10","96","98","The next generation of performance support systems and tools for learning at the workplace are likely to be delivered in augmented reality (AR). Although there are many impressive prototypes and bespoke applications, interoperability has been neglected. To fix this, an IEEE Computer Society working group is creating a data format for the enrichment and exchange of AR learning content.","1558-0814","","10.1109/MC.2016.301","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7598181","virtual reality;augmented reality;artificial reality;enterprise performance management;standards;interoperability","Employment;Performance evaluatio;Virtual reality;Performance evaluation;Computational modeling;XML;Interoperability;Augmented reality","augmented reality;computer based training;learning (artificial intelligence);open systems","augmented reality;performance support systems;interoperability;IEEE Computer Society working group;data format;AR learning content","","6","","2","IEEE","19 Oct 2016","","","IEEE","IEEE Magazines"
"The augmented painting: Playful interaction with multi-spectral images","W. van Eck; Y. Kolstee","AR Laboratory, Royal Academy of Art, The Hague, Netherlands; AR Laboratory, Royal Academy of Art, The Hague, Netherlands","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","65","69","Museum conservators and researchers often take multi-spectral captures of the paintings they study, commonly using x-ray, infrared and ultraviolet equipment. Usually these captures are not accessible to the museum visitor, even though they offer valuable information about the painting. Since 2009 the AR Lab has been developing installations which allow museum visitors to explore these special captures in an user-friendly and playful way. This article describes and comments on the different phases this project went through, and gives a preview of our latest augmented reality application.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483990","Augmented reality;painting;conservator;Van Gogh;restoration;visualization;user interface;installation","Painting;Tablet computers;Augmented reality;Art;Paints;Software;Media","augmented reality;human computer interaction;museums","augmented painting;playful interaction;multi-spectral images;museum conservators;museum visitor;AR Lab;user-friendly way;augmented reality application","","17","","7","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"[POSTER] Augmented Wire Routing Navigation for Wire Assembly","M. Rice; H. H. Tay; J. Ng; C. Lim; S. K. Selvaraj; E. Wu",Institute for Infocomm Research; Institute for Infocomm Research; Institute for Infocomm Research; Institute of High Performance Computing; Institute of High Performance Computing; Bombardier Aerospace,"2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","88","91","Within modern manufacturing, digital solutions are needed to optimize and aid shop floor processes. This includes user-centered technologies that can be appropriately integrated into factory environments to assist in the efficiency of manufacturing tasks. In this paper, we present a dynamic system to support the electrical wiring assembly of commercial aircraft. Specifically, we describe the system design, which aims to improve the productivity of factory operators through the integration of wearable and mobile solutions. An evaluation of the augmented reality component of our system using a pair of smart glasses is reported with 12 participants, as we describe important interaction issues in the ongoing development of this work.","","978-1-4673-7660-0","10.1109/ISMAR.2015.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328068","Augmented reality;wire assembly;indoor location tracking;GPS navigation","Wires;Assembly;Routing;Glass;Augmented reality;Navigation;Aircraft","aircraft manufacture;assembling;augmented reality;computer aided manufacturing;mobile computing;productivity;wearable computers;wires (electric)","augmented wire routing navigation;shop floor process;digital solution optimization;user-centered technologies;factory environments;manufacturing tasks;electrical wiring assembly;commercial aircraft;factory operator productivity;mobile solutions;wearable solutions;augmented reality component;smart glasses","","6","3","11","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Browsing Spatial Photography Using Augmented Models","F. Niebling; M. E. Latoschik",University of Würzburg; University of Würzburg,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","47","48","Both digital and physical 3D models of buildings as well as historical photographs of architecture are used for a wide range of needs, from research in humanities and information technologies, museum contexts and library studies, to touristic applications. Spatially oriented photographs play an important role in visualizing and browsing contemporary as well as historical architecture, starting with the ground-breaking Photo Tourism project [4]. We present a technique to combine physical 3D models of buildings with spatially registered historical photographic documents in a hand-held Augmented Reality (AR) environment. Users are enabled to spatially explore historical views of architecture by selecting photos from a collection of images which are then utilized as textures for the physical model rendered on their respective mobile device. We compare different methods to select photos registered to a physical model in hand-held AR.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699207","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality Human-centered computing;Visualization;Visualization application domains;Geographic visualization","Solid modeling;Three-dimensional displays;Buildings;Photography;Visualization;Cameras;Augmented reality","augmented reality;data visualisation;digital photography;history;mobile computing;museums;photography;solid modelling;travel industry","browsing spatial photography;information technologies;museum contexts;library studies;touristic applications;spatially oriented photographs;historical architecture;spatially registered historical photographic documents;physical model;augmented models;hand-held augmented reality environment;ground-breaking photo tourism project;hand-held AR","","2","","4","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Viability of Augmented Content for Field Policing","H. Engelbrecht; S. G. Lukosch",Delft University of Technology; Delft University of Technology,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","386","389","This paper describes the design and evaluation of a prototype for mobile information provisioning in augmented reality (AR) for field officers of the Dutch police. Five different fictional cases were constructed in cooperation with officers from the Dutch police. These cases were comprised of dynamic as well as static hotspots that would occur naturally during field work. Three different versions of the early prototype were tested using the method of heuristic evaluation. The application was shown to three experts from two police departments. Evaluation of the heuristics, possible future improvements as well as AR viability considerations for field policing are discussed.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699296","Human-centered computing—Interaction paradigms—Mixed/augmented reality—;Human-centered computing—HCI design and evaluation methods—Usability testing","Law enforcement;Cameras;Meters;Prototypes;Augmented reality;Smart phones;Collaboration","augmented reality;mobile computing;police data processing","static hotspots;dynamic hotspots;augmented reality;mobile information provisioning;augmented content;field policing;AR viability considerations;police departments;heuristic evaluation;Dutch police","","1","","13","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Research opportunities on virtual reality and augmented reality: a survey","M. Shanmugam; M. Sudha; K. Lavitha; V. P. Venkatesan; R. Keerthana","Department of Banking Technology, Pondicherry University, Pondicherry, India; Department of CSE, Sri Manakula Vinayagar Engineering College, Pondicherry, India; Department of CSE, Sri Manakula Vinayagar Engineering College, Pondicherry, India; Department of Banking Technology, Pondicherry University, Pondicherry, India; Department of CSE, Sri Manakula Vinayagar Engineering College, Pondicherry, India","2019 IEEE International Conference on System, Computation, Automation and Networking (ICSCAN)","24 Oct 2019","2019","","","1","6","Augmented reality(AR) is a technology that covers virtual objects into a real environment with real objects for better observer's knowledge. Virtual Reality (VR) enables user to interact with a computer-simulated environment which is either a simulation of the real world or an imaginary world. VR and AR are the key to explore, and touch the past, present and the future. They are the basis of creating one's own world, one's own custom-built reality. It enables users to design a video game to have a virtual stroll around the universe, to practice their own dream house, to experience a walk on an alien planet. We can learn by experiencing the most threatening and difficult situations by playing safe. Very few really know the basic principles of VR & AR and their open problems. In this survey, we present the historical overview of Virtual Reality and Augmented Reality, characteristics, and types of VR and AR systems. The requirements and challenges of typical VR and AR systems are illustrated.","","978-1-7281-1525-2","10.1109/ICSCAN.2019.8878796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878796","Virtual Reality;Augmented Reality;Sensorama;NASA;Treating phobias","Augmented reality;Headphones;NASA;Head;Google","augmented reality;computer simulation","virtual reality;virtual objects;computer-simulated environment;custom-built reality;augmented reality;video game design","","","","8","IEEE","24 Oct 2019","","","IEEE","IEEE Conferences"
"Augmented Reality Application for Plant Learning","G. Zhao; Q. Zhang; J. Chu; Y. Li; S. Liu; L. Lin","School of Educational Information Technology Central China Normal University Wuhan, China; School of Educational Information Technology Central China Normal University Wuhan, China; School of Educational Information Technology Central China Normal University Wuhan, China; School of Educational Information Technology Central China Normal University Wuhan, China; School of Educational Information Technology Central China Normal University Wuhan, China; National Engineering Research Center for E-Learning Central China Normal University Wuhan, China","2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS)","10 Mar 2019","2018","","","1108","1111","Augmented reality learning resources meet the requirements of contextual and adaptive ubiquitous learning and are gradually favored in the field of education. In our previous work, we proposed a plant knowledge expansion learning system. This system used mobile intelligent terminal to take pictures of plants to get the text, pictures, audio, video and other information related to plants. On the basis of the existing system, this paper further explored the application of augmented reality technology for plant learning, and developed plants augmented reality information display module. This module can be used to scan a specific plant and obtain its 3D model and text information in realtime. Learners can interact with the model by rotating and scaling, which effectively enhances learners' interest in learning.","2327-0594","978-1-5386-6565-7","10.1109/ICSESS.2018.8663953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663953","plant learning;interactive learning;augmented reality technology (AR)","Augmented reality;Three-dimensional displays;Solid modeling;Cameras;Education;Learning systems;Feature extraction","augmented reality;biology computing;botany;computer aided instruction;mobile learning","augmented reality technology;plants augmented reality information display module;augmented reality application;augmented reality learning resources;contextual learning;adaptive ubiquitous learning;plant knowledge expansion learning system;mobile intelligent terminal;contextual learning","","5","","15","IEEE","10 Mar 2019","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality using scalable recognition and tracking","J. Ha; J. Jung; B. Han; K. Cho; H. S. Yang","Computer Science Department, Korea Advanced Institute of Science and Technology, South Korea; Computer Science Department, Korea Advanced Institute of Science and Technology, South Korea; Computer Science Department, Korea Advanced Institute of Science and Technology, South Korea; Computer Science Department, Korea Advanced Institute of Science and Technology, South Korea; Computer Science Department, Korea Advanced Institute of Science and Technology, South Korea","2011 IEEE Virtual Reality Conference","29 Apr 2011","2011","","","211","212","In this paper, a new mobile Augmented Reality (AR) framework which is scalable to the number of objects being augmented is proposed. The scalability is achieved by a visual word recognition module on the remote server and a mobile phone which detects, tracks, and augments target objects with the received information from the server. The server and the mobile phone are connected through a conventional Wi-Fi. In the experiment, it takes 0.2 seconds for the cold start of an AR service initiation on a 10k object database, which is fairly acceptable in a real-world AR application.","2375-5334","978-1-4577-0038-5","10.1109/VR.2011.5759473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759473","Augmented Reality;Tracking","Mobile handsets;Mobile communication;Servers;Target tracking;Scalability;Augmented reality;Visualization","augmented reality;mobile computing;mobile handsets;tracking;wireless LAN","mobile augmented reality;visual word recognition;remote server;mobile phone;Wi-Fi;tracking","","3","","9","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"Training with a world champion: augmented reality applications in sport Design-led research","S. Palmieri; A. Righi; M. Bisson; A. Ianniello","Department of Design, Politecnico di Milano, Milan, Italy; Department of Design, Politecnico di Milano, Milan, Italy; Department of Design, Politecnico di Milano, Milan, Italy; Department of Design, Politecnico di Milano, Milan, Italy","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","366","370","Recent and continuous innovations in the field of extended reality and, in particular, augmented reality, are able to revolutionize different aspects of the reference market sectors. At the same time, a constant evolution in the area of artificial intelligence, machine learning and deep learning, if combined with the aforementioned innovations, allows to conceive solutions able to shape new ways to inform, to improve skills and to spend time. The ability to simulate contexts, environments, actions and emotions and the possibility to use the data generated by the simulations in a disruptive way permit to imagine and create learning and strengthening paths.This developing research has been carried out within the Interdepartmental Laboratory EDME (Environmental Design Multisensory Experience), which belongs to the Design Department of Politecnico di Milano. It has been conducted by investigating the state of the art of augmented reality and artificial intelligence technologies, highlighting interesting and highly innovative case studies; from this first phase we moved on to analyze the sport sector in which an important potential for future development was recognized. The last part of the first phase of this research project consisted in the elaboration of a concept for an enabling technological system and a business model with a high innovation coefficient, whose realization is hypothesized for the year 2030.It is intended to demonstrate how a design operation, which started from emerging technologies and a sector of high interest and assumed a scenario of use over ten years, is not only extremely interesting but also, and above all, useful to consciously predict and accompany the aforementioned technological development.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319066","augmented reality;machine learning;deep learning;simulation;sport;design-led;2030","Augmented reality;Sports;Training;Companies;Technological innovation;Business;Data models","augmented reality;design;innovation management;learning (artificial intelligence);sport","world champion;augmented reality applications;continuous innovations;market sectors;machine learning;deep learning;EDME;artificial intelligence technologies;sport sector;design operation;environmental design multisensory experience;innovation coefficient;sport design-led research","","1","","28","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"An Analysis of Augmented Reality Aided Vehicle Operation","J. Domingo; D. Kostic; G. Monahan; K. Pietroszek; I. Humer; C. Eckhardt","Computer Science Department, California Polytechnic State University, San Luis Obispo, CA, USA; Computer Engineering Department, California Polytechnic State University, San Luis Obispo, CA, USA; Computer Science Department, California Polytechnic State University, San Luis Obispo, CA, USA; Institute of IDEAS American University Washington DC, Washington, DC, USA; Computer Science Department, California Polytechnic State University, San Luis Obispo, CA, USA; Computer Science Department, California Polytechnic State University, San Luis Obispo, CA, USA","2021 International Conference on Advanced Learning Technologies (ICALT)","2 Aug 2021","2021","","","376","380","In this study, we investigated the effect of augmented reality aided dashboard information projected on the windshield on car driving performance. As augmented reality technology becomes more popular and accessible, essential driving information such as the current velocity can be projected to where the traffic happens in terms of location and distance. In comparison with a Heads Up Display (HUD) on a windshield, augmented reality devices offer the possibility to place the data farther in front of the car. Because of this, the eyes of the driver do not need to re-focus constantly to a closer object, when most of the imminent attention needs to be set to the space in front of the vehicle. To test in a safe environment, we developed a virtual reality car parkour and conducted a user study. Splitting our participants in two equally big groups, one with a conservative dashboard and the other with the velocity displayed 10 m ahead and over the horizon. Assessing the participant’s performance in areas such as maintaining the speed limit, distance to the traffic, and time to match up with the given speed limit, we found striking positive results using the augmented reality solution.","2161-377X","978-1-6654-4106-3","10.1109/ICALT52272.2021.00121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499789","Augmented Reality;Car;Driving;Immersion","Space vehicles;Performance evaluation;Head-up displays;Automobiles;Augmented reality;Automotive components","augmented reality;automobiles;automotive components;head-up displays;traffic engineering computing","driving information;windshield;augmented reality devices;virtual reality car parkour;augmented reality aided dashboard information;car driving performance;augmented reality aided vehicle operation analysis;heads up display;HUD","","1","","25","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"Machine Intelligence Matters: Rethink Human-Robot Collaboration Based on Symmetrical Reality","Z. Zhang; X. Wang","Tencent, Shenzhen, China; National Engineering Laboratory for Public Safety Risk Perception and Control by Big Data (NEL-PSRPC), China Academy of Electronics and Information Technology, Beijing, China","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","225","228","Human-robot collaboration could be valuable in some challenging tasks. Previous researches only consider the human-centered systems, but there will be many changes in the symmetrical reality (SR) systems because there are two perceptual centers in symmetrical reality. In this paper, we introduce the contents of the symmetrical reality-based human-robot collaboration and interpret the human- robot collaboration from the perspective of equivalent interaction. By analyzing task definition in symmetrical reality, we present the special features of human-robot collaboration. Furthermore, there are many fields in which the symmetrical reality can produce a remarkable effect, we only list some typical applications, such as service robots, remote training, interactive exhibition, digital assistants, companion robots, the immersive entertainment community and so forth. The current situation and future development of this framework are also analyzed to provide a kind of guidance for researchers.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288369","Human-centered computing—Human computer interaction (HCI)—HCI theory;concepts and models;Human-centered computing—Human computer interaction (HCI)— Interaction paradigms—Mixed / augmented reality","Training;Service robots;Collaboration;Entertainment industry;Task analysis;Augmented reality;Machine intelligence","augmented reality;control engineering computing;human-robot interaction;intelligent robots","human-centered systems;symmetrical reality;human-robot collaboration;service robots;companion robots;machine intelligence;remote training;interactive exhibition;digital assistants;immersive entertainment community;augmented reality","","2","","16","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Magic Cards: A New Augmented-Reality Approach","O. Demuynck; J. M. Menéndez","Signals, Systems, and Radiocommunications Department, Universidad Politécnica de Madrid, Spain; Signals, Systems, and Radiocommunications Department, Universidad Politécnica de Madrid, Spain","IEEE Computer Graphics and Applications","21 Jan 2013","2013","33","1","12","19","Augmented reality (AR) commonly uses markers for detection and tracking. Such multimedia applications associate each marker with a virtual 3D model stored in the memory of the camera-equipped device running the application. Application users are limited in their interactions, which require knowing how to design and program 3D objects. This generally prevents them from developing their own entertainment AR applications. The Magic Cards application solves this problem by offering an easy way to create and manage an unlimited number of virtual objects that are encoded on special markers.","1558-1756","","10.1109/MCG.2012.94","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6287499","Shape analysis;Image color analysis;Labeling;Augmented reality;Multimedia communication;Solid modeling;Virtual reality;Rendering (computer graphics);computer graphics;augmented reality;virtual reality;VR;computer games;infotainment;image-based rendering;nonsecret encoding schemes;multimedia","Shape analysis;Image color analysis;Labeling;Augmented reality;Multimedia communication;Solid modeling;Virtual reality;Rendering (computer graphics)","augmented reality;entertainment;solid modelling","augmented reality approach;virtual 3D model;multimedia application;3D object;entertainment AR application;Magic Cards application;virtual object","","3","","7","IEEE","27 Aug 2012","","","IEEE","IEEE Magazines"
"EyeBuy: Using augmented reality in accessible interfaces for consumers with visual acuity reduction","C. E. Forte; S. Luciano; C. V. Pazini; M. Marengoni","Digital Games-Americana College of technology (FATEC), SP, Brazil; Digital Games-Americana College of technology (FATEC), SP, Brazil; Digital Games-Americana College of technology (FATEC), SP, Brazil; PPGEE-Mackenzie University, São Paulo, SP, Brazil","2013 1st Workshop on Virtual and Augmented Assistive Technology (VAAT)","10 Apr 2014","2013","","","1","6","This paper discusses the use of augmented reality to develop accessible applications. Specifically, we developed a system used in tablets that, enriched by this technology, aid consumers with reduced visual acuity during shopping at a supermarket. We present the project development, the experiments and discussions about the obtained results.","","978-1-4799-3896-4","10.1109/VAAT.2013.6786183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786183","Augmented Reality;Accessible Interface;Visual Acuity Reduction","Proposals;Visualization;Augmented reality;Games;Three-dimensional displays;Time measurement;Educational institutions","augmented reality;handicapped aids;retail data processing","EyeBuy;augmented reality;consumers with visual acuity reduction;accessible applications;tablet computers;supermarket;shopping","","1","","16","IEEE","10 Apr 2014","","","IEEE","IEEE Conferences"
"Augmented reality for motion analysis of patients with upper extremity motor dysfunction","M. Cidota; S. Lukosch; P. J. M. Bank","Faculty of Technology, Delft University of Technology, The Netherlands; Faculty of Technology, Delft University of Technology, The Netherlands; Department of Neurology, Leiden University Medical Center, The Netherlands","2015 3rd IEEE VR International Workshop on Virtual and Augmented Assistive Technology (VAAT)","16 Jul 2015","2015","","","1","4","Various diseases affect human motion (e.g. neurovascular diseases, neurodegenerative diseases, and musculoskeletal pain conditions). Currently, each medical discipline uses disease-specific clinical tests to assess motor (dys)function, based on subjectively scored and low-resolution clinimetric tests, qualitative video analysis, or cumbersome marker-based motion capturing. As such, no standard protocols for motion recording exist with respect to type of movements and activities of the upper extremity in various patient groups. For a better understanding of how different disorders affect motor function, a uniform, standardized and objective evaluation is a desirable goal in the study of motion disorders. Our aim is to explore the capabilities of the augmented reality (AR) technology for uniform assessment of the motor function, both for diagnosis and treatment.","","978-1-4673-6518-5","10.1109/VAAT.2015.7155401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155401","human motion assessment;augmented reality;optical see-through Head Mounted Device;serious gaming","Training;Augmented reality;Collaboration;Medical diagnostic imaging;Monitoring;Diseases;Real-time systems","augmented reality;human computer interaction;medical computing;medical disorders;motion estimation","augmented reality;patient motion analysis;upper extremity motor dysfunction;human motion;neurovascular diseases;neurodegenerative diseases;musculoskeletal pain conditions;disease-specific clinical tests;subjectively scored low-resolution clinimetric tests;qualitative video analysis;marker-based motion capturing;motion recording;uniform-standardized objective evaluation;motion disorders;AR technology;uniform motor function assessment","","","","19","IEEE","16 Jul 2015","","","IEEE","IEEE Conferences"
"The Matter of Attention and Motivation – Understanding Unexpected Results from Auditory Localization Training Using Augmented Reality","S. H. Chon; S. Kim","University of Colorado Boulder, Boulder, CO, US; Rochester Institute of Technology, Rochester, NY, US","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1503","1506","We present the results from a seven-week auditory localization training using Microsoft HoloLens. Eight participants were divided into two groups. Both groups showed a generally declining pattern in localization performance over the eight tests, unlike the results from our previous study. The decreasing slope was smaller for the train group than for the control group, which might reflect some mild effect of training. There was a one-time performance improvement after two trainings, which was not observed from subsequent tests. The training program might have been too simple to maintain participants' attention for weeks. Possible extraneous factors such as the academic calendar are discussed that might have had an impact on this decreasing pattern against the hypotheses.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797683","Localization;Training effect;Augmented reality;HRTFs;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Applied Computing;Education;Interactive learning environments","Training;Visualization;Augmented reality;Task analysis;Ear;Atmospheric measurements;Particle measurements","augmented reality;behavioural sciences computing;human factors","training program;augmented reality;seven-week auditory localization training;Microsoft HoloLens;generally declining pattern;localization performance;train group;control group;one-time performance improvement;motivation;academic calendar","","1","","16","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"A step forward in manual welding: demonstration of augmented reality helmet","D. Aiteanu; B. Hillers; A. Graser","Institute of Automation, University of Bremen, Bremen, Germany; Institute of Automation, University of Bremen, Bremen, Germany; Institute of Automation, University of Bremen, Bremen, Germany","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","309","310","A new welding helmet for the manual welding process has been developed. The welders working conditions are improved by augmenting the visual information before and during welding. The image is improved by providing a better view of the working area. An online quality assistant is available during welding, suggesting the correction of the guns position or pointing out welding errors, by analyzing the electrical welding parameters. An assembly advisor will suggest the assembly sequence, by displaying the type and the position of the following piece into the actual ensemble. In addition, an available online documentation of the welding process gives an opportunity to reduce the effort of post process quality assurance which often uses expensive X-ray investigations.","","0-7695-2006-5","10.1109/ISMAR.2003.1240734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240734","","Welding;Augmented reality;Documentation;Protection;Employee welfare;Computer aided manufacturing;Assembly systems;Robotic assembly;Cameras;Glass","welding;augmented reality;helmet mounted displays;computer based training;user interfaces;computer vision","manual welding;augmented reality helmet;welding process;visual information;online quality assistant;guns position;welding errors;electrical welding parameters;assembly advisor;assembly sequence;actual ensemble;online documentation;x-ray investigations","","25","53","8","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Towards the development of guidelines for educational evaluation of augmented reality tools","M. M. O. da Silva; R. A. Roberto; V. Teichrieb; P. S. Cavalcante","UFPE, Informatics Center, Brazil; UFPE, Informatics Center, Brazil; UFPE, Informatics Center, Brazil; EDUMATEC, Education Center, Brazil","2016 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual & Augmented Reality (KELVAR)","29 Sep 2016","2016","","","17","21","Augmented Reality (AR) is heralded to be a promising technology for education. Thus, it is important to properly evaluate it so practitioners feel more confident in its use. Considering the current lack of studies to evaluate AR based educational technology, this work aims to provide some guidelines in order to assist researchers when conducting educational evaluations. The proposed principles were based on both theoretical and practical research. The guidelines presented involve the use of multiple metrics, both quantitative and qualitative, high involvement of teachers and a comprehensive evaluation taking into account both formative and summative aspects. Two practical evaluation experiences were designed applying these principles and their findings are discussed in this paper.","","978-1-5090-2344-8","10.1109/KELVAR.2016.7563677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7563677","K.3.m [Computing Milieux]: Computers andEducation—Miscellaneous","Guidelines;Measurement;Augmented reality;Informatics;Educational technology;Training","augmented reality;computer aided instruction","educational evaluation;augmented reality tool;AR based educational technology","","7","","30","IEEE","29 Sep 2016","","","IEEE","IEEE Conferences"
"An empiric evaluation of confirmation methods for optical see-through head-mounted display calibration","P. Maier; A. Dey; C. A. L. Waechter; C. Sandor; M. Tönnis; G. Klinker","Fachgebiet Augmented Reality (FAR), Fakultät für Informatik, Technische Universität München, Munchen, Germany; Magic Vision Laboratory, School of Computer and Information Science, University of South Australia, Adelaide, Australia; Fachgebiet Augmented Reality (FAR), Fakultät für Informatik, Technische Universität München, Munchen, Germany; Magic Vision Laboratory, School of Computer and Information Science, University of South Australia, Adelaide, Australia; Fachgebiet Augmented Reality (FAR), Fakultät für Informatik, Technische Universität München, Munchen, Germany; Fachgebiet Augmented Reality (FAR), Fakultat fur Informatik, Garching b. Munchen, Germany","2011 10th IEEE International Symposium on Mixed and Augmented Reality","5 Mar 2012","2011","","","267","268","The calibration of optical see-through head-mounted displays is an important fundament for correct object alignment in augmented reality. Any calibration process for OSTHMDs requires users to align 2D points in screen space with 3D points in the real world and to confirm each alignment. In this poster, we present the results of our empiric evaluation where we compared four confirmation methods: Keyboard, Hand-held, Voice, and Waiting. The Waiting method, designed to reduce head motion during confirmation, showed a significantly higher accuracy than all other methods. Averaging over a time frame for sampling user input before the time of confirmation improved the accuracy of all methods in addition. We conducted a further expert study proving that the results achieved with a video see-through head-mounted display showed valid for optical see-through head-mounted display calibration, too.","","978-1-4577-2185-4","10.1109/ISMAR.2011.6143895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162910","","Calibration;Keyboards;Three dimensional displays;Accuracy;Augmented reality;Electronic mail;Adaptive optics","","","","13","","5","IEEE","5 Mar 2012","","","IEEE","IEEE Conferences"
"IEEE Approved Draft Standard for an Augmented Reality Learning Experience Model","",,"IEEE P1589/D3, October 2019","3 Feb 2020","2020","","","1","67","Augmented Reality (AR) promises to provide significant boosts in operational efficiency by making information available to employees needing task support in context in real time. To support according implementations of AR training systems,this document proposes an overarching integrated conceptual model that describes interactions between the physical world, the user, and digital information, the context for AR-assisted learning and other parameters of the environment. It defines two data models and their binding to XML and JSON for representing learning activities (also known as employee tasks and procedures) and the learning environment in which these tasks are performed (also known as the workplace). The interoperability specification and standard is presented in support of an open market where interchangeable component products provide alternatives to monolithic Augmented Reality-assisted learning systems. Moreover, it facilitates the creation of experience repositories and online marketplaces for Augmented Reality-enabled learning content. Specific attention was given to reuse and repurposing of existing learning content and catering to ‘mixed’ experiences combining real world learner guidance with the consumption (or production) of traditional contents such as instructional video material or learning apps and widgets.","","978-1-5044-6238-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8979561","Augmented Reality;E-Learning;Workplace Training;Learning Activity;Learning Experience;Performance Support;Immersive Learning Environment;Mixed Reality","IEEE Standards;Augmented reality;Context modeling;Real-time systems;Data models;Training data","","","","","","","","3 Feb 2020","","","IEEE","IEEE Standards"
"IEEE Draft Standard for an Augmented Reality Learning Experience Model","",,"IEEE P1589/D1, May 2017","8 May 2017","2017","","","1","27","Augmented Reality (AR) promises to provide significant boosts in operational efficiency by making information available to employees needing task support in context in real time. To support according implementations of AR training systems,this document proposes an overarching integrated conceptual model that describes interactions between the physical world, the user, and digital information, the context for AR-assisted learning and other parameters of the environment. It defines two data models and their binding to XML and JSON for representing learning activities (also known as employee tasks and procedures) and the learning environment in which these tasks are performed (also known as the workplace). The interoperability specification and standard is presented in support of an open market where interchangeable component products provide alternatives to monolithic Augmented Reality-assisted learning systems. Moreover, it facilitates the creation of experience repositories and online marketplaces for Augmented Reality-enabled learning content. Specific attention was given to reuse and repurposing of existing learning content and catering to ‘mixed’ experiences combining real world learner guidance with the consumption (or production) of traditional contents such as instructional video material or learning apps and widgets.","","978-1-5044-4044-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7921682","Augmented Reality;E-Learning;Workplace Training;Learning Activity;Learning Experience;Performance Support;Immersive Learning Environment;Mixed Reality","IEEE Standards;Augmented reality;Learning systems;Training","","","","","","","","8 May 2017","","","IEEE","IEEE Standards"
"An Analysis Tool for Cooperative Mixed Reality Scenarios","M. Prilla; L. M. Rühmann","Technical University Clausthal, Informatics, Germany; Technical University Clausthal, Informatics, Germany","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","31","35","In this paper, we want to introduce a novel mixed reality (MR) analysis tool that provides 3D reproductions of multiple actors using head-mounted AR devices in a cooperative setting. The tool is motivated by a challenge we are faced with when analysing AR support for cooperative scenarios: For this analysis, one needs information on people's movements and behaviour as well as on their interaction with digital information and objects. As other means of analysis proved insufficient for these purposes, we created and applied a novel tool which shows wearers of Head Mounted Displays (HMD) devices, the digital objects they interacted with and the actual setting they were in. The tool features several features for the analysis of these settings, which were predominately based on requirements stemming from two cases studies. In this paper, we present the tool, its most prominent features, and its application in two cases. To our knowledge, there is no other tool that includes similar features and means for analysis available, and we would like to discuss its benefits and possible applications with interested colleagues.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699330","Mixed Reality;Augmented Reality;Analysis Tool;Cooperation;Human-Centered computing—Interaction paradigms—Mixed / augmented reality;Human-Centered computing-collaborative and social computing—collaborative and social computing systems and tools—open source software","Tools;Task analysis;Resists;Three-dimensional displays;Search problems;Augmented reality","augmented reality;helmet mounted displays;human computer interaction","cooperative mixed reality scenarios;head-mounted AR devices;Head Mounted Displays devices;mixed reality analysis tool;HMD devices","","1","","11","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Research on Intangible cultural heritage education inheritance based on augmented reality technology","X. -Z. Li; C. -C. Chen; X. Kang","College of Design, National Taipei University of Technology, Taipei City, Taiwan; Department of Interaction Design, National Taipei University of Technology, Taipei City, Taiwan; School of Design, NingboTech University, Ningbo, China","2022 IEEE International Conference on Consumer Electronics - Taiwan","1 Sep 2022","2022","","","49","50","The intangible cultural heritage is exposed to the risk of being lost or forgotten forever. As a result, importance should be attached to the protection of intangible cultural heritage. This paper introduces design concepts and working prototypes for augmented reality (AR) applications, which makes users know more about the process of Chinese lanterns. 3D images are overlapped a real environment through AR technology, giving intangible cultural heritage learning more fun. Visitors can experience this app during the lantern festival. Studies show that it is feasible to use AR technology for intangible cultural heritage education, which can transfer knowledge and improve learning interests.","2575-8284","978-1-6654-7050-6","10.1109/ICCE-Taiwan55306.2022.9869146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869146","Intangible cultural heritage;augmented reality;traditional Chinese lanterns;Interactive Learning Technology","Three-dimensional displays;Prototypes;Cultural differences;Augmented reality;Consumer electronics","augmented reality;computer aided instruction;history;human computer interaction;virtual reality","AR technology;Intangible cultural heritage education inheritance;augmented reality technology;augmented reality applications","","1","","8","IEEE","1 Sep 2022","","","IEEE","IEEE Conferences"
"[Poster] Utilizing contact-view as an augmented reality authoring method for printed document annotation","K. Č. Pucihar; P. Coulton","SCC, Lancaster University, UK; LlCA, Lancaster University, UK","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","299","300","In Augmented Reality (AR) the real world is enhanced by superimposed digital information commonly visualized through augmented annotations. The visualized data comes from many different data sources. One increasingly important source of data is user generated content. Unfortunately, AR tools that support user generated content are not common hence the majority of augmented data within AR applications is not generated utilizing AR technology. In this paper we discuss the main reasons for this and evaluate how the contact-view paradigm could enhance annotation authoring process within the class of tabletop size AR workspaces. This evaluation is based on a prototype that allows musicians to annotate a music score manuscript utilizing freehand drawing on top of device screen. Experimentation showed the potential of contact-view paradigm as an annotation authoring method that performs well in single and collaborative multi-user situations.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948459","AR;magic-lens;authoring;annotation;collaboration;contact-view;mobile;handheld;tbaletop","Augmented reality;Context;Prototypes;Collaboration;Rendering (computer graphics);User-generated content;Cameras","augmented reality;document handling","contact-view method;augmented reality authoring method;printed document annotation;AR;augmented annotation;AR technology;contact-view paradigm;annotation authoring process;freehand drawing;multiuser situation","","4","","13","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"[POSTER] Illumination Estimation Using Cast Shadows for Realistic Augmented Reality Applications","S. Jiddi; P. Robert; E. Marchand","Technicolor, IRISA; NA; IRISA","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","192","193","Augmented Reality (AR) scenarios aim to provide realistic blending between real world and virtual objects. A key factor for realistic AR is thus a correct illumination simulation. This consists in estimating the characteristics of real light sources and use them to model virtual lighting. In this paper, we briefly introduce a novel method for recovering both 3D position and intensity of multiple light sources using detected cast shadows. Our algorithm has been successfully tested on a set of real scenes where virtual objects have visually coherent shadows.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088480","","Lighting;Three-dimensional displays;Light sources;Estimation;Augmented reality;Geometry;Image color analysis","augmented reality;digital simulation;lighting;object detection","virtual lighting;virtual objects;visually coherent shadows;realistic blending;light source intensity;illumination estimation;augmented reality scenarios;illumination simulation;realistic augmented reality applications;realistic AR;real world;real light sources;3D position;cast shadow detection","","10","5","6","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"[POSTER] Towards Estimating Usability Ratings of Handheld Augmented Reality Using Accelerometer Data","M. Ericson; T. Taketomi; G. Yamamoto; G. Klinker; C. Santos; H. Kato","Nara Sentan Kagaku Gijutsu Daigakuin Daigaku, Ikoma, Nara, JP; Technische Universität München; Nara Institute of Science and Technology; Nara Institute of Science and Technology; Nara Sentan Kagaku Gijutsu Daigakuin Daigaku, Ikoma, Nara, JP; Nara Institute of Science and Technology","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","196","197","Usability evaluations are important to the development of augmented reality systems. However, conducting large-scale longitudinal studies remains challenging because of the lack of inexpensive but appropriate methods. In response, we propose a method for implicitly estimating usability ratings based on readily available sensor logs. To demonstrate our idea, we explored the use of features of accelerometer data in estimating usability ratings in an annotation task. Results show that our implicit method corresponds with explicit usability ratings at 79% and 84%. These results should be investigated further in other use cases, with other sensor logs.","","978-1-4673-7660-0","10.1109/ISMAR.2015.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328102","","Usability;Augmented reality;Accelerometers;Standards;Handheld computers;Yttrium;Feature extraction","augmented reality;user interfaces","usability ratings estimation;handheld augmented reality;accelerometer data;usability evaluation;augmented reality systems;sensor logs;annotation task","","3","","8","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"MagicCup: a tangible interface for virtual objects manipulation in table-top augmented reality","H. Kato; K. Tachibana; M. Tanabe; T. Nakajima; Y. Fukuda","Osaka University, Japan; Hiroshima City University, Japan; Knack Images Production Center, Japan; Hiroshima City University, Japan; Hiroshima Institute of Technology, Japan","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","75","76","We propose a tangible interface for virtual object manipulation in table-top augmented reality based on ARToolKit. It is designed for city planning. Augmented reality technology enables users to consider city plans more effectively and easily. One important issue of the augmented reality environment is how a user can manipulate 3D structures that are displayed as virtual objects. It has to be intuitive and easy so that it may not disturb a user's thoughts. We propose a new direct manipulation method based on a tangible user interface. The user holds a transport cup upside down and can pick up, move or delete a virtual object.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320434","","Augmented reality;Computational modeling;Cameras;Urban planning;Computer displays;Production;Cities and towns;User interfaces;Computer simulation;Shape","haptic interfaces;interactive devices;augmented reality;town and country planning","MagicCup;tangible interface;virtual object manipulation;table-top augmented reality;ARToolkit;city planning;3D structure manipulation;user interface","","13","","3","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"Willing to be fooled: Security and autoamputation in augmented reality","B. Brinkman","Miami University, USA","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","89","90","What does it mean to trust, or not trust, an augmented reality system? Froma computer security point of view, trust in augmented reality represents a real threat to real people. The fact that augmented reality allows the programmer to tinker with the user's senses creates many opportunities for malfeasance. It might be natural to think that if we warn users to be careful it will lower their trust in the system, greatly reducing risk.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483995","","Augmented reality;Stress;Accuracy;Security;Media;Sorting;Sensors","augmented reality;security of data;trusted computing","computer security;risk reduction;augmented reality systems;anonymity protection;autoamputation concept","","3","","3","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"An automatic parallax adjustment method for stereoscopic augmented reality systems","W. -C. Chen; F. -J. Hsiao; C. -W. Lin","Electronics & Optoelectronics Research Laboratories, Industrial Technology and Research Institute, Taiwan; Electronics & Optoelectronics Research Laboratories, Industrial Technology and Research Institute, Taiwan; Electronics & Optoelectronics Research Laboratories, Industrial Technology and Research Institute, Taiwan","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","215","216","This paper presents an automatic parallax adjustment method that considers the border effect to produce more realistic stereo images on a stereoscopic augmented reality system. Three-dimensional (3D) imaging is an emerging method of displaying three-dimensional information and providing an immersive and intuitive experience with augmented reality. However, the protruding parts of displayed stereoscopic images may be blurry and cause viewing discomfort. Furthermore, the border effect may make it difficult for an imaging system to display regions next to screen borders, even with considerable negative parallax. This paper proposes a method of automatically adjusting the parallax of displayed stereo images by analyzing the feature points in regions near screen borders to produce better stereo effects. Experimental results and a subjective assessment of human factor issues indicate that the proposed method makes stereoscopic augmented reality systems significantly more attractive and comfortable to view.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643574","acceptance of MR/AR technology;MR/AR for entertainment;usability studies and experiments","Three dimensional displays;Visualization;Augmented reality;Feature extraction;Cameras;Stereo vision","augmented reality;stereo image processing","automatic parallax adjustment method;stereo images;stereoscopic augmented reality system;three dimensional imaging;negative parallax","","1","","5","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Challenges and Applications of Urban Augmented Reality Summary","G. Moreau; T. Taketomi",Ecole Centrale de Nantes; Nara Institute of Science and Technology,"2015 IEEE International Symposium on Mixed and Augmented Reality Workshops","3 Dec 2015","2015","","","87","87","Summary form only given. Cities have started collecting tons of information about themselves using vast sensors arrays and stored in Geographical Information Systems. All this mass of information can already be enriched by citizens through user-generated content. Beyond collecting, abstracting and storing this information raises the problem of its representation. A reasonable assumption is that onsite presentation of the adequate information would provide a good solution. An analogy can be made with the GPS-based navigation systems that merely render a directed arrow depending on location and itinerary. Such a system can be seen as the basis of an augmented reality system. Many projects involving augmented reality in urban environments have emerged in the last 15 years. Yet there remains challenges both on the applications and technological points of views: Outdoor localization and mapping, Data presentation, Interaction and authoring, Application domains, Acceptability, Hardware issues. The goal of this workshop is to review the challenges of urban augmented reality and the available methods that aim at solving some of those challenges and to give the audience of the variety of the existing and yet to invent applications. The workshop will feature 2 full papers about geolocalization from maps and building facade rectification for image-based matching out of 6 submissions. Those papers will appear onto IEEExplore. It will also include a number of applications papers that will directly appear on the workshop website (https://sites.google.com/site/urbanarworkshop/home). It provides a place for discussing the remaining challenges and the solutions the community is trying to bring.","","978-1-4673-8471-1","10.1109/ISMARW.2015.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344763","","Augmented reality;Conferences;Sensor arrays;Information systems;Geology;Information science","augmented reality;geographic information systems;town and country planning","urban augmented reality;cities;sensors arrays;geographical information systems;user-generated content;information collection;information abstraction;information storage;information representation;GPS-based navigation systems;urban environments;outdoor localization;mapping;data presentation;data interaction;authoring;application domains;building facade rectification;image-based matching","","","","","IEEE","3 Dec 2015","","","IEEE","IEEE Conferences"
"Using augmented reality to support situated analytics","N. A. M. ElSayed; B. H. Thomas; R. T. Smith; K. Marriott; J. Piantadosi",Wearable Computer Lab; Wearable Computer Lab; Wearable Computer Lab; Monash Adaptive Visualisation Lab; University of South Australia,"2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","175","176","We draw from the domains of Visual Analytics and Augmented Reality to support a new form of in-situ interactive visual analysis. We present a Situated Analytics model, a novel interaction, and a visualization concept for reasoning support. Situated Analytics has four primary elements: situated information, abstract information, augmented reality interaction, and analytical interaction.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223352","H.5.1 [Multimedia Information Systems]: Artificial, Augmented, and Virtual Realities — Life Cycle","Data visualization;Visualization;Augmented reality;Analytical models;Cognition;Solid modeling;Layout","augmented reality;data analysis;data visualisation;human computer interaction;inference mechanisms","visual analytics;interactive visual analysis;situated analytics model;reasoning support;situated information;abstract information;augmented reality interaction;analytical interaction","","20","","6","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Augmented Reality Based Re-formable Mock-Up for Design Evaluation","J. Park","Department of Computer Science, Hongik University, Seoul, South Korea","2008 International Symposium on Ubiquitous Virtual Reality","18 Jul 2008","2008","","","17","20","Rapid prototyping allows for evaluation of design product in a short period of time. Designers or CEOs may perceive the size and appearance of the product by touching the automatically constructed physical objects produced through rapid prototyping. However, it is usually impossible to change its color, texture, and user interface. In this paper, we introduce 'Augmented Reality based Re-formable Mock-up', which enables interactive changes of shapes of products as well as colors, textures, and user interfaces. The shapes of the physical objects are re-formable by assembling different parts to the main body of the mock-up. Augmented Reality technologies were used to alter the appearance of the mock-up by rendering the 3D models, colors, and interfaces accordingly. The re-assembled mock-up was detected by comparing the edges of the mock-up with those of candidate 3D models. Skin detection was used in order to render the hand region on the top of rendered virtual object. Fingertip tracking algorithm was also implemented so that the users may manipulate the design product using their fingertips. Developed AR-based re-formable mock-up is expected to be used for realistic design evaluation and CEO presentations.","","978-0-7695-3259-2","10.1109/ISUVR.2008.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568636","Augmented Reality;mock-up;design evaluation","Augmented reality;Rendering (computer graphics);Prototypes;Product design;User interfaces;Shape;Assembly;Skin;Object detection;Algorithm design and analysis","augmented reality;CAD;product design;rendering (computer graphics)","augmented reality;reformable mock-up;design evaluation;rapid prototyping;rendering;3D models;skin detection;fingertip tracking algorithm","","11","","13","IEEE","18 Jul 2008","","","IEEE","IEEE Conferences"
"Augmented reality for maintenance application on a mobile platform","N. S. Lakshmprabha; S. Kasderidis; P. Mousouliotis; L. Petrou; O. Beltramello","University of Rome Tor Vergata; NOVOCAPTIS; Aristotle University of Thessaloniki; NOVOCAPTIS; European Organization for Nuclear Research, CERN","2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","355","356","Pose estimation is a major requirement for any augmented reality (AR) application. Cameras and inertial measurement units (IMUs) have been used for pose estimation not only in AR but also in many other fields. The level of accuracy and pose update required in an AR application is more demanding than in any other field. In certain AR applications, (maintenance for example) a small change in pose can cause a huge deviation in the rendering of the virtual content. This misleads the user in terms of an object location and can display incorrect information. Further, the huge amount of processing power required for the camera based pose estimation results in a bulky system. This reduces the mobility and ergonomics of the system. This demonstration shows a fast pose estimation using a camera and an IMU on a mobile platform for augmented reality in a maintenance application.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223442","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, Augmented, and Virtual Realities","Estimation;Augmented reality;Maintenance engineering;Cameras;Europe;Organizations;Mobile communication","augmented reality;mobile computing;pose estimation;software maintenance","augmented reality application;AR application;maintenance application;mobile platform;pose estimation;cameras;inertial measurement units;IMU;accuracy level;rendering;virtual content;object location","","3","","5","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Dorsal and Ventral Pathways Implications in an Augmented Reality Environment","A. S. Frangos; T. -J. Lee; D. To; I. Giannopulu","Bond University, Gold Coast, QLD, AU; Bond University, Gold Coast, QLD, AU; Bond University, Gold Coast, QLD, AU; Bond University, Gold Coast, QLD, AU","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1658","1662","The Ventral Pathway (VP) and Dorsal Pathway (DP) are responsible for identifying (what) and localising (where) objects in 3D space. These pathways project integrated information into the frontal (FC) and the prefrontal (PF) cortices making possible for humans not only to interact with objects but also express motivations and emotions directly or indirectly associated with the actions they perform with objects. The neural implications of these pathways were examined in a sample of healthy participants ( n = 30) aged 22 years old while invited to create an installation using a set of common (CO) and uncommon objects (UO) in augmented reality (AR). All participants were equipped with a 32 channels EEG, a frequency analysis of brain waves has been performed. The results have shown an alpha power increase in the ventral pathway when UO were involved in the creative task. This finding is attributed to a greater need to attend the UO as no representation of them exists in the VP. Increased theta and delta powers were observed in the FC when creating an installation with UO, indicating more higher-order functioning involving emotion and motivation. Engaging multimodal complex brain areas, it seems that creativity in augmented reality requires similar brain patterns as in real world.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797757","Augmented Reality (AR);Neuro-imaging;Ventral Pathway (VP);Dorsal Pathway (DP);Electro-Encephalography (EEG);Frontal Cortex (FC);Prefrontal Cortex (PFC)","Electroencephalography;Task analysis;Augmented reality;Object recognition;Creativity;Electrodes;Three-dimensional displays","augmented reality;bioelectric potentials;electroencephalography;human computer interaction;medical signal processing;neurophysiology","brain wave frequency analysis;32 channels EEG;common objects;alpha power;dorsal pathway;uncommon objects;healthy participants;neural implications;prefrontal cortices;ventral pathway;augmented reality environment;age 22.0 year","","2","","19","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Using Chromo-coded light fields for augmented reality","I. Schillebeeckx; R. Pless","Washington University in St. Louis, St. Louis, MO; Washington University in St. Louis, St. Louis, MO","2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","281","282","The light field, or plenoptic function, is a mathematical construct that models the location and direction of light to describe the complete visual appearance of a scene. The light field provides a unifying construct to describe cameras and displays. Explicitly manipulating the light field is an approach to changing the world to make it easier to understand. One way to create light fields is with materials like lenticular arrays, whose color appearance can be made to vary by viewing angle. These Chromo-coded light fields use color to create additional geometric cues, making it cheaper, faster and more accurate to measure object pose. For high-end applications like augmented reality, the color-cues make it possible to accurately measure pose of small objects to project digital content. This poster offers demonstrations of a few augmented reality applications made possible by chromo-coded light fields.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504763","Light Field;Lenticular Array;Augmented Reality","Cameras;Augmented reality;Image color analysis;Three-dimensional displays;Lenses;Solid modeling;Visualization","augmented reality;geometry;image colour analysis","Chromo-coded light fields;augmented reality;plenoptic function;mathematical construct;visual appearance;scene;lenticular arrays;color appearance;geometric cues;color-cues","","1","","7","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Blending Spaces: Cross-Reality Interaction Techniques for Object Transitions Between Distinct Virtual and Augmented Realities","R. Cools; A. Esteves; A. L. Simeone","Department of Computer Science, KU Leuven; ITI / LARSyS, Instituto Superior Técnico, University of Lisbon; Department of Computer Science, KU Leuven","2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","27 Dec 2022","2022","","","528","537","Cross-Reality (CR) involves interaction between different modalities and levels of immersion such as Virtual and Augmented Reality, as we explore in this paper. Whereas previous work assumed similarity between their respective Virtual and Augmented Environment (VE and AE), we explore the case in which VE and AE are distinct. This gives rise to novel and critical problems, such as how to visualise and interact with the other environment. In this context we investigate the fundamental interaction of transitioning an object across environments, to which we contribute five interaction techniques. Two are inspired by literature: Virtual Magic Lens and Binary Transition; while the other three are entirely novel: Auto Blended Space, Manual Blended Space - Button Transition and Manual Blended Space - Touch Transition. In a study evaluating the first four techniques, we found that participants (N=20) performed a CR object manipulation and transition task significantly faster using our Auto Blended Space technique. We then modified Manual Blended Space - Button Transition into Manual Blended Space - Touch Transition in response to these results, and reassessed the four techniques in a more complex object manipulation task (N=16). We found that this type of task was better suited to manual transition methods rather than automatic methods. Taken together, our final contribution are five blended space design factors, and timely Cross-Reality transition design guidelines.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00069","KU Leuven; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9994912","Human-centered computing;Mixed / augmented reality;Virtual reality","Visualization;Navigation;Design methodology;Virtual environments;Manuals;Task analysis;Augmented reality","augmented reality","augmented environment;augmented reality;auto blended space technique;CR object manipulation;cross-reality interaction techniques;cross-reality transition design guidelines;distinct virtual realities;manual blended space - button transition;manual blended space - touch transition;manual transition methods;object transitions;VE AE;virtual environment;virtual magic lens","","2","","40","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"The next problems to solve in augmented reality","Z. I. Bhutta; S. Umm-e-Hani; I. Tariq","Department of Information Technology, University of Lahore; Department of Information Technology, University of Lahore; Department of Computer Science, University of Lahore","2015 International Conference on Information and Communication Technologies (ICICT)","19 May 2016","2015","","","1","4","Augmented reality (AR) is a growing phenomenon. We are on the verge of ubiquitously adopting Augmented Reality (AR) technologies to enhance our perception and help us see, hear, and feel our environments in new and enriched ways. AR will really change the way people see the universe. This paper provides a review on classification of different augmented reality challenges ranges from human factors to hard problem of law and policy which aims to explore new challenges and issues for the acceptance of AR technology.","","978-1-4673-8907-5","10.1109/ICICT.2015.7469490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7469490","Augmented Reality;Augmented Reality technologies;challenges;AR acceptance","Augmented reality;Computers;Mobile communication;Privacy;Visualization;User interfaces","augmented reality","augmented reality;AR technology;augmented reality challenges","","2","","18","IEEE","19 May 2016","","","IEEE","IEEE Conferences"
"Analysis of Virtual Reality and Augmented Reality SDK’s and Game Engines: A Comparison","S. Angra; B. Sharma; A. Sharma","Immersive and Interactive Technology Lab, Chitkara University Institute of Engineering and Technology Chitkara University, Punjab, India; Immersive and Interactive Technology Lab, Chitkara University Institute of Engineering and Technology Chitkara University, Punjab, India; Department of Computer Science and Engineering, MM Engineering College, Maharishi Markandeshwar (Deemed to be University), Mullana-Ambala, Haryana, India","2022 International Conference on Edge Computing and Applications (ICECAA)","8 Nov 2022","2022","","","1681","1684","At present, many immersive technologies such as Augmented Reality (AR), Virtual Reality (VR), Mixed Reality (MR) and Extended Reality (XR) technologies are in demand because people tend to learn more through picturing the things rather than learning the things theoretically. Theoretical learning leads to boredom in Education. Therefore, with the aim of providing knowledge to the peers, this paper provides the discussion on the main foundation of the immersive technologies which are Game Engines and Software Development Kits (SDK’s). Many people assume Game engine and SDK to be same that is why this paper brings out more clarity about the difference between the two.","","978-1-6654-8232-5","10.1109/ICECAA55415.2022.9936111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9936111","Augmented Reality;Education;Innovation;Technology;Innovative;Virtual Reality;Communication;Game Engines;Software Development Kits;immersive","Extended reality;Education;Mixed reality;Games;Animation;Software;X reality","augmented reality;computer games;mobile computing;multimedia computing;virtual reality","Game Engines;immersive technologies;Game engine;Virtual Reality;Augmented Reality SDK","","","","15","IEEE","8 Nov 2022","","","IEEE","IEEE Conferences"
"Mixed reality in virtual world teleconferencing","T. Kantonen; C. Woodward; N. Katz","VTT Technical Research Center of Finland, Finland; VTT Technical Research Center of Finland, Finland; IBM, Corporation, USA","2010 IEEE Virtual Reality Conference (VR)","8 Apr 2010","2010","","","179","182","In this paper we present a Mixed Reality (MR) teleconferencing application based on Second Life (SL) and the OpenSim virtual world. Augmented Reality (AR) techniques are used for displaying virtual avatars of remote meeting participants in real physical spaces, while Augmented Virtuality (AV), in form of video based gesture detection, enables capturing of human expressions to control avatars and to manipulate virtual objects in virtual worlds. The use of Second Life for creating a shared augmented space to represent different physical locations allows us to incorporate the application into existing infrastructure. The application is implemented using open source Second Life viewer, ARToolKit and OpenCV libraries.","2375-5334","978-1-4244-6238-4","10.1109/VR.2010.5444792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444792","mixed reality;virtual worlds;Second Life;teleconferencing;immersive virtual environments;collaborative augmented reality","Virtual reality;Teleconferencing;Second Life;Avatars;Augmented virtuality;Augmented reality;Video sharing;Object detection;Humans;Libraries","augmented reality;avatars;teleconferencing","mixed reality;virtual world teleconferencing;second life;OpenSim virtual world;augmented reality;augmented virtuality;virtual avatars;video based gesture detection","","27","7","25","IEEE","8 Apr 2010","","","IEEE","IEEE Conferences"
"""Move the couch where?"" : developing an augmented reality multimodal interface","S. Irawati; S. Green; M. Billinghurst; A. Duenser; H. Ko","Department of Human Computer Interaction and Robotics, University of Science and Technology, China; Department of Mechanical Engineering, University of Canterbury, New Zealand; Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; Imaging Media Research Center, Korea Institute of Science and Technology, South Korea","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","183","186","This paper describes an augmented reality (AR) multimodal interface that uses speech and paddle gestures for interaction. The application allows users to intuitively arrange virtual furniture in a virtual room using a combination of speech and gestures from a real paddle. Unlike other multimodal AR applications, the multimodal fusion is based on the combination of time-based and semantic techniques to disambiguate a users speech and gesture input. We describe our AR multimodal interface architecture and discuss how the multimodal inputs are semantically integrated into a single interpretation by considering the input time stamps, the object properties, and the user context.","","1-4244-0650-1","10.1109/ISMAR.2006.297812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079274","","Augmented reality;Speech;Application software;Virtual reality;Computer interfaces;Virtual environment;Mice;User interfaces;Graphical user interfaces;Space technology","augmented reality;gesture recognition;speech recognition;speech-based user interfaces","augmented reality multimodal interface;paddle gesture;speech gesture;multimodal fusion;semantic technique;time-based technique","","19","1","24","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"A mobile Passive Augmented Reality Device - mPARD","H. T. Regenbrecht; R. Specht","DaimlerChrysler Aerospace, Ulm, Germany; DaimlerChrysler Aerospace, Ulm, Germany","Proceedings IEEE and ACM International Symposium on Augmented Reality (ISAR 2000)","6 Aug 2002","2000","","","81","84","Describes an RF-based approach to mobile augmented reality (AR), solving the problem of providing sufficient computational and graphics power on conventional wearable computers. Two devices are presented which work together and can be used either in a hand-held AR display version or as a wearable version using an external mobile camera and a head-mounted display. The process of evaluation and improvement is ongoing, but the results so far are presented, including usability tests in industrial applications.","","0-7695-0846-4","10.1109/ISAR.2000.880926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=880926","","Augmented reality;Wearable computers;Computer vision;Virtual reality;Cameras;Application software;Mobile computing;Computer graphics;Computer displays;Videoconference","mobile computing;portable computers;augmented reality;computer graphic equipment;cameras;helmet mounted displays;human factors;computer displays","mobile passive augmented reality device;mPARD;RF-based approach;computational power;graphics power;wearable computers;hand-held display;external mobile camera;head-mounted display;usability tests;industrial applications","","9","8","12","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Evaluation of three input techniques for selection and annotation of physical objects through an augmented reality view","B. H. Thomas","Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, SA, Australia","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","33","36","This paper presents results from a study into the usability issues of two tasks (selection and annotation of a physical object) for users operating mobile augmented reality systems. The study compared the following three different modes of cursor manipulation: a handheld mouse, a head cursor, and an image-plane vision-tracked device. The selection task was evaluated based on number of mouse button clicks, completion time, and a subjective survey. The annotation task was evaluated based on accuracy of the annotation, completion time, and a subjective survey.","","1-4244-0650-1","10.1109/ISMAR.2006.297791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079253","","Augmented reality;Wearable computers;Head;Mice;Collaborative work;Virtual reality;Usability;User interfaces;Computer graphics;Cameras","augmented reality;human factors;interactive devices;mobile computing;user interfaces;wearable computers","mobile augmented reality system;usability issue;physical object selection;physical object annotation;cursor manipulation;handheld mouse;head cursor;image-plane vision-tracked device;wearable computer;input device;human factor;user interface technology","","6","","14","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Augmented Reality in Medical Teaching-Learning Process Content: A Systematic Review","I. Bianchi; A. L. Zanatta; R. Rieder","University of Passo Fundo (UPF), Passo Fundo, RS, Brazil; University of Passo Fundo (UPF), Passo Fundo, RS, Brazil; University of Passo Fundo (UPF), Passo Fundo, RS, Brazil","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","129","133","Educators have attempted to innovate the teaching-learning process through computational tools. Some medical educational applications have been created with Augmented Reality resources. Serious Games are one of these kinds of applications, aiming as purpose education or training tasks for users considering entertainment too. Augmented Reality games require appropriate devices for satisfactory experience, as well a usability evaluation to ensure the application's efficiency. With this in mind, this study presents a systematic review to identify approaches that use Mixed or Augmented Reality games in the teaching-learning process of medical contents, and that execute at least one preliminary evaluation with users. Only six selected studies attend the eligibility criteria. We notice a lack of Mixed or Augmented Reality serious games in many medical areas, such as hematology. This work also verified that the evaluation process of these games no adopts a standard protocol or well-known instruments available in the literature for usability evaluation, revealing an opportunity for new studies.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262671","Augmented Reality;Games;Medicine;teaching-learning process","Games;Training;Systematics;Sun;Engines;Usability;Tools","augmented reality;biomedical education;computer aided instruction;serious games (computing);teaching;user interfaces","medical areas;medical teaching-learning process content;medical educational applications;augmented reality games;medical contents;augmented reality serious games","","1","","25","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"Augmented Reality for Infrastructure Inspection with Semi-autonomous Aerial Systems: An Examination of User Performance, Workload, and System Trust","J. V. Dam; A. Krasner; J. L. Gabbard",Virginia Tech; Virginia Tech; Virginia Tech,"2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","11 May 2020","2020","","","742","743","The use of augmented reality (AR) with drones in infrastructure inspection can increase human capabilities by helping workers access hard-to-reach areas and supplementing their field of view with useful information. Still unknown though is how these aids impact performance when they are imperfect. A total of 28 participants flew as an autonomous drone while completing a target detection task around a simulated bridge. Results indicated significant differences between cued and un-cued trials but not between the four cue types: none, bounding box, corner-bound box, and outline. Differences in trust amongst the four cues indicate that participants may trust some cue styles more than others.","","978-1-7281-6532-5","10.1109/VRW50115.2020.00222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090653","Augmented reality;signal detection;infrastructure inspection;workload;unmanned aerial system.","Inspection;Task analysis;Bridges;Augmented reality;Signal detection;Visualization","augmented reality;autonomous aerial vehicles;inspection;object detection","augmented reality;infrastructure inspection;semiautonomous aerial systems;user performance;system trust;autonomous drone;target detection task","","1","","6","IEEE","11 May 2020","","","IEEE","IEEE Conferences"
"""Kapow!"": Augmenting Contacts with Real and Virtual Objects Using Stylized Visual Effects","V. Mercado; J. -M. Normand; A. Lécuyer","Univ Rennes, INSA, Inria, CNRS, IRISA; École Centrale de Nantes, AAU, Inria Hybrid; Univ Rennes, Inria, CNRS, IRISA","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","116","117","We propose a set of stylized visual effects (VFX) meant to improve the sensation of contact with objects in Augmented Reality (AR). Various graphical effects have been conceived, such as virtual cracks, virtual wrinkles, or even virtual onomatopoeias inspired by comics. The VFX are meant to augment the perception of contact, with either real or virtual objects, in terms of material properties or contact location for instance. These VFX can be combined with a pseudohaptics approach to further increase the range of simulated physical properties of the touched materials. An illustrative setup based on a HoloLens headset was designed, in which our proposed VFX could be explored. The VFX appear each time a contact is detected between the user’s finger and one object of the scene. Such VFX- based approach could be introduced in AR applications for which the perception and display of contact information are important.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287824","Augmented-Reality;Virtual Environments;Visual Effects;Pseudo-Haptics","Headphones;Fingers;Visual effects;Augmented reality;Physics;Material properties","augmented reality;haptic interfaces","VFX;augmented reality;graphical effects;virtual cracks;virtual wrinkles;virtual onomatopoeias;real objects;virtual objects;material properties;contact location;stylized visual effects;comics;pseudohaptics;HoloLens headset","","","","8","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Depth perception in mirrors: The effects of video-based augmented reality in driver's side view mirrors","V. Kane; M. Smith; G. Burnett; J. L. Gabbard; D. Large","Virginia Tech, Blacksburg, USA; Virginia Tech, Blacksburg, USA; Univ. of Nottingham, Nottingham, UK; Virginia Tech, Blacksburg, USA; Univ. of Nottingham, Nottingham, UK","2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","195","196","This study explored the effects that augmented reality graphics have on a drivers' distance estimation/depth perception in an augmented side view mirror. The study was conducted both inside a simulator and outside in a parking lot. Sixteen participants partook in the study, 8 in the simulator and 8 in the test vehicle outside. Distance judgments were compared across four side view mirror conditions both simulator and outdoor scenarios. Results show some opportunities for AR to improve depth judgments, but further analysis is necessary.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504720","Augmented reality;depth perception;near side mirror","Mirrors;Augmented reality;Vehicle dynamics;Accidents;Automobiles","augmented reality;driver information systems;estimation theory;video signal processing","depth perception;video-based augmented reality;driver side view mirrors;distance estimation","","4","","8","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Walled Gardens: Apps and Data as Barriers to Augmenting Reality","B. MacIntyre; H. Rouzati; M. Lechner","School of Interactive Computing, Georgia Tech, USA; Augmented Environments Laboratory, Georgia Tech, USA; Wikitude, Austria","IEEE Computer Graphics and Applications","15 May 2013","2013","33","3","77","81","For augmented reality (AR) to reach its potential, AR content from multiple distinct sources must be simultaneously displayed in a more unified manner than is possible given today's application-centric environments. AR browsers and AR-enabled Web browsers point toward the functionalities that OSs must incorporate to fully support AR content. Also, application developers need richer forms of content describing the physical world and the objects in it. Standards such as ARML (Augmented Reality Markup Language) 2.0 have begun providing the glue needed to bind AR content to the physical world.","1558-1756","","10.1109/MCG.2013.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6516495","augmented reality;ARML 2.0;mobile computing;computer graphics","Augmented reality;Three dimensional displays;Mobile communication","augmented reality;online front-ends;operating systems (computers);XML","walled gardens;AR content;multiple distinct sources;application-centric environments;AR browsers;AR-enabled Web browsers;application developers;ARML 2.0;augmented reality markup language 2.0","","9","","3","IEEE","15 May 2013","","","IEEE","IEEE Magazines"
"Mixed Reality, Mamulengos and MamuLEDs","J. Jácome; M. Oliveira; F. Alvim; V. Teichrieb; G. L. Ramalho","Voxar Labs /MusTIC, Cln - UFPE, Recife, Brazil; Cia. Artistica Mamulengos e Catrevagens, Recife, Brazil; Escola Municipal de Arte Joδo Pernambuco Recife, Recife, Brazil; Voxar Labs, CIn-UFPE, Recife, Brazil; MusTIC, CIn-UFPE, Recife, Brazil","2019 21st Symposium on Virtual and Augmented Reality (SVR)","5 Dec 2019","2019","","","252","259","VR/AR/MR techniques have been applied to puppet theaters in different cultural contexts around the world. However, we are not yet aware of the use of these techniques in the Brazilian Northeast Popular Puppet Theater, a tradition known in Pernambuco as Mamulengo. We present here a system developed for ""The Fight Between the Real Puppet and the Virtual Puppet"" sketch created for the course ""Virtual and Augmented Reality"" of Computer Science program at CIn-UFPE. The aim of this paper is to investigate how VR/AR/MR techniques can contribute to the creation of Mamulengo shows. We used the method of Qualitative Case Study, analyzing the audiovisual records of essays and presentation, the software solution developed in Unity3D and the data collected from a focus group interview. This study identified as weaknesses of the system: the hand tracking instability and the lack of tactile feedback, causing some physical and psychological discomfort in an experienced doll handler. As strengthens of the system, we found that the technology aroused interest because of its novelty and potential for expanding of the tools available for puppetry.","","978-1-7281-5434-3","10.1109/SVR.2019.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920835","Mixed Reality;Hand Tracking;Mamulengos;MamuLEDs","Augmented reality","augmented reality;human computer interaction;psychology;user interfaces;virtual reality","Augmented Reality;Computer Science program;CIn-UFPE;Mamulengo shows;audiovisual records;software solution;hand tracking instability;mixed Reality;mamulengos;MamuLEDs;puppet theaters;cultural contexts;Brazilian Northeast Popular Puppet Theater;tradition;Pernambuco;Virtual Puppet;group interview","","","","","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Education System for Bangladesh Using Augmented Reality, Virtual Reality and Artificial Intelligence","H. Khan; F. Soroni; S. J. Sadek Mahmood; N. Mannan; M. M. Khan","Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka, Bangladesh","2021 IEEE World AI IoT Congress (AIIoT)","21 Jun 2021","2021","","","0137","0142","This paper presents an innovative application for students to study and understand their coursework without any external help from a private tutor. The system uses Augmented Reality (AR) to provide hands on experience for the students. The presented system also supports Virtual Reality (VR) that enriches this process and immerses the users into a fun and productive learning experience. Moreover, the system introduces an industry first Artificial intelligence (AI) based study guide that directs students towards necessary topics and advises them on what to improve on. All the core system features are implemented and are accessible via two mediums. First, a standalone mobile phone application. Second, a dedicated web portal.","","978-1-6654-3568-0","10.1109/AIIoT52608.2021.9454247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454247","Augmented reality;virtual reality;artificial intelligence;education;education system;mobile application;web application;immersive learning","Industries;Learning (artificial intelligence);Mobile handsets;Augmented reality;Portals","augmented reality;computer aided instruction;Internet;mobile computing;virtual reality","education system;bangladesh;Augmented Reality;Virtual Reality;Artificial intelligence;innovative application;external help;private tutor;productive learning experience;core system features;standalone mobile phone application","","3","","15","IEEE","21 Jun 2021","","","IEEE","IEEE Conferences"
"Studying “Avatar Transitions” in Augmented Reality: Influence on Sense of Embodiment and Physiological Activity","R. Otono; A. Genay; M. Perusquía-Hernández; N. Isoyama; H. Uchiyama; M. Hachet; A. Lécuyer; K. Kiyokawa","NAIST, Japan; Inria, Bordeaux, France; NAIST, Japan; NAIST, Japan; NAIST, Japan; Inria, Bordeaux, France; Inria, Rennes, France; NAIST, Japan","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","503","504","The impact of avatar transitions, in which an avatar's appearance is changed, has been little studied. We implemented an avatar transition system that is decomposed into two parts: an active one and a passive one. In the active transition, the avatar's appearance is transformed according to the user's physical action. In the passive transition, users automatically experience the same transition without physical action. The influence of transitions on the user's physical performance and the sense of embodiment was explored. Our results show that active transitions increase the sense of agency and magnitude of surface electromyography (sEMG) compared to passive transitions, and both transitions increase the sEMG magnitude following the virtual Reality embodiment.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974381","Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods","Avatars;Design methodology;Physiology;Electromyography;IEEE activities;Augmented reality","augmented reality;avatars;electromyography;medical signal processing;virtual reality","active transition;augmented Reality;avatar transition system;avatar transitions;passive transition;physical action;user;virtual Reality embodiment","","","","2","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Binocular vision-based augmented reality system with an increased registration depth using dynamic correction of feature positions","S. Vallerand; M. Kanbara; N. Yokoya","Nara Institute of Science and Technology, Graduate School of Information Science, Ikoma, Nara, Japan; Nara Institute of Science and Technology, Graduate School of Information Science, Ikoma, Nara, Japan; Nara Institute of Science and Technology, Graduate School of Information Science, Ikoma, Nara, Japan","IEEE Virtual Reality, 2003. Proceedings.","2 Apr 2003","2003","","","271","272","In vision-based augmented reality systems, the relationship between the real and virtual worlds needs to be estimated to perform the registration of the virtual objects. This paper suggests a registration method which increases the registration depth of video see-through augmented reality systems using binocular cameras. The method uses both monocular and stereoscopic vision-based techniques in order to perform the registration. Also, the registration method can be combined with a facultative correction of the 2D positions of the feature points. The correction increases the stability and the accuracy of the proposed registration method.","1087-8270","0-7695-1882-6","10.1109/VR.2003.1191154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191154","","Augmented reality;Cameras;Strontium;Stability;Information science;Virtual reality","augmented reality;user interfaces;stereo image processing;image registration","binocular vision-based augmented reality;registration depth;dynamic feature position correction;virtual object registration;video see-through augmented reality systems;binocular cameras;stereoscopic vision;monocular vision;stability","","2","","3","IEEE","2 Apr 2003","","","IEEE","IEEE Conferences"
"IEEE Standard for Augmented Reality Learning Experience Model","",,"IEEE Std 1589-2020","16 Apr 2020","2020","","","1","48","Augmented Reality (AR) promises to provide significant boosts in operational efficiency by making information available to employees needing task support in context in real time. To support according implementations of AR training systems,this document proposes an overarching integrated conceptual model that describes interactions between the physical world, the user, and digital information, the context for AR-assisted learning and other parameters of the environment. It defines two data models and their binding to XML and JSON for representing learning activities (also known as employee tasks and procedures) and the learning environment in which these tasks are performed (also known as the workplace). The interoperability specification and standard is presented in support of an open market where interchangeable component products provide alternatives to monolithic Augmented Reality-assisted learning systems. Moreover, it facilitates the creation of experience repositories and online marketplaces for Augmented Reality-enabled learning content. Specific attention was given to reuse and repurposing of existing learning content and catering to `mixed' experiences combining real world learner guidance with the consumption (or production) of traditional contents such as instructional video material or learning apps and widgets.;Augmented Reality (AR) promises to provide significant boosts in operational efficiency by making information available to employees needing task support in context in real time. To support according implementations of AR training systems,this document proposes an overarching integrated conceptual model that describes interactions between the physical world, the user, and digital information, the context for AR-assisted learning and other parameters of the environment. It defines two data models and their binding to XML and JSON for representing learning activities (also known as employee tasks and procedures) and the learning environment in which these tasks are performed (also known as the workplace). The interoperability specification and standard is presented in support of an open market where interchangeable component products provide alternatives to monolithic Augmented Reality-assisted learning systems. Moreover, it facilitates the creation of experience repositories and online marketplaces for Augmented Reality-enabled learning content. Specific attention was given to reuse and repurposing of existing learning content and catering to ‘mixed’ experiences combining real world learner guidance with the consumption (or production) of traditional contents such as instructional video material or learning apps and widgets.","","978-1-5044-6448-2","10.1109/IEEESTD.2020.9069498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9069498","Augmented Reality;E-Learning;Workplace Training;Learning Activity;Learning Experience;Performance Support;Immersive Learning Environment;Mixed Reality","IEEE Standards;Augmented reality;Training data;Learning systems;Electronic learning","augmented reality;computer based training;formal specification;open systems;XML","JSON;XML;monolithic augmented reality-assisted learning;augmented reality-enabled learning;augmented reality learning experience model;AR training systems;integrated conceptual model;operational efficiency;IEEE standard;experience repositories;interoperability specification;learning environment;learning activities;data models;AR-assisted learning","","2","","7","","16 Apr 2020","","","IEEE","IEEE Standards"
"Tinmith-evo5 - an architecture for supporting mobile augmented reality environments","W. Piekarski; B. H. Thomas","Wearable Computer Laboratory School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia","Proceedings IEEE and ACM International Symposium on Augmented Reality","6 Aug 2002","2001","","","177","178","This paper presents a summary of a new software architecture we have developed, known as Tinmith-evo5, which is designed as one possible methodology for writing complex AR applications. While software for 2D environments is very mature, in the 3D case there is still missing software support that we are attempting to address.","","0-7695-1375-1","10.1109/ISAR.2001.970530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=970530","","Augmented reality;Electrical capacitance tomography;Computer architecture;Wearable computers;User interfaces;Virtual environment;Virtual reality;Layout;Application software;Laboratories","augmented reality;software architecture;object-oriented programming","Tinmith-evo5;mobile augmented reality enviromnents;software architecture;complex AR applications;3D environments;softivare support;object oriented applications;user interaction techniques","","20","6","3","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"ARVIKA-augmented reality for development, production and service","W. Friedrich","Automation and Drives, Siemens AG, Germany","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","3","4","Augmented reality (AR) is a form of human-machine interaction where information is presented in the field of view of an individual. ARVIKA, funded by the German Ministry of Education and Research, develops this technology and applications in the fields of development, production, and service in the automotive and aerospace industries, for power and processing plants and for machine tools and production machinery. Up to now, AR has only been a subject of individual research projects and a small number of application-specific industrial projects on a global scale. The current state of the art and the available appliances do not yet permit a product-oriented application of the technology. However, AR enables a new, innovative form of human-machine interaction that not only places the individual in the center of the industrial workflow, but also offers a high potential for process and quality improvements in production and process workflows. ARVIKA is primarily designed to implement an augmented reality system for mobile use in industrial applications. The report presents the milestones that have been achieved after a project duration of a full three years.","","0-7695-1781-1","10.1109/ISMAR.2002.1115059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115059","","Augmented reality;Batch production systems;Man machine systems;Home appliances;Ergonomics;Vehicle crash testing;Assembly systems;Automation;Educational products;Educational technology","augmented reality;engineering graphics;user interfaces;mobile computing","ARVIKA;augmented reality;human-machine interaction;development;production;service;aerospace industries;automotive industries;power plants;processing plants;machine tools;production machinery","","61","4","","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Geometric and photometric registration for real-time augmented reality","M. Kanbara; N. Yokoya","Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","279","280","This paper proposes an augmented reality system with correct representation of shading and shadow. To realize a seamless augmented reality system, we need to resolve certain problems. The geometric and photometric registration problems are particularly important. These problems require the position of light sources and user's viewpoint. The proposed system resolves these problems using a 3D marker which combines a 2D square marker and a mirror ball. The 2D marker and the ball are used to estimate the relationship between the real and virtual worlds and the positions of light sources in the real world, respectively.","","0-7695-1781-1","10.1109/ISMAR.2002.1115112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115112","","Photometry;Augmented reality;Mirrors;Light sources;Cameras;Layout;Information science;Virtual environment;Lighting;Rendering (computer graphics)","augmented reality;image registration;computational geometry;photometry;light sources;real-time systems","real-time augmented reality;photometric registration;geometric registration;shading;shadow;light source position;user viewpoint;3D marker;2D square marker;mirror ball;real/virtual world relationship","","25","2","4","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Authoring and user interaction for the production of wave field synthesis content in an augmented reality system","F. Melchior; T. Laubach; D. de Vries","Fraunhofer IDMT, Germany; Fraunhofer IDMT, Germany; Delft University of Technnology, Netherlands","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","48","51","Wave field synthesis (WFS) enables the accurate reproduction of a sound field for a large listening area with correct characteristics for each listener position. An exact perspective on the synthesized wave field is provided for every listener. Therefore, WFS-technology is ideally suited to be combined with augmented reality systems, where every user perceives his own visual perspective of a given scene. This work presents a concept for authoring and user interaction for the production of wave field synthesis content in an augmented reality system. Also, the implementation of a prototype WFS-AR system based on ARToolkit is explained.","","0-7695-2459-1","10.1109/ISMAR.2005.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544662","","Production systems;Augmented reality;User interfaces;Layout;Integral equations;Surface waves;Hardware;Workstations;Prototypes;Circuits","sound reproduction;audio user interfaces;augmented reality;authoring systems;visual perception;audio signal processing;signal synthesis;acoustic waves;acoustic field","user interaction;wave field synthesis content production;augmented reality system;sound field;visual perspective;ARToolkit;authoring systems","","5","","19","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"IoT Based Augmented Reality System of Human Heart: An Android Application","D. Agrawal; S. B. Mane; A. Pacharne; S. Tiwari","Department of Computer Engineering and IT, College of Engineering Pune, Pune, Maharashtra, India; Department of Computer Engineering and IT, College of Engineering Pune, Pune, Maharashtra, India; Department of Computer Engineering and IT, College of Engineering Pune, Pune, Maharashtra, India; Department of Computer Engineering and IT, College of Engineering Pune, Pune, Maharashtra, India","2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI)","2 Dec 2018","2018","","","899","902","Augmented Reality has been defined broadly as combining real and computer-generated digital information into the user's view of the physical and interactive real world in such a way that they appear as one environment, thus providing a bridge between digital information and the physical world. Augmented Reality can amplify human perception and cognition in remarkable new ways. Currently, during a cardiac examination, it becomes extremely difficult for the patient to comprehend the results. As the results are non-intuitive, doctors have a tough time explaining them to patients. Therefore, the patients have to rely on doctor's judgment against his own. The system proposed in this paper intends to make use of Augmented Reality (AR) technology for evaluation and visualization of a beating heart to make this doctor-patient interaction more intuitive. The system proposed in this paper is an android application which uses device's camera to display the 3D heart model in the augmented view. The real-time pulse data is loaded via a pulse sensor connected with an MCU through the cloud. Hence, the results obtained have shown us that this system has proven to bring more intuitiveness in beating heart visualization and analysis.","","978-1-5386-3570-4","10.1109/ICOEI.2018.8553807","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8553807","Augmented Reality;IoT;3D Model","Heart;Augmented reality;Animation;Three-dimensional displays;Solid modeling;Real-time systems;Conferences","augmented reality;cardiology;data visualisation;Internet of Things;medical computing;mobile computing;solid modelling","augmented reality system;Android application;augmented reality technology;beating heart visualization;beating heart analysis;IoT;augmented view;3D heart model;doctor-patient interaction;cardiac examination;cognition;human perception;interactive real world;physical world;computer-generated digital information;human heart","","5","","12","IEEE","2 Dec 2018","","","IEEE","IEEE Conferences"
"AR-View: An augmented reality device for digital reconstruction of Yuangmingyuan","Yetao Huang; Yue Liu; Yongtian Wang","Beijing Institute of Technology, China; Beijing Institute of Technology, China; Beijing Institute of Technology, China","2009 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media and Humanities","17 Nov 2009","2009","","","3","7","Yuanmingyuan was a vast and magnificent royal garden built continuously by several emperors of the Qing Dynasty. Unfortunately, it was looted and burnt down by the Anglo-French forces in 1860 and suffered from continual damages later on. Because of its special significance in the Chinese history, the reconstruction of Yuanmingyuan has been argued for a long time and visitors could only imagine its fabled charms. With the help of augmented reality (AR) technology, we have digitally reconstructed Yuanmingyuan by designing and manufacturing a fixed-position device AR-View to provide a combined real and virtual image of Dashuifa (Great waterworks), a symbol of Yuanmingyuan. With the help of AR-view, the original exquisite architectures and fountains are superimposed upon the current ruins. The key technologies of mechanical tracking for registration and dual-channel eyepieces for stereo display are discussed. To solve the problems exposed during public trials, improvements of software and hardware for public use are also illustrated in this paper. Ergonomics and industrial design are involved to ameliorate the functions and appearance of the latest version of AR-View, making it more stable and convenient for public use. As the first application of augmented reality technology on a Chinese historical site, AR-View opens the door to the practical use of augmented reality in the area of digital reconstruction of historical sites in China.","2381-8360","978-1-4244-5508-9","10.1109/ISMAR-AMH.2009.5336752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336752","Case studies;interactivity and interaction;social media and AR/MR;education and training","Augmented reality;Image reconstruction;History;Telescopes;Computer architecture;Computer interfaces;Computer vision;Springs;Local government;Navigation","augmented reality;image reconstruction;image registration;stereo image processing;three-dimensional displays","AR-View;augmented reality;digital reconstruction;Yuangmingyuan;image registration;dual-channel eyepieces;stereo display;ergonomics;industrial design","","5","1","5","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Markerless augmented reality for cubic panorama sequences","C. Warrington; G. Roth; E. Dubois","University of Ottawa, Canada; National Research Council; University of Ottawa, Canada","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","255","256","This paper presents a system for introducing augmented reality (AR) enhancements into an image-based cubic panorama sequence. Panoramic cameras, such as the Point Gray Research Ladybug allow rapid capture and generation of panoramic sequences for users to navigate and view. Our AR system provides the ability for authors to add virtual content into the panoramic sequences. First, a user manually selects a planar region over which to add the content. Then the system automatically finds a matching planar region in all the panoramas, allowing the virtual content to propagate. No preconditioning of the imaged scene through the addition of physical markers is necessary. Instead, 3-D position information is obtained by matching interest-point features across the panoramic sequence. This paper presents an application of augmented reality algorithms to the unique case of pre-captured panoramic sequences.","","1-4244-0650-1","10.1109/ISMAR.2006.297832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079294","","Augmented reality;Cameras;Navigation;Layout;Computer vision;Computer graphics;Councils;Application software;Chromium;Image processing","augmented reality;image enhancement;image matching;image sequences","augmented reality;image-based cubic panorama sequence;Point Gray Research Ladybug;virtual contents;3D position information","","3","","5","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Human Perception and Psychology in Augmented Reality (HPPAR) Summary","B. H. Thomas; G. F. Welch; J. Baumeister",University of South Australia; University of South Australia; University of South Australia,"2015 IEEE International Symposium on Mixed and Augmented Reality Workshops","3 Dec 2015","2015","","","3","3","Summary form only given. The main thrust of this half-day workshop is the development of the research agenda for human perception and psychology in augmented reality. With the convergence of historical advances in Augment Reality (AR) techniques with small and affordable technologies (e.g., sensors, displays, and input devices) we are on the threshold of AR becoming an effective tool for many applications and even everyday life. Traditional AR research has focused on creating technologies, algorithms, and techniques to achieve demonstrations that we evaluate with engineering benchmarks, such as performance of a tracking system, photorealism of the graphics, and human performance completing a task.","","978-1-4673-8471-1","10.1109/ISMARW.2015.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344746","","Augmented reality;Conferences;Psychology;Australia;Medical services","augmented reality;psychology;visual perception","human perception and psychology in augmented reality;HPPAR;research agenda","","2","","","IEEE","3 Dec 2015","","","IEEE","IEEE Conferences"
"Linear solutions for visual augmented reality registration","A. Ansar; K. Daniilidis","GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA","Proceedings IEEE and ACM International Symposium on Augmented Reality","6 Aug 2002","2001","","","183","184","Correct registration of virtual objects into real scenes requires robust estimation of camera pose. Since most augmented reality applications also require real-time performance in potentially restricted environments with no a priori motion model, we seek pose estimation algorithms which are fast, perform well with few reference objects and require no initialization. We present a pair of linear pose estimation algorithms for arbitrary point and line correspondences and demonstrate their suitability for augmented reality applications.","","0-7695-1375-1","10.1109/ISAR.2001.970533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=970533","","Augmented reality;Cameras;Equations;Linear systems;Chromium;Kernel;Layout;Motion estimation;Optical fiber networks;Geometrical optics","augmented reality;image registration","visual augmented reality registration;virtual objects;real scenes;robust estimation;camera pose;linear pose estimation algorithms;arbitrary point correspondences;arbitrary line correspondences;real-time performance;restricted environments;pose estimation algorithms","","","7","3","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Clash tanks: An investigation of virtual and augmented reality gaming experience","S. Ranade; M. Zhang; M. Al-Sada; J. Urbani; T. Nakajima","Department of Computer Science and Engineering, Waseda University, Tokyo, Japan; Department of Computer Science and Engineering, Waseda University, Tokyo, Japan; Department of Computer Science and Engineering, Waseda University, Tokyo, Japan; Department of Computer Science and Engineering, Waseda University, Tokyo, Japan; Department of Computer Science and Engineering, Waseda University, Tokyo, Japan","2017 Tenth International Conference on Mobile Computing and Ubiquitous Network (ICMU)","5 Apr 2018","2017","","","1","6","Despite the popularity of Virtual and Augmented Reality (AR/VR) within gaming, the full potential of Virtual and Augmented Reality technologies is yet to be investigated. Specifically, systems that combine both VR and AR within one cohesive user experience are largely uninvestigated, especially within game settings. Thus, we propose Clash Tanks, which is a game that is developed to investigate how VR and AR can coexist within one game environment. We present our approach's technical architecture to embody both VR and AR, related interaction methods and game mechanics. Our developed prototype is an immersive VR cockpit, containing various AR components and game elements, which is used to operate two real robots in various game modes. We carried a preliminary user study to investigate our approach's immersion and enjoyment aspects. Overall, participants favored our approach in terms of enjoyment, specifically citing that they felt immersed within the VR cockpit while controlling the robot. Participants also mentioned some shortcomings such as motion sickness and vision blurriness because of the head mounted display. Lastly, we present our future direction for our project.","","978-4-907626-31-0","10.23919/ICMU.2017.8330112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8330112","Mixed-Reality;Augmented Reality;Virtual Reality","Games;Resists;Task analysis;Augmented reality;Cameras;Robot vision systems","augmented reality;computer games;helmet mounted displays;mobile computing","Clash tanks;virtual reality gaming experience;augmented reality gaming experience;AR/VR;Augmented Reality technologies;cohesive user experience;game settings;Clash Tanks;game environment;related interaction methods;game mechanics;developed prototype;immersive VR cockpit;game elements;game modes;immersion;enjoyment aspects;motion sickness;vision bluriness;head mounted display","","3","","15","","5 Apr 2018","","","IEEE","IEEE Conferences"
"Dynamic compact visualizations for augmented reality","M. Tatzgern; D. Kalkofen; D. Schmalstieg","Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","3","6","In Augmented Reality (AR), careless augmentations can easily lead to information overflow. Especially on small screen devices, only a limited amount of information can be displayed comprehensively. Compact visualization filters data by reducing redundancies and creating a layout of the remaining information. Previously, this approach was applied to create static compact explosion diagrams. In this paper, we extend the approach to annotations, which are a major source of information in AR, and create compact layouts of annotations and annotated explosion diagrams. We present methods to transfer compact visualizations to dynamic AR settings and achieve interactive frame rates even on limited-resource hardware, such as mobile phones. Moreover, we create temporally coherent and scene-aware layouts.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549347","Augmented Reality;Visualization","Layout;Explosions;Data visualization;Optimization;Cameras;Augmented reality;Redundancy","augmented reality;data visualisation","dynamic compact visualizations;augmented reality;AR;information overflow;small screen devices;redundancy reduction;static compact explosion diagrams;annotated explosion diagrams;dynamic AR settings;interactive frame rates;limited-resource hardware;mobile phones;scene-aware layouts","","21","2","11","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"Simultaneous Localization and Mapping for Augmented Reality","G. Reitmayr; T. Langlotz; D. Wagner; A. Mulloni; G. Schall; D. Schmalstieg; Q. Pan","Graz University of Technology, Graz, Austria; Graz University of Technology, Graz, Austria; Graz University of Technology, Graz, Austria; Graz University of Technology, Graz, Austria; Graz University of Technology, Graz, Austria; Graz University of Technology, Graz, Austria; Graz University of Technology, Graz, Austria","2010 International Symposium on Ubiquitous Virtual Reality","26 Aug 2010","2010","","","5","8","Recently, the methods of Simultaneous Localization and Mapping (SLAM) have received great interest in the field of Augmented Reality. Accurate tracking in unknown and new environments promises to reduce the initial costs of building AR systems which often require extensive and accurate models of the environments, interaction objects and virtual annotations. However, it is still an open question how interesting and useful annotations can be created, attached and stored for unknown and arbitrary locations. In this paper, we discuss possible uses of SLAM in the different components of typical AR systems to provide meaningful applications and go beyond current limitations.","","978-1-4244-7702-9","10.1109/ISUVR.2010.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557942","Augmented Reality;Simultaneous localization and mapping;Tracking;Interaction;Panorama","Solid modeling;Simultaneous localization and mapping;Visualization;Cameras;Augmented reality;Three dimensional displays","augmented reality;SLAM (robots)","augmented reality;SLAM;simultaneous localization and mapping;virtual annotations;arbitrary locations","","20","3","12","IEEE","26 Aug 2010","","","IEEE","IEEE Conferences"
"ARtalet: Tangible User Interface Based Immersive Augmented Reality Authoring Tool for Digilog Book","T. Ha; W. Woo; Y. Lee; J. Lee; J. Ryu; H. Choi; K. Lee","GIST U VR Laboratory, South Korea; GIST U VR Laboratory, South Korea; MNU, South Korea; GIST HMCI Laboratory, South Korea; GIST HMCI Laboratory, South Korea; GIST IDEG Laboratory, South Korea; GIST IDEG Laboratory, South Korea","2010 International Symposium on Ubiquitous Virtual Reality","26 Aug 2010","2010","","","40","43","A Digilog Book is an augmented reality (AR) based next generation publication supporting both sentimental analog emotions and immersive digital contents to improve a user's experience. This paper enhances the Digilog Book authoring tool, ARtalet. This is a tangible user interface based immersive AR authoring tool providing an intuitive non-programming based authoring methods using a 3D user interface in an AR environment. As novel authoring functions, we propose 3D object trajectory manipulation, real-time deformation, and audio/vibration feedback authoring functions to enhance a user's experience and interest. The ARtalet can be applicable to other Digilog application authoring, including posters, pictures, newspapers, and sign boards.","","978-1-4244-7702-9","10.1109/ISUVR.2010.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557935","component;Augmented Reality;Authoring Tool;3D Object Trajectory Manipulation;Real-time 3D Object Deformation;Multisensory Feedback;Tangible User Interface","Three dimensional displays;Books;Trajectory;Vibrations;Haptic interfaces;Augmented reality;Cameras","augmented reality;authoring systems;electronic publishing;real-time systems;user interfaces","ARtalet;tangible user interface;immersive augmented reality authoring tool;next generation publication;sentimental analog emotions;immersive digital contents;digilog book authoring tool;intuitive nonprogramming based authoring methods;3D user interface;3D object trajectory manipulation;real-time deformation;audio/vibration feedback authoring functions","","18","1","20","IEEE","26 Aug 2010","","","IEEE","IEEE Conferences"
"Discovering educational augmented reality math applications by prototyping with elementary-school teachers","I. Radu; B. McCarthy; Y. Kao",Georgia Institute of Technology; WestEd; WestEd,"2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","271","272","In recent years, augmented reality (AR) applications for children's entertainment have been gaining popularity, and educational organizations are increasingly interested in applying this technology to children's educational games. In this paper we describe our collaboration with teachers and game designers, in order to explore educational potential for AR technology. This paper specifically investigates the topics of: What mathematics curriculum topics should technological innovations address in the Grade 1-3 classrooms? Which of the topics are suitable for AR games? And, how can we facilitate an efficient dialogue between educators and game designers?","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504758","Augmented Reality;Prototyping;Mathematics;Elementary Classroom;Pedagogy;Teachers","Prototypes;Augmented reality;Games;Mathematics;Education;Standards;Organizations","augmented reality;computer aided instruction;computer games;mathematics computing;teaching","educational game;elementary school teacher;mathematics curriculum;educational AR;educational augmented reality","","18","","6","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Joystick mapped Augmented Reality Cues for End-Effector controlled Tele-operated Robots","A. Nawab; K. Chintamani; D. Ellis; G. Auner; A. Pandya","Mobile Intelligence Corporation, Livonia, MI, USA; Electrical and Computer Engineering Department, Wayne State University, USA; Industrial Engineering Department, Wayne State University, USA; Electrical and Computer Engineering Department, Wayne State University, USA; Electrical and Computer Engineering Department, Wayne State University, USA","2007 IEEE Virtual Reality Conference","23 Apr 2007","2007","","","263","266","End-effector control of robots using just remote camera views is difficult due to lack of perceived correspondence between the joysticks and the end-effector coordinate frame. This paper reports the positive effects of augmented reality visual cues on operator performance during end-effector controlled tele-operation using only camera views. Our solution is to overlay a color-coded coordinate system on the end-effector of the robot using AR techniques. This mapped and color-coded coordinate system is then directly mapped to similarly color-coded joysticks used for control of both position and orientation. The AR view along with mapped markings on the joystick give the user a clear notion of the effect of their joystick movements on the end-effector of the robot. All camera views display this registered dynamic overlay information on-demand. An insertion task was used to compare performance with and without the coordinate mapping using fifteen subjects. Preliminary results indicate a significant reduction in distance and reversal errors","2375-5334","1-4244-0905-5","10.1109/VR.2007.352496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161038","Robotics;Augmented Reality;Tele-operations;Kinematics;Performance Testing","Augmented reality;Robot control;Cameras;Robot kinematics;Robot vision systems;Software testing;Intelligent robots;Displays;Human factors;Navigation","augmented reality;end effectors;manipulator kinematics;telerobotics","joystick mapped augmented reality;tele-operated robots;robot end-effector control","","16","","12","IEEE","23 Apr 2007","","","IEEE","IEEE Conferences"
"Augmented Reality System for Aiding Mild Alzheimer Patients and Caregivers","K. M. Kanno; E. A. Lamounier; A. Cardoso; E. J. Lopes; G. F. Mendes de Lima",Federal University of Uberlândia; Federal University of Uberlândia; Federal University of Uberlândia; Federal University of Uberlândia; Federal University of Uberlândia,"2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","593","594","Alzheimer's Disease (AD) has become ever more prominent within the area of healthcare. Studies show that it is the most common cause of dementia in older adults. In addition, a large percentage of patients and their caregivers still face enormous challenges concerning treatment and the performing of everyday tasks. Forgetfulness and location awareness are recurrent symptoms. On the other hand, smartphones have become a more common feature of their daily lives. Therefore, this paper presents a mobile application to help individuals diagnosed in the early stages of Alzheimer's Disease to identify objects and people. In addition, it can track the location of an AD individual, since they frequently become disoriented and lost. The application presented herein proposes an accessible interface, based on Augmented Reality techniques that uses speech commands for different features: time reminders for taking medicine, identification of which medicine to be taken, people recognition from photos, among others. In addition tests revealed a promising interface using voice recognition and a feasibility of locating individuals using the caregiver's mobile application.","","978-1-5386-3365-6","10.1109/VR.2018.8446143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446143","Alzheimer's Disease;Mobile Technology;Augmented Reality Interface;Assistive Technology;K.6.1 [Management of Computing and Information Systems]: Project and People Management-Life Cycle;K.7.m [The Computing Profession]: Miscellaneous-Ethics","Augmented reality;Alzheimer's disease;Speech recognition;Assistive technology;Task analysis","augmented reality;diseases;health care;medical information systems;mobile computing;patient monitoring;smart phones;speech recognition","people recognition;caregivers;recurrent symptoms;mobile application;medicine;augmented reality system;Alzheimer patients;Alzheimers disease;healthcare;dementia;smartphones;speech commands;voice recognition","","11","","6","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Teach Me a Story: an Augmented Reality Application for Teaching History in Middle School","B. Schiavi; F. Gechter; C. Gechter; A. Rizzo","University of Technology of Belfort-Montbeliard, Belfort, Cedex, France; University of Technology of Belfort-Montbeliard, Belfort, Cedex, France; College Simone Signoret/ Lycée Condorcet, Belfort, France; Institute for Creative Technologies, University of Southern California","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","679","680","Augmented Reality (AR) is now more and more widespread in many application fields. Thanks to the new progresses in computer power, AR can now be used widely in education without any expensive additional devices. In this paper is presented the feedback of an experimental protocol using an AR application as an additional support for a History lesson in secondary schools. Even if the technical part has a lead role in the student experience, the most challenging issue is related to the choice of the teaching lesson as itself which must fit several, sometimes contradictory, requirements.","","978-1-5386-3365-6","10.1109/VR.2018.8446412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446412","Augmented Reality;Pedagogical application;History;Human-centered computing [Human computer interaction (HCI)];HCI design and evaluation methods-User studies","Education;Augmented reality;Three-dimensional displays;History;Protocols;Urban areas;Electronic mail","augmented reality;computer aided instruction;educational institutions;history;teaching","story;middle school;experimental protocol;AR application;secondary schools;teaching lesson;augmented reality application;teaching history;history lesson","","10","","6","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"A Comparison of Desktop and Augmented Reality Scenario Based Training Authoring Tools","A. N. V. González; K. Kapalo; S. Koh; R. Sottilare; P. Garrity; J. J. Laviola",University of Central Florida; University of Central Florida; Army Research Laboratory; University of Central Florida; University of Central Florida; University of Central Florida,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1199","1200","This work presents a comparison of two applications (Augmented Reality (AR) and desktop) to author Scenario-Based Training (SBT) simulations. Through an iterative design process two interface conditions are developed and then evaluated qualitatively and quantitatively. A graph based authoring visualization help designers understand the scenario learning artifacts and relationships. No significant difference was found on time taken to complete tasks nor on the perceived usability of the systems. However, Desktop was perceived as more efficient, corroborated by the significantly higher number of mistakes made in AR. Findings are presented towards building better AR immersive authoring tools.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797973","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797973","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Computing methodologies;Modeling and simulation;Simulation support systems;Simulation environments","Task analysis;Tools;Augmented reality;Training;Authoring systems;Visualization;Solid modeling","augmented reality;computer based training;user interfaces","desktop;scenario learning artifacts;AR immersive authoring tools;augmented reality;iterative design process;training authoring tools;scenario-based training simulations;interface conditions;graph based authoring visualization","","10","","8","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Prioritization and static error compensation for multi-camera collaborative tracking in augmented reality","J. Wang; L. Qian; E. Azimi; P. Kazanzides","Shanghai Jiao Tong Univ., China; Johns Hopkins University, Baltimore, MD, US; Johns Hopkins University, Baltimore, MD, US; Shanghai Jiao Tong Univ., China","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","335","336","An effective and simple method is proposed for multi-camera collaborative tracking, based on the prioritization of all tracking units, and then modeling the discrepancy between different tracking units as a locally static transformation error. Static error compensation is applied to the lower-priority tracking systems when high-priority trackers are not available. The method does not require high-end or carefully calibrated tracking units, and is able to effectively provide a comfortable augmented reality experience for users. A pilot study demonstrates the validity of the proposed method.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892313","Augmented reality;multi-camera tracking","Cameras;Augmented reality;Trajectory;Error compensation;Target tracking;Calibration","augmented reality;cameras;error compensation","static error compensation;multicamera collaborative tracking;locally static transformation error;augmented reality","","8","","4","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Embodying an Extra Virtual Body in Augmented Reality","N. Rosa; J. -P. van Bommel; W. Hürst; T. Nijboer; R. C. Veltkamp; P. Werkhoven","Universiteit Utrecht, Utrecht, Utrecht, NL; Universiteit Utrecht, Utrecht, Utrecht, NL; Universiteit Utrecht, Utrecht, Utrecht, NL; Universiteit Utrecht, Utrecht, Utrecht, NL; Universiteit Utrecht, Utrecht, Utrecht, NL; Universiteit Utrecht, Utrecht, Utrecht, NL","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1138","1139","Presence and the sense of embodiment are essential concepts for the experience of our self and virtual bodies, but there is little quantitative evidence for a relation between these, and this relation becomes more complicated when there are real and virtual bodies in augmented reality (AR). We investigate the experience of body ownership, agency, self-location and self-presence in AR where users can see their real body and a virtual body from behind. Active arm movement congruency and virtual anthropomorphism are varied. We found significant effects of movement congruency but not anthropomorphism, a strong correlation between self-presence and body ownership, and a moderate correlation between self-presence and agency and self-location.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798055","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed/augmented reality;Empirical studies in HCI","Anthropomorphism;Avatars;Augmented reality;Correlation;Conferences;Cameras","augmented reality","augmented reality;virtual bodies;quantitative evidence;body ownership;active arm movement congruency;virtual anthropomorphism;virtual body;AR","","8","","10","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Exploring Cultural Heritage in Augmented Reality with GoFind!","L. Sauter; L. Rossetto; H. Schuldt","Department of Mathematics and Computer Science, University of Basel, Switzerland; Department of Mathematics and Computer Science, University of Basel, Switzerland; Department of Mathematics and Computer Science, University of Basel, Switzerland","2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","17 Jan 2019","2018","","","187","188","Historic photo collections are important instruments to document the development of cityscapes in the course of time. However, in most cases, such historic photos are buried in archives that are not easily accessible. But even when cultural heritage archives are opened and exposed to the public, for instance by specialized digital libraries, the value of the individual images is limited as they can only be used in the context of the digital library's retrieval engine and independent of the actual location that is being displayed. With GoFind!, we bring the retrieval engine of historic multimedia collections to mobile devices. The system provides location-based querying in historic multimedia collections and adds an augmented reality-based user interface that enables the overlay of historic images and the current view. GoFind! can be used by historians and tourists and provides a virtual view into the past of a city.","","978-1-5386-9269-1","10.1109/AIVR.2018.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613660","Cultural Heritage;Multimedia Retrieval;Augmented Reality","Augmented reality;Urban areas;Mobile handsets;Cultural differences;Engines;Multimedia systems;User interfaces","augmented reality;digital libraries;history;location based services;mobile computing;multimedia computing;query processing;user interfaces","GoFind;historic photo collections;cultural heritage archives;retrieval engine;historic multimedia collections;augmented reality-based user interface;digital libraries;historic images overlay;location-based query;mobile devices;cityscapes","","8","1","8","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Barcode-Assisted Planar Object Tracking Method for Mobile Augmented Reality","N. Park; W. Lee; W. Woo","GIST U VR Laboratory, Gwangju, South Korea; GIST U VR Laboratory, Gwangju, South Korea; GIST U VR Laboratory, Gwangju, South Korea","2011 International Symposium on Ubiquitous Virtual Reality","3 Nov 2011","2011","","","40","43","In this paper, we propose a planar target tracking method that exploits a barcode containing information about a target. Our method combines both barcode detection and natural feature tracking methods to track a planar object efficiently on mobile devices. A planar target is detected by recognizing the barcode located near the target, and the target's keypoints are tracked in video sequences. We embed the information related to a planar object into the barcode, and the information is used to limit image regions to perform keypoint matching between consecutive frames. We show how to detect a barcode robustly and what information is embedded for efficient tracking. Our detection method runs at 30 fps on modern mobile devices, and it can be used for mobile augmented reality applications using planar targets.","","978-1-4577-0356-0","10.1109/ISUVR.2011.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6068303","QRCode Detection;QRCode Tracking;Planar Object Tracking;Augmented Reality;2D Barcode Tracking","Target tracking;Augmented reality;Mobile communication;Vectors;Cameras;Mobile handsets;Robustness","augmented reality;bar codes;feature extraction;image matching;image sequences;mobile computing;object detection;target tracking","planar target tracking;barcode detection;natural feature tracking;object detection;mobile augmented reality;mobile devices;video sequences;image regions;keypoint matching;consecutive image frames","","7","5","8","IEEE","3 Nov 2011","","","IEEE","IEEE Conferences"
"On Visual Artifacts of Physics Simulation in Augmented Reality Environment","S. Kim; Y. Kim; S. -H. Lee","School of Information and Communications, Gwangju Institute of Science and Technology, Gwangju, South Korea; School of Information and Communications, Gwangju Institute of Science and Technology, Gwangju, South Korea; School of Information and Communications, Gwangju Institute of Science and Technology, Gwangju, South Korea","2011 International Symposium on Ubiquitous Virtual Reality","3 Nov 2011","2011","","","25","28","Due to the incomparable ability to increase realism in synthesizing the motion of virtual objects, physics simulation is increasingly adopted in augmented reality (AR) applications. In this paper, we show with experiments that, if physics simulation is naively employed in AR applications, visual artifacts diminishing the realism of a scene may occur when real and virtual objects collide. This is due to the intrinsic limitation of AR in that virtual objects cannot apply forces to the real objects. We discuss possible methods to alleviate this artifacts.","","978-1-4577-0356-0","10.1109/ISUVR.2011.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6068299","augmented reality;physics simulation;physics engine;collision avoidance","Physics;Computational modeling;Solid modeling;Visualization;Augmented reality;Sports equipment","augmented reality;collision avoidance;image motion analysis","virtual objects;physics simulation;augmented reality;visual artifacts","","5","","10","IEEE","3 Nov 2011","","","IEEE","IEEE Conferences"
"Ground Camera Images and UAV 3D Model Registration for Outdoor Augmented Reality","W. Liu; C. Wang; Y. Zang; S. -H. Lai; D. Weng; X. Bian; X. Lin; X. Shen; J. Li","Xiamen University, Xiamen, Fujian, CN; Xiamen University, Xiamen, Fujian, CN; Xiamen University, Xiamen, Fujian, CN; National Tsing Hua University, Hsinchu, TW; Beijing Institute of Technology, Beijing, Beijing, CN; Xiamen University, Xiamen, Fujian, CN; Xiamen University, Xiamen, Fujian, CN; Xiamen University, Xiamen, Fujian, CN; University of Waterloo, Waterloo, ON, CA","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1050","1051","This paper presents a novel virtual-real registration approach for augmented reality (AR) in large-scale outdoor environments. Essentially, it is a pose estimation for the mobile camera images (ground camera images) in 3D model recovered by Unmanned Aerial Vehicle (UAV) image sequence via Structure-From-Motion (SFM) technology. The approach considers to indirectly establish the spatial relationship between 2D and 3D space by inferring the transformation relationship between the ground camera images and the UAV 3D model rendered images. Specifically, the proposed approach can overcome the positioning errors, which are deterioration and drift in the GPS, and deviation of orientation. The experimental results demonstrate the possibility of the proposed virtual-real registration approach, and show that the approach is robust, efficient and intuitive for AR in large-scale outdoor environments.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797821","Virtual-real registration;outdoor AR;cross-domain image matching;Human-centered computing;Visualization;Visualization techniques;Augmented reality","Solid modeling;Three-dimensional displays;Cameras;Unmanned aerial vehicles;Mobile handsets;Global Positioning System;Augmented reality","augmented reality;autonomous aerial vehicles;cameras;control engineering computing;image registration;image sequences;pose estimation;remotely operated vehicles;rendering (computer graphics);solid modelling","unmanned aerial vehicle image sequence;virtual-real registration approach;structure-from-motion technology;SFM technology;mobile camera images;outdoor augmented reality;UAV 3D model registration;ground camera images;large-scale outdoor environments","","5","","3","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"ARBlocks: A projective augmented reality platform for educational activities","R. A. Roberto; V. Teichrieb","Voxar Laboratories, Informatics Center, Federal University of Pernambuco (UFPE), Brazil; Voxar Laboratories, Informatics Center, Federal University of Pernambuco (UFPE), Brazil","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","175","176","This demonstration will allow visitors to use different applications builded for the ARBlocks, a dynamic blocks platform based on projective augmented reality and tangible user interfaces aiming early childhood educational activities. Those applications, along with the platform itself, were designed to be useful tools for educators to teach general subjects for children, such as mathematical and language skills, as well as develop important abilities, like motor coordination and collaboration.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180937","augmented reality;education;tangible user interface","Augmented reality;Education;Laboratories;Data visualization;Games","augmented reality;computer aided instruction;teaching;user interfaces","ARBlocks;projective augmented reality platform;dynamic blocks platform;tangible user interfaces;early childhood educational activities;general subject teaching;mathematical skills;language skills;motor coordination;motor collaboration","","5","","6","IEEE","12 Apr 2012","","","IEEE","IEEE Conferences"
"Decoupled mapping and localization for Augmented Reality on a mobile phone","P. Martin; E. Marchand; P. Houlier; I. Marchal","Orange – IRISA, Inria; Université de Rennes 1, Inria; Orange; Orange","2014 IEEE Virtual Reality (VR)","24 Apr 2014","2014","","","97","98","Using Simultaneous Localization And Mapping (SLAM) methods become more and more common in Augmented Reality (AR). To achieve real-time requirement and to cope with scale factor and the lack of absolute positioning issue, we propose to decouple the localization and the mapping step. We explain the benefits of this approach and how a SLAM strategy can still be used in a way that is meaningful for the end user.","2375-5334","978-1-4799-2871-2","10.1109/VR.2014.6802069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802069","Augmented reality;simultaneous location and mapping;mobile phone","Simultaneous localization and mapping;Augmented reality;Mobile handsets;Cameras;Real-time systems;Three-dimensional displays;Optimization","augmented reality;mobile computing;mobile handsets;real-time systems;robot vision;SLAM (robots)","decoupled mapping and localization;augmented reality;mobile phone;simultaneous localization and mapping method;SLAM method;real-time requirement;scale factor;absolute positioning;SLAM strategy","","4","1","5","IEEE","24 Apr 2014","","","IEEE","IEEE Conferences"
"Real-Time Augmented Reality with Occlusion Handling Based on RGBD Images","X. Guo; C. Wang; Y. Qi","Beihang University Qingdao Research Institute, Qingdao, China; Beihang University Qingdao Research Institute, Qingdao, China; Beihang University Qingdao Research Institute, Qingdao, China","2017 International Conference on Virtual Reality and Visualization (ICVRV)","23 May 2019","2017","","","298","302","Augmented Reality (AR) is one of the latest developments in human-computer interaction technology. It aims to generate illusions from seamless fusion of virtual objects and real world. Typical AR system requires two basic parts: three-dimensional registration and real-virtual fusion. Occlusion handling is crucial for visual realism. To optimize visual realism, we generated a real-time systematic architecture to operate occlusion handling. The architecture is based on RGBD images, and it consists of three parts: real-time camera tracking system, 3D reconstruction system and AR fusion system. Specifically, we used a two-pass scheme strategy to execute the AR system. The first pass tracks camera poses timely at video rate, which allows the reconstruction results be updated and visualized correspondingly during the scanning. The second pass takes place simultaneously to handle occlusion between virtual objects and real scene according to camera pose. Finally, the render results of virtual objects and the color images are fused to generate AR contents. Our results indicate that this method is stable and precise for occlusion handling, and can effectively improve realism in AR system.","2375-141X","978-1-5386-2636-8","10.1109/ICVRV.2017.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719144","augmented reality;occlusion handling;scene reconstruction;rgbd","Cameras;Image reconstruction;Three-dimensional displays;Real-time systems;Augmented reality;Color;Rendering (computer graphics)","augmented reality;cameras;computer graphics;image colour analysis;image reconstruction;image registration;object tracking;pose estimation;rendering (computer graphics)","augmented Reality;occlusion handling;RGBD images;human-computer interaction technology;seamless fusion;virtual objects;three-dimensional registration;real-virtual fusion;visual realism;real-time systematic architecture;real-time camera;3D reconstruction system;fusion system;AR system;two-pass scheme strategy;camera pose tracking;video rate","","4","","16","IEEE","23 May 2019","","","IEEE","IEEE Conferences"
"An Educational Augmented Reality Application for Elementary School Students Focusing on the Human Skeletal System","M. E. Kouzi; A. Mao; D. Zambrano",Carleton University; Carleton University; Carleton University,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1594","1599","Augmented Reality (AR) as a new field regarding Human Computing Interaction (HCI) has been gaining momentum in the last few years. Being able to project interactive graphics into real-life environments can be applied in various fields, research and commercial goals. In the field of education, textbooks are still considered to be the primary tool used by students to learn about new topics. Since AR requires interaction and exploration, it brings a ludic component that is hard to replicate using regular textbooks. The application we developed allows elementary school students to interact with a fully three-dimensional human skeleton model, using specialized virtual buttons. Students can understand this complex structure and learn the names of important bones just by using a tablet, a picture and their hands. Results show that the majority of students consider that our AR application helped them visualize and learn more about the human skeletal system. Additionally, the data we gathered shows that there was a 16% increase in correct responses regarding bone names after using our AR application. Our AR application successfully helped the students learn about the human skeletal system by introducing them to AR technologies.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798058","Augmented Reality;Human Computer Interaction (HCI);Education;Elementary School;Skeleton System;3D object","Three-dimensional displays;Bones;Solid modeling;Games;Augmented reality;Education;Visualization","augmented reality;biology computing;computer aided instruction;human computer interaction","educational augmented reality application;elementary school students;human skeletal system;interactive graphics;commercial goals;three-dimensional human skeleton model;AR application;human computing interaction;specialized virtual buttons;AR technologies","","4","","11","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Influence analysis of visual stimuli on localization of tactile stimuli in augmented reality","A. Niijima; T. Ogawa","Graduate School of Engineering, University of Tokyo, Japan; Information Technology Center, University of Tokyo, Japan","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","105","106","In augmented reality (AR) environment, tactile stimuli as if a user touched virtual objects are important for realizing natural interactions. Most previous works employ tactile devices such as vibration actuators. However, the place where the system can stimulate a user depends on the place which is covered by the devices. In addition the accuracy of user's tactile perception is low, so it is difficult to present tactile feedback at intended locations. The purpose of this study is to establish a method that represents smooth two-dimensional tactile moving strokes independent of locations of the tactile devices. Our aim is to let a user perceive that locations of vibrotactile perception are on those of visual stimuli. Thus we can present tactile feedback in larger places with higher resolution by controlling visual stimuli. In this paper we have investigated the correlation between visual stimuli and tactile perception. The results of experiments showed that visual stimuli can induce tactile illusion, which resembles the position of virtual objects.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180904","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180904","H.5.1 [Information Systems]: Multimedia Information Systems — Artificial;augmented and virtual realities;H.5.2 [Information Systems]: User Interfaces — Haptic I/O","Visualization;Phantoms;Augmented reality;Actuators;Vibrations;Tactile sensors;Educational institutions","actuators;augmented reality;haptic interfaces;tactile sensors;touch (physiological);visual perception","influence analysis;visual stimuli;localization;tactile stimuli;augmented reality;AR environment;user touched virtual objects;natural interactions;tactile devices;vibration actuators;user tactile perception;tactile feedback;two-dimensional tactile moving strokes;vibrotactile perception;tactile illusion","","3","","7","IEEE","12 Apr 2012","","","IEEE","IEEE Conferences"
"Global illumination for Augmented Reality on mobile phones","M. Csongei; L. Hoang; C. Sandor; Y. B. Lee","University of South Australia, Adelaide, SA, AU; Magic Vision Lab, University of South Australia; Magic Vision Lab, University of South Australia; Samsung Advanced Institute of Technology, Samsung","2014 IEEE Virtual Reality (VR)","24 Apr 2014","2014","","","69","70","The goal of our work is to create highly realistic graphics for Augmented Reality on mobile phones. One of the greatest challenges for this is to provide realistic lighting of the virtual objects that matches the real world lighting. This becomes even more difficult with the limited capabilities of mobile phone GPUs. Our approach differs in the following important aspects compared to previous attempts: (1) most have relied on rasterizer approaches, while our approach is based on raytracing; (2) we perform distributed rendering in order to address the limited mobile GPU capabilities; (3) we use image-based lighting from a pre-captured panorama to incorporate real world lighting. We utilize two markers: one for object tracking and one for registering the panorama. Our initial results are encouraging, as the visual quality resembles real objects and also the reference renderings which were created offline. However, we still need to validate our approach in human subject studies, especially with regards to the trade-off between latency of remote rendering and visual quality.","2375-5334","978-1-4799-2871-2","10.1109/VR.2014.6802055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802055","H.5.1. [Information Interfaces and Presentation]: Multimedia Information Systems — [Artificial, augmented and virtual realities];H.1.2. [Information Systems]: Models and Principles — [Human factors];I.3.2. [Computer Graphics]: Graphics Systems — [Distributed/Networked Graphics]","Rendering (computer graphics);Lighting;Mobile handsets;Visualization;Augmented reality;Prototypes;Image color analysis","augmented reality;mobile computing;rendering (computer graphics)","global illumination;augmented reality;mobile phones;highly realistic graphics;virtual objects;real world lighting;GPU;distributed rendering;image-based lighting","","3","","11","IEEE","24 Apr 2014","","","IEEE","IEEE Conferences"
"Augmented reality system for overlaying a scene in a video onto real world and reliving the camera operator's experience","T. Arakawa; K. Kasada; T. Narumi; T. Tanikawa; M. Hirose","Graduate School of Information Science and Technology, University of Tokyo, Bunkyo, Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Bunkyo, Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Bunkyo, Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Bunkyo, Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Bunkyo, Tokyo, Japan","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","139","140","This paper reports a reliving video experience system using augmented reality techniques. This system overlays a scene from video material onto the real world and allows users to experience how the camera operator captured the scene by inducing them to move as in the same way as the camera operator did. We propose novel interaction techniques that balance the competing goals of inducing users to move in the same way as the camera operator and allowing them to feel that they are observing freely. The proposed methods implement three induction techniques to induce the user to avoid unintentional movements, and to start moving the device and rotate it appropriately. We implemented this system in an exhibition system that relives the video of old railways and exhibited it at the railway museum for two weeks. The analysis results of users' operational logs and questionnaires suggest that the proposed system and interaction techniques are effective for reliving video experiences in the real world.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549401","augmented reality;digital museum;image connection;mobile device;user interface","Cameras;Augmented reality;Rail transportation;Video sequences;Educational institutions;Visualization;Object recognition","augmented reality;cameras;exhibitions;museums;railways;video signal processing","augmented reality system;scene overlaying;video material;real world;camera operator experience;video experience system;interaction techniques;induction techniques;exhibition system;old railway video;railway museum;time 2 week","","2","","3","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"Third-Person Perspective Avatar Embodiment in Augmented Reality: Examining the Proteus Effect on Physical Performance","R. Otono; N. Isoyama; H. Uchiyama; K. Kiyokawa","NAIST, Japan; NAIST, Japan; NAIST, Japan; NAIST, Japan","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","730","731","Embodiment in augmented reality (AR) is applicable to various fields such as exercise and education. However, full-body embodiment in AR is still challenging to implement due to technical problems such as low body tracking accuracy. Therefore, the study on the impact of an avatar in AR on user performance is limited. We implemented an AR embodiment system and investigated its impact on user physical performance. The system allows users to see their avatar instead of their real body from a third-person perspective. The results show that a muscular avatar improves user physical performance during and after controlling the avatar.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757438","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed/augmented reality;Human-centered computing—Human computer interaction (HCI)—Empirical studies in HCI","Human computer interaction;Three-dimensional displays;Avatars;Conferences;Education;Augmented reality","augmented reality;avatars","person perspective avatar embodiment;augmented reality;proteus effect;education;full-body embodiment;low body tracking accuracy;user performance;AR embodiment system;user physical performance;third-person perspective;muscular avatar","","2","","6","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"E-Book Browsing Method by Augmented Reality Considering Paper Shape","T. Yamamoto; H. Aida; D. Yamashita; Y. Honda; M. Miki","Department of Science and Engineering, Doshisha University, Kyoto, Japan; Graduate School of Science and Engineering, Doshisha University, Kyoto, Japan; Department of Science and Engineering, Doshisha University, Kyoto, Japan; Department of Science and Engineering, Doshisha University, Kyoto, Japan; Graduate School of Science and Engineering, Doshisha University, Kyoto, Japan","2017 International Symposium on Ubiquitous Virtual Reality (ISUVR)","24 Jul 2017","2017","","","30","33","E-books have an advantage over printed books in that they allow users to read multiple books on a device such as a tablet or a smartphone. However, e-books also have drawbacks, such as the lack of book weight and of paper-like texture. This study proposes a method in which a user can read while experiencing the tactile sensations of book weight and paper feel through the superimposed display of an e-book page on paper space using augmented reality. Book pages deform to various shapes depending on the way a book is held. If an e-book is superimposed and displayed without adapting to changes in the paper space, differences in visual and tactile information are created and cause discomfort to the user. Therefore, in this study, a proposed method was applied that estimates the curvature of a book and applies a correction to the projection, and the accuracy of the corrections was measured. The effectiveness of the method was verified with respect to the usability of the proposed system through an experiment with test subjects.","","978-1-5386-3091-4","10.1109/ISUVR.2017.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988649","Augmented Reality;E-book;Printed book;Curvature estimation","Electronic publishing;Cameras;Shape;Resists;Augmented reality;Estimation;Visualization","augmented reality;electronic publishing;haptic interfaces;human computer interaction","e-book browsing method;paper shape;augmented reality;usability;tactile sensations;book weight;paper feel","","1","","3","IEEE","24 Jul 2017","","","IEEE","IEEE Conferences"
"[DC] Context-Aware Inference and Adaptation in Augmented Reality","S. Davari","Center for Human-Computer Interaction and Department of Computer Science, Virginia Tech, USA","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","938","939","Augmented Reality(AR) offers the potential for easy and efficient information access, reinforcing the wide belief that AR Glasses are the next-generation of personal computing devices. However, to realize this all-day AR vision, the AR interface must be able to address the challenges that constant and pervasive presence of virtual content can cause for the user. The optimal interface, that is the most efficient yet least intrusive, in one context may be the worst interface for another context. Throughout the day, as the user switches context, an optimal all-day interface must adapts its virtual content display and interactions as well. This work aims to propose a research agenda to design and validate different adaptation techniques and context-aware AR interfaces and introduce a framework for the design of such intelligent interfaces.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757487","Human-centered computing—Mixed / augmented reality;Human-centered computing—Interaction techniques;Human-centered computing—Empirical Studies in HCI","Human computer interaction;Three-dimensional displays;Conferences;Glass;Next generation networking;Augmented reality","augmented reality;inference mechanisms;ubiquitous computing","AR glasses;computing devices;optimal interface;virtual content display;context-aware AR interfaces;intelligent interfaces;information access;augmented reality","","1","","7","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Anchoring 2D gesture annotations in augmented reality","B. Nuernberger; K. -C. Lien; T. Höllerer; M. Turk","University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara","2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","247","248","Augmented reality enhanced collaboration systems often allow users to draw 2D gesture annotations onto video feeds to help collaborators to complete physical tasks. This works well for static cameras, but for movable cameras, perspective effects cause problems when trying to render 2D annotations from a new viewpoint in 3D. In this paper, we present a new approach towards solving this problem by using gesture enhanced annotations. By first classifying which type of gesture the user drew, we show that it is possible to render annotations in 3D in a way that conforms more to the original intention of the user than with traditional methods. We first determined a generic vocabulary of important 2D gestures for remote collaboration by running an Amazon Mechanical Turk study with 88 participants. Next, we designed a novel system to automatically handle the top two 2D gesture annotations - arrows and circles. Arrows are handled by identifying their anchor points and using surface normals for better perspective rendering. For circles, we designed a novel energy function to help infer the object of interest using both 2D image cues and 3D geometric cues. Results indicate that our approach outperforms previous methods in terms of better conveying the original drawing's meaning from different viewpoints.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504746","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces and Presentation]: User Interfaces — Interaction styles","Three-dimensional displays;Augmented reality;Collaboration;Cameras;Head;Printers;Rendering (computer graphics)","augmented reality;computational geometry;gesture recognition;image sensors;rendering (computer graphics)","2D gesture annotations;augmented reality;collaboration systems;static cameras;movable cameras;perspective effects;generic vocabulary;Amazon mechanical turk;anchor points;surface normals;rendering;energy function;2D image cues;3D geometric cues","","1","","7","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Casting shadows: Ecological interface design for augmented reality pedestrian collision warning","H. Kim; J. D. Isleib; J. L. Gabbard","Industrial and Systems Engineering, Virginia Tech; Industrial and Systems Engineering, Virginia Tech; Industrial and Systems Engineering, Virginia Tech","2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","205","206","Ecological interface design (EID) has the opportunity to complement current approaches for augmented reality (AR) interface design by considering human-environment interaction and leveraging the inherent benefit of AR interfaces: conformal graphics. This work applies EID to design a novel interface for pedestrian collision warning for an automotive AR head-up display (HUD). Our initial usability evaluation shows potential benefits of incorporating EID into AR interface design.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504725","Augmented reality;ecological interface design;driving","Vehicles;Usability;Roads;Augmented reality;Human computer interaction;Information processing","augmented reality;ecology;ergonomics;head-up displays;pedestrians;user interfaces","ecological interface design;augmented reality pedestrian collision warning;human-environment interaction;conformal graphics;EID;automotive AR head-up display;HUD;usability evaluation;AR interface design","","1","","7","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Augmented Reality Interfaces for Semi-Autonomous Drones","C. Hutton",IIIusioneering Lab University of Minnesota,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1361","1362","With recent advances in hardware technology, drones are increasingly present in research activities outside of robotics, performing a multitude of tasks such as image capture and sample collection. However, user interfaces for task-oriented drones have not kept pace with hardware breakthroughs. Current planning and control interfaces for drones are not intuitive and often place a large cognitive burden on those who are not highly trained in their use. This paper proposes a course of research that seeks to leverage natural user interfaces in augmented reality (AR) for controlling drones completing task-oriented objectives.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797893","Human-centered computing;Mixed/augmented reality;Visualization techniques;Treemaps;Visualization;Visualization design and evaluation methods","Drones;Task analysis;User interfaces;Robots;Augmented reality;Planning","augmented reality;autonomous aerial vehicles;control engineering computing;mobile robots;user interfaces","augmented reality interfaces;semiautonomous drones;image capture;task-oriented drones;control interfaces;task-oriented objectives;natural user interfaces","","1","","16","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"A Book Without Pages: Developing an Augmented Reality Storyteller Based on Open Web Data","P. Siriaraya; K. Takumi; Y. Kawai; S. Nakajima","Kyoto Institute of Technology; Kyoto Sangyo University; Kyoto Sangyo, Osaka University; Kyoto Sangyo University","2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","98","983","In this study, we describe research carried out to develop a context aware augmented reality storyteller. The system allows users to listen to short stories from books and novels as they move around in the physical world based on the spatial characteristics of their physical location. Large-Scale Open web data from sources such as Open Street Map, Google Street View and Project Gutenberg were collected and used to implement our system. Word embedding based modeling and Natural Language Processing techniques were used to match the stories with the physical locations. As an example, we show how our proposed approach could be implemented to map stories from Aesop's Fables to different locations in two cities, Kyoto and San Francisco.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942316","Open Web Data;Location based services;Context Aware service;Augmented Reality;Open Street Map","Urban areas;Servers;Augmented reality;Image segmentation;Context-aware services;Google","augmented reality;Internet;multimedia computing;natural language processing;ubiquitous computing","context aware augmented reality storyteller;Open Street Map;Google Street View;Project Gutenberg;natural language processing techniques;large-scale open web data;word embedding based modeling","","","","8","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"A building-wide indoor tracking system for augmented reality","S. Côté; F. Rheault; J. Barnard","Bentley Systems, Inc. Québec, QC, Canada; Departement d'informatique, Université de Sherbrooke, Sherbrooke, QC, Canada; Departement d'informatique, Université Laval Québec, QC, Canada","2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","167","168","Buildings require regular maintenance, and augmented reality (AR) could advantageously be used to facilitate the process. However, such AR systems would require accurate tracking to meet the needs of engineers, and work accurately in entire buildings. Popular tracking systems based on visual features cannot easily be applied in such situations, because of the limited number of visual features indoor, and of the high degree of similarity between rooms. In this project, we propose a hybrid system combining low accuracy radio-based tracking, and high accuracy tracking using depth images. Results show tracking accuracy that would be compatible with AR applications.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223348","Tracking;augmented reality;ICP;depth cameras","Three-dimensional displays;Buildings;Accuracy;Cameras;Augmented reality;Maintenance engineering;Visualization","augmented reality;feature extraction;indoor navigation;mobile radio;object tracking","building-wide indoor tracking system;augmented reality;AR systems;visual features;radio-based tracking;depth images","","","","3","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Location, location, location. An exercise in cost and waste reduction using Augmented Reality in composite layup manufacturing","C. Freeman; R. Scott; R. Krain","Advanced Manufacturing Research Centre with Boeing, University of Sheffield; Advanced Manufacturing Research Centre with Boeing, University of Sheffield; TEKS SARL LTD","2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","387","388","An Augmented Reality (AR) composite layup tool was created using low cost, off the shelf components and software to prove and demonstrate the application of AR in a manufacturing environment. The project tested different tracking technologies in order to ascertain their practicality within an industrial environment. By developing an understanding of the challenges faced in implementing such an application, the project further demonstrates the potential for cost and waste reduction. The experimental setup is at a lower price point than existing all in one solutions, thus increasing access to the technology. The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement n° [283336] - REFORM.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223458","Augmented Reality;Composite Layup;Waste Reduction;TEKS;REFORM","Manufacturing;Augmented reality;Robustness;Maintenance engineering;Image recognition;Waste reduction;Accuracy","augmented reality;cost reduction;manufacturing industries;production engineering computing;waste reduction","cost reduction;waste reduction;augmented reality;composite layup manufacturing;AR composite layup tool;off the shelf components;manufacturing environment;industrial environment","","","1","5","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Exploring Stereovision-Based 3-D Scene Reconstruction for Augmented Reality","G. -Y. Nie; Y. Liu; C. Wang; Y. Liu; Y. Wang","Beijing Institute of Technology, Beijing, Beijing, CN; Nankai University, Tianjin, Tianjin, CN; China Electronics Standardization Institute, China; China AICFVE of Beijing Film Academy, Beijing Institute of Technology, China; China AICFVE of Beijing Film Academy, Beijing Institute of Technology, China","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1100","1101","Three-dimensional (3-D) scene reconstruction is one of the key techniques in Augmented Reality (AR), which is related to the integration of image processing and display systems of complex information. Stereo matching is a computer vision based approach for 3-D scene reconstruction. In this paper, we explore an improved stereo matching network, SLED-Net, in which a Single Long Encoder-Decoder is proposed to replace the stacked hourglass network in PSM-Net for better contextual information learning. We compare SLED-Net to state-of-the-art methods recently published, and demonstrate its superior performance on Scene Flow and KITTI2015 test sets.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797778","Computing methodologies;Scene understanding;Reconstruction;Mixed/augmented reality","Image reconstruction;Convolution;Training;Three-dimensional displays;Mercury (metals);Augmented reality;Image color analysis","augmented reality;computer vision;image matching;image reconstruction;stereo image processing","three-dimensional scene reconstruction;stereovision-based 3D scene reconstruction;computer vision based approach;SLED-Net;single long encoder-decoder;Scene Flow test set;KITTI2015 test set;improved stereo matching network;complex information;display systems;image processing;augmented reality","","","","4","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"A Replication Study to Measure the Perceived Three-Dimensional Location of Virtual Objects in Optical See Through Augmented Reality","F. A. Khan; M. S. Arefin; N. Phillips; J. E. Swan",Mississippi State University; Mississippi State University; Mississippi State University; Mississippi State University,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","796","797","An important research question in optical see-through (OST) augmented reality (AR) is, how accurately and precisely can a virtual object's real world location be perceived? Previously, a method was developed to measure the perceived three-dimensional location of virtual objects in OST AR. In this research, a replication study is reported, which examined whether the perceived location of virtual objects are biased in the direction of the dominant eye. The successful replication analysis suggests that perceptual accuracy is not biased in the direction of the dominant eye. Compared to the previous study's findings, overall perceptual accuracy increased, and precision was similar.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00249","National Science Foundation(grant numbers:IIS-1937565,IIS-1320909); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757633","Augmented Reality;Depth Perception;Optical see-through Display;Replication Study","Three-dimensional displays;Conferences;Optical variables measurement;User interfaces;Augmented reality","augmented reality;computational geometry","replication study;perceived three-dimensional location;virtual object;optical see through augmented reality;OST AR","","","","3","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Collaborative Learning with Augmented Reality Tornado Simulator","Y. -M. Chiou; C. -C. Shen","Department of Computer and Information Sciences, University of Delaware, USA; Department of Computer and Information Sciences, University of Delaware, USA","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","293","298","Research has shown that AR can improve learning with better content understanding. In addition, collaborative learning has shown to increase motivation and improve learning performance. Using the subject of tornado, the paper describes the design of a multi-user augmented reality tornado simulator using Unity to facilitate collaborative learning. Students working in pairs first set up a village and configure the funnel width, pressure difference, and rotation speed of a tornado and then watch the tornado whipping through the village to destroy properties on Apple iPads. To evaluate the performance of collaborative learning, 22 sixth-grade students were recruited into control and experimental groups, whose learning performance was measured with pre and post tornado knowledge test questionnaires. The results demonstrate a significant performance improvement with collaborative learning.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757425","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed/augmented reality;Applied computing—Education—Collaborative learning","Three-dimensional displays;Conferences;Tablet computers;User interfaces;Collaborative work;Tornadoes;Augmented reality","augmented reality;computer aided instruction;groupware","collaborative learning;multiuser augmented reality tornado simulator;post tornado knowledge test questionnaires;Apple iPads","","","","29","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Visuo-haptic learning of the cochlea: Using physical optical glyphs with augmented reality","A. Zariwny","BMC, IMS, University of Toronto, Toronto, Canada","2013 IEEE International Symposium on Technology and Society (ISTAS): Social Implications of Wearable Computing and Augmediated Reality in Everyday Life","30 Sep 2013","2013","","","74","75","To develop a novel augmented reality (AR)-enabled teaching tool to demonstrate the complex structure of the human cochlea to medical students. The cochlea is small but intricate anatomical structure often represented as a snail shell-like object. It is more accurately defined as a spiral negative space within the temporal bone, but this is difficult to convey with traditional teaching tools (prosections and illustrations largely). Using a handheld tablet equipped with an integrated camera, digitally-rendered 3D models of this structure can be visually superimposed over illustrations of the cochlea and/or physical models of the petrous temporal bone, thus highlighting the negative space.","2158-3412","978-1-4799-0929-2","10.1109/ISTAS.2013.6613104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6613104","augmented reality;3D printing;visuo-haptic;anatomy;cochlea;pedagogy;mobile app","Three-dimensional displays;Solid modeling;Education;Bones;Augmented reality;Biomedical imaging;Brain modeling","augmented reality;biomedical education;bone;cameras;computer aided instruction;ear;haptic interfaces;medical computing;notebook computers;rendering (computer graphics);teaching","petrous temporal bone;physical models;digitally-rendered 3D models;integrated camera;handheld tablet;spiral negative space;snail shell-like object;intricate anatomical structure;medical students;complex structure;human cochlea;augmented reality-enabled teaching tool;AR-enabled teaching tool;physical optical glyphs;visuo-haptic learning","","","","27","IEEE","30 Sep 2013","","","IEEE","IEEE Conferences"
"Augmented Reality Board Game to Favor Water Source's Preservation","J. Hernández; A. A. Navarro-Newball",Pontificia Universidad Javeriana; Pontificia Universidad Javeriana,"2019 International Conference on Virtual Reality and Visualization (ICVRV)","6 Oct 2020","2019","","","271","272","We present an architecture to integrate augmented reality (AR) elements to a board game. Our serious board game is aimed at creating consciousness about water source's preservation in a rural community.","2375-141X","978-1-7281-4752-9","10.1109/ICVRV47840.2019.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9213002","Software Architecture;Augmented Reality;Board Game","Games;Water resources;Augmented reality;Pediatrics;Visualization;Computer architecture","augmented reality;environmental science computing;serious games (computing);water conservation;water resources","augmented reality board game;serious board game;water source preservation","","","","2","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"VeZoo – Augmented Reality Experience for the Cali's Zoo","C. Saul Arboleda; J. D. B. Diego Balanta",Pontificia Universidad Javeriana; Pontificia Universidad Javeriana,"2019 International Conference on Virtual Reality and Visualization (ICVRV)","6 Oct 2020","2019","","","302","303","We are implementing a prototype mobile application with augmented reality (AR) that will allow the information of animals to be communicated to the visitors of a zoo, ensuring that more information can be transmitted, updated and delivered in a more didactic and dynamic way through the use of technology.","2375-141X","978-1-7281-4752-9","10.1109/ICVRV47840.2019.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9213076","Augmented Reality;Zoo;Mobile","Animals;Mobile applications;Tools;Solid modeling;Visualization;Augmented reality;Three-dimensional displays","augmented reality;biology computing;mobile computing;user experience;zoology","VeZoo;augmented reality experience;Cali's Zoo;prototype mobile application;AR experience","","","","1","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"[DC] Situated augmented reality: beyond the egocentric viewpoint","N. C. Martins","IEETA, University of Aveiro, ISEC, Polytechnic Institute of Coimbra","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","721","722","Augmented reality (AR) is well suited for situated visualization (SV), a method to represent data in context, with potential in many situations. Furthermore, AR-based SV poses challenges and research prospects. A vital one is the egocentric viewpoint limitation of the users, which reduces their ability to explore all the available information. To create new approaches that will overcome this limitation, this work began by understanding the relevance of viewpoints in typical AR-based SV scenarios, characterizing the approaches already proposed in order to tackle it. The new proposed approaches should be evaluated in different settings to improve and validate them, as well as propose guidelines for some relevant scenarios.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419209","Augmented reality;situated visualization;egocentric viewpoint limitation","Three-dimensional displays;Conferences;Data visualization;Big Data;Task analysis;Artificial intelligence;Augmented reality","augmented reality;data visualisation","augmented reality;situated visualization;egocentric viewpoint;AR based SV scenarios;data representation;data visualization","","","","10","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Learning Environments in AR: Comparing Tablet and Head-mounted Augmented Reality Devices at Room and Table Scale","P. Craig; P. Willemsen; E. Downs; A. Lover; W. Barber",University of Minnesota Duluth; University of Minnesota Duluth; University of Minnesota Duluth; University of Minnesota Duluth; University of Minnesota Duluth,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","892","893","This paper presents work to examine how presentation scale and device form factor may affect learning in augmented reality (AR) en-vironments. We conducted a 2 (form factor) x 2 (scale) experiment in which 131 participants explored an AR learning environment using either tablet AR or a Hololens2 crossed with either full room scale or at table scale. Dependent variables measured participants declarative knowledge about information acquired in the environ-ment as well as their understanding of spatial layout. Initial analysis suggests comparable outcomes across all manipulations with respect to acquiring declarative and spatial knowledge.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757486","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed/ augmented reality;Human-centered computing—Empirical studies in HCI;Applied computing—Interactive learning environments","Three-dimensional displays;Atmospheric measurements;Conferences;Layout;User interfaces;Particle measurements;Augmented reality","augmented reality","table scale;presentation scale;device form factor;tablet AR;Hololens2;room scale;learning environments;head-mounted augmented reality devices","","","","7","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Towards Dynamic Realtime Object Labeling in Augmented Reality","B. Troutman; M. Tuceryan","Department of Computer and Information Science, Indiana University, Purdue University Indianapolis, Indianapolis, Indiana, United States; Department of Computer and Information Science, Indiana University, Purdue University Indianapolis, Indianapolis, Indiana, United States","2022 IEEE 2nd International Conference on Intelligent Reality (ICIR)","23 Mar 2023","2022","","","49","53","The applicability of augmented reality (AR) is stunted by the current limitations of localization systems. In various forms, simultaneous localization and mapping (SLAM) has become a common framework for providing device localization in AR systems; however, outside of camera localization data, SLAM systems typically fail to provide additional information about the environment to consumer applications. This limits the domain of potential AR applications, as many applications will require some degree of interaction between the real and virtual worlds. One such application is object labeling for moving objects. In this work, we implement an AR moving object labeling system by utilizing LUMO-SLAM, a SLAM system that registers and localizes unknown moving objects in the environment. Test runs of the system show that moving object information provided by LUMO-SLAM is sufficient for implementing a useful moving object labeling system and potentially other real-world applications of AR.","","978-1-6654-8755-9","10.1109/ICIR55739.2022.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10070898","Augmented Reality (AR);Object Labeling;SLAM;Dynamic SLAM;Monocular Vision;Localization","Location awareness;Simultaneous localization and mapping;Cameras;Registers;Labeling;Augmented reality","augmented reality;cameras;mobile robots;object detection;robot vision;SLAM (robots)","AR systems;augmented reality;camera localization data;consumer applications;device localization;localization systems;localizes unknown moving objects;LUMO-SLAM;object information;potentially other real-world applications;registers;SLAM system;system show;towards dynamic realtime object labeling;useful moving object labeling system","","","","13","IEEE","23 Mar 2023","","","IEEE","IEEE Conferences"
"Pinch-n-Paste: Direct texture transfer interaction in augmented reality","A. Umakatsu; T. Mashita; K. Kiyokawa; H. Takernura","Osaka University, Japan; Osaka University, Japan; Osaka University, Japan; Osaka Daigaku, Suita, Osaka, JP","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","73","74","Our Pinch-n-Paste allows a user to touch or pinch one part of an object, copy and move its texture, and paste it onto another object, directly with his or her hand, in an augmented reality environment. To transfer texture appropriately from one part of an object to another, two texture images are generated by the Least Square Conformal Map (LSCM) technique. Two regions in the texture images corresponding to source and target areas of interest are then obtained using cross-boundary brushes. Target texel values are sampled from corresponding source texels by Moving Least Squares (MLS), and are finally mapped onto the target object. In this poster, we will describe the basic idea, implementation details, and example interaction results and a preliminary user study.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549369","Augmented Reality;texture transfer;3D physics interaction","Brushes;Three-dimensional displays;Electronic mail;Clothing;Augmented reality;Cameras;Mathematical model","augmented reality;image texture;least squares approximations;user interfaces","texture transfer interaction;pinch-n-paste interaction technique;augmented reality environment;least square conformal map technique;LSCM technique;texture image generation;cross-boundary brush;moving least squares;MLS;object mapping","","","","7","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"SkillsLab+ - Augmented Reality Enhanced Medical Training","C. Gießer; J. Knode; A. Gruenewald; T. J. Eiler; V. Schmuecker; R. Brueck","Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany","2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","22 Dec 2021","2021","","","194","197","The digitization of medical studies can help future doctors cope with new opportunities and challenges of our time. Computer-assisted procedures have long since become part of a doctor's daily routine and the use of modern digital technology is unlikely to decline in the future. In order to be better prepared, the use of modern technology must already take place during studies and training. This is exactly where SkillsLab+ comes in and combines the first practical experiences of the medical course SkillsLab with state of the art methods of augmented reality. Additional information, images and instructions are projected directly into the learner's field of vision and they learn how to use this new technology in a meaningful way. Supporting digitization of the SkillsLab can promote self-study and helps students to be better prepared for the actual teaching. Upcoming studies will investigate this assumption and a comparison between the conventional SkillsLab and the enhanced and and digitised SkillsLab+ will be sought.","","978-1-6654-3225-2","10.1109/AIVR52153.2021.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644341","Augmented Reality;medical students;self-guided learning;SkillsLab","Training;Conferences;Medical services;Artificial intelligence;Augmented reality;Biomedical imaging","augmented reality;biomedical education;computer aided instruction;educational courses;medical computing;teaching","conventional SkillsLab;augmented reality enhanced medical training;medical studies;computer-assisted procedures;doctor;digital technology;medical course SkillsLab+;self-study","","","","13","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Early steps towards understanding text legibility in handheld augmented reality","B. Dao; J. L. Gabbard","Pamplin College of Business, Virginia Tech, USA; Virginia Bioinformatics Institute, Industrial & Systems Engineering, Virginia Tech, USA","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","159","160","Over the past decades, augmented reality (AR) has seen vast improvements in graphic displays and mobile tracking capabilities. To our knowledge, handheld AR researcher in text legibility has mostly focused on algorithms for overlaying screen-aligned annotations; no one has yet employed a series of user-based studies to systematically investigate text legibility in handheld AR applications. In this preliminary work, we survey current approaches to text depictions in AR applications and the literature. We have found no single consistent form of displaying text, but see some basic trends emerging. This initial work lays the foundation for examining different text styles in various environments in order to create guidelines for effective text drawing approaches. By assessing current strategies for rendering text labels in handheld AR, we can catalog drawing styles for use in follow-on user-based studies.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549411","Handheld Augmented Reality;User Interface Design;Text Legibility;Color Perception","Augmented reality;Mobile communication;Color;Lighting;Visualization;Guidelines","augmented reality;mobile computing;rendering (computer graphics)","follow-on user-based studies;text label rendering;text drawing approach;screen-aligned annotation;mobile tracking capability;graphic display;AR;handheld augmented reality;text legibility understanding","","","1","14","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"A User-Based Comparison of Two Augmented Reality Glasses","E. M. Klose; L. Schmidt","Human-Machine Systems Engineering Group, University of Kassel, Germany; Human-Machine Systems Engineering Group, University of Kassel, Germany","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","1","2","We present a scenario-based laboratory study with 40 participants comparing two augmented reality (AR) glasses in a travelling scenario. In a within-subject design, the binocular Epson Moverio BT-200 and the monocular Vuzix M100 were compared with regard to performance, acceptance, workload and preference. While performance was equal with both glasses, the Epson Moverio BT-200 glasses got higher acceptance and lower workload ratings and were preferred by the majority of the participants. The findings provide knowledge on human factors in AR glasses usage.","","978-1-5386-3365-6","10.1109/VR.2018.8446175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446175","Data glasses;user study;performance;acceptance;workload.: Human-centered computing-Mixed / augmented reality;Human-centered computing-User studies","Glass;Augmented reality;Human factors;Videos;Cameras;Google;Feeds","augmented reality;human computer interaction;human factors;interactive devices","binocular Epson Moverio BT-200;monocular Vuzix M100;AR glasses usage;augmented reality glasses;within-subject design;human factors;workload ratings;user acceptance","","","","10","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"The effect of an occluder on near field depth matching in optical see-through augmented reality","C. Hua; J. Edward Swan",Mississippi State University; Mississippi State University,"2014 IEEE Virtual Reality (VR)","24 Apr 2014","2014","","","81","82","We have conducted an experiment to study the effect of an occluding surface on the accuracy of near field depth matching in augmented reality (AR). Our experiment was based on replicating a similar experiment conducted by Edwards et al. [2]. We used an AR haploscope, which allows us to independently manipulate accommodative demand and vergence angle. Sixteen observers matched the perceived depth of an AR-presented virtual object with a physical pointer. Overall, observers overestimated depth by 6 mm or less with or without the presence of the occluder. The data from Edwards et al. [2] is normalized, and when we performed the same normalization procedure on our own data, our results do not agree with Edwards et al. [2]. We suspect that eye vergence explains these results.","2375-5334","978-1-4799-2871-2","10.1109/VR.2014.6802061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802061","Depth perception;augmented reality","Observers;Augmented reality;Surgery;Context;Head;Biomedical optical imaging;Educational institutions","augmented reality;pattern matching","occluder;near field depth matching;optical see-through augmented reality;occluding surface;AR haploscope;accommodative demand;vergence angle;AR-presented virtual object;perceived depth;normalization procedure","","","","2","IEEE","24 Apr 2014","","","IEEE","IEEE Conferences"
"Amalgamation of Virtual Reality, Augmented Reality and Machine Learning: A Review","S. Angra; B. Sharma; K. D. Sharma","Chitkara University Institute of Engineering & Technology, Chitkara University, Punjab; Chitkara University Institute of Engineering & Technology, Chitkara University, Punjab; Chitkara University Institute of Engineering & Technology, Chitkara University, Punjab","2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)","18 Jul 2022","2022","","","2601","2604","Nowadays, Visualization plays an important role in every field. People memorize the images/videos more as compared to the text. Consequently, Augmented and virtual reality fields are in surplus demand and this area when combined with machine learning generates more efficient results. AR/VR plays a vital role in the field of education, medicine, gaming and so on. This paper reviews the work already carried out by different authors in the field of AR/VR integrated with Machine Learning.","","978-1-6654-3789-9","10.1109/ICACITE53722.2022.9823716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9823716","Machine learning;Augmented Reality;Virtual Reality;markers;immersive","Solid modeling;Visualization;Machine learning algorithms;Education;Machine learning;Augmented reality;Diseases","augmented reality;learning (artificial intelligence);virtual reality","machine learning;amalgamation;Augmented reality;virtual reality fields;surplus demand","","1","","17","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Amalgamation of 3-Dimensions in Education field using Augmented Reality Technology","S. Singh; A. Kaur","Chitkara University Institute of Engineering and Technology Chitkara University, Punjab, India; Chitkara University Institute of Engineering and Technology Chitkara University, Punjab, India","2022 7th International Conference on Communication and Electronics Systems (ICCES)","29 Jul 2022","2022","","","114","119","Augmented reality (AR) is a method that overlays a user’s perspective of the real world with a computer-generated image. In order to build best AR applications that helped us to accept augmented reality related technologies and systems, one of the key foundations is to understand and determine the user’s expectations. This paper examines existing research on user expectations for augmented reality in education to assist in the future endeavors. AR in education can generate creative experiences and improve problem-solving skills to prepare pupils for the future. Gaming engines like Unity and Unreal are used to develop AR based digital applications. In the present paper, mechanism being AR applications and Unity 3D software is discussed. A digital application is also mentioned in the paper which is developed by exploring Unity 3D software. In addition, Unity 3D software is also explored and digital applications are developed using the same","","978-1-6654-9634-6","10.1109/ICCES54183.2022.9835871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835871","Augmented Reality;Virtual Reality;Education;Teaching;Learning","Visualization;Three-dimensional displays;Education;Writing;Software;Pupils;Augmented reality","augmented reality;computer aided instruction;computer games;solid modelling;virtual reality","AR applications;Unity 3D software;digital application;3-dimensions;education field;augmented reality technology;computer-generated image;augmented reality related technologies;key foundations;user expectations;future endeavors;AR based digital applications","","","","27","IEEE","29 Jul 2022","","","IEEE","IEEE Conferences"
"Augmented Reality Floods and Smoke Smartphone App Disaster Scope utilizing Real-time Occlusion","T. Itamiya; H. Tohara; Y. Nasuda","Aichi Koka Daigaku, Gamagori, Aichi, JP; Aichi Koka Daigaku, Gamagori, Aichi, JP; Aichi Koka Daigaku, Gamagori, Aichi, JP","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1397","1397","Natural disasters occur frequently in Japan. In the Great East Japan Earthquake in 2011 and the heavy rain disaster at western Japan in 2018, many people didn't have the crisis consciousness enough to evacuate safely. We developed the augmented reality smartphone-application Disaster Scope that enables immersive experience in order to improve the crisis awareness of disasters in peacetime. The application can superimpose the occurrence situation of disasters such as CG floods and debris and fire smoke in the actual scenery, using only a smartphone and paper headset. By using a smartphone equipped with a 3D depth sensor, it is possible to sense the height from the ground and recognize surrounding objects. The real-time occlusion processing enabled using only by a smartphone. The collision detection of the real world's objects and CG debris is possible. The floods height and flow speed can be changed by each user's setting. As a result, it has become possible to understand more realistically the dangerous of floods and a fire smoke charge. We utilized this system in evacuation drills organized by elementary schools and municipalities. As a result of the survey and verification, it was very useful for improving crisis awareness of students and citizens.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798269","Augmented Reality;Evacuation drill;Smartphone;Occlusion;Training;Floods;Tsunami;Fire;Smoke;[Computational and artificial intelligence]: Computer science - Programming - Augmented reality","Conferences;Virtual reality;Three-dimensional displays;User interfaces","augmented reality;computer graphics;disasters;emergency management;floods;rain;smart phones","augmented reality floods;natural disasters;Great East Japan Earthquake;heavy rain disaster;crisis consciousness;CG floods;CG debris;floods height;fire smoke charge;Western Japan;realtime occlusion processing;Disaster Scope;smoke smartphone application","","6","","0","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Embedding augmented and virtual reality in educational learning method: Present and future","R. Al-Azawi; M. S. Shakkah","Gulf College, Oman; Gulf College, Oman","2018 9th International Conference on Information and Communication Systems (ICICS)","7 May 2018","2018","","","218","222","This paper discusses the new opportunity for improving the quality of teaching and learning methods by using new trends of educational technology. Those new tends are delivering materials not based on the availability of teacher or lecturer. Educational technologies currently focus on dealing with electronic learning (E-Learning) and mobile learning (M-Learning) as a useful educational tool. Many studies start to give big attention on the next step in Virtual and Augmented Reality as a useful tool for education, training, simulation... etc. Due the increase of using mobile devices as a part of teaching methods, Mobile Augmented Reality are used as an exemplify the potentials for education process. This paper expects to encourage educators and learners to join the innovations in the educating and learning process. The mix of these technologies in the teaching and learning process can give new learning condition and enhance the educating and learning quality. The learning procedure ends up noticeably pleasant and intriguing with advances. In spite of the fact that innovation has a ton of advantage to the instruction field, instructors must be imaginative and creative to execute innovation in the educating and learning process. Therefore, educators and learners need to choose the suitable innovation as per the lesson educated. The main goal for this paper is to assist teachers to be motivated appreciate by adding new technologies in their teaching method by selecting a suitable technology based on teaching requirements and materials.","2573-3346","978-1-5386-4366-2","10.1109/IACS.2018.8355470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355470","Virtual Reality;Augmented Reality;Mobile Augmented Reality;Mixed Reality","Augmented reality;Technological innovation;Mobile handsets;Electronic learning","augmented reality;computer aided instruction;mobile computing;teaching","educational learning method;educational technology;E-Learning;mobile learning;useful educational tool;simulation;teaching method;Mobile Augmented Reality;education process;innovation;learning process;learning condition;learning quality;learning procedure;electronic learning","","12","","21","IEEE","7 May 2018","","","IEEE","IEEE Conferences"
"The Use of Augmented Reality Technologies in Electrical Engineering","A. Pogodaev; I. Muzyleva; L. Yazykova; S. Kondratyev","Lipetsk State Technical University, Lipetsk, Russia; Lipetsk State Technical University, Lipetsk, Russia; Lipetsk State Technical University, Lipetsk, Russia; Lipetsk State Technical University, Lipetsk, Russia","2020 2nd International Conference on Control Systems, Mathematical Modeling, Automation and Energy Efficiency (SUMMA)","17 Dec 2020","2020","","","646","650","The article discusses one of the technologies of the industrial revolution 4.0 - augmented reality (AR). The analysis of the capabilities of marker and markerless technology and related software. The analysis of examples of the application of this technology in education is carried out. The practical aspects of the application of marker technology in the educational process of electrical engineering disciplines are examined in detail. The implementation of the methodology consists of two stages. The first is the selection and creation of 3D models of electrical objects. As an example, the basis of the electromagnetic relay, an induction motor and a DC machine in their classical sense are taken. The choice of these devices is due to the fact that understanding the principle of their action is the basis of many electrical engineering disciplines. In particular, understanding the operation of automation systems is impossible without understanding the principle of operation of the electromagnetic relay. The synthesis of electric drive control systems is impossible without understanding the principle of operation of the corresponding electric machine. The second part of the proposed methodology consists in placing the created 3D model in the constructor of augmented reality objects EV Toolbox. The use of the augmented reality objects obtained allows us to show and, accordingly, ""examine"" the simulated electrical device from all sides by turning the paper marker. The instructor is given the object of augmented reality and the part of the software that is responsible for demonstrating the object. The teacher can clearly show and explain the principle of the object's operation, and it's an easier task for the student to perceive such material.","","978-1-7281-8840-9","10.1109/SUMMA50634.2020.9280643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9280643","digitalization of education;augmented reality;AR;educational process organization;augmented reality content;Mixed reality;3D modeling;electric motor;stator;rotor;asynchronous motor;EV Toolbox","Electrical engineering;Solid modeling;Three-dimensional displays;Software;Mathematical model;Relays;Augmented reality","augmented reality;computer aided instruction;electric drives;electrical engineering computing;electrical engineering education;solid modelling","industrial revolution 4.0;simulated electrical device;3D model;electric machine;electric drive control systems;electromagnetic relay;electrical objects;electrical engineering;educational process;marker technology;markerless technology;augmented reality technologies","","7","","11","IEEE","17 Dec 2020","","","IEEE","IEEE Conferences"
"Implementation of an augmented reality system on a PDA","W. Pasman; C. Woodward","Faculty of Information Tech. and Systems, Delft University of Technnology, Netherlands; Technical Research Centre of Finland, VTT Information Technology, Finland","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","276","277","We present a client/server implementation for running demanding mobile AR application on a PDA device. The system incorporates various data compression methods to make it run as fast as possible on a wide range of communication networks, from GSM to WLAN.","","0-7695-2006-5","10.1109/ISMAR.2003.1240718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240718","","Augmented reality;Image coding;GSM;Wireless LAN;Displays;Cameras;Decoding;Hardware;Software architecture;Rendering (computer graphics)","mobile computing;client-server systems;augmented reality;notebook computers;wireless LAN;data compression","augmented reality system;PDA;client-server implementation;mobile AR application;data compression;communication networks;GSM;WLAN;handheld displays;camera;personal digital assistant","","16","2","5","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Results of a study on software architectures for augmented reality systems","T. Reicher; A. Mac Williams; B. Brugge; G. Klinker","Institut für Informatik, Technische Universität, Garching bei München, Germany; Institut für Informatik, Technische Universität, Garching bei München, Germany; Institut für Informatik, Technische Universität, Garching bei München, Germany; Institut für Informatik, Technische Universität, Garching bei München, Germany","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","274","275","Research prototypes in AR usually do not emphasize software architecture. Nevertheless, their architecture is not arbitrary, but results from specific needs. Architectural approaches embodying research contributions are of particular value for reuse at component and architectural levels. We have conducted a study of existing AR software architectures for the ARVIKA project by W. Friedrich et al (2001). This has resulted in a catalog of important desired quality attributes for AR systems, a reference architecture for comparison of AR architectures, and a catalog of architectural approaches used in current AR systems. We believe this lays the foundation for further research in AR software architectures.","","0-7695-2006-5","10.1109/ISMAR.2003.1240717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240717","","Computer architecture;Augmented reality;Software architecture;Context modeling;Software prototyping;Information systems;Image analysis;Bars;Wire;Assembly","software architecture;augmented reality;software prototyping;object-oriented programming","software architectures;augmented reality systems;research prototypes;software architecture;architectural approaches;research contributions;component levels;architectural levels;ARVIKA;quality attributes;AR systems","","8","1","20","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"A mirror metaphor interaction system: touching remote real objects in an augmented reality environment","E. Hosoya; M. Kitabata; H. Sato; I. Harada; H. Nojima; F. Morisawa; S. Mutoh; A. Onozawa","NTT Microsystem Integration Laboratories, Atsugi, Kanagawa, Japan; NTT Microsystem Integration Laboratories, Atsugi, Kanagawa, Japan; NTT Microsystem Integration Laboratories, Atsugi, Kanagawa, Japan; NTT Microsystem Integration Laboratories, Atsugi, Kanagawa, Japan; NTT Microsystem Integration Laboratories, Atsugi, Kanagawa, Japan; NTT Microsystem Integration Laboratories, Atsugi, Kanagawa, Japan; NTT Microsystem Integration Laboratories, Atsugi, Kanagawa, Japan; NTT Microsystem Integration Laboratories, Atsugi, Kanagawa, Japan","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","350","351","We propose a real-world-oriented interface called the ""mirror metaphor interaction system"". The display shows a mirror image from a camera facing a user, and the user can ""touch"" objects without making direct contact with the display. The ""touched"" object displays a menu or works directly. Objects can be placed in a remote room as well as in the user's room, and can also be moved around in a room. The user can therefore control equipment or interact with objects anywhere through the display of the system by combining images from local and remote places translucently. Our demonstration shows how the interface makes it easy to establish contact with movable objects in a remote room by ""touching"" them in the display.","","0-7695-2006-5","10.1109/ISMAR.2003.1240755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240755","","Mirrors;Augmented reality;Displays;Cameras;Character generation;Sensor systems;Infrared sensors;Control equipment;Ubiquitous computing;Home computing","augmented reality;gesture recognition;computer graphics","mirror metaphor interaction system;remote real objects;augmented reality environment;real-world-oriented interface;mirror image;nondirect contact;remote room;user room;equipment control;object interaction;image combinations;translucent combination;movable objects;translucent self-image","","4","1","6","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Prototype Algorithm Design for Web Based Service Oriented Architecture Mobile Augmented Reality System","J. Shah; B. Agrawal","KSV University, Gandhinagar, Gujarat, India; VJKM Groups of Institution, Kalol, Gujarat, India","2015 Fifth International Conference on Communication Systems and Network Technologies","1 Oct 2015","2015","","","1085","1088","Augmented Reality & Mobile Augmented Reality has very widely used in nowadays Smartphone's and there is not any Software Architecture available. So when one application will develop for Mobile Augmented Reality will targeted only on one mobile handsets or device. When the device will change for some reason the application will require to Re-Architect because of its operating system and handle the network and GPS. Also the application will required to Install in device and require some kind of storage and some extra libraries to developed Mobile Augmented Reality System. In this paper propose algorithm for web based service oriented architecture for mobile augmented reality system. Using this prototype algorithm user can design any mobile augmented reality system application, also extend the services using current web services. A Framework is proposed in order to achieve any Application design using this Software Architecture will run on any mobile device platforms without the need for Installation or no Installation. Architecture will give the ""Web Based Interface"" so the User's have some kind of Network support and GPS Support will easily get the Application on any mobile Device. Also the framework will base on SOA so web services will design according to handle the Mobile data e.g. Images, Audio, and Video etc. To and from the web server. Software Architecture will give the Application to Portability, extensibility, No Need for Installation, Reusability without any code change. Same code will run on multiple mobile devices without the OS limitation and any third party will design his own application using the same code or extend it as per his choice.","","978-1-4799-1797-6","10.1109/CSNT.2015.85","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280087","Service Oriented Mobile Augmented Reality;Web Based Mobile Augmented Reality","Servers;Augmented reality;Mobile communication;Global Positioning System;Service-oriented architecture","Android (operating system);augmented reality;mobile computing;service-oriented architecture;smart phones;software portability;software prototyping;software reusability;user interfaces;Web services","prototype algorithm design;Web based service oriented architecture mobile augmented reality system;smartphone;software architecture;mobile handsets;operating system;GPS;mobile device platforms;Web based interface;SOA;mobile data handling;Web server;OS limitation","","","","11","IEEE","1 Oct 2015","","","IEEE","IEEE Conferences"
"Augmented reality for enhancement of endoscopic interventions","U. Bockholt; A. Bisler; M. Becker; W. Muller-Wittig; G. Voss","Department Visualization & Virtual Reality, Fraunhofer Institute for Computer Graphics, Darmstadt, Germany; Department Visualization & Virtual Reality, Fraunhofer Institute for Computer Graphics, Darmstadt, Germany; Department Visualization & Virtual Reality, Fraunhofer Institute for Computer Graphics, Darmstadt, Germany; Centre for Advanced Media Technology (CAMTech), Singapore; Centre for Advanced Media Technology (CAMTech), Singapore","IEEE Virtual Reality, 2003. Proceedings.","2 Apr 2003","2003","","","97","101","Computer assisted operation planning systems win more and more recognition in the field of surgery. These systems offer new possibilities to prepare an intervention with the goal to shorten the expansive time in the operation room required for the intervention. The safest and most effective surgical approach should be selected. But often, it is difficult to transfer the output of the planning system to the intra-operative situation and so to consider the planning results in the real intervention. At the Fraunhofer Institute for Computer Graphics (IGD) in Darmstadt and the Centre for Advanced Media Technology (CAMTech) in Singapore, methods are developed to bridge the gap between the external planning session and the intra-operative case: augmented reality (AR) techniques are used to overlap preoperative scanned image data as well as results of the planning session to the operation field.","1087-8270","0-7695-1882-6","10.1109/VR.2003.1191126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191126","","Augmented reality;Orthopedic surgery;Biomedical imaging;Neurosurgery;Displays;Technology planning;Shape;Biological tissues;Deformable models;Endoscopes","augmented reality;medical image processing;surgery;planning;endoscopes","augmented reality;endoscopic intervention enhancement;computer assisted operation planning systems;surgery;intra-operative case;preoperative scanned image data","","7","","14","IEEE","2 Apr 2003","","","IEEE","IEEE Conferences"
"Study on the perception mechanism and method of virtual and real objects in augmented reality assembly environment","Jingzhou Song; Qingxuan Jia; Hanxu Sun; Xin Gao","Automation School, Beijing University of Posts and Telecommunications, Beijing, China; Automation School, Beijing University of Posts and Telecommunications, Beijing, China; Automation School, Beijing University of Posts and Telecommunications, Beijing, China; Automation School, Beijing University of Posts and Telecommunications, Beijing, China","2009 4th IEEE Conference on Industrial Electronics and Applications","30 Jun 2009","2009","","","1452","1456","Augmented reality assembly, is a promising application of virtual reality in design and manufacturing and has drawn much more and more attentions from industries and research institutes. The focus of this study are as follows. (1) using the agent-oriented modeling for subassembly object and the behavior reasoning based on petri net model of environment, to build the system model of augmented reality assembly environment and construct the percepting mechanism of the virtual and real objects; (2) based on above percepting mechanism, to solve the epipolar geometry constraint by least robustness square estimation model, and to sense the depth of the occluded virtual objects or real objects in the environment through assembly scene recognizing, background eliminating and geometrical features restructuring of product contour; (3) combining awareness process of object features matching, constrained motion and features fitting with image based visual hull generating and volume querying, to detect the collision of virtual and real objects, including the dynamic deformable objects. The research results is of very important academic and applicative interest in the field of digital design, assembly and maintenace. It would be helpful to promote the application research of augmented reality and virtual reality technology.","2158-2297","978-1-4244-2799-4","10.1109/ICIEA.2009.5138442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5138442","augmented reality;perception mechanism;augmented assembly;depth sensing;collision detection","Augmented reality;Solid modeling;Deformable models;Virtual reality;Assembly systems;Manufacturing industries;Focusing;Geometry;Robustness;Motion estimation","augmented reality;multi-agent systems;Petri nets;realistic images","perception mechanism;augmented reality assembly environment;virtual reality;agent-oriented modeling;subassembly object;behavior reasoning;petri net model;epipolar geometry constraint;robustness square estimation model;occluded virtual objects;occluded real objects;assembly scene recognizing;background eliminating;geometrical features restructuring;product contour;object features matching;constrained motion;features fitting","","1","","18","IEEE","30 Jun 2009","","","IEEE","IEEE Conferences"
"On the use of Augmented Reality techniques in learning and interpretation of cardiologic data","E. Lamounier; A. Bucioli; A. Cardoso; A. Andrade; A. Soares","Reality Research Group Faculty of Electrical Engineering from Federal, University of Uberlândia Brazil, Brazil; Faculty of Computer Enginnering, Minas Gerais State University, Ituiutaba, Brazil; Virtual and Augmented Reality Research Group, University of Uberlândia Brazil, Brazil; Biomedical Engineering Laboratory Faculty of Electrical Engineering, University of Uberlândia Brazil, Brazil; Biomedical Engineering Laboratory Faculty of Electrical Engineering, Uberlândia Brzil, Brazil","2010 Annual International Conference of the IEEE Engineering in Medicine and Biology","11 Nov 2010","2010","","","610","613","Augmented Reality is a technology which provides people with more intuitive ways of interaction and visualization, close to those in real world. The amount of applications using Augmented Reality is growing every day, and results can be already seen in several fields such as Education, Training, Entertainment and Medicine. The system proposed in this article intends to provide a friendly and intuitive interface based on Augmented Reality for heart beating evaluation and visualization. Cardiologic data is loaded from several distinct sources: simple standards of heart beating frequencies (for example situations like running or sleeping), files of heart beating signals, scanned electrocardiographs and real time data acquisition of patient's heart beating. All this data is processed to produce visualization within Augmented Reality environments. The results obtained in this research have shown that the developed system is able to simplify the understanding of concepts about heart beating and its functioning. Furthermore, the system can help health professionals in the task of retrieving, processing and converting data from all the sources handled by the system, with the support of an edition and visualization mode.","1558-4615","978-1-4244-4123-5","10.1109/IEMBS.2010.5628019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5628019","","Augmented reality;Heart;Electrocardiography;Cardiology;Data visualization;Animation","augmented reality;biomedical measurement;data visualisation;electrocardiography;medical computing","augmented reality techniques;cardiologic data learning;cardiologic data interpretation;heart beat evaluation;heart beat visualization;heart beat frequencies;heart beat signals;electrocardiographs;patient heart beat real time data acquisition;data visualization","Algorithms;Computer Graphics;Computer Simulation;Diagnosis, Computer-Assisted;Electrocardiography;Humans;Models, Cardiovascular;Signal Processing, Computer-Assisted;User-Computer Interface","20","","18","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"An interactive Augmented Reality system: A prototype for industrial maintenance training applications","B. Besbes; S. N. Collette; M. Tamaazousti; S. Bourgeois; V. Gay-Bellile","CEA, LIST, Vision and Content Engineering Laboratory, France; CEA, LIST, Vision and Content Engineering Laboratory, France; CEA, LIST, Vision and Content Engineering Laboratory, France; CEA, LIST, Vision and Content Engineering Laboratory, France; CEA, LIST, Vision and Content Engineering Laboratory, France","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","269","270","In this paper, we present an innovative Augmented Reality prototype designed for industrial education and training applications. The system uses an Optical See-Through HMD integrating a calibrated camera and a laser pointer to interactively augment an industrial object with virtual sequences designed to train a user for specific maintenance tasks. The training leverages user interactions by simply pointing on a specific object component. The architecture of our prototype involves two main vision-based modules : camera localization and user-interaction handling. The first module includes markerless trackers for camera localization, which can deal with partial occlusions and specular reflections on the metallic object surfaces. In the second module, we developed fast image processing methods for red laser dot tracking. By combining these processing elements, the proposed system is able to interactively augment in real time an industrial object making the learning process more interesting and intuitive.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402568","MR/AR applications [industrial and military MR/AR applications];—[Sensors]: vision-based registration and tracking—;User interaction [interaction techniques for MR/AR];—[MR/AR applications]: MR/AR for art, cultural heritage, or education and training—","Prototypes;Training;Cameras;Augmented reality;Laser modes;Laser applications;Real-time systems","augmented reality;cameras;computer based training;helmet mounted displays;human computer interaction;image processing;industrial training;laser beam applications;maintenance engineering;production engineering computing;target tracking","interactive augmented reality system;industrial maintenance training;industrial education;optical see-through HMD;calibrated camera;laser pointer;virtual sequences;maintenance tasks;object component;vision-based modules;camera localization;user-interaction handling;partial occlusions;specular reflections;metallic object surfaces;image processing methods;red laser dot tracking;industrial object","","28","1","5","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Tag detection algorithm for improving the instability problem of an augmented reality","S. -w. Lee; D. -c. Kim; D. -y. Kim; T. -d. Han","Media System Laboratory, Department of Computer Science, Yonsei University, South Korea; Media System Laboratory, Department of Computer Science, Yonsei University, South Korea; Media System Laboratory, Department of Computer Science, Yonsei University, South Korea; Media System Laboratory, Department of Computer Science, Yonsei University, South Korea","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","257","258","Detection technology is a requirement for an Augmented Reality system. One of the problems with detection technology is the instability problem, which occurs when an obstacle occludes a tag while detecting the tag, and the augmented object suddenly disappears. We have proposed a corner detection algorithm to solve this instability problem. The key feature is that if the tag can recognize its position using its four corner cells despite the obstacle being present, then it can maintain its augmented object. We defined the corner case for all types of cases where the instability problem occurs in ARToolkit or ARTag. We have adapted our proposed algorithm to the corner case in ARToolkit, ARTag and ColorCode vision systems and have compared their false detection rates.","","1-4244-0650-1","10.1109/ISMAR.2006.297828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079290","","Detection algorithms;Augmented reality;Object detection;Machine vision;Error analysis;Laboratories;Computer science;Data gloves;Image recognition;Cameras","augmented reality;edge detection;object detection","tag detection algorithm;augmented reality;instability problem;corner detection","","2","4","4","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Augmenting text document by on-line learning of local arrangement of keypoints","H. Uchiyama; H. Saito","Keio University, Japan; Keio University, Japan","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","95","98","We propose a technique for text document tracking over a large range of viewpoints. Since the popular SIFT or SURF descriptors typically fail on such documents, our method considers instead local arrangement of keypoints. We extends locally likely arrangement hashing (LLAH), which is limited to fronto-parallel images: We handle a large range of viewpoints by learning the behavior of keypoint patterns when the camera viewpoint changes. Our method starts tracking a document from a nearly frontal view. Then, it undergoes motion, and new configurations of keypoints appear. The database is incrementally updated to reflect these new observations, allowing the system to detect the document under the new viewpoint. We demonstrate the performance and robustness of our method by comparing it with the original LLAH.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336491","LLAH;on-line learning;pose estimation;paper registration;paper based augmented reality","Augmented reality;Nearest neighbor searches;Cameras;Image databases;Pattern matching;Robustness;Multimedia systems;Virtual reality;Image processing;Computer vision","augmented reality;text analysis","text document augmentation;online learning;locally likely arrangement hashing;pose estimation;paper-based augmented reality","","11","2","18","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Collaboration in Mediated and Augmented Reality (CiMAR) Summary","S. Lukosch; M. Billinghurst; K. Kiyokawa; S. Feiner; L. Alem","Policy and Management, Delft University of Technology, Netherlands; School of Information Technology and Mathematical Sciences, University of South Australia, Australia; Osaka University, Japan; Department of Computer Science, Columbia University, NewYork, USA; Australia","2015 IEEE International Symposium on Mixed and Augmented Reality Workshops","3 Dec 2015","2015","","","1","2","Summary form only given. The world is becoming more complex everyday, so problem solving often requires global teams of experts working together. To do this effectively there is a need for collaborative tools, and so a variety of teleconferencing and telepresence technologies have been developed. However, most of them involve some variation of traditional video conferencing, which has limitations, such as not being able to effectively convey spatial cues. This workshop focuses on how Augmented Reality (AR) [1] and Mediated Reality (MR) [2] technology can be used to overcome these limitations and develop radically new types of collaborative experiences. In combination, AR and MR technologies could be used to merge the shared perceived realities of different users, as well as enrich each user's own individual experience in a collaborative task. Several studies have explored the effectiveness of using AR and MR for complex tasks. For example, AR has been shown to improve the effectiveness of individual manual assembly tasks [3], while MR systems have been shown to improve the performance time and mental effort in collaborative design tasks [4]. Recent research on using MR for collaboration among crime scene investigators indicates that using shared visual feedback promotes mutual understanding, leads to consensus, and supports hypothesis testing [5]. There are many examples of collaborative AR applications. The Studierstube system [6] targets face-to-face presentations and allows users to walk around virtual 3D scientific data. WearCom [7] enables users to see remote users as virtual avatars in real space. Höllerer et al. [8] allow indoor AR users to visualize the locations and paths of outdoor AR users, and all users to create shared annotations. Poelman et al. [5] present an AR system that allows remote experts to collaborate with local investigators on a crime scene investigation in order to secure evidence. Datcu et al. [9] present an AR system that supports the distributed situational awareness of cross-organisational teams in the security domain. Gauglitz et al. [10] introduce a tablet-based system that incorporates a touchscreen interface through which a remote user can navigate a physical environment and create world-aligned annotations for supporting remote maintenance. In summary, MR and AR technology is becoming mature enough to support a variety of collaboration scenarios. However, there are still a number of open issues that need further research. One major issue concerns the presence of remote users and how they can interact with the system and each other. Partial answers can be found in the areas of human-computer interaction, social interaction, affective computing, and task domain analysis. This workshop brings together researchers who are developing or interested in creating collaborative systems using AR and MR technologies. Starting with a keynote from Prof. Tetsuro Ogi from Keio University, Japan, workshop participants will discuss open research issues in relation to: Case studies using MR/AR for collaboration; Tools for building collaborative MR/AR systems; Effects of MR/AR on trust, presence, and coordination; Interaction models for collaboration in MR/AR; Tools for collaboration in MR/AR; Collaboration awareness in MR/AR. The goal is to build a picture of current and prior research on collaboration in AR and MR, as well as set up a common research agenda for work going forward. This, in turn, can be used to grow the research community.","","978-1-4673-8471-1","10.1109/ISMARW.2015.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344745","","Collaboration;Augmented reality;Conferences;Australia;Security;Manuals","augmented reality;groupware","collaboration in mediated and augmented reality;CiMAR;collaborative tools;teleconferencing technologies;telepresence technologies;video conferencing;spatial cues;AR technologies;MR technologies;collaborative task;assembly tasks;MR systems;collaborative design tasks;shared visual feedback;collaborative AR applications;Studierstube system;face-to-face presentations;virtual 3D scientific data;WearCom;remote users;virtual avatars;indoor AR users;shared annotations;crime scene investigation;distributed situational awareness;cross-organisational teams;security domain;tablet-based system;touchscreen interface;remote maintenance;human-computer interaction;social interaction;affective computing;task domain analysis;collaborative MR/AR systems;collaboration awareness","","1","","10","IEEE","3 Dec 2015","","","IEEE","IEEE Conferences"
"Augmented Reality – Principles and Practice Tutorial","D. Schmalstieg; T. Höllerer","Inst. for Comput. Graphics, Vision Graz Univ. of Technol., Graz, Austria; Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","xxviii","xxviii","Summary form only given. The complete presentation was not made available for publication as part of the conference proceedings.The world is becoming more complex and problem solving often requires teams of experts to work together at the same or from different locations. To support this there is a need for collaborative tools, and a variety of teleconferencing and telepresence technologies have been developed. However, most of them involve some variation of traditional video conferencing, which has limitations, such as not being able to effectively convey spatial cues or share the user's task space. This workshop will focus on how these limitations can be overcome by using Mixed Reality (MR) technology, leading to the development of radically new types of collaborative experiences. The target audience includes everyone with an interest in developing AR applications, academic and industrial professionals and students alike, from beginner level onwards. They will receive a thorough overview of AR technology illustrated with many practical examples. A background in computer graphics and computer vision will be useful, but is not strictly necessary. The tutorial will be conducted with a mixture of slide presentation, video clips and live demonstrations. Audience members will be engaged in an active dialog and will be able to ask questions at any time during the tutorial. Participants will learn a broad foundation of the components and terminology used in developing AR on smartphones, so they can perform their own investigations. They will also gain appreciation for what is currently possible and what isn't, and what to expect from future research.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836436","","Tutorials;Augmented reality;Electronic mail;Problem-solving","augmented reality;computer graphics;computer vision;groupware;smart phones;teleconferencing","augmented reality;collaborative tools;teleconferencing;telepresence technologies;video conferencing;mixed reality technology;computer graphics;computer vision;smartphones","","1","","","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"A Study on the Icon and Layout Design of Device UI in Augmented Reality","D. Liu; J. W. Park","The graduate school of Advanced Imaging Science, Multimedia & Film, Chung-Ang University, Seoul, South Korea; The graduate school of Advanced Imaging Science, Multimedia & Film, Chung-Ang University, Seoul, South Korea","2019 2nd World Conference on Mechanical Engineering and Intelligent Manufacturing (WCMEIM)","20 Feb 2020","2019","","","245","248","As an new emerging design field, the user interface design of the augmented reality device has many characteristics that distinguish it from the design of former electronic device interface in the form of the expression and interaction. In this paper, it takes the user experience as the center to analyze the device user interface in augmented reality environment and to summarize the skeuomorphic and flat design features of the user interface icons during the interaction with the augmented reality product, as well as the impact of the fixed layout and floating layout of the interface on the user experience, and thus to provide reference for the design and application of the user interface of the augmented reality device.","","978-1-7281-5045-1","10.1109/WCMEIM48965.2019.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004102","user experience;augmented reality;device UI","Layout;Conferences;Mechanical engineering;Manufacturing;Augmented reality","augmented reality;graphical user interfaces","user interface design;augmented reality device;electronic device interface;user experience;device user interface;augmented reality environment;skeuomorphic design features;flat design features;user interface icons;augmented reality product;fixed layout;floating layout;device UI;skeuomorphic features","","1","","8","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"ARMLAAPPS: Augmented Reality Application in Microeconomics","D. F. Ali; N. Johari; M. Omar; M. S. Sunar","School of Education, Faculty of Social Sciences and Humanities, Universiti Teknologi Malaysia, Johor, Malaysia; School of Education, Faculty of Social Sciences and Humanities, Universiti Teknologi Malaysia, Johor, Malaysia; School of Education, Faculty of Social Sciences and Humanities, Universiti Teknologi Malaysia, Johor, Malaysia; Institute of Human Centered Engineering, Universiti Teknologi Malaysia, Johor, Malaysia","2020 6th International Conference on Interactive Digital Media (ICIDM)","4 Feb 2021","2020","","","1","5","Augmented Reality (AR) is a technology that combines both virtual and real environments simultaneously. It is designed to let users experience activities in a way close to real-world experience within a safe environment. It can also supplement the difficult information presented in a conventional approach to enhance users' understanding of the complex concept. It has been used widely in various fields due to the effectiveness of this technology. However, the application of AR is scarcely explored, especially for the Microeconomics field. Therefore, this study aims to develop and investigate augmented reality application development to enhance students' visualization skills in Microeconomic courses. Through this study, a mobile augmented reality application called Augmented Reality Mobile Learning Apps (ARMLAAPPS) was developed to give an interactive learning experience that can enhance students' visualization skills and help students learn more efficiently and in a more flexible way. After the development process, the evaluation of ARMLAAPPS is conducted to identify the effectiveness of the ARMLAAPPS in enhancing visualization skills among Microeconomics students in higher institutions. Based on the results, this study has successfully developed the ARMLAAPPS, and it has proven to be effective in improving students' visualization when learning Microeconomics.","","978-1-7281-4928-8","10.1109/ICIDM51048.2020.9339660","Ministry of Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9339660","augmented reality;microeconomics;visualization skills;mobile learning;higher institutions","Visualization;Three-dimensional displays;Microeconomics;Media;User experience;Augmented reality","augmented reality;computer aided instruction;mobile computing","mobile augmented reality application;Augmented Reality Mobile Learning Apps;ARMLAAPPS;interactive learning experience;help students;visualization skills;Microeconomics students;learning Microeconomics;virtual environments;real environments;real-world experience;safe environment;difficult information;users;complex concept;Microeconomics field;augmented reality application development;Microeconomic courses","","","","13","IEEE","4 Feb 2021","","","IEEE","IEEE Conferences"
"Augmented Reality Serious Games for Smart Physical Rehabilitation","M. Gaspar; O. Postolache; J. Monge; J. Mendes","ISCTE-Instituto Universitário de Lisboa and Instituto de Telecomunicações, Lisbon, Portugal; ISCTE-Instituto Universitário de Lisboa and Instituto de Telecomunicações, Lisbon, Portugal; ISCTE-Instituto Universitário de Lisboa and Instituto de Telecomunicações, Lisbon, Portugal; FEUP, Porto, Portugal","2023 13th International Symposium on Advanced Topics in Electrical Engineering (ATEE)","28 Apr 2023","2023","","","1","6","In this paper, are presented the advantages that augmented reality can give in a Stroke rehabilitation recovery process comparing traditional rehabilitation. Thus the work focuses on an Augmented Reality system specifically developed and designed for physical rehabilitation and Several Augmented Reality games were developed for Meta Quest platform that provides parameters for health professional to extract information about rehabilitation process outcomes. Additionally, two different Applications were developed to be used by a physiotherapist and a patient with the main purpose of better interaction between both. These applications provides essential information so that the interaction and performance of augmented reality games is carried out. Validation results of the system with several volunteers are also included in the paper.","2159-3604","979-8-3503-3193-6","10.1109/ATEE58038.2023.10108178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108178","Stroke;Physical Rehabilitation Process;Augmented Reality Serious Game;Meta Quest;mobile APP","Electrical engineering;Stroke (medical condition);Serious games;Data mining;Augmented reality","augmented reality;computer games;patient rehabilitation;serious games (computing)","augmented reality games;Augmented Reality serious games;Augmented Reality system;Meta Quest platform;rehabilitation process outcomes;smart physical rehabilitation;Stroke rehabilitation recovery process;traditional rehabilitation","","","","12","IEEE","28 Apr 2023","","","IEEE","IEEE Conferences"
"The Effect of Attention Guidance and the Potential of Cinmatic Augmented Reality in Narrative Immersion","J. S. Kao; K. Kao","Dept. of Game Development, Inland Norway University of Applied Sciences, Hamar, Norway; YBL Education Foundation of Management, Taipei, Taiwan","2022 IEEE Games, Entertainment, Media Conference (GEM)","20 Jan 2023","2022","","","1","5","This paper discusses issues relate to narrative immersion in cinematic extended reality (CXR). System immersion built by reality technologies forms the fundamental feature of the new medium of storytelling. Attention guidance is widely applied in CXR to maintain the flow of narrative immersion. The authors review several attention guidance approaches and suggest diegetic cue is the preferred method in CXR since it embeds in the scene and less disturbs the storytelling. A framework is proposed in this paper to illustrate pathways of Cinematic Augmented Reality (CAR) and Cinematic Virtual Reality (CVR) to achieve narrative immersion. The authors conclude that CAR has more advantages in fulfilling narrative immersion than CVR due to viewers' reinforced involvement in CAR, suggesting the value of exploring the potential of CAR as a storytelling medium.","2766-6530","978-1-6654-6138-2","10.1109/GEM56474.2022.10017977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017977","attention guidance;augmented reality;cinematic virtual reality;diegetic cues;narrative immersion","Extended reality;Entertainment industry;Games;Media;Automobiles;Augmented reality","augmented reality;computer games;multimedia computing","attention guidance approaches;CAR;cinematic augmented reality;cinematic extended reality;cinematic virtual reality;CXR;narrative immersion;storytelling medium","","","","38","IEEE","20 Jan 2023","","","IEEE","IEEE Conferences"
"An introduction to Augmented Reality with applications in aeronautical maintenance","M. Hincapié; A. Caponio; H. Rios; E. González Mendívil","Instituto Tecnològico y de Estudios Superiores de Monterrey, Monterrey, Nuevo Leon, Mexico; Instituto Tecnològico y de Estudios Superiores de Monterrey, Monterrey, Nuevo Leon, Mexico; Instituto Tecnològico y de Estudios Superiores de Monterrey, Monterrey, Nuevo Leon, Mexico; Instituto Tecnològico y de Estudios Superiores de Monterrey, Monterrey, Nuevo Leon, Mexico","2011 13th International Conference on Transparent Optical Networks","1 Aug 2011","2011","","","1","4","Augmented Reality is a breakthrough technology that could considerably ease execution of complex operations. Augmented Reality mixes virtual and actual reality, making available to the user new tools to ensure efficiency in the transfer of knowledge for several processes and in several environments. Various solutions based on Augmented Reality have been proposed by the research community: particularly in maintenance operations Augmented Reality tools have offered new perspectives and have promised dramatic improvements. On the other side Augmented Reality is an extremely demanding technology and, at the present day, it is still affected by serious flaws that undermine its implementations in the industrial context. This paper presents examples of Augmented Reality applications and shows the feasibility of Augmented Reality solutions in maintenance tasks, underlining advantages it could introduce. At the same time the principal flaws of Augmented Reality are commented and possible lines of investigation are suggested.","2161-2064","978-1-4577-0882-4","10.1109/ICTON.2011.5970856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5970856","Augmented Reality;Maintenance operations","Maintenance engineering;Augmented reality;Hardware;Training;Manufacturing;Cameras;Industries","aerospace computing;aircraft maintenance;augmented reality","augmented reality;aeronautical maintenance;virtual reality;actual reality","","39","1","14","IEEE","1 Aug 2011","","","IEEE","IEEE Conferences"
"Breast3D: An Augmented Reality System for Breast CT and MRI","B. Allison; X. Ye; F. Janan","School of Computer Science, University of Lincoln, Lincoln, UK; School of Computer Science, University of Lincoln, Lincoln, UK; School of Computer Science, University of Lincoln, Lincoln, UK","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","247","251","Adoption of Virtual Reality (VR), Augmented Reality (AR) and Mixed Reality (MR) - known collectively as Extended Reality (XR) devices has been rapidly increasing over recent years. However, the focus of XR research has shown a lack of diversity in solutions to the problems within medicine, with it being predominantly focused in augmenting surgical procedures. Whilst important, XR applied to aiding medical diagnosis and surgical planning is relatively unexplored. In this paper we present a fully functional mammographic image analysis system, Breast3D, that can reconstruct MRI and CT scan data in XR. With breast cancer Breast Imaging-Reporting and Data System (BI-RADS) risk lexicon, early detection and clinical workflow such as Multi-disciplinary team (MDT) meetings for cancer in mind, our new mammography visualization system reconstructs CT and MRI volumes in a real 3D space. Breast3D is built upon the past literature and inspired from research for diagnosis and surgical planning. In addition to visualising the models in MR using the Microsoft HoloLens, Breast3D is versatile and portable to different XR head-mounted displays such as HTC Vive. Breast3D demonstrates the early potential for XR within diagnostics of 3D mammographic modalities, an application that has been proposed but until now has not been implemented.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319058","Extended Reality;Mixed Reality;Augmented Reality;Breast Cancer;Computer Aided Diagnosis","Breast;Three-dimensional displays;Breast cancer;X reality;Magnetic resonance imaging;Two dimensional displays;Image reconstruction","augmented reality;biological organs;biomedical MRI;cancer;computerised tomography;helmet mounted displays;image reconstruction;mammography;medical image processing","mammography visualization system;HTC Vive;Microsoft HoloLens;XR head-mounted displays;CT scan data;fully functional mammographic image analysis system;XR research;Extended Reality devices;MRI;breast CT;Augmented Reality System;surgical planning;Breast3D","","","","23","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"An Augmented Reality Application Using Graphic Code Markers","B. Patrão; L. Cruz; N. Gonçalves","Institute of Systems and Robotics, University of Coimbra - Portugal; Institute of Systems and Robotics, University of Coimbra - Portugal; Portuguese Mint and Official Printing Office, University of Coimbra - Portugal","2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","17 Jan 2019","2018","","","193","194","This paper lies on presenting applications of the Graphic Code exploiting its large-scale information coding capabilities applied to Augmented Reality. Machine Readable Codes (MRCs) are largely used for many reasons, such as, product tagging or to hold URLs. The recently introduced Graphic Code differs from classical MRCs because it is fully integrated with images for aesthetic control. Furthermore, it is able to code large amount of information and, for that reason, it can store different types of models for applications that are unusual for classical MRCs. The main advantage of using our approach as an Augmented Reality marker is the possibility of creating generic applications that can read and decode these Graphic Code markers which may contain 3D models and complex scenes encoded in it. Additionally, the resulting marker has strong aesthetic characteristics associated to it.","","978-1-5386-9269-1","10.1109/AIVR.2018.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613663","Augmented Reality;Machine Readable Codes;Large Information Coding;Graphic Pattern;Steganography","Conferences;Artificial intelligence;Virtual reality","augmented reality;solid modelling","Machine Readable Codes;Augmented Reality marker;Graphic Code markers;Augmented Reality application","","","","2","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"First Deployments of Augmented Reality in Operating Rooms","N. Navab; T. Blum; L. Wang; A. Okur; T. Wendler","Institute for Computer-Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Institute for Computer-Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Institute for Computer-Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Institute for Computer-Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Technical University of Munich, Germany","Computer","29 Jun 2012","2012","45","7","48","55","Researchers are developing augmented reality visualization systems to provide accessible and user-friendly interfaces for medical intervention and patient information systems. A related video can be seen here: http://youtu.be/kifj0ZP4Mos. It shows how augmented reality visualization systems can provide accessible and user-friendly interfaces for medical intervention and patient information systems.","1558-0814","","10.1109/MC.2012.75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165241","augmented reality;computer-assisted intervention","Single photon emission computed tomography;Surgery;Augmented reality;Image reconstruction;Three dimensional displays;Medical diagnostic imaging;Visualization;Computer aided diagnosis;User interfaces","augmented reality;medical computing;user interfaces","first deployments;operating rooms;augmented reality visualization systems;user-friendly interfaces;medical intervention;patient information systems","","78","3","13","IEEE","6 Mar 2012","","","IEEE","IEEE Magazines"
"Augmented Reality as Mirror Therapy in Post Stroke Treatment","S. da Costa Alves Basílio; A. L. N. Ferreira; D. G. do Nascimento; R. S. N. Silva","Antony Leme Novais Ferreira, Davi Guerra do Nascimento e Rafaela Satil Neiva Silva; CEFET-MG; CEFET-MG; CEFET-MG","2018 20th Symposium on Virtual and Augmented Reality (SVR)","19 Aug 2019","2018","","","220","224","After a stroke, a limb may present motor deficits that lead to daily activities limitation and functional disabilities, restricting the patient's social interaction, leading to insolation and even depression due the inability to perform basic tasks. One of the means of treatment for this deficit is the mirror therapy that seeks the activation of neural networks through an optical illusion between a good and an affected limb. This work presents a technological approach for the mirror therapy application. Here we propose, explain and discuss the use of augmented reality as mirror therapy in the stroke treatment. Using a smart phone camera we replace a compromised member by a virtual that makes specific movements. In this way, we seek to create an efficient therapeutic tool that is easily accessible through a cellular device, providing resource for the practice of this therapy and speeding up the motor and functional recovery of patients.","","978-1-7281-0604-5","10.1109/SVR.2018.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802400","Augmented Reality;Mirror Therapy;Stroke;Physiotherapy","","augmented reality;cameras;medical disorders;neural nets;patient rehabilitation;patient treatment;smart phones;virtual reality","motor recovery;functional recovery;cellular device;efficient therapeutic tool;smart phone camera;optical illusion;neural networks;mirror therapy application;affected limb;functional disabilities;daily activities limitation;motor deficits;post stroke treatment;augmented reality","","1","","0","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"From boards to augmented reality learning","W. F. Maqableh; M. S. Sidhu","Department of Graphics and Multimedia, University of Tenaga National, Kajang, Selangor Darul Ehsan, Malaysia; Department of Graphics and Multimedia, University of Tenaga National, Kajang, Selangor Darul Ehsan, Malaysia","2010 International Conference on Information Retrieval & Knowledge Management (CAMP)","20 May 2010","2010","","","184","187","Over the last years there have been many experiments and innovations in the field of education and training to improve the educational learning theory regarding knowledge delivery. From traditional learning tools to virtual education, different technologies have played great roles at different times. Augmented Reality and its supporting technologies have emerged in the field of education to adopt many educational applications such as mathematics, physics, chemistry, history and in many other domains. In this paper we review the use of these technologies and how it affects in the educational process.","","978-1-4244-5650-5","10.1109/INFRKM.2010.5466920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5466920","Augmented reality;virtual reality;mixed reality;interface;education;interactivity","Augmented reality;Virtual reality;Computer displays;Educational technology;Physics education;Computer interfaces;Graphics;Chemical technology;Computer architecture;Space technology","augmented reality;computer aided instruction","augmented reality learning;educational learning theory;knowledge delivery;virtual education","","8","","15","IEEE","20 May 2010","","","IEEE","IEEE Conferences"
"Comparing Distance Judgments in Real and Augmented Reality","J. K. Stefanucci; S. Creem-Regehr; B. Bodenheimer","University of Utah, USA; University of Utah, USA; University of Utah, USA","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","82","86","There is a growing interest in using augmented reality for simulation and training across fields such as medicine, military, and others. An important question to address is whether distances to virtual objects displayed in augmented reality are perceived accurately and similarly to the real world. Current augmented reality (AR) devices, such as the HoloLens, provide an advantage over virtual reality with regard to depth perception because they display virtual objects in a real world context that preserves depth cues of the real world. However, these AR devices limit real world experience because they restrict the field of view (FOV), add weight, and may be cumbersome to wear over time. In the current study, we investigated whether distance judgments were similar when objects were presented in the real world or in augmented reality (via the HoloLens version 1). All participants wore the device to control for the effect of weight on distance judgments. We also tested whether reducing cues to depth by asking participants to view the targets both monocularly and binocularly affected judgments. Participants blind walked to a cube placed at varying distances in both a condition where the cube was viewed monocularly and binocularly. There was no main effect for viewing in augmented reality vs. the real world. But, viewing condition (either monocular or binocular) did interact with group such that viewing monocularly resulted in greater underestimation of farther distances for AR targets compared to real world targets. These findings provide support for the notion that distance estimations to real and augmented reality objects can be similar, given binocular viewing conditions. Our study suggests that AR may be well suited for training and simulation applications that utilize the range of distances tested herein.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00026","Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585817","Augmented reality;Distance perception;Perceptual fidelity","Training;Solid modeling;Multimedia systems;Computational modeling;Estimation;Augmented reality","augmented reality;helmet mounted displays;stereo image processing;three-dimensional displays;virtual reality;visual perception","distance judgments;virtual objects;current augmented reality devices;virtual reality;world context;world experience;binocularly affected judgments;varying distances;augmented reality vs;world targets;augmented reality objects;given binocular viewing conditions","","1","","20","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"The Impact of Virtual Reality, Augmented Reality, and Interactive Whiteboards on the Attention Management in Secondary School STEM Teaching","M. Erofeeva; N. O. Klowait","Center for Sociological Research, Russian Presidential Academy of National Economy and Public Administration (RANEPA), Moscow, Russia; Center for Innovative Social Research, Russian Presidential Academy of National Economy and Public Administration (RANEPA), Moscow, Russia","2021 7th International Conference of the Immersive Learning Research Network (iLRN)","28 Jun 2021","2021","","","1","5","Today, technologies like interactive whiteboards, augmented and virtual reality serve as instructional aids to facilitate interactive learning. The aim of this paper is to study how the use of such technologies impacts the dynamics of classroom attention management. Employing a multimodal conversation-analytic framework, we analyze video recordings of the first encounters with interactive whiteboards, augmented reality and virtual reality across twelve in-person classroom lessons set in four Russian secondary schools. This paper highlights how the teacher, faced with a breakdown of regular channels for managing attention (such as mutually-orientable gaze), uses their voice and body to facilitate the temporal coordination of student contributions, maintain focus on a given classroom activity, and visibly monitor classroom dynamics. The findings suggest means to alleviate tensions between new and old teaching methods, and provide further evidence on the need for a granular vocabulary for the analysis of body-orientation in a classroom context.","","978-1-7348995-2-8","10.23919/iLRN52045.2021.9459318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459318","classroom interaction studies;augmented reality;virtual reality;multimodality;attention management","Vocabulary;Electric breakdown;Educational technology;Augmented reality;Video recording;Monitoring","augmented reality;computer aided instruction;interactive systems;STEM;teaching","classroom dynamics;classroom activity;managing attention;Russian secondary schools;in-person classroom lessons;multimodal conversation-analytic framework;classroom attention management;interactive learning;secondary school STEM teaching;interactive whiteboards;augmented reality;virtual reality","","2","","21","","28 Jun 2021","","","IEEE","IEEE Conferences"
"Automatic determination of text readability over textured backgrounds for augmented reality systems","A. Leykin; M. Tuceryan","Department of Computer Science, Indiana University, Bloomington, USA; Department of Computer and Information Science, Purdue University, Indiana University, USA","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","224","230","This paper describes a pattern recognition approach to determine readability of text labels in augmented reality systems. In many augmented reality applications, one of the ways in which information is presented to the user is to place a text label over the area of interest. However, if this information is placed over very busy and textured backgrounds, this can affect the readability of the text. The goal of this work was to identify methods of quantitatively describing conditions under which such text would be readable or unreadable. We used texture properties and other visual features to determine if a text placed on a particular background would be readable or not. Based on these features, a supervised classifier was built that was trained using data collected front human subjects' judgment of text readability. Using a rather small training set of about 400 human evaluations over 50 heterogeneous textures the system is able to achieve a correct classification rate of over 85%.","","0-7695-2191-6","10.1109/ISMAR.2004.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383059","","Augmented reality;Layout;Pattern recognition;Humans;Computer science;Information science;Application software;Graphics;Interference;Labeling","augmented reality;text analysis;pattern recognition","automatic text readability determination;textured background;augmented reality system;pattern recognition;supervised classifier","","41","11","17","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"Towards endoscopic augmented reality for robotically assisted minimally invasive cardiac surgery","F. Devernay; F. Mourgues; E. Coste-Maniere","Chir team, Inria, Sophia Antipolis Cedex, France; Chir team, Inria, Sophia Antipolis Cedex, France; Chir team, Inria, Sophia Antipolis Cedex, France","Proceedings International Workshop on Medical Imaging and Augmented Reality","7 Aug 2002","2001","","","16","20","One of the problems tightly linked to endoscopic surgery is the fact that, because of the narrow field of view, it is sometimes quite difficult to locate the objects that can be seen through the endoscope. This is especially true in cardiac surgery, where it is difficult to not confuse two coronary arteries on a beating heart. We propose a methodology to achieve coronary localisation by augmented reality on a robotized stereoscopic endoscope. The method we propose involves five steps: making a time-variant 3D model of the beating heart using coronarography and CT-scan or MRI, calibrating the stereoscopic endoscope, reconstructing the 3D operating field, registering the operating field surface with the 3D heart model, and adding information on the endoscopic images by augmented reality. The da Vinci/sup TM/ surgical system was used for our first experiments with the Cardiac Surgery team at Hopital Europeen Georges Pompidou, Paris, France.","","0-7695-1113-9","10.1109/MIAR.2001.930258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=930258","","Minimally invasive surgery;Augmented reality;Heart;Endoscopes;Surges;Magnetic resonance imaging;Instruments;Deformable models;Robot sensing systems;Thyristors","augmented reality;surgery;medical robotics;cardiology;solid modelling;medical image processing","augmented reality;medical robots;minimally invasive cardiac surgery;endoscopic surgery;coronary arteries;da Vinci system;coronary localisation;robot stereoscopic endoscope;time-variant 3D model;coronarography;CT-scan;MRI;3D heart model","","39","1","15","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Autocalibration of an electronic compass in an outdoor augmented reality system","B. Hoff; R. Azuma","HRL Laboratories LLC, USA; HRL Laboratories LLC, USA","Proceedings IEEE and ACM International Symposium on Augmented Reality (ISAR 2000)","6 Aug 2002","2000","","","159","164","Accurate registration in an augmented reality system requires accurate trackers. An electronic compass can be a valuable sensor in an outdoor augmented reality system because it provides absolute heading estimates. However, compasses are vulnerable to distortion caused by environmental disturbances to Earth's magnetic field. These disturbances vary with geographic location and are not trivial to model. Static calibration methods exist but these require an explicit initial calibration step and do not adapt to changing distortion patterns. This paper describes in detail an autocalibration method that compensates for changing compass distortions. With minimal user input, it automatically measures and adjusts the calibration table used to correct the compass output. Autocalibration uses redundant heading information computed from rate gyroscopes. We demonstrate that autocalibration converges to solutions similar to a distortion table that was manually measured with a mechanical turntable. With autocalibration, an electronic compass can provide useful measurements even as the user walks around through areas of varying magnetic distortion.","","0-7695-0846-4","10.1109/ISAR.2000.880939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=880939","","Calibration;Distortion measurement;Augmented reality;Magnetic sensors;Sensor systems;Earth;Magnetic fields;Gyroscopes;Mechanical variables measurement;Area measurement","augmented reality;calibration;compasses;image registration;gyroscopes;user interfaces","electronic compass autocalibration;outdoor augmented reality system;image registration;sensor;environmental disturbance;Earth;magnetic field;geographic location;compass distortions","","19","18","8","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"The importance of being mobile: some social consequences of wearable augmented reality systems","S. K. Feiner","Department of Computer Science, Columbia University, New York, NY, USA","Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99)","6 Aug 2002","1999","","","145","148","What are the consequences of mobility for augmented reality? This paper explores some of the issues that I believe will be raised by the development and future commonplace adoption of mobile, wearable, augmented reality systems. These include: social influences on tracking accuracy, the importance of appearance and comfort, an increase in collaborative applications, integration with other devices, and implications for personal privacy.","","0-7695-0359-4","10.1109/IWAR.1999.803815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=803815","","Augmented reality;Wearable computers;Biomedical monitoring;Global Positioning System;Computer science;Computer graphics;Collaboration;Privacy;Mobile computing;Manuals","augmented reality;mobile computing;portable computers;social aspects of automation;data privacy;ergonomics","wearable augmented reality systems;mobility;social influences;tracking accuracy;appearance;comfort;collaborative applications;personal privacy;mobile computing;wearable computing","","17","","17","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Photo-based Industrial Augmented Reality application using a single keyframe registration procedure","P. Georgel; S. Benhimane; J. Sotke; N. Navab","CAMP, Technical University of München, Germany; METAIO; CAMP, Technical University of München, Germany; CAMP, Technical University of München, Germany","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","187","188","In the recent years, many industrial augmented reality (IAR) applications are shifting from video to still images to create a mixed view. This new type of application is called photo-based augmented reality. In order to guarantee the success of these applications, a simple and efficient registration method is required. We present a new method to register an image to a CAD model using a single keyframe. This registration is based on sparse 3D information from the model linked to the keyframe during its offline registration. We demonstrate this method in our in-house IAR software for visual inspection and documentation: VID.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336468","","Augmented reality;Matrix decomposition;Transmission line matrix methods;Cameras;Documentation;Registers;Inspection;Application software;Head;Displays","augmented reality;CAD;image registration;industrial engineering;production engineering computing;solid modelling","photo-based industrial augmented reality;single keyframe registration procedure;still image;sparse 3D information;CAD model","","4","","7","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Design and Calibration of an Augmented Reality Haploscope","N. Phillips; K. Massey; M. S. Arefin; J. E. Swan",Mississippi State University; Mississippi State University; Mississippi State University; Mississippi State University,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","75","76","Most augmented reality (AR) research is performed with commercially-available displays. However, these displays have unadjustable mechanical and optical properties, which limit the experimental questions that can be asked. In order to ask certain questions, it becomes necessary to build a custom display, using off-the-shelf optical components. In the field of visual perception, such devices are often developed, and are called haploscopes. In this paper, we describe the mechanical design of an AR haploscope, which can present virtual objects seen in augmented reality. In order to make accurate measurements, the haploscope must be carefully calibrated, but this calibration is quite difficult. Therefore, this abstract contributes a description of an AR haploscope, and outlines calibration procedures.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699263","","Optical imaging;Calibration;Augmented reality;Lenses;Adaptive optics;Monitoring","augmented reality;calibration;optical engineering computing;visual perception","optical properties;experimental questions;custom display;off-the-shelf optical components;visual perception;mechanical design;AR haploscope;augmented reality haploscope;commercially-available displays;unadjustable mechanical properties;calibration procedures;virtual objects","","1","","9","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Digital map based pose improvement for outdoor Augmented Reality","Joonsuk Park; Donghyun Lee; Jun Park","Hongik University, Seoul, Korea; Hongik University, Seoul, Korea; Hongik University, Seoul, Korea","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","309","310","With popularization of smart phones, needs for location based services (LBS), which is one of the most promising Augmented Reality applications, increased rapidly. However, accuracy of most commercially available Global Positioning Systems (GPS) is below levels for providing practically meaningful location based information. Especially when there are high building structures nearby, GPS location measurements are known to be erroneous and deviant. In this paper, we present a computer vision based method for improving user's position and orientation for outdoor Augmented Reality with initial values obtained from a GPS and a digital compass. Given a digital map, our goal was to determine corresponding buildings visible in the camera image and improve the user location and orientation. In average, our method improved (14.4m, 3.3m) in position and 2.8 degrees in orientation. Our method is suitable for mobile services in urban environments where tall buildings degrade GPS signals.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402588","GPS;outdoor tracking;location based service;depth map","Buildings;Global Positioning System;Image edge detection;Augmented reality;Compass;Cameras;Accuracy","augmented reality;cameras;cartography;computer vision;Global Positioning System;mobile computing;smart phones;structural engineering","digital map;pose improvement;outdoor augmented reality;smart phone;location based service;LBS;Global Positioning System;location based information;building structure;GPS location measurement;computer vision;user position;digital compass;camera image;user location;user orientation;mobile service;urban environment;tall building;GPS signal","","1","","9","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"An Approach for Using Augmented Reality to PSEN","G. A. Ferreira; M. M. V. de Paula","IMC (Instituto de Matemática e Computação), Universidade Federal de Itajubá, Itajubá, Brasil; IMC (Instituto de Matemática e Computação), Universidade Federal de Itajubá, Itajuba, Brazil","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","185","190","The augmented reality, as an educational tool, does not represent an innovation, but, for PSEN (Pupils with Special Educational Needs) it must be built for does not represent an obstacle, but an inclusive resource and catalyst for the learning process. This paper will describe the strategy used for develop an application based in augmented reality for PSEN.","","978-0-7695-5001-5","10.1109/SVR.2013.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655777","Realidade Aumentada;PNEE","Software;Visualization;Manuals;Augmented reality;Three-dimensional displays;Cameras;Materials","augmented reality;computer aided instruction;handicapped aids","learning process;pupils with special educational needs;PSEN;educational tool;augmented reality","","","","14","IEEE","7 Nov 2013","","","IEEE","IEEE Conferences"
"Exploring the Use of Augmented Reality in a Kinesthetic Learning Application Integrated with an Intelligent Virtual Embodied Agent","M. Z. Iqbal; E. Mangina; A. G. Campbell","School of Computer Science, University College Dublin, Dublin, Ireland; School of Computer Science, University College Dublin, Dublin, Ireland; School of Computer Science, University College Dublin, Dublin, Ireland","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","12","16","Technology in education is rapidly changing the way that students learn. This allows for the creation of learning tools that provide better interaction, creative engagement and adaptability to a learner. Augmented Reality (AR) is one of these emerging technologies which can facilitate the development of new learning tools. AR has successfully been proven to allow new types of learning pedagogies by providing human-centered learning environments. In particular, the pedagogical approach of Kinesthetic learning or ”Learning by Doing” has not been explored in great detail in combination with Augmented Reality. This approach is to physically act out an activity to aid in the learning process and has been previously proven as one of the most successful approaches. For a successful application of this pedagogy, the student must get precise feedback and be guided through a process, thus some form of intelligent guide needs to be actively monitoring the learning environment. This paper presents the exploration of this concept through the presentation of an initial prototype system that was developed and implemented based on an adaptive learning methodology within an AR application, with the prospect that in the future will use intelligent agents.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951995","Human-centered-computing;Interaction-paradigms—Mixed-/-Augmented-reality;Applied-computing—E-learning;Applied-computing—Interactive-learning-environments","","augmented reality;computer aided instruction;human computer interaction;multi-agent systems;virtual reality","Augmented Reality;learning process;adaptive learning methodology;intelligent agents;kinesthetic learning;intelligent virtual embodied agent;learning tools;pedagogical approach;human-centered learning environments;student learning","","5","","39","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"The Impact of Focus and Context Visualization Techniques on Depth Perception in Optical See-Through Head-Mounted Displays","A. Martin-Gomez; J. Weiss; A. Keller; U. Eck; D. Roth; N. Navab","Department of Informatics, Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Munich, Germany; Department of Informatics, Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Munich, Germany; Department of Informatics, Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Munich, Germany; Department of Informatics, Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Munich, Germany; FAU Erlangen-Nürnberg, Erlangen, Germany; Department of Informatics, Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Munich, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2022","2022","28","12","4156","4171","Estimating the depth of virtual content has proven to be a challenging task in Augmented Reality (AR) applications. Existing studies have shown that the visual system makes use of multiple depth cues to infer the distance of objects, occlusion being one of the most important ones. The ability to generate appropriate occlusions becomes particularly important for AR applications that require the visualization of augmented objects placed below a real surface. Examples of these applications are medical scenarios in which the visualization of anatomical information needs to be observed within the patient's body. In this regard, existing works have proposed several focus and context (F+C) approaches to aid users in visualizing this content using Video See-Through (VST) Head-Mounted Displays (HMDs). However, the implementation of these approaches in Optical See-Through (OST) HMDs remains an open question due to the additive characteristics of the display technology. In this article, we, for the first time, design and conduct a user study that compares depth estimation between VST and OST HMDs using existing in-situ visualization methods. Our results show that these visualizations cannot be directly transferred to OST displays without increasing error in depth perception tasks. To tackle this gap, we perform a structured decomposition of the visual properties of AR F+C methods to find best-performing combinations. We propose the use of chromatic shadows and hatching approaches transferred from computer graphics. In a second study, we perform a factorized analysis of these combinations, showing that varying the shading type and using colored shadows can lead to better depth estimation when using OST HMDs.","1941-0506","","10.1109/TVCG.2021.3079849","Bayerische Forschungsstiftung(grant numbers:DOK-178-17); Deutsche Forschungsgemeinschaft(grant numbers:NA-620/33-2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429918","Augmented reality;perception;depth estimation;visualization techniques;human computer interaction;design and evaluation methods;user studies","Visualization;Estimation;User interfaces;Image color analysis;Augmented reality;Rendering (computer graphics);Head-mounted displays;Human computer interaction","augmented reality;data visualisation;helmet mounted displays;medical image processing;object tracking;three-dimensional displays;visual perception","anatomical information;appropriate occlusions;AR applications;augmented objects;Augmented Reality applications;chromatic shadows;context visualization techniques;depth estimation;depth perception tasks;display technology;existing in-situ visualization methods;hatching approaches;important ones;medical scenarios;multiple depth;occlusion;Optical See-Through HMDs;OST displays;OST HMDs;patient;Video See-Through Head-Mounted Displays;virtual content;visual properties;visual system;VST","Humans;Computer Graphics;User-Computer Interface;Equipment Design;Augmented Reality;Depth Perception","2","","59","CCBY","12 May 2021","","","IEEE","IEEE Journals"
"Research on Robot Remote Control System Based on Augmented Reality","J. Si","Shijiazhuang Medical College, Shijiazhuang, China","2022 International Conference on Electronics and Devices, Computational Science (ICEDCS)","2 Jan 2023","2022","","","412","414","The application of virtual reality technology makes the development of remote control system, augmented reality technology is the expansion of virtual reality technology, the computer-generated virtual objects superimposed into the real world perceived by users. This paper introduces and implements a robot remote control system, explains its structure and key technology. The experimental and operation results show that the system can effectively improve human-computer interaction capability and improve the accuracy of remote control.","","978-1-6654-5541-1","10.1109/ICEDCS57360.2022.00095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9997069","augmented;reality;virtual reality;robot;simulation;remote control","Human computer interaction;Scientific computing;Remote control;Robots;Augmented reality","augmented reality;control engineering computing;human computer interaction;human-robot interaction;telerobotics","augmented reality;computer-generated virtual objects;human-computer interaction;robot remote control system;virtual reality","","","","6","IEEE","2 Jan 2023","","","IEEE","IEEE Conferences"
"Evaluation of the Augmented Reality Educational Application for the 2nd cycle of primary school","L. O. Lopes; V. Gonçalves","Escola Superior de Educação, Instituto Politécnico de Bragança, Bragança, Portugal; Centro de Investigação em Educação Básica, Instituto Politécnico de Bragança, Bragança, Portugal","2021 16th Iberian Conference on Information Systems and Technologies (CISTI)","12 Jul 2021","2021","","","1","6","The use of augmented reality (AR) technology has been shown to be useful in several areas of human activity. In this sense, this study aims to understand whether these AR technologies can contribute to inform and educate children of the 2nd cycle of primary school about the outbreak by COVID-19. For this purpose, in addition to the systematic review of the literature of the last 5 years on AR, a case study was carried out with a group of experts who evaluated an AR application using Metaverse Studio. The study showed a very favorable response in relation to the use of these applications in the teaching-learning context, namely in basic education, confirming that it can improve the cognitive capacity of children, allowing them to retain knowledge and develop creative and autonomous learning after the experience of using this technology.","2166-0727","978-989-54659-1-0","10.23919/CISTI52073.2021.9476454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476454","augmented reality;primary school;augmented reality technology.","COVID-19;Systematics;Education;Augmented reality;Information systems","augmented reality;computer aided instruction;diseases;epidemics;medical computing;teaching","augmented reality educational application;primary school;human activity;AR technologies;COVID-19 outbreak;systematic literature review;AR application;Metaverse Studio;teaching-learning context;basic education;children cognitive capacity;knowledge retention;knowledge retention;autonomous learning;creative learning","","6","","0","","12 Jul 2021","","","IEEE","IEEE Conferences"
"An observational study of user interaction in collaborative learning environment by using Augmented Reality","W. Matcha; D. R. A. Rambli","Computer and Information Sciences Department, Universiti Teknologi Petronas, Tronoh, Perak, Malaysia; Computer and Information Sciences Department, Universiti Teknologi Petronas, Tronoh, Perak, Malaysia","2011 International Conference on User Science and Engineering (i-USEr )","13 Feb 2012","2011","","","178","182","This paper presents the observational result of a preliminary study which aim to investigate the user interaction for collaborative Augmented Reality (AR) interface. AR, a new technology for educators, indicates potential to support individual learning. So far, however, there has been less research works conducted to investigate the potential of AR in collaborative learning. This study aims to fulfill that gap. Several students from different fields have been recruited as volunteers in this study. The observational results show that AR could support various types of communication cues and even its space can be used as a shared point of reference to create a mutual understanding in collaborative learning environment. These results at final point, could strengthen the conjectures that AR can be used to support a collaborative learning.","","978-1-4577-1655-3","10.1109/iUSEr.2011.6150561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6150561","augmented reality;computer-supported collaborative learning;collaborative augmented reality;augmented reality interface","Collaboration;Collaborative work;Augmented reality;Monitoring;Speech;Educational institutions","augmented reality;computer aided instruction;groupware;human computer interaction","user interaction;collaborative learning environment;collaborative augmented reality interface;individual learning","","1","","19","IEEE","13 Feb 2012","","","IEEE","IEEE Conferences"
"Coupling digital and physical worlds in an AR magic show performance: Lessons learned","A. Carreras; C. Sora","Institut Universitari De l'Audiovisual, Universitat Pompeu Fabra, Spain; Roc Boronat, Barcelona, Spain","2009 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media and Humanities","17 Nov 2009","2009","","","25","28","¿Magic for a Pixeloscope¿ is a one hour show conceived to be represented in a theater scenario that merges mixed and augmented reality (MR/AR) and full-body interaction with classical magic to create new tricks. The show was conceived by an interdisciplinary team composed by a magician, two interaction designers, a theater director and a stage designer. The magician uses custom based hardware and software to create new illusions which are a starting point to explore new language for magical expression. In this paper we introduce a conceptual framework used to inform the design of different tricks; we explore the design and production of some tricks included in the show and we describe the feedback received on the world premiere and some of the conclusions obtained.","2381-8360","978-1-4244-5508-9","10.1109/ISMAR-AMH.2009.5336729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336729","Interaction design;magic;mixed reality;augmented reality;full-body interaction;magical expression;performance;interactive theater;H.5.1 [Multimedia Information Systems];Artificial;augmented;and virtual realities;J.5. [Arts and Humanities];Performing arts;J.7. [Computers in other systems];Real time","Virtual reality;Art;Augmented reality;History;Digital control;Communication system control;Hardware;Production;Feedback;Multimedia systems","augmented reality;humanities","digital worlds;physical worlds;AR magic show performance;Magic for a Pixeloscope;augmented reality;mixed reality;full-body interaction;magician;interaction designers;theater director;stage designer;custom based hardware;custom based software;world premiere","","2","","18","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"SaaS Framework for Library Augmented Reality Application","A. A. G. Alex; S. Jegatha; J. G. Jayanthi; S. A. Rabara","Qanawat L.L.C, Dubai; Dept. of MCA, Dhanalakshmi Srinivasan Engg. College, Perambalur, Tamilnadu, India; Dept. of Comput. Applic., JJ.Coll. of Eng. & Tech., Tiruchirappalli, India; Dept. of Comput. Sci., St.Joseph's Coll., Tiruchirappalli, India","2014 World Congress on Computing and Communication Technologies","3 Apr 2014","2014","","","8","12","Augmented reality is an emerging technology of Virtual Reality, which has a great development and application prospects. Augmented Reality involves knowledge about sensors, image recognition, computer vision, human-computer interaction, virtual reality, and many other areas. The key technologies include displaying, registration and tracking, interactive etc. There exist a number of augmented reality applications. Most of them are able to collect the data from different servers related to the environment and traffic etc. But the softwares which address the students' issues are very less or in the discussion stages. Hence in this paper, we planned to focus on one of the major issue of automating Library application with the augmented reality software and we propose architecture for accessing the library books meta-data.","","978-1-4799-2877-4","10.1109/WCCCT.2014.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755095","SaaS;Augmented reality;OCR;Image Processing","Augmented reality;Libraries;Servers;Optical character recognition software;Computer architecture;Image edge detection","augmented reality;cloud computing;library automation","SaaS framework;library augmented reality;virtual reality;augmented reality software;library books metadata","","2","","18","IEEE","3 Apr 2014","","","IEEE","IEEE Conferences"
"Augmented Reality Services Using Smart Glasses for Great Gilt-bronze Incense Burner of Baekje","Y. -S. Yoon; D. -M. Kim; J. -W. Suh","Contents Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea; College of Electrical and Computer Engineering, Chungbuk National University, Chungbuk, Korea; College of Electrical and Computer Engineering, Chungbuk National University, Chungbuk, Korea","2022 International Conference on Electronics, Information, and Communication (ICEIC)","11 Apr 2022","2022","","","1","4","In this paper, we propose an augmented reality service using smart glasses for the Great gilt-bronze incense burner of Baekje, one of the cultural heritage of Korea. The proposed service shows the augmented real world to the user by using Microsoft's HoloLens 2, which is one of smart glasses, in order to provide an augmented reality service. First, we installed a replica of the Great gilt-bronze incense burner of Baekje and the basic environment of the augmented reality service proposed by a QR code. Next, we created the augmented reality service that can provide extended experience using the Unity program and Mixed Reality Toolkit. The proposed service uses the QR code to confirm the existence of the Great gilt-bronze incense burner of Baekje and informs the start of the proposed AR service. And the proposed AR service shows the information of the Great gilt-bronze incense burner of Baekje to the audience. In addition, we provide the audience with an expanded AR experience by augmenting the four divine beasts that appear in the Great gilt-bronze incense burner into virtual objects. In this paper, we were able to confirm whether the proposed AR service using the HoloLens 2 for the Great gilt-bronze incense burner of Baekje, which is the Korean national treasure No. 287, works well.","2767-7699","978-1-6654-0934-6","10.1109/ICEIC54506.2022.9748275","Cultural Heritage Administration, National Research Institute of Cultural Heritage(grant numbers:2021A02P01-001); Korea Creative Content Agency (KOCCA)(grant numbers:R2020040045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9748275","Augmented Reality(AR) Service;Smart Glasses;Hololens 2;Cultural Heritage;Korean National Treasure No.287;Great Gilt-bronze Incense Burner of Baekje","Mixed reality;Resists;Cameras;Cultural differences;Augmented reality;Smart glasses","augmented reality;helmet mounted displays;history","smart glasses;AR services;augmented reality services;Great Gilt-bronze Incense Burner of Baekje;cultural heritage;Korea;Microsoft HoloLens 2;QR code;Unity program;mixed reality toolkit;Korean national treasure No. 287","","","","8","IEEE","11 Apr 2022","","","IEEE","IEEE Conferences"
"Context-Aware Markerless Augmented Reality for Shared Educational Spaces","T. Scargill","Department of Electrical and Computer Engineering, Duke University","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","469","472","In order for markerless augmented reality (AR) to reach its full potential in educational settings it must be able to adapt to the wide range of possible environments, devices and user cognitive states that affect learning outcomes. Shared educational spaces, such as classrooms, art galleries, museums, teaching hospitals and wildlife centers present enticing opportunities in terms of specialized AR applications, existing infrastructure to leverage, and large numbers of AR sessions to gather data on. In this work we make feasible the challenging concept of context-aware AR through the use of a ‘local expert’, which learns the optimal configuration of AR algorithms and virtual content for the specific educational space and use case for which it is implemented. To compute insights from multiple AR devices, enable timely responses to fast-changing user cognitive states, and ensure the security of sensitive user data, we propose an edge-computing architecture, in which storage and computation related to our local expert is performed on a server on the same local area network as the mobile AR devices.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585872","Markerless augmented reality;context-aware augmented reality;edge computing","Performance evaluation;Art;Hospitals;Wildlife;Education;Computer architecture;Servers","augmented reality;cognition;computer aided instruction;museums;teaching","feasible the challenging concept;context-aware AR;local expert;specific educational space;use case;multiple AR devices;user cognitive states;sensitive user data;context-aware markerless augmented reality;shared educational spaces;educational settings;art galleries;teaching hospitals","","","","22","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Two-Phase Calibration for a Mirror Metaphor Augmented Reality System","J. S. Jang; G. S. Jung; T. H. Lee; S. K. Jung","School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea","Proceedings of the IEEE","20 Jan 2014","2014","102","2","196","203","According to the ways to see the real environments, mirror metaphor augmented reality systems can be classified into video see-through virtual mirror displays and reflective half-mirror displays. The two systems have distinctive characteristics and application fields with different types of complexity. In this paper, we introduce a system configuration to implement a prototype of a reflective half-mirror display-based augmented reality system. We also present a two-phase calibration method using an extra camera for the system. Finally, we describe three error sources in the proposed system and show the result of analysis of these errors with several experiments.","1558-2256","","10.1109/JPROC.2013.2294253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702441","Augmented reality;error analysis;mirror metaphor augmented reality;reflective half-mirror displays;registration error","Mirrors;Cameras;Calibration;Augmented reality;Rendering (computer graphics);Prototypes;Classification","augmented reality;calibration;display instrumentation;error analysis;mirrors;video cameras;video signal processing","mirror metaphor augmented reality systems;video see-through virtual mirror displays;reflective half-mirror displays;system configuration;reflective half-mirror display-based augmented reality system;two-phase calibration method;camera;error sources;error analysis","","12","","18","IEEE","20 Jan 2014","","","IEEE","IEEE Journals"
"Authoring Augmented Reality Learning Experiences as Learning Objects","M. E. C. Santos; G. Yamamoto; T. Taketomi; J. Miyazaki; H. Kato","Interactive Media Design Laboratory, Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Interactive Media Design Laboratory, Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Interactive Media Design Laboratory, Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Interactive Media Design Laboratory, Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Interactive Media Design Laboratory, Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan","2013 IEEE 13th International Conference on Advanced Learning Technologies","19 Sep 2013","2013","","","506","507","Engineers and educators alike have prototyped a variety of augmented reality learning experiences (ARLEs). However, adapting ARLEs in educational practice would require an interdisciplinary approach that considers learning theory, pedagogy and instructional design. To address this requirement, we model ARLEs as learning objects by outlining the necessary components, and we propose a participatory design to demonstrate the authoring process of an augmented reality learning object (ARLO). ARLOs can be made useful in many scenarios if teachers are empowered to edit its context elements, content and instructional activity. Lastly, we point to the research questions entailed in modeling ARLEs as ARLOs.","2161-377X","978-0-7695-5009-1","10.1109/ICALT.2013.165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6602007","augmented reality;augmented reality learning experience;authoring;learning object;participatory design","Augmented reality;Context;Context modeling;Solid modeling;Visualization;Three-dimensional displays;Computational modeling","augmented reality;computer aided instruction","augmented reality learning experiences;learning objects;ARLE;interdisciplinary approach;learning theory;instructional design;participatory design;augmented reality learning object;ARLO","","12","","6","IEEE","19 Sep 2013","","","IEEE","IEEE Conferences"
"Real-time Hand-object Occlusion for Augmented Reality Using Hand Segmentation and Depth Correction","Y. Wu; Y. Liu; J. Wang","Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology","2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","631","632","Hand-object occlusion is crucial to enhance the realism of Aug-mented Reality, especially for egocentric hand-object interaction scenes. In this paper, a hand segmentation-based depth correction approach is proposed, which can help to realize real-time hand-object occlusion. We introduce a lightweight convolutional neural net-work to quickly obtain real hand segmentation mask. Based on the hand mask, different strategies are adopted to correct the depth data of hand and non-hand regions, which can implement hand-object occlusion and object-object occlusion simultaneously to deal with complex hand situations during interaction. The experimental re-sults demonstrate the feasibility of our approach presenting visually appealing occlusion effects.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00158","National Natural Science Foundation of China(grant numbers:61960206007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108726","Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Mixed / augmented reality;Computing methodologies-Computer graphics-Image manipulation-Image processing","Deep learning;Three-dimensional displays;Conferences;Neural networks;User interfaces;Real-time systems;Robustness","augmented reality;convolutional neural nets;feature extraction;image segmentation","Aug-mented Reality;augmented Reality;complex hand situations;egocentric hand-object interaction scenes;hand mask;hand segmentation mask;hand segmentation-based depth correction approach;nonhand regions;object-object occlusion;real-time hand-object occlusion","","","","8","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Work-In-Progress—Developing Materials Science Experiments Using Augmented Reality: How Much Reality is Needed?","M. -L. Bourguet; W. Ye; M. Romero-Gonzalez","School of Electronic Eng. and Comp. Science Queen Mary U. of London, London, UK; International School Beijing U. of Posts and Telecom, Beijing, China; School of Eng. and Materials Science Queen Mary U. of London, London, UK","2022 8th International Conference of the Immersive Learning Research Network (iLRN)","11 Jul 2022","2022","","","1","3","This work-in-progress paper presents two Augmented Reality applications for teaching fractography. The first application has little connection with reality, whereas the second application has a strong anchoring and dependency with reality: students need to have prepared physical lab samples to trigger the display of virtual elements on their phone. Student feedback reveals a tension with the teacher’s view on how much reality is needed. Where the teacher sees the use of physical samples to assess laboratory skills, many students view Augmented Reality as a learning complement on the theoretical rather than the experimental aspects of fractography.","","978-1-7348995-3-5","10.23919/iLRN55037.2022.9815921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815921","Augmented reality;materials science;experimental skills;fractography;samples;reality","Materials science and technology;Education;Prototypes;Augmented reality","augmented reality;computer aided instruction;fractography;laboratories;materials science computing;student experiments;teaching","materials science experiments;augmented reality applications;physical lab samples;fractography teaching;virtual elements;student feedback;laboratory skills","","","","8","","11 Jul 2022","","","IEEE","IEEE Conferences"
"Augmented reality for board games","E. Molla; V. Lepetit","CV Laboratory, EPF Lausanne, Switzerland; CV Laboratory, EPF Lausanne, Switzerland","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","253","254","We introduce a new type of Augmented Reality games: By using a simple webcam and Computer Vision techniques, we turn a standard real game board pawns into an AR game. We use these objects as a tangible interface, and augment them with visual effects. The game logic can be performed automatically by the computer. This results in a better immersion compared to the original board game alone and provides a different experience than a video game. We demonstrate our approach on Monopoly™, but it is very generic and could easily be adapted to any other board game.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643593","","Games;Augmented reality;Three dimensional displays;Computers;Detectors;Computer vision;Cameras","augmented reality;computer games;computer vision;graphical user interfaces","augmented reality;webcam;computer vision;board game;tangible interface","","21","","19","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Performance analysis of an outdoor augmented reality tracking system that relies upon a few mobile beacons","R. Azuma; H. Neely; M. Daily; J. Leonard","HRL Laboratories LLC, USA; HRL Laboratories LLC, USA; HRL Laboratories LLC, USA; Raytheon Missile Systems Company, USA","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","101","104","We describe and evaluate a new tracking concept for outdoor Augmented Reality. A few mobile beacons added to the environment correct errors in head-worn inertial and GPS sensors. We evaluate the accuracy through detailed simulation of many error sources. The most important parameters are the errors in measuring the beacon and user's head positions, and the geometric configuration of the beacons around the point to augment. Using Monte Carlo simulations, we identify combinations of beacon configurations and error parameters that meet a specified goal of 1 m net error at 100 m range.","","1-4244-0650-1","10.1109/ISMAR.2006.297798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079260","","Performance analysis;Augmented reality;Infrared sensors;Global Positioning System;Computer errors;Computer displays;Military computing;Unmanned aerial vehicles;Sensor systems;Laboratories","augmented reality;Global Positioning System;military computing;Monte Carlo methods;target tracking","outdoor augmented reality tracking system;mobile beacons;tracking concept;head-worn inertial sensors;GPS sensors;head positions;geometric configuration;Monte Carlo simulations","","11","2","17","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Uses of Augmented Reality for Supporting Educational Presentations","A. Montero; T. Zarraonandia; I. Aedo; P. Díaz","Computer Science Department, Universidad Carlos III de Madrid, Madrid, Spain; Computer Science Department, Universidad Carlos III de Madrid, Madrid, Spain; Computer Science Department, Universidad Carlos III de Madrid, Madrid, Spain; Computer Science Department, Universidad Carlos III de Madrid, Madrid, Spain","2013 IEEE 13th International Conference on Advanced Learning Technologies","19 Sep 2013","2013","","","426","428","This work aims to explore the benefits and potential uses of Augmented Reality technology for supporting communication in lectures and presentations. In this paper we present the architecture and implementation of an Augmented Presentation Feedback System (APFs). The system allows a speaker equipped with an Augmented Reality Head-Mounted Display to visualize visual cues depicted over the listeners' heads. These can be used as a way of providing the speaker with continuous, private and immediate feedback on her explanations, so she can adapt the content and pace of the explanation to the specific needs of the listener and improve the flow of the presentation.","2161-377X","978-0-7695-5009-1","10.1109/ICALT.2013.130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601972","Augmented Reality;Classroom Communication System","Augmented reality;Visualization;Computer architecture;Context;Mobile communication;Conferences","augmented reality;data visualisation;educational technology;helmet mounted displays;technical presentation","educational presentations;augmented reality technology;lecture communication;augmented presentation feedback system;APF;augmented reality head-mounted display;visual cue visualization;listener heads;private feedback;immediate feedback;continuous feedback","","4","","12","IEEE","19 Sep 2013","","","IEEE","IEEE Conferences"
"Augmented reality goggles with an integrated tracking system for navigation in neurosurgery","E. Azimi; J. Doswell; P. Kazanzides","Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Juxtopia Limited Liability Company, Baltimore, MD, USA; Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","123","124","Precise tumor identification is crucial in image-guided neurosurgical procedures. With existing navigation systems, the surgeon must turn away from the patient to view the imaging data on a separate monitor. In this study, an innovative system is introduced that illustrates the tumor boundaries precisely augmented on the spot where the tumor is located with regard to the patient. Additionally, it allows the surgeon to track the distal end of the tools contextually, where direct visualization is not possible. In this approach, the tracking system is compact and worn by the surgeon, eliminating the need for additional devices that are bulky and typically limited by line of sight constraints.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180913","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180913","Augmented reality;HMD;neurosurgery;surgical navigation","Surgery;Augmented reality;Biomedical optical imaging;Tumors;Optical sensors;Adaptive optics;Cameras","augmented reality;medical computing;neurophysiology;surgery;tumours","augmented reality goggles;integrated tracking system;neurosurgery;precise tumor identification;image-guided neurosurgical procedures;navigation systems;tumor boundaries;direct visualization","","23","","8","IEEE","12 Apr 2012","","","IEEE","IEEE Conferences"
"Estimation of Illuminants for Plausible Lighting in Augmented Reality","S. Lee; S. K. Jung","Graduate School of Computer Engineering, Kyungpook National University, Daegu, South Korea; College of IT Engineering, Kyungpook National University, Daegu, South Korea","2011 International Symposium on Ubiquitous Virtual Reality","3 Nov 2011","2011","","","17","20","This paper presents a practical method to estimate the positions of light sources in real environment, using a mirror sphere placed on a known natural marker. For the stable results of static lighting, we take the multiple images around a sphere and estimate the principal light directions of the vector clusters for each light source in running-time. We also estimate the moving illuminant for changes of the scene illumination, and augment the virtual objects onto the real image with the proper shading and shadows. Some experimental results show that the proposed method produces plausible AR visualization in real time.","","978-1-4577-0356-0","10.1109/ISUVR.2011.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6068297","augmented reality;multiple illuminants;virtual lighting","Light sources;Lighting;Cameras;Vectors;Mirrors;Augmented reality;Visualization","augmented reality;light sources;mirrors;pose estimation;realistic images","augmented reality;plausible lighting;illuminant estimation;light source position estimation methods;mirror sphere;natural marker;static lighting;scene illumination;virtual objects;plausible AR visualization","","6","","16","IEEE","3 Nov 2011","","","IEEE","IEEE Conferences"
"A door lock system with augmented reality technology","C. -H. Hung; Y. -Y. Fanjiang; K. -C. Chung; C. -Y. Kao","Department of Information Technology, Lee-Ming Institute of Technology, New Taipei City, Taiwan; Department of Computer Science and Information Engineering, Fu Jen Catholic University, New Taipei City, Taiwan; Department of Computer Science and Information Engineering, Fu Jen Catholic University, New Taipei City, Taiwan; Department of Digital Multimedia Technology, Lee-Ming Institute of Technology, New Taipei City, Taiwan","2017 IEEE 6th Global Conference on Consumer Electronics (GCCE)","21 Dec 2017","2017","","","1","2","This paper presents a door lock system combine with augmented reality technology (AR) and mobile phone remote control system. The system consists four parts: augmented reality application, wireless network module, microcontroller, and electronic door lock. General access control has a keyhole or numeric keypad. Interested people can easily start from here that can open the door. The system only has a similar Quick Response Code (QR Code) sign above the doorknob. Therefore, those people who have interested will not know how to start to open the door. The owner who only needs to active the AR application and press the correct password that will be able to open the door.","","978-1-5090-4045-2","10.1109/GCCE.2017.8229462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8229462","augmented reality technology;door lock system;wireless module","Augmented reality;Smart phones;Wireless communication;Conferences;Games;Consumer electronics","augmented reality;microcontrollers;mobile handsets;radio networks;telecontrol","augmented reality technology;mobile phone remote control system;wireless network module;electronic door lock;general access control;Quick Response Code;door lock system;augmented reality","","10","","4","IEEE","21 Dec 2017","","","IEEE","IEEE Conferences"
"Smartwatch-assisted robust 6-DOF hand tracker for object manipulation in HMD-based augmented reality","H. -i. Kim; W. Woo","KAIST, Graduate School of Culture Technology; KAIST, Graduate School of Culture Technology","2016 IEEE Symposium on 3D User Interfaces (3DUI)","28 Apr 2016","2016","","","251","252","We introduce a smartwatch assisted sensor fusion approach to robustly track 6-DOF hand movement in head mounted display (HMD) based augmented reality (AR) environment, which can be used for robust 3D object manipulation. Our method uses a wrist-worn smartwatch with HMD-mounted depth sensor to robustly track 3D position and orientation of user's hand. We introduce HMD-based augmented reality platform with smartwatch, and method to accurately calibrate orientation between smartwatch and HMD. We also implement natural 3D object manipulating system using 6-DOF hand tracker with hand grasping detection. Our proposed system is easy to use, and doesn't require any hand held devices.","","978-1-5090-0842-1","10.1109/3DUI.2016.7460065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460065","Augmented Reality;Wearable Computing;3D User Interfaces;Hand Interaction;Virtual 3D Object Manipulation","Three-dimensional displays;Cameras;Robustness;Tracking;Augmented reality;Calibration;Grasping","augmented reality;calibration;helmet mounted displays;object detection;object tracking;sensor fusion;wearable computers","smartwatch-assisted robust 6-DOF hand tracker;HMD-based augmented reality;smartwatch assisted sensor fusion approach;6-DOF hand movement tracking;head mounted display;augmented reality environment;AR environment;3D object manipulation;wrist-worn smartwatch;HMD-mounted depth sensor;3D position tracking;orientation calibration;natural 3D object manipulating system;hand grasping detection","","4","1","8","IEEE","28 Apr 2016","","","IEEE","IEEE Conferences"
"The Development of Learning Media Based on Augmented Reality for Industrial Metrology and Quality Control Courses","Marsono; R. Kristyanto","Department of Mechanical Engineering, State University of Malang, Malang, Indonesia; Department of Mechanical Engineering, State University of Malang, Malang, Indonesia","2021 7th International Conference on Electrical, Electronics and Information Engineering (ICEEIE)","30 Nov 2021","2021","","","1","6","Industrial metrology and quality control courses are compulsory subjects Mechanical Engineering Department students, Faculty of Engineering, State University of Malang. The learning media used are still conventional using modules so that the attractiveness of students is less. An alternative learning media is needed to increase student attractiveness, namely augmented reality-based engineering learning media. The objectives of this research and development include developing products in the form of application-based learning media with the application of augmented reality technology for industrial metrology and control courses and knowing the level of student attractiveness regarding the application-based learning media used. The validation results obtained of material expert validation shows a percentage of 88.75%, media expert validation shows a percentage of 86.25%, and attractiveness students on small groups show a percentage of 95.69 %. It can be concluded that the learning media of augmented reality-based engineering measurement in industrial metrology and quality control courses is very feasible to be used in the learning process.","","978-1-6654-3232-0","10.1109/ICEEIE52663.2021.9616852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616852","Industrial Metrology;Quality Control;Augmented Reality;Engineering Measurement","Process control;Electric variables measurement;Quality control;Media;Metrology;Mechanical engineering;Augmented reality","augmented reality;computer aided instruction;educational courses;engineering education;measurement;mechanical engineering computing;quality control","industrial metrology;quality control courses;student attractiveness;application-based learning media;augmented reality technology;media expert validation;augmented reality-based engineering measurement;Mechanical Engineering Department students;augmented reality-based engineering learning media","","","","15","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Exploring the Adoption of Virtual and Augmented Reality in Enhancing Interactive Learning in Tanzania","A. Misso; J. Stephen; B. Maiseli; M. Issaka","University of Dar es Salaam, Dar es Salaam, Tanzania; University of Dar es Salaam, Dar es Salaam, Tanzania; University of Dar es Salaam, Dar es Salaam, Tanzania; University of Dar es Salaam, Dar es Salaam, Tanzania","2019 IST-Africa Week Conference (IST-Africa)","18 Jul 2019","2019","","","1","9","The challenge of inadequate teaching and learning facilities impedes the development of the education system in Tanzania. This instigates the need to combine education and technology for provision of education. This paper assessed the adoption of Virtual and Augmented Reality as a tool to improve interactive learning. The research assessed the awareness and perceived usefulness of virtual and augmented realities in education. The research utilized a quantitative methodology whereby an online survey was used to collect data. Results indicate 69.7% of the respondents were aware of virtual and augmented reality. Moreover, 87.4% of the respondents agreed that virtual and augmented reality can be adopted to improve interactive learning. Interestingly, Science, Engineering, and Medical fields were proposed for adoption. These technologies influence students' interest and motivation to learn through visualizations and interactivity. However, further research is recommended on cost-effective gadgets for virtual reality technology and suitable content for augmented reality technology.","2576-8581","978-1-905824-63-2","10.23919/ISTAFRICA.2019.8764839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764839","Virtual reality;Augmented reality;Interactive learning","Augmented reality;Education;Tools;Solid modeling;Three-dimensional displays;Government","augmented reality;computer aided instruction;data visualisation;human computer interaction;teaching","Tanzania;inadequate teaching;learning facilities;education system;interactivity;virtual reality technology;augmented reality technology;interactive learning;cost-effective gadgets","","1","","22","","18 Jul 2019","","","IEEE","IEEE Conferences"
"The Mosaic Sustainable Marker Detection Method for Augmented Reality Systems","I. Ruban; O. Makoveychuk; V. Khudov; I. Khizhnyak; H. Khudov; O. Baranik","Electronic Computers Department, Kharkiv National University of Radio Electronics, Kharkiv, Ukraine; Electronic Computers Department, Kharkiv National University of Radio Electronics, Kharkiv, Ukraine; Electronic Computers Department, Kharkiv National University of Radio Electronics, Kharkiv, Ukraine; Department of Mathematical and Software Automated Control Systems, Kharkiv Ivan Kozhedub National Air Force University, Kharkiv, Ukraine; Radar Troops Tactic Department, Kharkiv Ivan Kozhedub National Air Force University, Kharkiv, Ukraine; Aviation Armament Complexes Department, Kharkiv Ivan Kozhedub National Air Force University, Kharkiv, Ukraine","2020 IEEE International Conference on Problems of Infocommunications. Science and Technology (PIC S&T)","2 Jul 2021","2020","","","311","317","The paper proposes the mosaic sustainable marker detection method for augmented reality markers. The existing markers of augmented reality systems have been analyzed. The advantages and disadvantages of existing markers of augmented reality systems have been analyzed. The mosaic sustainable marker detection method for augmented reality systems has been developed. The block diagram of mosaic sustainable marker detection method for augmented reality systems is presented. The stages of the mosaic sustainable marker detection method for augmented reality systems are considered. Experimental studies of the mosaic sustainable marker detection method for augmented reality systems has been carried out.","","978-1-7281-9177-5","10.1109/PICST51311.2020.9467962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9467962","the image;the method of detection;the augmented reality system;the mosaic sustainable marker","Augmented reality","augmented reality;image segmentation;object detection","augmented reality systems;augmented reality markers;mosaic sustainable marker detection;block diagram","","","","17","IEEE","2 Jul 2021","","","IEEE","IEEE Conferences"
"Augmented reality based on occlusion recovery","Y. Yuan; W. -c. Liu","College of Information Science and Technology, Jiujiang University Jiujiang, Jiangxi, China; College of Information Science and Technology, Jiujiang University Jiujiang, Jiangxi, China","Proceedings of 2013 3rd International Conference on Computer Science and Network Technology","1 Dec 2014","2013","","","1162","1165","In view of the occlusion problem between virtual scene and real object, we propose an augmented reality method based on occlusion recovery. To avoid the negative influence of shadows on occlusion subtraction, we firstly design a occlusion subtraction approach for foreground objects. Secondly, we recover the foreground occlusion based on stereo vision and interpolation technology. Finally, we recover the correct occlusion relation between virtual scene and real object. Experimental results show that our approach remarkably improves the reality sense of the augmented reality system.","","978-1-4799-0561-4","10.1109/ICCSNT.2013.6967308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6967308","Augmented Reality;Occlusion between Virtual Scene and Real Object;Occlusion Recovery","Augmented reality;Cameras;Gravity;Educational institutions;Computers;Image restoration;Vectors","augmented reality;interpolation;stereo image processing","occlusion recovery;occlusion problem;virtual scene;augmented reality method;occlusion subtraction;foreground objects;stereo vision;interpolation technology;foreground occlusion;reality sense;augmented reality system","","","","10","IEEE","1 Dec 2014","","","IEEE","IEEE Conferences"
"AR Basketball: Consolidating Fingerstroke-Level Model for a Visuo-Haptic Augmented Reality based Smartphone Application","A. I. Pritom; I. Ahmed; M. Z. Chowdhury; M. J. Islam","Department of Computer Science and Engineering, Green University of Bangladesh, Dhaka, Bangladesh; Department of Computer Science and Engineering, Islamic University of Technology, Gazipur, Bangladesh; Department of Computer Science and Engineering, Islamic University of Technology, Gazipur, Bangladesh; Department of Computer Science and Engineering, Green University of Bangladesh, Dhaka, Bangladesh","2020 IEEE Region 10 Symposium (TENSYMP)","2 Nov 2020","2020","","","1269","1272","In the era of extensive progression of smartphones, gaming applications have become an undisputed reality of our routine micro-moments. And when it comes to a realistic gaming experience, Augmented Reality has shown significant advancement to uplift itself from just a fantastical concept to one of the front-runners of todays gaming industry. In this work, we propose a Mobile Augmented Reality (MAR) based smartphone application, namely “AR Basketball” to justify the flexible adjustments required to design an intrinsic reality-based gaming UI. This research is one of the earliest investigations to revisit operators of Finger-stroke Level Model (FLM) for MAR and attempts to map different finger-stroke activities with touch-sensitive AR-based smartphone applications. The complete game was uploaded in Google play store for user feedback after being fused with several other common AR sporting applications developed by one of the authors conducting this research work. The empirical study shows that a redesigned FLM for MAR ensures better task completion time compared to the same action-based gaming applications designed for other platforms.","2642-6102","978-1-7281-7366-5","10.1109/TENSYMP50017.2020.9230964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9230964","Mobile Augmented Reality (MAR);Fingerstroke-Level Model (FLM);Human Computer Interaction (HCI)","Task analysis;Games;Augmented reality;Time factors;Computational modeling;Visualization;Solid modeling","augmented reality;computer games;haptic interfaces;mobile computing;smart phones;sport","routine micromoments;realistic gaming experience;gaming industry;Mobile Augmented Reality;AR Basketball;intrinsic reality-based gaming UI;action-based gaming applications;fingerstroke-Level Model;undisputed reality;finger-stroke activities;finger-stroke level model;AR sporting applications;visuo-haptic augmented reality based smartphone application;touch-sensitive AR-based smartphone applications;user feedback","","","","12","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"[Poster] A preliminary study on altering surface softness perception using augmented color and deformation","P. Punpongsanon; D. Iwai; K. Sato","Graduate School of Engineering Science, Osaka University; Osaka Daigaku, Suita, Osaka, JP; Graduate School of Engineering Science, Osaka University","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","301","302","Choosing the appropriate soft/hard material is important for designing a product such as sofa or bed, but typically limited by the number of physical materials that the designer owns. Pseudo-haptic feedback is an alternative way that enables designer to roughly simulate material properties (e.g., softness, hardness) by only generating the visual illusion. However, the current technique is limited within video see-through augmented reality, in which the user interact in a real space while looking at a virtual space. This paper explores the possibility to realize pseudo-haptic feedback for touching objects in spatial augmented reality. We investigate and compare effects of visually superimposing a projection graphics onto the surface of a touched object and the fingernail/finger for changing the surface tactile perception. The potential of our method is discussed through a preliminary user study.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948460","Spatial augmented reality;pseudo-haptics;perception","Image color analysis;Materials;Visualization;Force;Color;Augmented reality;Force measurement","augmented reality;haptic interfaces","surface softness perception;augmented color;augmented deformation;product design;pseudohaptic feedback;material softness property;material hardness property;projection graphics;surface tactile perception","","2","","4","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Application of virtual reality and augmented reality technology in Teaching1","L. Li; X. Wu","School of Information, Yunnan University of Finance and Economics, Kunmin, Yunnan, China; Experimental Center, Yunnan University of Finance and Economics, Kunming, Yunnan, China","2020 15th International Conference on Computer Science & Education (ICCSE)","22 Sep 2020","2020","","","543","546","""Internet Plus Education"" is just unfolding with the upgrading of educational philosophy and the innovation of teaching methods. The application of virtual reality and augmented reality technology in the field of education has broad prospects. This paper introduces the classification of virtual technology, puts forward the composition of teaching system and human-computer interaction system based on AR and AR technology, describes the key technologies of teaching system based on VR and AR, and points out the problems of VR and AR application in teaching.","2473-9464","978-1-7281-7267-5","10.1109/ICCSE49874.2020.9201763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201763","virtual reality;augmented reality;teaching","Education;Three-dimensional displays;Solid modeling;Software;Augmented reality;Human computer interaction","augmented reality;human computer interaction;teaching","teaching system;human-computer interaction system;virtual reality;augmented reality technology;Internet Plus Education;educational philosophy;virtual technology;AR technology","","2","","11","IEEE","22 Sep 2020","","","IEEE","IEEE Conferences"
"Effects of Virtual Reality and Augmented Reality on Induced Anxiety","Y. -Y. Li; P. -H. Chiu; S. -C. Yeh; C. Zhou","Department of Psychology, Fudan University, Shanghai, China; Department of Psychology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China","2017 5th International Conference on Enterprise Systems (ES)","23 Nov 2017","2017","","","132","138","Objective: This study aimed to explore and compare the effects of augmented reality (AR) and virtual reality (VR) on induced anxiety in set-up scenes for claustrophobia treatment and determine which device functions better. Methodology: Healthy individuals were selected as subjects. During the experiment, the AR and VR scenes were introduced in sequence. The social anxiety scale was assessed after every scene. The subjects' skin conductance and heart rates were measured throughout the entire process. Results: Results showed both the objective indicators and subjective scales of preliminary experiments. Conclusion: System development and integration of data acquisition systems and VR were successfully completed, and preliminary experiments were conducted.","2572-6609","978-1-5386-0936-1","10.1109/ES.2017.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119379","virtual reality;augmented reality;claustrophobia;anxiety","Medical treatment;Fires;Skin;Heart rate;Training;Augmented reality","augmented reality;biomedical measurement;cardiology;data acquisition;patient treatment;psychology;skin","subjective scales;virtual reality;augmented reality;induced anxiety;claustrophobia treatment;Healthy individuals;social anxiety scale;objective indicators;system development;data acquisition systems;system integration;VR scenes;AR scenes;heart rate measurement;skin conductance measurement","","1","","18","IEEE","23 Nov 2017","","","IEEE","IEEE Conferences"
"Educational Advancements in the Field of Augmented Reality and Virtual Reality","R. Bheda; D. Bhimani; F. Dharamshi; S. Sheth; R. Menon; R. Somra; R. Bhasuru; C. Mahajan; S. Gajbhiye; D. Toradmalle","Computer Engineering Shah and Anchor Kutchhi Engineering College, Mumbai, India; Computer Engineering Shah and Anchor Kutchhi Engineering College, Mumbai, India; Computer Engineering Shah and Anchor Kutchhi Engineering College, Mumbai, India; Information Technology Shah and Anchor Kutchhi Engineering College, Mumbai, India; Board Advisor, Equinox Partners; EQ Labs, IBM USA Advisor; Director-Cloud Transformation & Engineering, CDK Global; Information Technology Shah and Anchor Kutchhi Engineering College, Mumbai, India; Information Technology Shah and Anchor Kutchhi Engineering College, Maharashtra, India; Information Technology Shah and Anchor Kutchhi Engineering College, Maharashtra, India","2021 International Conference on Communication information and Computing Technology (ICCICT)","12 Aug 2021","2021","","","1","4","Technology has constantly kept on evolving since many years. This has helped in the growth of many fields throughout the world. One such important field is Education. Different technologies have helped education to grow positively and help everyone learn and practice with ease and understanding. Technology has proven to be a useful aid in education, as it enables teaching methods to be eased and efficiency enhanced by incorporating economical and effective means of transmitting digital content. Researchers have shown us that Virtual Reality and Augmented Reality have great potential to support two types of users: students, on the one hand, increase productivity and from the other teachers, broaden their teaching techniques. Hence, it makes the experience of education and learning more effective and stimulating. Nonetheless, even for non-skilled developers, there is no specifically designed platform for the flexible creation of AR/VR content. There is therefore a need to develop new tools to allow users to easily become producers of such experiences.","","978-1-6654-0430-3","10.1109/ICCICT50803.2021.9509941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509941","Virtual Reality;Augmented Reality;Education","Productivity;Computers;Education;Tools;Safety;Security;Augmented reality","augmented reality;computer aided instruction;teaching;user experience","educational advancements;Augmented Reality;Virtual Reality;digital content;teaching techniques;AR content;VR content;productivity","","","","15","IEEE","12 Aug 2021","","","IEEE","IEEE Conferences"
"Experimental evaluation of an augmented reality visualization for directing a car driver's attention","M. Tonnis; C. Sandor; G. Klinker; C. Lange; H. Bubb","Inst. fur Inf., Tech. Univ. Munchen, Garching, Germany; Institut füur Informatik, Technical University of München, Garching, Germany; Institut füur Informatik, Technical University of München, Garching, Germany; Institut füur Maschinenwesen, Technical University of München, Garching, Germany; Institut füur Maschinenwesen, Technical University of München, Garching, Germany","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","56","59","With recent advances of head-up display technology in cars, augmented reality becomes interesting in supporting the driving task to guide a driver's attention. We have set up an experiment to compare two different approaches to inform the driver about dangerous situations around the car. One approach used AR to visualize the source of danger in the driver's frame of reference while the other one presented information in an egocentric frame of reference. Both approaches were evaluated in user tests.","","0-7695-2459-1","10.1109/ISMAR.2005.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544664","","Augmented reality;Visualization;Navigation;Displays;Testing;Automotive components;Roads;Eyes;Vehicles;Taxonomy","driver information systems;augmented reality;data visualisation;automobiles;road safety;head-up displays","experimental evaluation;augmented reality visualization;car driver attention redirection;head-up display technology","","58","3","8","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Support system for guitar playing using augmented reality display","Y. Motokawa; H. Saito","Department of Information and Computer Science, Keio University, Yokohama, Japan; Department of Information and Computer Science, Keio University, Yokohama, Japan","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","243","244","Learning to play the guitar is difficult. We proposed a system that assists people learning to play the guitar using augmented reality. This system shows a learner how to correctly hold the strings by overlaying a virtual hand model and lines onto a real guitar. The player learning to play the guitar can easily understand the required position by overlapping their hand on a visual guide. An important issue for this system to address is the accurate registration between the visual guide and the guitar, therefore we need to track the pose and the position of the guitar. We also proposed a method to track the guitar with a visual marker and natural features of the guitar. Since we used marker information and edge information as natural features, the system could continually track the guitar. Accordingly, our system can constantly display visual guides at the required position to enable a player to learn to play the guitar in a natural manner.","","1-4244-0650-1","10.1109/ISMAR.2006.297825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079287","","Augmented reality;Instruments;Computer displays;Universal Serial Bus;Cameras;Image edge detection;Keyboards;Computer science;Chromium;Image processing","augmented reality;computer displays;edge detection;feature extraction;image registration","support system;guitar playing;augmented reality display;virtual hand model;virtual lines;visual guide;visual marker;natural features;edge information","","46","2","4","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Archeoguide: system architecture of a mobile outdoor augmented reality system","P. Dahne; J. N. Karigiannis","Computer Graphics Center ZGDV e. V., Darmstadt, Germany; INTRACOM S.A., Greece","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","263","264","We present the system architecture of a mobile outdoor augmented reality system for the Archeoguide project. We begin with a short introduction to the project. Then we present the hardware we chose for the mobile system and we describe the system architecture we designed for the software implementation. We conclude this paper with the first results obtained from experiments we made during our trials at ancient Olympia in Greece.","","0-7695-1781-1","10.1109/ISMAR.2002.1115103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115103","","Augmented reality;Rendering (computer graphics);Computer architecture;Hardware;Wearable computers;Image reconstruction;Batteries;Cameras;Computer graphics;Software design","archaeology;software architecture;mobile computing;augmented reality;user interfaces;image processing;wearable computers","Archeoguide;system architecture;mobile outdoor augmented reality system;experiments;ancient Olympia;wearable computers;cultural heritage;historical sites;archaeology;software architecture","","37","6","6","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Streaming mobile augmented reality on mobile phones","D. M. Chen; S. S. Tsai; R. Vedantham; R. Grzeszczuk; B. Girod","Information Systems Laboratory, University of Stanford, USA; Information Systems Laboratory, University of Stanford, USA; Nokia Research Center, Palo Alto, USA; Nokia Research Center, Palo Alto, USA; Information Systems Laboratory, University of Stanford, USA","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","181","182","Continuous recognition and tracking of objects in live video captured on a mobile device enables real-time user interaction. We demonstrate a streaming mobile augmented reality system with 1 second latency. User interest is automatically inferred from camera movements, so the user never has to press a button. Our system is used to identify and track book and CD covers in real time on a phone's viewfinder. Efficient motion estimation is performed at 30 frames per second on a phone, while fast search through a database of 20,000 images is performed on a server.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336472","","Augmented reality;Mobile handsets;Streaming media;Delay;Cameras;Books;Image databases;Motion estimation;Real time systems;Layout","augmented reality;mobile computing;motion estimation;multimedia systems;object recognition;video signal processing;video streaming","streaming mobile augmented reality;mobile phone;continuous object recognition;continuous object tracking;live video;real-time user interaction;camera movement;book cover identification;book cover tracking;CD cover tracking;phone viewfinder;motion estimation","","35","11","10","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality in industrial applications: Approaches for solution of user-related issues","J. Tumler; F. Doil; R. Mecke; G. Paul; M. Schenk; E. A. Pfister; A. Huckauf; I. Bockelmann; A. Roggentin","Fraunhofer IFF Magdeburg, Germany; Fraunhofer IFF Magdeburg, Germany; Fraunhofer IFF Magdeburg, Germany; Bauhaus University Weimar, Germany; Volkswagen Group Research, Germany; Otto von Guericke University Magdeburg, Magdeburg, Germany; Otto von Guericke University Magdeburg, Magdeburg, Germany; Otto von Guericke University Magdeburg, Magdeburg, Germany; Otto von Guericke University Magdeburg, Magdeburg, Germany","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","87","90","Augmented Reality (AR) uses computer-generated virtual information to enhance the user’s information access. While numerous previous studies have demonstrated the large potential of AR to improve industrial processes by enhancing product quality and reducing production times it is still unclear if and how long term usage of such AR technology produces stress and strain. This paper presents an approach to use the analysis of Heart Rate Variability to objectively measure current user strain during different work tasks. Results of a user study comparing strain during an AR supported and a non-AR supported work task in a laboratory setting are presented and discussed.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637330","H.1.2 [MODELS AND PRINCIPLES]: User/Machine Systems—Human factors;H.5 [INFORMATION INTERFACES AND PRESENTATION]: General","Strain;Heart rate variability;Augmented reality;Electronic mail;Mobile communication;Psychology;Electrocardiography","augmented reality;human factors;mobile computing","mobile augmented reality;industrial manufacturing;computer-generated virtual information;product quality;heart rate variability analysis","","31","","16","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"ARVino - outdoor augmented reality visualisation of viticulture GIS data","G. R. King; W. Piekarski; B. H. Thomas","Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory, School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","52","55","This work describes the combination of two technologies, augmented reality and GIS, to provide a new way to visualise viticulture GIS data using outdoor mobile computers. Viticulturists use GIS to assist with accurately understanding the parameters that affect their yields and quality of the grapes from different vineyards. The ability to view this data in the field digitally would be advantageous to the viticulturist. This work describes the ARVino system; an AR platform that was built for visualising 3D data outdoors using a movable tripod-based computer. We describe the user interface, some problems that were encountered, and how the visualisation and interface were evaluated through an expert review.","","0-7695-2459-1","10.1109/ISMAR.2005.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544663","","Augmented reality;Data visualization;Geographic Information Systems;Wearable computers;Portable computers;Australia;Mobile computing;Pipelines;Virtual environment;Displays","agriculture;data visualisation;augmented reality;geographic information systems;mobile computing;user interfaces;agricultural products","ARVino;outdoor augmented reality visualisation;viticulture GIS data;outdoor mobile computers;grape quality;vineyards;3D data visualisation;movable tripod-based computer;user interface","","30","","9","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Real-time and markerless vision-based tracking for outdoor augmented reality applications","D. Stricker; T. Kettenbach","Fraunhofer Institute of Computer Graphics Research (IGD), Darmstadt, Germany; Fraunhofer Institute of Computer Graphics Research (IGD), Darmstadt, Germany","Proceedings IEEE and ACM International Symposium on Augmented Reality","6 Aug 2002","2001","","","189","190","A novel concept for markerless optical tracking called ""tracking with reference images"" is introduced. This concept provides a flexible and practicable framework and is especially relevant for outdoor augmented reality applications, for which no tracking solution currently exists. The implementation is achieved using an image matching technique, which compares the current live video image with one or more of the reference images. The complete system has been tested outdoors in the context of a mobile AR-application for archeology. The system runs on a laptop at around 10 Hz and provides views of virtual monuments superposed to their ruins.","","0-7695-1375-1","10.1109/ISAR.2001.970536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=970536","","Augmented reality;Optical filters;Image matching;Application software;Cameras;Image registration;Computer graphics;System testing;Portable computers;Image processing","augmented reality;real-time systems;computer vision;optical tracking;image matching;archaeology;laptop computers;mobile computing","markerless vision-based tracking;outdoor augmented reality applications;real-time vision-based tracking;markerless optical tracking;tracking with reference images;tracking solution;image matching technique;current live video image;reference images;mobile AR application;archeology;laptop;virtual monuments;ruins;10 Hz","","27","10","4","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Augmented reality as a comparison tool in automotive industry","S. Nolle; G. Klinker","Group Research, Virtual Techniques, Volkswagen AG, Wolfsburg, Germany; Technische Universitat Munchen, Germany","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","249","250","Augmented reality (AR) can be used in the automotive industry to compare real parts of a car with their associated construction data. The real parts have to be checked whether they correspond to the latest version of the design and whether they have been manufactured with appropriate precision. With AR, CAD construction data can be superimposed on the real parts striving for maximum correspondence. The real and the virtual part should both be visible at the same time and in the same place. Therefore, for this kind of overlay, a special method of augmentation is needed. We present and discuss some visualization schemes.","","1-4244-0650-1","10.1109/ISMAR.2006.297829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079291","","Augmented reality;Automotive engineering;Shape;Construction industry;Data visualization;Prototypes;Wire;Layout;Muscles;Bones","augmented reality;automobile industry;CAD;production engineering computing;program visualisation","augmented reality;automotive industry;associated construction data;CAD construction;visualization schemes","","27","1","6","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"A Systematic Review of Usability Studies in Augmented Reality between 2005 and 2014","A. Dey; M. Billinghurst; R. W. Lindeman; J. E. Swan II","Empathic Computing Lab, University of South Australia; Empathic Computing Lab, University of South Australia; HIT Lab NZ University of Canterbury; Mississippi State University","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","49","50","Augmented Reality (AR) interfaces have been studied extensively over the last few decades, with a growing number of user-based experiments. In this paper, we systematically review most AR papers published between 2005 and 2014 that include user studies. A total of 291 papers have been reviewed and classified based on their application areas. The primary contribution of the review is to present the broad landscape of user-based AR research, and to provide a high-level view of how that landscape has changed. We also identify areas where there have been few user studies, and opportunities for future research. This poster describes the methodology of the review and the classifications of AR research that have emerged.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836457","","Augmented reality;Usability;Collaboration;Haptic interfaces;Entertainment industry;Systematics;Australia","augmented reality;pattern classification","augmented reality;user-based AR research classifications;usability studies","","24","","3","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Experimental evaluation of augmented reality in object assembly task","A. Tang; C. Owen; F. Biocca; Weimin Mou","M.I.N.D. Laboratories, M.E.T. Lab, Michigan State University, USA; M.I.N.D. Laboratories, M.E.T. Lab, Michigan State University, USA; M.I.N.D. Laboratories, M.E.T. Lab, Michigan State University, USA; M.I.N.D. Laboratories, M.E.T. Lab, Michigan State University, USA","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","265","266","This study evaluated the effectiveness of spatially overlaid instructions using augmented reality (AR) in an assembly task compared with other traditional media. Results indicate that overlaying 3D instructions on the workspace reduce error rate by 82%, particularly cumulative errors. Measurement of mental effort also suggests some of the mental workload is offloaded to the computer.","","0-7695-1781-1","10.1109/ISMAR.2002.1115105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115105","","Augmented reality;Assembly;Error analysis;NASA;Humans;Computer aided instruction;Time measurement;Calibration;Computer errors;Computer interfaces","augmented reality;user interfaces;computer based training;assembling;human factors;helmet mounted displays;image processing","experimental evaluation;augmented reality;object assembly task;spatially overlaid instructions;head mounted display;3D instructions;error rate;mental workload;human computer interaction;training","","18","1","2","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Challenges for Asynchronous Collaboration in Augmented Reality","A. Irlitti; R. T. Smith; S. Von Itzstein; M. Billinghurst; B. H. Thomas","Wearable Computer Lab, Univ. of South Australia, Australia; Wearable Computer Lab, Univ. of South Australia, Australia; Wearable Comput. Lab., University of South Australia, Adelaide, SA, AU; Empathic Computing Lab, University of South Australia, Australia; Wearable Computer Lab, Univ. of South Australia, Australia","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","31","35","Collaboration is a promising area of investigation for Augmented Reality (AR) applications. While there have been numerous examples of co-located and remote synchronous collaborative AR applications, there has not been the same interest in pursuing asynchronous interfaces. Asynchronous processes differ from their synchronous counterparts due to the collaboration occurring over a period of time, without the requirement of all parties being present simultaneously. For AR applications, asynchronous collaboration is typically considered to be the combination of drawn registered annotations, and their review at a later time. The potential on offer far exceeds this stance. This paper uncovers a unique opportunity for pursuing asynchronous collaboration support in AR, identifies how communications can be enhanced, and discusses the research challenges unique to asynchronous collaboration in AR.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836453","H.5.3 [Information interfaces and presentation (e.g.;HCI)]: Group and Organization Interfaces—Asynchronous interaction—Computer-supported cooperative work; I.3.6 [Computer Graphics]: Methodology and Techniques—Interaction Techniques","Collaboration;Electronic mail;Augmented reality;Context;Stakeholders;Resists;Production","augmented reality;groupware","augmented reality;asynchronous collaboration information;AR applications;asynchronous interfaces;registered annotations","","18","","44","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"[Poster] Towards mobile augmented reality for the elderly","D. Kurz; A. Fedosov; S. Diewald; J. Güttier; B. Geilhof; M. Heuberger",Metaio GmbH; Metaio GmbH; Metaio GmbH; TU München; Metaio GmbH; Metaio GmbH,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","275","276","Mobility and independence are key aspects for self-determined living in today's world and demographic change presents the challenge to retain these aspects for the aging population. Augmented Reality (AR) user interfaces might support the elderly, for example, when navigating as pedestrians or by explaining how devices and mobility aids work and how they are maintained. This poster reports on the results of practical field tests with elderly subjects testing handheld AR applications. The main finding is that common handheld AR user interfaces are not suited for the elderly because they require the user to hold up the device so the back-facing camera captures the object or environment related to which digital information shall be presented. Tablet computers are too heavy and they do not provide sufficient grip to hold them over a long period of time. One possible alternative is using head-mounted displays (HMD). We present the promising results of a user test evaluating whether elderly people can deal with AR interfaces on a lightweight HMD. We conclude with an outlook to improved handheld AR user interfaces that do not require continuously holding up the device, which we hope are better suited for the elderly.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948447","","Senior citizens;Tablet computers;Augmented reality;User interfaces;Navigation;Cameras;Manuals","augmented reality;helmet mounted displays;mobile computing;user interfaces","mobile augmented reality;elderly;AR user interfaces;handheld AR applications;tablet computers;head-mounted displays;HMD","","16","","6","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"An augmented reality based simulation of obstetric forceps delivery","R. Lapeer; M. S. Chen; J. Villagrana","School of Computing Sciences, University of East Anglia, Norwich, UK; School of Computing Sciences, University of East Anglia, Norwich, UK; School of Computing Sciences, University of East Anglia, Norwich, UK","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","274","275","During the process of human childbirth, obstetric forceps delivery is a justified alternative to Caesarean section when vaginal delivery proves difficult or impossible. Currently, training of forceps interventions is done on a real case due to the lack of realistic dummy models. This paper presents a basic augmented reality implementation of a forceps delivery which provides a platform for both training of forceps placement and manipulation for junior obstetricians as well as the assessment of any mechanical effects these actions may have on the fetus, and the fetal head and skull in particular.","","0-7695-2191-6","10.1109/ISMAR.2004.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383073","","Augmented reality;Fetus;Image segmentation;Blades;Skull;Optical polarization;Optical devices;Magnetic heads;Face detection;Humans","medical computing;computer based training;augmented reality;digital simulation;obstetrics","augmented reality based simulation;human childbirth;obstetric forceps delivery;Caesarean section;vaginal delivery;realistic dummy model;forceps placement training;junior obstetricians","","16","","5","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"AR storyboard: an augmented reality based interactive storyboard authoring tool","Midieum Shin; Byung-soo Kim; Jun Park","Department of Computer Science, Hongik University, Seoul, South Korea; Department of Computer Science, Hongik University, Seoul, South Korea; Department of Computer Science, Hongik University, Seoul, South Korea","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","198","199","In early stages of production, storyboards are used for visually describing the story and the script. In This work, an augmented reality based storyboard-authoring tool is introduced. Proposed tool is easy-to-use, and provides intuitive interface for scene composition and camera pose/motion control. Using AR Storyboard, non-experienced users may compose 3D scenes for a Storyboard using interfaces in his/her real environments.","","0-7695-2459-1","10.1109/ISMAR.2005.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544692","","Augmented reality;Layout;Cameras;Production;Motion control;Animation;Computer science;Rendering (computer graphics);Aging;Pediatrics","augmented reality;graphical user interfaces;authoring systems;cameras","AR storyboard;augmented reality;interactive storyboard authoring tool;graphical user interfaces","","15","","7","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"An adaptive estimator for registration in augmented reality","Lin Chai; K. Nguyen; B. Hoff; T. Vincent","Colorado Schml of Mines, Golden, CO, USA; SymSystems, LLC, Englewood, CO, USA; SymSystems, LLC, Englewood, CO, USA; Colorado Schml of Mines, Golden, CO, USA","Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99)","6 Aug 2002","1999","","","23","32","In augmented reality (AR) systems using head-mounted displays (HMD), it is important to accurately sense the position and orientation (pose) of the user's head with respect to the world, in order that graphical overlays are drawn correctly aligned with real world objects. It is desired to maintain registration dynamically (while the person is moving their head) so that the graphical objects will not appear to lag behind, or swim around, the corresponding real objects. We present an adaptive method for achieving dynamic registration which accounts for variations in the magnitude of the users head motion, based on a multiple model approach. This approach uses the extended Kalman filter to smooth sensor data and estimate position and orientation.","","0-7695-0359-4","10.1109/IWAR.1999.803803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=803803","","Augmented reality;Decision support systems","augmented reality;helmet mounted displays;image registration;adaptive estimation;Kalman filters;filtering theory","adaptive estimator;image registration;augmented reality;AR systems;head-mounted displays;HMD;position sensing;orientation sensing;pose sensing;graphical overlays;adaptive method;dynamic registration;extended Kalman filter","","15","1","12","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"A stereo vision-based augmented reality system with an inertial sensor","M. Kanbara; H. Fujii; H. Takemura; N. Yokoya","Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan","Proceedings IEEE and ACM International Symposium on Augmented Reality (ISAR 2000)","6 Aug 2002","2000","","","97","100","This paper proposes a robust registration method with stereo cameras and an inertial sensor for augmented reality. The geometric registration is one of the most important problems because virtual objects should be superimposed on the right place as if they really exist in the real world. The vision-based registration is achieved by estimating a position and an orientation of camera(s) by tracking markers in the real world. The proposed method realizes a robust tracking of markers using stereo images and a camera orientation obtained by the inertial sensor.","","0-7695-0846-4","10.1109/ISAR.2000.880931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=880931","","Augmented reality;Sensor systems;Cameras;Robustness;Image sensors;Information science;Virtual environment;Costs;Position measurement;Sensor phenomena and characterization","stereo image processing;augmented reality;image registration;cameras;sensors","stereo vision;augmented reality;inertial sensor;robust registration method;stereo camera;geometric registration;virtual objects;vision-based registration;position estimation;camera orientation","","15","6","10","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Feature Tracking for Mobile Augmented Reality Using Video Coder Motion Vectors","G. Takacs; V. Chandrasekhar; B. Girod; R. Grzeszczuk","Information Systems Laboratory, University of Stanford, USA; Information Systems Laboratory, University of Stanford, USA; Information Systems Laboratory, University of Stanford, USA; Nokia Research Center, Palo Alto, USA","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","141","144","We propose a novel, low-complexity, tracking scheme that uses motion vectors directly from a video coder. We compare our tracking algorithm against ground truth data, and show that we can achieve a high level of accuracy, even though the motion vectors are rate-distortion optimized and do not represent true motion. We develop a framework for tracking in video sequences with various GOP structures. Such a scheme would find applications in the context of Mobile Augmented Reality. The proposed feature tracking algorithm can significantly reduce the required rate of feature extraction and matching.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538838","","Augmented reality;Feature extraction;Target tracking;Video sequences;Mobile handsets;Spatial databases;Personal digital assistants;Data mining;Displays;Image databases","augmented reality;feature extraction;mobile handsets","feature tracking;video coder;motion vectors;mobile augmented reality;feature extraction;feature matching","","14","5","17","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Color harmonization for Augmented Reality","L. Gruber; D. Kalkofen; D. Schmalstieg","Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","227","228","In this paper we discuss color harmonization for Augmented Reality. Color harmonization is a technique used to adjust the combination of colors in order to follow aesthetic guidelines. We implemented a system which is able to harmonize the combination of the colors in video based AR systems. The presented approach is able to re-color virtual and real-world items, achieving overall more visually pleasant results. In order to allow preservation of certain colors in an AR composition, we furthermore introduce the concept of constraint color harmonization.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643580","","Image color analysis;Visualization;Pixel;Augmented reality;Histograms;Real time systems;Cameras","augmented reality;image colour analysis;video signal processing","aesthetic guidelines;video based augmented color reality;constraint color harmonization","","13","1","3","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Camera-marker alignment framework and comparison with hand-eye calibration for augmented reality applications","G. Bianchi; C. W. M. Harders; P. Cattin; G. Szekely","Comput. Vision Lab., Fed. Inst. of Technol., Zurich, Switzerland; Comput. Vision Lab., Fed. Inst. of Technol., Zurich, Switzerland; Comput. Vision Lab., Fed. Inst. of Technol., Zurich, Switzerland; Comput. Vision Lab., Fed. Inst. of Technol., Zurich, Switzerland","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","188","189","An integral part of every augmented reality system is the calibration between camera and camera-mounted tracking markers. Accuracy and robustness of the AR overlay process is greatly influenced by the quality of this step. In order to meet the very high precision requirements of medical skill training applications, we have set up a calibration environment based on direct sensing of LED markers. A simulation framework has been developed to predict and study the achievable accuracy of the backprojection needed for the scene augmentation process. We demonstrate that the simulation is in good agreement with experimental results. Even if a slight improvement of the precision has been observed compared to well-known hand-eye calibration methods, the subpixel accuracy required by our application cannot be achieved even when using commercial tracking systems providing marker positions within very low error limits.","","0-7695-2459-1","10.1109/ISMAR.2005.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544687","","Calibration;Augmented reality;Cameras;Computer vision;Application software;Medical simulation;Infrared detectors;Firewire;Laboratories;Robustness","augmented reality;calibration;cameras;light emitting diodes;biomedical education;medical computing","camera-marker alignment framework;hand-eye calibration;augmented reality;medical skill training application;LED marker;subpixel accuracy","","12","","7","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Designing backpacks for high fidelity mobile outdoor augmented reality","W. Piekarski; R. Smith; B. H. Thomas","Wearable Computer Laboratory School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; Wearable Computer Laboratory School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","280","281","This paper presents the design for our latest backpack to support mobile outdoor augmented reality, and how it evolved from lessons learned with our previous designs. We present a number of novel features which help to reduce size and weight, improve reliability and ease of configuration, and reduce CPU usage on laptop computers.","","0-7695-2191-6","10.1109/ISMAR.2004.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383076","","Augmented reality;Portable computers;Wearable computers;Australia;Global Positioning System;Optical design;Cables;Design engineering;Fasteners;Joining processes","augmented reality;mobile computing;laptop computers","backpack design;high fidelity mobile outdoor augmented reality;laptop computer","","10","","3","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"3D-registered interaction-surfaces in augmented reality space","C. Geiger; L. Oppermann; C. Reimann","Hochschule Harz, Germany; Hochschule Harz, Germany; Paderborn University, C -LAB","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","5","13","The user interface and its ease of use are seen as a crucial point for the enduring success of almost any application. The creation of effective user interfaces is no simple task, especially within the domain of augmented reality. Many developers still use traditional desktop-interfaces for their AR applications, even if they are not really suitable for the user, simply because the development of a usable 3D interface is much too complicated and thus consuming too much time and money. This paper describes the ARGUI system, which provides developers of ARToolkit applications with the possibility to create 2D interaction-surfaces registered in 3D. With ARGUI 2D interactions on 2D objects registered in 3D are possible, e.g. attached to a marker. The integration of a complete 2D GUI library is shown in detail, which simplifies the creation of the user interface even more.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320417","","Augmented reality;User interfaces;Mice;Focusing;Application software;Graphical user interfaces;Keyboards;Software architecture;Software libraries","graphical user interfaces;augmented reality","augmented reality;desktop interfaces;3D registered interaction surfaces;3D interface;graphical user interface;ARToolkit;3D interaction-surfaces;ARGUI system;GUI library","","8","","14","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"Visualization of sensor data using mobile phone augmented reality","A. -s. Gunnarsson; M. Rauhala; A. Henrysson; A. Ynnerman","VITA, Linkoping University, Sweden; VITA, Linkoping University, Sweden; VITA, Linkoping University, Sweden; VITA, Linkoping University, Sweden","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","233","234","We have developed a prototype system for visual inspection of hidden structures using a mobile phone wireless ZigBee sensor network. Data collected from an embedded wireless sensor matrix is used to synthesize graphics in real-time. Combining this with augmented reality technology on a mobile phone yields a novel approach to on-site inspection of a broad range of elements and their current internal states.","","1-4244-0650-1","10.1109/ISMAR.2006.297820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079282","","Data visualization;Mobile handsets;Augmented reality;Wireless sensor networks;Inspection;Prototypes;ZigBee;Sensor systems;Network synthesis;Graphics","augmented reality;data visualisation;mobile computing;mobile handsets","sensor data visualization;mobile phone augmented reality;visual inspection;ZigBee sensor network;embedded wireless sensor matrix","","8","","6","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"VesARlius: An Augmented Reality System for Large-Group Co-located Anatomy Learning","F. Bork; A. Lehner; D. Kugelmann; U. Eck; J. Waschke; N. Navab","Chair for Computer Aided Medical Procedures, Technische Universität München, Munich, Germany; Chair for Computer Aided Medical Procedures, Technische Universität München, Munich, Germany; Chair for Vegetative Anatomy, Ludwig-Maximilians Universität, Munich, Germany; Chair for Computer Aided Medical Procedures, Technische Universität München, Munich, Germany; Chair for Vegetative Anatomy, Ludwig-Maximilians Universität, Munich, Germany; Chair for Computer Aided Medical Procedures, Technische Universität München, Munich, Germany","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","122","123","Interactive educational environments are one of the prime applications for the use of Augmented Reality (AR). A large variety of such systems has been proposed in the past for various areas of education. However, in most cases the number of users these AR systems can support is limited. Only few systems have been developed that support a large number of co-located users to jointly collaborate in a dynamic and interactive learning environment. Multi-user AR collaboration presents a unique setting with distinct challenges and requirements for user interaction and information sharing. In this paper, we present VesARlius, a novel AR system for collaborative and interactive anatomy learning in a large group of co-located users. Our system employs a set of multi-user collaboration paradigms allowing users to engage in an interactive AR learning environment. We evaluated the collaborative features of our system in a user study with 16 medical students. Results demonstrate the potential of the VesARlius system to be used effectively for large-group AR anatomy learning. From our lessons learned, we provide a set of design guidelines for developing similar AR systems to enable large-group collaboration in other application domains.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951926","","Collaboration;Synchronization;Pins;Three-dimensional displays;Solid modeling;Augmented reality","augmented reality;biology computing;computer aided instruction;groupware;interactive systems;medical computing","multiuser AR collaboration;user interaction;information sharing;AR system;collaborative anatomy;interactive anatomy;multiuser collaboration paradigms;interactive AR learning environment;collaborative features;VesARlius system;augmented reality system;interactive educational environments;dynamic learning environment;interactive learning environment;co-located anatomy learning","","7","","3","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"[Poster] AIBLE: An inquiry-based augmented reality environment for teaching astronomical phenomena","S. Fleck; G. Simon; J. M. Christian Bastien","ESPE, Université de Lorraine, Metz cedex 01, France; Loria, Université de Lorraine, France; UFR SHS, Université de Lorraine, Metz cedex 01, France","2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design (ISMAR-MASH'D)","27 Oct 2014","2014","","","65","66","We present an inquiry-based augmented reality (AR) learning environment (AIBLE) designed for teaching basic astronomical phenomena in elementary classroom (children of 8-11 years old). The novelty of this environment lies in the combination of both Inquiry Based Sciences Education and didactics principles with AR features. This environment was user tested by 69 pupils in order to assess its impact on learning. The main results indicate that AIBLE provides new opportunities for the identification of learners' problem solving strategies.","2381-8360","978-1-4799-6887-9","10.1109/ISMAR-AMH.2014.6935440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935440","Human-Centered Computing [Human-Computer Interaction]: HCI design and evaluation methods","Moon;Education;Sun;Earth;Augmented reality;Problem-solving","astronomy computing;augmented reality;computer aided instruction;educational institutions;teaching","AIBLE;inquiry-based augmented reality learning environment;astronomical phenomena teaching;elementary classroom;inquiry based science education;didactics principles;AR features","","7","","5","IEEE","27 Oct 2014","","","IEEE","IEEE Conferences"
"Butterfly effect: an augmented reality puzzle game","M. Norton; B. MacIntyre","GVU Center, Georgia Institute of Technology, Atlanta, GA, USA; GVU Center, Georgia Institute of Technology, Atlanta, GA, USA","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","212","213","Butterfly effect is a 3D puzzle game using augmented reality. The key motivation was to create a game that leverages the structure of the physical world during gameplay without requiring the computer to have a detailed model of the space. The butterflies are virtual, but the space the player navigates is physical. The player travels her environment, collecting the butterflies. For butterflies that are out of reach, the player can rotate the virtual world in 90 degree chunks about an arbitrary axis to bring them to an accessible location.","","0-7695-2459-1","10.1109/ISMAR.2005.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544699","","Augmented reality;Games;Space technology;Physics computing;Space exploration;Navigation;Scattering;Humans;Laboratories;Telephone sets","computer games;augmented reality","butterfly effect;augmented reality;3D puzzle game;gameplay;virtual world","","7","","6","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"The Ventriloquist Effect in Augmented Reality","M. Kytö; K. Kusumoto; P. Oittinen","Department of Computer Science, Aalto University School of Science; Department of Computer Science, Aalto University School of Science; Department of Computer Science, Aalto University School of Science","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","49","53","An effective interaction in augmented reality (AR) requires utilization of different modalities. In this study, we investigated orienting the user in bimodal AR. Using auditory perception to support visual perception provides a useful approach for orienting the user to directions that are outside of the visual field-of-view (FOV). In particular, this is important in path-finding, where points-of-interest (POIs) can be all around the user. However, the ability to perceive the audio POIs is affected by the ventriloquism effect (VE), which means that audio POIs are captured by visual POIs. We measured the spatial limits for the VE in AR using a video see-through head-worn display. The results showed that the amount of the VE in AR was approx. 5°–15° higher than in a real environment. In AR, spatial disparity between an audio and visual POI should be at least 30° of azimuth angle, in order to perceive the audio and visual POIs as separate. The limit was affected by azimuth angle of visual POI and magnitude of head rotations. These results provide guidelines for designing bimodal AR systems.","","978-1-4673-7660-0","10.1109/ISMAR.2015.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328059","","Visualization;Azimuth;Augmented reality;Speech;Visual perception;Navigation;Uncertainty","augmented reality;helmet mounted displays","ventriloquist effect;augmented reality;bimodal AR system;auditory perception;visual perception support;visual field-of-view;FOV;VE;video see-through head-worn display;audio POI;visual POI;points-of-interest","","6","","26","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality: Placing Labels Based on Gaze Position","A. McNamara; C. Kabeerdoss","Department of Visualization, Texas A&M University; Department of Visualization, Texas A&M University","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","36","37","The arrangement of Augmented Reality (AR) labels on mobile displays can cause problems when the labels over populate the screen space. This can result in occlusion, not only of real scene, but also of other labels annotating the scene. We are developing view management systems that arrange and display AR content based on user attention. We present a pilot user study that tests speed and accuracy on a simple information retrieval task on simulated AR scenarios. We varied the presentation in two ways: a naive approach and a gaze-based approach. The results did not show statistical differences between the two methods, yet results from this study provide valuable insight for subsequent studies.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836454","","Augmented reality;Visualization;Human computer interaction;Mobile communication;Information retrieval;Atmospheric measurements","augmented reality;information retrieval;mobile computing","gaze-based approach;naive approach;information retrieval;user attention;AR content;view management systems;mobile displays;gaze position;mobile augmented reality labels","","6","1","9","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"ELRA - Teaching Brazilian Sign Language Using Augmented Reality","D. R. Nazareth; M. A. Dos Santos Alencar; J. F. De Magalhaes Netto","Escola Superior de Tecnologia - EST, Universidade do Estado do Amazonas, Amazonas, Brasil; Inst. de Comput. - ICOMP, Univ. Fed. do Amazonas - UFAM Manaus, Brazil; Inst. de Comput. - ICOMP, Univ. Fed. do Amazonas - UFAM Manaus, Brazil","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","110","113","With the spread of information technologies and communication, the creation and use of intelligent systems have contributed to the social and digital inclusion and promoting citizenship of people. Children with hearing loss need to be inserted in early learning in signs in Brazilian Sign Language(LIBRAS). This paper describes ELRA application that uses Augmented Reality in the teaching-learning of LIBRAS. The application is under development and explores 3D objects to help children, mediated by technology.","","978-1-4799-4261-9","10.1109/SVR.2014.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913080","Sign Language;PDA;education;deaf;LIBRAS","Three-dimensional displays;Assistive technology;Augmented reality;Gesture recognition;Software;Personal digital assistants;Education","augmented reality;computer aided instruction;handicapped aids;natural language processing;sign language recognition;teaching","ELRA;Brazilian sign language teaching;augmented reality;intelligent systems;hearing loss;learning in signs in Brazilian sign language;LIBRAS","","5","","17","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"BrainChat - A Collaborative Augmented Reality Brain Interface for Message Communication","B. Kerous; F. Liarokapis","Faculty of Informatics, Masaryk University Brno, Czech Republic; Faculty of Informatics, Masaryk University Brno, Czech Republic","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","279","283","This paper presents BrainChat, an augmented reality based multiuser concept for brain-computer interfaces. The goal is to provide seamless communication based only on thoughts. A working prototype is presented, which demonstrates two-person textual communication based on non-invasive brain computer interfaces. Design choices are discussed and directions for future work are provided, considering the relevant research directions in Brain-Computer Interfaces based on Electroencephalography.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088505","","Electroencephalography;Augmented reality;Brain-computer interfaces;Brain;Electrodes;Training;Calibration","augmented reality;brain-computer interfaces;electroencephalography","noninvasive brain computer interfaces;BrainChat;collaborative augmented reality Brain interface;message communication;multiuser concept;seamless communication;working prototype;two-person textual communication;design choices;electroencephalography","","4","","24","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Spatial measurements for medical augmented reality","B. Reitinger; P. Werlberger; A. Bornik; R. Beichel; D. Schmalstieg","Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","208","209","This work presents a set of augmented reality (AR) based interaction techniques for spatial analysis of medical datasets. Computer-aided medical planning tools such as our virtual liver surgery planning system require precise and intuitive interaction for the quantitative inspection of anatomical and pathological structures. We argue that AR is a superior tool compared to desktop 2D or 3D visualization for performing such analysis, because it allows true direct manipulation of 3D virtual objects in space, while rendering the medical data in the familiar context of the user's own body.","","0-7695-2459-1","10.1109/ISMAR.2005.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544697","","Augmented reality;Biomedical imaging;Volume measurement;Liver;Oncological surgery;Distance measurement;Data analysis;Path planning;Inspection;Performance analysis","augmented reality;surgery;rendering (computer graphics);data visualisation;medical computing","spatial measurements;medical augmented reality;medical dataset rendering;computer-aided medical planning tool;virtual liver surgery planning system;3D virtual object;quantitative inspection;3D visualization","","4","","6","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Augmented reality on smartphones","A. Henrysson; M. Ollila","Norrköping Visualization and Interaction Studio, Linköping University, Norrkoping, Sweden; Norrköping Visualization and Interaction Studio, Linköping University, Norrkoping, Sweden","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","27","28","Smartphones with built-in cameras are becoming ubiquitous. These devices couple a camera with communication and processing units and are increasingly capable of 3D rendering. We have conducted camera sensitivity test on current smartphones to evaluate in what extent they can be used for augmented reality (AR) using optical tracking.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320421","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320421","","Augmented reality;Smart phones;Smart cameras;Rendering (computer graphics);Optical sensors;Displays;Image resolution;Testing;Optical mixing;Decoding","augmented reality;mobile handsets;cameras;optical tracking","augmented reality;smartphones;built-in cameras;3D rendering;optical tracking;camera sensitivity test","","4","","5","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"[POSTER] Automated Evaluation and Configuration of Object Tracking for Augmented Reality","K. K. Thiel; E. Jundt; G. Klinker","Volkswagen AG; Volkswagen AG; TU, Munich","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","132","134","Object tracking configuration is a tedious task for users due to an overwhelming amount of parameters while solving a multicriterial optimisation problem for a black box. With increasing complexity of the algorithms and fast changing situations due to the upcoming fourth industrial revolution, even experts will find themselves struggling with this topic. For this reason we present a concept for an automated evaluation and configuration of object tracking algorithms used in augmented reality applications. Given an arbitrary but specified use case the best suitable parameter set shall be found. Therefore the concept utilises statistical analysis of the vast parameter space performing multicriterial optimisation regarding a formalisation of the tracking quality within a virtual testbed.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088465","","Optimization;Target tracking;Augmented reality;Object tracking;Complexity theory;Industries","augmented reality;object tracking;optimisation;statistical analysis","statistical analysis;augmented reality applications;object tracking algorithms;black box;multicriterial optimisation problem","","3","1","11","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"3DOF tracking accuracy improvement for outdoor Augmented Reality","J. Park; J. Park","Hongik University, Seoul, South Korea; Hongik University, Seoul, South Korea","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","263","264","Outdoor Augmented Reality (AR) gained popularity recently due to its potential for location based mobile services. However, most commercially available Global Positioning Systems (GPS), except for the expensive high-end models, do not provide accurate location information that is enough to be used for displaying practically meaningful location based information. In this paper, we present a computer vision based method for improving user's two dimensional location and one-dimensional orientation, the initial values of which are obtained from a GPS and a digital compass. Our method utilizes corner positions of buildings in the map and the vertical edges of the buildings in the captured images. We applied anisotropic diffusion in order to filter noise and preserve edges, and dual vertical edge filters on gray and saturation images. Our method is suitable for mobile services in urban environments where tall buildings degrade GPS signals. In average, our method improved 15.0 meters in position and 2.2 degrees in orientation.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643598","outdoor tracking;LBS;anisotropic diffusion","Global Positioning System;Image edge detection;Buildings;Accuracy;Compass;Anisotropic magnetoresistance;Augmented reality","augmented reality;computer vision;filtering theory;Global Positioning System;image denoising","3DOF tracking accuracy improvement;outdoor augmented reality;global positioning systems;location based mobile services;computer vision based method;two dimensional location;one-dimensional orientation;digital compass;anisotropic diffusion;dual vertical edge filters;saturation images;gray images;GPS signals","","3","2","7","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Birds vs. Fish: Visualizing Out-of-View Objects in Augmented Reality using 3D Minimaps","F. Bork; U. Eck; N. Navab","Chair for Computer Aided Medical Procedures, Technische Universität München, Munich, Germany; Chair for Computer Aided Medical Procedures, Technische Universität München, Munich, Germany; Chair for Computer Aided Medical Procedures, Technische Universität München, Munich, Germany","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","285","286","Despite recent technological advanced in Augmented Reality (AR), the majority of state-of-the-art head-mounted displays (HMDs) still suffers from a limited field of view. Hence, there is a high probability that virtual objects are located outside of the user's view. Several approaches to mitigate the problem of out-of-view objects have been proposed in the past by using visualization techniques to guide the user's attention towards such objects. However, none of these techniques provides any context about the real environment. Current state-of-the-art HMDs are equipped with various sensors to create a 3D map of the environment. In this work, we leverage such 3D reconstructions and developed a set of different 3D minimap visualizations for conveying information about out-of-view objects in AR. We propose a novel kind of minimap using stereographic fisheye projection and compare it to more traditional, bird's-eye view minimaps. Preliminary results show that our stereographic fisheye minimap offers a set of distinct advantages over bird's-eye view minimaps that facilitate the localization of virtual objects in AR environments.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951973","","Visualization;Three-dimensional displays;Cameras;Augmented reality;Games;Head-mounted displays;Sensors","augmented reality;data visualisation;helmet mounted displays","augmented reality;head-mounted displays;visualization techniques;HMDs;3D reconstructions;stereographic fisheye minimap;3D minimap visualizations;out-of-view object visualization;3D map;stereographic fisheye projection;bird-eye view minimaps;AR environments;virtual object localization","","3","","5","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Augmented Reality for Vocational Education Training in K12 Classrooms","M. Belani; A. Parnami","Indraprastha Institute of Information Technology, Delhi; Indraprastha Institute of Information Technology, Delhi","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","317","320","Vocational Education Training (VET) is becoming a more integral part of the curriculum to account for the requirement of skilled workforce in the global scenario. Augmented Reality (AR) can serve as a valuable medium to integrate this aspect into mainstream educational systems. In this work, we explore the feasibility of AR for vocational skill training of students at the K12 level based on the state of the art literature analysis. Furthermore, we propose opportunities concerned with the aspects of effective integration and usability of these training modules into the traditional pedagogical systems.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288407","Human-centered computing;Visualization;Visualization techniques;Treemaps;Human-centered computing;Visualization;Visualization design and evaluation methods","Training;Design methodology;Sociology;Usability;Statistics;Augmented reality","augmented reality;computer based training;computer science education;educational courses;educational institutions;vocational training","augmented reality;training modules;K12 Classrooms;vocational education training;skilled workforce;literature analysis","","3","","39","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"PoLAR: A Portable Library for Augmented Reality","P. -J. Petitprez; E. Kerrien; P. -F. Villard","Inria, Villers-les-Nancy, France; Inria, Villers-les-Nancy, France; Inria, Villers-les-Nancy, France","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","227","230","We present here a novel cross-platform library to facilitate research and development applications dealing with augmented reality (AR). Features include 2D and 3D objects visualization and interaction, camera flow and image manipulation, and soft-body deformation. Our aim is to provide computer vision specialists' with tools to facilitate AR application development by providing easy and state of the art access to GUI creation, visualization and hardware management.We demonstrate both the simplicity and the efficiency of coding AR applications through three detailed examples. PoLAR can be downloaded at http://polar.inria.fr and is distributed under the GPL licence.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836502","1.3.4 [Computer Graphics]: Graphics Utilities—Application packages; I.4.9 [Image Processing and Computer Vision]: Applications—[I.6.8]: Simulation and Modeling—Types of Simulation Animation","Three-dimensional displays;Libraries;Cameras;Two dimensional displays;Engines;Augmented reality;Graphical user interfaces","augmented reality;data visualisation;digital libraries;graphical user interfaces;image processing;research and development;software tools;solid modelling","3D models;hardware management;GUI creation;AR application development tools;computer vision specialists;soft-body deformation;image manipulation;camera flow;objects interaction;3D objects visualization;2D objects visualization;research and development applications;cross-platform library;augmented reality;portable library;PoLAR","","3","","9","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"AR UX design: Applying AEIOU to handheld augmented reality browser","Mandi Jieying Lee; Yuan Wang; H. B. -L. Duh","Keio-NUS CUTE Center / IDMI, National University of Singapore, Singapore; Keio-NUS CUTE Center / IDMI, National University of Singapore, Singapore; Keio-NUS CUTE Center / IDMI / ECE, National University of Singapore, Singapore","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","99","100","With maturing technologies and availability of the sensor-enriched device, the driving force behind handheld augmented reality (HAR) technology will be leaning towards the experience technology can bring. Though attentions are gathered on usability and conventions for this technology, the user experience cannot be ignored. It will be more commonly available in the hands of the public and become a technology that is not solely used by experts. It will be important to approach the technology with friendlier and more user-centered focus to bring it out of research labs and into people's life. In this paper, we will introduce design exploration constructs inspired from a method that is commonly used in the field of the industrial design to guide designers of HAR application to explore different aspects of user experience. The purpose of proposing AEIOU is to provide a platform to create encompassing user experience that is beyond the usability considerations or the existing design conventions. The advantage of having such a platform is to provide a starting ground for discussion and betterment of HAR application. The use of these constructs is discussed in relation to the design process of AR browser.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6484000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6484000","Interaction and interactivity;user experience;practice and methods","Browsers;Augmented reality;Usability;Educational institutions;Buildings;Layout;Availability","augmented reality","AR UX design;AEIOU;handheld augmented reality browser;sensor enriched device;HAR;user centered focus;industrial design","","3","","12","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Vision-based augmented reality for pilot guidance in airport runways and taxiways","J. Molineros; R. Behringer; C. Tam","Rockwell Science Center, USA; Rockwell Science Center, USA; Rockwell Science Center, USA","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","302","303","This paper describes our on-going efforts to develop an augmented reality system for enhanced pilot situational awareness in airport runways and taxiways. The system consists of a sensing component based on computer vision and an information component based on high-fidelity graphic model databases. Vision algorithms are used for a variety of guidance and warning tasks. A necessary requirement is for vision algorithms to have a real-time response.","","0-7695-2191-6","10.1109/ISMAR.2004.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383087","","Augmented reality;Airports;Image databases;Spatial databases;Visual databases;Graphics;Data mining;Feature extraction;Character recognition;Optical character recognition software","computer vision;augmented reality;visual databases;real-time systems;airports;aircraft landing guidance","vision-based augmented reality;pilot guidance;airport runways;taxiways;pilot situational awareness;computer vision;high-fidelity graphic model databases;real-time response","","2","1","9","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"Forked! A demonstration of physics realism in augmented reality","D. Beaney; B. Mac Namee","DIT AI Group, School of Computing, Dublin Institute of Technology, Ireland; DIT AI Group, School of Computing, Dublin Institute of Technology, Ireland","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","171","172","In making fully immersive augmented reality (AR) applications, real and virtual objects will have to be seen to physically interact together in a realistic and believable way. This paper describes Forked! a system that has been developed to show how physical interactions between real and virtual objects can be simulated realistically and believably through appropriate use of a physics engine. The system allows users control a robotic forklift to manipulate virtual crates in an AR environment. The paper also describes a evaluation experiment in which it is shown that the physical interactions between the forklift and the virtual creates are realistic and believable enough to be comparable with the physical interactions between a forklift and real crates.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336479","","Augmented reality;Robot kinematics;Engines;Robot control;Artificial intelligence;Physics computing;Control systems;Performance evaluation;Layout;Cameras","augmented reality;manipulators","physics realism;augmented reality;Forked!;robotic forklift;virtual crates","","1","","5","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Annotation-based assistance system for unmanned helicopter with wearable augmented reality environment","M. Koeda; Y. Matsumoto; T. Ogasawara","Nara Institute of Science and Technology, Ikoma, Nara, Japan; Nara Institute of Science and Technology, Ikoma, Nara, Japan; Nara Institute of Science and Technology, Ikoma, Nara, Japan","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","288","289","In this paper, we introduce an annotation-based assistance system for an unmanned helicopter with a wearable augmented reality environment. In this system, an operator controls the helicopter remotely while watching an annotated view from the helicopter through a head mounted display (HMD) with a laptop PC in a backpack. Annotations assist the operation indicating some conditions of the helicopter and a name of buildings nearby. The position and the attitude of the helicopter is measured by GPS and a gyroscope, and sent to the operator's PC via a wireless LAN.","","0-7695-2191-6","10.1109/ISMAR.2004.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383080","","Helicopters;Augmented reality;Wireless LAN;Gyroscopes;Control systems;Global Positioning System;Cameras;Head;Payloads;Image generation","augmented reality;wearable computers;helmet mounted displays;telecontrol;aircraft control;wireless LAN;Global Positioning System;laptop computers;remotely operated vehicles;aerospace computing;helicopters","annotation-based assistance system;unmanned helicopter;wearable augmented reality environment;remote control;head mounted display;laptop PC;GPS;gyroscope;wireless LAN","","1","","3","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"Adaptive Augmented Reality Using Context Markup and Style Maps","E. Mendez; D. Schmalstieg","Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","267","268","Augmented reality (AR) enables users to visualize synthetic information overlaid on top of real imagery. Such visualization may be achieved by tools that distort, filter or enhance the explored information. However, little to no work has focused on the separation of style definitions and their mapping to scene objects. We target this separation based on a context rich scenegraph. Our research allows the definition of visualization styles independent on the data to be visualized.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538860","Object overlay and spatial layout techniques;real-time rendering;interaction techniques for MR/AR","Augmented reality;Layout;Information filtering;Data visualization;Lenses;Computer graphics;Rendering (computer graphics);Data structures;Displays;Information filters","augmented reality;data visualisation;realistic images","adaptive augmented reality;context markup;style maps;visualize synthetic information;scenegraph","","1","","5","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Specular reflection elimination for projection-based augmented reality","Hanhoon Park; Moon-Hyun Lee; Sang-Jun Kim; Jong-Il Park","Department of ECE, Hanyang University, Seoul, South Korea; Department of ECE, Hanyang University, Seoul, South Korea; Department of ECE, Hanyang University, Seoul, South Korea; Department of ECE, Hanyang University, Seoul, South Korea","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","194","195","In projection-based augmented reality, specular reflection may distract the users. This work demonstrates that the specular reflection can be eliminated by redundantly illuminating the projection surface using multiple overlapping projectors mounted at different locations. Our initial system using two projectors is presented. The system automatically determines the pixels which include specular reflection in one projector, blank the light falling on the pixel and boost the other projector's output so that the added light is projected onto the pixel consistently.","","0-7695-2459-1","10.1109/ISMAR.2005.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544690","","Augmented reality;Optical reflection;Geometry;Surface reconstruction;Calibration;Cameras;Visual effects;Virtual environment;Image reconstruction;Optimization methods","augmented reality;computational geometry;cameras;optical projectors;lighting","specular reflection elimination;projection-based augmented reality;projection surface;multiple overlapping projector","","1","2","8","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"A dice game in third person augmented reality","R. Colvin; T. Hung; D. Jimison; B. Johnson; E. Myers; T. Blaine","Entertainment Technology Center, Carnegie Mellon University, Pittsburgh, PA, USA; Entertainment Technology Center, Carnegie Mellon University, Pittsburgh, PA, USA; Entertainment Technology Center, Carnegie Mellon University, Pittsburgh, PA, USA; Entertainment Technology Center, Carnegie Mellon University, Pittsburgh, PA, USA; Entertainment Technology Center, Carnegie Mellon University, Pittsburgh, PA, USA; Entertainment Technology Center, Carnegie Mellon University, Pittsburgh, PA, USA","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","3","4","We describe a prototype entertainment application of the augmented-reality toolkit based on a fantasy dice game. Two players roll dice bearing glyphs that are interpreted by a computer, which provides graphical and auditory feedback. Our prototype uses entirely consumer-grade equipment: a USB Webcam, a projector, and a 2 GHz desktop with 5.1 surround speakers. Unlike many AR-Toolkit applications, our players are not encumbered by head-mounted displays. Face-to-face gameplay, integrated with the physicality of a traditional dice game, display results on a shared projection screen from a third-person point-of-view. This combination of elements provides a unique application of AR-Toolkit for merging the spectacle of modern video games with a tangible interface.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320416","","Augmented reality;Games;Cameras;Application software;Prototypes;Feedback;Computer displays;Auditory displays;Loudspeakers;Universal Serial Bus","computer games;augmented reality;user interfaces;entertainment","entertainment application;augmented reality toolkit;fantasy dice game;graphical feedback;auditory feedback;consumer-grade equipment;USB Webcam;face-to-face gameplay;shared projection screen;video games","","1","5","6","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"Augmented reality in support of interaction for location-aware applications","K. Rehman","Laboratory for Communication Engineering, University of Cambridge, Cambridge, UK","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","286","287","There has been an increased interest in both the augmented reality (AR) and ubiquitous computing (Ubicomp) research communities to integrate these two technologies. In an attempt to introduce visual interaction into location-aware applications we have developed a prototype that lets users experience a Ubicomp environment visually. Some system issues we came across in accomplishing this task are described.","","0-7695-2191-6","10.1109/ISMAR.2004.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383079","","Augmented reality;Pervasive computing;Prototypes;Yarn;Laboratories;Design engineering;Ubiquitous computing;Physics computing;Visualization;Programming profession","augmented reality;mobile computing","augmented reality;location-aware applications;ubiquitous computing;visual interaction","","","","3","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"[POSTER] An Adaptive Augmented Reality Interface for Hand Based on Probabilistic Approach","J. Jung; H. Lee; H. S. Yang","Korea Advanced Institute of Science and Technology, Daejeon, Daejeon, KR; Korea Advanced Institute of Science and Technology, Daejeon, Daejeon, KR; Korea Advanced Institute of Science and Technology, Daejeon, Daejeon, KR","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","152","155","In this paper we propose an adaptive Augmented Reality interface for hand gestures based on a probabilistic model. The proposed method provides an in-situ interface and the corresponding functionalities by recognizing a context of hand shape and gesture which requires the accurate recognition of static and dynamic hand states. We present an appearance-based hand feature representation that yields robustness against hand shape variations, and a feature extraction method based on the fingertip likelihood from a GMM model. Experimental results show that both context-sensitivity and accurate hand gesture recognition are achieved throughout the quantitative evaluation and its implementation as a three-in-one virtual interface.","","978-1-4673-7660-0","10.1109/ISMAR.2015.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328084","","Shape;Estimation;Gesture recognition;Accuracy;Robustness;Augmented reality;Adaptation models","augmented reality;feature extraction;Gaussian processes;gesture recognition;image representation;mixture models;shape recognition","adaptive augmented reality interface;probabilistic model;hand shape recognition;appearance-based hand feature representation;feature extraction method;fingertip likelihood;GMM model;context-sensitivity;hand gesture recognition;three-in-one virtual interface;Gaussian mixture model","","","","8","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"[Poster] Augmented reality binoculars on the move","T. Oskiper; M. Sizintsev; V. Branzoi; S. Samarasekera; R. Kumar",SRI International; SRI International; SRI International; SRI International; SRI International,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","289","290","In this paper, we expand our previous work on augmented reality (AR) binoculars to support wider range of user motion - up to thousand square meters compared to only a few square meters as before. We present our latest improvements and additions to our pose estimation pipeline and demonstrate stable registration of objects on the real world scenery while the binoculars are undergoing significant amount of parallax-inducing translation.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948454","inertial navigation;sensor fusion;EKF","Augmented reality;Global Positioning System;Materials;Training;Accuracy;Google;Earth","augmented reality;image registration;interactive devices;pose estimation","augmented reality binoculars;AR binoculars;user motion;pose estimation;object registration;parallax-inducing translation","","","","4","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Utilizing Augmented Reality for Performance and Decision-Making in Collaborative Time-Critical Environments","J. Gower",University of South Australia,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","946","949","The world has seen the introduction of new technology such as smart-phones and more readily accessible and portable AR HMDs. These technological advancements have paved the way for advances in the space of AR resulting in a boom of research interested in this field. The use of AR for supporting task performance, decision-making, and collaboration are some of the areas that are being explored within this space. Research conducted within these areas has managed to produce promising results showing that AR if used and designed correctly can be used as an effective tool to increase performance and support decision-making and collaboration. However, there is a lack of research that brings together all these elements. There is also a lack of research that has been conducted using AR with a focus on time-critical tasks. This work aims to explore whether augmented reality can improve performance and decision-making in collaborative time-critical tasks and how this can be achieved.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974334","","Decision making;Collaboration;Space exploration;Time factors;Task analysis;Augmented reality","augmented reality;decision making","augmented reality;collaborative time-critical environments;collaborative time-critical tasks;decision-making;portable AR HMDs;readily accessible AR HMDs;smart-phones;task performance;technological advancements","","","","26","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Testable design representations for mobile augmented reality authoring","C. Geiger; V. Paelke; C. Reimann; W. Rosenbach; J. Stoecklein","Hochschule Harz, Germany; C-Laboratories, Germany; C-Laboratories, Germany; Siemens SBS C-LAB, Germany; Siemens SBS C-LAB, Germany","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","281","282","This paper applies the idea of a continuously testable design representation to authoring of augmented realities for mobile devices.","","0-7695-1781-1","10.1109/ISMAR.2002.1115113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115113","","Testing;Augmented reality;Prototypes;Automata;Iterative methods;Mobile computing;Wireless communication;Communications technology;Hardware;Personal digital assistants","augmented reality;user interfaces;mobile computing;authoring systems","testable design representations;mobile augmented reality authoring;mobile devices;prototyping;mobile computing","","","","5","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Hand gesture control of virtual object in augmented reality","S. S. Rani; K. J. Dhrisya; M. Ahalyadas","Amrita Vishwa Vidyapeetham, Coimbatore, Tamil Nadu, IN; Department of Computer Science and Engineering, Amrita University, India; Department of Computer Science and Engineering, Amrita University, India","2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","4 Dec 2017","2017","","","1500","1505","Augmented Reality (AR) is an emerging field, which is evolving exponentially. Its concept is to coalesce the virtual world into the real world. The augmented reality intent to enhance our perception of the real world by integrating virtual objects. The existing Augmented Reality Hand gesture control systems detect hand gesture and embed the virtual object in augmented reality using markers and motion sensing devices like Kinect. In this paper, a new Hand Gesture Control in Augmented Reality System (HGCARS) is introduced in which the gesture recognition is performed using a secondary camera and the reality is captured using an IP camera. The virtual object is inserted into the video feed obtained from an IP camera. The virtual object is controlled by using the position and depth of user's hand, measured using a simple webcam, thus reducing the cost of implementation.","","978-1-5090-6367-3","10.1109/ICACCI.2017.8126053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8126053","Augmented Reality;Hand Gesture;Tracking;Virtual Objects;Real world","Skin;Augmented reality;Cameras;Image color analysis;Gesture recognition;Feature extraction","augmented reality;cameras;gesture recognition","virtual object;virtual world;existing Augmented Reality Hand gesture control systems;hand gesture recognition;augmented reality system;hand gesture detection;motion sensing devices;HGCARS;secondary camera;IP camera","","12","","12","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Smart devices, smart environments, smart students - A review on educational opportunities in virtual and augmented reality learning environments","G. Molnár; D. Sik","Department of Technical Education, Budapest University of Technology and Economics, Budapest, Hungary; Department of Technical Education, Budapest University of Technology and Economics, Budapest, Hungary","2019 10th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)","11 May 2020","2019","","","495","498","In our paper we present currently used and researched devices and environments supporting the experience-based educational opportunities. We focused on the various virtual and augmented reality devices, applications and environments including the combination of the different tools. Our future aims are to create a concept how it is possible to combine these systems in the fields of education.","2380-7350","978-1-7281-4793-2","10.1109/CogInfoCom47531.2019.9089984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089984","Leonar3Do;Leap Motion;Smart glasses;MaxWhere;virtual and augmented reality","Conferences;Three-dimensional displays;Education;Augmented reality;Tools;Smart devices;Smart glasses","augmented reality;computer aided instruction","smart devices;smart environments;smart students;virtual reality learning environments;augmented reality learning environments;experience-based educational opportunities;virtual reality devices;augmented reality devices","","6","","30","IEEE","11 May 2020","","","IEEE","IEEE Conferences"
"Exploration of design methods and tools for virtual, augmented and mixed reality","A. M. Olthof; J. Verlinden; S. B. Allouch",Amsterdam University of Applied Sciences University of Amsterdam; University of Antwerp; University of Amsterdam,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","233","237","This paper shows an overview of design practices of the XR-lab at the Amsterdam University of Applied Sciences, The Netherlands. Over the course of six years, interdisciplinary teams of students have delivered 55+ prototypes in virtual, augmented, and mixed reality for a variety of 40+ clients. As human-computer interaction is entering a new evolutionary phase towards human-computer integration, new opportunities in extended reality (XR) have the potential to funda-mentally alter human characteristics and abilities. Therefore, this paper begins with taking a philosophical stance on ‘being human’ and the anthropological concept of ‘liminality’ in XR-experiences. A further exploration of the concept of 'emotional rehearsal spaces' uses know-how from performance art, dance, architecture, and dra-maturgy. Insights from tangible practices at the XR-lab show the cultural journey in XR-collaborations. This is made visible through a quick and dirty experiment on artistic thinking, design thinking, and system thinking, which shows how interdisciplinary collaborations are able to ignite new combinations of thought in design teams and individual professionals. Finally, we show an overview of specific design methods and tools that have been explored at the XR-lab over the years.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974210","Exploration;design methods;design tools;human enhancement;extended reality;mixed reality;augmented reality;virtual reality;Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Mixed / augmented reality;Human-centered computing-Interaction design-Interaction design theory;concepts and paradigms","Art;Shape;Extended reality;Mixed reality;Prototypes;Computer architecture;Teamwork","art;computer aided instruction;history;humanities;organisational aspects;professional aspects;virtual reality","Amsterdam University;Applied Sciences;augmented reality;augmented, reality;design practices;design teams;design thinking;emotional rehearsal spaces;extended reality;human characteristics;human-computer integration;human-computer interaction;mixed reality;specific design methods;tangible practices;virtual reality;XR-collaborations;XR-experiences;XR-lab","","","","20","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"User-Centered Prototyping for Single-User Cross-Reality Virtual Object Transitions","N. Wang; F. Maurer",University of Calgary; University of Calgary,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","171","174","Cross-reality is a newly emerged research field that studies the transition and current usage of multiple systems along Milgram's Reality-Virtuality Continuum(RVC). Our research currently focuses on studying how the user could interact with CR applications and move virtual objects along Milgram's RVC. The prototype is an embodiment of an application and can be used to gain insights and knowledge. We build low-fidelity and high-fidelity prototypes to study the transition of 3D virtual objects. However, We face challenges since cross-reality involves more than one space on the RVC, so when designing the prototype, researchers and designers can not refer to their previous experience and interaction metaphor from a space they are familiar with, such as physical, AR, or VR space. Thus we plan to conduct elicitation studies to gain more knowledge and insights to serve as a benchmark to guide the design of the prototypes.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974379","Human-centered computing;Interaction design;Interaction design process and methods;User centered design Human-centered computing;Mixed / augmented reality Human-centered computing;Virtual reality","Three-dimensional displays;Prototypes;Benchmark testing;Augmented reality;Faces;Guidelines","augmented reality;user centred design","3D virtual objects;CR applications;high-fidelity prototypes;interaction metaphor;Milgram reality-virtuality continuum;Milgram RVC;single-user cross-reality virtual object transitions;user-centered prototyping","","","","41","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"An Optimal Visualization of Traffic System by using Augmented Reality and Virtual Reality","R. Dang; V. Krishna; R. Sharma; M. Kowsigan","Department of Computing Technologies, SRM Institute of Science and Technology, Chengalpet, India; Department of Computing Technologies, SRM Institute of Science and Technology, Chengalpet, India; Department of Computing Technologies, SRM Institute of Science and Technology, Chengalpet, India; Department of Computing Technologies, SRM Institute of Science and Technology, Chengalpet, India","2023 3rd International Conference on Smart Data Intelligence (ICSMDI)","26 May 2023","2023","","","309","315","This study explains the concept of deadlock by focusing on prevention and avoidance with the help of one of the emerging technologies, Augmented Reality (AR). With the help of AR, people can easily understand this concept. This can be easily explained with the help of real time example of traffic system on the road. To solve this issue, this study has implemented the Bankers Algorithm, which is a Deadlock Prevention Algorithm. The Bankers Algorithm can use its calculation and prevent the occurrence of Deadlock or incase a deadlock is happening it can help to resolve it.","","978-1-6654-6487-1","10.1109/ICSMDI57622.2023.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127942","Bankers Algorithm;Deadlock;Augmented Reality;Traffic Jam;Traffic Control System","Roads;Focusing;Games;System recovery;Control systems;Real-time systems;Augmented reality","augmented reality;concurrency control;flexible manufacturing systems;virtual reality","Augmented Reality;Bankers Algorithm;Deadlock Prevention Algorithm;optimal visualization;time example;traffic system;virtual Reality","","","","12","IEEE","26 May 2023","","","IEEE","IEEE Conferences"
"How does Augmented Reality Improve the Play Experience in Current Augmented Reality Enhanced Smartphone Games?","M. Wölfel; M. Braun; S. Beuck","Faculty of Computer Science and Business Information Systems, Karlsruhe University of Applied Sciences, Karlsruhe, Germany; School of Digital Media, Furtwangen University, Furtwangen, Germany; School of Digital Media, Furtwangen University, Furtwangen, Germany","2019 International Conference on Cyberworlds (CW)","5 Dec 2019","2019","","","407","410","This paper investigates the current state of handheld augmented reality (AR) gaming apps available on the App Store (iOS) and the Play Store (Android). To be able to directly compare the differences between games played with and without AR, only games in which the AR mode can be switched on/off were investigated. Because the main scope of this paper is on the evaluation of the experience provided by AR, parts of the game experience questionnaire (GEQ) have been included in the empirical study. It showed that AR has big potential to improve immersion or flow in the game-play. This paper also identifies differences in the implementation of AR features and investigates how and what parameter in the GEQ can be positively influenced.","2642-3596","978-1-7281-2297-7","10.1109/CW.2019.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919204","augmented reality;mobile games;game experience;hand-held devices","Games;Land mobile radio;Three-dimensional displays;Augmented reality;Switches;Task analysis","augmented reality;computer games;mobile computing;smart phones;user interfaces","Android;iOS;GEQ;game-play;game experience questionnaire;Play Store;App Store;handheld augmented reality gaming apps;smartphone games;play experience","","1","","11","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"EnterCY: A Virtual and Augmented Reality Tourism Platform for Cyprus","S. Constantinou; A. Pamboris; R. Alexandrou; C. Kronis; D. Zeinalipour-Yazti; H. Papadopoulos; A. Konstantinidis","University of Cyprus, Nicosia, Cyprus; Frederick University, Nicosia, Cyprus; Frederick University, Nicosia, Cyprus; Frederick University, Nicosia, Cyprus; University of Cyprus, Nicosia, Cyprus; Frederick University, Nicosia, Cyprus; University of Cyprus, Nicosia, Cyprus","2022 23rd IEEE International Conference on Mobile Data Management (MDM)","25 Aug 2022","2022","","","314","317","This demo paper presents EnterCY, an integrated Virtual and Augmented Reality Tourism platform for Cyprus. The platform's web-based, spatio-temporal virtual exploration component allows potential visitors to explore the rich cultural heritage, variety of activities, and wealth of sightseeing locations in Cyprus before their visit. EnterCY also enhances tourists' experiences during their visit through its mobile component, which offers on-site visual and audio guidance, personalized recommendations, as well as entertaining and learning features (e.g., story-telling), based on mobile-friendly Augmented Reality, location-awareness and Machine Learning technologies. Through Immersive Reality technologies, the platform provides for an after visit experience by creating personalized 360 video mementos of tourists' tours and supports integrated features that allow for experience sharing in popular social media platforms.","2375-0324","978-1-6654-5176-5","10.1109/MDM55031.2022.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9861199","Virtual Reality;Augmented Reality;Tourism Platform;Location Awareness;AI Based Recommendation","Visualization;Social networking (online);Machine learning;Cultural differences;Augmented reality","augmented reality;data visualisation;Internet;learning (artificial intelligence);mobile computing;social networking (online);travel industry;user interfaces;virtual reality","Cyprus;demo paper presents EnterCY;spatio-temporal virtual exploration component;potential visitors;rich cultural heritage;tourists;mobile component;on-site;audio guidance;entertaining learning features;mobile-friendly Augmented Reality;Machine Learning technologies;Immersive Reality technologies;visit experience;popular social media platforms","","","","4","IEEE","25 Aug 2022","","","IEEE","IEEE Conferences"
"Designing Virtual Pedagogical Agents and Mentors for Extended Reality","T. D. Do",University of Central Florida,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","476","479","The use of virtual and augmented reality for educational purposes has seen a rapid increase in interest in recent years. Extended reality offers unique affordances to learners, and can enhance learning. Specifically, we are interested in the use of pedagogical agents in extended reality due to their potential to increase student motivation and learning. However, the design of pedagogical agents in extended reality is still a nascent area of study, which can be important in an immersive environment where social cues can be more salient. Pedagogical agent design aspects such as speech, appearance, and modality can prime social cues and affect learning outcomes and instructor perception. In this paper, we propose a project to investigate auditory and visual social cues of pedagogical agents in XR such as speech, ethnicity, and modality.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00112","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585866","Computing methodologies;Computer graphics;Graphics systems and interfaces;Mixed / augmented reality;Applied computing;Education;Interactive learning environments","Visualization;Extended reality;Affordances;X reality","augmented reality;computer aided instruction","extended reality;pedagogical agent design aspects;virtual pedagogical agents;virtual reality;augmented reality;student motivation;student learning;social cues;XR","","1","","37","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Zero-Programming Augmented Reality Authoring Tools for Educators: Status and Recommendations","S. Vert; D. Andone","Multimedia Research Center, Politehnica University of Timisoara, Timisoara, Romania; eLearning Center, Politehnica University of Timisoara, Timisoara, Romania","2017 IEEE 17th International Conference on Advanced Learning Technologies (ICALT)","7 Aug 2017","2017","","","496","498","Augmented reality technologies are being used in education to create engaging and memorable learning experiences for the students. To boost the adoption of such technologies even further, educators need access to augmented reality authoring tools that do not require programming skills, are under constant maintenance and development, are easy to use, are free and whose outputs can reach a wide range of students. Over the recent years, several such products have been launched on the market and have been used successfully in creating learning activities. In this paper we look at the current options, with a focus on what features have yet to be implemented in order to expand the possibilities of augmented reality in education.","2161-377X","978-1-5386-3870-5","10.1109/ICALT.2017.129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8001842","augmented reality learning;augmented reality authoring tools;technology-enhanced education","Augmented reality;Tools;Education;Programming profession;Games;Three-dimensional displays","augmented reality;computer aided instruction","zero-programming augmented reality authoring tools;education;memorable learning experiences","","5","","22","IEEE","7 Aug 2017","","","IEEE","IEEE Conferences"
"Augmented Reality in Food production traceability – use case","V. Todorović; N. Milić; M. Lazarević","Industrial Engineering and Engineering Management, University of Novi Sad, Novi Sad, Republic of Serbia; Graphical Engineering and Design, University of Novi Sad, Novi Sad, Republic of Serbia; Industrial Engineering and Engineering Management, University of Novi Sad, Novi Sad, Republic of Serbia","IEEE EUROCON 2019 -18th International Conference on Smart Technologies","11 Oct 2019","2019","","","1","5","The contemporary food supply chain should adequately provide information that consumers and other concerned bodies need to know such as variety of the food attributes, country of origin, way of production etc. This paper discusses the use of Augmented Reality (AR) applications for the needs of food traceability. The aim of this paper is to provide an update on the contemporary knowledge and scientific development of mobile augmented reality (MAR) in food production and packaging systems, and to identify future needs for bringing the Augmented Reality (AR) to the food market. By showing the case of a developed mobile app based on Augmented Reality, this paper gives an example of the usage of MAR in food packaging.","","978-1-5386-9301-8","10.1109/EUROCON.2019.8861734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861734","Augmented Reality;Mobile application;Food traceability;Mobile Augmented Reality;Food labeling;Food production","Production;Augmented reality;Packaging;Feeds;Safety;Mobile handsets;Business","augmented reality;food packaging;food processing industry;food products;labelling (packaging);mobile computing;production engineering computing;supply chain management","mobile augmented reality;food packaging;food traceability;food production;supply chain;mobile application;food labeling","","3","","19","IEEE","11 Oct 2019","","","IEEE","IEEE Conferences"
"Time-domain augmented reality based on locally adaptive video sampling","T. Orikasa; S. Kagami; K. Hashimoto","Graduate School of Information Sciences, University of Tohoku, Japan; Graduate School of Information Sciences, University of Tohoku, Japan; Graduate School of Information Sciences, University of Tohoku, Japan","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","261","262","We propose a new approach for augmented reality, in which real-world scene images are augmented with video fragments manipulated in the time domain. The proposed system aims to display slow-motion video sequences of moving objects instantly without accumulated time lag so that a user can recognize and observe high-speed motion on the spot. Images from a high-speed camera are analyzed to detect regions with important visual features, which are overlaid on a normal-speed video sequence.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643597","","Pixel;Streaming media;Video sequences;Time domain analysis;Cameras;Instruction sets;Real time systems","augmented reality;image sampling;image sensors;image sequences","time domain augmented reality;locally adaptive video sampling;real world scene images;video fragments;slow motion video sequences;high speed camera;high speed motion","","2","","7","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Loosely-coupled mixed reality: Using the environment metaphorically","M. Lee; G. J. Kim","Digital Experience Laboratory, Korea University, South Korea; Digital Experience Laboratory, Korea University, South Korea","2009 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media and Humanities","17 Nov 2009","2009","","","51","52","Mixed reality refers to the compositing of synthetic and real objects. The two forms of mixed reality are the augmented reality and augmented virtuality. The association between the real and virtual objects, in both cases,is usually desired to be as tight and explicit as possible. The paper proposes a new form of mixed reality called the ""Loosely coupled Mixed Reality"" which uses only minimal explicit and technologically supported association cues between the real and virtual objects.","2381-8360","978-1-4244-5508-9","10.1109/ISMAR-AMH.2009.5336726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336726","","Virtual reality;Land mobile radio;Usability;Humans;Augmented reality;Augmented virtuality;Displays;Sensor systems;Wearable sensors;Computational efficiency","augmented reality","augmented reality;augmented virtuality;real objects;virtual objects;loosely coupled mixed reality;synthetic objects","","1","","3","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"EXMAR: EXpanded view of mobile augmented reality","S. Hwang; H. Jo; J. -h. Ryu","KAIST, Graduate School of Culture Technology, South Korea; KAIST, Graduate School of Culture Technology, South Korea; KAIST, Graduate School of Culture Technology, South Korea","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","235","236","There have been many studies to minimize the psychological and physical load increase caused by mobile augmented reality systems. In this paper, we propose a new technique called “EXMAR”, which enables the user to explore his/her surroundings with an expanded field of view, resulting in a decrease of physical movement. Through this novel interaction technique, the user can explore off-screen point of interests with environmental contextual information by simple dragging gestures. To evaluate this initial approach, we conducted a proof of concept usability test under a set of scenarios such as “Exploring objects behind the user”, “Avoiding the invasion of personal space” and “Walk and type with front-view.” Through this initial examination, we found that users can explore off-screen point of interests and grasp the spatial relations without the increase of mental effort. We believe that this preliminary study gives a meaningful indication that employing the interactive field of view can be a useful method to decrease the physical load without any additional mental efforts in a mixed and augmented reality environment.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643584","Augmented Reality;Mixed Reality;Distortion Correction;Expanded Field Of View (EFOV);Fish-eye lens;interaction","Visualization;Three dimensional displays;Indexes","augmented reality;mobile computing","mobile augmented reality system;EXMAR technique;interaction technique;dragging gestures;expanded field of view;off-screen point of interests;environmental contextual information;proof of concept usability test","","4","","5","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Towards a hybrid space combining Spatial Augmented Reality and virtual reality","J. S. Roo; M. Hachet","Lnria, France; Lnria, France","2017 IEEE Symposium on 3D User Interfaces (3DUI)","6 Apr 2017","2017","","","195","198","Spatial Augmented Reality (SAR) allows a user, or a group of users, to benefit from digital augmentations embedded directly into the physical world. This enables co-located information and unobstructed interaction. On the other hand, SAR suffers from limitations that are inherently linked to its physical dependency, which is not the case for see-through or immersive displays. In this work, we explore how to facilitate the transition from SAR to VR, and vice versa, integrating both into a unified experience. We developed a set of interaction techniques and obtained first feedback from informal interviews.","","978-1-5090-6716-9","10.1109/3DUI.2017.7893339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893339","Mixed Reality;Augmented Reality;HMD;3D Interaction","Navigation;Three-dimensional displays;Augmented reality;Tracking;Resists;Buildings","augmented reality","spatial augmented reality;virtual reality;SAR;hybrid space;see-through displays;immersive displays;interaction techniques","","12","","21","EU","6 Apr 2017","","","IEEE","IEEE Conferences"
"Aspects of User Profiles That Can Improve Mobile Augmented Reality Usage","S. R. R. Sanches; M. Oizumi; C. Oliveira; E. F. Damasceno; A. C. Sementille","Departamento Acadêmico de Computação, Universidade Tecnológica Federal do Paraná (UTFPR), Cornélio Procópio, Brasil; Departamento Acadêmico de Computação, Universidade Tecnológica Federal do Paraná (UTFPR), Cornélio Procópio, Brasil; Departamento Acadêmico de Computação, Universidade Tecnológica Federal do Paraná (UTFPR), Cornélio Procópio, Brasil; Departamento Acadêmico de Computação, Universidade Tecnológica Federal do Paraná (UTFPR), Cornélio Procópio, Brasil; Departamento de Computação, Universidade Estadual Paulista “Julio de Mesquita Filho” (UNESP), Bauru, Brasil","2017 19th Symposium on Virtual and Augmented Reality (SVR)","20 Nov 2017","2017","","","236","242","Augmented Reality (AR) applications running on mobile devices have become more popular in recent years. As with digital games, many developers have begun to direct their applications to mobile platforms, although the processing power of these devices is usually smaller when compared to the computing power of laptops and desktops. Applications developed for computing devices, including mobile devices, typically have a well-defined target audience, and some of them use AR technology. The use of AR can actually add value to the application, but despite the additional motivation, interaction in this type of environment may be more complex compared to traditional applications. Considering this context, the main objective of the present work is to identify which key aspects in the user profile impact the design of mobile AR applications.","","978-1-5386-3588-9","10.1109/SVR.2017.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114443","Augmented Reality;Mobile Device;User Profile","Games;Mobile handsets;Performance evaluation;Land mobile radio;Prototypes","augmented reality;computer games;mobile computing","mobile augmented reality usage;Augmented Reality applications;mobile devices;digital games;mobile platforms;processing power;computing power;laptops;desktops;computing devices;user profile impact;mobile AR applications","","1","","15","IEEE","20 Nov 2017","","","IEEE","IEEE Conferences"
"Augmented Reality Enhanced Analytics to Measure and Mitigate Disengagement in Teaching Young Children","M. Singh; S. Bangay; A. Sajjanhar","School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","782","785","The research identifies novel AR-based metrics to address disengagment in young children during learning in class-rooms and to provide better insights to teachers to make learning by AR more engaging, fun and stimulating. Util-ising AR applications and mobile devices to measure and mitigate students' disenagagement in their learning, studying how novel AR-based metrics can be analysed and contribute to better understand disengagement amongst young children during learning. Two research goals have been de-fined to guide this research to investigate the use of AR enhanced analytics to address disengagement in young chil-dren. Key contributions of this research include: 1) Capture of data from device sensors, user interactions and learning outcomes within the augmented reality experience., and 2) Deriving metrics from this sensory data to provide five cat-egories of AR Enhanced Analytics (AREA) measures rep-resenting the quality of the learning experience; namely (a) Learning Analytics, (b) Interaction Analytics, (c) Spatial Analytics, (d) Sensory Analytics and (d) Emotion Analyt-ics. The novel metrics will be validated for detailed and relevant sensing of the learning environmental and student behavioural stimuli including; a) position/location, b) time duration, c) interaction / engagement with virtual assets, d) experience recall, e) sentiments (audio and video), biometric (temperature, heart beat) and f) movements (using device sensors such as accelerometer, gyroscope and magnetome-ter, and through feature points tracked visually). AR-based metrics can be visualised and presented to support teachers in managing their classrooms and their teaching practice to address factors as associated with student disengagement.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974476","Augmented reality;analytics;education;young children","Temperature sensors;Temperature;Tracking;Heart beat;Magnetic sensors;Education;Magnetic devices","augmented reality;computer aided instruction;handicapped aids;teaching","AR Enhanced Analytics measures rep-resenting;AR-based metrics;augmented reality Enhanced Analytics;augmented reality experience;class-rooms;device sensors;disengagment;Emotion Analyt-ics;Interaction Analytics;key contributions;Learning Analytics;learning environmental student behavioural stimuli;learning experience;learning outcomes;mitigate disengagement;mobile devices;novel metrics;research goals;Sensory Analytics;sensory data;Spatial Analytics;stimulating;student disengagement;students;teaching young children;user interactions;util-ising AR applications;young chil-dren","","","","15","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Press the red button: A user study comparing notification placement with augmented and non-augmented tasks in AR","L. Plabst; S. Oberdörfe; F. Ortega; F. Niebling","HCI Group, University of Würzburg; Computer Science NUILAB, Colorado State University; Hochschule Fulda; Hochschule Fulda","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","483","484","Visual notifications are omnipresent in applications ranging from smart phones to Virtual Reality (VR) and Augmented Reality (AR) systems. However notifications can cause disruptive effects on task performance and different notification placements have been shown to have an influence on response times, as well as e.g. on user per-ceived intrusiveness and disruptiveness. We investigated the effects and impacts of four visual notification types in AR environments where a card game task was performed in AR or the real world. In a user study, we interrupted the execution of the main task with one of the AR notification types.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00101","DFG(grant numbers:425868361); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974166","Human-centered computing-User studies Human-centered computing-Mixed / augmented reality","Visualization;Presses;Games;Distance measurement;Time factors;Task analysis;Augmented reality","augmented reality;computer games;human computer interaction;interactive systems;smart phones;virtual reality","AR notification types;card game task;different notification placements;disruptive effects;disruptiveness;intrusiveness;nonaugmented tasks;red button;response times;smart phones;task performance;user study comparing notification placement;visual notification types;visual notifications","","","","4","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"From Augmented Reality to Augmented Computing: A Look at Cloud-Mobile Convergence","X. Luo","Qualcomm, Inc., San Diego, CA, USA","2009 International Symposium on Ubiquitous Virtual Reality","4 Sep 2009","2009","","","29","32","There has been considerable number of virtual and augmented reality applications designed and developed for mobile devices. However the state-of-the-art systems are commonly confined by several limitations. In this position paper the concept rdquocloud-mobile convergence for virtual reality (CMCVR)rdquo is presented. CMCVR envisions effective and user-friendly integration of the mobile device and cloud-based resources. Through the proposed framework, mobile devices could be augmented to deliver some user experiences comparable to those offered by fixed systems. A preliminary research that follows the CMCVR paradigm is also described.","","978-1-4244-4437-3","10.1109/ISUVR.2009.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232249","","Augmented reality;Cloud computing;Convergence;Virtual reality;Mobile computing;Smart phones;Portable computers;Cellular phones;Energy consumption;Internet","augmented reality;mobile computing;mobile handsets","augmented reality;augmented computing;cloud-mobile convergence;mobile device;virtual reality;cloud-based resources","","39","1","8","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"Perceiving Affordances for Passing Through Apertures: A Discussion of Factors Influencing Replication Across Extended Reality","S. H. Creem-Regehr; J. K. Stefanucci; B. Bodenheimer","Department of Psychology, University of Utah; Department of Psychology, University of Utah; Department of Computer Science, Vanderbilt University","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","274","275","A growing body of work suggests that affordances- perceived capabilities for action- are a useful measure for testing theoretical and applied questions in both the real world and extended realities (XR). In this review, we discuss replications across studies suggesting that affordances for passability are perceived similarly in XR environments when compared to real world judgments. Further, representations of the body in these environments can recalibrate passability affordance judgments as well.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00061","National Science Foundation(grant numbers:1763254,1763966); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974384","Affordances;Perception;Extended Reality;Virtual Reality;Augmented Reality;Replication;Computing methodologies;Computer graphics;Graphics systems and interfaces;Mixed/augmented reality","Extended reality;Affordances;Apertures;X reality;Testing","augmented reality","extended reality;factors influencing replication;growing body;passability affordance judgments;perceived capabilities;perceiving affordances;replications;useful measure;world judgments;XR environments","","","","9","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Learning and Teaching Fluid Dynamics using Augmented and Mixed Reality","N. Bhatia; O. K. Matar","Department of Chemical Engineering, Imperial College London, South Kensington, London, UK; Department of Chemical Engineering, Imperial College London, South Kensington, London, UK","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","865","869","We have been developing an interactive and multimodal platform to facilitate learning fluid dynamics with the rationale of using an immersive environment as a visualisation medium. Before the pan-demic, we used our in-house virtual reality app to teach fluid dynamics (FD), significantly enhancing student engagement. Since the COVID-19 pandemic struck, we have explored AR and MR applications for scaling our remote online and hybrid teaching efforts. The work presented in this paper has two objectives. (i) Provide an AR learning medium for remotely located students. (ii) Provide a student-paced instructional learning medium using MR for the hy-brid or onsite students. To achieve this, we describe a methodology in four parts. (i) A computational fluid dynamics data processing and distribution pipeline for generating 3D models for AR and MR. (ii) A platform-independent FD learning platform that uses WebXR for rendering models in AR. (iii) Hololens-based instructional medium in MR for learning FD.(iv) A pedagogy design. We discuss the results of a feasibility study on 18 hybrid learning students to assess the effectiveness of the pedagogy design using MR. We conclude that by using our platform, students can interactively visualise our in-house fluid dynamics models aligned with the course work and acquire knowledge naturally and intuitively.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974540","Learning and Teaching;Fluid Dynamics;Augmented Reality;Mixed Reality;Remote Learning;Hybrid Teaching","Solid modeling;Three-dimensional displays;Pandemics;Computational modeling;Education;Pipelines;Mixed reality","computational fluid dynamics;computer aided instruction;data visualisation;distance learning;educational courses;medical computing;teaching;virtual reality","AR learning medium;augmented reality;computational fluid dynamics data processing;COVID-19 pandemic;distribution pipeline;hy-brid students;hybrid teaching efforts;immersive environment;in-house fluid dynamics models;in-house virtual reality app;instructional medium;interactive platform;learning fluid dynamics;mixed reality;multimodal platform;onsite students;pan-demic;pedagogy design;platform-independent FD learning platform;remote online;remotely located students;student engagement;student-paced instructional learning medium;visualisation medium","","","","33","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Virtual, Augmented, and Mixed Reality for HRI (VAM-HRI)","C. T. Chang; E. Rosen; T. R. Groechel; M. Walker; J. Z. Forde","Department of Computer Science, University of Colorado Boulder, Boulder, Colorado, USA; Department of Computer Science, Brown University, Providence, RI; Viterbi School of Engineering, University of Southern California, Los Angeles, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, USA; Department of Computer Science, Brown University, Providence, RI","2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","29 Sep 2022","2022","","","1237","1240","The 5th International Workshop on Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI) will bring together HRI, robotics, and mixed reality researchers to address challenges in mixed reality interactions between humans and robots. Topics relevant to the workshop include development of robots that can interact with humans in mixed reality, use of virtual reality for developing interactive robots, the design of augmented reality interfaces that mediate communication between humans and robots, social applications for virtual and mixed reality in HRI, the investigations of mixed reality interfaces for robot learning, comparisons of the capabilities and perceptions of robots and virtual agents, and best design practices. Special topics of interest this year include VAM-HRI research during the ongoing COVID-19 pandemic as well as the ethical implications of VAM-HRI research. VAM-HRI 2022 will follow on the success of VAM-HRI 2018–21 and advance the cause of this nascent research community. Website: https://vam-hri.github.io","","978-1-6654-0731-1","10.1109/HRI53351.2022.9889655","NSF(grant numbers:1764092,1925083); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889655","Virtual Reality;Augmented Reality;Mixed Reality;Human-Robot Interaction","COVID-19;Ethics;Pandemics;Conferences;Mixed reality;Robot learning;Robots","augmented reality;human-robot interaction;interactive systems;robots;user interfaces;virtual reality","robotics;mixed reality researchers;mixed reality interactions;virtual reality;interactive robots;augmented reality;mixed reality interfaces;robot learning;VAM-HRI research;Human-Robot Interaction","","1","","30","IEEE","29 Sep 2022","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality with Head-Tracking for Efficient Teleoperation of Groups of Robots","N. Mollet; R. Chellali","Robotics, Brain and Cognitive sciences Dpt. Intaro Team, IIT-Italian Institute of Technology, Genoa, Italy; Robotics, Brain and Cognitive sciences Dpt. Intaro Team, IIT-Italian Institute of Technology, Genoa, Italy","2008 International Conference on Cyberworlds","9 Jan 2009","2008","","","102","108","This paper deals with the usage of Virtual and Augmented Reality techniques in the field of teleoperation. The global context is a project for collaborative teleoperation of real robots groups. The aim is to enable to a group of teleoprators to control in a collaborative way groups of robots to achieve complex tasks like inspecting an area or to explore unknown parts of an unknown environment. More precisely, we first present the usage of Collaborative Virtual Environments (CVE) system for the representation of the robot's world. This CVE and its interactions capabilities offer an abstraction of the environment and robots for teleoperators. We also present an application of this system throughout the original usage of a head-tracking system combined with a VR helmet. This application enables to control an active vision system on a remote mobile robot. Augmented Reality add-ons are included to ease the control process.","","978-0-7695-3381-0","10.1109/CW.2008.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4741286","Virtual Reality;Teleoperation;Robotics;Augmented Reality;Telepresence","Augmented reality;Virtual reality;Teleoperators;Online Communities/Technical Collaboration;Cognitive robotics;Industrial training;Virtual environment;Defense industry;Robot control;International collaboration","augmented reality;mobile robots;telerobotics","virtual reality;augmented reality;head tracking;teleoperation;robots;collaborative virtual environments;active vision system;remote mobile robot","","9","","9","IEEE","9 Jan 2009","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality based assembly design system for personalized learning","H. A. Adas; S. Shetty; S. K. Hargrove","Tennessee State University, Nashville, TN, US; Tennessee State University, Nashville, TN, US; Tennessee State University, Nashville, TN, US","2013 Science and Information Conference","14 Nov 2013","2013","","","696","702","Recent technological advances have revolutionized the way humans interact with computers and the world around them. These technological advances have significantly changed science and engineering practices and it has become imperative to bring these changes into engineering classrooms. This paper presents the development of a Virtual and Augmented Reality (VAR) based personalized learning environment. The VAR environment provides a virtual instruction based pedagogical tool which integrates virtual models and visual cues to teach engineering design. With machine design as the theme, the learning environment immerses students in practical assembly design challenges, where student can interact with real and virtual machine part objects in presence of interactive and guided support.","","978-0-9893193-0-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6661817","Virtual Reality;Augmented Reality;Machine Assembly;Six-bar Quick Return;Personalized Learning","Reactive power;Augmented reality;Three-dimensional displays;Solid modeling;Assembly;Prototypes;Cameras","augmented reality;computer aided instruction;engineering education;interactive programming;program assemblers;student experiments;virtual machines","guided support;interactive support;virtual machine;students;engineering classrooms;personalized learning;assembly design system;augmented reality;virtual reality","","1","","25","","14 Nov 2013","","","IEEE","IEEE Conferences"
"Research on Augmented Reality Extended Tracking Technology for Mobile Terminal","X. Li; X. Wang","Institute of Smart City, Shanghai University, Shanghai, China; Institute of Smart City, Shanghai University, Shanghai, China","2018 International Conference on Audio, Language and Image Processing (ICALIP)","6 Sep 2018","2018","","","184","188","In consideration of problems with mobile terminal augmented reality, including instability and robustness of the spatial registration results, in this paper, we proposed an improved extended tracking algorithm based on mobile terminal. The algorithm adjusts the recursion of the decision trees based on the feature points, which overcomes the problems of inadequate feature tracking and weak stability of the traditional tracking algorithms. After matching and tracking the feature points of the image, the algorithm of this paper combines the assistant tracking technology of mobile multi-sensor fusion, and realizes the augmented reality system. The experimental results show that the system improves the display effect of the virtual objects in the real scene when there are light, scale and noise in the scene for the complicated outdoor environment, and has strong robustness and stability.","","978-1-5386-5195-7","10.1109/ICALIP.2018.8455747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8455747","Augmented Reality;Extended Target Tracking;Sensor;Mobile Terminal","Target tracking;Decision trees;Augmented reality;Feature extraction;Cameras;Robustness;Interference","augmented reality;decision trees;image registration;mobile computing;robot vision;sensor fusion;target tracking","experimental results;augmented reality system;mobile multisensor fusion;assistant tracking technology;traditional tracking algorithms;inadequate feature tracking;feature points;decision trees;improved extended tracking algorithm;spatial registration results;instability;mobile terminal augmented reality;augmented reality extended tracking technology","","","","13","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"The Pervasive Rapid E-Preparedness Augmented Reality Environment (PREPARE) E-Learning Intervention for HAZWOPER Training of Fire Fighter/EMTs","D. Collington; J. Doswell; J. Johnson; M. Messam; S. Salaam; A. Boykin","National Institutes of Health ASCEND-BUILD, Morgan State University, Baltimore, MD, USA; Juxtopia, LLC, Baltimore, MD, USA; Juxtopia, LLC, Baltimore, MD, USA; Juxtopia, LLC, Baltimore, MD, USA; Juxtopia, LLC, Baltimore, MD, USA; Juxtopia, LLC, Baltimore, MD, USA","2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT)","13 Aug 2018","2018","","","377","379","A Juxtopia research team collaborated with the Maryland Fire & Rescue Institute (MFRI) to test how the Juxtopia® wearable augmented reality (AR) intervention may better deliver a hands-on clinical training intervention to firefighter Emergency Medical Technicians (EMT) and prepare them for effective response to HAZMAT (hazardous materials) incidences. During a controlled study, human subjects participated in a minimal risk research study (i.e., both as victims or caregivers) in which firefighter EMTs participated in a simulated training exercise that mimicked their real-world operations. This study consisted of two testing days. Day one included 10 participants that completed a full day of training and familiarity with wearable augmented reality (AR) goggles and a Juxtopia® Virtual Tutor (JVT) software application, which is derived from the Juxtopia® Intelligent Virtual Instructor (JiVi) platform. Day two included the completion of four psychomotor clinical skills performed by EMTs. It also included the application of moulage injuries for victims, using the Juxtopia® CAMMRAD PREPARE system to administer clinical skills on patient actors. This paper discusses the research methods and results.","2161-377X","978-1-5386-6049-2","10.1109/ICALT.2018.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8433542","augmented reality;HAZWOPER;EMT;clinical skills","Training;Eye protection;Injuries;Augmented reality;Task analysis;Hazardous materials;Fires","augmented reality;computer based training;educational institutions;emergency management;fires;hazardous materials;human computer interaction","E-Learning Intervention;Juxtopia wearable augmented reality intervention;Juxtopia Virtual Tutor software application;Juxtopia Intelligent Virtual Instructor platform;Juxtopia CAMMRAD PREPARE system;psychomotor clinical skills;wearable augmented reality goggles;simulated training exercise;firefighter EMTs;minimal risk research study;hazardous materials;HAZMAT incidences;EMT;Emergency Medical Technicians;hands-on clinical training intervention;Maryland Fire & Rescue Institute;Juxtopia research team;HAZWOPER training;pervasive rapid e-preparedness augmented reality environment","","","","7","IEEE","13 Aug 2018","","","IEEE","IEEE Conferences"
"The Exploration of Augmented Reality Technology Applied in Colleges' Experimental Teaching","C. Chen; T. Yu; J. Wang","Educational Technology Center, Naval Medical University of Chinese PLA, Shanghai, China; Educ. Facilities Support Dept., Naval Med. Univ. of Chinese PLA, Shanghai, China; Educ. Technol. Center, Naval Med. Univ. of Chinese PLA, Shanghai, China","2018 9th International Conference on Information Technology in Medicine and Education (ITME)","27 Dec 2018","2018","","","652","655","The Augmented reality technology is a new informational teaching method. Virtual information can be superimposed on the real environment to form an interactive three-dimensional image by computing, which realized the combination of virtual situations and real environments. This paper described the concept and characteristics of augmented reality technology, analyzed the feasibility of using this technology on experimental teaching in colleges, proposed the way to achieve augmented reality teaching, and investigated on how to improve the teaching effect by using augmented reality.","2474-3828","978-1-5386-7744-5","10.1109/ITME.2018.00150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8589382","colleges, augmented reality, AR, experimental teaching, teaching effect","Augmented reality;Educational technology;Instruments;Real-time systems;Solid modeling","augmented reality;computer aided instruction;educational courses;teaching","augmented reality technology;teaching effect;augmented reality teaching;experimental teaching;virtual situations;virtual information;informational teaching method;colleges","","","","12","IEEE","27 Dec 2018","","","IEEE","IEEE Conferences"
"Applying Relief Mapping on Augmented Reality","K. Kalarat","Multimedia Technology and Animation, Walailak University, Nakhonsithammarat, Thailand","2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)","27 Aug 2015","2015","","","315","318","Augmented Reality is a variation of Virtual Environment (VE) in Virtual Reality (VR). Virtual Reality technologies Virtual Environment makes user experiences immersion inside a synthetic environment and user cannot see the real world. In contrast, Augmented Reality (AR) medium of information added to the real world in registration with the world to combine virtual objects and real world. Technically, Augmented Reality is able to enhance all five senses by adding digital or computer generated information such as images, audio, video, interaction and overlaying them over in physical world. Its most commonly use is visual. Augmented Reality allows the user to see the virtual object blended in real world environment. To apply Augmented Reality to applications used for illustration the architecture or infrastructure of building, 3D visual model is a content which is good way to show obviously architecture's element because it is able to display the appearance of each building part separately responding to camera perspective in real-time. That means AR system have to re-render the digital object every time the viewer changes position even a tiny bit as temporal registration. Therefore, the computations for three-dimensional computer graphics must be considered about rendering system on the observed devices because time lags could be occurred when lacking computational speed while it is operating the imagery overlay on the top of the physical world for each frame. There are mainly constraints that are limited the AR system performance such as limited memory and limited computational capability. To enhance the limitations of handheld devices, this research applies Relief Mapping algorithm to 3D model in Augmented Reality technology to reduce the number of polygons on the facade of Sino Portuguese Architecture which consist of many bas-relief patterns on their facades. Our system uses game engine, Unity3D, for real-time rendering and Vuforia SDK implemented augmented reality application on handheld device. The result of the research after applying Relief Mapping technique instead of using the conventional modeling creation, more than 80,000 polygons/ 1 bas-relief, is to create by having a single polygon per a bas-relief and the quality of visualization is compatible to each other on AR application.","","978-1-4799-1966-6","10.1109/JCSSE.2015.7219816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219816","Augmented Reality;AR Interaction;Sino Portuguese Architecture;Bas-relief;Mapping algorithm;Game Engine","Augmented reality;Three-dimensional displays;Solid modeling;Computer architecture;Rendering (computer graphics);Buildings;Architecture","augmented reality;civil engineering computing;data visualisation;rendering (computer graphics);solid modelling","relief mapping;augmented reality;Sino Portuguese architecture;Phuket;Thailand;virtual environment;virtual reality;virtual objects;digital generated information;computer generated information;3D visual model;digital object rerendering;3D computer graphics;Unity3D game engine;Vuforia SDK;bas-relief;data visualization","","1","5","17","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Multi-scale Mixed Reality Collaboration for Digital Twin","H. -I. Kim; T. Kim; E. Song; S. Y. Oh; D. Kim; W. Woo","KAIST UVR Lab; Motion Computing Lab, KAIST; KAIST UVR Lab; KAIST UVR Lab; KAIST UVR Lab; KAIST UVR Lab","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","435","436","In this poster, we present a digital twin-based mixed reality system for remote collaboration with the size-scaling of the user and the space. The proposed system supports collaboration between an AR host user and a VR remote user by sharing a 3D digital twin of the AR host user. To enhance the coarse authoring of a shared digital twin environment, we provide a size scaling of the digital twin environment with the world-in-miniature view. Also, we enable scaling the size of the VR user’s avatar to enhance both coarse (size-up) and fine-grained (size-down) authoring of the digital twin environment. We describe the system setup, input methods, and interaction methods for scaling space and user.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585826","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Collaborative interaction","Three-dimensional displays;Digital twin;Avatars;Collaboration;Mixed reality;Systems support;Augmented reality","augmented reality;avatars;user interfaces","multiscale mixed reality collaboration;digital twin-based mixed reality system;remote collaboration;AR host user;VR remote user;shared digital twin environment;VR user;fine-grained authoring;avatar","","5","","5","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"3D discrepancy check via Augmented Reality","S. Kahn; H. Wuest; D. Stricker; D. W. Fellner","Fraunhofer Institute of Computer Graphics Research (IGD), Germany; Fraunhofer Institute of Computer Graphics Research (IGD), Germany; German Research Center of Artificial Intelligence, University of Kaiserslautern, Germany; Fraunhofer Institute of Computer Graphics Research, Technical University of Darmstadt, Germany","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","241","242","For many tasks like markerless model-based camera tracking it is essential that the 3D model of a scene accurately represents the real geometry of the scene. It is therefore very important to detect deviations between a 3D model and a scene. We present an innovative approach which is based on the insight that camera tracking can not only be used for Augmented Reality visualization but also to solve the correspondence problem between 3D measurements of a real scene and their corresponding positions in the 3D model. We combine a time-of-flight camera (which acquires depth images in real time) with a custom 2D camera (used for the camera tracking) and developed an analysis-by-synthesis approach to detect deviations between a scene and a 3D model of the scene.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643587","","Three dimensional displays;Cameras;Solid modeling;Pixel;Mathematical model;Data models;Computational modeling","augmented reality;computational geometry;data visualisation;image sensors;object detection","3D discrepancy check;markerless model based camera tracking;scene geometry;augmented reality visualization;time-of-flight camera;custom 2D camera","","8","1","6","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Large area indoor tracking for industrial augmented reality","F. Scheer; S. Müller","Daimler Benz Aerospace, Germany; University of Koblenz, Germany","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","269","270","A precise tracking with minimal setup times, minimal changes to the environment and acceptable costs, satisfying industrial demands in large factory buildings is still a challenging task for augmented reality (AR) applications. We present a system to determine the pose for monitor based AR systems in large indoor environments, e.g. 200 × 200 meters and more. An infrared laser detects retroreflective targets and computes a 2D position and orientation based on the information of a preprocessed map of the targets. Based on this information the 6D pose of a video camera attached to a servo motor, that is further mounted on a mobile cart is obtained by identifying the transformation between the laser scanner and the several adjustable views of the camera through a calibration method. The adjustable steps of the servo motor are limited to a discrete number of steps to limit the calibration effort. The positional accuracy of the system is estimated by error propagation and presented.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643601","","Cameras;Three dimensional displays;Target tracking;Servomotors;Production facilities;Laser modes","augmented reality;calibration;infrared detectors;video cameras","industrial augmented reality;indoor tracking;2D position;video camera;laser scanner;infrared laser;retroreflective target;calibration method;error propagation","","1","1","10","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"SolarSystemGO — An augmented reality based game with astronomical concepts","J. M. Patricio; M. C. Costa; J. A. Carranca; B. Farropo","C212 - Centro de Investigação em Cidades Inteligentes, Instituto Politécnico de Tomar, Tomar, Portugal; Escola Superior de Tecnologia de Tomar, Instituto Politécnico de Tomar, Tomar, Portugal; Escola Superior de Tecnologia de Tomar, Instituto Politécnico de Tomar, Tomar, Portugal; Escola Superior de Tecnologia de Tomar, Instituto Politécnico de Tomar, Tomar, Portugal","2018 13th Iberian Conference on Information Systems and Technologies (CISTI)","28 Jun 2018","2018","","","1","3","Mobile devices, such as smartphones or tablets, have becoming increasingly performant and affordable, and presently are available to most children and teenagers, leading to the development of a multitude of apps for these devices. In this paper we present the preliminary implementation of project SolarSystemGO, a Mobile Augmented Reality game created with the Unity3D game engine, coupled with Vuforia for the Augmented component, that runs on Android, with Astronomy (and the Solar System in particular) in mind, aimed at providing awareness of the vastness and proportionality of the Solar System objects, such as the Sun and the planets. The hardware requirements of SolarSystemGO, namely the existence of gyroscope in the mobile device, required the modification of the interaction with the Vuforia layer, in order to provide a more realistic and performant gaming experience.","","978-989-98434-8-6","10.23919/CISTI.2018.8399284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8399284","Augmented Reality;Gamification;Astronomy;GPS;Mobile apps;Android","Games;Planets;Augmented reality;Sun;Mobile handsets;Hardware","astronomy computing;augmented reality;mobile computing;serious games (computing);solid modelling","astronomical concepts;Mobile devices;smartphones;tablets;children;teenagers;preliminary implementation;project SolarSystemGO;Mobile Augmented Reality game;Unity3D game engine;Augmented component;Solar System objects;mobile device;realistic gaming experience;performant gaming experience;SolarSystemGO;augmented reality based game","","3","","8","","28 Jun 2018","","","IEEE","IEEE Conferences"
"A Testbed for Exploring Multi-Level Precueing in Augmented Reality","J. -S. Liu; B. Tversky; S. Feiner","Department of Computer Science, Columbia University; Department of Human Development, Teachers College, Columbia University; Department of Computer Science, Columbia University","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","540","541","Precueing information about upcoming subtasks prior to performing them has the potential to make an entire task faster and easier to accomplish than cueing only the current subtask. Most AR and VR research on precueing has addressed path-following tasks requiring simple actions at a series of locations, such as pushing a button or just visiting that location. We present a testbed for exploring multi-level precueing in a richer task that requires the user to move their hand between specified locations, transporting an object between some of them, and rotating it to a designated orientation.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00121","National Science Foundation(grant numbers:CMMI-2037101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757378","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality;Computing methodologies—Computer graphics—Graphics systems and interfaces—Perception","Three-dimensional displays;Conferences;User interfaces;Task analysis;Augmented reality","augmented reality","multilevel precueing;augmented reality;VR research;path-following tasks","","3","","9","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Touch experience in augmented reality","D. Li; J. Xie; D. Weng; Y. Li","Beijing Institute of Technology, China; Beijing Institute of Technology, China; Beijing Institute of Technology, China; Beijing Institute of Technology, China","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","87","88","In this paper, we presented two prototype systems to analyze the role of touch in AR system. One was an AR evaluation prototype system used to design the aircraft cockpit. In this system, the pilots can touch the virtual buttons and meters to test the ergonomics performance of design results. The other was a touchable AR girl prototype system used to treat heterosexual-social anxiety. In this system, patients can touch and feel a virtual girl. We designed a series of subjective and objective experiments to prove the importance of “touchable” to enhancing the user experience in AR system.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549376","Touch;augmented reality","Augmented reality;Prototypes;Aircraft;Solid modeling;Haptic interfaces;Head;Three-dimensional displays","augmented reality;user interfaces","augmented reality;AR system;AR evaluation prototype;aircraft cockpit;touchable AR girl prototype system;heterosexual-social anxiety treatment;virtual girl;touchable importance;user experience","","1","","4","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"Research and Application of Indoor Guide Based on Mobile Augmented Reality System","X. Yan; W. Liu; X. Cui","Xi'an University of Post & Telecommunications, Xi'an, China; Xi'an University of Post & Telecommunications, Xi'an, China; Xi'an University of Post & Telecommunications, Xi'an, China","2015 International Conference on Virtual Reality and Visualization (ICVRV)","12 May 2016","2015","","","308","311","In view of the low precision and poor interaction in current traditional indoor navigation system of digital map, this paper puts forward an indoor guide strategy, which combines WiFi positioning technology with mobile AR technology. At the same time, the traditional natural feature extraction algorithm is improved by combining FASE with SURF. FAST-SURF can meet the requirement of robustness and real-time performance. A new mobile AR indoor guide system is designed and implemented in the digital museum based on the Android platform. Experiments show that the system has better practicability and broad application prospects with high precision of positioning and matching, good real-time performance and high precision of positioning navigation.","","978-1-4673-7673-0","10.1109/ICVRV.2015.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7467255","mobile augmented reality;WiFi positioning;FAST-SURF;indoor guide;Android platform Introduction","Feature extraction;Mobile communication;Navigation;Fingerprint recognition;Augmented reality;Real-time systems;IEEE 802.11 Standard","augmented reality;indoor navigation;mobile computing;museums;smart phones","Android platform;digital museum;FAST-SURF;mobile AR indoor guide system;natural feature extraction algorithm;mobile AR technology;WiFi positioning technology;digital map;indoor navigation system;indoor guide;mobile augmented reality system","","1","","11","IEEE","12 May 2016","","","IEEE","IEEE Conferences"
"Effectiveness of occluded object representations at displaying ordinal depth information in augmented reality","M. A. Livingston; K. R. Moser","Naval Research Laboratory, USA; Mississippi State University, USA","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","107","108","An experiment was conducted to investigate the utility of a number of iconographic styles in relaying ordinal depth information at vista space distances of more than 1900m. The experiment consisted of two tasks: distance judgments with respect to discrete zones, and ordinal depth determination in the presence of icon overlap. The virtual object representations were chosen based on their effectiveness, as demonstrated in previous studies. The first task is an adaptation of a previous study investigating distance judgments of occluded objects at medium field distances. We found that only one of the icon styles fared better than guessing. The second is a novel task important to situation awareness and tested two specific cases: ordinal depth of icons with 50% and 100% overlap. We found that the case of full overlap made the task effectively impossible with all icon styles, whereas in the case of partial overlap, the Ground Plane had a clear advantage.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549385","Augmented reality;human factors evaluation;situation awareness;ordinal depth;X-ray vision","Augmented reality;Airports;Buildings;Brightness;Standards;Abstracts","augmented reality;computer graphics","occluded object representation effectiveness;ordinal depth information display;augmented reality;iconographic styles;vista space distance;distance judgments;discrete zones;ordinal depth determination;icon overlap;virtual object representations;medium field distance;situation awareness;partial overlap;ground plane","","1","","6","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"Enhanced Geometric Techniques for Point Marking in Model-Free Augmented Reality","W. S. Lages; Y. Li; L. Lisle; F. Lu; T. Höllerer; D. A. Bowman","Virginia Polytechnic Institute and State University, Blacksburg, VA, US; Virginia Polytechnic Institute and State University, Blacksburg, VA, US; Virginia Polytechnic Institute and State University, Blacksburg, VA, US; Virginia Polytechnic Institute and State University, Blacksburg, VA, US; Virginia Polytechnic Institute and State University, Blacksburg, VA, US; Computer Science University of California, Santa Barbara","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1036","1037","Specifying points in three-dimensional space is essential in AR applications. Geometric triangulation is a straightforward way to specify points, but its naïve implementation has low precision. We designed two enhanced geometric techniques for 3D point marking: VectorCloud, which uses multiple rays to reduce jittering, and ImageRefinement, which allows 3D ray refinement to improve precision. Our experiments, conducted in both simulated and real AR, demonstrate that both techniques improve the precision of 3D point marking, and that ImageRefinement is superior to VectorCloud overall. These results are particularly relevant in the design of mobile AR systems for large outdoor areas.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798087","Human-centered computing;Mixed / augmented reality;Pointing;User interface design","Three-dimensional displays;Head;Task analysis;Solid modeling;Augmented reality;Human computer interaction","augmented reality;computational geometry;image motion analysis;jitter;ray tracing;solid modelling","model-free augmented reality;three-dimensional space;geometric triangulation;naïve implementation;3D ray refinement;geometric techniques;AR applications;3D point marking;vectorcloud;jittering;image refinement","","","","4","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Real-time augmented face","V. Lepetit; L. Vacchetti; D. Thalmann; P. Fua","CVLaboratory, Swiss Federal Institute of Technology, Switzerland; CVLaboratory, Swiss Federal Institute of Technology, Switzerland; VRLaboratory, Swiss Federal Institute of Technology, Switzerland; CVLaboratory, Swiss Federal Institute of Technology, Switzerland","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","346","347","This real-time augmented reality demonstration relies on our tracking algorithm described in V. Lepetit et al (2003). This algorithm considers natural feature points, and then does not require engineering of the environment. It merges the information from preceding frames in traditional recursive tracking fashion with that provided by a very limited number of reference frames. This combination results in a system that does not suffer from jitter and drift, and can deal with drastic changes. The tracker recovers the full 3D pose of the tracked object, allowing insertion of 3D virtual objects for augmented reality applications.","","0-7695-2006-5","10.1109/ISMAR.2003.1240753","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240753","","Augmented reality;Firewire;Cameras;Robust stability;Jitter;Hardware;Portable computers;Humans;Face;Glass","augmented reality;face recognition;real-time systems;tracking;solid modelling","real-time augmented face;real-time systems;augmented reality demonstration;tracking algorithm;natural feature points;information merging;recursive tracking;reference frames;3D pose;3D virtual objects","","1","5","1","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Approach to the Interior Design Using Augmented Reality Technology","J. Hui","NANJING FORESTRY UNIVERSITY, Nanjing, Jiangsu, China","2015 Sixth International Conference on Intelligent Systems Design and Engineering Applications (ISDEA)","2 May 2016","2015","","","163","166","This paper analyzes the use of Augmented Reality technology and Augmented Reality 3D interior model for interior design. According to the feature of interior design, the best way to share the concept of an interior design project to customer in the conceptual design stage is to perform it in a vivid 3D prototype. The traditional 3D interior space prototypes are created by designers and evaluated by customers, but we want to expand the affection of customers' requirements in the conceptual design. The designer and customer establish a 3D interior space model together in conceptual design stage by first creating 3D interior structure model, followed by choosing hard-soft decoration method and customized decoration requirements in an Augmented Reality Interior Design System. A hard decoration modeling framework is built for design project improvement and evaluation to guarantee that user can coordinate every aspect of the design project to achieve a balance between structure and function. The augmented content and sensory information of decorative material-furniture-appliance for soft decoration can be simulated with special stereoscopic equipments as an AR3D interior prototype in ARID system to enhance the understanding and participation of customers in the customized interior design project.","","978-1-4673-9393-5","10.1109/ISDEA.2015.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7462587","Interior Design;Augmented Reality;3D interior models","Solid modeling;Augmented reality;Three-dimensional displays;Prototypes;Rendering (computer graphics);Hydroelectric power generation;Lighting","architectural CAD;augmented reality;domestic appliances;furniture","augmented reality technology;3D interior space model;conceptual design stage;3D interior space prototypes;customers requirements;3D interior structure model;hard-soft decoration method;customized decoration requirements;augmented reality interior design system;hard decoration modeling;design project improvement;design project evaluation;decorative material-furniture-appliance;stereoscopic equipments;AR3D interior prototype;ARID system;customized interior design project","","11","","6","IEEE","2 May 2016","","","IEEE","IEEE Conferences"
"A Kinect-Based Augmented Reality Game for Lower Limb Exercise","Y. Tokuyama; R. P. C. J. Rajapakse; S. Yamabe; K. Konno; Y. -P. Hung","Department of Media Engineering, Tokyo Polytechnic University, Iiyama, Atsugi, Kanagawa, Japan; Graduate Institute of Animation and Film Art, Tainan National university of the Arts, Tainan, Taiwan; Hitachi Industry & Control Solutions, Ltd., Tokyo, Japan; Department of Computer and Information Sciences, Iwate University, 4-3-5 Ueda, Morioka, Iwate, Japan; Graduate Institute of Animation and Film Art, Tainan National university of the Arts, No. 66, Daci, Guantian, Tainan, Taiwan","2019 International Conference on Cyberworlds (CW)","5 Dec 2019","2019","","","399","402","Augmented reality (AR) is where 3D virtual objects are integrated into a 3D real environment in real time. The augmented reality applications such as medical visualization, maintenance and repair, robot path planning, entertainment, military aircraft navigation, and targeting applications have been proposed. This paper introduces the development of an augmented reality game which allows the user to carry out lower limb exercise using a natural user interface based on Microsoft Kinect. The system has been designed as an augmented game where users can see themselves in a world augmented with virtual objects generated by computer graphics. The player sitting in a chair just has to step on a mole that appears and disappears by moving upward and downward randomly. It encourages the activities of a large number of lower limb muscles which will help prevent falls. It is also suitable for rehabilitation.","2642-3596","978-1-7281-2297-7","10.1109/CW.2019.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918980","augmented reality;lower limb exercise;rehabilitation;healthcare","Games;Augmented reality;Art;Maintenance engineering;Mirrors;Visualization;Coordinate measuring machines","augmented reality;computer games;computer graphics;muscle;patient rehabilitation;user interfaces","kinect-based augmented reality game;lower limb exercise;3D virtual objects;augmented reality applications;medical visualization;robot path planning;military aircraft navigation;natural user interface;Microsoft Kinect;lower limb muscles","","3","","10","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"A Summary of Virtual Reality, Augmented Reality and Mixed Reality Technologies in Film and Television Creative Industries","R. Ge; T. -C. Hsiao","College of Computer Science and Technology, Huaqiao University, Fujian, China; College of Computer Science and Technology, Huaqiao University, Fujian, China","2020 IEEE 2nd Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS)","22 Sep 2020","2020","","","108","111","Virtual reality and augmented reality technologies have been applied to scientific research for many years and the achievements are remarkable. Although the application area of mixed reality is relatively narrow comparing to the first two applications, we have initially seen results. However, in fact, these technologies can be applied in film and television creation far more than that. I then illustrate some other aspects which these realistic contents can also be applied to in film and television creation in the future and the influence on the industry.","","978-1-7281-8712-9","10.1109/ECBIOS50299.2020.9203607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9203607","Virtual reality;Augmented reality;Mixed reality;film and television creation","Motion pictures;TV;Industries;Virtual reality;Glass;Lenses;Production","augmented reality","mixed reality technologies;television creative industries;virtual reality;scientific research;television creation;augmented reality","","1","","10","IEEE","22 Sep 2020","","","IEEE","IEEE Conferences"
"Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI)","T. Williams; D. Szafir; T. Chakraborti; E. Phillips","Colorado School of Mines, Golden, CO; University of Colorado Boulder, Boulder, CO; IBM Research AI, Cambridge, MA; U. S. Air Force Academy, Air Force Academy, CO","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","25 Mar 2019","2019","","","671","672","The 2 nd International Workshop on Virtual, Augmented, and Mixed Reality for Human-Robot Interactions (VAM-HRI) will bring together HRI, Robotics, and Mixed Reality researchers to identify challenges in mixed reality interactions between humans and robots. Topics relevant to the workshop include development of robots that can interact with humans in mixed reality, use of virtual reality for developing interactive robots, the design of new augmented reality interfaces that mediate communication between humans and robots, comparisons of the capabilities and perceptions of robots and virtual agents, and best design practices. VAM-HRI was held for the first time at HRI 2018, where it served as the first workshop of its kind at an academic AI or Robotics conference, and served as a timely call to arms to the academic community in response to the growing promise of this emerging field. VAM-HRI 2019 will follow on the success of VAM-HRI 2018, and present new opportunities for expanding this nascent research community.","2167-2148","978-1-5386-8555-6","10.1109/HRI.2019.8673207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673207","Virtual Reality;Augmented Reality;Human-Robot Interaction","Robots;Conferences;Human-robot interaction;Augmented reality;Artificial intelligence;Planning","augmented reality;control engineering computing;human-robot interaction;user interfaces","mixed reality interactions;interactive robots;virtual agents;human-robot interaction;virtual augmented and mixed reality;VAM-HRI","","14","","23","IEEE","25 Mar 2019","","","IEEE","IEEE Conferences"
"AR Tips: Augmented First-Person View Task Instruction Videos","G. Lee; S. Ahn; W. Hoff; M. Billinghurst","University of South Australia, Adelaide, SA, Australia; University of South Australia; Colorado School of Mines; University of South Australia","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","34","36","This research investigates applying Augmented Reality (AR) visualisation of spatial cues in first-person view task instruction videos. Instructional videos are becoming popular, and are not only used in formal education and training, but even in everyday life as more people seek for how-to videos when they need help with instructions. However, video clips are 2D visualisation of the task space, sometimes making it hard for the viewer to follow and match the objects in the video to those in the real-world task space. We propose augmenting task instruction videos with 3D visualisation of spatial cues to overcome this problem, focusing on creating and viewing first-person view instruction videos. As a proof of concept, we designed and implemented a prototype system, called AR Tips, which allows users to capture and watch first-person view instructional videos on a wearable AR device, augmented with 3D visual cues shown in-situ at the task environment. Initial feedback from potential end users indicate that the prototype system is very easy to use and could be applied to various scenarios.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951933","Augmented task guidance;instructional video;spatial cue","Videos;Task analysis;Visualization;Prototypes;Augmented reality;Three-dimensional displays;Annotations","augmented reality;data visualisation","augmented reality visualisation;spatial cues;formal education;video clips;real-world task space;creating viewing first-person view instruction videos;first-person view instructional videos;3D visual cues;task environment;augmented first-person view task instruction videos","","4","","9","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"A Case Study of the Development of Using Augmented Reality in Teaching Nature and Life Technology to Junior High School Students in Southern Taiwan","G. -J. Chen; R. -S. Chen","Information and Learning Technology, National University of Tainan, Tainan, Taiwan; Appliid English Chihlee, University of Technology, New Taipei County, Taiwan","2018 1st International Cognitive Cities Conference (IC3)","9 Dec 2018","2018","","","145","148","This study used augmented reality software as a research tool for Junior High School Curriculum in the “Nature and Life Technology” field, designed a set of teaching units by using the augmented reality teaching system (ARTS). In this study, the researchers discussed how augmented reality technology can be applied into the field of Nature and Life Technology. The researchers used Lightning Studios software to design the three teaching units: start movement, plate tectonics and electromagnetic inductions, integrated with AR technique. The total 140 ninth graders from one junior high school in southern Taiwan have participated in this study. After using the application of ARTS, all participants filled in questionnaires and had individual interviews with the researchers. The study results showed that both students and teachers who used ARTS not only enhanced students' learning motivation, and changed their learning attitudes to be more active, but also make up for the shortage of teaching materials, and provided more different teaching methods.","","978-1-5386-5059-2","10.1109/IC3.2018.00-41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567185","augmented-reality;junior-education;nature-and-life-technology","Education;Augmented reality;Software;Tools;Electromagnetic induction;Media","augmented reality;computer aided instruction;educational institutions;teaching","Life Technology;Lightning Studios software;teaching units;southern Taiwan;ARTS;teaching materials;Junior High School students;reality software;research tool;Junior High School Curriculum;augmented reality teaching system;augmented reality technology;teaching methods;ninth graders","","2","","13","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
"Using the augmented reality sandbox for advanced learning in geoscience education","S. N. Kundu; N. Muhammad; F. Sattar","Department of Geography, National University of Singapore, Singapore; Department of Geography, National University of Singapore, Singapore; School of Education, Charles Darwin University, Australia","2017 IEEE 6th International Conference on Teaching, Assessment, and Learning for Engineering (TALE)","11 Jan 2018","2017","","","13","17","Augmented reality is influential in achieving experiential learning in several subjects. In a geoscience classroom where spatial thinking skills and visualization of real-world phenomena is key to enhance understanding, experiential learning through the use of augmented reality sandbox and augmented reality constructs can be very effective. Augmented reality is being successfully used for holistic training in critical applications of medicine, aerospace, robotics and now it is increasingly getting popular in formal education. Geoscience, being is an observational science, poses a challenge for an educator as delivering an understanding of earth processes through geological time scales difficult to achieve in the confines of a classroom. Field based studies have always been complementing geoscience education but they are becoming a logistic headache for many educational institutions. Augmented reality, through the draping of virtual reality onto a physical model, presents a realistic simulation of earth processes which facilitates the design and implementation of experiential learning modes in a geoscience classroom. The current article discusses the Augmented Reality construct and its integration in tutorials aimed at achieving experiential learning for geoscience students. We also discussed extending the use of similar constructs for transitioning student understanding in real-world problems and applications.","2470-6698","978-1-5386-0900-2","10.1109/TALE.2017.8252296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252296","Augmented reality Sandbo;Geoscience;Experiential Learning;Spatial Cognition","Geoscience;Education;Augmented reality;Cognition;Surface topography;Data visualization;Color","augmented reality;computer aided instruction;data visualisation;educational institutions;geophysics computing;physics education","augmented reality sandbox;geoscience education;virtual reality;experiential learning modes;geoscience classroom;advanced learning;spatial thinking skills;visualization;educational institutions","","13","","29","IEEE","11 Jan 2018","","","IEEE","IEEE Conferences"
"V-Museum: A Virtual Museum Based on Augmented and Virtual Realities for Cultural Heritage Mediation","M. Kadri; H. Khalloufi; A. Azough","LISAC Laboratory, Sidi Mohamed Ben Abdellah University, Fez, Morocco; LISAC Laboratory, Sidi Mohamed Ben Abdellah University, Fez, Morocco; LISAC Laboratory, Sidi Mohamed Ben Abdellah University, Fez, Morocco","2020 International Conference on Intelligent Systems and Computer Vision (ISCV)","23 Sep 2020","2020","","","1","5","Cultural tourism is a growing sector. It is one of the best ways to discover the cultural heritage and way of life of a region and its people. However, without modernization and digital mediation, this sector can rapidly deteriorate. In this paper, a novel, playful and informative cultural touristic experience is presented. It consists of a virtual Space Door accessible through augmented reality and leading to a virtual museum built using virtual reality. Evaluation of the prototype was conducted in a real environment to confirm usability, ease of use and interest of the prototype.","","978-1-7281-8041-0","10.1109/ISCV49265.2020.9204253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204253","Augmented Reality;Cultural Tourism;Virtual Museum;Cultural Heritage;Historical Monuments;3D Model;Visualization","Cultural differences;Urban areas;Augmented reality;Three-dimensional displays;Prototypes;Target tracking","augmented reality;history;museums;travel industry","virtual museum;augmented realities;virtual realities;cultural heritage mediation;cultural tourism;growing sector;digital mediation;playful;informative cultural touristic experience;augmented reality;virtual reality;virtual space door","","5","","21","IEEE","23 Sep 2020","","","IEEE","IEEE Conferences"
"The Deployment of a Mixed Reality Experience for a Small-Scale Exhibition in the Wild","K. Cheng; I. Furusawa","Rakuten Institute of Technology, Rakuten, Inc., Japan; Marketing & UX CoE Dept., Rakuten, Inc., Japan","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","214","215","Museums and exhibitions often present physical artefacts which may contain rich histories or deep meaning associated with them. These additional contents are often installed physically as informational panels shown on the wall. However, these may sometimes be challenging to deploy due to space constraints. In order to address this challenge, we introduce the use of mixed reality. Mixed reality offers an immersive and interactive experience through the use of head mounted displays and in-air gestures. Visitors can discover additional content virtually, without changing the physical space. For a small-scale exhibition at a cafe, we developed a Microsoft HoloLens application to create an interactive experience on top of a collection of historic physical items. Through public experiences at the café, we received positive feedback of our system. In this paper, we discuss the design and implications of our system, survey results, as well as challenges that were encountered in deploying our mixed reality experience in a public setting.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699334","Mixed reality;exhibition;public deployment;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, Augmented, Virtual, and Mixed Realities","Sports;Organizations;Visualization;Augmented reality;History;Videos","augmented reality;exhibitions;helmet mounted displays;history;museums","immersive experience;interactive experience;physical space;small-scale exhibition;historic physical items;mixed reality experience;exhibitions;physical artefacts;informational panels;space constraints;museums;head mounted displays;in-air gestures;Microsoft HoloLens","","3","","4","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"First Deployment of Diminished Reality for Anatomy Education","N. Ienaga; F. Bork; S. Meerits; S. Mori; P. Fallavollita; N. Navab; H. Saito","Keio University, Yokohama, Japan; Technische Universitt Mnchen, Munich, Germany; Keio University, Yokohama, Japan; Keio University, Yokohama, Japan; University of Ottawa, Ottawa, Canada; Technische Universitt Mnchen, Munich, Germany; Keio University, Yokohama, Japan","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","294","296","Understanding the anatomy of the human body is vital for everyone working in the medical domain. Augmented reality (AR) systems for anatomy teaching, which display virtual information directly on top of a users' body, have proven to facilitate mental mapping compared to traditional teaching paradigms. In this paper, we explore the potential of diminished reality (DR) in the context of anatomy education. As a first necessary step to achieving a DR anatomy education system, parts of the human body have to be extracted and diminished from the video stream. Our system diminishes either the arm or head of the user by projecting a background image recovered using RGB-D cameras. Such a system, if combined with an accurate overlay of virtual counterparts, could potentially improve the learning effect by attracting the users' attention to the virtual information and improve visual perception by avoiding the well-known floating effect of AR.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836520","Mixed Reality;Diminished Reality;Anatomy Education","Cameras;Augmented reality;Education;Head;Streaming media;Three-dimensional displays;Image reconstruction","augmented reality;biomedical education;cameras;computer aided instruction;image colour analysis;medical computing;visual perception","diminished reality;human body anatomy education;medical domain;augmented reality systems;AR systems;virtual information;user body;mental mapping;DR anatomy education;video stream;user head;user arm;background image projection;RGB-D cameras;learning effect improvement;visual perception improvement","","7","1","10","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Projected Augmented Reality to Drive Osteotomy Surgery: Implementation and Comparison With Video See-Through Technology","V. Mamone; V. Ferrari; S. Condino; F. Cutolo","Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy; Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy; Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy; Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy","IEEE Access","22 Sep 2020","2020","8","","169024","169035","In recent years, the spreading of visual augmented reality as an effective tool in image-guided surgery, has stimulated the research community to investigate the use of commercial augmented reality headsets a broad range of potential applications. This aroused enthusiasm among clinicians for the potential of augmented reality, but also revealed some technological and human-factor limitations that still hinder its routine adoption in the operating room. In this work, we propose an alternative to head-mounted displays, based on projected augmented reality. Projected augmented reality completely preserves the surgeon's natural view of the operating field, because it requires no perspective conversion and/or optical mediation. We selected a cranio-maxillofacial surgery application as a benchmark to test the proposed system and compare its accuracy with the one obtained with a video see-through system. The augmented reality overlay accuracy was evaluated by measuring the distance between a virtual osteotomy line and its real counterpart. The experimental tests showed that the accuracy of the two augmented reality modes is similar, with a median error discrepancy of about 0.3 mm for the projected augmented reality mode. Results suggest that projected augmented reality can be a valuable alternative to standard see-through head-mounted displays to support in-situ visualization of medical imaging data as surgical guidance.","2169-3536","","10.1109/ACCESS.2020.3021940","Horizon 2020 Project Video-Optical See Through AR Surgical System (VOSTARS) (Call: ICT-29-2016 Photonics KET 2016)(grant numbers:731974); Italian Ministry of Education, University and Research (MIUR) in the Framework of the Laboratory of Augmented Reality, CrossLab Project (Departments of Excellence), University of Pisa; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186694","Augmented reality;projected augmented reality;video see-through;head-mounted display;computer-assisted surgery;cranio-maxillofacial surgery;augmented reality accuracy","Surgery;Augmented reality;Cameras;Visualization;Optical imaging;Biomedical optical imaging","augmented reality;biomedical optical imaging;bone;medical image processing;surgery","surgical guidance;medical imaging data visualization;optical mediation;osteotomy surgery;video see-through technology;visual augmented reality modes;augmented reality headsets","","13","","46","CCBYNCND","4 Sep 2020","","","IEEE","IEEE Journals"
"Magestro: Gamification of the Data Collection Process for Development of the Hand Gesture Recognition Technology","S. Ekneling; T. Sonestedt; A. Georgiadis; S. Yousefi; J. Chana","Department of Computer and Systems Sciences, Stockholm University; Department of Computer and Systems Sciences, Stockholm University; Manomotion AB; Department of Computer Science and Media Technology, Linnaeus University; Manomotion AB","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","417","418","The work presented in this demo, explores the enhancement of the data collection and data annotation processes via gamification. For the use case of Hand Tracking (HT) and Gesture Recognition (GR) we have created an Augmented Reality (AR) and Virtual Reality (VR) application that implements both the collection and annotation task. Similar to other popular “Simon Says” games such as Guitar hero, the game versions of the app were easily understood and used by users. Based on previous results, the game versions were widely adopted by the users because of their novelty and entertainment value.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699220","Augmented Reality;Virtual Reality;Gamification;Hand Gestures;Gamification—Gesture Recognition—;Data Collection—Data Collection App—Game—Application;ManoMotion—Virtual Reality (VR)—Data Annotation—;Gesture Analysis—Data Labeling—","Games;Data collection;Augmented reality;Task analysis;Three-dimensional displays;Gesture recognition","augmented reality;computer games;gesture recognition;object tracking","gamification;data collection process;data annotation processes;hand tracking;augmented reality;virtual reality application;hand gesture recognition technology;Magestro","","1","","3","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Design and Development of Mobile Augmented Reality for Mathematical Experiments","Y. Yang; Q. Liu; L. Wu; S. Xu; S. Yu; N. Zhang","School of Educational Information Technology, Centeral China Normal University, Wuhan, China; School of Educational Information Technology, Centeral China Normal University, Wuhan, China; School of Educational Information Technology, Centeral China Normal University, Wuhan, China; School of Educational Information Technology, Centeral China Normal University, Wuhan, China; School of Educational Information Technology, Centeral China Normal University, Wuhan, China; School of Educational Information Technology, Centeral China Normal University, Wuhan, China","2019 International Symposium on Educational Technology (ISET)","1 Aug 2019","2019","","","139","143","In the information age, augmented reality has entered a period of rapid development, widely used in various fields. This paper is meant to firstly state the application status of AR in the field of education briefly and then summarize three types of teaching tools based on augmented reality: head-mounted AR, desktop AR and mobile AR. After comparing the three types of AR applications, taking the three views in the mathematics textbook of middle school as an example, the study designs and develops a mobile augmented reality software ""Exploring the Three Views"" to supplement class teaching, encouraging hands-on practice of students, with the aim to help students acquire the knowledge of three views, cultivate practical ability and improve spatial imagination ability.","","978-1-7281-3388-1","10.1109/ISET.2019.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782260","Augmented Reality, Mobile Augmented Reality, Mathematics Experiment","Education;Mathematics;Augmented reality;Solid modeling;Three-dimensional displays;Information technology;Tools","augmented reality;computer aided instruction;educational institutions;mathematics computing;mobile computing;teaching","mathematical experiments;teaching tools;head-mounted AR;AR applications;mathematics textbook;mobile augmented reality software;education;desktop AR;mobile AR","","1","","21","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"Computer vision and sensor fusion for efficient hybrid tracking in augmented reality systems","D. P. Kaur; A. Mantri","School of Electronics and Electrical Engineering, Chitkara University, Rajpura, Punjab; Chitkara University Research and Innovation Network, Chitkara University, Rajpura, Punjab","2015 IEEE 3rd International Conference on MOOCs, Innovation and Technology in Education (MITE)","11 Jan 2016","2015","","","176","181","Augmented Reality is one of the most fundamental enabling technologies of this era which modifies our perception to such an extent that we are able to see, hear and feel the ordinary everyday objects in a new and enriched way. This technology is an amalgamation of Real and Virtual Worlds which aims to enhance the physical information by exactly super-imposing the computer generated content on it. The technology can prove helpful to surgeons and doctors to visualize and train a surgery, can instruct a mechanic for repair of an unknown piece of equipment, can serve as a source of entertainment, can help soldiers for spotting enemy snipers, and can be used as an efficient teaching aid for education. A typical Augmented Reality (AR) system requires the integration of hardware and software with factors such as Tracking, Registration, Interaction and Display playing an important role in the system design. The focus of this paper is specifically towards surveying the available Tracking Techniques for various Augmented Reality applications. Based on the existing methods of sensor based, vision based and hybrid tracking, a new method for efficient tracking is proposed.","","978-1-4673-6747-9","10.1109/MITE.2015.7375310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375310","Augmented Reality;Sensor Based Tracking;Vision Based Tracking;Hybrid Tracking;Mobile AR;Augmented Reality for Education","Augmented reality;Cameras;Tracking;Education;Robustness;Global Positioning System;Mobile communication","augmented reality;computer vision;sensor fusion","computer vision;sensor fusion;hybrid tracking;augmented reality system;computer generated content;surgery;AR system;Virtual Worlds amalgamation;real world amalgamation","","1","1","23","IEEE","11 Jan 2016","","","IEEE","IEEE Conferences"
"E-learning system using Augmented Reality","S. Patil; C. Prabhu; O. Neogi; A. R. Joshi; N. Katre","Dept. of Information Technology, D. J. Sanghvi College of Engg.; Dept. of Information Technology, D. J. Sanghvi College of Engg.; Dept. of Information Technology, D. J. Sanghvi College of Engg.; Dept. of Information Technology, D. J. Sanghvi College of Engg.; Dept. of Information Technology, D. J. Sanghvi College of Engg.","2016 International Conference on Computing Communication Control and automation (ICCUBEA)","23 Feb 2017","2016","","","1","5","Virtual reality replaces the existing world with a simulated one. Augmented reality is, however, in real time. The emerging field of Augmented Reality opens up avenues in numerous fields with education being no exception. Our paper proposes an e-learning system for three-dimensional geometry, which makes use of Augmented Reality to enable the user to comprehend the three-dimensional geometry concepts faster and better. It facilitates the students understanding of three-dimensional geometry, which can be difficult when attempting to do the same in two-dimensional space. Based on the marker, the system generates the three-dimensional object and blends it in the real world footage. The system allows the user to manipulate the object through virtual buttons, while also allowing him/her to access the object's properties. Furthermore, the system provides interactive videos to aid the users understanding as well as a quiz by which the user can assess his/her knowledge of the three-dimensional concepts.","","978-1-5090-3291-4","10.1109/ICCUBEA.2016.7860038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860038","Augmented Reality;augment;geometry","Augmented reality;Geometry;Videos;Cameras;Electronic learning;Three-dimensional displays;Shape","augmented reality;computational geometry;computer aided instruction;video signal processing","e-learning system;augmented reality;virtual reality;3D geometry concepts;2D space;3D object;virtual buttons;interactive videos","","4","","4","IEEE","23 Feb 2017","","","IEEE","IEEE Conferences"
"The Virtual-Augmented Reality Simulator: Evaluating OST-HMD AR calibration algorithms in VR","D. Gasques; W. Liu; N. Weibel","Computer Science and Engineering, UC, San Diego; Computer Science and Engineering, UC, San Diego; Computer Science and Engineering, UC, San Diego","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","702","703","When developing AR applications for high-precision domains such as surgery, we face a common problem: how can the system guarantee that the end-user will see a virtual object aligned with its real-world counterpart? Alignment, or registration, is a crucial feature of AR displays, but achieving accurate alignment between real and virtual objects is not trivial. With hundreds of calibration approaches available, we need better tools to understand how and when calibration algorithms fail as well as understand what can be done to improve alignment. This poster introduces a novel AR simulator in VR that facilitates experimentation with different calibration algorithms.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757408","Augmented Reality;Head-Mounted Displays;Alignment;Registration;Simulator;Virtual Reality;Augmented Reality—Head-Mounted Displays—Alignment—Simulator","Three-dimensional displays;Conferences;Surgery;Virtual reality;User interfaces;Calibration;Faces","augmented reality;calibration;data visualisation;helmet mounted displays;human computer interaction;surgery","virtual object;calibration approaches;VR;different calibration algorithms;virtual-augmented reality simulator;OST-HMD;developing AR applications;high-precision domains;surgery;system guarantee;end-user;real-world counterpart;crucial feature","","","","9","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"HORUS EYE: See the Invisible Bird and Snake Vision for Augmented Reality Information Visualization","N. A. M. ElSayed; R. T. Smith; B. H. Thomas","Wearable Computer Lab, University of South Australia; Wearable Computer Lab, University of South Australia; Wearable Computer Lab, University of South Australia","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","203","208","This paper presents a novel technique, called Horus Eye, for augmented reality information visualization. “Horus”, the famous deity in ancient Egyptian mythology, inspires this visualization technique, which is designed to simulate bird and snake vision to highlight data of interest. The contribution of this approach is the merging of information with the real scene, leveraging the real world context to interpret the data. Our technique is a context-based interactive visualization, controlled by users' queries. This paper presents a work in progress with use cases and two adaptations of Horus Eye.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836498","Horus Eye;Augmented Reality;Visualization;Information Visualization;Blended Information;Scene Manipulation;Diminished Reality","Data visualization;Birds;Image color analysis;Visualization;Sensitivity;Brightness;Sugar","augmented reality;data visualisation","Horus eye;invisible bird vision;snake vision;augmented reality information visualization;ancient Egyptian mythology;context-based interactive visualization","","5","","23","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"User attention oriented augmented reality on documents with document dependent dynamic overlay","T. Toyama; W. Suzuki; A. Dengel; K. Kise",DFKI GmbH; Osaka Prefecture University; DFKI GmbH; Osaka Prefecture University,"2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","299","300","When we read a document (any kind of, scientific papers, novels, etc.), we often encounter a situation that the information from the reading document is too less to comprehend what the author(s) would like to convey. In this paper, we demonstrate how the combination of a wearable eye tracker, a see-through head-mounted display (HMD) and an image based document retrieval engine enhances people's reading experiences. By using our proposed system, the reader can get supportive information in the see-through HMD when he wants. A wearable eye tracker and a document retrieval engine are used to detect which line in the document the reader is reading. We propose a method to detect the reader's attention on a word in a reading document, in order to present information at a preferable moment. Furthermore, we also propose a method to project a point of the document to a point of the HMD screen, by calculating the pose of the reading document in the camera image. This projection enables the system to overlay the information dynamically in an augmented view on the reading line. The results from the user study and the experiments show the potential of the proposed system in a practical use case.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671814","","Augmented reality;Calibration;Visualization;Feature extraction;Engines;Dictionaries;Tracking","augmented reality;helmet mounted displays;information retrieval","user attention oriented augmented reality;document dependent dynamic overlay;wearable eye tracker;see-through head-mounted display;HMD;image based document retrieval engine;camera image","","4","2","8","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"AR CARD: Interactive Cards using Augmented Reality","A. S; D. Gangadhar; J. Mohan; N. T. Mathew; T. Sreenath","Department of Computer Science, Mar Baselios College of Engineering and Technology, Trivandrum, Kerala, India; Department of Computer Science, Mar Baselios College of Engineering and Technology, Trivandrum, Kerala, India; Department of Computer Science, Mar Baselios College of Engineering and Technology, Trivandrum, Kerala, India; Department of Computer Science, Mar Baselios College of Engineering and Technology, Trivandrum, Kerala, India; Department of Computer Science, Mar Baselios College of Engineering and Technology, Trivandrum, Kerala, India","2021 International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)","21 Dec 2021","2021","","","1","6","Interactive cards using augmented reality are used to break the bounds of information confined within a small card. The existing business cards cannot give much information in a single glance. Only trivial information is present in the business card which only gives vague information. Augmented Reality can enhance the user experience by including much more information regarding the user by just scanning the business card. AR CARD allows the user to view the details or information that are not present on the business card as an augmented detail view by including more interactive UI thereby enhancing the user experience. The augmented display for a specific card can only be triggered by a target image which when scanned, details related to the target image which is the business card is fetched and augmented. By implementing an Interactive Augmented card the user can have a better interactive experience as well as acquire a lot of information which a business card is unable to provide.","","978-1-6654-2503-2","10.1109/SMARTGENCON51891.2021.9645911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9645911","Augmented Reality;Wifi;Markerless;AR Card","Head;Market research;User experience;Distance measurement;Object recognition;Augmented reality;Business","augmented reality;interactive systems;user interfaces","augmented detail view;user experience;AR CARD;augmented reality;business cards;interactive augmented card;interactive UI","","","","9","IEEE","21 Dec 2021","","","IEEE","IEEE Conferences"
"Evaluating wide-field-of-view augmented reality with mixed reality simulation","D. Ren; T. Goldschwendt; Y. Chang; T. Höllerer","University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara","2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","93","102","Full-surround augmented reality, with augmentations spanning the entire human field of view and beyond, is an under-explored topic since there is currently no hardware that can support it. As current AR displays only support relatively small fields of view, most AR applications to-date employ relatively small point-based annotations of the physical world. Anticipating a change in AR capabilities, we experiment with wide-field-of-view annotations that link elements far apart in the visual field. We have built a system that uses full-surround virtual reality to simulate augmented reality with different field of views, with and without tracking artifacts. We conducted a study comparing user performance on five different task groups within an information-seeking scenario, comparing two different fields of view and presence and absence of tracking artifacts. A constrained field of view significantly increased task completion time. We found indications for task time effects of tracking artifacts to vary depending on age.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504692","H.5.1 [Information Interfaces and Presentation (e.g., HCI)]: Multimedia Information Systems — Artificial, augmented, and virtual realities;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism — Virtual reality","Augmented reality;Solid modeling;Visualization;Three-dimensional displays;Performance evaluation;Hardware","augmented reality;user interfaces","wide-field-of-view augmented reality;mixed reality simulation;full-surround augmented reality;AR applications;point-based annotation;wide-field-of-view annotation;full-surround virtual reality;augmented reality simulation;user performance;tracking artifacts;task time effects;information seeking","","31","","40","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"New Technologies and Tools for Immersive and Engaging Visitor Experiences in Museums: The Evolution of the Visit-Actor in Next-Generation Storytelling, through Augmented and Virtual Reality, and Immersive 3D Projections","D. Pantile; R. Frasca; A. Mazzeo; M. Ventrella; G. Verreschi","ETT S.p.A., Genoa, Italy; ETT S.p.A., Genoa, Italy; ETT S.p.A., Genoa, Italy; ETT S.p.A., Genoa, Italy; ETT S.p.A., Genoa, Italy","2016 12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","24 Apr 2017","2016","","","463","467","This paper will describe the multimedia solutions designed and developed by ETT S.p.A. for four different clients and will explain the potential of the use of technology in museum and tourist attractions, as well as the variety of solutions available on the market. Starting from a theoretical analysis on the shift from the idea of a collection-oriented museum to that of a visitor-oriented one, we shall illustrate a storytelling approach based on, and using, Immersive Visitor Engagement Technology. We shall also describe a series of practical examples and case histories of ETT projects in the museum sector. Particular emphasis is placed on Augmented Reality, Virtual Reality, and Immersive 3D Projection projects.","","978-1-5090-5698-9","10.1109/SITIS.2016.78","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7907505","interactive museum exhibit;augmented reality;virtual reality;mixed reality;gamification;cultural heritage;visitor engagement;edutainment;storytelling","Three-dimensional displays;Augmented reality;Market research;Glass;Multimedia communication;History","augmented reality;museums","multimedia solution design;multimedia solution development;tourist attractions;collection-oriented museum;visitor-oriented museum;immersive visitor engagement technology;ETT projects;augmented reality;virtual reality;immersive 3D projection projects","","7","","5","IEEE","24 Apr 2017","","","IEEE","IEEE Conferences"
"Is That Me?—Embodiment and Body Perception with an Augmented Reality Mirror","C. Nimcharoen; S. Zollmann; J. Collins; H. Regenbrecht",University of Otago; University of Otago; University of Otago; University of Otago,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","158","163","Virtual reality has been used intensively to study embodiment and body perception, in particular for research purposes in psychological domains. Virtual avatars are used to resemble users' appearance and to implement interactively simulated behaviour. To make this a realistic and believable experience users should feel embodiment, i.e. ownership, agency, and self-location/presence. State-of-the-art capture and display technologies allow for extending virtual reality embodiment to the realm of augmented reality for higher efficacy-instead of seeing a virtual reality body one would see a captured, 3D representation of their own body naturally controlled by their real body movements within the context of the present real environment. However, it is unclear whether users would experience embodiment with their augmented reality avatar and whether findings from virtual reality targeting body perception can be replicated. Here we present an augmented reality system comprising a 3D point cloud capturing system (Microsoft Kinect) and an optical see-through head-mounted display (Microsoft HoloLens), both connected to a purpose-developed application displaying a user's body in a virtual 3D mirror embedded into the real environment. In a study with 24 participants, we evaluated embodiment and body weight perception as a proof of concept. This is based on a similar study conducted in Virtual Reality. Our findings show that users experience ownership and agency with the mirrored body and that body weight perception in virtual and augmented reality systems is similar.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699238","Ownership;agency;presence;mixed reality;optical see-through displays;self-location;H.5.1 [Information Interfaces and Presentation (e.g. HCI)]: Multimedia Information Systems — Artificial, augmented, and virtual realities","Augmented reality","augmented reality;avatars;helmet mounted displays;psychology","virtual reality body;head-mounted display;3D point cloud capturing system;virtual avatars;augmented reality system;virtual reality embodiment;display technologies;realistic experience users;interactively simulated behaviour;body weight perception;virtual 3D mirror;augmented reality avatar;body movements;3D representation","","12","","19","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Augmented Reality for Quick and Intuitive Robotic Packing Re-Programming","D. Araiza-Illan; A. De San Bernabe; F. Hongchao; L. Y. Shin","Advanced Remanufacturing and Technology Centre (ARTC), Agency for Science, Technology and Research (A*STAR), Singapore; Advanced Remanufacturing and Technology Centre (ARTC), Agency for Science, Technology and Research (A*STAR), Singapore; Advanced Remanufacturing and Technology Centre (ARTC), Agency for Science, Technology and Research (A*STAR), Singapore; Advanced Remanufacturing and Technology Centre (ARTC), Agency for Science, Technology and Research (A*STAR), Singapore","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","25 Mar 2019","2019","","","664","664","Current manufacturing applications are subject to constant changes in production orders for their robotic systems to adapt to the dynamic nature of the market. Hence, reprogramming robots needs to be a fast, easy and effective process. In this demonstration, we present an augmented reality (AR) interface using HoloLens. Our interface provides an intuitive platform to re-program a robotic packing application through simple hand gestures and the information gathered by the HoloLens' spatial mapping functionality.","2167-2148","978-1-5386-8555-6","10.1109/HRI.2019.8673327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673327","Augmented reality;robot programming;intuitive interfaces","Augmented reality;Robot programming;Cameras;Robot vision systems","augmented reality;control engineering computing;gesture recognition;industrial robots;mobile robots;packaging;production engineering computing;robot programming","production orders;robotic systems;augmented reality interface;intuitive platform;robotic packing application;manufacturing applications;robotic packing reprogramming;augmented reality;AR interface;HoloLens","","7","","3","IEEE","25 Mar 2019","","","IEEE","IEEE Conferences"
"Doctor Herb, The Herbal Augmented Reality Application","R. Nobnop; Y. Thongpaeng; N. Chaiwut","School of Information Technology, Mae Fah Luang University, Chiangrai, Thailand; School of Information Technology, Mae Fah Luang University, Chiangrai, Thailand; School of Information Technology, Mae Fah Luang University, Chiangrai, Thailand","2020 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT & NCON)","11 May 2020","2020","","","46","48","Herb is a natural product that can find throughout Thailand. Many pieces of evidence confirm the using herb as a medical treatment in ancient. Not only that but also for cooking. However, only a small group know each kind of herb. In this research, we investigate the smartphone augmented reality application and booklet. The propose of this research is an application that defines the features and usage of the local herb. The user can visualize the herb characteristics and name through the animation in the application. The final result reveals significant cognitive learning of the user.","","978-1-7281-6398-7","10.1109/ECTIDAMTNCON48261.2020.9090718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090718","Herb;Augmented Reality (AR)","Three-dimensional displays;Augmented reality;Education;Information technology;Media;Digital art;Telecommunications","augmented reality;biology computing;botany;smart phones","doctor herb;herbal augmented reality application;natural product;medical treatment;smartphone augmented reality application;herb characteristics","","","","6","IEEE","11 May 2020","","","IEEE","IEEE Conferences"
"HomeWindow: An augmented reality domestic monitor","P. Lapides; E. Sharlin; S. Greenberg","Dept. Computer Science, University of Calgary, Calgary, AB, Canada; Dept. Computer Science, University of Calgary, Calgary, AB, Canada; Dept. Computer Science, University of Calgary, Calgary, AB, Canada","2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","2 Aug 2012","2009","","","323","324","Computation is increasingly prevalent in the home: it serves as a way to control the home itself, or it is part of the many digital appliances within it. The question is: how can home inhabitants effectively understand and control the digital home? Our solution lets a person examine and control their home surroundings through a mobile display that serves as a `magic lens', where the detail shown varies with proximity. In particular, HomeWindow is an augmented reality system that superimposes an interactive graphical interface atop of physical but digital artifacts in the home. One can get an overview of a room's computational state by looking through the display: the basic state of all digital hot spots are shown atop their physical counterparts. As one approaches a particular digital spot, more detailed information as well as a control interface is shown using a semantic zoom. Our current implementation works with two home devices. First, people can examine and remotely control the status of mobile domestic robots. Second, people can discover the power consumption of household appliances, where appliances are surrounded by a colorful aura that reflects its current and historical energy use.","2167-2148","978-1-60558-404-1","10.1145/1514095.1514197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6256086","Augmented reality;human-robot interaction;energy awareness;domestic computing ubiquitous computing","Robots;Computers;Home appliances;Augmented reality;Green products;Image color analysis;Computer science","augmented reality;domestic appliances;graphical user interfaces;home automation;interactive systems;mobile computing;mobile robots;telerobotics","HomeWindow;augmented reality domestic monitor;digital appliances;home inhabitants;digital home;mobile display;magic lens;augmented reality system;interactive graphical interface;digital artifact;room computational state;digital hot spots;control interface;semantic zoom;home devices;remote control;mobile domestic robots;power consumption;household appliances;colorful aura","","","1","3","","2 Aug 2012","","","IEEE","IEEE Conferences"
"Research on the Application of Augmented Reality Technology in College English Teaching","X. Zhou","College of Foreign Languages and Literature Wuhan Donghu University, Wuhan, China","2021 International Conference on Computers, Information Processing and Advanced Education (CIPAE)","26 Nov 2021","2021","","","18","21","Augmented Reality (AR) is a technology that can innovate traditional education. This technology connects virtual objects with the real world, and it can visualize complex spatial relationships and abstract concepts, it also deepen people's perception of the surrounding environment and understanding of knowledge, and enable learners to experience impossible phenomena in the real world. AR brings new opportunities for teaching innovation. On the basis of the technical characteristics of augmented reality and the advantages of its application, and by analyzing the problems facing college English teaching, the paper discusses the advantages of augmented reality in college English teaching and the practice of teaching activities. It can promote the vigorous development of English classroom based on the deep integration of augmented reality technology and English teaching. The purpose of this paper is to provide reference model and educational theory support for the introduction of augmented reality technology into college English classroom.","","978-1-6654-2665-7","10.1109/CIPAE53742.2021.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9610454","Augmented Reality;Virtual Reality;College English Teaching","Computers;Technological innovation;Visualization;Education;Information processing;Augmented reality","augmented reality;computer aided instruction;educational institutions;further education;linguistics;multimedia computing;teaching","college English teaching;teaching activities;augmented reality technology;college English classroom;teaching innovation;AR technology;spatial relationship visualization;abstract concept visualization;learning experience","","","","10","IEEE","26 Nov 2021","","","IEEE","IEEE Conferences"
"Augmented reality application for smart tourism: GökovAR","Ö. F. Demir; E. Karaarslan","Department of Computer Engineering, Mugla Sitki Kocman University, Mugla, Turkey; Department of Computer Engineering, Mugla Sitki Kocman University, Mugla, Turkey","2018 6th International Istanbul Smart Grids and Cities Congress and Fair (ICSG)","12 Jul 2018","2018","","","164","167","Usage of augmented reality technology in daily life is becoming more widespread. This technology is also being applied in the field of tourism. In this study, a prototype of mobile application for smart tourism has been developed by using augmented reality technology. The requirements, the competences and incompleteness of the methods is described. The prototype application is developed in the pilot region of Gökova Mugla. This application aims to introduce important centers, touristic places, restaurants, hotels and sightseeing places to domestic and foreign tourists. The intensity, ratings, comments, current social media data and price information about these areas will be provided simultaneously on the mobile application. Image processing techniques and location data will be used for implementing augmented reality technology.","","978-1-5386-4478-2","10.1109/SGCF.2018.8408965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408965","Smart City;Smart Tourism;Augmented Reality;Mobile Computing;Social Media","Augmented reality;Urban areas;Prototypes;Global Positioning System;Social network services;Cameras;Servers","augmented reality;image processing;location based services;mobile computing;social networking (online);travel industry","mobile application;smart tourism;augmented reality technology;augmented reality application;Gökova Mugla;GökovAR;image processing;social media","","17","","11","IEEE","12 Jul 2018","","","IEEE","IEEE Conferences"
"A Study on Integrating Augmented Reality Technology and Game-Based Learning Model to Improve Motivation and Effectiveness of Learning English Vocabulary","S. -Y. Chen; C. -Y. Hung; Y. -C. Chang; Y. -S. Lin; Y. -H. Lai","Department of Computer Science and Information Engineering, National Taitung University, Taitung, Taiwan; Education Department, National Taiwan Normal University, Taipei, Taiwan; Department of Computer Science and Information Engineering, National Taitung University, Taitung, Taiwan; Department of Information Science and Management Systems, National Taitung University, Taitung, Taiwan; Department of Computer Science and Information Engineering, National Taitung University, Taitung, Taiwan","2018 1st International Cognitive Cities Conference (IC3)","9 Dec 2018","2018","","","24","27","This study mainly focuses on developing a gamebased learning system with the augmented reality technology, which is applied to English curriculums in primary schools. Through the interactions of voice, graphics and real-world environments, students can learn common vocabulary of each English letter, and then discuss the impact on learning motivation and effectiveness. The purpose is combining the particularities of high interactivity, immersion and authenticity of the augmented reality with the game-based learning model to expect for attracting more people to invest in developing the augmented reality applications for the game-based learning. The system is evaluated by three experts with English education background. Through the quasi-experimental research method, there are 46 second grade students of primary school divided into the control group and experiment group to be investigated for learning motivation and learning effectiveness by questionnaire individually. The results show that it is significant in improving students' motivation and effectiveness through the augmented reality-based English learning system.","","978-1-5386-5059-2","10.1109/IC3.2018.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567161","Digital Game-based Learning;Augmented Reality;ARCS Motivation Model","Augmented reality;Education;Games;Vocabulary;Learning systems;Standards","augmented reality;computer aided instruction;linguistics;serious games (computing)","English curriculums;English education background;augmented reality-based English learning system;English vocabulary learning;game-based learning model;augmented reality technology","","17","","7","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
"Modelling learning from Ingress (Google's augmented reality social game)","L. Y. Sheng","Jalan Genting Kelang, Tunku Abdul Rahman University College, Kuala Lumpur, Malaysia","2013 IEEE 63rd Annual Conference International Council for Education Media (ICEM)","26 May 2014","2013","","","1","8","This is a concept paper looking into how Google's worldwide augmented reality game called Ingress could be used to inform the development of learning from games. Ingress is Google's attempt in creating a game based on augmented reality of actual physical locations where a story line is set to guide two different factions of agents to move around geographical locations with mobile devices to capture strategic places called portals which are based on actual artefacts. This paper describes how Ingress, through the use of mobile devices and augmented reality, incorporated within its gameplay the elements of MOOC, badges, crowd learning, seamless and geo-learning, and learning from gaming which are considered as new and emerging forms of pedagogies identified in Open University's 2013 report on innovating pedagogy. Initial findings of an online survey on the motivation to play and continue playing the game will be presented. This paper will end with a discussion on the potential of using the Ingress model with its integrated forms of pedagogies, and the limitations and issues that might arise. The conclusion is that although the process to enhance learning experience through gamification is not without difficulties, there exists a vast potential of benefits which justifies continuous research and exploration in this area.","","978-1-4799-3216-0","10.1109/CICEM.2013.6820152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6820152","Ingress;gamification;learning design;augmented reality;Google","Games;Google;Augmented reality;Mobile handsets;Portals;Communities;Conferences","augmented reality;computer games;educational computing","modelling;Google augmented reality social game;Google worldwide augmented reality game;mobile devices;portals;MOOC;badges;crowd learning;geolearning;gaming;pedagogy;Ingress model;gamification","","7","","2","IEEE","26 May 2014","","","IEEE","IEEE Conferences"
"Design computer-assisted learning in an online Augmented Reality environment based on Shneiderman's eight Golden Rules","N. Aottiwerch; U. Kokaew","Department of Computer Science, Khon Kaen University, Thailand; Department of Computer Science, Khon Kaen University, Thailand","2017 14th International Joint Conference on Computer Science and Software Engineering (JCSSE)","7 Sep 2017","2017","","","1","5","Microbial science is inevitably involved in human daily life because these creatures live around us. They are both useful and punishable. If the people have knowledge about microorganisms, it can control the microbes that cause the wicked things, and it can also be useful to use microorganisms effectively. Currently, the study still use the microscope in the education. There are limitations when exploring various cycles, it will not be able to explore as the time required. As the cycles of nature, it must have time as a variable. Therefore, the microscope helps to see the structure clearer only, but it cannot see all the natural cycles covered by a single microscope. Therefore, this research uses the Augmented Reality technology to be developed as instructional media (A case study of Phylum Basidiomycota, the fungi, which is considered to be the most complex internal structure). This helps to visualize the three-dimensional structure and cycles of nature from electronic devices. But the problem of instructional media created with Augmented Reality technology is that it is inaccessible and difficult to use. The researcher has developed together with online instructional media for easy access, and designed instructional media with the theory of Shneiderman's 8 Golden Rules for ease of use, and measured the performance with real applications by the third-year students of the Faculty of Science, Khon kaen University. It was found that Augmented Reality instructional media in online system was accessible and easy to use. It is also very satisfying for users, with an average score of 4.5 out of 1-5, this means that the criteria is very good.","","978-1-5090-4834-2","10.1109/JCSSE.2017.8025926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8025926","Augmented Reality;Media;Golden Rules","Augmented reality;Media;Solid modeling;Microscopy;Cameras;Microorganisms","augmented reality;biology computing;computer aided instruction;Internet;microorganisms","computer-assisted learning;online augmented reality environment;Shneiderman's eight Golden Rules;microbial science;microorganisms;Phylum Basidiomycota;fungi;complex internal structure;three-dimensional structure;electronic devices;third-year students;Faculty of Science;Khon kaen University;online was;augmented reality instructional media","","6","","11","IEEE","7 Sep 2017","","","IEEE","IEEE Conferences"
"Mapping 2D input to 3D immersive spatial augmented reality","M. R. Marner; R. T. Smith; B. H. Thomas",University of South Australia; University of South Australia; University of South Australia,"2015 IEEE Symposium on 3D User Interfaces (3DUI)","25 Jun 2015","2015","","","171","172","This poster presents Viewpoint Cursor, a technique for mapping 2D user input from devices such as mobile phones, trackballs, or computer mice, to 3D multi-projector spatial augmented reality systems. While the ubiquity of input devices such as these make them obvious choices for spatial augmented reality, their 2D nature makes them difficult to use. Existing VR techniques rely on a display in front of the user's eyes on which to place virtual information. Immersive spatial augmented reality systems allow users to experience and interact with projected virtual information from any angle, using arbitrary placement of projectors. Viewpoint Cursor addresses these issues by mapping 2D input to a plane in front of the user's view. Ray casting is then used to find the 3D location for the cursor in the scene, which is then projected using the projection system. The user's position is tracked, with the input remapped accordingly, resulting in 2D input that matches what the user expects, regardless of their location.","","978-1-4673-6886-5","10.1109/3DUI.2015.7131755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131755","Spatial Augmented Reality;User Interfaces","Three-dimensional displays;Augmented reality;Mobile handsets;Lasers;Mice;User interfaces;Electronic mail","augmented reality;optical projectors","2D user input mapping;3D immersive spatial augmented reality;viewpoint cursor;3D multiprojector spatial augmented reality systems;virtual information;projector placement;ray casting;projection system","","3","","8","IEEE","25 Jun 2015","","","IEEE","IEEE Conferences"
"View-dependent Virtual and Augmented Reality for Machine Tools","P. Sommer; A. Verl","Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany","2016 European Modelling Symposium (EMS)","8 May 2017","2016","","","149","154","In recent papers, the concept of an intelligent window for machine tools (iWindow) using virtual and augmented reality in order to replace traditional windows in machine tools was introduced. Such intelligent windows provide additional possibilities for observing the machine interior under difficult visibility conditions, combine and reduce the number of supporting systems and enrich the machine interior with contextual information. For creating a view-dependent virtual and augmented reality individual solution approaches presented in other research were combined, extended and applied to machine tools to form an intelligent window. For the impression of a real window and perspectively correctly overlay virtual objects, the operator's head position is tracked and the perspective projection matrix is calculated continuously. The necessary equations are presented. In an experimental setup, view-dependent rendering for virtual reality on opaque displays as well as augmented reality on transparent displays were validated. The rendering is performing well and an accurate overlay of virtual and real machine interior can be created. However, several difficulties regarding illumination, transparency and human stereo vision did occur. Possible improvements and solutions are suggested.","2473-3539","978-1-5090-4971-4","10.1109/EMS.2016.035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920244","view-dependent rendering; virtual reality; augmented reality; machine tools","Rendering (computer graphics);Augmented reality;Machine tools;Magnetic heads;Head;Solid modeling;Cameras","augmented reality;machine tools;production engineering computing;rendering (computer graphics)","view-dependent virtual reality;view-dependent augmented reality;machine tools;intelligent window;iWindow;machine interior;overlay virtual objects;perspective projection matrix;view-dependent rendering;opaque displays;transparent displays","","2","","12","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Research on the Application of Augmented Reality Technology in TV Programs","L. Xi; Z. Wang","School of Journalism and Communication, China West Normal University, Nanchong, China; School of Journalism and Communication, China West Normal University, Nanchong, China","2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA)","6 Oct 2020","2020","","","972","974","Augmented reality technology is a technology that integrates real world information and virtual world information. The application of augmented reality technology in TV programs is to simulate and display some video, audio, even taste, environmental atmosphere, etc. that are difficult to experience in the real world through computer technology, so that users can pass visual, auditory, and taste And touch. In the field of television production, from the teletext system in the 1990s to the virtual studio system and real-time virtual implantation system, TV workers have been using technical means to superimpose different virtual information on the video images taken by the camera Above. TV practitioners use ar technology to present the audience with more brilliant pictures, richer information, and more refined TV pictures. At this stage, the augmented reality production technology emphasized in the field of television production is mainly visual augmented reality technology. This is a technology based on real-time tracking the position of the image taken by the camera, and superimposing the corresponding video, audio, graphic information in real time through the computer system. This technology can superimpose virtual information on the TV screen to the real world. The ordinary TV screen not only displays real-world information, but also displays virtual information at the same time. The two kinds of information complement and superimpose each other, and even through elaborate program creative design, a good interaction effect between the real world and the virtual world can be achieved, which ultimately makes it difficult for viewers to distinguish between the virtual world and the real world in front of the TV screen.","","978-1-7281-6521-9","10.1109/AEECA49918.2020.9213670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9213670","augmented reality technology;application;TV programs","TV;Augmented reality;Media;Internet;Visualization;Production;Real-time systems","augmented reality;television production","TV workers;virtual information;TV practitioners;richer information;refined TV pictures;augmented reality production technology;television production;visual augmented reality technology;graphic information;ordinary TV screen;displays real-world information;information complement;TV programs;virtual world information;computer technology;virtual studio system;real-time virtual implantation system","","1","","5","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"A review on using augmented reality in text translation","L. Tatwany; H. C. Ouertani","Information Technology Department, King Saud University, Riyadh, Saudi Arabia; Information Technology Department, King Saud University, Riyadh, Saudi Arabia","2017 6th International Conference on Information and Communication Technology and Accessibility (ICTA)","12 Apr 2018","2017","","","1","6","In recent years with the rapidly growth of smart phones/devices, augmented reality becomes part of many mobile applications. For instance, we can cite the translation applications. This paper reports on a review of literature on augmented reality text translation. The main components of any augmented reality translation application are: text detection, text extraction and text translation. Therefore the factors considered in our study include: the used Optical Character Recognition (OCR) for text extraction, the used technique/algorithm for detecting the text, the used API's for text translation, the used tools in developing these applications and used programming language(s), the application supporting platform(s), the supported translation languages, the dataset used for evaluating the system and lastly, the results of the experiments. In total, 12 studies published between 1998 and 2016 were analyzed. The main findings from this review provide the current state of the art on research in augmented reality in text translation. Furthermore, the paper permits to set up the ways towards developing an android mobile application for real time Arabic text translation. Although the enrichment and the integration of the new technologies in the translation process, the existing applications are still limited to few number of languages. Arabic language is one of those not yet supported.","2379-4402","978-1-5386-4460-7","10.1109/ICTA.2017.8336044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336044","Augmented reality;text translation;OCR;Text detection;AR","Augmented reality;Optical character recognition software;Real-time systems;Cameras;Character recognition;Mobile applications","application program interfaces;augmented reality;language translation;natural language processing;optical character recognition;smart phones;text analysis","augmented reality translation application;text detection;text extraction;supported translation languages;translation process;mobile applications;translation applications;augmented reality text translation;Android mobile application;Arabic text translation;optical character recognition;OCR","","1","","27","IEEE","12 Apr 2018","","","IEEE","IEEE Conferences"
"Interactive Augmented Reality For The Depth Of An Object Using The Model-Based Occlusion Method","T. Hidayat; I. A. Astuti","Faculty of Computer Sciences, Amikom University Yogyakarta, Yogyakarta, Indonesia; Faculty of Computer Sciences, Amikom University Yogyakarta, Yogyakarta, Indonesia","2020 3rd International Conference on Computer and Informatics Engineering (IC2IE)","4 Dec 2020","2020","","","382","387","The general concept in marker-based Augmented Reality is to add virtual objects in the real world using markers as object tracking. In its development AR devices can detect 3D real objects as object tracking (3D Object Tracking) so as to allow interaction between virtual objects and real objects. However, the application of AR for general devices such as Android smartphones that do not have depth sensors, virtual objects are added without having depth information from the real world so that virtual content is always displayed in front of or on top of real objects and causes Occlusion problems. Occlusion refers to the problem when real objects that are closer to the user are covered by more distant virtual objects. This research formulates the handling of the Occlusion problem using the Model-Based Occlusion method in which the geometry information of the model from real objects must be known and registered in advance to the system. To maintain the suitability of the model's geometry information with its real object, Tracking is needed. In this case using 3D Object Tracking by utilizing real objects that have been registered in the ModelBased Occlusion. The results of this study are the virtual objects that appear can occupy the correct position in the Augmented Reality application. In this case using 3D Object Tracking by utilizing real objects that have been registered in the ModelBased Occlusion. The results of this study are the virtual objects that appear can occupy the correct position in the Augmented Reality application. In this case using 3D Object Tracking by utilizing real objects that have been registered in the ModelBased Occlusion. The results of this study are the virtual objects that appear can occupy the correct position in the Augmented Reality application.","","978-1-7281-8247-6","10.1109/IC2IE50715.2020.9274565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274565","augmented reality;model-based occlusion;3d object tracking","Target tracking;Three-dimensional displays;Solid modeling;Object tracking;Testing;Augmented reality;Lighting","augmented reality;computer vision;object detection;object tracking;smart phones;stereo image processing","geometry information;virtual content;depth information;Android smartphones;3D real object detection;interactive augmented reality;marker-based augmented reality;model-based occlusion method;distant virtual objects;occlusion problem;3D object tracking","","","","19","IEEE","4 Dec 2020","","","IEEE","IEEE Conferences"
"AGraphAR: A library for the support of graphs in augmented reality interactive games","N. Oliveira; P. Dias Almeida; P. M. Moreira","Departamento de Engenharia Informática, Universidade do Minho, Braga, Portugal; Departamento de Engenharia Informática, Universidade do Minho, Braga, Portugal; IPVC-Instituto Politécnico de Viana do Castelo, Portugal LIACC-Laboratory de Inteligência Artificial e Ciência de Computadores, Universidade do Porto, Portugal","2013 8th Iberian Conference on Information Systems and Technologies (CISTI)","17 Oct 2013","2013","","","1","4","Recent technological developments in web browsers related to the ability to natively capture and process media from local devices and render 3D computer graphics, in particular due to the evolution of HTML5 and its associated APIs, such as WebGL, make it possible to provide virtual augmented reality applications directly from the web environment. In this paper we present a library for the representation and construction of graph based interactive augmented reality games implemented for the web environment. There is a lot of applications, particularly in the context of serious games and in particular those dealing with education, that internally represents information or concepts in a graph-like structure and that could benefit from the appealing look of augmented reality. The herein described library greatly simplifies the development of these applications by encapsulating operations management of the graph and taking care of the main challenges from the aspect of augmented reality. In order to test and validate the library three interactive activities are described.","2166-0727","978-989-98434-0-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6615884","Augmented Reality;Graphs;HTML5;JavaScript;WebGL","Three-dimensional displays;Rendering (computer graphics);Augmented reality;Libraries;Browsers;Visualization;Solid modeling","augmented reality;computer aided instruction;interactive systems;Internet;rendering (computer graphics);serious games (computing)","AGraphAR;Web browsers;local devices;3D computer graphic rendering;HTML5;API;WebGL;virtual augmented reality applications;graph based interactive augmented reality games;graph-like structure;serious games;education;operations management;interactive activities","","","","6","","17 Oct 2013","","","IEEE","IEEE Conferences"
"A task-level pipelined many-SIMD augmented reality processor with congestion-aware network-on-chip scheduler","G. Kim; Seongwook Park; Kyuho Lee; Y. Kim; Injoon Hong; Kyeongryeol Bong; Dongjoo Shin; Sungpill Choi; J. Park; Hoi-Jun Yoo","Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea","2014 IEEE COOL Chips XVII","26 Jun 2014","2014","","","1","3","A 36 Heterogeneous multicore processor is proposed to accelerate recognition-based markerless augmented reality. To enable a real-time operation of the proposed augmented reality, task-level pipelined multicore architecture with DLP/TLP optimized SIMD processing elements is implemented. In addition, the multicore employs a congestion-aware network-on-chip scheduler for 2D-mesh network-on-chip to support massive internal data transaction caused by task-level pipeline. As a result, it achieves 1.22TOPS peak performance and 1.57TOPS/W energy-efficiency, which are 88% and 76% improvement over a state-of-the-art augmented reality processor, for 30fps 720p test input video.","","978-1-4799-3810-0","10.1109/CoolChips.2014.6842959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6842959","heterogeneous multicore;network-on-chip scheduler;2D-mesh NoC;augmented reality;object recognition;dynamic resource management","Augmented reality;Multicore processing;Real-time systems;Network-on-chip;Acceleration;Throughput","augmented reality;energy conservation;image processing;low-power electronics;multiprocessing systems;network-on-chip;object recognition","single instruction multiple data processing elements;SIMD processing elements;task-level pipelined many-SIMD augmented reality processor;congestion-aware network-on-chip scheduler;heterogeneous multicore processor;recognition-based markerless augmented reality;task-level pipelined multicore architecture;data level parallelism;DLP;task level parallelism;TLP;2D-mesh network-on-chip;internal data transaction;energy efficiency;test input video","","","","5","IEEE","26 Jun 2014","","","IEEE","IEEE Conferences"
"Mobile augmented reality system for in-situ 3D modeling and authoring","Han Kyu Yoo; J. W. Lee","Dept. of Digital Contents Sejong University Seoul, Korea; Dept. of Digital Contents Sejong University Seoul, Korea","2014 International Conference on Big Data and Smart Computing (BIGCOMP)","17 Feb 2014","2014","","","282","285","This paper proposes a mobile augmented reality system that can model 3D virtual objects and author augmented reality contents on site. The differences of the proposed system from the existing ones are an interaction approaches used to generate and manipulate primitives and additional features such as a shadow and a multi-freezing mode to create realistic augmented reality contents efficiently.","2375-9356","978-1-4799-3919-0","10.1109/BIGCOMP.2014.6741453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6741453","In-situ authoring;modeling;augmented reality;gesture recognition;interaction","Three-dimensional displays;Augmented reality;Hidden Markov models;Smart phones;Lighting;Solid modeling;Mobile communication","augmented reality;authoring systems;human computer interaction;mobile computing;solid modelling","in-situ 3D modeling;mobile augmented reality system;3D virtual objects;augmented reality content authoring;interaction approaches;primitives;shadow mode;multifreezing mode","","","","10","IEEE","17 Feb 2014","","","IEEE","IEEE Conferences"
"Geometry learning tool for elementary school using augmented reality","J. Purnama; D. Andrew; M. Galinium","Swiss German University, Bumi Serpong Damai, ID; Department of Information Tehcnology, Swiss German University, Tangerang, Indonesia; Department of Information Tehcnology, Swiss German University, Tangerang, Indonesia","2014 International Conference on Industrial Automation, Information and Communications Technology","16 Oct 2014","2014","","","145","148","Augmented Reality is a technology that overlay the virtual objects into the real world. With the capabilities of Augmented Reality in combining virtual and real world object in real time, it can be utilized to help education process for elementary students. There are numerous frameworks to build Augmented Reality based application. OpenCv is a computer library vision that implements various tools for processing images. The purpose of this research is to test whether OpenCv is capable to build Augmented Reality based application or not. With the capabilities of OpenCv in detecting color and registering the virtual object in real time, it supports the Augmented Reality based application creation. The research is done by creating the Augmented Reality Geometry Learning Tool prototype system based on OpenCv to help elementary students learning using protractor. The prototype system then is implemented in the elementary school to obtain the response from the students. The response from the student is satisfying and it proves OpenCv is capable to build Augmented Reality based application.","","978-1-4799-4909-0","10.1109/IAICT.2014.6922112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6922112","Augmented Reality;Mathematics;Geometry Application;OpenCV","Augmented reality;Prototypes;Geometry;Educational institutions;Libraries;Real-time systems","augmented reality;computer aided instruction;geometry;mathematics computing","geometry learning tool;elementary school;virtual objects;real world object;education process;elementary students;OpenCv;computer library vision;color detection;augmented reality based application creation;protractor","","18","","6","IEEE","16 Oct 2014","","","IEEE","IEEE Conferences"
"Application Research of two-dimensional code in mobile augmented reality","M. Zhao; Q. Li","School of computer engineering and Science Shanghai University, Shanghai Dian Ji University, Shanghai, China; School of computer engineering and Science Shanghai University, Shanghai Dian Ji University, Shanghai, China","2019 6th International Conference on Systems and Informatics (ICSAI)","27 Feb 2020","2019","","","845","848","Augmented Reality (AR) is an emerging technology that adds computer-generated virtual information to real-world scenarios, thereby enhancing people's understanding of the surrounding real-world environment. With the development of network, augmented reality technology is gradually applied to mobile devices based on smart phones. Augmented reality technology has been widely used in foreign cultural circles, such as ancient architecture research, Museum exhibitions, enhanced travel and campus navigation. At present, our country's mobile augmented reality technology can only aim at a small number of targets, and can not meet the needs of target recognition and tracking for mobile users. On this basis, two-dimensional code is gradually developed in the mobile augmented reality system. A large number of two-dimensional code content coding technology and fast positioning technology can meet the needs of people. Target recognition requirements. Therefore, this paper expounds the general situation of two-dimensional code and mobile augmented reality technology, studies the application of two- dimensional code in mobile augmented reality, and points out its application in library.","","978-1-7281-5256-1","10.1109/ICSAI48974.2019.9010434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010434","two-dimensional code;mobile augmented reality technology;application research;smart phone;identification","Augmented reality;Mobile handsets;Image coding;Libraries;Cameras;Error correction codes","augmented reality;mobile computing;museums","mobile users;fast positioning technology;mobile augmented reality technology;computer-generated virtual information;mobile devices;ancient architecture research;smart phones;museum exhibitions;two-dimensional code content coding technology;target recognition requirements","","1","","7","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Taiwan Imaginary: Puppet Show in Hand, The Creative Apparatus Using Multimedia Augmented Reality","S. H. Lin","National Taiwan Normal University, Taiwan","2008 International Conference on Computer Science and Software Engineering","22 Dec 2008","2008","6","","349","352","An ""augmented reality"" multimedia project is realized by Su-hui LIN, investigator coming from Taiwan, Docteur en Histoire de lpsilaart de l'Universite Paris-Sorbonne(Paris IV). The goal is to transform the traditional hand puppet show of Taiwan into a new stage. In first phase, contemporary Taiwanese artists will be invited to collaborate with this project. Enabling to present the historical story through out the VR environment, some 3D hand puppet models will be created through VR4MAX software. The audiences are allowed to interact with the digital content by waving their hand or moving their body. 3D, AR (augmented reality) and VR technology are utilized in this project, the investigator hopes to bring up audiencepsilas attention and experiencing traditional folk art in a new way. Finally, this project will be presented by projecting the content onto the inner or outer wall of one Taiwan historical building. Under the augmented reality system, the traditional folk art of Taiwan will be illustrated in a more interesting way. This kind of demonstration will give Taiwanese audience some new thought, not only skinning in the dream of being ""the computer kingdom"" but also cherishing the root of the culture of Taiwan.","","978-0-7695-3336-0","10.1109/CSSE.2008.558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4723269","Taiwan image;multimedia;augmented reality;hand puppet show","Augmented reality;Art;Virtual reality;Cultural differences;Computer science;Software engineering;Computer graphics;Collaboration;TV;Concrete","augmented reality;humanities;multimedia computing;solid modelling","Taiwan imaginary;hand puppet show;creative apparatus;multimedia augmented reality;virtual reality environment;3D hand puppet model;VR4MAX software;audience interaction","","","","10","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"A review of Augmented Reality and its application in context aware library system","A. Mahadik; Y. Katta; R. Naik; N. Naikwade; N. F. Shaikh","Computer Engineering, MES College of Engineering, Pune, Maharashtra, India; Computer Engineering, MES College of Engineering, Pune, Maharashtra, India; Computer Engineering, MES College of Engineering, Pune, Maharashtra, India; Computer Engineering, MES College of Engineering, Pune, Maharashtra, India; Computer Engineering, MES College of Engineering, Pune, Maharashtra, India","2016 International Conference on ICT in Business Industry & Government (ICTBIG)","6 Apr 2017","2016","","","1","6","Augmented Reality has revolutionized the way of looking at actuality. The colossal developments in this area have led to visualizations beyond desktop. Unreal objects can be augmented on real surfaces. Augmented Reality has converged the knowledge of computer vision, virtual reality, image-processing, human-to-computer interaction and more such areas. It has found applications in various expanses like Games, Entertainment, Military, Navigation and many more. One such application could be in Library Management System. Earlier systems for book tracking involved immobile computers that only had the shelf numbers nested with book id to locate a book. A borrower needed to ask the Librarian/support staff to look up the shelf number from the system so as to find a book or simply do it manually by himself by searching each shelf. The application of Augmented Reality in Library Administration is useful in automating the proximity location tracking of a book and providing alternatives to the borrower in the books context. The borrower is navigated through the library till he/she reaches the shelf where the book is kept. The spine of the book serves as the index of the required book and contextual information is augmented once the book is located. Thus Augmented Reality can prove immensely helpful for Library Administration.","","978-1-5090-5515-9","10.1109/ICTBIG.2016.7892686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892686","Mobile Augmented Reality;Marker Based Tracking;Natural Feature Tracking;Context Awareness;SaaS Framework","Augmented reality;Libraries;Feature extraction;Databases;Training;Context-aware services","augmented reality;data visualisation;library automation","augmented reality;context aware library system;visualizations;computer vision;virtual reality;image processing;human-to-computer interaction;library management system;immobile computers;support staff;library administration;proximity location tracking;books context;borrower;contextual information","","5","","23","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"The study and improvement of Augmented reality based on feature matching","Ruobing Yang","Media School, Linyi University, Linyi, China","2011 IEEE 2nd International Conference on Software Engineering and Service Science","11 Aug 2011","2011","","","586","589","Augmented reality is an emerging technology of Virtual Reality, which has a great development and application prospects. Augmented Reality involves knowledge about sensors, image recognition, computer vision, human-computer interaction, virtual reality, and many other areas. The key technologies include displaying, registration and tracking, interactive etc. Among them, registration and tracking is the most important technology. In Augmented reality system, the traditional methods of registration and tracking technology has the problems of not accurate, low efficient. In this paper, improved feature matching algorithm is used in augmented reality system. Experimental results show that, compared with traditional methods, improved algorithm can significantly improve the efficiency of registration and tracking.","2327-0594","978-1-4244-9698-3","10.1109/ICSESS.2011.5982388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5982388","Augmented Reality;Feature matching;registration;ARToolKit","Augmented reality;Cameras;Solid modeling;Algorithm design and analysis;Computer vision;Analytical models","augmented reality","augmented reality system;feature matching algorithm;virtual reality;registration technology;tracking technology","","4","","10","IEEE","11 Aug 2011","","","IEEE","IEEE Conferences"
"Local Shape Preserving Deformations for Augmented Reality Assisted Laparoscopic Surgery","A. Łach; F. Kalim; C. Heiliger; N. Piaseczna; M. Grimm; A. Winkler; O. Solyanik; H. Kirr; L. Hiendl; U. Eck; R. Doniec; N. Navab; K. Karcz; S. Mandal","Department of Biosensors and Processing of Biomedical Signals, Faculty of Biomedical Engineering, Silesian University of Technology (SUOT), Zabrze, Poland; Maxer Endoscopy GmbH, Wurmlingen, Germany; Clinic for General, Visceral and Transplant Surgery, Ludwig-Maximilians-University (LMU), Munich, Germany; Department of Biosensors and Processing of Biomedical Signals, Faculty of Biomedical Engineering, Silesian University of Technology (SUOT), Zabrze, Poland; Chair for Computer Aided Medical Procedures & Augmented Reality (CAMP), Technical University of Munich (TUM), Munich, Germany; Chair for Computer Aided Medical Procedures & Augmented Reality (CAMP), Technical University of Munich (TUM), Munich, Germany; Department of Radiology, University Hospital, LMU Munich, Munich, Germany; Clinic for General, Visceral and Transplant Surgery, Ludwig-Maximilians-University (LMU), Munich, Germany; Clinic for General, Visceral and Transplant Surgery, Ludwig-Maximilians-University (LMU), Munich, Germany; Chair for Computer Aided Medical Procedures & Augmented Reality (CAMP), Technical University of Munich (TUM), Munich, Germany; Department of Biosensors and Processing of Biomedical Signals, Faculty of Biomedical Engineering, Silesian University of Technology (SUOT), Zabrze, Poland; Chair for Computer Aided Medical Procedures & Augmented Reality (CAMP), Technical University of Munich (TUM), Munich, Germany; Clinic for General, Visceral and Transplant Surgery, Ludwig-Maximilians-University (LMU), Munich, Germany; Maxer Endoscopy GmbH, Wurmlingen, Germany","2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","8 Sep 2022","2022","","","562","565","Image registration is a commonly required task in computer assisted surgical procedures. Existing registration methods in laparoscopic navigation systems suffer from several constraints, such as lack of deformation compensation. The proposed algorithm aims to provide the surgeons with updated navigational information about the deep-seated anatomy, which considers the continuous deformations in the operating environment. We extended an initial rigid registration to a shape-preserving deformable registration pathway by incorporating user interaction and an iterative mesh editing scheme which preserves local details. The proposed deformable registration workflow was tested with phantom and animal trial datasets. A qualitative evaluation based on expert feedback demonstrated satisfactory outcome, and an commensurate execution efficiency was achieved. The improvements offered by the method, couples with its relatively easy implementation, makes it an attractive method for adoption in future pre-clinical and clinical applications of augmented reality assisted surgeries.","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871029","BMBF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871029","","Laparoscopes;Visualization;Uncertainty;Shape;Surgery;Anatomical structure;Reliability","augmented reality;image registration;medical computing;medical image processing;medical robotics;surgery","animal trial datasets;attractive method;augmented reality assisted surgeries;local shape preserving deformations;augmented reality assisted laparoscopic surgery;image registration;commonly required task;computer assisted surgical procedures;registration methods;laparoscopic navigation systems;deformation compensation;updated navigational information;deep-seated anatomy;continuous deformations;initial rigid registration;shape-preserving deformable registration pathway;iterative mesh editing scheme;local details;deformable registration workflow;phantom","Algorithms;Animals;Augmented Reality;Humans;Laparoscopy;Surgeons;Surgery, Computer-Assisted","","","12","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Augmented Reality as a Tool to Guide Patient-Specific Templates Placement in Pelvic Resections","A. R. Mendicino; S. Condino; M. Carbone; F. Cutolo; N. Cattari; L. Andreani; P. D. Parchi; R. Capanna; V. Ferrari","Department of Information Engineering, EndoCAS Center for Computer Assisted Surgery, University of Pisa, Pisa (PI), ITALY; Department of Information Engineering, EndoCAS Center for Computer Assisted Surgery, University of Pisa, Pisa (PI), ITALY; Department of Information Engineering, EndoCAS Center for Computer Assisted Surgery, University of Pisa, Pisa (PI), ITALY; Department of Information Engineering, EndoCAS Center for Computer Assisted Surgery, University of Pisa, Pisa (PI), ITALY; Department of Information Engineering, EndoCAS Center for Computer Assisted Surgery, University of Pisa, Pisa (PI), ITALY; Orthopedics and Traumatology I Department, University of Pisa, Pisa, Italy; Orthopedics and Traumatology I Department, University of Pisa, Pisa, Italy; Orthopedics and Traumatology I Department, University of Pisa, Pisa, Italy; Department of Information Engineering, EndoCAS Center for Computer Assisted Surgery, University of Pisa, Pisa (PI), ITALY","2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","8 Sep 2022","2022","","","3481","3484","Patient-specific templates (PST) have become a useful tool for guiding osteotomy in complex surgical scenarios such as pelvic resections. The design of the surgical template results in sharper, less jagged resection margins than freehand cuts. However, their correct placement can become difficult in some anatomical regions and cannot be verified during surgery. Conventionally, pelvic resections are performed using Computer Assisted Surgery (CAS), and in recent years Augmented Reality (AR) has been proposed in the literature as an additional tool to support PST placement. This work presents an AR task to simplify and improve the accuracy of the positioning of the template by displaying virtual content. The focus of the work is the creation of the virtual guides displayed during the AR task. The system was validated on a patient-specific phantom designed to provide a realistic setup. Encouraging results have been achieved. The use of the AR simplifies the surgical task and optimizes the correct positioning of the cutting template: an average error of 2.19 mm has been obtained, lower than obtained with state-of-the-art solutions. In addition, supporting PST placement through AR guidance is less time-consuming than the standard procedure that solely relies on anatomical landmarks as reference.","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871766","","Surgery;Phantoms;Biology;Task analysis;Augmented reality;Standards","augmented reality;bone;computerised tomography;medical image processing;phantoms;surgery","pelvic resections;complex surgical scenarios;surgical template;computer assisted surgery;augmented reality;virtual guides;patient-specific phantom;cutting template;patient-specific templates placement;osteotomy;anatomical landmarks","Augmented Reality;Humans;Margins of Excision;Osteotomy;Phantoms, Imaging;Surgery, Computer-Assisted","","","10","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Effect of Full Body Avatar in Augmented Reality Remote Collaboration","T. -Y. Wang; Y. Sato; M. Otsuki; H. Kuzuoka; Y. Suzuki","University of Tsukuba; University of Tsukuba; University of Tsukuba; OKI Electric Industry Co., Ltd; University of Tsukuba","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1221","1222","In this paper, we compared three different types of avatar design (“Body”, “Hand + Arm”, and “Hand only”) for the augmented reality remote instruction system in terms of usability. The result showed that the usability of the remote instruction system with full body avatar has a higher usability. In addition, participants felt more easily to track the full body avatar than the avatar with hand only. However, concerning the understandability of the instruction, there was no difference between three designs.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798044","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality","Avatars;Usability;Task analysis;Collaboration;Augmented reality;Resists","augmented reality;avatars;groupware","full body avatar;augmented reality remote collaboration;augmented reality remote instruction system","","9","","8","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"MR-FoodCoach: Enabling a convenience store on mixed reality space for healthier purchases","J. Ahn; H. Gaza; J. Oh; K. Fuchs; J. Wu; S. Mayer; J. Byun","Department of Software, Sejong University; Department of Software, Sejong University; Department of Software, Sejong University; Institute of Computer Science, University of St. Gallen; Institute of Computer Science, University of St. Gallen; Institute of Computer Science, University of St. Gallen; Department of Software, Sejong University","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","891","892","We study ways to improve the shopping experience in a mixed-reality environment. In the demonstration, the participants would experience the concept of mixed-reality-enabled convenience stores for healthier purchases. Over Microsoft HoloLens2, anywhere can become a convenience store where physical and virtual foods can be recognized and deployed. The prototype would help customers with healthier purchases. For each product, its nutrition facts and even an intuitive metric, NutriScore, are available for customers. Furthermore, the visualization of its footsteps in supply chains over the globe would guarantee transparency of its origin. GS1 EPCIS standard and temporal reachability computation enable the demonstration.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00191","National Research Foundation of Korea; MSIP(grant numbers:NRF-2019K1A3A1A14012376/SNF-188402,NRF-2020R1F1A1066555); IITP; MSIP(grant numbers:2022-0-00407); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974511","Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Mixed / augmented reality;Applied computing-Life and medical sciences-Consumer health-Information systems-Information systems applications-Spatial-temporal systems","Measurement;Visualization;Supply chains;Prototypes;Mixed reality;Standards;Augmented reality","augmented reality;customer services;food products;production engineering computing;purchasing;reachability analysis;standards;supply chains","customers service;GS1 EPCIS standard;healthier purchases;Microsoft HoloLens2;mixed-reality-enabled convenience stores;nutriscore;physical foods;reachability computation;shopping experience;supply chains;virtual foods","","","","7","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"The learning approaches using Augmented Reality in learning environments: Meta-Analysis","N. Tuli; A. Mantri; S. Sharma; G. Singh; S. Gargrish; B. Sharma","Chitkara University Institute of Engineering and Technology, Chitkara University, India; Chitkara University Institute of Engineering and Technology, Chitkara University, India; Chitkara University Institute of Engineering and Technology, Chitkara University, India; Chitkara University Institute of Engineering and Technology, Chitkara University, India; Chitkara University Institute of Engineering and Technology, Chitkara University, India; Chitkara University Institute of Engineering and Technology, Chitkara University, India","2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)","20 Apr 2021","2021","","","871","875","With the emergence of Industrial Revolution 4.0, the educational settings are changing quickly. Augmented Reality (AR) is one of the upcoming technologies. AR enhances the real world by overlaying/augmenting the virtual/digital information over it. It provides the user with the ability to interact with the created virtual world in real space. The aim of this study is to classify the learning approaches implemented through AR technology. The technique used for the analysis is derived from systematic search of online literature databases like Taylor Francis, Web of Science, Springer, ScienceDirect and Scopus. The keywords used for the search include learning approaches, AR, AR in education, AR in learning and teaching and integration approaches. The findings of this research work highlights 4 categories of educational learning approaches that highlight AR. The approaches are experimental learning, game-based, interactive and collaborative learning. The research findings can be referred by other researchers and educators to identify the potential of AR in education and the learning approaches currently used with AR for their further research on how these approaches can be effectively and efficiently implemented in educational settings.","","978-1-7281-7741-0","10.1109/ICACITE51222.2021.9404738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9404738","Augmented Reality;leaching and learning approaches;education;integration approaches","Systematics;Databases;Education;Collaborative work;Augmented reality","augmented reality;computer aided instruction;groupware;learning (artificial intelligence);teaching;virtual reality","educational settings;augmented Reality;learning environments;Industrial Revolution 4;Augmented Reality;created virtual world;teaching integration approaches;educational learning approaches;experimental learning","","1","","37","IEEE","20 Apr 2021","","","IEEE","IEEE Conferences"
"Evaluation of the virtual mirror as a navigational aid for augmented reality driven minimally invasive procedures","C. Bichlmeier; E. Euler; T. Blum; N. Navab","Computer Aided Medical Procedures & Augmented Reality (CAMP), TUM, Munich, Germany; Trauma Surgery Department, Klinikum Innenstadt LMU, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality, TUM, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality, TUM, Munich, Germany","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","91","97","The paper presents a user study investigating perceptual effects of a virtual mirror being used as a tangible interactive tool in a medical Augmented Reality scenario. In particular, we evaluated whether an additional perspective provided by the virtual mirror supports instrument guidance in terms of precision and straightness. 31 participants were asked to navigate an endoscopic instrument in a simulated minimally invasive port setting. Results show a significant higher precision of instrument guidance when a virtual mirror provides additional views of the target region.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643555","","Mirrors;Target tracking;Instruments;Navigation;Surgery;Cameras;Biomedical imaging","augmented reality","virtual mirror;navigational aid;augmented reality;tangible interactive tool;instrument guidance;endoscopic instrument","","8","","22","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Visualising the Invisible: Augmented Reality and Virtual Reality as Persuasive Technologies for Energy Feedback","A. D. Fredericks; Z. Fan; S. I. Woolley","School of Computing and Mathematics, Keele University, Keele, United Kingdom; School of Computing and Mathematics, Keele University, Keele, United Kingdom; School of Computing and Mathematics, Keele University, Keele, UK","2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","9 Apr 2020","2019","","","1209","1212","In the last fifteen years, the outlook for engaging direct energy feedback as a method of effectively curtailing domestic energy consumption has grown more pessimistic. Continuing studies and reviews suggest the impact of such techniques on consumers is much less than the minimum ten percent reduction originally hoped. Persuasive technology research has demonstrated multiple successes in promoting resource conserving behaviours however, including in energy consumption related topics. One of the main obstacles with energy feedback is that making use of electricity is an 'invisible' process and doesn't produce any visible feedback to the consumer. This paper suggests harnessing Augmented Reality and Virtual Reality as persuasive technologies to visualise the 'invisible' consumption of domestic activities and promote energy conserving behaviours. A literature section provides short reviews of relevant topics, providing the justification and motivation for conducting this research while an overview of a methodology focusing on a user-centered approach discusses how to incorporate effective consumer feedback into the development process of appropriate energy feedback visualisations. Initial implementation methods for the visualisations are discussed and future work building upon this paper is outlined.","","978-1-7281-4034-6","10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9060080","Energy Feedback, Augmented and Virtual Reality, Persuasive Technology, Smart Meter, In-Home Display","Visualization;Energy consumption;Data visualization;Smart meters;Augmented reality;User centered design","augmented reality;data visualisation;energy conservation;energy consumption;environmental factors;mobile computing;user interfaces","visible feedback;augmented reality;virtual reality;persuasive technologies;invisible consumption;domestic activities;energy conserving;appropriate energy feedback visualisations;direct energy feedback;domestic energy consumption;minimum ten percent reduction;persuasive technology research;resource conserving;energy consumption related topics;effective consumer feedback;invisible process","","1","","27","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"An Augmented Reality exhibition guide for the iPhone","Mohamed Ashraf Nassar; F. Meawad","German University in Cairo, Egypt; German University in Cairo, Egypt","2010 International Conference on User Science and Engineering (i-USEr)","22 Feb 2011","2010","","","157","162","Handheld Augmented Reality (AR) can enable intuitive browsing and annotation of objects in an exhibition through the visitors' in-hand mobile devices. Several researchers explored Handheld AR technologies in museums and exhibition-like environments. However, despite the proliferation of smart phones that can act as magic lenses for augmented objects, AR technologies are not widely adopted in exhibitions. This paper investigates the possible techniques to build a reliable, scalable and cost effective solution for an indoor marker based exhibition guide on the iPhone. After reviewing possible tracking technologies, available open source marker based tracking toolkits on the iPhone are explored. The paper concludes with a proposed design for dynamic content creation to augment and annotate exhibition objects.","","978-1-4244-9049-3","10.1109/IUSER.2010.5716742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716742","component;augmented reality;marker;tracking","Mobile handsets;Augmented reality;Mobile communication;Usability;Prototypes;Servers;Robustness","augmented reality;exhibitions;mobile computing;mobile handsets;museums;public domain software","augmented reality exhibition guide;iPhone;handheld augmented reality;intuitive browsing;object annotation;in-hand mobile device;museum;smart phone;augmented object;indoor marker;tracking technology;open source marker based tracking toolkit;dynamic content creation","","4","","19","IEEE","22 Feb 2011","","","IEEE","IEEE Conferences"
"Expanding Space with Augmented Reality","L. P. Kozlova; O. A. Kozlova","Faculty of Industrial Automation and Electrical Engineering, Saint Petersburg Electrotechnical University ""LETI"", Saint Petersburg, Russia; Faculty of Information Systems and Technologies, The Bonch-Bruevich St. Petersburg State University of Communication, Saint Petersburg, Russia","2021 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus)","9 Apr 2021","2021","","","965","967","Replacing real life with the virtual space has long ceased to be a theory. Among the whole variety of visualization, systems that allow projecting non-existent objects into real-world space are especially distinguished. Thus, augmented reality technology has found its application in many different fields. The article discusses the general concepts and principles of building augmented reality systems.","2376-6565","978-1-6654-0476-1","10.1109/ElConRus51938.2021.9396699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396699","augmented reality;virtual reality;image recognition;marker recognition","Visualization;Mixed reality;Software;Hardware;Character recognition;Cultural differences;Augmented reality","augmented reality;data visualisation","virtual space;augmented reality;visualization","","1","","2","IEEE","9 Apr 2021","","","IEEE","IEEE Conferences"
"Machine learning schemes in augmented reality for features detection","G. Dandachi; A. Assoum; B. Elhassan; F. Dornaika","Doctoral School for science and technology, Lebanese University, Tripoli, Lebanon; Faculty of sciences, Lebanese University, Tripoli, Lebaenon; Doctoral School for science and technology, Lebanese University, Tripoli, Lebanon; University of the Basque country, UPV/EHV, San Sebastian, Spain","2015 Fifth International Conference on Digital Information and Communication Technology and its Applications (DICTAP)","1 Jun 2015","2015","","","101","105","Augmented Reality (AR) is a relatively old concept technology, which reached the large public very recently. We can use it to enhance our environments, by augmenting the image, the voice and delivering details and annotations about the surrounding space. Augmented reality (AR) is a growing field, with many diverse applications ranging from TV and film production, to industrial maintenance, medicine, education, entertainment and games. This paper presents an improved approach for image augmented-reality, by acting on two axes in the augmented reality process. First, a machine learning step is added to the detection part. Second, the registration of augmented image is processed by using the following techniques: statistical appearance models, and covariance matrices of dense image descriptors. A tuning of the used techniques and algorithms will be done in order to obtain a reliable and real-time image augmentation. We give a detailed description on how we chose the methods, and we compare our approach with other methods used in this domain. Finally, an evaluation of the proposed technique is presented as well as a performance study for a given use case.","","978-1-4799-4129-2","10.1109/DICTAP.2015.7113179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113179","Augmented reality;image processing;machine learning;features extraction and detection;image registration;graph search","Feature extraction;Image registration;Augmented reality;Support vector machines;Computer vision;Classification algorithms;Covariance matrices","augmented reality;covariance matrices;image segmentation;learning (artificial intelligence);statistical analysis","machine learning schemes;feature detection;AR;augmented reality process;augmented image segmentation;statistical appearance models;covariance matrices;dense image descriptors;real-time image augmentation","","8","","22","IEEE","1 Jun 2015","","","IEEE","IEEE Conferences"
"Augmented and Virtual Reality based approaches in Minimally Invasive Surgery training","M. A. Rahman; P. Mahmud; M. S. Mashuk","Computer Science Department, University of Nottingham, Nottingham, UK; EECS Department, North South University, Dhaka, Bangladesh; EECS Department, North South University, Dhaka, Bangladesh","2013 International Conference on Informatics, Electronics and Vision (ICIEV)","1 Aug 2013","2013","","","1","4","Continuing development in surgical techniques has elevated the level of sophistication in surgery. In order to reduce trauma to healthy tissue of the patient body, scientists are continuously trying different technologies in surgery. Minimally Invasive Surgery is one of this new practices adopted by the surgeons, which allows doctors to operate on patient with minimal damage and this reduces the post-operative pain of the patient and prolonged hospital stay. The biggest drawback of this operation technique is its complexity. Due to this reason it takes a lot of practice and training for a surgeon to master this process before operating. Augmented Reality and Virtual Reality simulation systems offer different solutions to this problem. In this short communication, recent advances in surgery simulation systems and how they are performing in teaching these techniques are discussed. In addition to it, a comparative study on contemporary augmented reality and virtual reality simulation systems in learning surgery has been also presented.","","978-1-4799-0400-6","10.1109/ICIEV.2013.6572714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6572714","MIS;Training;Augmented Reality;Virtual Reality;Haptic Feedback;Tactile Realism","Solid modeling;Training;Augmented reality;Minimally invasive surgery;Haptic interfaces","augmented reality;biomedical communication;biomedical education;computer based training;hospitals;surgery","augmented reality-based simulation approach;virtual reality-based simulation approach;minimally-invasive surgery training;surgical techniques;trauma reduction;healthy tissue;patient body;patient postoperative pain reduction;prolonged-hospital stay reduction;surgery simulation systems;surgery learning","","3","","20","IEEE","1 Aug 2013","","","IEEE","IEEE Conferences"
"Augmented Reality Games for Upper-Limb Stroke Rehabilitation","J. W. Burke; M. D. J. McNeill; D. K. Charles; P. J. Morrow; J. H. Crosbie; S. M. McDonough","School of Computing and Information Engineering, University of Ulster, Coleraine, UK; School of Computing and Information Engineering, University of Ulster, Coleraine, UK; School of Computing and Information Engineering, University of Ulster, Coleraine, UK; School of Computing and Information Engineering, University of Ulster, Coleraine, UK; School of Health Sciences, University of Ulster, Jordanstown, UK; School of Health Sciences, University of Ulster, Jordanstown, UK","2010 Second International Conference on Games and Virtual Worlds for Serious Applications","6 May 2010","2010","","","75","78","Stroke is the number one cause of severe physical disability in the UK. Recent studies have shown that technologies such as virtual reality and imaging can provide an engaging and motivating tool for physical rehabilitation. In this paper we summarize previous work in our group using virtual reality technology and webcam-based games. We then present early work we are conducting in experimenting with desktop augmented reality (AR) for rehabilitation. AR allows the user to use real objects to interact with computer-generated environments. Markers attached to the real objects enable the system (via a webcam) to track the position and orientation of each object as it is moved. The system can then augment the captured image of the real environment with computer-generated graphics to present a variety of game or task-driven scenarios to the user. We discuss the development of rehabilitation prototypes using available AR libraries and express our thoughts on the potential of AR technology.","","978-1-4244-6332-9","10.1109/VS-GAMES.2010.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5460103","serious games;rehabilitation;stroke;augmented reality;video-capture","Augmented reality;Games;Virtual reality;Medical treatment;Feedback;Physics computing;Computer graphics;Prototypes;Libraries;Motion detection","augmented reality;computer games;medical computing;patient rehabilitation","augmented reality games;upper-limb stroke rehabilitation;virtual reality;Webcam-based games;computer-generated environments","","55","1","14","IEEE","6 May 2010","","","IEEE","IEEE Conferences"
"Concept and architecture for programming industrial robots using augmented reality with mobile devices like microsoft HoloLens","J. Guhl; S. Tung; J. Kruger","Department of Industrial Automation Technology, Technische Universität, Berlin, Germany; Technische Universitat Berlin, Berlin, Berlin, DE; Department of Industrial Automation Technology, Technische Universität, Berlin, Germany","2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)","8 Jan 2018","2017","","","1","4","This paper proposes a concept for human-robot interaction using techniques of virtual and augmented reality on mobile devices like cell phones and tablets or mixed reality devices like the HoloLens. By combining data received from real robots together with the perception and abilities of a human operator innovative applications are imaginable. Visualizing not only the current robot state but also the robots environment captured with different sensors and processed with both machine and human vision can lead to a rising percentage of robot assisted workplaces or robot installations. Since the visualization of and the interaction with the robotic application is not locally restricted new or improved use cases like remote maintenance or faster startup of industrial robots can be realized. Therefore, an architecture split into three functional units and an overview of our implementation is presented.","1946-0759","978-1-5090-6505-9","10.1109/ETFA.2017.8247749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8247749","Human-robot interaction;Robot programming;Augmented reality;Virtual reality;Mobile Devices;HoloLens","Service robots;Mobile handsets;Robot sensing systems;Human-robot interaction;Computer architecture;Augmented reality","augmented reality;human-robot interaction;industrial robots;mobile robots;robot programming","architecture split;augmented reality;mobile devices;human-robot interaction;cell phones;mixed reality devices;human vision;robot assisted workplaces;robot installations;Microsoft HoloLens;machine vision;industrial robot programming;virtual reality","","37","","12","IEEE","8 Jan 2018","","","IEEE","IEEE Conferences"
"A novel campus navigation APP with augmented reality and deep learning","C. -H. Lin; Y. Chung; B. -Y. Chou; H. -Y. Chen; C. -Y. Tsai","Department of Electrical Engineering, National Taiwan Normal University, Taipei, Taiwan, R.O.C; Department of Electrical Engineering, National Taiwan Normal University, Taipei, Taiwan, R.O.C; Department of Electrical Engineering, National Taiwan Normal University, Taipei, Taiwan, R.O.C; Department of Electrical Engineering, National Taiwan Normal University, Taipei, Taiwan, R.O.C; Department of Electrical Engineering, National Taiwan Normal University, Taipei, Taiwan, R.O.C","2018 IEEE International Conference on Applied System Invention (ICASI)","25 Jun 2018","2018","","","1075","1077","Augmented reality has been widely used in many applications because of its ability to offer an amazing way to overlay computer-generated images over the user's real-world view, creating a composite view rooted in real and virtual worlds. Augmented Reality is a realistic, direct or indirect view of the physical reality environment whose elements are “enhanced” through computer-generated or sensory input such as sound, video, graphics, tactile, or GPS data. In this paper, we present a novel campus navigation APP that uses augmented reality to provide users with a new and interesting way to meet our campus. With advanced augmented reality technologies such as computer vision and object recognition, the information about the campus environment and its objects is overlaid on the real world and becomes interactive. In order to improve the APP efficiency, this paper presents a virtual terrain modeling interface with deep learning to improve the object recognition ability.","","978-1-5386-4342-6","10.1109/ICASI.2018.8394464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8394464","augmented reality;deep learning;computer vision;computer vision","Augmented reality;Solid modeling;Databases;Three-dimensional displays;Global Positioning System;Feature extraction;Engines","augmented reality;computer graphics;educational institutions;educational technology;learning (artificial intelligence);mobile computing;object recognition","deep learning;novel campus navigation APP;real-world view;realistic view;direct view;indirect view;advanced augmented reality technologies;GPS data;virtual terrain modeling interface;object recognition ability;physical reality environment","","13","","4","IEEE","25 Jun 2018","","","IEEE","IEEE Conferences"
"Game-Based Evacuation Drills Using Simple Augmented Reality","H. Mitsuhara; M. Shishibori; J. Kawai; K. Iguchi","Graduate School of Science and Technology, Tokushima University, Tokushima, Japan; Graduate School of Science and Technology, Tokushima University, Tokushima, Japan; Graduate School of Advanced Technology and Science, Tokushima University, Tokushima, Japan; Graduate School of Advanced Technology and Science, Tokushima University, Tokushima, Japan","2016 IEEE 16th International Conference on Advanced Learning Technologies (ICALT)","1 Dec 2016","2016","","","133","137","Since conventional evacuation drills do not adequately simulate disaster situations, participants do not feel a sense of tension during evacuation. We developed a game-based evacuation drill (GBED) system that focuses on situational and audio-visual realities and scenario-based interactivity. To improve the visual reality in a GBED, we adopt simple augmented reality (AR) and a binocular opaque head-mounted display (HMD). The simple AR represents vague extensive disaster situations (i.e., rain, fog, smoke and fire) by superimposing the overall disaster situations (dynamic three-dimensional computer graphics) onto the real-time vision captured by a stereo camera (attached to the HMD).","2161-377X","978-1-4673-9041-5","10.1109/ICALT.2016.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7756942","Augmented reality;head-mounted display;evacuation drills;disaster situations;disaster education;game-based learning","Visualization;Games;Real-time systems;Fires;Rain;Augmented reality;Resists","augmented reality;computer aided instruction;computer games;computer graphics;disasters;emergency management;helmet mounted displays;real-time systems","game-based evacuation drill;GBED system;situational realities;audio-visual realities;scenario-based interactivity;visual reality;augmented reality;binocular opaque head-mounted display;HMD;disaster situations;dynamic three-dimensional computer graphics;real-time vision;stereo camera;disaster education;game-based learning","","8","","22","IEEE","1 Dec 2016","","","IEEE","IEEE Conferences"
"CADET: A Collaborative Agile Data Exploration Tool for Mixed Reality","J. McDade; A. Drogemuller; A. Jing; N. Ireland; J. Walsh; B. Thomas; W. Mayer; A. Cunningham",University of South Australia; University of South Australia; University of South Australia; University of South Australia; University of South Australia; University of South Australia; University of South Australia; University of South Australia,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","899","900","The need to understand and communicate the nuances of complex situational information is an ever-present requirement in Command and Control (C2). It is often difficult for remote users of a system to clearly understand what a user is trying to relay. Mixed Reality (MR) technology presents a significant opportunity for exploring and communicating C2 data. In this paper, we present our system, CADET, as step towards enriching the collaborative C2 user ex-perience by allowing users to remotely and locally perform adhoc analysis through information displays created by hand interactions and speech in MR.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974227","Human-centered computing- Visualization-Visualization application domains-Information visualization;Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Mixed / augmented reality","Command and control systems;Mixed reality;Data visualization;Collaboration;Relays;Augmented reality","augmented reality;command and control systems;groupware;user experience;user interfaces","adhoc analysis;CADET;collaborative agile data exploration tool;collaborative C2 user experience;command and control;complex situational information;hand interactions;information displays;mixed reality technology;remote users;significant opportunity","","","","5","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Benchmarking Network Performance of Augmented Reality Based Surgical Telementoring Systems","D. Shabir; M. Anbatawi; N. Abdurahiman; M. Trinh; J. Padhan; A. Al-Ansari; J. Abinahed; Z. Deng; E. Yaacoub; A. Mohammed; N. V. Navkar","Department of Surgery, Hamad General Hospital, Hamad Medical Corporation, Doha, Qatar; Department of Surgery, Hamad General Hospital, Hamad Medical Corporation, Doha, Qatar; Department of Surgery, Hamad General Hospital, Hamad Medical Corporation, Doha, Qatar; Department of Computer Science, University of Houston, Houston, TX, USA; Department of Surgery, Hamad General Hospital, Hamad Medical Corporation, Doha, Qatar; Department of Surgery, Hamad General Hospital, Hamad Medical Corporation, Doha, Qatar; Department of Surgery, Hamad General Hospital, Hamad Medical Corporation, Doha, Qatar; Department of Computer Science, University of Houston, Houston, TX, USA; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Surgery, Hamad Medical Corporation, Doha, Qatar","2022 IEEE 22nd International Conference on Bioinformatics and Bioengineering (BIBE)","14 Dec 2022","2022","","","261","264","Telementoring in surgery facilitates the transfer of surgical knowledge from the mentor to the mentee. Augmented Reality (AR) further assists this transfer by overlaying visual cues (e.g., in the form of virtual surgical instrument motion) generated by the mentor onto the operative field of the mentee. In this work, we present a benchmark for comparing such AR based surgical telementoring systems. The results compare the network performances of these systems across different types of surgery (open or minimally invasive), based on the locations of the mentor and the mentee (inter- or intra- country), and finally the underlying networking protocols (RTMP versus WebRTC).","2471-7819","978-1-6654-8487-9","10.1109/BIBE55377.2022.00061","Qatar National Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9973705","Minimally Invasive Surgery;Open Surgery;Telementoring;Network Communication;Augmented Reality (AR)","Visualization;Protocols;Minimally invasive surgery;Instruments;Benchmark testing;Bioinformatics;Augmented reality","augmented reality;medical computing;medical robotics;surgery;telemedicine;virtual reality","augmented Reality;Augmented Reality;benchmarking network performance;mentee;mentor;network performances;surgery;surgical knowledge;surgical telementoring systems;underlying networking protocols;virtual surgical instrument motion;visual cues","","","","29","IEEE","14 Dec 2022","","","IEEE","IEEE Conferences"
"Approach augmented reality real-time rendering for understanding light and shade in art education","A. Nanthanasit; N. Wongta","Department of Arts, Chiang Mai Rajabhat University, Chiang Mai, Thailand; College of Arts, Media and Technology Chiang Mai University, Chiang Mai, Thailand","2018 International Conference on Digital Arts, Media and Technology (ICDAMT)","11 Jun 2018","2018","","","71","74","This paper propose is approached the integration of Augmented Reality (AR) system and Real-time rendering to enhance the process of Art education, that create the new learning experience and better quality of teaching. According to the subject about light and shade, which every art student must learn. By understanding how light operates on the fundamental volumes of the shape such as sphere, cylinder, and cube. The student will be able to realistically shade and render basic forms and be prepared to draw more complex subjects. However, the teaching process is through illustrated books, which hard for the student who did not have an experience in Light and Shade to clearly understand the method. Augmented reality technology is able to support the effective way to describe how light and shade work. By showing the shape in three-dimension with light and shade. From real-time rendering technique, the light source can move around to cast the different appearance of light and shade. It is simple to use and understand for student. Furthermore, Augmented reality enhanced interesting way to study in the way that computer screen cannot deliver.","","978-1-5386-0573-8","10.1109/ICDAMT.2018.8376498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8376498","Augmented Reality;Real-time Rendering;Light and Shade;Art Education","Education;Art;Light sources;Augmented reality;Rendering (computer graphics);Media;Cameras","art;augmented reality;computer aided instruction;rendering (computer graphics);teaching;virtual reality","art education;art student;light shade work;real-time rendering technique;light source;augmented reality real-time rendering;AR system;teaching process","","3","","9","IEEE","11 Jun 2018","","","IEEE","IEEE Conferences"
"A Mixed Reality Guidance System for Blind and Visually Impaired People","H. Schieber; C. Kleinbeck; C. Pradel; L. Theelke; D. Roth","Human-Centered Computing and Extended Reality, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany; Human-Centered Computing and Extended Reality, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany; Human-Centered Computing and Extended Reality, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany; Human-Centered Computing and Extended Reality, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany; Human-Centered Computing and Extended Reality, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","726","727","Persons affected by blindness or visual impairments are challenged by spatially understanding unfamiliar environments. To obtain such understanding, they have to sense their environment closely and carefully. Especially objects outside the sensing area of analog assistive devices, such as a white cane, are simply not perceived and can be the cause of collisions. This project proposes a mixed reality guidance system that aims at preventing such problems. We use object detection and the 3D sensing capabilities of a mixed reality head mounted device to inform users about their spatial surroundings.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757681","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality;Human-centered computing—Accessibility—Accessibility systems and tools","Solid modeling;Three-dimensional displays;Conferences;Mixed reality;Virtual reality;Object detection;Resists","augmented reality;handicapped aids;helmet mounted displays;object detection","mixed reality guidance system;blind;visually impaired people;blindness;visual impairments;understanding unfamiliar environments;sensing area;analog assistive devices;3D sensing capabilities;mixed reality head","","3","","8","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Spatial Augmented Reality System with functions focused on the rehabilitation of Parkinson’s patients","J. M. Mota; R. Baena-Pérez; I. Ruiz-Rube; M. J. P. Duarte; A. Ruiz-Castellanos; J. M. Correro-Barquín","Dpto. de Ingeniería Informática, Universidad de Cádiz, Cádiz, España; Dpto. de Ingeniería Informática, Universidad de Cádiz, Cádiz, España; Dpto. de Ingeniería Informática, Universidad de Cádiz, Cádiz, España; Dpto. de Filología, Universidad de Cádiz, Cádiz, España; Dpto. de Filología, Universidad de Cádiz, Cádiz, España; Universidad de Cádiz, Cádiz, España","2021 International Symposium on Computers in Education (SIIE)","28 Oct 2021","2021","","","1","5","In 2009 Pranav Mistry presented the Sixth Sense project, which used Spatial Augmented Reality to display information directly on the user’s environment using a projector. The user interacts with the virtual elements without the need to use typical interfaces such as screens or keyboards. At present, different projects make use of Virtual Reality in serious games as a mechanism for the rehabilitation of patients. This research presents an update of the Sixth Sense project to study the possibilities offered by Augmented Reality as a mechanism for the rehabilitation of patients with neurological diseases by the Linguistics Area of the University of Cadiz.","","978-1-6654-4024-0","10.1109/SIIE53363.2021.9583636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583636","Augmented reality;rehabilitation;Parkinson;language disorders;interaction","Neurological diseases;Computers;Spatial augmented reality;Education;Keyboards;Games;Linguistics","augmented reality;diseases;gesture recognition;human computer interaction;neurophysiology;virtual reality","Spatial Augmented Reality system;rehabilitation;parkinson;2009 Pranav Mistry;Sixth Sense project;virtual elements;typical interfaces;keyboards;Virtual Reality;serious games","","1","","27","IEEE","28 Oct 2021","","","IEEE","IEEE Conferences"
"A proposed combination of photogrammetry, Augmented Reality and Virtual Reality Headset for heritage visualisation","E. Y. Putra; A. K. Wahyudi; C. Dumingan","Program Studi Teknik Informatika, Universitas Klabat; Program Studi Teknik Informatika, Universitas Klabat; Program Studi Teknik Informatika, Universitas Indonesia","2016 International Conference on Informatics and Computing (ICIC)","24 Apr 2017","2016","","","43","48","Along with the development, Augmented Reality technology has been implemented in various areas. Augmented Reality has also been widely applied to preserve the historical heritage. This paper discusses our research that combines some of the latest technology. This study was initiated on the reconstruction of the 3D scanning using photogrammetry techniques, incorporation of multimedia elements, and 3D models displayed using Augmented Reality by using Virtual Reality Headset devices to maximize the experience of the user. This paper describes the methods and techniques used in collecting the data and providing innovation in the visualization of cultural heritage. The result is the system can provide new experiences for users and a good 3D visualisation.","","978-1-5090-1648-8","10.1109/IAC.2016.7905687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7905687","Augmentd Reality;Photogrammetry;Virtual Reality Headset;3D reconstruction","Three-dimensional displays;Solid modeling;Smart phones;Cameras;Augmented reality;Unmanned aerial vehicles;Headphones","augmented reality;data visualisation;history;virtual reality","augmented reality;heritage visualisation;photogrammetry techniques;virtual reality headset devices","","11","","19","IEEE","24 Apr 2017","","","IEEE","IEEE Conferences"
"Towards the improvement of ADHD children through augmented reality serious games: Preliminary results","D. Avila-Pesantez; L. A. Rivera; L. Vaca-Cardenas; S. Aguayo; L. Zuñiga","Computer Science Department, San Marcos National University, Lima, Peru; Informatics and Electronic Faculty, Polytechnic School of Chimborazo, Riobamba, Ecuador; Laboratório de Ciencias Matematicas, North Fluminense State University, Rio de Janeiro, Brazil; Informatics and Electronic Faculty, Polytechnic School of Chimborazo, Riobamba, Ecuador; Informatics and Electronic Faculty, Polytechnic School of Chimborazo, Riobamba, Ecuador","2018 IEEE Global Engineering Education Conference (EDUCON)","24 May 2018","2018","","","843","848","Attention Deficit-Hyperactivity Disorder is the most common childhood neurodevelopment disorder that globally affects 3 to 5 percent of children. Several computerized training programs for ADHD have been designed to improve executive functions. With technological advancement, new approaches can be used to develop interactive experiences with visual effects. In this sense, Serious Games have recently shown great potential to be adopted in this psychotherapeutic area. One critical challenge is developing serious games using emerging technologies like Augmented Reality (AR) focus on cognitive-behavioral therapies for children with this disorders in scholar-age. This paper aim is to improve ADHD children's attention and train them using an Augmented Reality Serious Games (ARSG) prototype. It was designed with the help of experts, workshops with designers, the guidance of psychologists and medical doctors specialized on ADHD, by using a methodical game design approach along with natural user interface (Kinect). Findings of this case study showed that player's attention and retention increased, improving their tolerance for frustration and with a significant time reduction in the game activities.","2165-9567","978-1-5386-2957-4","10.1109/EDUCON.2018.8363318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8363318","ADHD;serious games;augmented reality;Augmented Reality Serious Games;ATHYNOS","Games;Medical treatment;Unified modeling language;Augmented reality;Conferences;Prototypes;Psychology","augmented reality;cognition;computer based training;medical disorders;neurophysiology;paediatrics;patient treatment;serious games (computing);user interfaces","computerized training programs;interactive experiences;visual effects;psychotherapeutic area;cognitive-behavioral therapies;ADHD children;methodical game design approach;player;attention deficit-hyperactivity disorder;augmented reality serious games prototype;ARSG prototype;scholar-age disorders;medical doctors;natural user interface;childhood neurodevelopment disorder","","16","","21","IEEE","24 May 2018","","","IEEE","IEEE Conferences"
"iARBook: An Immersive Augmented Reality system for education","M. W. Bazzaza; B. Al Delail; M. J. Zemerly; J. W. P. Ng","Electrical and Computer Engineering Department, Khalifa University of Science, Technology and Research, Abu Dhabi, United Arab Emirates; Electrical and Computer Engineering Department, Khalifa University of Science, Technology and Research, Abu Dhabi, United Arab Emirates; Electrical and Computer Engineering Department, Khalifa University of Science, Technology and Research, Abu Dhabi, United Arab Emirates; Etisalat BT Innovation Center (EBTIC), BT Innovate & Design, Abu Dhabi, United Arab Emirates","2014 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)","19 Mar 2015","2014","","","495","498","The advancement in technology nowadays has improved learning methods that are beginning to override the traditional methods. Augmented Reality (AR) is one such technology that has seen many applications in education. This paper describes how an Immersive Augmented Reality (iAR) application in conjunction with a book, can act as a new smart learning method by engaging as many of the user's senses and human functions as possible. In addition, a survey was conducted on students and educators who have tested the application. The purpose of the survey is to study the effectiveness of the application in enhancing the user's learning experience and help to devise plans to improve the system.","","978-1-4799-7672-0","10.1109/TALE.2014.7062576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7062576","Immersive Augmented Reality;Smart Education;Edutainment;Augmented Reality;Interactive Learning","Augmented reality;Three-dimensional displays;Education;Cameras;Speech;Solid modeling;Robots","augmented reality;computer aided instruction;interactive systems;user interfaces","iARBook;immersive augmented reality system;educational technology;user learning enhancement;interactive learning","","16","","9","IEEE","19 Mar 2015","","","IEEE","IEEE Conferences"
"Artistic Visualisation of Practical Information Using Augmented Reality","V. Geroimenko","School of Art and Media, Plymouth University, Plymouth, UK","2013 17th International Conference on Information Visualisation","2 Dec 2013","2013","","","404","409","Augmented Reality (AR) is a novel visualisation technology that can be effectively used in a wide range of areas, from science to art and everyday life. This paper addresses the issue of developing AR applications that combine practical and artistic aspects of information visualisation. It includes both some theoretical consideration of the problem and an analysis of the AR installations by the author: ""Plymouth Hoe and the Surrounding World"", ""Scope"" and ""Plymouth Blitz - 70 years on"". The paper concludes that, though the use of Augmented Reality as a new visual medium for solving the dilemma of practical vs. artistic information visualisation still remains a purely creative task in most cases, there are some rational elements that can facilitate an effective implementation.","2375-0138","978-0-7695-5049-7","10.1109/IV.2013.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676593","Augmented reality;art;visualisation;conceptual model;artistic visualisation;art exhibition;augmented reality installation","Augmented reality;Visualization;Art;Painting;Browsers;Educational institutions;Smart phones","art;augmented reality;data visualisation","artistic visualisation;augmented reality;information visualisation","","3","","19","IEEE","2 Dec 2013","","","IEEE","IEEE Conferences"
"Development of an interactive book with Augmented Reality for teaching and learning geometric shapes","T. G. Kirner; F. M. V. Reis; C. Kirner","Universidade Federal de Itajubá, Itajuba, Minas Gerais, Brazil; Universidade Federal de Itajubá, Itajuba, Minas Gerais, Brazil; Universidade Federal de Itajubá, Itajuba, Minas Gerais, Brazil","7th Iberian Conference on Information Systems and Technologies (CISTI 2012)","30 Aug 2012","2012","","","1","6","This paper focuses on the GeoAR, an interactive book which incorporates Augmented Reality resources, developed to support teaching and learning of Geometry topics covering the main geometric shapes. The GeoAR development followed a process based on prototyping, proposed to support the creation of Augmented Reality applications. The paper points out concepts and related work, describes the development of the GeoAR, relates prototypes evaluations, and discusses the use of the GeoAR by children in a real situation.","2166-0735","978-989-96247-7-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6263179","Augmented reality;interactive book with augmented reality;educational software","Software;Prototypes;Shape;Animation;Augmented reality;Educational institutions","augmented reality;computer aided instruction;geometry;interactive systems;mathematics computing","interactive book;augmented reality;geometric shape learning;geometric shape teaching;GeoAR;geometry topics;children","","3","","20","","30 Aug 2012","","","IEEE","IEEE Conferences"
"Hardware Performance Analysis of Mobile-Based Augmented Reality Systems","K. Ashutosh","Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India","2020 International Conference on Computational Performance Evaluation (ComPE)","18 Sep 2020","2020","","","671","675","Mobile-based augmented reality (AR) systems are occupying consumer markets at a fast rate. Mobile-based AR applications are successful owing to the ease of access and good hardware that our smartphones have. However, with the increasing demand for applications, the AR systems need to be accurate and energy-efficient. State of the art hardware specifications of our smartphones allows us to perform a variety of tasks, including video screening, navigation, and browsing. Firstly, applications of augmented reality and the hardware challenges associated with them are discussed. Next, an analysis of two important hardware components - global positioning system (GPS) and battery performance is presented, both in the capacity of AR applications. It is observed that current hardware specifications are good enough for a wide range of applications except for applications that require high accuracy.","","978-1-7281-6644-5","10.1109/ComPE49325.2020.9200079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200079","Augmented Reality;Global Positioning System (GPS);Mobile Augmented Reality;Battery performance","Global Positioning System;Augmented reality;Hardware;Three-dimensional displays;Feature extraction;Task analysis","augmented reality;Global Positioning System;mobile computing;smart phones","hardware performance analysis;mobile-based augmented reality systems;consumer markets;smartphones;AR systems;battery performance;AR applications;hardware specifications;global positioning system;GPS","","1","","25","IEEE","18 Sep 2020","","","IEEE","IEEE Conferences"
"Illuminating the mixed reality stage: applying complex lighting conditions to AR","M. Wittkamper; E. Meier; W. Broll","GMD Institute of Applied Information Technology FIT, Sankt Augustin, Germany; GMD Institute of Applied Information Technology FIT, Sankt Augustin, Germany; GMD Institute of Applied Information Technology FIT, Sankt Augustin, Germany","Proceedings IEEE and ACM International Symposium on Augmented Reality","6 Aug 2002","2001","","","187","188","The Mixed Reality Stage is an augmented reality environment which aims to support creative and collaborative stage design processes. In this application scenario, the proper simulation of real lighting is crucial for a seamless integration of virtual objects into a physical model stage. The authors present their approach to emulating complex real world lighting conditions for rendering in real-time. They introduce mechanisms that significantly reduce the effective number of light sources, while simultaneously minimizing the loss of visualization quality.","","0-7695-1375-1","10.1109/ISAR.2001.970535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=970535","","Virtual reality;Light sources;Layout;Electrical capacitance tomography;Augmented reality;Process design;Costs;Glass;Acceleration;Fixtures","augmented reality;groupware;digital simulation;lighting;rendering (computer graphics);real-time systems;data visualisation","Mixed Reality Stage;complex lighting conditions;AR;augmented reality environment;creative collaborative stage design processes;application scenario;real lighting simulation;seamless integration;virtual objects;physical model stage;complex real world lighting conditions;real-time rendering;light sources;visualization quality","","1","6","1","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"DeclutterAR: Mobile Diminished Reality and Augmented Reality to Address Hoarding by Motivating Decluttering and Selling on Online Marketplace","S. W. T. Chan; B. Ryskeldiev; S. Nanayakkara","Mercari R4D, Tokyo, Japan; Mercari R4D, Tokyo, Japan; Augmented Human Lab, National University of Singapore","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","870","874","Hoarding behaviour is a widespread issue in which people have difficulty discarding or parting with their possessions. We present our work to address hoarding behaviours in people and promote the selling or donating of items that they no longer use or value through an online marketplace application (app). We introduce DeclutterAR, a feature linked to the marketplace app that uses Diminished Reality to remove real-world objects in the Augmented Reality (AR) scene, allowing you to visualise your “cluttered spaces” as “decluttered spaces”. DeclutterAR also allows users to sort removed objects to sell or give away. This work describes the system implementation and preliminary user study and discusses concepts of using Diminished Reality to motivate and support users in visualising target behaviours.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974306","Human-centered computing-Human-Computer Interaction (HCI)-Interaction paradigms-Mixed / augmented reality;Computing methodologies-Computer graphics-Image manipulation-Image processing","Visualization;Augmented reality;System implementation","augmented reality;data visualisation;electronic commerce;Internet;mobile computing","address hoarding;Augmented Reality scene;DeclutterAR;discusses concepts;hoarding behaviour;marketplace app;mobile Diminished Reality;motivating decluttering;online marketplace application;preliminary user study;real-world objects;selling;target behaviours;widespread issue","","","","39","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Evaluation of Hand Gesture Annotation in Remote Collaboration Using Augmented Reality","S. Yamada; N. P. Chandrasiri","Faculty of Information, Kogakuin University, Tokyo, Japan; Faculty of Information, Kogakuin University, Tokyo, Japan","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","727","728","In this research we have devised a system which can tell works to the worker by using the hand gestures of the helper. In this system, by using augmented reality, it is possible to display as if the helper's hand model actually exist in front of the worker. In order to evaluate the usefulness of the proposed system, we conducted comparative experiments on remote work support by instruction annotations using conventional method of drawn lines, and the proposed method of by using hand gesture instructions. As a result, no significant difference was found between two methods in terms of ease of understanding in the instructions. However, regarding working time, the hand gesture instructions were shorter by 20 seconds (shortened by 19%) on average than the other.","","978-1-5386-3365-6","10.1109/VR.2018.8446287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446287","Hand gesture;augmented reality;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;augmented;and virtual realities","Conferences;Virtual reality;Three-dimensional displays;User interfaces","augmented reality;gesture recognition","hand gesture annotation;remote collaboration;augmented reality;remote work support;hand gesture instructions;helper hand model","","2","","3","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Innovations in Tourism Industry & Development Using Augmented Reality (AR), Virtual Reality (VR)","P. K. Katkuri; A. Mantri; S. Anireddy","Department of Computer Science & Engineering, Chitkara University Institute of Enginering & Technology, Chitkara University, Punjab, India; Chitkara University Institute of Enginering & Technology, Chitkara University, Punjab, India; Department of Computer Science & Engineering, Chitkara University Institute of Enginering & Technology, Chitkara University, Punjab, India","TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)","12 Dec 2019","2019","","","2578","2581","Over recent times, the evolution of digital technology has become a necessity to stay competitive in tourism and to attract the modern tourist. A new form of digital technology that is used in the public space is Virtual and Augmented Reality. This paper emphasizes on the analysis of scientific & technical aspects of developing mobile AR applications in smart tourism, which provides the necessary information about the destinations and their attractions. We address how the requirements of a user are essential to developing an AR application to attract tourists. We aim to present the technologies for tourism concerning AR and VR. This paper also acknowledges the technological limitations concerning end-user adaption.","2159-3450","978-1-7281-1895-6","10.1109/TENCON.2019.8929478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8929478","Augmented Reality;mobile applications;tourist experience;experience quality;Location awareness","Augmented reality;Industries;Three-dimensional displays;Solid modeling;Engines;Visualization","augmented reality;mobile computing;travel industry","tourism industry & development;virtual reality;VR;digital technology;modern tourist;public space;augmented reality;scientific & technical aspects;mobile AR applications;smart tourism;attractions;tourists;technological limitations","","7","","14","IEEE","12 Dec 2019","","","IEEE","IEEE Conferences"
"The Design and Implementation of Augmented Reality Learning Systems","S. Oh; Y. -C. Byun","Convergence Research and Development Laboratory, LG Electronics Limited, Seoul, South Korea; Department of Computer Engineering, Jeju National University, Jeju, Jeju, South Korea","2012 IEEE/ACIS 11th International Conference on Computer and Information Science","7 Jun 2012","2012","","","651","654","In this paper, we present an augmented reality learning system that enables users to experience an interactive flower garden with the assistance of interactive agents in the augmented picture. We develop an interactive agent that generates problem-solving peer support to a user's action. We overlay virtual flower garden over a physical book and offer a collaborative environment that allows a learner to interact with the agent. To evaluate the effectiveness of the proposed system, we implement it on a mobile device and enable users to experience the collaborative task with the animated character. Through evaluation, we found that the interactive agent could be a promising technology for motivating users to engage in learning systems.","","978-1-4673-1536-4","10.1109/ICIS.2012.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6211167","Augmented reality system;interactive learning system;collaborative learning environment","Learning systems;Augmented reality;Problem-solving;Collaboration;Mobile handsets;Humans;Fertilizers","augmented reality;computer aided instruction;gardening;groupware;mobile computing;software agents","augmented reality learning system design;augmented reality learning system implementation;interactive flower garden;interactive agents;augmented picture;virtual flower garden;physical book;collaborative environment;mobile device;collaborative task","","9","","11","IEEE","7 Jun 2012","","","IEEE","IEEE Conferences"
"Bright: an augmented reality assistive platform for visual impairment","A. M. Bakshi; J. Simson; C. de Castro; C. C. Yu; A. Dias",", Manhasset, New York, USA; , Konstanz, Germany; , Los Angeles, California, USA; , New York, New York, USA; , New York, New York, USA","2019 IEEE Games, Entertainment, Media Conference (GEM)","26 Aug 2019","2019","","","1","4","283 million people suffer from moderate to severe vision impairment or blindness; many today rely on lens-based optical aids of limited use. Electronic pass-through zoom headsets are extremely expensive and provide narrow feature sets with compromised comfort and ease-of-use, while mobile app-based aids provide useful functionality but in an inconvenient form factor. The present project explores the development of an aid for the visually impaired, designed as a software solution running on off-the-shelf optical see-through augmented reality head-mounted display devices such as the Microsoft HoloLens, to deliver a broad feature set while reducing cost and optimizing comfort and usability.","","978-1-7281-2404-9","10.1109/GEM.2019.8811556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811556","vision impairment;blindness;augmented reality;virtual reality;headset;assistive technology;wearable computing;voice interface","Visualization;Augmented reality;Headphones;Software;Cameras;Face recognition;Hardware","augmented reality;handicapped aids;helmet mounted displays;lenses;mobile computing","compromised comfort;mobile app-based aids;useful functionality;inconvenient form factor;software solution;augmented reality head-mounted display devices;broad feature;optimizing comfort;augmented reality assistive platform;visual impairment;severe vision impairment;lens-based optical aids;electronic pass-through zoom headsets;narrow feature;Bright;Microsoft HoloLens","","6","","21","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"Ubiquitous Augmented Reality System","X. Li; D. Chen; S. Xiahou","School of Automation Engineering, University of Electronic Science and Technology, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology, Chengdu, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","28 Dec 2009","2009","3","","91","94","In the research prototypes of augmented reality (AR), the virtual rendering information always only relates to the external image features of real world. Due to this static and single-channel relation, AR technology could not dynamically show ""virtual"" augmented information according to the corresponding internal invisible state information of real objects. This paper presents a ubiquitous augmented reality (UAR) prototype system designed for combining ubiquitous computing and augmented reality technologies. By using wireless sensor networks to gather needed monitoring data throughout the real object or physical environment, this system supports hybrid tracking in mobile status and provides an AR interactive interface to represent multi-type augmented information adapting to the sensor data from real world.","","978-0-7695-3888-4","10.1109/KAM.2009.312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362439","augmented reality;ubiquitous computing;wireless sensor networks","Augmented reality;Wireless sensor networks;Sensor systems;Robustness;Prototypes;Ubiquitous computing;Industrial training;Knowledge acquisition;Automation;Design engineering","augmented reality;rendering (computer graphics);ubiquitous computing;wireless sensor networks","ubiquitous augmented reality system;virtual rendering information;internal invisible state information;ubiquitous computing;wireless sensor networks;hybrid tracking;mobile status;multitype augmented information;sensor data","","8","","6","IEEE","28 Dec 2009","","","IEEE","IEEE Conferences"
"Image-Based Label Placement for Augmented Reality Browsers","J. Jia; Y. Zhang; X. Wu; W. Guo","Hebei Key Laboratory of Computational Mathematics and Applications, Shijiazhuang, China; College of Mathematics and Information Sciences, Hebei Normal University, Shijiazhuang, China; College of Mathematics and Information Sciences, Hebei Normal University, Shijiazhuang, China; Hebei Key Laboratory of Computational Mathematics and Applications, Shijiazhuang, China","2018 IEEE 4th International Conference on Computer and Communications (ICCC)","1 Aug 2019","2018","","","1654","1659","In this paper, we introduce a label placement technique for placing labels in Augmented Reality systems. One of the common challenges in Augmented Reality applications is lacking in knowledge of the real environment, limiting efficient representation and optimal layout of the digital information augment onto user's view. In order to overcome this problem, we propose an image-based label placement method, which combines identifying potentially important image regions and determining manual placement tendencies while labeling. Then we add geometric constraints for placing labels in the optimization problem to obtain the final label layout. Our method will provide special benefits to Augmented Reality browsers which is usually in the absence of scene knowledge. Also it can be used to many similar applications in the domain of Augmented Reality.","","978-1-5386-8339-2","10.1109/CompComm.2018.8780965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780965","label placement;Augmented Reality;image-based layout;text overlay","Layout;Augmented reality;Manuals;Legged locomotion;Image edge detection;Optimization","augmented reality;geographic information systems;image representation;online front-ends;optimisation","optimal layout;digital information augment;image-based label placement method;optimization problem;image regions;augmented reality browsers;manual placement tendencies;geometric constraints","","2","","15","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"Augmented reality digital technologies (ARDT) for foreign language teaching and learning","O. Scrivner; J. Madewell; C. Buckley; N. Perez",Indiana University; Indiana University; Indiana University; Indiana University,"2016 Future Technologies Conference (FTC)","19 Jan 2017","2016","","","395","398","The present study focuses on Augmented Reality and its role in language education. It has often been claimed that emerging technologies have great potential to improve language learning and increase learner performance. While their digital capabilities are almost limitless, to our knowledge, no study has been conducted to measure their effectiveness on actual language learners. In this paper we report and discuss our on-going work on the design, management, and implementation of Augmented Reality experiences for foreign language instruction. We concentrate on the beginner's level Spanish course for which we have used Aurasma, an augmented reality app for mobile devices. The project has a three-fold purpose: 1) to increase second language learners' motivation, 2) to measure statistically the effectiveness of this technology in classroom settings, and 3) to contribute to our knowledge of digital technology and language instruction.","","978-1-5090-4171-8","10.1109/FTC.2016.7821639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821639","augmented reality;language instruction;mobile;emerging technologies","Augmented reality;Mobile handsets;Education;Mobile communication;Games;Vocabulary;Visualization","augmented reality;computer aided instruction;educational courses;human factors;linguistics;mobile computing;statistical analysis;teaching","augmented reality digital technology;ARDT;foreign language teaching;foreign language learning;language education;learner performance;foreign language instruction;beginner level Spanish course;Aurasma;augmented reality app;mobile device;second language learner motivation;statistical measure","","15","","21","IEEE","19 Jan 2017","","","IEEE","IEEE Conferences"
"Interactive augmented reality system using projector-camera system and smart phone","C. Lim; J. Choi; J. -I. Park; H. Park","Department of Computer and Software, Hanyang University Seoul, Republic of Korea; Department of Computer and Software, Hanyang University Seoul, Republic of Korea; Department of Computer and Software, Hanyang University Seoul, Republic of Korea; Department of Electronic Engineering Pukyong, National University Busan, Republic of Korea","2015 International Symposium on Consumer Electronics (ISCE)","6 Aug 2015","2015","","","1","2","This paper proposes a user immersive augmented reality (AR) system which utilizes three kinds of computer vision technology: projector-camera-based spatial AR, hand-gesture-based user interaction, and mobile AR. The proposed system augments 2D virtual contents on a tabletop using the projector-camera-based AR, and a user can interact with the augmented 2D contents by using natural hand gestures and a physical object by using smart phone. Also, the proposed system further enhances user-immersion by adopting the mobile AR, which augments 3D virtual contents on the physical object when user sees the object through smart phone's camera. This paper verifies the effectiveness of the proposed AR system through implementing a car driving application.","2159-1423","978-1-4673-7365-4","10.1109/ISCE.2015.7177800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177800","projector-camera system;mobile augmented reality;hand-gesture-based interface;object tracking","Smart phones;Mobile communication;Cameras;Three-dimensional displays;Augmented reality;Calibration;Image recognition","augmented reality;cameras;interactive systems;microcomputers;optical projectors;smart phones","interactive augmented reality system;projector-camera system;smart phone;user immersive augmented reality system;computer vision technology;projector-camera-based spatial AR;hand-gesture-based user interaction;mobile AR;2D virtual contents;tabletop","","6","","6","IEEE","6 Aug 2015","","","IEEE","IEEE Conferences"
"Augmented reality mobile application and its influence in Quechua language learning","C. Montellanos; J. Luis; M. Vásquez; C. Alberto; H. Salazar; J. Luis","School of Engineering, Universidad Autónoma del Perú, Lima, Perú; School of Engineering, Universidad Autónoma del Perú, Lima, Perú; School of Engineering, Universidad Autónoma del Perú, Lima, Perú; School of Engineering, Universidad Autónoma del Perú, Lima, Perú; School of Engineering, Universidad Autónoma del Perú, Lima, Perú; School of Engineering, Universidad Autónoma del Perú, Lima, Perú","2019 IEEE Sciences and Humanities International Research Conference (SHIRCON)","5 Mar 2020","2019","","","1","4","Augmented reality technology is being a huge support in education standing out the user's attention to interact with virtual world in real space. In this article, the level of influence that would have the use of a mobile application with augmented reality will be evaluated in primary students for Quechua language learning. Likewise, the quasi-experimental design is used and the sample consists of sixty students divided into two classrooms of thirty students respectively. The experimental group improves his grades in a 19.7% unlike the control group and also a reduction of time for understanding the information is seen. In conclusion, the augmented reality mobile application influences significantly in Quechua language learning for fourth-year pupils of primary school.","","978-1-7281-3818-3","10.1109/SHIRCON48091.2019.9024860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9024860","Augmented reality;Mobile Application;Learning;Mobile-D Methodology;Language","Augmented reality;Mobile applications;Education;Tools;Computer architecture;Sociology;Statistics","augmented reality;computer aided instruction;mobile computing;natural language processing","quasiexperimental design;primary students;augmented reality technology;Quechua language learning;augmented reality mobile application","","5","","7","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"IntelligShop: Enabling Intelligent Shopping in Malls through Location-Based Augmented Reality","A. Adhikari; V. W. Zheng; H. Cao; M. Lin; Y. Fang; K. C. -C. Chang","Advanced Digital Sciences Center, Singapore; Advanced Digital Sciences Center, Singapore; Advanced Digital Sciences Center, Singapore; Advanced Digital Sciences Center, Singapore; Advanced Digital Sciences Center, Singapore; Advanced Digital Sciences Center, Singapore","2015 IEEE International Conference on Data Mining Workshop (ICDMW)","4 Feb 2016","2015","","","1604","1607","Shopping experience is important for both citizens and tourists. We present IntelligShop, a novel location-based augmented reality application that supports intelligent shopping experience in malls. As the key functionality, IntelligShop provides an augmented reality interface -- people can simply use ubiquitous smartphones to face mall retailers, then IntelligShop will automatically recognize the retailers and fetch their online reviews from various sources (including blogs, forums and publicly accessible social media) to display on the phones. Technically, IntelligShop addresses two challenging data mining problems, including robust feature learning to support heterogeneous smartphones in localization and learning to query for automatically gathering the retailer content from the Web for augmented reality. We demonstrate the system effectiveness via a test bed established in a real mall of Singapore.","2375-9259","978-1-4673-8493-3","10.1109/ICDMW.2015.103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7395868","IntelligShop;location-based augmented reality","Augmented reality;Yttrium;Hair;Data mining;Smart phones;Robustness;Electronic mail","augmented reality;data mining;learning (artificial intelligence);retail data processing;smart phones","Intelligshop;location-based augmented reality;intelligent shopping experience;malls;augmented reality interface;ubiquitous smart phones;data mining;robust feature learning;heterogeneous smart phones;retailer content;Web;Singapore","","3","","9","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"An Interactive 5E Learning Cycle-Based Augmented Reality System to Improve Students' Learning Achievement in a Microcosmic Chemistry Molecule Course","S. -H. Cheng; H. -C. Chu","Department of Computer Science and Information Management, Soochow University Taipei, Taiwan; Department of Computer Science and Information Management, Soochow University Taipei, Taiwan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","1 Sep 2016","2016","","","357","360","In this study, an interactive 5E learning cycle-based augmented reality system is proposed for conducting microcosmic Chemistry molecule learning activities. Augmented reality has been widely used for enhancing students' learning motivation. However, numerous studies have indicated that without effective learning strategies for helping students construct solid knowledge, their learning performance might be disappointing. To cope with this problem, an interactive 5E learning cycle approach has been adopted to develop an augmented reality mobile learning system which reinforces students' understanding of the concepts of the microcosmic structure of Chemistry molecule learning unit. In order to evaluate students' learning achievement, self-efficacy and learning behavior patterns when using this approach, an experiment was conducted to examine the effectiveness of the proposed approach. The students' learning behaviors when using the interactive AR tools to learn about microcosmic Chemistry molecule structures and the ways in which they perform the interactive 5E learning cycle-based learning tasks will be recorded. Accordingly, the learning behavioral patterns will be analyzed via lag-sequential analysis and quantitative content analysis.","","978-1-4673-8985-3","10.1109/IIAI-AAI.2016.119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557633","augmented reality;high school education;interactive 5E learning cycle;microcosmic Chemistry molecule course","Augmented reality;Education;Computers;Organic compounds;Hydrocarbons","augmented reality;chemistry computing;courseware;human computer interaction;mobile learning","interactive 5E learning cycle-based augmented reality system;student learning achievement improvement;microcosmic Chemistry molecule course;microcosmic Chemistry molecule learning activities;student learning motivation enhancement;learning performance;augmented reality mobile learning system;student self-efficacy;learning behavior patterns;interactive AR tools;lag-sequential analysis;quantitative content analysis","","3","","16","IEEE","1 Sep 2016","","","IEEE","IEEE Conferences"
"Design Research of Interactive Picture Books of Cultural Education Based on Augmented Reality Technology","H. Yan; W. Liu; X. Xia; Y. Xu; T. Ssong","School of New Media, Beijing Institute of Graphic Communication, Beijing, China; School of New Media, Beijing Institute of Graphic Communication, Beijing, China; School of New Media, Beijing Institute of Graphic Communication, Beijing, China; School of New Media, Beijing Institute of Graphic Communication, Beijing, China; School of New Media, Beijing Institute of Graphic Communication, Beijing, China","2021 16th International Conference on Computer Science & Education (ICCSE)","21 Oct 2021","2021","","","958","962","The application of augmented reality technology shows a new thinking of cultural education. What is different from the traditional cultural education is that it enhances user experience not only in the aspect of story but also ideological connotation of culture. In this paper, augmented reality technology will be applied to the design of picture book Xi Shi Dance. By using of Unity development engine and Vuforia SDK, we studied and developed the interactive augmented reality works. Been ranked among the first batch of intangible cultural heritage in 2006, Xi Shi Legend is a household story in china. The classic plot and character of Xi Shi Legend are used in this third-person puzzle solving interactive picture book, so as to achieve the purpose of inheriting excellent Chinese culture and popularizing traditional cultural knowledge.","2473-9464","978-1-6654-1468-5","10.1109/ICCSE51940.2021.9569391","Beijing Institute of Graphic Communication; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9569391","culture;education;interactive picture book;augmented reality technology","Technological innovation;Education;User experience;Cultural differences;Augmented reality;Engines","augmented reality;computer aided instruction;history;user experience","augmented reality technology;traditional cultural education;interactive augmented reality works;intangible cultural heritage;Xi Shi Legend;Chinese culture;traditional cultural knowledge;user experience;culture ideological connotation;Unity development engine;Vuforia SDK;China;third-person puzzle;interactive picture book Xi Shi Dance design research","","2","","10","IEEE","21 Oct 2021","","","IEEE","IEEE Conferences"
"Augmented reality based self-treatment using acupressure","S. Kausar; M. K. Multani; B. Zahoor; A. Nazeer","Department of Computer Science, Bahria University, Islamabad, Pakistan; Department of Computer Science, Bahria University, Islamabad, Pakistan; Department of Computer Science, Bahria University, Islamabad, Pakistan; Department of Computer Science, Bahria University, Islamabad, Pakistan","2017 13th International Conference on Emerging Technologies (ICET)","8 Feb 2018","2017","","","1","5","Acupressure is an ancient Asian method of relieving pain and curing diseases. This paper presents our work on customized Augmented Reality Based Self-Treatment Using Acupressure (ARBASTUA) that uniquely uses facial symmetry to model acupressure points personalized for users' faces and displays the information using augmented reality. We also bridge the gap in presenting this useful information to users in a user-friendly manner. With the increase in use of smart-phones, a lot of health tips apps have been released. Most of these apps are text based, and provide health related information in text form which is not very user friendly. This information can be better presented in a novel way by using augmented reality.","","978-1-5386-2260-5","10.1109/ICET.2017.8281702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281702","Acupressure;Golden Ratio;Face Detection;Face Symmetry;Augmented Reality;Chinese medicine","Diseases;Augmented reality;Face detection;Pain;Androids;Humanoid robots;Strain","augmented reality;diseases;health care;medical information systems;mobile computing;mobile handsets;patient treatment","facial symmetry;acupressure points;user-friendly manner;health tips apps;health related information;Augmented reality based self-treatment;ancient Asian method;curing diseases;customized Augmented Reality;ARBASTUA;smart-phones","","2","","11","IEEE","8 Feb 2018","","","IEEE","IEEE Conferences"
"Augmented Reality for 3D House Design Visualization from Floorplan Image","M. Auliaramadani; N. Suciati; S. C. Hidayati; H. Fabroyir; R. R. Hariadi","Department of Informatics, Faculty of Intelligent Electrical Informatics Technology, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Faculty of Intelligent Electrical Informatics Technology, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Faculty of Intelligent Electrical Informatics Technology, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Faculty of Intelligent Electrical Informatics Technology, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Faculty of Intelligent Electrical Informatics Technology, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2020 International Conference on Electrical Engineering and Informatics (ICELTICs)","12 Jan 2021","2020","","","1","6","Smartphones currently support the augmented reality feature, capable of displaying virtual objects into the real world environment at a specific location designated with a marker. This research develops an augmented reality application on a smartphone to visualize a 3D house design. The floorplan image captured by the smartphone camera is designated as a marker and then sent to the server. The server-side application, built using deep learning and integer programming techniques, detects corner positions on the image and produces a vector containing 2D coordinates. The client application on the smartphone uses the 2D coordinates to draw a 3D house model using Unity 3D. The model is then added over the floor plan image marker using Vuforia. Based on the test results, the 3D house models can be drawn according to the provided floorplan with moderate accuracy. The augmented reality application offers an alternative approach to examine a floorplan so that a user can better understand and engage with the design.","","978-1-7281-8199-8","10.1109/ICELTICs50595.2020.9315422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315422","Augmented Reality;Floorplan;Visualization;Image Recognition","Three-dimensional displays;Solid modeling;Augmented reality;Image recognition;Servers;Informatics;Feature extraction","augmented reality;design engineering;floors;integer programming;learning (artificial intelligence);smart phones;structural engineering computing","augmented reality application;3D house design visualization;augmented reality feature;virtual objects;smartphone camera;server-side application;deep learning;integer programming techniques;client application;3D house model;Unity 3D;floor plan image marker;2D coordinates","","1","","12","IEEE","12 Jan 2021","","","IEEE","IEEE Conferences"
"Markerless Augmented Reality for iOS Platform: A University Navigational System","T. -W. Hew; S. -H. Saw; M. Muniandy; J. Khaw; Y. Min; W. -K. Cheng; T. -B. Tan","Department of Computer Science, Universiti Tunku Abdul Rahman, Kampar Perak, Malaysia; Department of Computer Science, Universiti Tunku Abdul Rahman, Kampar Perak, Malaysia; Department of Computer Science, Universiti Tunku Abdul Rahman, Kampar Perak, Malaysia; Department of Computer Science, Universiti Tunku Abdul Rahman, Kampar Perak, Malaysia; Department of Computer Science, Universiti Tunku Abdul Rahman, Kampar Perak, Malaysia; Department of Computer Science, Universiti Tunku Abdul Rahman, Kampar Perak, Malaysia; Department of Computer Science, Universiti Tunku Abdul Rahman, Kampar Perak, Malaysia","2018 IEEE Conference on Wireless Sensors (ICWiSe)","3 Feb 2019","2018","","","61","65","Augmented reality simulations of any imaginable 3D objects have created a whole new possibility for product demonstration, product testing, building simulations and more to come. The use of augmented reality technology increases day by day as technology proceeds to progress exponentially, where smartphones are already capable of processing realistic graphics, allowing complex 3D models and architectures to be simulated through the graphic processing units. This paper presents an alternative, markerless Augmented Reality solution for iOS platform to provide a convenient way to visualize the buildings in the university that are not within our reach. Although any form of simulation may not be able to provide touring experiences as realistic as visiting to the place physically, it is able to save the troubles of visitors for the need to visit to a distant area.","","978-1-5386-7069-9","10.1109/ICWISE.2018.8633284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8633284","Augmented Reality;University Navigation System;Markerless Tracking;3D Model;Computer Graphics","Augmented reality;Buildings;Navigation;Cameras;Sensors;Solid modeling;Three-dimensional displays","augmented reality;educational institutions;graphics processing units;iOS (operating system);smart phones","building simulations;augmented reality simulations;smartphones;university navigational system;iOS platform;graphic processing units;augmented reality technology;product testing;product demonstration;imaginable 3D objects","","1","","12","IEEE","3 Feb 2019","","","IEEE","IEEE Conferences"
"A Features Determination of an Augmented Reality Application with Regards to Commercial Perspective","V. Wattanasoontorn; M. Theppaitoon; N. Boonsri","College of Computing, Prince of Songkla University, Phuket, Thiland; College of Computing, Prince of Songkla University, Phuket, Thiland; Phuket College of International Tourism, Phuket Rajabhat University, Phuket, Thiland","2020 17th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","4 Aug 2020","2020","","","33","36","Regarding a commercial perspective, the cost of production of any application always one of the main concerns. In terms of an augmented reality application, both the aesthetic part from the graphic design team and the logical part from the developer team are defined in the early pre-production process for numerous factors. This paper presents a framework aim at decreasing production time with a case study of `Canvas Kids,' a 3D augmented reality application for kids. By focusing on features determination of the application, the effort estimated with production working days from 5 experts in this field for each feature was compared with the satisfaction score from 42 target users. The satisfaction was studied in five perspectives, including aesthetic, joyful, time spent using the application, the number of functions used, and overall impression. The result shows that with our proposed framework, an augmented reality production team could decrease the production time by features preselected.","","978-1-7281-6486-1","10.1109/ECTI-CON49241.2020.9158240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158240","Augmented Reality;Functional Analysis;Feature Determination;Value Analysis","Production;Three-dimensional displays;Augmented reality;Games;Animation;Solid modeling;Visualization","augmented reality;computer graphics","features determination;commercial perspective;graphic design team;early pre-production process;augmented reality production team;3D augmented reality application;Canvas Kids","","","","9","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Mga Kwento ni Lola Basyang: An Augmented Reality On Selected Philippine Folklore","M. S. Besa","FEU Institute of Technology, P. Paredes St. Sampaloc, Manila, Philippines","2021 IEEE 13th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)","16 Mar 2022","2021","","","1","6","Children storybooks have gone far, from flat books to embossed to Audio-book to Pop-up book and now Augmented Reality books. Augmented Reality or AR is one of the innovative technologies that will be universally used given its potential and fascination.The goal of this study is to create a new way of learning with children storybooks with new technology. The innovation underpinning this research is the embedded Augmented Reality 2-Dimensional of children’s book on a mobile application. The research provides an insight into what was done using AR on children’s story books enabling the reader to place this example of AR in perspective and understand it more clearly. This paper specifically highlights an innovative development of the interfaces for providing an AR children storybook that enhances story reading and learning experience for preschool and young schoolers children via mobile AR application.","","978-1-6654-0167-8","10.1109/HNICEM54116.2021.9732029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9732029","Audio-book;Pop-up book;Augmented Reality;2Dimensional;Quick Response (QR) Code;Vuforia;Folktale;Folklore","Technological innovation;Conferences;Humanoid robots;Mobile applications;Information technology;Augmented reality;Nanotechnology","augmented reality;computer aided instruction;cultural aspects;electronic engineering computing;natural language processing","innovative technologies;potential fascination;children storybooks;innovation;embedded Augmented Reality 2-Dimensional;innovative development;AR children storybook;story reading;learning experience;preschool;young schoolers children;mga kwento ni lola basyang;selected philippine folklore;flat books;Audio-book;Pop-up book;Augmented Reality books","","","","12","IEEE","16 Mar 2022","","","IEEE","IEEE Conferences"
"Toward Rapid Digital Prototyping for Augmented Reality Applications","I. Börsting; V. Gruhn","University of Duisburg-Essen, Essen, Germany; University of Duisburg-Essen, Essen, Germany","2018 IEEE/ACM 4th International Workshop on Rapid Continuous Software Engineering (RCoSE)","30 Aug 2018","2018","","","12","15","In rapid continuous software development, time- and cost-effective prototyping techniques are beneficial through enabling software designers to quickly explore and evaluate different design concepts. Regarding low-fidelity prototyping for augmented reality (AR) applications, software designers are so far restricted to non-digital prototypes, which enable the visualization of first design concepts, but can be laborious in capturing interactivity. The lack of empirical values and standards for designing user interactions in AR-software leads to a particular need for applying end-user feedback to software refinement. In this paper we present the concept of a tool for rapid digital prototyping for augmented reality applications, enabling software designers to rapidly design augmented reality prototypes, without requiring programming skills. The prototyping tool focuses on modeling multimodal interactions, especially regarding the interaction with physical objects, as well as performing user-based studies to integrate valuable end-user feedback into the refinement of software aspects.","","978-1-4503-5745-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8452101","Augmented Reality;prototyping;HCI","Software;Prototypes;Augmented reality;Tools;User interfaces;Standards","augmented reality;human computer interaction;software prototyping;user interfaces","augmented reality applications;rapid continuous software development;cost-effective prototyping techniques;software designers;low-fidelity prototyping;nondigital prototypes;user interactions;AR-software;software refinement;augmented reality prototypes;prototyping tool;software aspects;rapid digital prototyping;valuable end-user feedback","","","","14","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Home Automation using Augmented Reality","A. Kiran; M. K. Chowdary","Department of Computer Science and Engineering, MLR Institute of Technology, Hyderabad, India; Department of Computer Science and Engineering, MLR Institute of Technology, Hyderabad, India","2022 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)","4 Apr 2023","2022","","","1","6","This article suggests integrating augmented reality and other updated platforms for intelligent appliance control. The proposed approach merges mobile AR and IoT to control household appliances. In recent years, smart home controllers have risen quickly, especially for IoT-enabled devices (IoT). Different apps can control different devices. Recently developed AR automates numerous technological equipment. When the mobile camera is focused at a target image, augmented reality (AR) enables virtual pop-ups. Pop-ups allow power on/off with a touch, boosting automation. Using processing, picture tracking, and communication, augmented reality drives applications.","","978-1-6654-6109-2","10.1109/ASSIC55218.2022.10088308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10088308","Augmented Reality;Internet of Things;Automation;Processing;Image Tracking;Cloud;Smart Home Controllers","Home appliances;Target tracking;Automation;Smart homes;Cameras;Boosting;Augmented reality","augmented reality;domestic appliances;home automation;Internet of Things;mobile computing","AR automates numerous technological equipment;augmented reality drives applications;different apps;home automation;household appliances;integrating augmented reality;intelligent appliance control;IoT-enabled devices;mobile camera;smart home controllers;updated platforms;virtual pop-ups","","","","11","IEEE","4 Apr 2023","","","IEEE","IEEE Conferences"
"Automatic cell identification and visualization using digital holographic microscopy with head mounted augmented reality devices: An Overview","T. O’Connor; S. Rawat; A. Markman; B. Javidi","University of Connecticut, Storrs, CT, US; Electrical and Computer Engineering Department, University of Connecticut Storrs, USA; Electrical and Computer Engineering Department, University of Connecticut Storrs, USA; Electrical and Computer Department, University of Connecticut Storrs, USA","2018 17th Workshop on Information Optics (WIO)","17 Feb 2019","2018","","","1","3","We overview a compact and field-portable digital holographic microscopy system based on shearing geometry and integrated with a head mounted augmented reality device for cell identification and visualization. Customized smart glasses containing an external camera connect directly to the 3D-printed system to record holograms of biological specimens. Following hologram acquisition, regions of interest containing biological cells are segmented and digitally reconstructed to generate a three-dimensional (3D) pseudocolor optical path length profile. From the optical path length profiles, morphological features are extracted and inputted into several classification models for comparison including random forest classifier, support vector machines, and k-nearest neighbor, each yielding a high classification accuracy. After successful classification of the target cell, the classification result along with a pseudocolor 3D rendering of the cell’s optical path length profile, and its extracted feature values are displayed to the augmented reality device for the user. The system was tested on both living and non-living samples, including feature extraction from video data of live paramecium. The overviewed system may allow for quickly and conveniently visualizing cells through an augmented reality device and extracting relevant information with potential applications of rapid diagnosis by healthcare professionals working in remote areas. We acknowledge support from the National Science Foundation (Directorate for Engineering (ENG) (NSF ECCS 1545687, NSF/IIS-1422179)).","","978-1-5386-6013-3","10.1109/WIO.2018.8643459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643459","Digital holography;Three-dimensional microscopy;Holographic interferometry;3D imaging;Augmented reality;Medical and biological imaging","Augmented reality;Feature extraction;Microscopy;Image reconstruction;Three-dimensional displays;Optical imaging;Optical recording","augmented reality;biomedical optical imaging;cellular biophysics;feature extraction;health care;holography;image classification;image reconstruction;image segmentation;medical image processing;optical microscopy;support vector machines","visualization;head mounted augmented reality devices;compact field-portable digital holographic microscopy system;augmented reality device;cell identification;customized smart glasses;biological specimens;hologram acquisition;biological cells;three-dimensional pseudocolor optical path length profile;classification models;high classification accuracy;target cell;classification result;pseudocolor 3D rendering;extracted feature values;feature extraction;overviewed system;conveniently visualizing cells;extracting relevant information","","","","12","IEEE","17 Feb 2019","","","IEEE","IEEE Conferences"
"Developing Augmented Reality Application for All-in-one Interface Card","M. Rashmi; S. G. R. Prasad","Dept. of Information Science and Engineering, RV College of Engineering, Bengaluru, India; Dept. of Information Science and Engineering, RV College of Engineering, Bengaluru, India","2019 International Conference on Communication and Electronics Systems (ICCES)","20 Feb 2020","2019","","","96","100","Technologies like Augmented Reality (AR) and Virtual Reality (VR) have been advanced quickly in recent years. Many hardware devices and special techniques have been developed. AR is a technology which integrates the virtual objects with the real time environment. But the critical breakthrough came, when AR spread to the smart phones, this enabled mass spread of AR applications in the field of Education, Manufacturing industries, Military, Medical etc. providing the information about the specified targets to the users. It is also one of the key technologies used in Industry 4.0. AR systems have already reached some level of maturity in educational field and the effectiveness have been widely proven. This paper proposes the development of Marker-based mobile Augmented Reality application, which demonstrates the working of RVCE All-in-one Interface Card.","","978-1-7281-1261-9","10.1109/ICCES45898.2019.9002316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9002316","Augmented Reality;Virtual Reality;Industry 4.0;RVCE All-in-one Interface Card","Cameras;Augmented reality;Conferences;Videos;Three-dimensional displays;Transmission line matrix methods;Smart phones","augmented reality;mobile computing","virtual reality;VR;virtual objects;smart phones;AR applications;marker-based mobile augmented reality application;RVCE all-in-one interface card","","","","12","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"Using augmented reality to treat phobias","M. C. Juan; M. Alcaniz; C. Monserrat; C. Botella; R. M. Banos; B. Guerrero","Universidad Politecnica de Valencia, Spain; Universidad Politecnica de Valencia, Spain; Universidad Politecnica de Valencia, Spain; Universitat Jaume I, Spain; Universidad de Valencia, Spain; Universidad de Valencia, Spain","IEEE Computer Graphics and Applications","7 Nov 2005","2005","25","6","31","37","Virtual reality (VR) is useful for treating several psychological problems, including phobias such as fear of flying, agoraphobia, claustrophobia, and phobia to insects and small animals. We believe that augmented reality (AR) could also be used to treat some psychological disorders. AR and VR share some advantages over traditional treatments. However, AR gives a greater feeling of presence (the sensation of being there) and reality judgment (judging an experience as real) than VR because the environment and the elements the patient uses to interact with the application are real. Moreover, in AR users see their own hands, feet, and so on, whereas VR only simulates this experience. With these differences in mind, the question arises as to the kinds of psychological treatments AR and VR are most suited for. In our system, patients see their own hands, feet, and so on. They can touch the table that animals are crossing or seeing their feet while the animals are running on the floor. They can also hold a marker with a dead spider or cockroach or pick up a flyswatter, a can of insecticide, or a dustpan.","1558-1756","","10.1109/MCG.2005.143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1528430","augmented reality;phobia to cockroaches/spiders;psychological treatments;virtual exposure","Augmented reality;Medical treatment;Virtual reality;Cameras;Animals;Layout;Object detection;Event detection;Psychology;Visualization","patient treatment;augmented reality;psychology;medical computing;behavioural sciences computing","augmented reality;phobia treatment;virtual reality;psychological disorders","Adult;Animals;Cockroaches;Computer Graphics;Computer Simulation;Desensitization, Psychologic;Female;Humans;Male;Models, Theoretical;Multimedia;Phobic Disorders;Spiders;Therapy, Computer-Assisted;Treatment Outcome;User-Computer Interface","97","","12","IEEE","7 Nov 2005","","","IEEE","IEEE Magazines"
"Augmented Reality 3D Displays With Micro Integral Imaging","J. Wang; X. Xiao; H. Hua; B. Javidi","Electrical & Computer Engineering Department, University of Connecticut, Storrs, Connecticut, USA; Electrical & Computer Engineering Department, University of Connecticut, Storrs, Connecticut, USA; 3DVIS Lab, University of Arizona, Tucson, Arizona, USA; 3DVIS Lab, University of Arizona, Tucson, Arizona, USA","Journal of Display Technology","19 May 2017","2015","11","11","889","893","In this paper, we present a 3D augmented reality micro integral imaging display system by combining conventional integral imaging and an augmented reality technique. Compared with conventional integral imaging, our proposed system has two advantages: 1) it provides 3D augmented reality display capability and 2) it has a compact design. To validate the feasibility of our proposed method, we experimented with a 3D scene and used two computer-generated objects for augmented reality. By combining the captured 2D elemental images of the 3D object and the computer generated virtual objects, we reconstruct 3D images for the augmented reality micro integral imaging display system. To the best of our knowledge, the first report on a video see through 3D augmented reality display has been experimentally demonstrated with a micro integral imaging display system. The proposed 3D system has potential to be applied to the head mounted display system due to its small form factor.","1558-9323","","10.1109/JDT.2014.2361147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915663","Augmented reality;displays;integral imaging;micro display;3D display","Three-dimensional displays;Imaging;Augmented reality;Image reconstruction;Lenses;Computers;Arrays","augmented reality;image processing;three-dimensional displays","augmented reality;3D displays;micro integral imaging;computer-generated objects;micro display","","40","","31","IEEE","2 Oct 2014","","","IEEE","IEEE Journals"
"Research on Automatic Dance Arrangement Method Based on Augmented Reality Technology","M. Lou","Hebei University of Economics and Business, Shijiazhuang, China","2020 IEEE International Conference on Industrial Application of Artificial Intelligence (IAAI)","1 Feb 2021","2020","","","427","431","In order to improve the accuracy of augmented reality for automatic choreography, it is necessary to perform automatic choreography and augmented reality processing. This paper proposes an automatic choreography motion feature detection technology based on augmented reality image feature detection, which combines multi-resolution image recognition and detection methods to perform automatic choreography augmented reality computer vision image feature analysis and dance key motion feature point detection processing, and track tracking method based on morphology. According to the detailed feature collection results of dance automatic choreography augmented reality computer vision images, the region segmentation of dance automatic choreography augmented reality is carried out by adopting three-dimensional recombination method of key motion feature points data of computer vision dance, the feature analysis of dance automatic choreography augmented reality is carried out by combining fuzzy image dance key motion feature points detection technology, the fringe pattern analysis of computer vision is carried out by adopting edge contour feature detection method, the error correction and compensation processing of dance motion feature detection are carried out according to light resolution characteristics, and the motion feature detection of dance automatic choreography is realized by combining shape feature distribution. The simulation results show that this method has better resolution of atlas and higher accuracy of parameter estimation of key dance action feature points, which effectively realizes the action correction of automatic dance arrangement and improves the accuracy of automatic dance arrangement.","","978-1-6654-0471-6","10.1109/IAAI51705.2020.9332864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332864","augmented reality technology;Dance;Automatic arrangement;Feature points;morphology","Analytical models;Three-dimensional displays;Tracking;Feature detection;Computational modeling;Feature extraction;Augmented reality","augmented reality;computer vision;edge detection;feature extraction;humanities;image motion analysis;image resolution;image segmentation;shape recognition;stereo image processing","augmented reality;image feature detection;computer vision;feature analysis;fuzzy image dance key motion feature points;edge contour feature detection;dance motion feature detection;shape feature distribution;dance automatic choreography;automatic choreography motion feature detection;automatic dance arrangement;multiresolution image recognition;region segmentation;three dimensional recombination;fringe pattern analysis","","","","10","IEEE","1 Feb 2021","","","IEEE","IEEE Conferences"
"Integrating Augmented Reality in Science Education in South Africa: Applications in the Mancosa iTEACHlab","V. Mbonye; R. Ebrahim","iTEACHlab, Mancosa School of Education, Mancosa, Durban, South Africa; iTEACHlab, Mancosa School of Education, Mancosa, Durban, South Africa","2022 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)","22 Aug 2022","2022","","","1","5","Integrating augmented reality (AR) in education merges the physical and virtual worlds to exhibit multi-dimensional content that would be difficult to display in a traditional classroom setting. Employing augmented reality in science education results in favourable outcomes since it enables learners to acquire and comprehend abstract science concepts. To achieve these positive outcomes, augmented reality must be successfully integrated into science lessons. However, there is limited material on how augmented reality can be implemented into science education in South Africa. Case studies enable individuals to learn from their experiences and to discover approaches that shape and accelerate progress toward resolving challenges. The purpose of this case study is to share experiences from augmented reality installations at the Mancosa school of education’s iTEACHlab. Also, the article presents an overview of augmented reality (AR) and its educational applications in South Africa. The paper adopts a document analysis technique to collect and analyse the data. Thus, it provides crucial information on how educational institutions might employ augmented reality into science education.","","978-1-6654-8422-0","10.1109/icABCD54961.2022.9856083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9856083","Augmented reality;Education;Emerging technologies;iTEACHlab;Teachers","Text analysis;Shape;Education;Big Data;Data communication;Artificial intelligence;Augmented reality","augmented reality;computer aided instruction;data analysis;educational institutions","South Africa;augmented reality installations;science education;Mancosa iTEACHlab;document analysis technique;data analysis","","","","32","IEEE","22 Aug 2022","","","IEEE","IEEE Conferences"
"Learning Media Design Based on Augmented Reality Introduction to Rare Plants","A. Syahputra; A. Sanjaya; Y. H. Agustin; W. S. Prasetya; Nurhayati; E. T. Siregar","Faculty of Engineering and Computer Science, Potensi Utama University, Medan, Indonesia; Faculty of Information Technology, Nusa Mandiri University, Jakarta Timur, Indonesia; Department of Informatics, Garut Institute of Technology, Garut, Indonesia; STMIK Pontianak, Pontianak, Indonesia; Faculty of Engineering and Computer Science, Potensi Utama University, Medan, Indonesia; Faculty of Engineering and Computer Science, Potensi Utama University, Medan, Indonesia","2021 3rd International Conference on Cybernetics and Intelligent System (ICORIS)","28 Dec 2021","2021","","","1","4","This research is motivated by the lack of technology-based learning media, namely Augmented Reality, the use of Augmented Reality can be used as an interactive and interesting learning media solution. By utilizing Augmented Reality technology, the introduction of rare plants that were originally presented in the form of images can be added with 3-dimensional information that is displayed virtually which will later use a smartphone device, so that the learning process is more interesting. The purpose of this research is to design learning media based on Augmented Reality in recognizing rare plants, this is because Augmented Reality is an application that can use a database in the form of 3-dimensional animation that affects students in learning activities. The media contained in Augmented Reality is a combination of real illustrations in the technological process.","","978-1-6654-2580-3","10.1109/ICORIS52787.2021.9649513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649513","Learning Media;Augmented Reality;Rare Plants","Databases;Media;Animation;Intelligent systems;Augmented reality;Cybernetics","augmented reality;computer aided instruction;computer animation;multimedia computing;smart phones;stereo image processing","media design;augmented reality;rare plants;technology-based learning media;interactive learning media solution;smartphone device;3-dimensional animation","","","","14","IEEE","28 Dec 2021","","","IEEE","IEEE Conferences"
"PostAR: Design a Responsive Reading System with Multiple Interactions for Campus Augmented Posters","S. Liu; S. Jang; W. Woo","UVR Lab, GSCT, KAIST; UVR Lab, GSCT, KAIST; UVR Lab, GSCT, KAIST","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","114","117","Augmented reality is a technology which extends measureless contents in the virtual space and makes actual objects not limited in the physical properties. As the most popular cultural media among the campus, the poster have its shortcoming of offering restricted information. In this paper, we introduce a responsive poster-reading system which generates diverse contents step by step with body-based and hand-based interactions, and a design guideline which applies for corresponding posters. The proposed method is able to provide users with a user-friendly, immersive and intuitive experience.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951921","MAR;augmented poster;visualization;interaction;guidance","Augmented reality;Three-dimensional displays;TV;Media;Avatars;Two dimensional displays","augmented reality;human computer interaction","PostAR;campus augmented posters;augmented reality;measureless contents;virtual space;actual objects;physical properties;cultural media;restricted information;responsive poster-reading system;diverse contents step;hand-based interactions;design guideline;body-based interactions;user-friendly experience;immersive experience;intuitive experience","","","","8","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"An Exploratory Study of Augmented Reality Marketing in UAE","I. Alotaibi","School of Management & Commerce, Amity University Dubai, United Arab Emirates","2021 1st International Conference on Artificial Intelligence and Data Analytics (CAIDA)","11 May 2021","2021","","","271","272","The main aim of this research paper is to understand whether firms in the UAE should take advantage of the augmented reality technology, and implement it within their marketing strategies. The paper will first explore what augmented reality marketing, the benefits of augmented reality marketing, and delve into why firms should focus more on using augmented reality in their marketing. Primary research carried out locally in the UAE to have an in depth understanding of the consumer preferences and attitudes towards augmented reality in marketing. Results showed that consumers do indeed have a positive preference towards augmented reality marketing. Recommendations were given along with further research directions.","","978-1-6654-1511-8","10.1109/CAIDA51941.2021.9425115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425115","Augmented Reality;marketing;strategy;consumers;e-marketing;AI","Data analysis;Artificial intelligence;Augmented reality","augmented reality;marketing data processing","UAE;augmented reality marketing;consumer preferences","","","","10","IEEE","11 May 2021","","","IEEE","IEEE Conferences"
"Virtual Reality Simulation for Prototyping Augmented Reality","A. M. Wafaa; N. D. Bonnefoy; E. Dubois; P. Torguet; J. -P. Jessel","IRIT Laboratory, University of Toulouse III, Toulouse, France; IRIT Laboratory, University of Toulouse III, Toulouse, France; IRIT Laboratory, University of Toulouse III, Toulouse, France; IRIT Laboratory, University of Toulouse III, Toulouse, France; IRIT Laboratory, University of Toulouse III, Toulouse, France","2008 International Symposium on Ubiquitous Virtual Reality","18 Jul 2008","2008","","","55","58","This paper presents an architecture to support fast prototyping of augmented reality systems, based on virtual reality. The architecture defines simulation services separated from other aspects of the system. These services support incremental evolution of simulated prototypes into nonsimulated systems. Focus is also placed on user interaction,through the definition of an interaction architecture that uniformly handles both input and tracking. Both architectures are component-oriented, favoring white-box reuse.","","978-0-7695-3259-2","10.1109/ISUVR.2008.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568646","incremental prototyping;simulation based prototyping;interaction architecture","Virtual reality;Virtual prototyping;Augmented reality;Prototypes;Software prototyping;System testing;Acceleration;Hardware;Laboratories;Large-scale systems","augmented reality;software prototyping","virtual reality simulation;augmented reality;prototyping;incremental evolution;component-oriented;white-box reuse","","8","","7","IEEE","18 Jul 2008","","","IEEE","IEEE Conferences"
"A tangible user interface using spatial Augmented Reality","L. K. Y. Chan; H. Y. K. Lau","Department of Industrial and Manufacturing Systems Engineering, University of Hong Kong, Hong Kong, China; Department of Industrial and Manufacturing Systems Engineering, University of Hong Kong, Hong Kong, China","2010 IEEE Symposium on 3D User Interfaces (3DUI)","29 Apr 2010","2010","","","137","138","In this paper, we describe the novel implementation of a tangible user interface framework, namely the MagicPad, inspired by the concept of Spatial Augmented Reality. By using an Infrared pen with any flat surface, such as a paper pad that receives projected images from a projector, a user is able to perform a variety of interactive visualization and manipulation in the 3D space. Two implementations using the MagicPad framework are presented, which include the magic lenses like interface inside a CAVE-like system and a virtual book in an art installation.","","978-1-4244-6847-8","10.1109/3DUI.2010.5444699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444699","augmented reality;3D user interface","User interfaces;Augmented reality;Virtual environment;Lenses;Virtual reality;Manufacturing industries;Manufacturing systems;Systems engineering and theory;Art;Hardware","augmented reality;user interfaces;virtual reality","tangible user interface;spatial augmented reality;MagicPad;infrared pen;interactive visualization-manipulation;CAVE-like system;magic lenses;virtual book;art installation","","8","","8","IEEE","29 Apr 2010","","","IEEE","IEEE Conferences"
"Photorealistic rendering for Augmented Reality: A global illumination and BRDF solution","S. Pessoa; G. Moura; J. Lima; V. Teichrieb; J. Kelner","Virtual Reality and Multimedia Research Group Informatics Center, Federal University of Pernambuco (UFPE), Brazil; Virtual Reality and Multimedia Research Group Informatics Center, Federal University of Pernambuco (UFPE), Brazil; Virtual Reality and Multimedia Research Group Informatics Center, Federal University of Pernambuco (UFPE), Brazil; Virtual Reality and Multimedia Research Group Informatics Center, Federal University of Pernambuco (UFPE), Brazil; Virtual Reality and Multimedia Research Group Informatics Center, Federal University of Pernambuco (UFPE), Brazil","2010 IEEE Virtual Reality Conference (VR)","8 Apr 2010","2010","","","3","10","This paper presents a solution for the photorealistic rendering of synthetic objects into dynamic real scenes, in Augmented Reality applications. In order to achieve this goal, an Image Based Lighting approach is used, where environment maps with different levels of glossiness are generated for each virtual object in the scene at every frame. Due to this, illumination effects, such as color bleeding and specular reflections, can be simulated for virtual objects in a consistent way. A unifying sampling method for the spherical harmonics transformation pass is also used. It is independent of map format and does not need to apply different weights for each sample. The developed technique is combined with an extended version of Lafortune Spatial BRDF, featuring Fresnel effect and an innovative tangent rotation parameterization. The solution is evaluated in various Augmented Reality case studies, where other features like shadowing and lens effects are also exploited.","2375-5334","978-1-4244-6238-4","10.1109/VR.2010.5444836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444836","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial, Augmented, and Virtual Realities;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Color, Shading, Shadowing, and Texture","Augmented reality;Lighting;Layout;Computer graphics;Virtual reality;Rendering (computer graphics);Hemorrhaging;Optical reflection;Sampling methods;Shadow mapping","augmented reality;image colour analysis;rendering (computer graphics);sampling methods","photorealistic rendering;augmented reality;global illumination;BRDF solution;image based lighting approach;color bleeding;specular reflection;sampling method;spherical harmonics transformation pass;Fresnel effect;tangent rotation parameterization;bidirectional reflectance distribution function","","29","1","41","IEEE","8 Apr 2010","","","IEEE","IEEE Conferences"
"Objective measures for the effectiveness of augmented reality","M. A. Livingston; C. Zanbaka; J. E. Swan; H. S. Smallman","Virtual Reality Laboratory, Naval Research Laboratory, Inc., Washington D.C., DC, USA; Department of Computer Science, University of North Carolina, Charlotte, USA; Department of Computer Science and Engineering, Mississippi State University, USA; Naval Research Laboratory, Inc., Washington D.C., DC, USA","IEEE Proceedings. VR 2005. Virtual Reality, 2005.","15 Aug 2005","2005","","","287","288","Augmented reality (AR) systems present a mixture of virtual and real objects. The challenge for AR system evaluators is how to tell whether the virtual world is effective at conveying the sense of reality. It may never be possible or even necessary to determine whether the user is truly fooled in all situations or is merely ""suspending disbelief,"" but one can objectively measure the effectiveness of an AR environment with a task-based approach. We present the results of our first such experiment, involving low-level perceptual tasks of recognition and depth matching.","2375-5334","0-7803-8929-8","10.1109/VR.2005.1492798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1492798","","Augmented reality;Displays;Laboratories;Performance evaluation;Needles;Computer science;Biomedical optical imaging;Graphics;Chromium;Graphical user interfaces","augmented reality;graphical user interfaces;visual perception","objective measures;virtual objects;virtual world;suspending disbelief;augmented reality environment effectiveness;perceptual tasks;recognition;depth matching;presence;perception;user interface","","8","","7","IEEE","15 Aug 2005","","","IEEE","IEEE Conferences"
"Real-time Physics-based Interaction in Augmented Reality","J. Li; H. Deng; Y. Gao; A. Chen; Z. Song; A. Hao","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University","2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","573","574","We propose a unified Augmented Reality (AR) based framework that combines the real-time physical multi-material simulation model and the efficient free-hand gesture interaction method. First, we employ a simple Red-Green-Blue-Depth (RGBD) camera to quickly acquire 3D environmental data to build the static boundary conditions. The real-time gestures are then detached and used as dynamic objects that interact with physical simulations. Finally, the calculated lighting parameters are used for real-time rendering and virtual-reality fusion. Our framework enables users to interact with various physical simu-lations in AR scenes, which considerably expands the applications of the fusion of AR and physical simulations.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108651","Human-centered computing;Human computer interaction (HCI);Interaction devices-Haptic devices;Computing methodologies;Computer graphics;Animation;Physical simulation","Solid modeling;Three-dimensional displays;Computational modeling;Conferences;Lighting;User interfaces;Rendering (computer graphics)","augmented reality;cameras;gesture recognition;human computer interaction;image colour analysis;rendering (computer graphics);robot vision;solid modelling;virtual reality","3D environmental data;calculated lighting parameters;free-hand gesture interaction method;physical simu-lations;physical simulations;real-time gestures;real-time physical multimaterial simulation model;real-time rendering;simple Red-Green-Blue-Depth camera;static boundary conditions;time physics-based interaction;unified Augmented Reality based framework;virtual-reality fusion","","","","5","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"An evaluation of graphical context when the graphics are outside of the task area","C. M. Robertson; B. MacIntyre; B. N. Walker","School of Interactive Computing, GVU Center, USA; School of Interactive Computing, GVU Center, USA; School of Psychology, GVU Center, Georgia Institute of Technology, USA","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","73","76","An ongoing research problem in Augmented Reality (AR) is to improve tracking and display technology in order to minimize registration errors. However, perfect registration is not always necessary for users to understand the intent of an augmentation. This paper describes the results of an experiment to evaluate the effects of graphical context in a Lego block placement task when the graphics are located outside of the task area. Four conditions were compared: fully registered AR; non-registered AR; a heads-up display (HUD) with the graphics always visible in the field of view; and a HUD with the graphics not always visible in the field of view. The results of this experiment indicated that registered AR outperforms both non-registered AR and graphics displayed on a HUD. The results also indicated that non-registered AR does not offer any significant performance advantages over a HUD, but is rated as less intrusive and can keep non-registered graphics from cluttering the task space.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637328","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Evaluation/methodology;augmented reality;communicative intent;augmented environments;human-computer interaction","Graphics;Augmented reality;Sensors;Maintenance engineering;Psychology;Sensor systems;Cameras","augmented reality","graphical context;augmented reality;AR;registration error minimization;Lego block placement task;heads-up display;human-computer interaction","","33","","13","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Reconstructing while registering: a novel approach for markerless augmented reality","G. Simon; M. . -O. Berger","LORIA UHP Nancy I INRIA Lorraine, France; LORIA UHP Nancy I INRIA Lorraine, France","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","285","293","This paper addresses the registration problem for unprepared multi-planar scenes. An interactive process is proposed to obtain accurate results using only the texture information of planes. In particular, classical preparation steps (camera calibration, scene acquisition) are greatly simplified, since they are included in the on-line registration process. Results are shown on indoor and outdoor scenes. Videos are available at url http://www.loria.fr//spl tilde/gsimon/Ismar.","","0-7695-1781-1","10.1109/ISMAR.2002.1115118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115118","","Augmented reality;Layout;Cameras;Calibration;Magnetic sensors;Uniform resource locators;Video sequences;Application software;Learning systems;Multimedia communication","augmented reality;image registration;image reconstruction;calibration","unprepared multi-planar scenes;markerless augmented reality;interactive process;planar texture information;camera calibration;scene acquisition;on-line registration process;outdoor scenes;indoor scenes;reconstruction","","34","2","17","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"A 3D Flexible and Tangible Magic Lens in Augmented Reality","J. Looser; R. Grasset; M. Billinghurst","HIT Laboratory NZ, University of Canterbury, Christchurch, New Zealand; HIT Laboratory NZ, University of Canterbury, Christchurch, New Zealand; HIT Laboratory NZ, University of Canterbury, Christchurch, New Zealand","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","51","54","The Magic Lens concept is a focus and context technique which facilitates the visualization of complex and dense data. In this paper, we propose a new type of 3D tangible Magic Lens in the form of a flexible sheet. We describe new interaction techniques associated with this tool, and demonstrate how it can be applied in different AR applications.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538825","H.5.2 [Information Systems]: Information Interfaces and Presentation-User Interfaces","Lenses;Augmented reality;Graphics;Hardware;Data visualization;User interfaces;Filtering;Glass;Information systems;Context awareness","augmented reality;data visualisation;user interfaces","3D tangible magic lens;augmented reality;dense data visualization;flexible sheet;interaction techniques","","30","","21","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Measurement of absolute latency for video see through augmented reality","T. Sielhorst; W. Sa; A. Khamene; F. Sauer; N. Navab","Chair for Computer Aided Medical Procedures, Technische Universität, Munich, Germany; Chair for Computer Aided Medical Procedures, Technische Universität, Munich, Germany; Imaging and Visualization Department, Siemens Corporate, NJ, USA; Imaging and Visualization Department, Siemens Corporate, NJ, USA; Chair for Computer Aided Medical Procedures, Technische Universität, Munich, Germany","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","215","220","Latency is a key property of video see through AR systems since users' performance is strongly related to it. However, there is no standard way of latency measurement of an AR system in the literature. We have created a stable and comparable way of estimating the latency in a video see through AR system. The latency is estimated by encoding the time in the image and decoding the time after camera feedback. We have encoded the time as a translation of a circle in the image. The cross ratio has been used as an image feature that is preserved in a projective transformation. The encoding allows for a simple but accurate way of decoding. We show that this way of encoding has an adequate accuracy for latency measurements. As the method allows for a series of automatic measurements we propose to visualize the measurements in a histogram. This histogram reveals meaningful information about the system other than the mean value and standard deviation of the latency. The method has been tested on four different AR systems that use different camera technology, resolution and frame rates.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538850","H.5.2 [Information Interfaces And Presentation]: User Interfaces-Standardization;Benchmarking","Delay;Augmented reality;Decoding;Cameras;Encoding;Histograms;Measurement standards;Image coding;Feedback;Visualization","augmented reality;video coding","video see through augmented reality;absolute latency;camera feedback;image coding","","25","","6","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Effects of sizes and shapes of props in tangible augmented reality","E. Kwon; G. J. Kim; S. Lee","Digital Experience Laboratory, Korea University, Seoul, South Korea; Digital Experience Laboratory, Korea University, Seoul, South Korea; 3DViz and Imaging System Laboratory, University of Arizona Tucson, Tempe, AZ, USA","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","201","202","In this paper, we investigated the effect of relative difference between the virtual object and tangible prop in its size and shape in terms of usability. We have found the obvious fact that in general that manipulation is more efficient with equally sized/shaped prop and virtual objects. In addition, when decoupled, the size difference factor did not matter. While an additional experiment (in progress) is needed to confirm the true effect of shape difference, we posit that prop design should concentrate on representing the critical shape features for a given class of objects the prop is to represent. Humans are adept at recognizing and identifying objects even if there are shown at different scales and in different angles. This ability, called ldquoconstancyrdquo is weaker in the dimension of shapes, e.g. compared to sizes, which is another reason to suspect shape to be a more critical factor for effective prop design. Another significant factor, in the design of props (not treated in this paper) is the prop to virtual object alignment (which can affect the task performance in terms of finding and feeling for a stable grasp). For instance, possible choices for spatially registering a prop to a virtual object (or vice versa) can be about their respective center of gravity, about the chosen surface, etc. Future experiments and prop design method will have to take this into account as well.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336463","","Augmented reality;Usability;Testing;Shape control;Laboratories;USA Councils;Guidelines;Floppy disks;Haptic interfaces;Product design","augmented reality","tangible augmented reality;tangible prop design;virtual object alignment;prop shape;prop size","","21","","7","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Perception thresholds for augmented reality navigation schemes in large distances","M. Tonnis; L. Klein; G. Klinker","Fakultät für InformatikBoltzmannstrae, Technische Universität, Garching, Germany; Fakultät für InformatikBoltzmannstrae, Technische Universität, Garching, Germany; Fakultät für InformatikBoltzmannstrae, Technische Universität, Garching, Germany","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","189","190","Because the resolution of see-through displays is lower than the resolution of the human eye, perception of AR schemes is complicated in large distances. To discover, how design issues of perception correlate with presentation in large distances, we developed three different variants of arrow-based route guidance systems. With a large-scale head-up display having a large focal depth, we tested the variants under different conditions on perception and interpretability.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637360","H.1.2 [Models and Principles]: User/Machine Systems—Human information processing;H.5.2 [Information Interfaces and Presentation]: User Interfaces—Prototyping","Distance measurement;Shape;Navigation;Augmented reality;Visualization;Pixel;Humans","augmented reality;head-up displays;human factors;user interfaces","perception thresholds;augmented reality navigation;see-through display;arrow-based route guidance system;head-up display;user interface","","17","","6","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Handling occlusion in augmented reality systems: a semi-automatic method","V. Lepetit; M. . -O. Berger","LORIA INRIA-Lorraine, Villers-Les-Nancy, France; LORIA INRIA-Lorraine, Villers-Les-Nancy, France","Proceedings IEEE and ACM International Symposium on Augmented Reality (ISAR 2000)","6 Aug 2002","2000","","","137","146","We present a semi-automatic approach to solve occlusion in AR systems. Once the occluding objects have been segmented by hand in selected views called key-frames, the occluding boundary is computed automatically in the intermediate views. To do that, the 3D reconstruction of the occluding boundary is achieved from the outlined silhouettes. This allows us to recover a good prediction of the 2D occluding boundary which is refined using region-based tracking and active contour models. As a result, we get an accurate estimation of the occluding objects. Various results are presented demonstrating occlusion resolution on real video sequences. Results and videos are available at the URL: http://www.loria.fr/-lepetit/Occlusions.","","0-7695-0846-4","10.1109/ISAR.2000.880937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=880937","","Augmented reality;Shape;Image reconstruction;Video sequences;Layout;Application software;Active contours;Predictive models;Uniform resource locators;Computer applications","augmented reality;user interfaces;image segmentation;image reconstruction;image sequences","occlusion handling;augmented reality;semi-automatic approach;image segmentation;key-frames;3D image reconstruction;region-based tracking;active contour models;video sequences","","16","14","9","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Augmented reality haptics: using ARToolKit for display of haptic applications","M. Adcock; M. Hutchins; C. Gunn","CSIRO, Australia; CSIRO, Australia; CSIRO Australia Matt","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","1","2","This paper described the integration of the ARToolKit with the Reachin Core Technology API. The result is a system capable of providing a coherent mix of real world video, computer haptics and computer graphics. A key feature is that new applications can be rapidly developed. Ultimately, this system is used to support rich object based collaboration between face-to-face and remote participants.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320415","","Haptic interfaces;Augmented reality;Rendering (computer graphics);Computer displays;Application software;Collaboration;Cameras;Imaging phantoms;Computer graphics;Layout","augmented reality;haptic interfaces;groupware;application program interfaces","augmented reality;ARToolKit;Reachin Core Technology API;real world video;computer haptics;computer graphics;haptic interaction;object-based collaboration","","11","2","10","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"Automatic contour model creation out of polygonal CAD models for markerless Augmented Reality","J. Platonov; M. Langer",Metaio GmbH; Metaio GmbH,"2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","75","78","We present a solution for automatic extraction of contour models out of polygonal CAD models. Such contour models can be used for markerless initialization and tracking purposes. To create a contour model we synthesize different views of the object using its CAD model. During the view generation we alternate the camera pose as well as light conditions in order to extract the most stable contours in terms of illumination invariance and view independence. We project the extracted 2D edges back into the 3D space and accumulate for every 3D point statistics over different views describing its visibility and stability under different illumination conditions. After filtering out all 3D points with probability below a certain threshold value we use the Euclidean Minimum Spanning Tree algorithm to get the connected contours out of the 3D point cloud. The result is a B-Spline or VRML representation of the most stable contours.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538829","I.4.8 [Image processing and computer vision]: Scene Analysis-Tracking","Augmented reality;Cameras;Lighting;Layout;Costs;Statistics;Stability;Probability;Filtering algorithms;Clouds","augmented reality;CAD;computational geometry;solid modelling;splines (mathematics);trees (mathematics)","automatic contour extraction model;industrial polygonal CAD model;markerless augmented reality;illumination invariance;2D edge extraction;euclidean minimum spanning tree algorithm;3D point cloud;B-spline contour model;VRML representation","","9","1","16","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Augmented reality techniques in games","D. Schmalstieg","Graz University of Technology, Austria","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","176","177","As a consequence of technical difficulties such as unreliable tracking, many AR applications get stuck in the ""how to implement"" phase rather than progressing to the ""what to show"" phase driven by information visualization needs rather than basic technology. In contrast, most of today's computer games are set in a fairly realistic 3D environment, and unlike many AR applications, game interfaces undergo extensive usability testing. This creates the interesting situation that games can be perfect simulators of AR applications, because they are able to show perfectly registered ""simulated AR"" overlays on top of a real-time environment. This work examines how some visualization and interaction techniques used in games can be useful for real AR applications.","","0-7695-2459-1","10.1109/ISMAR.2005.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544681","","Augmented reality;Cameras;Games;Application software;Mice;Visualization;Keyboards;Displays;Computer interfaces;Usability","augmented reality;computer games;graphical user interfaces;real-time systems","augmented reality techniques;computer games;AR application;realistic 3D environment;game interfaces;usability testing;real-time environment","","7","1","6","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Vesp'R - Transforming Handheld Augmented Reality","E. Kruijff; E. Veas","Institute for Computer Graphics and Vision, Graz University of Technology, Austria; Institute for Computer Graphics and Vision, Graz University of Technology, Austria","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","277","278","This paper presents first results of an interaction design study performed for a novel handheld interaction system. Human factors of mid-size, self-containing wearable computer systems are explored.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538865","Handheld AR;spatial user interface","Augmented reality;Ergonomics;Fatigue;Computer graphics;Human factors;Personal digital assistants;Cameras;Displays;Wearable computers;Cellular phones","augmented reality;wearable computers","augmented reality;handheld interaction system;human factors;wearable computer systems","","6","3","11","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Augmented reality (AR) for assembly processes - an experimental evaluation","S. Wiedenmaier; O. Oehme; L. Schmidt; H. Luczak","Institute of Industrial Engineering and Ergonomics, RWTH Aachen University of Technology, Aachen, Germany; Institute of Industrial Engineering and Ergonomics, RWTH Aachen University of Technology, Aachen, Germany; Institute of Industrial Engineering and Ergonomics, RWTH Aachen University of Technology, Aachen, Germany; Institute of Industrial Engineering and Ergonomics, RWTH Aachen University of Technology, Aachen, Germany","Proceedings IEEE and ACM International Symposium on Augmented Reality","6 Aug 2002","2001","","","185","186","A PAL-video-camera (Toshiba ACM 413 E with 2.2 mm lens) and a HMD were connected to a Silicon Graphics Workstation O2 (SGI). As the HMD, a clip-on display (MircoOptical) with a 640x480 resolution was used. The clip-on display can be used like other HMDs in video see-through mode. It works like a little monitor in front of the user's eyes which covers just a small part of his field of view. The assembling person was not restricted by the inconveniences of the video see-through mode. Test subjects have to grasp a little wooden cylinder in a box. By passing a flap to accede to the cylinder the workstation gets a mouse signal to write the time into a log-file and to show the assembly position on a pegboard with 48 holes in the clip-on display. For the tests 12 apprentices and students with similar practical experience in mechanics and electronics were selected.","","0-7695-1375-1","10.1109/ISAR.2001.970534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=970534","","Augmented reality;Assembly;Displays;Workstations;Electronic equipment testing;Lenses;Silicon;Graphics;Monitoring;Eyes","augmented reality;head-up displays;assembling","PAL-video-camera;Toshiba ACM 413 E;HMD;Silicon Graphics Workstation 02;SGI;MircoOptical;video see-through mode;head mounted display;augmented reality;assembly processes","","5","6","4","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"A concept for the application of augmented reality in manual gas metal arc welding","P. Tschirner; B. Hillers; A. Graser","Institute of Automation, University of Brethemen, Bremen, Germany; Institute of Automation, University of Brethemen, Bremen, Germany; Institute of Automation, University of Brethemen, Bremen, Germany","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","257","258","The problem of creating manual welds of constant high quality results from missing optical information during the actual welding process. Due to the extreme brightness conditions in arc welding and the use of protective glasses, even experienced welders can hardly recognize details of the welding process and the environment. This paper describes a new research project for the development of a support system for the welder.","","0-7695-1781-1","10.1109/ISMAR.2002.1115098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115098","","Augmented reality;Welding;Portable computers;Protection;Glass;Cameras;Computer displays;Data mining;Brightness;Image quality","production engineering computing;user interfaces;augmented reality;image processing;helmet mounted displays;arc welding","augmented reality;manual gas metal arc welding;missing optical information;extreme brightness conditions;protective glasses;head-mounted display","","5","64","3","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Tutorial 3: SOFA, an Open-Source Framework for Physics Simulation in Augmented Reality","",,"2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","xxxii","xxxii","This tutorial will shortly review the background in physics simulation and introduce the main principles of the SOFA framework. Examples of SOFA simulations will be presented. The afternoon will be more ""hands-on"" oriented starting with an interactive user tutorial, followed by a developer tutorial. Further to this tutorial, you should have all the basis to build your own physics simulation. The SOFA tutorial at ISMAR is the opportunity to discover an open-source physics engine and include physics in your AR applications. From a starting up to a developer level, this tutorial focus on the wide topic of physics simulation. Not only will the physics of SOFA add realism into your AR application, but it might allow you to address new research and industrial challenges. Moreover, the flexible architecture of the software and the large international open-source community will make your start with SOFA easier. Attend the tutorial and join the community! This tutorial is done once a year. A global publication about SOFA has been published in 2012: Multi-Model Framework for Interactive Physical Simulation. All publications based on SOFA can be found here: https://www.sofa-framework.org/applications/publications/.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088435","","Augmented reality","augmented reality;physics computing;public domain software","SOFA;open-source framework;physics simulation;augmented reality","","1","","","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"1st International Workshop on Recognition Based Augmented Reality Summary","K. Kise; T. Toyama; A. Shimada; W. Mayol-Cuevas","Osaka Prefecture University, Japan; German Research Center for Artificial Intelligence, Germany; Kyushu University, Japan; University of Bristol, UK","2015 IEEE International Symposium on Mixed and Augmented Reality Workshops","3 Dec 2015","2015","","","74","74","Summary form only given. The technology of AR has evolved to a point where there are well established methods to annotate the world using known markers, and more recently, the spatial 3D information on the environment itself. This has resulted in AR been nowadays widely experienced by a large number of people in a variety of situations. However, in order to take AR to the next level, it is essential to consider methods that allow the automated detection of objects, materials and shapes. One way to fulfil this goal is to develop AR that incorporates the recognition of visual object detection and use these to enhance the places and situations where current AR methods have not explored. Of interest for this goal are methods that include large-scale object recognition to distinguish and locate objects or materials, and go beyond using traditional markers. This workshop will showcase some examples of this nascent area and hopes to attract discussion among the ISMAR community of how best to incorporate object and pattern recognition that takes AR to the next levels.","","978-1-4673-8471-1","10.1109/ISMARW.2015.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344760","","Artificial intelligence;Augmented reality;Conferences;Visualization;Object detection;Three-dimensional displays;Shape","augmented reality;object recognition;object tracking","recognition based augmented reality;AR technology;spatial 3D information;automated object detection;visual object detection recognition;large-scale object recognition;ISMAR community;pattern recognition","","","","","IEEE","3 Dec 2015","","","IEEE","IEEE Conferences"
"Object-oriented toolkit for augmented reality","C. Reimann; S. Engel; V. Paelke","C-Laboratory, Paderborn University, Germany; C-Laboratory, Paderborn University, Germany; C-Laboratory, Paderborn University, Germany","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","32","34","In this paper, we describe the new OO-ARToolKit which contains a number of improvements over the original version by H. Kato and M. Billinghurst. We explain the new software-architecture and the advantages which have been gained by using it. Furthermore, we deliver an insight into the internal processes and describe the easier approach to working with the new OO-ARToolKit.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320423","","Augmented reality;Libraries;Linux;Object oriented programming;Image reconstruction;Application software;Software architecture;Filters;Subspace constraints;Pattern matching","augmented reality;object-oriented programming;software architecture","object-oriented toolkit;augmented reality;OO-ARToolKit;software architecture","","","","4","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"Stencil Marker: Designing Partially Transparent Markers for Stacking Augmented Reality Objects","X. Zhang; J. Lundgren; Y. Mesaki; Y. Hiroi; Y. Itoh",Tokyo Institute of Technology; Tokyo Institute of Technology; Tokyo Institute of Technology; Tokyo Institute of Technology; Tokyo Institute of Technology,"2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","255","257","We propose a transparent colored AR marker that allows 3D objects to be stacked in space. Conventional AR markers make it difficult to display multiple objects in the same position in space, or to manipulate the order or rotation of objects. The proposed transparent colored markers are designed to detect the order and rotation direction of each marker in the stack from the observed image, based on mathematical constraints. We describe these constraints to design markers, the implementation to detect its stacking order and rotation of each marker, and a proof-of-concept application Totem Poles. We also discuss the limitations of the current prototype and possible research directions.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288474","Human-centered computing;Visualization;Visualization techniques;Treemaps;Human-centered computing;Visualization;Visualization design and evaluation methods","Human computer interaction;Three-dimensional displays;Image color analysis;Stacking;Prototypes;Augmented reality","augmented reality;data visualisation;human computer interaction","partially transparent markers;rotation direction;stacking order;stencil marker;augmented reality object stacking;transparent colored AR marker;3D object stacking;object manipulation;mathematical constraints;Totem Poles","","","","7","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Photometric registration by adaptive high dynamic range image generation for augmented reality","Yusaku Nishina; Bunyo Okumura; Masayuki Kanbara; Naokazu Yokoya","Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","53","56","This paper describes photometric registration for augmented reality (AR) using a high-dynamic-range (HDR) image. In photorealistic AR, estimating the lighting environment of virtual objects is difficult because of low dynamic range cameras. In order to overcome this problem, we propose a method that estimates the lighting environment from an HDR image and renders virtual objects using an HDR environment map. Virtual objects are overlaid in real-time by adjusting the dynamic range of the rendered image with tone mapping according to the exposure time of the camera. The HDR image is generated from multiple images captured with various exposure times. We have found through experimentation that the updating rate is improved by effectively limiting the dynamic range, depending on the exposure time. We have verified the effect of limiting the dynamic range on the reality of virtual objects.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637323","H.5.1 [Information interfaces and presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities","Image generation;Dynamic range;Lighting;Cameras;Light sources;Estimation;Reflectivity","augmented reality;image registration;photometry","photometric registration;adaptive high dynamic range image generation;augmented reality;virtual object rendering;tone mapping","","2","3","11","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Action- and Workflow-Driven Augmented Reality for Computer-Aided Medical Procedures","N. Navab; J. Traub; T. Sielhorst; M. Feuerstein; C. Bichlmeier","CAMP, Technische Universität, Munich, Germany; CAMP, Technische Universität, Munich, Germany; CAMP, Technische Universität, Munich, Germany; CAMP, Technische Universität, Munich, Germany; CAMP, Technische Universität, Munich, Germany","IEEE Computer Graphics and Applications","17 Sep 2007","2007","27","5","10","14","During the past three years, we've tried to develop integrated AR solutions in the context of minimally invasive surgery. We have therefore focused on four main issues: recovery and monitoring of surgical workflow, integrating preoperative and intraoperative anatomic and functional data, improving visual perception in a mixed environment, and developing new user interaction paradigms for taking full advantage of the virtual data, while overlaid onto the real scene. Each of these issues is the subject of many existing and future publications. Here, we provide a brief overview of our activities and current results in regard to each of these issues.","1558-1756","","10.1109/MCG.2007.117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4302577","augmented reality;surgery;virtual reality;medical procedures","Augmented reality;Optical imaging;Biomedical imaging;Anatomy;Orthopedic surgery;Liver;Biomedical optical imaging;Computerized monitoring;Virtual reality;User interfaces","augmented reality;medical computing;surgery","action-driven augmented reality;workflow-driven augmented reality;computer-aided medical procedures;minimally invasive surgery;surgical workflow monitoring;surgical workflow recovery;preoperative anatomic data;intraoperative anatomic data;preoperative functional data;intraoperative functional data;visual perception;mixed environment;user interaction paradigm","Computer Simulation;Environment;Imaging, Three-Dimensional;Models, Biological;Robotics;Surgery, Computer-Assisted;Telemedicine;User-Computer Interface","62","2","5","IEEE","17 Sep 2007","","","IEEE","IEEE Magazines"
"Vivid Educational Experience with Virtual Reality","N. Mavrogeorgi; S. Koutsoutos; A. Yannopoulos; T. Varvarigou; G. Kambourakis","Department of Electrical & Computer Engineering, National and Technical University of Athens, Athens, Greece; Department of Electrical & Computer Engineering, National and Technical University of Athens, Athens, Greece; Department of Electrical & Computer Engineering, National and Technical University of Athens, Athens, Greece; Department of Electrical & Computer Engineering, National and Technical University of Athens, Athens, Greece; Department of Electrical & Computer Engineering, National and Technical University of Athens, Athens, Greece","2009 Fourth International Multi-Conference on Computing in the Global Information Technology","6 Oct 2009","2009","","","196","201","In this paper, we present an educational system that represents cultural heritage virtually. The system contains an editor for specifying the educational scripts which will be displayed at Augmented Reality and Mixed Reality. The editor is a very simple application interface for Augmented Reality and Mixed Reality developers. It is a useful and easy-to-use tool for editing educational scripts for augmented reality and for exporting X3D files from the developer's input. The X3D files permit the generation of the augmented reality world. Augmented and Mixed reality permit real and virtual world to be combined. This interaction is done in real-time. The editor enables developers to facilitate their work, that is creating educational scripts of augmented reality. A web service requests (a) the localization of the user that is found by the device (PDA) which the user utilizes and (b) the user preferences that desires to get informed (political data, cultural data etc). After these data are specified, the web service provides information and scenarios to the user according to his preferences and to the sight where the user is located (found according to his location). The user can interact with these scenarios, living historical immersive experiences virtually.","","978-1-4244-4680-3","10.1109/ICCGI.2009.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5280078","Education;Augmented Reality;Mixed Reality;Mobile Entertainment;user interaction;wireless;web-service;editor;design","Virtual reality;Augmented reality;Cultural differences;Web services;Information technology;Personal digital assistants;Real time systems;Buildings;Augmented virtuality;Displays","augmented reality;computer aided instruction;notebook computers;Web services","virtual reality;educational system;augmented Reality;mixed Reality;application interface;X3D files;real-time interaction;web service;educational experience;educational scripts;cultural heritage;user localization","","1","","10","IEEE","6 Oct 2009","","","IEEE","IEEE Conferences"
"Web-based Augmented Reality Video Streaming for Marketing","V. Valjus; S. Järvinen; J. Peltola","ICT, Media Technologies, VTT Technical Research Center of Finland, Oulu, Finland; ICT, Media Technologies, VTT Technical Research Center of Finland, Oulu, Finland; ICT, Media Technologies, VTT Technical Research Center of Finland, Oulu, Finland","2012 IEEE International Conference on Multimedia and Expo Workshops","16 Aug 2012","2012","","","331","336","This paper presents an Adobe Flash-based augmented reality video streaming application and its practical use in web marketing. The application enables augmenting the content of a web cam view by adding video content to it. Aller Media, a Nordic media company, used the application for advertising two Finnish movies with promotional video content. We have examined combining of conventional print media and digital media and the suitability of the augmented reality video streaming application for the web environment and marketing purposes. Additionally, we measured the technical performance of the application. The feedback from Aller Media and the end-users indicates that the application is useful for marketing purposes. In addition, the results show that the application is well suited for web environment as its performance is sufficient and as the distribution is more efficient compared to desktop or mobile applications.","","978-1-4673-2027-6","10.1109/ICMEW.2012.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6266277","augmented reality;Adobe Flash;video streaming;marketing","Streaming media;Media;Libraries;Augmented reality;Cameras;Computers;Delay","advertising data processing;augmented reality;entertainment;Internet;promotion (marketing);video streaming","Web-based augmented reality video streaming;Adobe Flash-based augmented reality video streaming application;Web marketing;Webcam;Aller Media;Nordic media company;Finnish movie advertisement;promotional video content;print media;digital media","","8","","5","IEEE","16 Aug 2012","","","IEEE","IEEE Conferences"
"Single access point based indoor localization technique for augmented reality gaming for children","C. P. Kumar; R. Poovaiah; A. Sen; P. Ganadas","Dept. of EE, Indian Inst. Of Technology Madras, India; Dept. of EE, Indian Inst. Of Technology Madras, India; Dept. of EE, Indian Inst. Of Technology Madras, India; Dept. of EE, Indian Inst. Of Technology Madras, India","Proceedings of the 2014 IEEE Students' Technology Symposium","1 May 2014","2014","","","229","232","In this paper we discuss our attempt to solve the problem of Indoor Localization for a game intended to enhance learning among children by involving them in `learning' along with `play'. The first part of the paper describes our methodology towards the construction of the Augmented Reality Game for enhancing astronomy learning in children, emphasizing the experiential nature of tangible interactions and the remote dimension which the game can take, due to the available social media tools, by bringing people into a virtual 3D space to interact with each other. To keep the game simple and less complicated, we employ Single Access Point based Indoor Localization technique for tracking players. In the latter part of the paper we discuss the Indoor Localization system being implemented to track real time location of the player in his/her physical environment and the same being mapped on a virtual game arena for facilitating remote play dimension. Technologies used for early prototype: - basic optics for creating a device that gives 3D illusion of celestial objects appearing on 2D screen, a Kinect-sensor environment, and potentiometer for interactions. Technologies for the game being currently developed: augmented and virtual reality elements, indoor position tracking using Kalman filter implemented inertial navigation system, with Wi-Fi RSSI data, onboard sensory data, geo-tagging.","","978-1-4799-2608-4","10.1109/TechSym.2014.6808052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6808052","Tangible;Gestural;Intuitive;Interactions;Augmented reality;Virtual reality;Space coordinates;Depth perception;Experiential;Play and Learn","Games;IEEE 802.11 Standards;Sensor systems;Navigation;Augmented reality;Fingerprint recognition","astronomy computing;augmented reality;computer aided instruction;computer games","single access point;indoor localization technique;augmented reality gaming;astronomy learning;tangible interaction;social media tool;virtual 3D space;virtual game;remote play dimension;3D illusion;celestial object;Kinect-sensor environment;potentiometer;virtual reality element;indoor position tracking;Kalman filter;inertial navigation system;Wi-Fi RSSI data;onboard sensory data;geo-tagging","","12","","5","IEEE","1 May 2014","","","IEEE","IEEE Conferences"
"Augmented reality in pneumatic conveying system: Fuller pump dry material line charger","G. Pantoja; L. E. Garza; E. G. Mendívil","Tecnológico de Monterrey, Centro de Innovación en Diseño y Tecnología, Monterrey, Mexico; Tecnológico de Monterrey, Centro de Innovación en Diseño y Tecnología, Monterrey, Mexico; Tecnológico de Monterrey, Centro de Innovación en Diseño y Tecnología, Monterrey, Mexico","2014 9th Iberian Conference on Information Systems and Technologies (CISTI)","14 Aug 2014","2014","","","1","5","The overall purpose of this project is to test the impact and potential benefits of Virtual and Augmented Reality technologies (AR&VR) to improve maintenance operation in industrial equipment. The main function for a Flapper valve of a Fuller-Kinyon type M pump is to prevent that the air generated to convey the bulk material through a conveying pipe flows inside of the material chute through the rotating screw. If this will occur, the material flow will decrease or even stop, causing a reduction of the pump capacity. Thus, it is necessary to maintain calibrated each flapper valve in the plant. This process of maintenance is done ten times per month, or when necessary, and it needs the pump to be shut down, taking up to two hours to finish the complete process. For this reason, an augmented reality application is being developed, aiming to reduce the consumed time by the maintenance process. Using this application, it is expected to dedicate less time training the new personnel responsible for the maintaining process, displaying tridimensional models, animations, images and text information that would simplify the instructions shown in a printed manual and adding an interactive environment between the users and the information displayed. A mobile device either a tablet or a smartphone is to be used as the hardware that will run the application, allowing the user to take it right to the working area, either in a workshop or directly in field. The information displayed includes CAD models of the pump and its components as well as animations illustrating the instructions to follow in each step of the process. Also, the right tool to use in each step will be indicated following by security warnings when needed. This project was developed from knowledge and experiences gathered among the different previous AR projects developed at ITESM. This information has been studied and ""best practices"" has been noted, learned and established to develop and implement AR.","2166-0727","978-9-8998-4343-1","10.1109/CISTI.2014.6877050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6877050","Augmented Reality;Virtual Reality;CAD models;maintenance process;mobile devices","Augmented reality;Maintenance engineering;Solid modeling;Animation;Three-dimensional displays;Training;Materials","augmented reality;CAD;conveyors;maintenance engineering;mobile computing;pneumatic systems;production engineering computing;pumps","augmented reality;pneumatic conveying system;fuller pump;dry material line charger;virtual reality;VR;AR;maintenance operation;industrial equipment;flapper valve;Fuller-Kinyon type M pump;conveying pipe flow;material chute;rotating screw;pump capacity;maintenance process;mobile device;smart phone;CAD models;computer aided design","","2","","8","","14 Aug 2014","","","IEEE","IEEE Conferences"
"Preliminary study on systematic literature review of augmented and virtual reality applied to motor and cognitive disabilities","R. Colpani; M. R. Petrucelli Homem","Departamento de Ciência da Computação, Universidade Federal de São Carlos - UFSCar, Sorocaba, Brasil; Departamento de Ciência da Computação, Universidade Federal de Sao Carlos, Sao Carlos, SP, BR","2015 10th Iberian Conference on Information Systems and Technologies (CISTI)","30 Jul 2015","2015","","","1","4","In recent years, studies have been making use of Virtual and Augmented Reality technologies, which has shown promising results. However, there are few studies conducted on the disabilities area. From this approach, this paper presents the results of a preliminary study on systematic literature review of augmented and virtual reality applied to motor and cognitive disabilities.","2166-0727","978-9-8998-4345-5","10.1109/CISTI.2015.7170532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7170532","Virtual Reality;Augmented Reality;Motor and Cognitive Disabilities","Augmented reality;Systematics;Software;Conferences;Bibliographies;IEEE Xplore","augmented reality;cognition;handicapped aids","systematic literature review;virtual reality;augmented reality;cognitive disabilities;motor disabilities","","","","12","","30 Jul 2015","","","IEEE","IEEE Conferences"
"Augmented Reality with Internet of Things","S. Sureshkumar; C. P. Agash; S. Ramya; R. Kaviyaraj; S. Elanchezhiyan","Dept of computer Science, Sri Krishna College of Engineering and Technology, Coimbatore, India; Dept of computer Science, Sri Krishna College of Engineering and Technology, Coimbatore, India; Department of Computer Science and Engineering, Paavai Engineering College, Namakkal; Department of Computer Science and Engineering, SRM Institute of Science and Technology, Chennai, India; Department of Computer Science and Engineering, Paavai Engineering College, Namakkal","2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)","12 Apr 2021","2021","","","1426","1430","Today technological changes make the probability of more complex things made into simple tasks with more accuracy in major areas and mostly in Manufacturing Industry. Internet of things contributes its major part in automation which helps human to make life easy by monitoring and directed to a related person with in a fraction of second. Continuous advances and improvement in computer vision, mobile computing and tablet screens have led to a revived interest in Augmented Reality the Augmented Reality makes the complex automation into an easier task by making more realistic real time animation in monitoring and automation on Internet of Things (eg like temperature, time, object information, installation manual, real time testing).In order to identify and link the augmented content, like object control of home appliances, industrial appliances. The AR-IoT will have a much cozier atmosphere and enhance the overall Interactivity of the IoT environment. Augmented Reality applications use a myriad of data generated by IoT devices and components, AR helps workers become more competitive and productive with the realistic environment in IoT. Augmented Reality and Internet of Things together plays a critical role in the development of next generation technologies. This paper describes the concept of how Augmented Reality can be integrated with industry(AR-IoT)4.0 and how the sensors are used to monitoring objects/things contiguously round the clock, and make the process of converting real-time physical objects into smart things for the upcoming new era with AR-IoT.","","978-1-7281-9537-7","10.1109/ICAIS50930.2021.9395941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395941","Augmented Reality;Automation in AR;Industry 4.0;AR and IoT;IoT with AR","Home appliances;Automation;Real-time systems;Temperature control;Task analysis;Augmented reality;Monitoring","augmented reality;computer animation;intelligent manufacturing systems;Internet of Things;manufacturing industries;production engineering computing","tablet screens;augmented reality;mobile computing;Internet of Things;manufacturing industry;computer vision;real time animation;industry AR-IoT 4.0","","13","","16","IEEE","12 Apr 2021","","","IEEE","IEEE Conferences"
"Key Technique of Assembly System in an Augmented Reality Environment","Y. Wang; Y. Shen; D. Liu; S. Wei; C. Zhu","School of Engineering Science, University of Science and Technology, Hefei, China; School of Engineering Science, University of Science and Technology, Hefei, China; School of Engineering Science, University of Science and Technology, Hefei, China; School of Engineering Science, University of Science and Technology, Hefei, China; School of Engineering Science, University of Science and Technology, Hefei, China","2010 Second International Conference on Computer Modeling and Simulation","25 Feb 2010","2010","1","","133","137","Assembly technology aims to develop fast, reliable and low cost method to improve product design in the manufacturing industry. Augmented Reality (AR) is a promising technology which can enhance the sense of reality by combining virtual objects with real ones. When AR technique is applied in assembly to develop an AR-based assembly system, it can provide more intuitive and natural interactions and make assembly task more reliable and effective than traditional assembly techniques. This paper describes several key aspects in AR-based assembly system: occlusion handling, collision detection and human-computer interaction. A prototype system is implemented to illustrate how to apply these techniques.","","978-1-4244-5643-7","10.1109/ICCMS.2010.201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5421417","assembly;augmented reality;interaction;occlusion;collision","Assembly systems;Augmented reality;Virtual reality;Prototypes;Costs;Product design;Manufacturing industries;Computational modeling;Computer simulation;Reliability engineering","assembling;augmented reality;human computer interaction;manufacturing industries","assembly system key technique;augmented reality environment;human-computer interaction;manufacturing industry design;AR technique;AR-based assembly system;occlusion handling;collision detection;virtual reality techniques","","6","1","14","IEEE","25 Feb 2010","","","IEEE","IEEE Conferences"
"An augmented reality method with image composition and image special effects","Q. Zhao; Y. Sun; Z. Sun","Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; School of Software, Sun Yat-sen University, Guangzhou, China","2015 8th International Congress on Image and Signal Processing (CISP)","18 Feb 2016","2015","","","866","870","Augmented reality for natural images on mobile devices is currently a research focus. Traditional methods augment natural images mainly by projecting virtual models, putting texts, audio and videos on the images. In this paper, we introduce image composition and image special effects into applications of augmented reality, and proposed an augmented reality method with image composition and image special effects. In this method, 3d-tracking of a camera is obtained first, then a template image is augmented by applying image composition, image special effects and 3d virtual model projection independently or jointly. Our method is implemented and validated by experiments. It extends and enriches the forms and applications of augmented reality.","","978-1-4673-9098-9","10.1109/CISP.2015.7407999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407999","Augmented reality;3d tracking;image composition;image special effects;mobile device","Transforms;Three-dimensional displays;Cameras;Augmented reality;Image color analysis;Solid modeling;Mobile handsets","augmented reality;image enhancement;mobile radio;solid modelling","augmented reality;image composition;image special effects;natural image;mobile device;3D-tracking;3d virtual model projection","","2","","9","IEEE","18 Feb 2016","","","IEEE","IEEE Conferences"
"Augmented reality based wrist rehabilitation system","A. Hacıoğlu; Ö. F. Özdemir; A. K. Şahin; Y. S. Akgül","Yapay Nazar Yazılım Limidet Şirketi, Kocaeli, Türkiye; Yapay Nazar Yazılım Limidet Şirketi, Kocaeli, Türkiye; İNOSENS Bilişim Teknolojileri San. ve Tic. Ltd. Şirketi, İstanbul, Türkiye; Bilgisayar Mühendisliği Bölümü, Gebze Teknik Üniversitesi, Kocaeli, Türkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","23 Jun 2016","2016","","","1869","1872","Physioterapy is a long period that becomes a part of the life of people who need it. Today, the new touchless sensors have positive influence on the comfort of the rehabilitation and healing period. In addition, with the virtual/augmented reality technology, these processes are expected to be relatively more advanced. This study presents a novel physiotherapy system that increases the interaction of the subject with the virtual scene by matching the 3D geometry of the scene with the subject's position. Besides, the developed game based on the Leap Motion, a touchless sensor, describes a new measuring metric for augmented reality. Finally, this article represents an example of augmented reality concept in the field of physiotherapy.","","978-1-5090-1679-2","10.1109/SIU.2016.7496128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496128","augmented reality;physiotherapy;rehabilitation;game","Matrix decomposition;Augmented reality;Tactile sensors;Games;Singular value decomposition;Medical treatment","augmented reality;computer games;medical computing;patient rehabilitation","augmented reality based wrist system;touchless sensor;healing period;rehabilitation period;virtual reality technology;physiotherapy system;virtual scene;3D geometry matching;leap motion","","2","","","IEEE","23 Jun 2016","","","IEEE","IEEE Conferences"
"Real-time SLAM for static multi-objects learning and tracking applied to augmented reality applications","D. Ramadasan; M. Chevaldonne; T. Chateau",Institut Pascal; ISIT; Institut Pascal,"2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","267","268","This paper presents a new approach for multi-objects tracking from a video camera moving in an unknown environment. The tracking involves static objects of different known shapes, whose poses and sizes are determined online. For augmented reality applications, objects must be precisely tracked even if they are far from the camera or if they are hidden. Camera poses are computed using simultaneous localization and mapping (SLAM) based on bundle adjustment process to optimize problem parameters. We propose to include in an incremental bundle adjustment the parameters of the observed objects as well as the camera poses and 3D points. We show, through the example of 3D models of basics shapes (planes, parallelepipeds, cylinders and spheres) coarsely initialized online using a manual selection, that the joint optimization of parameters constrains the 3D points to approach the objects, and also constrains the objects to fit the 3D points. Moreover, we developed a generic and optimized library to solve this modified bundle adjustment and demonstrate the high performance of our solution compared to the state of the art alternative. Augmented reality experiments in realtime demonstrate the accuracy and the robustness of our method.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223398","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223398","I.4.8 [Image Processing and Computer Vision]: Scene Analysis — Motion;Object recognition;Shape;Surface fitting;Tracking;SLAM;I.4.9 [Image Processing and Computer Vision]: Applications;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial;augmented","Three-dimensional displays;Simultaneous localization and mapping;Cameras;Augmented reality;Optimization;Real-time systems;Shape","augmented reality;object tracking;real-time systems;SLAM (robots);video cameras;video signal processing","real-time SLAM;static multiobjects learning;augmented reality applications;multiobjects tracking;video camera;camera poses;simultaneous localization and mapping;problem parameters optimization;incremental bundle adjustment;3D points;3D models;parameters constrains","","2","","10","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Improve accessibility of virtual and augmented reality for people with balance impairments","S. M. S. Ferdous","University of Texas at San Antonio, San Antonio, TX, US","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","421","422","Most people experience some imbalance in a fully immersive Virtual Environment (VE) (i.e., wearing a Head Mounted Display (HMD) that blocks the users view of the real world). However, this imbalance is significantly worse in People with Balance Impairments (PwBIs) and minimal research has been done to improve this. In addition to imbalance problem, lack of proper visual cues can lead to different accessibility problems for PwBIs (e.g., small reach from the fear of imbalance, decreased gait performance, etc.) We plan to explore the effects of different visual cues on peoples' balance, reach, gait, etc. Based on our primary study, we propose to incorporate additional visual cues in VEs that proved to significantly improve balance of PwBIs while they are standing and playing in a VE. We plan to further investigate if additional visual cues have similar effects in augmented reality. We are also developing studies to research reach and gait in VR as our future work.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892356","Virtual Reality;Balance;Accessibility;Visual Feedback;Gait;Head-mounted Display","Visualization;Games;Augmented reality;Multiple sclerosis;Parkinson's disease;Elevators","augmented reality;handicapped aids","virtual reality;augmented reality;balance impairments;fully immersive virtual environment;VE;people with balance impairments;PwBI;imbalance problem;visual cues;VR","","3","","9","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Technological Review on Integrating Image Processing, Augmented Reality and Speech Recognition for Enhancing Visual Representations","R. M. Jayamanne; D. Shaminda","Department of Computing, Informatics Institude of Technology, Sri Lanka; Department of Computing, Informatics Institude of Technology, Sri Lanka","2020 International Conference on Image Processing and Robotics (ICIP)","5 Mar 2021","2020","","","1","6","There is still a lack of research focus on augmenting user engagement by AR-based applications. As technology has grown, the movie industry has been undergoing a remarkable change in the past few years. Visually attractive movie posters play a major role in advertising even in the era of digital promotion. This paper is a review of the use of technologies such as Image processing, Augmented Reality and Speech Recognition to interactively present movie information to users in a more convenient method.","","978-1-7281-6541-7","10.1109/ICIP48927.2020.9367358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367358","Image-processing;Augmented Reality;Speech Recognition;Convolutional Neural Network","Visualization;Speech recognition;Motion pictures;Feature extraction;Wavelet analysis;Augmented reality;Robots","augmented reality;data visualisation;image processing;speech recognition;virtual reality","technological review;integrating image processing;augmented reality;speech recognition;visual representations;augmenting user engagement;AR-based applications;movie industry;remarkable change;attractive movie posters;digital promotion;interactively present movie information","","1","","28","IEEE","5 Mar 2021","","","IEEE","IEEE Conferences"
"Robot Supported Virtual and Augmented Reality","E. Vonach","TU Wien, Interactive Media Systems Group, Vienna, Austria","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","1","2","In this dissertation different aspects from research in the fields of Tangible User Interfaces, encounter-type devices and Passive Haptics are combined to investigate the benefits that robots offer for providing haptic feedback in Virtual and Augmented Reality. Robotic elements like micro drives and robotic arms are employed for the actuation of passive or active physical objects. In that way physical props can be collocated with virtual counterparts to allow high fidelity, natural interaction.","","978-1-5386-3365-6","10.1109/VR.2018.8446400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446400","Immersive virtual reality;encounter-type/prop-based/passive haptic feedback;actuation;tangible user interface.: H.5.2 [Information interfaces and presentation]: User Interfaces-Input devices and strategies;Haptic I/O;H.5.1 [Information interfaces and presentation]: Multimedia Information Systems-Artificial;augmented;and virtual realities","Haptic interfaces;Manipulators;User interfaces;Virtual reality;Monitoring;Robot sensing systems","augmented reality;haptic interfaces;mobile robots","microdrives;robotic arms;active physical objects;virtual counterparts;encounter-type devices;haptic feedback;augmented reality;tangible user interfaces;passive haptics;virtual reality;passive physical objects;physical props;natural interaction;high fidelity","","","","9","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Professional Information Visualization Using Augmented Reality; AR Visiting Card","M. F. Hossain; N. Biswas; S. Barman; A. K. M. Bahalul Haque","Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh","2020 2nd International Conference on Sustainable Technologies for Industry 4.0 (STI)","16 Feb 2021","2020","","","1","5","Augmented reality gives new dimensions in application and services. The same goes for the business field. Since augmented reality can change the perspective and perception about objects, attributes and services; it can be a nice addition in business sector. This proposed augmented reality-based project is an approach to enhance the acceptability and presentation of traditional and classic visiting card. Sharing professional information of a person, including his/her company, plays a vital role in business. Virtual visiting card opens new ways to communicate and share commercial information with others.","","978-1-6654-0489-1","10.1109/STI50764.2020.9350321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350321","Visiting Card;Professional;commercial;Vuforia;Augmented Reality;Unity","Industries;Visualization;Technological innovation;Companies;Augmented reality;Business","augmented reality;data visualisation;virtual reality","professional information visualization;AR visiting card;business field;business sector;augmented reality-based project;traditional visiting card;classic visiting card;virtual visiting card","","1","","15","IEEE","16 Feb 2021","","","IEEE","IEEE Conferences"
"Fruitify: Nutritionally augmenting fruits through markerless-based augmented reality","A. Kulpy; G. Bekaroo","Middlesex University (Mauritius Branch Campus), Bonne Terre, Vacoas, Mauritius; Middlesex University (Mauritius Branch Campus), Bonne Terre, Vacoas, Mauritius","2017 IEEE 4th International Conference on Soft Computing & Machine Intelligence (ISCMI)","5 Feb 2018","2017","","","149","153","In the past few decades, a significant decrease in fruit consumption around the world has resulted in a hiking rate of cardiovascular diseases and obesity among youngsters. In order to address this issue, healthy eating is being recommended. However, awareness on nutritional information on fruits remain an important challenge that still needs to be addressed even though various sources in the form of books, websites and mobile applications are already available. This is also potentially due to the limited interaction and engagement with such sources. One technology that has shown to improve engagement, enhance understanding and provide a unique learning experience is Augmented Reality. However, limited work has been undertaken to provide nutritional information on fruits via this technology. As such, this paper investigates the application of AR to nutritionally augment fruits through a proposed prototype called Fruitify, before discussing the usability tests performed on the application and involving end users. As key findings, a system usability scale score of 82.1% was obtained where participants expressed strong intention to utilize the tool again in the future.","","978-1-5386-1314-6","10.1109/ISCMI.2017.8279616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279616","fruitify;augmented reality;markerless;nutritional information;awareness","Usability;Tools;Three-dimensional displays;Augmented reality;Mobile handsets;Task analysis;Prototypes","augmented reality;diseases;food products;health care;mobile computing","mobile applications;Fruitify;markerless-based augmented reality;cardiovascular diseases;obesity;healthy eating;fruits nutritional information","","4","","27","IEEE","5 Feb 2018","","","IEEE","IEEE Conferences"
"Is Any Room Really OK? The Effect of Room Size and Furniture on Presence, Narrative Engagement, and Usability During a Space-Adaptive Augmented Reality Game","J. -e. Shin; H. Kim; C. Parker; H. -i. Kim; S. Oh; W. Woo",KAIST UVR Lab; KAIST UVR Lab; The University of Sydney; KAIST UVR Lab; KAIST UVR Lab; KAIST UVR Lab,"2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","30 Dec 2019","2019","","","135","144","One of the main challenges in creating narrative-driven Augmented Reality (AR) content for Head Mounted Displays (HMDs) is to make them equally accessible and enjoyable in different types of indoor environments. However, little has been studied in regards to whether such content can indeed provide similar, if not the same, levels of experience across different spaces. To gain more understanding towards this issue, we examine the effect of room size and furniture on the player experience of Fragments, a space-adaptive, indoor AR crime-solving game created for the Microsoft HoloLens. The study compares factors of player experience in four types of spatial conditions: (1) Large Room - Fully Furnished; (2) Large Room - Scarcely Furnished; (3) Small Room - Fully Furnished; and (4) Small Room - Scarcely Furnished. Our results show that while large spaces facilitate a higher sense of presence and narrative engagement, fully-furnished rooms raise perceived workload. Based on our findings, we propose design suggestions that can support narrative-driven, space-adaptive indoor HMD-based AR content in delivering optimal experiences for various types of rooms.","1554-7868","978-1-7281-0987-9","10.1109/ISMAR.2019.00-11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943577","Augmented Reality;Augmented Reality Game;Augmented Narrative","Usability;Games;Augmented reality;Indoor environment;Media;Mobile handsets;Tracking","augmented reality;computer games;helmet mounted displays;indoor environment;user experience","fully-furnished rooms;space-adaptive indoor HMD-based;room size;furniture;narrative engagement;Head Mounted Displays;indoor environments;player experience;narrative-driven augmented reality content;space-adaptive augmented reality game","","10","","48","IEEE","30 Dec 2019","","","IEEE","IEEE Conferences"
"Mobile Edge Computing – a Booster for the Practical Provisioning Approach of Web-Based Augmented Reality","P. Ren; X. Qiao; J. Chen; S. Dustdar","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China; Distributed Systems Group, TU Wien, Austria","2018 IEEE/ACM Symposium on Edge Computing (SEC)","9 Dec 2018","2018","","","349","350","Web-based Augmented Reality (Web AR) provides a lightweight, cross-platform, and pervasive AR solution. However, all of the current Web AR implementations still face some challenges, which greatly hinder the promotion of Web AR applications. Benefiting from Mobile Edge Computing (MEC) paradigm, in this paper, we propose a MEC-based collaborative Web AR solution, which can be regarded as a feasible and promising one. The edge server not only reduces the network latency but also decreases the bandwidth usage of core networks. Prototype implementation demonstrated the effectiveness and practicability of the proposed MEC-based solution for real-world Web AR development and deployment.","","978-1-5386-9445-9","10.1109/SEC.2018.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567686","Mobile Augmented Reality;Web based Augmented Reality;Cloud Computing;Mobile Edge Computing","Cloud computing;Servers;Bandwidth;Performance evaluation;Edge computing;Augmented reality;Collaboration","augmented reality;mobile computing;Web services","Web-based Augmented Reality;Web AR applications;Mobile Edge Computing paradigm;MEC-based collaborative Web AR solution;edge server;MEC-based solution;Web AR implementations","","33","","2","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
"Experiences on hybrid television and augmented reality on ISDB-T","R. Sotelo; J. Joskowicz; N. Rondan","Facultad de Ingenieria, Universidad de Montevideo, Uruguay; Facultad de Ingenieria, Universidad de Montevideo, Uruguay; Facultad de Ingenieria, Universidad de Montevideo, Uruguay","2017 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)","20 Jul 2017","2017","","","1","5","Hybrid Television allows the provision of new services for the user by adding other media and applications to the traditional audiovisual content, that can be experienced in the main TV set or in a Companion Screen. This paper describes some applications of Hybrid Television illustrating the concept of Augmented Reality in Broadcasting environments or Augmented Broadcasting. The applications were executed in a real testbed. Standards in force have been used in order to ensure synchronization and repeatability. The testbed has the particularity that is an HbbTV 2.0 system (originally designed to work with DVB systems), running with ISDB-Tb broadcasting.","2155-5052","978-1-5090-4937-0","10.1109/BMSB.2017.7986231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7986231","DTV and broadband multimedia systems;Set-top box and home networking;Interactivity;Hybrid Television;ISDB-T;HbbTV;Augmented Reality;Augmented Broadcasting","TV;Digital multimedia broadcasting;Data communication;Communication standards;Multiplexing;Augmented reality","augmented reality;digital video broadcasting;synchronisation","hybrid television;augmented reality;audiovisual content;main TV set;broadcasting environments;augmented broadcasting;synchronization;HbbTV 2.0 system;DVB systems;ISDB-Tb broadcasting","","2","","20","IEEE","20 Jul 2017","","","IEEE","IEEE Conferences"
"Fieldtrip Ni Juan: An Augmented Reality Mobile Application for the Tourist Spots in the Philippines for Travel Hub PH","M. A. Acaya; J. P. G. Amador; E. S. Elinon; R. M. A. Recaido; J. R. D. Bermudez; R. R. H. Guadanaa; A. C. Bangit; E. Q. Ramirez","College of Computing and Information Technologies, National University, Manila, Philippines; College of Computing and Information Technologies, National University, Manila, Philippines; College of Computing and Information Technologies, National University, Manila, Philippines; College of Computing and Information Technologies, National University, Manila, Philippines; College of Computing and Information Technologies, National University, Manila, Philippines; College of Computing and Information Technologies, National University, Manila, Philippines; College of Computing and Information Technologies, National University, Manila, Philippines; College of Computing and Information Technologies, National University, Manila, Philippines","TENCON 2018 - 2018 IEEE Region 10 Conference","24 Feb 2019","2018","","","2242","2247","This paper promotes the use of Augmented Reality (AR) for travel agencies, specifically for Travel Hub PH. The main feature of this application is the Regions module, where the user can see 3D models of several tourist destinations per Philippine region - with text-to-speech facts pertaining to the tourist spots - and what each region is best known for. The paper will focus on the acceptability of the proposed system for Travel Hub PH.","2159-3450","978-1-5386-5457-6","10.1109/TENCON.2018.8650364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8650364","Augmented Reality;3D models;Text-to-Speech;Mobile Based Augmented Reality Application","Three-dimensional displays;Solid modeling;Augmented reality;Information technology;Smart phones;Mobile applications;IEEE Regions","augmented reality;mobile computing;speech synthesis;travel industry","tourist spots;Travel Hub PH;travel agencies;tourist destinations;Philippine region;augmented reality mobile application;regions module;Fieldtrip Ni Juan;AR;text-to-speech facts","","2","","11","IEEE","24 Feb 2019","","","IEEE","IEEE Conferences"
"[POSTER] Movable Spatial AR On-The-Go","A. Lee; J. -H. Lee; J. Kim","Human Robot Interaction Lab., ETRI; Human Robot Interaction Lab., ETRI; Human Robot Interaction Lab., ETRI","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","182","183","We present a movable spatial augmented reality (SAR) system that can be easily installed in a user workspace. The proposed system aims to dynamically cover a wider projection area using a portable projector attached to a simple robotic device. It has a clear advantage than a conventional SAR scenario where, for example, a projector should be installe1d with a fixed projection area in the workspace. In the previous research [1], we proposed a data-driven kinematic control method for a movable SAR system. This method targets a SAR system integrated with a user-created robotic (UCR) device where an explicit kinematic configuration such as CAD model is unavailable. Our contribution in this paper is to show the feasibility of the data-driven control method by developing a practical application where dynamic change of projection area matters. We outline the control method and demonstrate an assembly guide example using a casually installed movable SAR system.","","978-1-4673-7660-0","10.1109/ISMAR.2015.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328095","Spatial augmented reality;kinematics;data-driven control;assembly guide","Kinematics;Assembly;Robots;Joints;Splines (mathematics);Augmented reality;Design automation","augmented reality;optical projectors;robots","movable spatial AR;augmented reality;SAR system;data-driven control method;spatial augmented reality;user created robot;UCR;projector-camera unit;PCU","","1","","4","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Bridging shape grammar and Tangible Augmented Reality into collaborative design learning","I. R. Chen; X. Wang; W. Wang","Faculty of Architecture, Design and Planning, University of Sydney, Australia; Faculty of Architecture, Design and Planning, University of Sydney, Australia; Faculty of Architecture, Design and Planning, University of Sydney, Australia","2009 13th International Conference on Computer Supported Cooperative Work in Design","26 May 2009","2009","","","468","473","This paper combines tangible augmented reality and shape grammar into collaborative design learning to bridge the gaps such as the difficulties of imaging the spatial form in a complex content and the obstacle of communication during the collaborative design. This work has been successful in mapping out a space of technical possibilities and providing a possible system setup to pursue the innovative idea. It not only describes the latent trends and assumptions that might be used to motivate and guide the design in cooperative work, but also makes links with existing research in cognitive science and education.","","978-1-4244-3534-0","10.1109/CSCWD.2009.4968103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4968103","Augmented Reality;Shape Grammar;Tangible Augmented Reality;Tangible User Interface","Shape;Augmented reality;Collaborative work;International collaboration;Education;Application software;Bridges;Cognitive science;User interfaces;Technological innovation","augmented reality;computer aided instruction;groupware","shape grammar;tangible augmented reality;collaborative design learning;cognitive science;cognitive education","","","","19","IEEE","26 May 2009","","","IEEE","IEEE Conferences"
"Smarter and safer road traffic using advanced VANET and wireless augmented reality","B. Dutta; A. Sreedhar; C. Sandeep","B.Tech, ECE SRM University, Chennai, India; B.Tech, ECE SRM University, Chennai, India; B.Tech, ECE SRM University, Chennai, India","2012 IEEE Conference on Sustainable Utilization and Development in Engineering and Technology (STUDENT)","10 Jan 2013","2012","","","68","71","With the advancements in wireless technology, wireless augmented reality have seen a growth in the recent years and their applications have magnified tremendously. Also the concept of vehicular Ad-hoc networks (VANET) and its applications have aggrandized the field of traffic and navigation in a similar way. This paper basically proposes the integration of both these technologies in the creation of a smarter and safer road traffic system. The review of the current and previous researches in these fields provides the design outline for the proposed theory.","1985-5753","978-1-4673-1705-4","10.1109/STUDENT.2012.6408367","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6408367","Augmented reality;Augmented Reality Toolkit (ARToolKIT);Global positioning System (GPS);Vehicular Ad-Hoc Networks(VANET)","Vehicles;Augmented reality;Vehicular ad hoc networks;Roads;Head;Magnetic heads","augmented reality;automated highways;road safety;road traffic;traffic engineering computing;vehicular ad hoc networks","road safety;advanced VANET;wireless augmented reality;wireless technology;vehicular ad-hoc network;navigation;road traffic system","","","","5","IEEE","10 Jan 2013","","","IEEE","IEEE Conferences"
"Standard-based publish-subscribe service enabler for social applications and augmented reality services","O. R. Rocha; B. Moltchanov","Politecnico di Torino, Italy; Telecom Italia Laboratory, Italy","2013 Proceedings of ITU Kaleidoscope: Building Sustainable Communities","17 Jun 2013","2013","","","1","6","A Publish/Subscribe mechanism based on the Open Mobile Alliance's (OMA) Next Generation Services Interface (NGSI) open standard, allows interfacing the information available from many publishers with heterogeneous customers. Pervasive devices (including mobile smartphones) publish a huge amount of real world information, which afterwards is accessed through web browsers and applications. The adoption of an open standard interface between information publishers and consumers allows to reduce the gap in the technologies used on both sides, therefore, include new actors into the services, increase the service offers and increment the world-wide and cross-domain usage of services based on the Publish/Subscribe paradigm. Major European Industrial Entities supported by the EU Research Program are deriving a cross-domain Future Internet open standard technology to be adopted and used in any application domain by any customer for any needs. The reference open standard chosen is OMA's NGSI. The open standard based technological binding created in the FI-WARE EU funded project and provided with an open reference implementation performed by Telecom Italia is demonstrated through examples of Augmented-Reality and social-impacting services that improve the quality of life for people (including those decease affected).","","978-92-61-14061-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6533786","publish-subscribe;reference standard;service enabler;augmented reality;e-learning;social impact;augmented reality","Context;Standards;Electronic publishing;Mobile communication;Augmented reality;Telecommunications;Communities","augmented reality;Internet;mobile computing;online front-ends;smart phones","standard-based publish-subscribe service enabler;social applications;augmented reality services;publish-subscribe mechanism;open mobile alliance;next generation services interface;NGSI open standard;heterogeneous customers;pervasive devices;mobile smartphones;information publishers;publish-subscribe paradigm;European industrial entities;EU research program;OMA NGSI;FI-WARE EU;Telecom Italia","","","3","12","","17 Jun 2013","","","IEEE","IEEE Conferences"
"Virtual Reality Evolution in Brazil: A Survey over the Papers in the ""Symposium on Virtual and Augmented Reality""","J. P. Detroz; M. G. Jasinski; R. Bosse; T. L. Berlim; M. Da Silva Hounsell","PPGCA-Graduate Program in Applied Computing, UDESC-Santa Catarina State University, Joinville, Brazil; PPGCA-Graduate Program in Applied Computing, UDESC-Santa Catarina State University, Joinville, Brazil; PPGCA-Graduate Program in Applied Computing, UDESC-Santa Catarina State University, Joinville, Brazil; PPGCA-Graduate Program in Applied Computing, UDESC-Santa Catarina State University, Joinville, Brazil; DCC - Dept. of Comput. Sci., UDESC - Santa Catarina State Univ., Brazil","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","210","219","Virtual Reality is becoming a mature technology field. To understand its origins and foresee strategies, a study on the last decade of papers published in the Brazilians' most prominent symposium (the SVR - Symposium on Virtual and Augmented Reality) has been carried out. Papers were classified according to language, international participants, areas and sub-areas of application and related technologies. Although oversees participants has proven not constant, papers published in English has proven stable to SVR editions. The study also shows that health related applications have received most of the attention although techniques and tools proposal have raised the most recently which could be related to the low-level programming languages and frameworks preferences. The number of Augmented Reality papers has grown steadily and a great variety of underlying knowledge fields (such as 3D interaction and real-time simulation) are persistent topics of interest. An expected shift from VRML to other 3D Web technologies have already happened but there are just a few research papers devoted to formulative, evaluative or descriptive approaches. Data show that by improving the research budget to the area could impact productivity, a centralized database of publications would facilitate recovering and analyzing past contributions and, that enforcing more scientifically rigorous and English-written papers could raise the quality and visibility of Brazilians' research in VR.","","978-1-4799-4261-9","10.1109/SVR.2014.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913095","Virtual Reality;Augmented Reality;Brazil;History","Augmented reality;Three-dimensional displays;Education;Communities;Avatars;Real-time systems","augmented reality","virtual reality evolution;Brazil;SVR;Symposium on Virtual and Augmented Reality;health related applications;low-level programming languages;knowledge fields;3D interaction;real-time simulation;VRML;3D Web technologies","","","","9","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"An approach to develop a LabVIEW based augmented reality application for smartphones","E. G. Migliore; J. Z. Abad; F. Q. Palomeque","Prometeo Project Researcher-SENESCYT, Ecuador; Universidad Politécnica Salesiana, Cuenca, Ecuador; Universidad Politécnica Salesiana, Cuenca, Ecuador","IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society","22 Dec 2016","2016","","","4970","4975","This paper presents an approach to develop a smartphone augmented reality application for automation and control education. This approach is based on the client/server architecture. On the server side, the standard academic research software LabVIEW platform is used for real time pattern recognition processing, enabling the quick augmented reality application creation. Adobe Flash technology is used to get a well-designed friendly graphical client interface. The employment of this application provides students in an amusing and straightforward way, all the information they required to both facilitate and increase their learning process. The computer-generated content that overlays the real-world environment is relates to the laboratory practices and equipment. Besides that, this application has incorporated innovative features that make augmented reality sensible, not only by the real-world environment, but also by the date it is being used. In other words, supplementary computer-generated content may vary according to the date the student uses the application.","","978-1-5090-3474-1","10.1109/IECON.2016.7793848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7793848","adobe AIR;augmented learning environment;augmented reality;labVIEW;smartphones","Servers;Inspection;Pattern recognition;Augmented reality;Smart phones;Real-time systems;Cameras","augmented reality;client-server systems;computer aided instruction;control engineering computing;control engineering education;graphical user interfaces;pattern recognition;virtual instrumentation","smartphone augmented reality;automation education;control education;client-server architecture;standard academic research software;LabVIEW platform;real time pattern recognition processing;Adobe Flash technology;graphical client interface;learning process;computer-generated content;laboratory practices;laboratory equipment","","2","","30","IEEE","22 Dec 2016","","","IEEE","IEEE Conferences"
"Augmented ""Ouch!"". How to Create Intersubjective Augmented Objects into Which We can Bump","N. Liberati","Dept. of International Liberal Studies, Chukyo University","2015 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design","10 Dec 2015","2015","","","21","26","The aim of this work is to provide the elements to design an inter-subjective augmented reality in order to make the augmented objects part of our everyday world. This work will analyse intersubjectivity from a phenomenological point of view using the works by Husserl and Schutz. Thanks to these two authors it will be possible to understand how our in-tersubjective world is constituted by highlighting its constitutive elements. Therefore, it will be possible to make the inverse process and to create an intersubjective augmented world. While phenomenology starts from an intersubjective world and it analyses how such an intersubjectivity it is possible, this work will start from the constitutive elements of intersubjectivity in order to apply them in augmented reality and to create an intersubjective augmented world. This work will be divided in two main parts. The first part of the work will focus on intersubjectivity from a phenomenological point of view and the second part will focus on the application of these elements on augmented reality. It will show how it is mandatory to create objects which could make us scream ""Ouch"" while bumping into them and augmented presences which resist to us.","","978-1-4673-9628-8","10.1109/ISMAR-MASHD.2015.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350730","Phenomenology;Intersubjectivity;Augmented Reality;Paramount Reality;Lifeworld;Husserl;Schutz","Augmented reality;Face;Psychology;Media;Art;Resists;Indexes","augmented reality","augmented Ouch!;intersubjective augmented objects;intersubjective augmented reality;intersubjective augmented world;phenomenology;augmented presences","","7","","37","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"Workshop on Virtual, Augmented and Mixed Reality in Education (VAMrE 2017) Summary","K. Chang; J. Zhang; T. Liu",NA; NA; NA,"2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","293","293","Summary form only given, as follows. A complete record of the workshop was not made available for publication as part of the conference proceedings. This Workshop on Virtual, Augmented and Mixed Reality in Education (VAMrE 2017) offers an opportunity to exchange, publish, and discuss ideas and thoughts regarding the scope of research related to the applications of VAMR in education. The theme is focused on, but not limited to, applications of VAMR in the development of teaching strategies, establishment of a teaching environment, improvement of learning effectiveness, application of psychological factors related to learning, and other related research.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088508","","Augmented reality","","","","2","","","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Evaluating controls for a point and shoot mobile game: Augmented Reality, Touch and Tilt","A. Marzo; B. Bossavit; M. Hachet","public University of Navarre, Pamplona, Spain; public University of Navarre, Pamplona, Spain; INRIA Bordeaux, Talence, France","2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design (ISMAR-MASH'D)","27 Oct 2014","2014","","","59","62","Controls based on Augmented Reality (AR), Tilt and Touch have been evaluated in a point and shoot game for mobile devices. A user study (n=12) was conducted to compare the three controls in terms of player experience and accuracy. Tilt and AR controls provided more enjoyment, immersion and accuracy to the players than Touch. Nonetheless, Touch caused fewer nuisances and was playable under more varied situations. Despite the current technical limitations, we suggest to incorporate AR controls into the mobile games that supported them. Nowadays, AR controls can be implemented on handheld devices as easily as the more established Tilt and Touch controls. However, this study is the first comparison of them and thus its findings could be of interest for game developers.","2381-8360","978-1-4799-6887-9","10.1109/ISMAR-AMH.2014.6935439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935439","Mobile;player experience;videogames;controller;augmented reality;tilt;touch","Abstracts;Indexes;Games;Aerospace electronics;Vectors;Accuracy;Correlation","augmented reality;computer games;mobile computing","point and shoot mobile game;augmented reality;tilt-and-touch;mobile device","","2","","18","IEEE","27 Oct 2014","","","IEEE","IEEE Conferences"
"Adapting Image Analysis Measures of Visual Clutter to Multiple Plane Augmented Reality User Interfaces","J. Flittner; J. L. Gabbard",Virginia Tech; Virginia Tech,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","92","95","This study focuses on understanding and quantifying the effects of clutter in multi-plane Augmented Reality User Interfaces (AR UI’s). It determines if image analysis measures of visual clutter can be expanded from single plane AR UI’s to multi-plane AR UI’s as well as examining the effects of multiple UI planes, UI clutter, and target clutter have on user performance. Image analysis measures of clutter were specifically chosen as they can be applied to complex and naturalistic images that may be found in AR UI applications and have shown use in predicting user performance in single plane AR UI’s. In this experiment, twelve participants performed a visual search task of locating a target object in an array of objects where objects were located in planes of different distances. Participants completed this task under two different clutter levels (low and high) against seven different AR UI plane arrays (2m, 4m, 6m, 2m4m, 2m6m, 4m6m, 2m4m6m) where the target was found in every available AR UI plane for each combination, with repetition. Task performance was measured through response time. Results show significant differences in response time between clutter levels, and number of planes. The end goal of this research is to build upon previous studies to develop a clutter score algorithm for AR UI’s that can predict user performance based on image analysis measures.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585870","Augmented reality;visual clutter","Visualization;Image analysis;Atmospheric measurements;User interfaces;Particle measurements;Time measurement;Time factors","augmented reality;clutter;feature extraction;image processing;user interfaces","single plane;visual search task;AR UI plane arrays;clutter score algorithm;image analysis measures;visual clutter;augmented reality;UI clutter;target clutter;naturalistic images;user interfaces","","1","","25","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Occlusion Handling in Outdoor Augmented Reality using a Combination of Map Data and Instance Segmentation","T. Ogawa; T. Mashita",NTT DOCOMO Inc; Osaka University,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","246","250","Visual consistency between virtual objects and the real environment is essential to improve user experience in Augmented Reality (AR). Occlusion handling is one of the key factors for maintaining visual consistency. In an application scenario for small areas such as indoors, various methods are applicable to acquire a depth information required for occlusion handling. However, in an application scenario in wide environment such as outdoor especially a scene including many buildings, occlusion handling is a challenging task because acquiring an accurate depth map is challenging. Several studies that have tackled this problem utilized 3D models of real buildings, but they have suffered from the accuracy of 3D models and camera localization. In this study, we propose a novel occlusion handling method using a monocular RGB camera and map data. Our method detects the regions of buildings in a camera image using an instance segmentation method and then obtains accurate occlusion handling in the image from each building instance and corresponding building map. The qualitative evaluation shows the improvement in the occlusion handling with buildings. The user study also shows the better performance of the perception of depth and distance than a model-based method.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585830","Augmented Reality;Occlusion;Map data;Instance segmentation","Location awareness;Visualization;Solid modeling;Image segmentation;Three-dimensional displays;Buildings;Cameras","augmented reality;cameras;computer graphics;image colour analysis;image segmentation","corresponding building map;occlusion handling;buildings;outdoor Augmented Reality;map data;visual consistency;application scenario;accurate depth map;novel occlusion;instance segmentation method;accurate occlusion","","1","","19","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Mobile Application to Support Interventions in Electric Power Substations with Augmented Reality Techniques and BIM","M. J. Aureliano Júnior; I. A. Peixoto; G. F. Cyrino; I. C. d. Santos Peres; A. Cardoso; E. A. Lamounier Júnior; G. F. d. Lima","Faculdade de Engenharia Elétrica, Universidade Federal de Uberlândia, Uberlândia, Brasil; Faculdade de Engenharia Elétrica, Universidade Federal de Uberlândia, Uberlândia, Brazil; Faculdade de Engenharia Elétrica, Universidade Federal de Uberlândia, Uberlândia, Brazil; Faculdade de Engenharia Elétrica, Universidade Federal de Uberlândia, Uberlândia, Brazil; Faculdade de Engenharia Elétrica, Universidade Federal de Uberlândia, Uberlândia, Brazil; Faculdade de Engenharia Elétrica, Universidade Federal de Uberlândia, Uberlândia, Brazil; Faculdade de Engenharia Elétrica, Universidade Federal de Uberlândia, Uberlândia, Brazil","2018 20th Symposium on Virtual and Augmented Reality (SVR)","19 Aug 2019","2018","","","243","247","Smartphones can be considered, for the most part, devices for leisure and entertainment. However, when analyzing the potential of today's handsets, it is remarkable the ability of these devices to meet the needs of professionals. This is due to the great technological potential contained in this device making it very efficient, complete and highly portable. Therefore, the easy handling and the low financial cost of acquiring state-ofthe- art smartphones has led to the development of countless benefits research when applied to the job market. From the set of tools that it has, a path to be traced is the solutions in Augmented Reality (AR) on mobile platforms. The ability to process and execute AR applications related to the use of the portable camera that makes it possible, makes possible the appearance of compatible application ideas. In this way, this article describes the development of a mobile application with AR technologies to minimize the risks of professionals working in high risk areas, as well as the incentive to increase worker familiarization in these areas. In this way, a prototype was developed that, through flat markers, presents three-dimensional models developed using Building Information Modeling (BIM) concepts for the user, accomplishing the stated expectations and proving the prosperity of researches in the AR areas, when applied to high risk sectors.","","978-1-7281-0604-5","10.1109/SVR.2018.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802393","Smartphone;Augmented Reality;BIM;Information Visualization;Safety","","augmented reality;building information modelling;mobile computing;power engineering computing;smart phones;solid modelling;substations","mobile platforms;portable camera;mobile application;AR technologies;electric power substations;smartphones;building information modeling;BIM concepts;augmented reality;three-dimensional models;flat markers","","1","","0","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"Walking Through Walls: The Effect of Collision-Based Feedback on Affordance Judgments in Augmented Reality","H. C. Gagnon; D. Na; K. Heiner; J. Stefanucci; S. Creem-Regehr; B. Bodenheimer","University of Utah, USA; Vanderbilt University, USA; University of Utah, USA; University of Utah, USA; University of Utah, USA; Vanderbilt University, USA","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","266","267","Feedback about actions in augmented reality (AR) is limited and can be ambi due to the nature of interacting with virtual objects. AR devices also have a restricted field of view (FOV), limiting the amount of available visual information that can be used to perform an action or provide feedback during or after an action. We used the Microsoft HoloLens 1 to investigate whether perceptual-motor, collision-based outcome feedback calibrates judgments of whether one can pass through an aperture in AR. Additionally, we manipulated the amount of information available within the FOV by having participants view the aperture at two different distances. Feedback calibrated passing-through judgments at both distances but resulted in an overestimation of the just-passable aperture width. Moreover, the far viewing condition had more overestimation of just-passable aperture width than the near viewing condition.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585892","Augmented reality;affordances;feedback;perception","Performance evaluation;Legged locomotion;Visualization;Limiting;Multimedia systems;Affordances;Apertures","augmented reality;calibration;feedback;human factors","Microsoft HoloLens 1;perceptual-motor;FOV;just-passable aperture width;viewing condition;walls;collision-based feedback;affordance judgments;augmented reality;virtual objects;visual information;collision-based outcome feedback","","","","3","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Transdisciplinary approach to Augmented reality Digital heritage Mobile applications","I. Tsokova; A. Stephenson","De Montfort University, Leicester, United Kingdom; De Montfort University, Leicester, United Kingdom","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","34","39","This paper follows the development and collaboration behind the creation of an Augmented reality (AR) mobile application. Sponsored by the Nupur arts organization and commissioned by the Arts Council England, we were asked to create a digital heritage experience telling the story of Gujarati migrants from East Africa and India during the 70s and 80s in Leicester, United Kingdom. This paper examines how being in a transdisciplinary team aided in the successful creation of 3D scanned models, which were later imported into an AR environment. Finally, this paper concludes with an analysis of the cultural implication of mobile applications such as this one and the social and communal impact they might have.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585861","Augmented reality;digital heritage;transdisciplinary collaboration;AR-enhanced cultural artefacts","Solid modeling;Art;Three-dimensional displays;Collaboration;Organizations;Africa;Mobile applications","augmented reality;history;mobile computing;multimedia computing;solid modelling","digital heritage experience;Gujarati migrants;augmented reality digital heritage mobile applications;East Africa;India;United Kingdom;story telling;3D scanned models;AR environment","","","","27","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Two-way Augmented Reality Co-location Under Telemedicine Context","M. Li; T. Slijkhuis; R. Huigen; A. Albayrak; D. van Eijk",TU Delft / Xi’an Jiaotong University; Royal Philips; Maritime Medical Applications BV; TU Delft; TU Delft,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","504","505","The medical care responsibilities are often on the shoulders of nonprofessionals such as captains who are equipped with forty hours of designated training every five years. However, this training is neither enough for the captains to handle medical incidents nor releases their stress during the treatment. Currently, captains have very limited support from a medical expert, only via phone call or email from the Radio Medical Services. Thus, the authors explored that how the two-way augmented reality (AR) can support the collaboration between captains and doctors for a better quality of care. A Human-Centred Design approach is applied in this study, including field study and user testing. The lean user experience method was applied with fast prototyping-testing loops. The main findings are AR played an essential role to boost confidence on the captain's side, and the real value of AR is in supporting medical skills like suturing and abdominal searching. This study serves as a pilot research, thus it was limited by small sample size and qualitative method. Improving the communication between the captains and doctors is key for future studies.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00121","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585828","Collaborative augmented reality;co-location;telemedicine;remote expert;Human-centered computing","Training;Visualization;Telemedicine;Collaboration;Shoulder;Medical services;User experience","augmented reality;biomedical education;health care;interactive systems;medical computing;medical information systems;patient care;telemedicine;user centred design","captains;human-centred design;lean user experience method;fast prototyping-testing loops;medical skills;telemedicine context;medical care responsibilities;designated training;medical incidents;medical expert;two-way augmented reality co-location;radio medical services;doctors","","","","8","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Heat Pain Threshold Modulation By Experiencing Burning Hands in Augmented Reality","D. Eckhoff; A. Cassinelli; C. Sandor","School of Creative Media, City University of Hong Kong, Hong Kong; School of Creative Media, City University of Hong Kong, Hong Kong; School of Creative Media, City University of Hong Kong, Hong Kong","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","352","353","Visual stimuli can modulate the temperature at which people perceive heat pain. However, very little research exists on the potential use of Augmented Reality (AR) to modulate the heat pain threshold (HPT). In this paper, we investigate whether participants’ HPTs can be modulated observing virtual flames on their hands through a video see-through head-mounted display (VST-HMD). In a pilot study (n = 7), we found that rendering virtual flames had a significant effect (p < 0.05) on the HPT. The virtual flames on the participant’s hand led to a decrease in the temperature at which they would perceive pain related to heat. These results indicate that AR-induced stimuli may be an effective way to achieve top-down modulation of the experience of pain.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585842","Human-centered computing;Mixed / augmented reality Applied computing;Psychology","Heating systems;Visualization;Head-mounted displays;Pain;Fires;Modulation;Rendering (computer graphics)","augmented reality;biothermics;helmet mounted displays;rendering (computer graphics)","HPT;AR-induced stimuli;heat pain threshold modulation;burning hands;augmented reality;visual stimuli;video see-through head-mounted display;virtual flames rendering;VST-HMD","","","","13","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Effects of a Distracting Background and Focal Switching Distance in an Augmented Reality System","M. S. Arefin; N. Phillips; A. Plopski; J. E. Swan",Mississippi State University; Mississippi State University; University of Otago; Mississippi State University,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","96","99","Many augmented reality (AR) applications require observers to shift their gaze between AR and real-world content. To date, commercial optical see-through (OST) AR displays have presented content at either a single focal distance, or at a small number of fixed focal distances. Meanwhile, real-world stimuli can occur at a variety of focal distances. Therefore, when shifting gaze between AR and real-world content, in order to view new content in sharp focus, observers must often change their eye’s accommodative state. When performed repetitively, this can negatively affect task performance and eye fatigue. However, these effects may be under reported, because past research has not yet considered the potential additional effect of distracting real world backgrounds.An experimental method that analyzes background effects is presented, using a text-based visual search task that requires integrating information presented in both AR and the real world. An experiment is reported, which examined the effect of a distracting background versus a blank background, at focal switching distances of 0, 1.33, 2.0, and 3.33 meters. Qualitatively, a majority of the participants reported that the distracting background made the task more difficult and fatiguing. Quantitatively, increasing the focal switching distance resulted in reduced task performance and increased eye fatigue. However, changing the background, between blank and distracting, did not result in significant measured differences. Suggestions are given for further efforts to examine background effects.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00029","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585881","augmented reality;focal distance switching;accommodation;background","Meters;Visualization;Atmospheric measurements;Optical switches;Observers;Fatigue;Particle measurements","augmented reality;data visualisation;human factors;visual perception","real-world stimuli;shifting gaze;real-world content;observers;eye fatigue;world backgrounds;background effects;text-based visual search task;distracting background;blank background;focal switching distance;reduced task performance;augmented reality;single focal distance;fixed focal distances","","","","12","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Co-Design of an Augmented Reality Maintenance Tool for Gas Pressure Regulation Stations","J. Hertel; J. Gabel; L. Kruse; M. Wollborn; F. Steinicke",Universität Hamburg; Universität Hamburg; Universität Hamburg; Gasnetz Hamburg GmbH; Universität Hamburg,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","720","724","While augmented reality (AR) gets established in many use cases in the broad field of industrial, education, and entertainment applications, so far, AR has not been used in gas pressure regulation stations (GPRS). In an iterative co-design process, we have developed a first AR prototype to support maintenance work in such GPRS environments. Together with different stakeholders, in particular the technical staff as potential end-users, we discussed and gathered the requirements, observed workers interacting with the AR prototype on-site, and collected feedback, but also identified problems and limitations. Eventually, we deduced two challenging use cases, (i) displaying expandable 3D models of the components built into the station, and (ii) digitizing an inspection form in AR to facilitate the inspection task. We describe the co-design process, its findings, and introduce lessons-learned for the resulting AR prototype.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974541","Human-centered computing-Interaction paradigms-Mixed / augmented reality;Human-centered computing-Human computer interaction (HCI)-HCI design and evaluation methods-Field studies;Human-centered computing-Interaction design-Interaction design process and methods-Interface design prototyping","Solid modeling;Three-dimensional displays;Prototypes;Maintenance engineering;Inspection;Regulation;Stakeholders","augmented reality;feedback;inspection;maintenance engineering;personnel;production engineering computing;software engineering","AR prototype;augmented reality maintenance tool;broad field;challenging use cases;entertainment applications;gas pressure regulation stations;GPRS environments;iterative co-design process;maintenance work;particular the technical staff;potential end-users","","","","14","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"A computer aided education system based on augmented reality by immersion to 3-D magnetic field","S. Matsutomo; T. Manabe; V. Cingoski; S. Noguchi","Niihama College, National Institute of Technology, Niihama, Japan; Niihama College, National Institute of Technology, Niihama, Japan; Faculty of Electrical Engineering, University “Goce Delcev” - Stip, Skopje, Macedonia; Hokkaido University, Graduate School of Information Science and Technology, Sapporo, Japan","2016 IEEE Conference on Electromagnetic Field Computation (CEFC)","16 Jan 2017","2016","","","1","1","In this paper, a visualization system of immersion into 3D magnetic field based on the augmented reality technology using a head mounted display, for education purpose, is presented. By utilizing the proposed visualization method, a user can easily observe and perceive in real-time a magnetic field distribution generated by single/multiple sources (e.g., permanent magnets and/or coils) and other magnetic/nonmagnetic material in an augmented 3-D space.","","978-1-5090-1032-5","10.1109/CEFC.2016.7816102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816102","Augmented reality technology;education;electromagnetic field analysis;visualization","Visualization;Magnetic fields;Real-time systems;Magnetic flux;Augmented reality;Three-dimensional displays;Permanent magnets","augmented reality;coils;educational aids;electronic engineering education;magnetic fields;permanent magnets","computer aided education system;3-D magnetic field;visualization system;augmented reality technology;head mounted display;magnetic field distribution;permanent magnets;coils;magnetic material;nonmagnetic material;augmented 3-D space","","1","","2","IEEE","16 Jan 2017","","","IEEE","IEEE Conferences"
"AACT: A mobile Augmented Reality application for Art Creation","A. Bhargava; J. Bertrand; S. V. Babu","Clemson University, Clemson, USA; Clemson University, Clemson, USA; Clemson University, Clemson, USA","2017 IEEE Symposium on 3D User Interfaces (3DUI)","6 Apr 2017","2017","","","254","255","In this paper, we present Augmented-Art Creation Tool (AACT) as our solution to the IEEE 3DUI 2017 challenge. Our solution employs multi-finger touch gestures along with the built-in camera and accelerometer on a mobile device for interaction in an Augmented Reality (AR) setup. We leverage a user's knowledge of touch gestures like pinching, swiping, etc. and physical device movement to interact with the environment making the metaphor intuitive. The system helps prevent occlusion by using the accelerometer and allowing touch gestures anywhere on the screen. The interaction metaphor allows for successful art piece creation and assembly.","","978-1-5090-6716-9","10.1109/3DUI.2017.7893368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893368","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities","Cameras;Mobile handsets;Pressing;Augmented reality;Accelerometers;Art;Performance evaluation","accelerometers;art;augmented reality;cameras;human computer interaction;mobile computing;user interfaces","AACT;augmented-art creation tool;mobile augmented reality;multifinger touch gesture;camera;accelerometer;mobile device;AR;interaction metaphor","","1","","2","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Mobile augmented reality application for Telugu language learning","P. Meda; M. Kumar; R. Parupalli","A Scientific Society under Ministry of Communications and Information Technology, Government of India; A Scientific Society under Ministry of Communications and Information Technology, Government of India; A Scientific Society under Ministry of Communications and Information Technology, Government of India","2014 IEEE International Conference on MOOC, Innovation and Technology in Education (MITE)","26 Jan 2015","2014","","","183","186","In the next generation ubiquitous computing, all the computing nodes would be networked using sensors embedded in the surrounding environment including wearable computing devices and smart phones. Augmented Reality(AR) is one of the ubiquitous computing technologies that can be used for realizing Internet of Things(IoT) applications. This paper deals with development & implementation of a mobile augmented reality(AR) application for language learning. Mobile AR application exploits smart phone's processing capabilities for sensing external objects using camera, augment real world objects(images) with virtual data for learning telugu language. A simple pilot experiment was conducted to study efficacy and usefulness of developed prototype application for language learning. Experimental results validates and showcases how augmented reality can be used for language learning utilizing smart phones inbuilt camera sensor.","","978-1-4799-6876-3","10.1109/MITE.2014.7020267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7020267","Augmented Reality;Mobile Learning;Ubiquitous Computing;Internet of Things(IoT);Optical Character Recognition(OCR);Android;Camera Sensor;Telugu Language Learning","Mobile communication;Augmented reality;Smart phones;Optical character recognition software;Cameras;Accuracy;Lighting","augmented reality;cameras;computer aided instruction;image sensors;Internet of Things;mobile computing;natural language processing;smart phones","mobile augmented reality application;Telugu language learning;ubiquitous computing;wearable computing devices;smart phones;Internet of Things applications;IoT applications;mobile AR application;augment real world objects;camera sensor","","8","","13","IEEE","26 Jan 2015","","","IEEE","IEEE Conferences"
"Illusion of depth in spatial augmented reality","S. Schmidt; G. Bruder; F. Steinicke","Department of Informatics, University of Hamburg; Department of Informatics, University of Hamburg; Department of Informatics, University of Hamburg","2016 IEEE VR 2016 Workshop on Perceptual and Cognitive Issues in AR (PERCAR)","8 Sep 2016","2016","","","1","6","Spatial augmented reality (SAR) is an emerging paradigm that differs from its origin, the traditional augmented reality (AR), in many regards. While traditional AR is a well-studied field of research, the characteristic features of SAR and their implications on the perception of spatial augmented environments have not been analyzed so far. In this paper, we present one of the first studies, which investigates the perceived spatial relationships between a user and their SAR environment. The results indicate that perceived depth of realworld objects can be manipulated by projecting illusions, such as color or blur effects, onto their surfaces. For the purpose of evaluating and comparing the illusions of interest, we developed a prototypic setup for conducting perceptual SAR experiments. Since this testing environment differs significantly from its counterparts in virtual and augmented reality, we also discuss potential challenges, which arise from the nature of SAR experiments.","","978-1-5090-0838-4","10.1109/PERCAR.2016.7562417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562417","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial;augmented;and virtual realities","Image color analysis;Augmented reality;Testing;Electronic mail;Two dimensional displays;Light sources;Atmospheric measurements","augmented reality;multimedia computing","depth illusion;spatial augmented reality;spatial augmented environments;spatial relationships;SAR environment;blur effects;prototypic setup","","4","","23","IEEE","8 Sep 2016","","","IEEE","IEEE Conferences"
"An augmented reality application for smart campus urbanization: MSKU campus prototype","U. Özcan; A. Arslan; M. İlkyaz; E. Karaarslan","Department of Computer Engineering, Mugla Sitki Kocman University, Mugla, Turkey; Department of Computer Engineering, Mugla Sitki Kocman University, Mugla, Turkey; Department of Computer Engineering, Mugla Sitki Kocman University, Mugla, Turkey; Department of Computer Engineering, Mugla Sitki Kocman University, Mugla, Turkey","2017 5th International Istanbul Smart Grid and Cities Congress and Fair (ICSG)","15 Jun 2017","2017","","","100","104","Augmented Reality applications are used in almost every area of our lives. These applications have been started to use in the town planning and smart city applications. In this study, a prototype application was developed using this technology. As a smart city/smart campus application, Mugla Sitki Kogman University Campus application will be made. The aim of this study is to adapt some of the smart city features to a campus. In addition, this study is an attempt to generate a visual aid for the smart campus concept. An augmented reality prototype is developed for the MSKU campus. Image detection methods are used to detect the places. External data sources including Twitter data will be used to get information about the detected places and presented on the screen. Methods, design, and findings are discussed.","","978-1-5090-5938-6","10.1109/SGCF.2017.7947610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947610","Smart City;Augmented Reality;City Planning;Image Processing;Smart Campus","Augmented reality;Smart cities;Databases;Prototypes;Feature extraction;Mobile communication","augmented reality;image processing;object detection;smart cities;town and country planning","augmented reality application;smart campus urbanization;MSKU campus prototype;town planning;smart city applications;prototype application;Mugla Sitki Kogman University Campus application;augmented reality prototype;smart campus concept;image detection methods","","10","","13","IEEE","15 Jun 2017","","","IEEE","IEEE Conferences"
"An Interactive Augmented Reality Chess Game Using Bare-Hand Pinch Gestures","M. Bikos; Y. Itoh; G. Klinker; K. Moustakas","Electrical and Computer Engineering Department, University of Patras, Patras-Rion, Greece; Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany; Electrical and Computer Engineering Department, University of Patras, Patras-Rion, Greece","2015 International Conference on Cyberworlds (CW)","4 Feb 2016","2015","","","355","358","In order to produce realistic simulations and enhance immersion in augmented reality systems, solutions must not only present a realistic visual rendering of virtual objects, but also allow natural hand interactions. Most approaches capable of understanding user interaction with virtual content can often be restrictive or computationally expensive. To cope with these problems, we demonstrate a method which employs user's thumb and forefinger to interact with the virtual content in a natural way, utilizing a single RGB-D camera. Based on this method, we develop and realise an augmented reality chess game, focused on providing an immersive experience to users, so that they are able to manipulate virtual chess pieces seamlessly over a board of markers and play against a chess engine.","","978-1-4673-9403-1","10.1109/CW.2015.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398440","Augmented Reality;Virtual Object Manipulation;Pinch Gesture Detection","Three-dimensional displays;Cameras;Games;Augmented reality;Engines;Image color analysis;Real-time systems","augmented reality;computer games;human computer interaction;rendering (computer graphics)","chess engine;virtual chess pieces;RGB-D camera;virtual content;user interaction;natural hand interactions;virtual objects;realistic visual rendering;augmented reality systems;realistic simulations;bare-hand pinch gestures;interactive augmented reality chess game","","9","","10","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"Augmented reality crossover gamified design for sustainable engineering education","F. H. Salman; D. R. Riley","Learning & Performance Systems, Pennsylvania State University, USA; Architectural Engineering, Pennsylvania State University, USA","2016 Future Technologies Conference (FTC)","19 Jan 2017","2016","","","1353","1356","This paper captures the design of a crossover Augmented Reality (AR) gamified learning experience called GreenDesigners focused on sustainable engineering education for high school students. Located at a solar demonstration house, our design leverages the functionality of an Augmented Reality interface developed to coordinate learning of sustainable engineering design concepts and practices across real-world (informal) and classroom settings (formal). It is anticipated that such “seam-ful” crossover learning and assessment designs could enable a preparatory transition from informal, active learning activities to formal design-focused activities thus expanding learning opportunities for youth within STEM fields.","","978-1-5090-4171-8","10.1109/FTC.2016.7821781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821781","Augmented Reality;sustainable engineering design;learner interaction;gamified curriculum;crossover learning","Games;Education;Augmented reality;Usability;Green products;Mobile communication;Videos","augmented reality;computer aided instruction;computer games;educational institutions;engineering education","crossover gamified design;sustainable engineering education;augmented reality gamified learning experience;AR;high-school students;solar demonstration house;augmented reality interface development;sustainable engineering design concepts;classroom settings;STEM fields;learning opportunities","","7","","18","IEEE","19 Jan 2017","","","IEEE","IEEE Conferences"
"Surface Micro-Reflector Array for Augmented Reality Display","Z. Yan; C. Du; L. Zhang","Chongqing Institutes of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing, China; Chongqing Institutes of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing, China; Unit 95903, Wuhan, China","IEEE Photonics Journal","9 Mar 2020","2020","12","2","1","9","Geometric optical waveguide display can significantly miniaturize the augmented reality eyeglasses, but suffers from the ghost image. In this paper, a method using surface micro-reflector array is proposed, which can dramatically suppress the ghost image. The transmission and expansion of the light bearing image are completed by using planar waveguide and micro-reflector array embedded in the surface layer of waveguide. The image quality is improved by using the dual channel to eliminate ghost image. The imaging process of optical system is modeled and simulated. The surface micro-reflector array waveguide element of 3 mm thickness is prepared for verification. The whole optical system has the advantages of simple structure, easy preparation and high structural strength. The display field of view is shown to be 25° × 25°, and the size of the full field of view area is 15 mm with even light distribution. What's more, the uniformity of imaging intensity is better than 20%, and the image is clear without ghost image, which can effectively realize the fusion of the virtual image and the real environment. Thus, the efficiency of augmented reality is greatly improved, and the danger of human eye safety is effectively avoided.","1943-0655","","10.1109/JPHOT.2020.2971622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981897","Augmented reality;waveguide;surface micro-reflector array;virtual image","Optical waveguides;Optical imaging;Optical surface waves;Surface waves;Optical polarization;Geometrical optics;Augmented reality","augmented reality;display devices;geometrical optics;image fusion;micro-optics;optical arrays;optical images;optical waveguides","imaging intensity;even light distribution;display field-of-view;structural strength;surface microreflector array waveguide element;surface layer;transmission;augmented reality eyeglasses;geometric optical waveguide display;augmented reality display;virtual image fusion;optical system;imaging process;image quality;planar waveguide;light bearing image;ghost image;size 3.0 mm","","6","","18","CCBY","4 Feb 2020","","","IEEE","IEEE Journals"
"An Educational Augmented Reality App To Facilitate Learning Experience","S. Sunil; S. S. Kumaran Nair","Indian School, Al Seeb Muscat, Sultanate of Oman; Department of Computing Middle East, Coventry University, Coventry, UK","2017 International Conference on Computer and Applications (ICCA)","23 Oct 2017","2017","","","279","282","Augmented Reality is changing education in a dramatic way and it brings a new dimension to teaching and learning practices through amazing visualization of the real world in an interactive environment. The aim of this research is focused at developing a prototype of mobile based Augmented Reality application using Vuforia and Unity which will be helpful and valuable for students in reinforcing their learning experience. Responses from students indicate that this application is very beneficial to improve their learning curiosity and their passion to learn.","","978-1-5386-2752-5","10.1109/COMAPP.2017.8079771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8079771","Augmented Reality;Unity;Vuforia;Learning;experience","Education;Augmented reality;Three-dimensional displays;Prototypes;Smart phones;Mobile communication;Visualization","augmented reality;computer aided instruction;data visualisation;interactive systems;mobile computing;teaching","learning practices;interactive environment;teaching practices;educational augmented reality app;learning experience facilitation;mobile based augmented reality application;real world visualization;Vuforia;Unity","","5","","22","IEEE","23 Oct 2017","","","IEEE","IEEE Conferences"
"Work-in-progress—ARETE - An Interactive Educational System using Augmented Reality","S. Masneri; A. Domínguez; F. Wild; J. Pronk; M. Heintz; J. Tiede; A. Nistor; G. Chiazzese; E. Mangina","Vicomtech Foundation, University of the Basque Country, San Sebastian, Spain; Vicomtech Foundation, Basque Research and Technology Alliance, San Sebastian, Spain; Institute of Educational Technology, The Open University, Milton Keynes, UK; Faculty of Behavioral and Movement Sciences, Vrije Universiteit, Amsterdam, The Netherlands; School of Informatics, University of Leicester, Leicester, UK; Chair of School Pedagogy, University of Würzburg, Würzburg, Germany; European Schoolnet, Brussels, Belgium; Istituto per le Tecnologie Didattiche, Consiglio Nazionale delle Ricerche, Palermo, Italy; School of Computer Science, University College Dublin (UCD), Dublin, Ireland","2020 6th International Conference of the Immersive Learning Research Network (iLRN)","4 Aug 2020","2020","","","283","286","ARETE (Augmented Reality Interactive Educational System) is a European project, which aims to develop an interactive toolkit for Augmented Reality (AR) content. In this work in progress paper, we describe the system which is currently being developed. The ARETE system follows human-centered interaction design practices and has a strong focus in interactive, multi-user and multi-lingual technologies. On completion, the system will be evaluated across three pilot studies. The three pilots will involve more than 3000 students across ten European countries and they will assess the impact of usage of the ARETE system and the educational value of AR for English literacy skills, STEM (Science, Technology, Engineering and Math) skills and in the implementation of Positive Behaviour Support in Schools (PBIS). ARETE will also be involved in the implementation of new standards for the creation of cross platform content and services as well as the creation of learning experience data repositories.","","978-1-7348995-0-4","10.23919/iLRN47897.2020.9155186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155186","augmented reality;digital education;interactive systems;standardization","Augmented reality;Standards;Education;Tools;Three-dimensional displays;Europe;Ecosystems","augmented reality;computer aided instruction;distance learning;human computer interaction;user centred design","European countries;ARETE system;educational value;work-in-progress-ARETE;Augmented Reality Interactive Educational System;European project;interactive toolkit;Augmented Reality content;progress paper;interaction design practices;multilingual technologies","","5","","16","","4 Aug 2020","","","IEEE","IEEE Conferences"
"3D augmented reality mobile navigation system supporting indoor positioning function","C. -S. Wang; Ding-Jung Chiang; Yi-Yun Ho","Dept. of Computer Science and Information Engineering, Aletheia University, Taipei, Taiwan; Dept. of Digital Multimedia Design, Taipei Chengshih University of Science & Technology, Taipei, Taiwan; Dept. of Computer Science and Information Engineering, Aletheia University, Taipei, Taiwan","2012 IEEE International Conference on Computational Intelligence and Cybernetics (CyberneticsCom)","14 Feb 2013","2012","","","64","68","“Oxford College,” well-known as “the earliest edification institution in northern Taiwan,” was planned by Rev. George Leslie Mackay. It is a typical Chinese and Western style architecture with rich historical and cultural content, now is a Class 2 national monument. This paper took “Oxford College” as an example to develop a 3D augmented reality mobile navigation system that supports the function of indoor positioning. This system collected the historical data to develop the 3D models according to the ratio of actual objectives, and constructed the 3D external and internal structures of Oxford College of the past and present. Moreover, this system combined RFID positioning function with the technology of markerless augmented reality to actively detect the location of visitors and to further instantaneously present 3D and multimedia navigation information on mobile devices.","","978-1-4673-0892-2","10.1109/CyberneticsCom.2012.6381618","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6381618","3D;Augmented Reality;mobile navigation;indoor;positioning;RFID;Localization;Oxford College;Mackay","Navigation;Augmented reality;Radiofrequency identification;Mobile handsets;Educational institutions;Mobile communication;Solid modeling","augmented reality;computerised navigation;exhibitions;humanities;mobile computing;radiofrequency identification;solid modelling","3D augmented reality;mobile navigation system;indoor positioning function;Oxford College;northern Taiwan;3D model;RFID positioning function;radiofrequency identification;multimedia navigation information;mobile device;markerless augmented reality;Class 2 national monument","","5","","9","IEEE","14 Feb 2013","","","IEEE","IEEE Conferences"
"wARna — Mobile-based augmented reality colouring book","M. F. Norraji; M. S. Sunar","Media and Game Innovation Centre of Excellence (MaGIC-X), Universiti Teknologi Malaysia, Malaysia; Media and Game Innovation Centre of Excellence (MaGIC-X), Universiti Teknologi Malaysia, Malaysia","2015 4th International Conference on Interactive Digital Media (ICIDM)","21 Jul 2016","2015","","","1","4","Usage of Augmented Reality (AR) in educational environment is not an alien thing recently, especially when considering the multimodality and interactivity nature of some AR application that proves to be a lot more immersive and engaging learning than its traditional counterpart. Regardless, another aspect of educational AR, or any AR app, that should not be overlooked is the robustness as well as the availability of the app itself. In this paper, we are discussing a type of mixed-reality book experience that augments a colouring book with user-manipulated three-dimensional (3D) contents in a mobile-based environment. We explore tracking approaches in AR for its efficiency as well as computational load that is most suitable for mobile environment, and we also investigate texture extraction and mapping method for 3D content. Our system is then based on a marker-based tracking system using fiducial marker and simple image processing technique for the texture extraction and mapping part.","","978-1-5090-1669-3","10.1109/IDM.2015.7516324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516324","Augmented Reality;Marker-based Detection;AR in Education;Texture Extraction","Three-dimensional displays;Augmented reality;Mobile communication;Image color analysis;Feature extraction;Libraries","augmented reality;computer aided instruction;feature extraction;image texture;mobile learning","wARna;mobile-based augmented reality colouring book augments;educational environment;multimodality interactivity;immersive application;learning engagement;mixed-reality book experience;user-manipulated three-dimensional contents;user-manipulated 3D contents;computational load;efficiency analysis;texture extraction;mapping method;3D content;marker-based tracking system;fiducial marker;image processing technique","","5","","8","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"Research and Development of Augmented Reality Children’s Puzzle Game Based on Vuforia","G. Wu; M. Qiu; Y. Zhang; Y. Zheng","Software School, Xiamen University, Xiamen, China; Software School, Xiamen University, Xiamen, China; Software School, Xiamen University, Xiamen, China; Software School, Xiamen University, Xiamen, China","2019 14th International Conference on Computer Science & Education (ICCSE)","23 Sep 2019","2019","","","354","359","The emergence of mobile augmented reality children's puzzle games conforms to the development of the information age. One augmented reality game named “Baby Running” was researched and developed, based on Unity engine and the Vuforia, which improves the interaction between the game and the player, and exercises the child's concentration and reaction. The paper will discuss the game planning, game system design, key technologies, game testing, and the system's conclusion and some future directions.","2473-9464","978-1-7281-1846-8","10.1109/ICCSE.2019.8845385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845385","Augmented Reality;Vuforia;Unity","Games;Augmented reality;Cameras;Education;Pediatrics;Engines;Software","augmented reality;computer games;mobile computing","augmented reality game;Vuforia;game planning;game system design;game testing;mobile augmented reality children;Baby Running;Unity engine","","4","","11","IEEE","23 Sep 2019","","","IEEE","IEEE Conferences"
"Augmented Reality Storytelling: A Transmedia Exploration","D. Santano; H. Thwaites","Centre for Research-Creation in Digital Media School of Arts, Sunway University, Selangor, Malaysia; Centre for Research-Creation in Digital Media School of Arts, Sunway University, Selangor, Malaysia","2018 3rd Digital Heritage International Congress (DigitalHERITAGE) held jointly with 2018 24th International Conference on Virtual Systems & Multimedia (VSMM 2018)","26 Aug 2019","2018","","","1","4","This research paper discusses the implementation of augmented reality in transmedia storytelling. The innovation was applied on the subject matter of culture and heritage. A range of content was designed for augmented reality distribution for the 2 research-creation output from the projects. The paper will discuss the consideration of the chosen content for AR distribution, its production design and lastly its limitation on the type of content that was chosen.","","978-1-7281-0292-4","10.1109/DigitalHeritage.2018.8809996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809996","augmented reality;transmedia;storytelling;culture and heritage;intangible heritage","Videos;Boats;Augmented reality;Interviews;Media;Three-dimensional displays;Business","augmented reality;computer aided instruction","AR distribution;production design;augmented reality storytelling;transmedia exploration;transmedia storytelling;innovation;heritage;augmented reality distribution;research-creation output","","4","","8","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"Markerless Augmented Reality based Interior Designing System","S. Sharma; Y. Kaikini; P. Bhodia; S. Vaidya","St Francis Institute of Engineering, College Mumbai University; St Francis Institute of Engineering, College Mumbai University; St Francis Institute of Engineering, College Mumbai University; St Francis Institute of Engineering, College Mumbai University","2018 International Conference on Smart City and Emerging Technology (ICSCET)","18 Nov 2018","2018","","","1","5","Large strides being made in digital technology, that digital architecture hasn't caught up effectively. Our application is a step in this direction, allowing users to view a 3D rendered model - a virtual resemblance of the physical furniture without any interruption of the markers - which can be viewed and configured in real time using our Augmented reality application. This study proposes a new method for applying Augmented Reality technology to interior design work, where a user can view virtual furniture and communicate with 3D virtual furniture data using a dynamic and flexible user interface.","","978-1-5386-1185-2","10.1109/ICSCET.2018.8537349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8537349","Augmented Reality (AR);Marker-less;Simultaneous location and mapping (SLAM);3D Rendering Models","Solid modeling;Three-dimensional displays;Augmented reality;Simultaneous localization and mapping;Smart phones;Cameras;Computational modeling","augmented reality;CAD;rendering (computer graphics);solid modelling;user interfaces","3D rendered model;physical furniture;Augmented Reality technology;interior design work;dynamic user interface;flexible user interface;interior designing system;markerless augmented reality;3D virtual furniture","","4","","5","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"Traditional Mask Augmented Reality Application","D. J. Santoso; W. S. Angga; F. Silvano; H. E. S. Anjaya; F. I. Maulana; M. Ramadhani","Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2021 International Conference on Information Management and Technology (ICIMTech)","14 Sep 2021","2021","1","","595","598","The industrial revolution 4.0 has become a challenge for various sectors in mastering information technology, one of which is the arts and culture sector. Cultural arts that are quite widely spread and developed in Indonesia are traditional masks. Traditional masks are one of the oldest and most beautiful cultures in Indonesia. However, with the development of the era to the digital world in the era of the industrial revolution 4.0, this beloved culture is fading due to the entry of foreign cultures and technological developments. Many young people who succeed the nation do not understand this cultural art, namely traditional masks. So those cultural arts such as traditional masks can still keep up with the development of digital technology in industry 4.0, we conduct research to use technology to preserve this traditional mask culture. The research uses the ADDIE method starting with Analyze, Design, Develop, Implement, and Evaluate. We took some examples of traditional masks such as Malangan masks, Cirebon masks, and Panji masks from several regions in Indonesia. This research implements marker-based Augmented reality technology and makes a traditional mask book that can be a means of augmented reality.","","978-1-6654-4937-3","10.1109/ICIMTech53080.2021.9534954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534954","traditional mask;marker-based;augmented reality;application","Fading channels;Art;Information management;Cultural differences;Information technology;Augmented reality","art;augmented reality;cultural aspects","Industrial Revolution 4;culture sector;cultural art;Indonesia;foreign cultures;technological developments;traditional mask culture;Malangan masks;Cirebon masks;Panji masks;traditional mask book;marker-based augmented reality technology;traditional mask augmented reality application;ADDIE method","","4","","16","IEEE","14 Sep 2021","","","IEEE","IEEE Conferences"
"Efficient 3D design drawing visualization based on mobile augmented reality","Y. -J. Oh; K. -W. Park; E. -K. Kim","Department of Computer Science, Sunchon National University, Jellanam-do, Republic of Korea; Division of Culture Content, Chonnam National University, Jellanam-do, Republic of Korea; Department of Computer Science, Sunchon National University, Jellanam-do, Republic of Korea","2015 17th International Conference on Advanced Communication Technology (ICACT)","27 Aug 2015","2015","","","568","573","Recently, in manufacturing, machinery, construction and shipbuilding industry, diversified researches of visualizing design drawings without difficulty utilizing augmented reality technology have been performed. In this paper, we propose efficient 3D design drawing visualization technique based on mobile augmented reality. Proposed technique first recognizes design drawing region, and only performs image tracking in its region. Through performance analysis, it could be seen that in technique being suggested in this paper, drawing recognition time was reduced by 4-33%, drawing matching recognition rate was increased by 5-15% and number of output frame per second was increased by 7-8 frames per second.","1738-9445","978-8-9968-6505-6","10.1109/ICACT.2015.7224925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224925","Augmented Reality;3D Structures;Drawing recognized","Three-dimensional displays;Feature extraction;Solid modeling;Augmented reality;Servers;Cameras;Mobile communication","augmented reality;image matching;mobile computing;stereo image processing","mobile augmented reality;augmented reality technology;3D design drawing visualization technique;image tracking;drawing recognition time;drawing matching recognition rate","","4","1","10","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Experimentation of visual augmented reality for visiting the historical monuments of the medina of Fez","M. Zaifri; A. Azough; S. O. El Alaoui","Computer Science and Modeling Laboratory (LIM), Sidi Mohamed Ben Abdellah University (FSDM), Fez, Morocco; Computer Science and Modeling Laboratory (LIM), Sidi Mohamed Ben Abdellah University (FSDM), Fez, Morocco; Computer Science and Modeling Laboratory (LIM), Sidi Mohamed Ben Abdellah University (FSDM), Fez, Morocco","2018 International Conference on Intelligent Systems and Computer Vision (ISCV)","7 May 2018","2018","","","1","4","Augmented reality goes beyond its description as a mere technology to a concept that sums up the convergence of multiple software and hardware technologies that are associated to enhance our vision of the world. The marriage of such a concept in its panoramic context with tourism has led to remarkable results. In this article, we present the modeling and implementation of a prototype of an Android mobile augmented reality application to serve as an electronic pocket guide to make visiting the medina of Fez even more attractive and informative. Replacing the database of specific historical monuments is sufficient to adapt the application to other cities.","","978-1-5386-4396-9","10.1109/ISACV.2018.8354051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354051","Augmented reality;tourism;mobile application;electronic pocket guide;historical monuments","Augmented reality;Prototypes;Cameras;Three-dimensional displays;Databases;Urban areas","augmented reality;history;mobile computing;travel industry","visual augmented reality;medina;Fez;hardware technologies;panoramic context;Android mobile augmented reality application;electronic pocket guide;historical monuments;tourism","","4","","11","IEEE","7 May 2018","","","IEEE","IEEE Conferences"
"Designing an Augmented Reality Educational Board Game Learning Activity with Dual-Scaffolding Teaching Strategy to Enhance EFL Reading Comprehension","C. -T. Li; L. -H. Lee; H. -T. Hou","National Taiwan University of Science and Technology, Taipei, Taiwan; National Keelung Commercial and Industrial Vocational High School, Keelung City, Taiwan; National Taiwan University of Science and Technology, Taipei, Taiwan","2021 10th International Congress on Advanced Applied Informatics (IIAI-AAI)","13 Jun 2022","2021","","","926","927","The research developed an augmented reality educational board game teaching activity integrating the technique of augmented reality and board game with dual-scaffolding teaching strategy to promote learners' EFL reading comprehension. An action research was conducted to evaluate the proposed approach. The experimental results revealed that the proposed approach not only significantly promoted the flow and technology acceptance degree of the learners, but also significantly improved their understanding of the plot diagram of EFL story after the learning activity.","2770-8470","978-1-6654-2420-2","10.1109/IIAI-AAI53430.2021.00166","Ministry of Science and Technology, Republic of China(grant numbers:MOST-107-2511-H-011-003-MY3,MOST-108-2511-H-011-003-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9791064","augmented reality;educational board game;scaffolding;EFL;reading comprehension","Education;Games;Informatics;Augmented reality","augmented reality;computer aided instruction;teaching","action research;augmented reality educational board game learning activity;augmented reality educational board game teaching activity;dual-scaffolding teaching strategy;enhance EFL reading comprehension;learners","","3","","7","IEEE","13 Jun 2022","","","IEEE","IEEE Conferences"
"Augmented reality based mobile learning system design in preschool education","M. Baykara; U. Gürtürk; B. Atasoy; İ. Perçin","Firat Universitesi, Elazig, TR; Firat Universitesi, Elazig, TR; Firat Universitesi, Elazig, TR; Firat Universitesi, Elazig, TR","2017 International Conference on Computer Science and Engineering (UBMK)","2 Nov 2017","2017","","","72","77","With the development of computers, the Internet and mobile technologies, different needs have emerged for people and different solutions have been discovered to meet these needs. One of the critical areas which are considered as the main factor in creating the tomorrow of human beings where a careful study should be done is the education and teaching. Many technologies are being used and various methods are being tried to develop and make the field of education and training more productive. Among these methods, the use of Augmented Reality (AR) technology is emerging in a wide range and scope with advancing technology and it is becoming widespread. In AR technology, the message and information to be given are visualized by visual and auditory methods (3D). In this study, a mobile-based augmented reality application was implemented for pre-school education. In the study, animals and plants were visualized in both English and Turkish as 3D, and at the same time, animals were presented with 3D visualization. In addition to providing audiovisual and visual material in pre-school education, the study will assist in children' development and accelerate the learning process.","","978-1-5386-0930-9","10.1109/UBMK.2017.8093560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093560","augmented reality;education;mobile devices;virtualization;mobile learning","Three-dimensional displays;Solid modeling;Education;Visualization;Augmented reality;Mobile communication;Loading","augmented reality;computer aided instruction;data visualisation;Internet;mobile learning;teaching","mobile learning system design;preschool education;mobile technologies;teaching;Augmented Reality technology;AR technology;visual methods;auditory methods;mobile-based augmented reality application;audiovisual material;children development;3D visualization;learning process","","3","","","IEEE","2 Nov 2017","","","IEEE","IEEE Conferences"
"Self-Guided Virtual Tour Using Augmented Reality","A. Kondlo; A. Henney; A. Bagula; O. Ajayi; L. Van Breda","Department of Computer Science, University of the Western Cape, South Africa; Department of Computer Science, University of the Western Cape, South Africa; Department of Computer Science, University of the Western Cape, South Africa; Department of Computer Science, University of the Western Cape, South Africa; Nature Reserve, University of the Western Cape, South Africa","2020 ITU Kaleidoscope: Industry-Driven Digital Transformation (ITU K)","30 Dec 2020","2020","","","1","5","The Cape Flats Nature Reserve, situated in the Western Cape, South Africa provides refuge to over 200 plant species, many endemic to the Western Cape. As part of the reserve's recreational activities, scheduled guided tours are offered to the public. The tours focus on the ecological importance and educational aspect of the reserve. A complete tour usually takes more than an hour. Due to the lack of trained tour guides and its strenuous nature, tours are only offered once daily. This has been identified as a challenge by the management of the nature reserve. In this paper a solution to the challenge using an augmented reality mobile application is proposed. The application allows visitors to experience the nature reserve in their own time without a guide. Augmented reality markers are placed at points of interest around the reserve. These in conjunction with the mobile application provide information about plants thereby mimicking actual tour guides. Outlines for the design and development of this self-guided tour application and the results of user acceptance and unit tests are provided in this paper.","","978-92-61-31391-3","10.23919/ITUK50268.2020.9303209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303209","Augmented reality;IoT;mobile application;nature reserve;virtual tour","Cameras;Augmented reality;Testing;Smart phones;Performance evaluation;Mobile applications;Sensors","augmented reality;ecology;mobile computing;travel industry","virtual tour;Cape Flats Nature Reserve;Western Cape;South Africa;scheduled guided tours;tours focus;ecological importance;educational aspect;augmented reality mobile application;augmented reality markers;tour guides;tour application","","2","","16","","30 Dec 2020","","","IEEE","IEEE Conferences"
"Fast HRFT measurement system with unconstrained head movements for 3D audio in virtual and augmented reality applications","N. D. Hai; N. K. Chaudhary; S. Peksi; R. Ranjan; J. He; W. -S. Gan","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Maxim Integrated Products Inc., Singapore; Maxim Integrated Products Inc., Singapore","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","10 Aug 2017","2017","","","6576","6577","Binaural audio plays an indispensable role in virtual reality (VR) and augmented reality (AR). Binaural audio recreates the sensation of the three dimensional auditory experience using Head- Related Transfer Functions (HRTFs). HRTFs are as unique as our fingerprint. To achieve an immersive audio experience, HRTFs measured from every particular user is required. Nowadays, the conventional methods for HRTF measurements requires a wellcontrolled environment, hardly any movement of the user, and projecting to the user a high level of unpleasant sound in a rather long duration. Such difficulties have greatly limited the use of individually measurement HRTFs and hinder the authenticity of immersive audio. To solve these problems, we proposed a fast and convenient HRTF measurement system that is an order of magnitude faster and more importantly, it does not place any constraints on the user's movement. With the help of a head-tracker and advanced adaptive signal processing algorithms, this system is able to achieve satisfactory HRTF measurement accuracy. In this demonstration, we will present a fast real-time HRTF acquisition system and show how the individualized HRTFs improve the audio experience in VR/AR applications.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.8005299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8005299","Fast and relaxed HRTF acquisition;Binauralrendering;Virtual reality (VR);Augmented reality (AR)","Headphones;Loudspeakers;Gallium nitride;Three-dimensional displays;Transfer functions;Augmented reality;Rendering (computer graphics)","audio signal processing;augmented reality;signal detection","fast HRFT measurement system;unconstrained head movements;3D audio;virtual reality applications;augmented reality applications;binaural audio;VR;AR;three dimensional auditory experience;head-related transfer functions;head-tracker;advanced adaptive signal processing;HRTF acquisition system","","2","","14","IEEE","10 Aug 2017","","","IEEE","IEEE Conferences"
"A multimodal augmented reality DJ music system","F. Farbiz; K. Y. Tang; K. Wang; W. Ahmad; C. Manders; C. Jyh Herng; Y. Kee Tan","ASTAR Institute of Infocomm Research, Singapore; ASTAR Institute of Infocomm Research, Singapore; ASTAR Institute of Infocomm Research, Singapore; ASTAR Institute of Infocomm Research, Singapore; ASTAR Institute of Infocomm Research, Singapore; ASTAR Institute of Infocomm Research, Singapore; ASTAR Institute of Infocomm Research, Singapore","2007 6th International Conference on Information, Communications & Signal Processing","12 Feb 2008","2007","","","1","5","One of the goals of human-computer interaction is to utilize more intuitive and natural methods for communication. This goal has become of particular importance in augmented reality (AR) applications. Developing such interaction techniques is critical since traditional interfaces (keyboard, mouse) are cumbersome and awkward in AR environments. This paper provides a description of a real-time interactive multimodal augmented reality entertainment system. The system design is based on the DJ music environment and consists of four main modules, namely a speech recognition module, a head tracking and graphic engine module, a gesture tracking module and finally, a sound synthesis module. Using our system, the user can scratch the music through gesture movement as if using a DJ turn table. The user can also enjoy real time interaction with virtual 3D dancers augmented on the table through voice commands and hand gestures.","","978-1-4244-0982-2","10.1109/ICICS.2007.4449564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4449564","Augmented Reality;Gesture Tracking;Head Tracking;Speech Recognition;Sound Synthesis","Augmented reality;Speech recognition;Mice;Speech synthesis;Virtual reality;Automatic speech recognition;Keyboards;Magnetic heads;Humans;Communication system control","augmented reality;entertainment;gesture recognition;music;user interfaces","multimodal augmented reality;DJ music system;human-computer interaction;entertainment system;speech recognition module;head tracking;graphic engine module;gesture tracking module;sound synthesis module;gesture movement;DJ turn table;virtual 3D dancers;voice commands;hand gestures","","1","","10","IEEE","12 Feb 2008","","","IEEE","IEEE Conferences"
"A conceptual design of Kanji mobile application with augmented reality technology for beginner","K. Thongchum; S. Charoenpit","Faculty of Information Technology, Thai-Nichi Institute of Technology, Bangkok, Thailand; Faculty of Information Technology, Thai-Nichi Institute of Technology, Bangkok, Thailand","2018 5th International Conference on Business and Industrial Research (ICBIR)","21 Jun 2018","2018","","","149","154","Japanese language is the most popular in Thailand. Thai-Nichi Institute of Technology has Japanese language in undergraduate program as the require subjects and elective subject. The most difficult aspects of learning Japanese is Kanji. The aim of this research were as follow (1) to find out the problems and learning behaviors of Kanji learner, (2) to design Kanji mobile application with Augmented Reality technology. The populations were TNI students. Sampling of this research were 141 TNI students. The instrument of this research was questionnaire to collect data. The result was found were not able to read kanji, not able to write kanji by stroke order, able to guess the meaning but not able to read and not able to know meaning of kanji. In learning behaviors aspect was found the most learning behaviors were practice of writing often in paper or in the air, learning through printing media, learning through the game and learning through entertainment media. In the term of a conceptual design that selected Augmented Reality to resolve Kanji learning problem. And the color theme of an application designed by used blue tone that blue can help to focusing and to keep user engaged that color can be very effective in learning and educational. And the user interface designed by Flat design that benefit majority of Flat design were easy to use, beautiful and responsive.","","978-1-5386-5254-1","10.1109/ICBIR.2018.8391183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8391183","kanji;mobile application;augmented reality technology","Mobile applications;Augmented reality;Media;Games;Business;Education;Information technology","augmented reality;computer aided instruction;educational institutions;linguistics;mobile learning;user interfaces","Japanese language;undergraduate program;elective subject;learning Japanese;Kanji learner;Kanji mobile application;augmented reality technology;learning behaviors aspect;conceptual design;Kanji learning problem;Flat design;TNI students;Augmented Reality;entertainment media;user interface","","1","","17","IEEE","21 Jun 2018","","","IEEE","IEEE Conferences"
"An Overview of Smart Classroom using the Augmented Reality Technology","K. Selvi K.; S. Prasannah S.R.; A. Youdhika; R. Ramprabhu; R. Benny T.","Department Of ECE, SNS College of Technology, Coimbatore, India; Department Of ECE, SNS College of Technology, Coimbatore, India; Department Of ECE, SNS College of Technology, Coimbatore, India; Department Of ECE, SNS College of Technology, Coimbatore, India; Department Of ECE, SNS College of Technology, Coimbatore, India","2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)","23 Apr 2020","2020","","","566","570","This paper describes the rapid advancements being made in the development of Augmented Reality (AR) based systems. Augmented reality has proven to be a great asset to the smart electronics technology and in this paper we have discussed on how the AR technology can benefit the education field and on how the use of AR technology in classrooms will help the student community in acquiring the knowledge about the subjects and enhance their perspectives on complex topics.","2575-7288","978-1-7281-5197-7","10.1109/ICACCS48705.2020.9074485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074485","Hologram;projection;augmented reality;interference","Three-dimensional displays;Speech recognition;Augmented reality;GSM;Interference;Education;Holography","augmented reality;computer aided instruction","Augmented Reality based systems;smart electronics technology;AR technology;education field;smart classroom;augmented reality technology;student community","","1","","13","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Hybrid cloud computing for user location-aware augmented reality construction","M. Jian; Y. Wang; B. Wu; Y. Cheng","Department of Computer Science and Information Engineering, National Formosa University No.64, Wunhua Rd., Huwei Township, Yunlin County, Taiwan; Department of Computer Science and Information Engineering, National Formosa University No.64, Wunhua Rd., Huwei Township, Yunlin County, Taiwan; Department of Computer Science and Information Engineering, National Formosa University No.64, Wunhua Rd., Huwei Township, Yunlin County, Taiwan; Department of Computer Science and Information Engineering, National Formosa University No.64, Wunhua Rd., Huwei Township, Yunlin County, Taiwan","2018 20th International Conference on Advanced Communication Technology (ICACT)","26 Mar 2018","2018","","","190","194","In this paper, the Hybrid Cloud Computing for User Location-aware Augmented Reality Construction is proposed including three layers: Estimation Layer, Scenario Layer, and Presentation Layer. Based on “Angle of the Arrival” position method in Estimation Layer, the location-aware information of individual user can be considered. According to Scenario Layer, the various augmented reality contents can be rapidly and dynamically re-established. Three types of virtual machines including scenario virtual machine, material and physical parameter database, and re-direction management are proposed Based on the proposed system structure, the cost of AR construction can be reduced for the various display devices.","","979-11-88428-01-4","10.23919/ICACT.2018.8323692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8323692","Augmented Reality;Cloud Computing;Edge Computing;Location Aware;Game","Augmented reality;Cloud computing;Mobile handsets;Estimation;Edge computing;Wireless communication;Virtual machining","augmented reality;cloud computing;location based services;mobile computing;virtual machines","Estimation Layer;Scenario Layer;Presentation Layer;location-aware information;augmented reality contents;physical parameter database;user location-aware augmented reality construction;Hybrid Cloud Computing;Angle of the Arrival position method;scenario virtual machine;material parameter database;re-direction management","","1","","19","","26 Mar 2018","","","IEEE","IEEE Conferences"
"Human-action recognition module for the new generation of augmented reality applications","A. I. Maqueda; C. R. del-Blanco; F. Jaureguizar; N. García","Grupo de Tratamiento de Imágenes, Universidad Politécnica de Madrid (UPM), Spain; Grupo de Tratamiento de Imágenes, Universidad Politécnica de Madrid (UPM), Spain; Grupo de Tratamiento de Imágenes, Universidad Politécnica de Madrid (UPM), Spain; Grupo de Tratamiento de Imágenes, Universidad Politécnica de Madrid (UPM), Spain","2015 International Symposium on Consumer Electronics (ISCE)","6 Aug 2015","2015","","","1","2","Augmented reality is becoming more and more popular due to the countless number of practical applications. A key element is the understanding of the scene and the involved human activities to be able to offer a rich interaction with the world via virtual actions and elements. For this purpose, a new vision-based human-action recognition module has been developed to be integrated with the new generation of augmented reality devices, which is based on Spatio-Temporal Interest Points and the Citation K-Nearest Neighbor classifier.","2159-1423","978-1-4673-7365-4","10.1109/ISCE.2015.7177833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177833","augmented reality;human action recognition;spatio-temporal features;STIP;C-KNN","Feature extraction;Augmented reality;Visualization;Video sequences;Support vector machines;Accuracy;Computer vision","augmented reality;computer vision;object recognition;pattern classification","augmented reality applications;human activities;virtual actions;vision-based human-action recognition module;augmented reality devices;spatio-temporal interest points;citation k-nearest neighbor classifier","","1","","9","IEEE","6 Aug 2015","","","IEEE","IEEE Conferences"
"Ariotivity: Provisioning Smart Objects with Augmented Reality and Open Standards","F. Campaña; F. Domínguez","Centro de Tecnologías de Información (CTI), Escuela Superior Politécnica del Litoral (ESPOL), Guayaquil, Ecuador; Centro de Tecnologías de Información (CTI), Escuela Superior Politécnica del Litoral (ESPOL), Guayaquil, Ecuador","2018 IEEE Third Ecuador Technical Chapters Meeting (ETCM)","20 Dec 2018","2018","","","1","6","Smart objects are computationally enhanced everyday objects such as watches, keychains and more. As these devices become ubiquitous, its seamless and secure interaction becomes critical. Due to the fragmented landscape of the Internet of Things (IoT) and the difficulty of allowing a secure exchange of resources among objects, the provisioning and interoperability of smart objects is still an open problem in IoT. With this goal in mind, we developed the Ariotivity framework: an Augmented Reality enhancement for the Iotivity framework. This framework is a preliminary solution to provision and interact with smart objects by means of a mobile device. It allows users to reconfigure and control smart objects through an augmented reality application and a backend that uses open standards developed for the IoT industry. This article presents the design of our first prototype, describes its functionality and reports the ways in which it could be enhanced. Preliminary results show its feasibility and proof-of-concept through example devices, but further development is needed to be deployed in real environments.","","978-1-5386-6657-9","10.1109/ETCM.2018.8580341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580341","open standards;smart objects;augmented reality;iotivity","Servers;Mobile handsets;Standards;Databases;Augmented reality;Internet of Things;Sensors","augmented reality;Internet of Things;mobile computing;open systems;security of data","secure interaction;augmented reality application;open standards;provisioning smart objects;everyday objects;seamless interaction;augmented reality enhancement;Internet of Things;IoT;Ariotivity framework;Iotivity framework","","1","","25","IEEE","20 Dec 2018","","","IEEE","IEEE Conferences"
"Evolution of Virtual and Augmented Reality Technologies in Historical and Archaeological Research","L. Borodkin","Lomonosov Moscow State University, Moscow, Russia","2022 International Workshop on High Technologies History and Development (HISTHIGHTECH)","7 Feb 2023","2022","","","9","12","History of the emergence and development of virtual reality technologies is analyzed, with an emphasis on applications in historical and archaeological research since the early 1990s to the present day. These technologies are considered both in the context of projects for the three-dimensional reconstruction of industrial and cultural heritage and for educational purposes (to create immersive effects). The first part contains very brief description of the most valuable achievements in the field of Virtual and Augmented Reality technologies development. Implementation of computer-based visualization is one of the most important issues of the paper in the context of discussed research projects.","","979-8-3503-2014-5","10.1109/HISTHIGHTECH57099.2022.10038138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10038138","virtual reality;augmented reality;3D-modeling;digital cultural heritage;digital industrial heritage;interactive 3D-reconstruction;visualization;virtual prototyping and simulation","Visualization;Solid modeling;Conferences;History;Cultural differences;Virtual prototyping;Augmented reality","archaeology;augmented reality;data visualisation;history;solid modelling","archaeological research;augmented reality technology development;computer-based visualization;cultural heritage;educational purposes;historical research;immersive effects;industrial heritage;three-dimensional reconstruction;virtual reality technology development","","1","","13","IEEE","7 Feb 2023","","","IEEE","IEEE Conferences"
"Augmented reality for material processing within shielded radioactive environment","B. Luo; S. Ge","Institute of Computer Application, China Academy of Engineering and Physics, Mianyang, China; Institute of Computer Application, China Academy of Engineering and Physics, Mianyang, China","2015 8th International Congress on Image and Signal Processing (CISP)","18 Feb 2016","2015","","","92","97","Safety requirement is the most important issue for operators in the filed of nuclear science, especially material processing within shielded radioactive manufacturing environment under which material processing needs a great of manual operations and any operation mistake would cause to permanent radiation threat to body of operators and loss of enormous economical value. This paper proposes a novel approach to increase this safety. The approach is base on an augmented reality framework with double-camera observation system designed according to the special structure of the shielded environment, and integrates augmented reality and finger tip interaction technology to interactively show the contexts of principles of processing devices, tools and steps in the form of texts, pictures, and animations, and also to enhance operation steps of material processing by superimposing virtual digital models onto video streams of the observation camera system. A simulation environment is set up to verify our approach. The results show the proposed approach is capable of extending viewing scopes of operators and making interactive training, and guiding complicate operations at advance so as to increase operational safety and comfort, diminish costly mistakes and improve material processing efficiency.","","978-1-4673-9098-9","10.1109/CISP.2015.7407856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407856","augmented reality;material processing;camera obvervation system;finger tip interaction","Augmented reality;Materials processing;Cameras;Streaming media;Computers;Thumb","augmented reality;materials science computing;nuclear engineering computing","material processing;augmented reality;safety requirement;nuclear science;shielded radioactive manufacturing environment;permanent radiation threat;economical value;augmented reality framework;double camera observation system;shielded environment;observation camera system;interactive training","","","","21","IEEE","18 Feb 2016","","","IEEE","IEEE Conferences"
"A Calibration Algorithm for Real-time Scene-aware Portable Augmented Reality","S. Yu; L. Qi; Y. Tie","Zhengzhou University, Zhengzhou, China; Zhengzhou University, Zhengzhou, China; Zhengzhou University, Zhengzhou, China","2019 8th International Symposium on Next Generation Electronics (ISNE)","14 Nov 2019","2019","","","1","3","In order to solve the problem of accurate holographic projection of the point cloud collected by an external high-precision depth camera in HoloLens, we propose an augmented reality calibration algorithm for real-time scene perception. Firstly, we build a portable high-precision real-time sensing system, using external RealSense to collect point cloud data, and the portable host processes and returns the data to HoloLens via a local area network. Secondly, it calibrates the internal parameters of HoloLens' webcam and RealSense depth cameras, then fixed the two cameras for dual purpose calibration, so as to obtain the internal rotation and translation matrix. Finally, the calculated posture computed by the matrix transformation transforms of the virtual object from the RealSense coordinate system displayed in OSG (Open Scene Graph) to HoloLens unified. The Direct X coordinate system is then transformed into the HoloLens Webcam coordinate system, and then the HoloLens API is used to acquire the fixed coordinate system established during the acquisition. At the same time, the virtual object of the holographic projection is accurately merged with the real object, and the spatial anchor is fixed in the real scene, so that the system realizes an accurate and real-time aware augmented reality capability.","2378-8607","978-1-7281-2062-1","10.1109/ISNE.2019.8896496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896496","HoloLens;RealSense;real-time perception;augmented reality calibration","Three-dimensional displays;Real-time systems;Calibration;Augmented reality;Solid modeling;Webcams","augmented reality;calibration;cameras;graph theory;image resolution;Internet;local area networks;matrix algebra","holographic projection;high-precision depth camera;augmented reality calibration algorithm;real-time scene perception;portable high-precision real-time sensing system;point cloud data;portable host processes;local area network;dual purpose calibration;internal rotation;translation matrix;matrix transformation transforms;virtual object;RealSense coordinate system;open scene graph;HoloLens API;fixed coordinate system;real-time scene-aware portable augmented reality;hololens Webcam","","","","3","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Demonstration of augmented-reality optical narrowcasting","N. Shatz; J. Bortz; M. Squire","SureFire, USA; SureFire, USA; SureFire, USA","2018 15th IEEE Annual Consumer Communications & Networking Conference (CCNC)","19 Mar 2018","2018","","","1","2","We introduce a new communications technology, which we refer to as augmented-reality optical narrowcasting. This technology has the potential to significantly enhance smartphone consumer communications by enabling information exchange between multiple transmitters and multiple receivers using free-space optical data transmission. A practical communication range of 400 meters in broad daylight is achievable with miniaturized optics transmitting HD video. An augmented-reality-style user interface, wherein visual representations of available information sources are overlaid on a live display of video imagery allows users to conveniently manage transmissions from multiple parties. The new technology is envisioned to be installed in smartphones and other mobile devices and in vehicles, opening new vistas for commerce and social interaction. We will demonstrate key features of the technology using custom optical communications hardware and software developed especially for this purpose.","2331-9860","978-1-5386-4790-5","10.1109/CCNC.2018.8319317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319317","optical communication;consumer electronics;augmented reality;smartphones;mobile devices;nonimaging optics","Optical transmitters;Augmented reality;Optical receivers;Optics;Optical beams;Cameras","augmented reality;free-space optical communication;high definition video;image representation;optical links;optical receivers;optical transmitters;smart phones;telecommunication computing;user interfaces","miniaturized optics;augmented-reality-style user interface;multiple parties;custom optical communications hardware;augmented-reality optical narrowcasting;communications technology;smartphone consumer communications;multiple transmitters;multiple receivers;free-space optical data transmission;information sources;communication range;HD video;visual representations;mobile devices;social interaction;video imagery display","","","","","IEEE","19 Mar 2018","","","IEEE","IEEE Conferences"
"Augmented Reality Application Development About Nutrition for the Elderly","C. Bravo Pillon; L. Rocha Machado; R. P. da Silva","Universidade Federal do Rio Grande do Sul, Porto Alegre, RS, BR; Universidade Federal do Rio Grande do Sul, Porto Alegre, RS, BR; Universidade Federal do Rio Grande do Sul, Porto Alegre, RS, BR","2018 XIII Latin American Conference on Learning Technologies (LACLO)","1 Aug 2019","2018","","","21","24","Each year increases the number of the elderly around the world, and, in this prospect, new challenges come up, both in relation to culture as in health. The misinformation is one of leading causes that contributes for an inappropriate nutrition between the elderly. The educational material plays a large role in raising awareness to adopt a healthy diet. In this way, the aim of this paper is to present the development and application process of an augmented reality application about nutrition for the elderly. The methodology adopted in this research is divided in four stages: research, development, evaluation and results analysis. In this paper, the first two stages of the methodology are emphasized. The results present the development process of a digital educational material aimed at the elderly, which uses the augmented reality technology. Therefore, the application might complement the learning of the elderly about nutrition in a playful, dynamic, and interactive way.","","978-1-7281-0382-2","10.1109/LACLO.2018.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8783970","elderly;nutritional orientation;digital educational material;application;augmented reality","Senior citizens;Augmented reality;Conferences;Hardware;Resists;Instruments;Assisted living","augmented reality;computer aided instruction;geriatrics;health care","augmented reality application development;healthy diet;digital educational material;augmented reality technology;elderly people","","","","","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"A new Augmented-Reality platform for Electromagnetic Education","C. Mateo-Segura","School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, Scotland, UK","2018 International Conference on Electromagnetics in Advanced Applications (ICEAA)","4 Nov 2018","2018","","","174","177","This contribution briefly reviews the role of novel technologies, in particular Augmented Reality (AR), in stimulating attention and increase the level of understanding of abstract concepts in subject areas that required 3D vision and manipulation of complex mathematical theory, such as electromagnetics (EM). A pilot project which proposes the inclusion of a novel augmented reality platform that allows both, 3D interaction with the course material and real-time feedback on students' performance will be described and examples of the ongoing activities at Heriot-Watt University will be summarized. Focus is placed on the pilot test carried out for 3rd year students of Electromagnetics. Results suggest that the platform is effective in engaging with the students, having also a positive impact on the students' learning experience. The platform, the metrics to measure its impact, the advantages and limitations, challenges as well as future developments will be summarized.","","978-1-5386-6762-0","10.1109/ICEAA.2018.8520476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8520476","Degrees;Education;Electromagnetic;Augmented Reality","Education;Three-dimensional displays;Augmented reality;Satellites;Electromagnetics;Visualization;Satellite broadcasting","augmented reality;computer aided instruction;educational courses;educational institutions;electromagnetism;real-time systems","3D interaction;augmented-reality platform;augmented reality platform;electromagnetic education;Heriot-Watt University;real-time feedback;course material","","","","14","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"The integration of augmented reality in the virtual learning environment for practical activities","H. El Kabtane; Y. Mourdi; M. El Adnani; M. Sadgal","University Cadi Ayyad, Marrakech, Morocco; University Cadi Ayyad, Marrakech, Morocco; University Cadi Ayyad, Marrakech, Morocco; University Cadi Ayyad, Marrakech, Morocco","2015 International Conference on Electrical and Information Technologies (ICEIT)","20 Jul 2015","2015","","","363","368","E-learning systems suffer from a lack of tools to provide practical activities for learners. The mixed reality is promised to be a new technology to create a virtual environment where the learner is an actor by interaction with virtual objects. The objective is to establish a virtual laboratory that all tools and products can be manipulated by learners like in real practical work. This virtualization can also solve the safety problems and may reduce the risk of some experiments: nuclear, chemical, etc. Another interesting benefit is the reduction of the investment on real hardware (locally or remotely). We propose an approach for developing integrated E-learning systems, helping to carry out the practical work by the distance learner based on an augmented reality system.","","978-1-4799-7479-5","10.1109/EITech.2015.7162960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7162960","E-learning;virtual reality;augmented reality;practical activities","Electronic learning;Videos;Solid modeling;Augmented reality;Virtual environments","augmented reality;computer aided instruction;distance learning","augmented reality system;distance learner;integrated E-learning systems;virtualization;learners;virtual laboratory;virtual objects interaction;virtual environment;mixed reality","","","","33","IEEE","20 Jul 2015","","","IEEE","IEEE Conferences"
"Development of immersive augmented reality interface system for construction robotic system","S. Lee; H. Jung; H. Song; S. Park","Department of Mechanical Engineering, Korea University, Seoul, South Korea; Department of Mechanical Engineering, Korea University, Seoul, South Korea; Department of Mechanical Engineering, Korea University, Seoul, South Korea; Department of Mechanical Engineering, Korea University, Seoul, South Korea","ICCAS 2010","17 Dec 2010","2010","","","2309","2314","This study develops immersive user interface system for construction robotic system by using augmented reality system. Unlike the traditional interface using a monitor view only, the AR interface system in this paper allows the operator to see the invisible eyesight out of camera view by using a virtual 3D model. The operator can control the camera view, and the images of 3D models are changed as the camera view changes in the AR system. With the augmented reality system developed in this paper, the operator can have a wide view of inside of the structure so that one can observe the situation of construction site without having to move the camera around. This AR system alarms the operator of a danger area and gives the operator a guide for completion of task by using the AR system. And this AR interface system contains a tele-operated construction robot system. Therefore, the operator can easily and safely complete construction operation.","","978-89-93215-02-1","10.1109/ICCAS.2010.5669910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669910","Construction automation;Tele-operated robot;Augmented reality;Immersive interface","Robot kinematics;Cameras;Joints;Automation;Augmented reality;Service robots","augmented reality;construction industry;industrial robots;solid modelling;telerobotics;user interfaces","immersive augmented reality interface system;construction robotic system;immersive user interface system;augmented reality system;monitor view;AR interface system;invisible eyesight;camera view;virtual 3D model;tele-operated construction robot system","","","","7","","17 Dec 2010","","","IEEE","IEEE Conferences"
"Meta-Review of Augmented Reality in Education","B. S. Hantono; L. E. Nugroho; P. I. Santosa","Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia; Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia; Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia","2018 10th International Conference on Information Technology and Electrical Engineering (ICITEE)","15 Nov 2018","2018","","","312","315","Augmented reality has been developed decades ago, but its implementation can be enjoyed by the wider community only in the last few years, along with the increasing number of affordable smartphones which are owned by almost everyone. Although previous studies have shown that augmented reality has the potential to improve learning in students, the benefits of education by utilizing augmented reality and the context in which this technology is more effective than other educational media is still not clear. This paper tries to discuss the topic of augmented reality in the world of education by doing a meta-review of some reviews that have been done before. This paper tries to look at the trend of augmented reality research in education and also to help researchers decide which topics to explore.","","978-1-5386-4739-4","10.1109/ICITEED.2018.8534888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8534888","Augmented reality;education;learning","Education;Augmented reality;Games;Smart phones;Bibliographies;Google;Systematics","augmented reality;computer aided instruction;smart phones","meta-review;augmented reality research;educational media","","20","","25","IEEE","15 Nov 2018","","","IEEE","IEEE Conferences"
"Augmented reality using Vuforia for marketing residence","D. Adrianto; M. Hidajat; V. Yesmaya","Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia","2016 1st International Conference on Game, Game Art, and Gamification (ICGGAG)","2 Oct 2017","2016","","","1","5","The concept of Augmented Reality is a technology in which the interaction between the human-computer that can generate two-dimensional or three dimensional object in real time. Augmented reality can provide the necessary functions and information in its application. In this case the augmented reality (AR) just need a tool like a camera that can capture images by detecting the object without the marker coordinates from the surrounding environment to make real 3D objects. Augmented Reality application development is simple and easy to develop, so it can serve as a promotional tool or the provision of information. Therefore, the notion obtained separately develop AR applications that help the residence marketing department in the home market to show a 3D object of marketed house. So that prospective buyers get the information more interactive with real look 3D objects. This study use a software named Vuforia (QCAR) to implement augmented reality in mobile applications for marketing residence. Vuforia provides convenience to the Android mobile platform in the shooting in 3D objects.","","978-1-5090-5479-4","10.1109/ICGGAG.2016.8052642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052642","augmented reality;marketing residence;vuforia;real environment;markerless;android","Augmented reality;Three-dimensional displays;Solid modeling;Real-time systems;Cameras;Software;Image edge detection","augmented reality;human computer interaction;marketing data processing;mobile computing","marketing residence;three dimensional object;mobile applications;QCAR;Vuforia software;home market;human-computer interaction;AR;3D object;Augmented Reality","","16","","11","IEEE","2 Oct 2017","","","IEEE","IEEE Conferences"
"Performance Analysis of Augmented Reality Based on Vuforia Using 3D Marker Detection","S. Sendari; A. Firmansah; Aripriharta","Electrical Engineering Department, Engineering Faculty, Universitas Negeri Malang, Malang, Indonesia; Electrical Engineering Department, Pascasarjana Universitas Negeri Malang, Malang, Indonesia; Electrical Engineering Department, Engineering Faculty, Universitas Negeri Malang, Malang, Indonesia","2020 4th International Conference on Vocational Education and Training (ICOVET)","21 Oct 2020","2020","","","294","298","In the field of education, especially engineering, there is evidence of skills gaps. According to a survey in the UK covers 2017-2024, the demand for electricity projected to increase. In fact, at the same time, 23.7% of electricity workers are predicted to experience retirement. Therefore, skills gaps need to be minimized through the development of effective and credible learning media. One of the innovations in developing instructional media is applying augmented reality. However, augmented reality performance needs testing to find out the factors that influence the success of object detection to provide maximum results when implemented in learning media. Several existing studies analyze the performance of augmented reality based on the NyARToolkit library, template matching, and the Metaio Mobile SDK. In this research, the performance of 3D object detection performed on augmented reality based on the Vuforia. The research scenarios based on the results of the analysis of the Vuforia working principle. The study conducted with three angles of shooting and several variations of light intensity and distance of the object. The research also conducted by covering part of the object's surface. The results showed that the Vuforia was able to detect objects well in several scenarios that applied with a success rate of 87.5%. The success rate of object detection strongly influenced by the surface area of the detected object and the intensity of the light space.","","978-1-7281-8131-8","10.1109/ICOVET50258.2020.9230276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9230276","augmented;reality;Vuforia;object;performance","Cameras;Augmented reality;Feature extraction;Object detection;Three-dimensional displays;Modems;Media","augmented reality;computer aided instruction;engineering education;feature extraction;image matching;object detection;stereo image processing","instructional media;augmented reality;3D object detection;Vuforia;performance analysis;3D marker detection;learning media;engineering education;NyARToolkit library;template matching;Metaio Mobile SDK","","8","","14","IEEE","21 Oct 2020","","","IEEE","IEEE Conferences"
"Collaborative Learning about Augmented Reality from Technology and Business Perspectives","M. Frydenberg; D. Andone","Bentley University, Waltham, MA; Politehnica University of Timisoara (UPT), Timisoara, Romania","2017 IEEE 17th International Conference on Advanced Learning Technologies (ICALT)","7 Aug 2017","2017","","","493","495","Augmented reality technologies are becoming widely used in educational and business contexts. This paper shares results of the TalkTech project, in which first-year introductory technology students from a university in the United States and fourth-year multimedia students from a university in Romania research applications of augmented reality in various industries, develop original augmented reality artifacts, and share their findings with international partners. Based on a project-based and collaborative learning approach, students communicate, research, develop together with the main goal to improve their digital literacy skills. By creating augmented reality artifacts, students better understand the impact of this technology and its business applications, and express their technological creativity in an innovative way.","2161-377X","978-1-5386-3870-5","10.1109/ICALT.2017.155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8001841","augmented reality;mobile technologies;project-based learning;collaborative learning;online communication","Augmented reality;Tools;Education;Industries;Collaborative work;Advertising","augmented reality;computer aided instruction;computer literacy","collaborative learning;augmented reality;business contexts;TalkTech project;first-year introductory technology students;United States;fourth-year multimedia students;Romania;digital literacy skills;technological creativity;project-based learning","","4","","12","IEEE","7 Aug 2017","","","IEEE","IEEE Conferences"
"The Feasibility of Augmented Reality on Virtual Tourism Website","C. Hsu","Department of Information Management, Overseas Chinese University, Taichung, Taiwan","2011 Fourth International Conference on Ubi-Media Computing","18 Aug 2011","2011","","","253","256","The Taiwan Tourism Bureau is carrying on with the ""Three-year Sprint Program"" of the Executive Yuan's ""Economic Development Vision for 201.,"" Tourism becomes the star industry in Taiwan and it will play a major role in future global economic development. Not only the physical improvements are encouraged, the information service online is also important. Therefore, we apply Augmented Reality technology for implementing the virtual tourism website. The website provided the necessary information for the destination basically, and increased the multimedia effects for the website especially. Some empirical researches show that a website with a high level of interactivity and rich multimedia is more likely than a text-based website to persuade consumers. Therefore, the virtual tourism website of Taichung City is herein provided for studying the feasibility of Augmented Reality on virtual Tourism. In the work, we conclude the technology advantage of Augmented Reality and demonstrate the effects of novel interactive operation with users. The result of the research will be the valuable reference as a company applying the Augmented Reality for virtual websites.","","978-1-4577-1174-9","10.1109/U-MEDIA.2011.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5992081","Augmented Reality;Virtual Tourism;Unity;User Interaction","Media;Augmented reality;Cities and towns;Economics;Buildings;Navigation;Business","augmented reality;travel industry;Web sites","augmented reality;virtual tourism Website;Taiwan tourism bureau;global economic development;information service;multimedia effect","","4","","14","IEEE","18 Aug 2011","","","IEEE","IEEE Conferences"
"Augmented Reality Engine Applications: A Survey","K. Rana; B. Patel","Computer Engineering Department, SCET, Surat; Computer Engineering Department, SCET, Surat","2019 International Conference on Communication and Signal Processing (ICCSP)","25 Apr 2019","2019","","","0380","0384","Augmented reality is currently upgrading technology where the main problem is pose tracking. When the device is static, pose tracking is not required. But when working with mobile devices, pose tracking is required to track user movements. In pose tracking, an application has to identify features from the given real-time video frames and mapping of those features between consecutive frames. After that, the model is used to render virtual content for augmented reality. Feature extraction and model detection are difficult to apply in the mobile device where a user has low computing power as well as low battery backup. To overcome this problem, there are many algorithms available which can provide effective feature tracking for the mobile environment and also uses less CPU power. Therefore augmented reality is somehow possible in mobile devices. But still, there is an accuracy issue related to model detection in augmented reality. In this paper, we have analyzed different augmented reality engines, their drawbacks, and possible improvements.","","978-1-5386-7595-3","10.1109/ICCSP.2019.8697999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8697999","Mobile Augmented reality;Computer vision;deep learning;Smartphone and Feature Tracking","Augmented reality;Feature extraction;Tracking;Magnetic sensors;Cameras;Deep learning","augmented reality;feature extraction;mobile computing;rendering (computer graphics);video signal processing","augmented reality engine applications;mobile device;real-time video frames;feature extraction;model detection;feature tracking;pose tracking;track user movements;virtual content rendering","","3","","24","IEEE","25 Apr 2019","","","IEEE","IEEE Conferences"
"The implementation of literacy and sign language learning system for deaf children based on the augmented reality","Jie Jiang; Yang Kuang","Institute of Education, Jiang Xi Science and Technology Normal University, NanChang, China; Institute of Education, Jiang Xi Science and Technology Normal University, NanChang, China","2014 IEEE Workshop on Advanced Research and Technology in Industry Applications (WARTIA)","6 Dec 2014","2014","","","911","913","This paper expound augmented reality applying on literacy and sign language learning system of the deaf children. It researched the applying of augmented reality, based on it, Used digital scripting language, Three-dimensional modeling and interactive animation technology, designed the system. In the paper, the augmented reality technology applied to education for disabled children, it promoted the application of augmented reality technology in the education practice, realized the Fusion of traditional print and digital technology.","","978-1-4799-6989-0","10.1109/WARTIA.2014.6976421","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976421","augmented reality;deaf children;ARToolkit","Augmented reality;Assistive technology;Gesture recognition;Cameras;Solid modeling;Three-dimensional displays;Computers","augmented reality;computer aided instruction;computer literacy;handicapped aids;sign language recognition","literacy system;sign language learning system;deaf children;augmented reality technology;digital scripting language;interactive animation technology;disabled children education","","1","","2","IEEE","6 Dec 2014","","","IEEE","IEEE Conferences"
"Eliciting Educators’ Needs on the Design and Application of Augmented Reality Educational Board Games on Cultural Heritage: The case of CHARMap","G. Kalmpourtzis; G. Ketsiakidis; L. Vrysis; T. Xi; X. L. Wang; C. Dimoulas","Infinitivity Design Labs, Laussonne, France; School of Design Shanghai Jiao Tong University, Shanghai, China; Laboratory of Electroacoustics & TV Systems, Aristotle University of Thessaloniki, Thessaloniki, Greece; Infinitivity Design Labs, Laussonne, France; School of Media & Communication, Shanghai Jiao Tong University, Shanghai, China; Aristotle University of Thessaloniki Thessaloniki, Greece","2021 IEEE Global Engineering Education Conference (EDUCON)","18 Jun 2021","2021","","","1282","1286","The education of cultural heritage has been in the spotlight of the academia and the industry. In the scope of teaching about cultural heritage in Greece and China, an Augmented Reality board game, called CHARMap, was created. The game aims at providing at creating intrinsically motivating learning experiences for students and explore possibilities towards a positive impact on educators' adoption of Augmented Reality technologies in learning contexts. This paper presents a pilot study during which primary and high school educators in Greece and China were presented with and explored the functionalities of this Augmented Reality board game. The aim of the study was to explore educators' potential interest and needs regarding the use of an Augmented Reality educational game around Cultural Heritage in their classrooms. The study contributes to the broader academic research body by providing empirical evidence concerning the design, adoption and application of Augmented Reality educational games on cultural heritage in classrooms.","2165-9567","978-1-7281-8478-4","10.1109/EDUCON46332.2021.9453877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9453877","game based learning;augmented reality;interactive storytelling;cultural heritage;game design","Industries;Conferences;Games;Cultural differences;Engineering education;Augmented reality","augmented reality;computer aided instruction;history;human factors;serious games (computing);teaching","academic research;augmented reality educational board games;high school educators;primary school educators;cultural heritage","","","","48","IEEE","18 Jun 2021","","","IEEE","IEEE Conferences"
"Panel - Ethics and emerging technology: Ethical concerns from a cognitive, media & technology focused psychology perspective concerning augmented reality, privacy, and sigularity","S. Pase; G. Hare; J. L. Hogg; S. Thoennes; C. Connors","Department of Media Psychology, Fielding Graduate University, Santa Barbara, CA, USA; Broadcast Productions, Fielding Graduate University, Santa Barbara, CA, USA; NA; Broadcast Productions, Fielding Graduate University, Santa Barbara, CA, USA; Naval Education Training, Professional Development Technology Center (NETPDTC), Orlando, FL, USA","2014 IEEE International Symposium on Ethics in Science, Technology and Engineering","8 Sep 2014","2014","","","1","3","Developing technologies such as augmented reality merges an individual's real life with a digital life that enhances both the visual and the physical experience. Augmented reality creates many ethical concerns in regards to impact on society and human behavior. Blurring the lines between what's real and what's artificial is a significant concern in the future development of augmented reality. This panel examines the ethical considerations from a cognitive and media-focused psychology perspective in developing and deploying mixed and augmented reality (MAR) applications to help improve your understanding of key psychological factors in technological development.","","978-1-4799-4992-2","10.1109/ETHICS.2014.6893438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893438","Media Psychology;Psychology;Cognitive;Augmented Reality;Immersive Technology;Privacy;Singularity;Ownership;Facial Recognition;Ethics","Psychology;Augmented reality;Privacy;Ethics;Media;Educational institutions;Business","augmented reality;ethical aspects;psychology","ethical concerns;augmented reality;digital life;human behavior;media-focused psychology perspective;cognitive perspective;technological development","","","","","IEEE","8 Sep 2014","","","IEEE","IEEE Conferences"
"Work-in-Progress–—Specific Heat of Water Experiment: Augmented Reality Chemistry Lab","R. Wirjadi; A. Vuong; F. Liu; R. LiKamWa","Arizona State University, Tempe, Arizona; Arizona State University, Tempe, Arizona; Arizona State University, Tempe, Arizona; Arizona State University, Tempe, Arizona","2021 7th International Conference of the Immersive Learning Research Network (iLRN)","28 Jun 2021","2021","","","1","3","Augmented Reality (AR) is becoming readily more available as the number of AR capable smartphones and tablets increase in popularity. With its exponential development, augmented reality offers an oppurtunity to facilitate education in online chemistry. In hopes of furthering the advancement of augmented reality in online chemistry education, we developed a boiling water experiment to show the effects of heat capacity and to create an interactive lab experiment for online learning. Our work-in-progress paper explores how the utilization of augmented reality can improve the learning process and better exhibit chemistry lab concepts.","","978-1-7348995-2-8","10.23919/iLRN52045.2021.9459386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459386","augmented reality;chemistry;heat capacity","Chemistry;Fluids;Education;Water heating;Augmented reality;Standards;Smart phones","augmented reality;chemistry computing;computer aided instruction;interactive systems;laboratories;mobile learning;multimedia computing;smart phones;specific heat;student experiments","tablets;online chemistry education;boiling water experiment;interactive lab experiment;smartphones;AR chemistry lab;augmented reality chemistry lab;specific heat;education facilitation;learning process","","","","9","","28 Jun 2021","","","IEEE","IEEE Conferences"
"The Golden Ratio of Instructive Content to Entertaining Content in Mobile Augmented Reality Games","X. Wei; P. Xi","School of Educational Technology, Northwest Normal University, Lanzhou, China; School of Educational Technology, Northwest Normal University, Lanzhou, China","2022 International Symposium on Educational Technology (ISET)","29 Aug 2022","2022","","","189","191","Mobile augmented reality games are more effective for teaching and learning, and the impact of different proportions of learning content in mobile augmented reality games on preschoolers' learning outcomes is significant. For preschoolers there is a golden ratio that makes them learn better. This paper will discuss the impact of the proportion of game content on learning outcomes in mobile augmented reality games. The results show that the right proportion of instructional content in mobile augmented reality games enhances teaching effectiveness, satisfaction, entertainment and motivation. However, the proportion of learning content in play varies significantly across the age range. This study focuses on improving teaching effectiveness for teachers and designers by adjusting the proportion of instructional content in mobile augmented reality games when the content is similar.","2766-2144","978-1-6654-8467-1","10.1109/ISET55194.2022.00048","National Natural Science Foundation of China(grant numbers:62067009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9867033","Mobile augmented reality games;Game-based learning;Pedagogical content;Entertaining content","Entertainment industry;Games;Educational technology;Augmented reality","augmented reality;computer aided instruction;computer games;entertainment;mobile computing;teaching","mobile augmented reality games;game content;learning content","","","","6","IEEE","29 Aug 2022","","","IEEE","IEEE Conferences"
"Enabling large-scale outdoor Mixed Reality and Augmented Reality","S. Feiner; T. Korah; D. Murphy; V. Parameswaran; M. Stroila; S. White","Columbia University, USA; Media Technologies Laboratory, Nokia Research Center, Finland; Media Technologies Laboratory, Nokia Research Center, Finland; Nokia Research Center, Palo Alto, Finland; NAVTEQ Research and Development, USA; Media Technologies Laboratory, Nokia Research Center, Finland","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","1","1","Summary form only given. While there is significant recent progress in technologies supporting augmented reality for small indoor environments, there is still much work to be done for large outdoor environments. This workshop focuses primarily on research that enables high-quality outdoor Mixed Reality (MR) and Augmented Reality (AR) applications. These research topics include, but are not restricted to: - 3D geo-referenced data (images, point clouds, and models) - Algorithms for object recognition from large databases of geo-referenced data - Algorithms for object tracking in outdoor environment - Multi-cue fusion to achieve improved performance of object detection and tracking - Novel representation schemes to facilitate large-scale content distribution - 3D reasoning to support intelligent augmentation - Novel and improved mobile capabilities for data capture (device sensors), processing, and display - Applications, experiences, and user interface techniques. The workshop will also showcase existing prototypes of applications enabled by these technologies: mirror worlds, high-fidelity virtual environments, applications of panoramic imagery, and user studies relating to these media types. This workshop aims to bring together academic and industrial researchers and to foster discussion amongst participants on the current state of the art and future directions for technologies that enable large-scale outdoor MR and AR applications. The workshop will start with a session in which position statements and overviews of the state of the art are presented. In the afternoon, we will follow up with discussion sessions and a short closing session.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093643","","","augmented reality;data handling;inference mechanisms;object detection;object recognition;object tracking;sensor fusion;user interfaces","outdoor mixed reality;augmented reality;3D geo-referenced data;object recognition;object tracking;multicue fusion;object detection;large-scale content distribution;3D reasoning;intelligent augmentation;data capture;data processing;data display;user interface technique;mirror worlds;high-fidelity virtual environment;panoramic imagery","","","","","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Augmented Reality Electric Circuit Experiment","A. A. H. Alkurdi","Department of Computer Science, Nawroz University, Duhok, Iraq","2019 International Conference on Advanced Science and Engineering (ICOASE)","30 May 2019","2019","","","7","11","The advancement of hardware technology, specifically in mobiles devices, has provided great computational power for running and creating sophisticated large programs such as, virtual reality, augmented reality and neural network based programs. Augmented reality (AR) is one of the finest and most exciting technologies nowadays. AR enables creating computerized objects and blending them with the real world. Which can be applied to enhance and simplify many aspects in a variety of disciplines. In result, instead of reading text and imagining experimentations it is possible to simulate the experiments through equipment and experiments as same as in real world scenarios, which can be much understandable and comprehensible. In the past decade, several institutions have adopted technological methods of teaching and learning. These instructional technologies can be used by some institutions that cannot provide enough time or proper equipment to students. This is where augmented and virtual reality are mostly favorable. In result, instead of reading text and imagining experimentations it is possible to simulate the experiments through equipment and experiments as same as in real world scenarios, which can be much understandable and comprehensible. In this paper, a model of an electric circuit is created to simulate the motion of electrons and how electric current runs through a wire and provides power for different tools. The creation of such a model involves design, modeling, simulation and animation of the model. This is done by relying on several software and frameworks such as Maya3D, Unity3D, ARKit, etc. .","","978-1-5386-9343-8","10.1109/ICOASE.2019.8723683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723683","augmented reality;ARKit;Maya3D;Unity3D;electric circuit","Integrated circuit modeling;Animation;Augmented reality;Solid modeling;Education;Software","augmented reality;computer aided instruction;electrical engineering computing;electrical engineering education;neural nets;solid modelling;teaching","augmented reality electric circuit experiment;hardware technology;mobiles devices;virtual reality;neural network;computerized objects;imagining experimentations;animation","","1","","16","IEEE","30 May 2019","","","IEEE","IEEE Conferences"
"The Influence of Size in Augmented Reality Telepresence Avatars","M. E. Walker; D. Szafir; I. Rae","University of Colorado Boulder, Boulder, CO, US; University of Colorado Boulder, Boulder, CO, US; Google, Madison, WI, USA","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","538","546","In this work, we explore how advances in augmented reality technologies are creating a new design space for long-distance telepresence communication through virtual avatars. Studies have shown that the relative size of a speaker has a significant impact on many aspects of human communication including perceived dominance and persuasiveness. Our system synchronizes the body pose of a remote user with a realistic, virtual human avatar visible to a local user wearing an augmented reality head-mounted display. We conducted a two-by-two (relative system size: equivalent vs. small; leader vs. follower), between participants study (N = 40) to investigate the effect of avatar size on the interactions between remote and local user. We found the equal-sized avatars to be significantly more influential than the small-sized avatars and that the small avatars commanded significantly less attention than the equal-sized avatars. Additionally, we found the assigned leadership role to significantly impact participant subjective satisfaction of the task outcome.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798152","Avatars, augmented reality;mixed reality;avatar-mediated communication;human-avatar interaction;avatar telepresence systems;avatar size;scenario-based design;team role;Human-centered computing—HCI—Interaction paradigms—Mixed / augmented reality Human-centered computing—HCI—Interaction paradigms—Virtual reality Human-centered computing—HCI—Interaction paradigms—Web-based interaction Human-centered computing—HCI—Interaction paradigms—Collaborative interaction Human-centered computing—HCI—HCI design and evaluation methods—User studies Human-centered computing—HCI—HCI design and evaluation methods—Laboratory experiments Human-centered computing—Interaction design—Interaction design process and methods—Scenario-based design","Avatars;Telepresence;Robots;Augmented reality;Collaboration;Leadership","augmented reality;avatars;helmet mounted displays","augmented reality telepresence avatars;augmented reality technologies;long-distance telepresence communication;realistic avatar;virtual human avatar;augmented reality head-mounted display;avatar size;equal-sized avatars;small-sized avatars;human communication","","14","","34","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Interactive Mobile Augmented Reality system using a vibro-tactile pad","M. -S. Jin; J. -I. Park","Hanyang University, South Korea; Hanyang University, South Korea","2011 IEEE International Symposium on VR Innovation","29 Apr 2011","2011","","","329","330","Smart phone is good platform for hand-held Augmented Reality. As smart phone users grow, Augmented Reality applications are increasing. This paper proposes an interactive Mobile Augmented Reality system using a vibro-tactile pad. The proposed system can provide vibro-tactile feedback for realistic immersive experience. For interactive Mobile Augmented Reality, We focus on providing expressions augmented object's movements and location information using vibration motors. Through simple memory test application, we prove that the proposed system is useful for providing intuitive knowledge for information of augmented object's movements and location.","","978-1-4577-0054-5","10.1109/ISVRI.2011.5759663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759663","Haptic I/O;Human factors;User Interfaces;Virtual Reality","Augmented reality;Mobile communication;Vibrations;Smart phones;Haptic interfaces;Tactile sensors","augmented reality;haptic interfaces;mobile computing;mobile handsets","interactive mobile augmented reality system;vibro tactile pad;smart phone;hand held augmented reality;vibro tactile feedback;realistic immersive experience;vibration motors","","4","5","5","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"Towards Immersive Comprehension of Software Systems Using Augmented Reality - An Empirical Evaluation","R. Mehra; V. S. Sharma; V. Kaulgud; S. Podder; A. P. Burden","Accenture Labs, India; Accenture Labs, India; Accenture Labs, India; Accenture Labs, India; Accenture, Singapore","2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)","24 Dec 2020","2020","","","1267","1269","While traditionally, software comprehension relies on approaches like reading through the code or looking at charts on screens, which are 2D mediums, there have been some recent approaches that advocate exploring 3D approaches like Augmented or Virtual Reality (AR/VR) to have a richer experience towards understanding software and its internal relationships. However, there is a dearth of objective studies that compare such 3D representations with their traditional 2D counterparts in the context of software comprehension. In this paper, we present an evaluation study to quantitatively and qualitatively compare 2D and 3D software representations with respect to typical comprehension tasks. For the 3D medium, we utilize an AR-based approach for 3D visualizations of a software system (XRaSE), while the 2D medium comprises of textual IDEs and 2D graph representations. The study, which has been conducted using 20 professional developers, shows that for most comprehension tasks, the developers perform much better using the 3D representation, especially in terms of velocity and recollection, while also displaying reduced cognitive load and better engagement.","2643-1572","978-1-4503-6768-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286073","Software Visualization;Augmented Reality;3D Software;User Study","Visualization;Three-dimensional displays;Two dimensional displays;Software systems;Task analysis;Augmented reality;Software engineering","augmented reality;cognition;data visualisation;graph theory;software maintenance;user interfaces;virtual reality","augmented reality;empirical evaluation;software comprehension;Virtual Reality;richer experience;understanding software;objective studies;traditional 2D counterparts;evaluation study;3D software representations;typical comprehension tasks;software system;2D graph representations;towards immersive comprehension","","","","20","","24 Dec 2020","","","IEEE","IEEE Conferences"
"Lightweight Deep Learning based Intelligent Mobile Augmented Reality","J. G. Ko; S. Lee; S. Lee; J. Lee","Content Research Division, Communications & Media Research Laboratory, ETRI (Electronics Telecommunications Research Institute), Daejeon, Korea; Content Research Division, Communications & Media Research Laboratory, ETRI (Electronics Telecommunications Research Institute), Daejeon, Korea; Content Research Division, Communications & Media Research Laboratory, ETRI (Electronics Telecommunications Research Institute), Daejeon, Korea; Content Research Division, Communications & Media Research Laboratory, ETRI (Electronics Telecommunications Research Institute), Daejeon, Korea","2021 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)","15 Dec 2021","2021","","","1","3","Recently augmented reality technology is developing from simply displaying virtual objects in the real world to technologies that realistically fuse with real information. This paper introduces intelligent mobile AR technology that provides object and scene information by utilizing lightweight object detection and scene segmentation techniques operable in mobile phones. We provide object detection and scene segmentation capabilities with effective model structure improvements and model compression-based deep learning models for lightweight deep-learning models.In addition, we have made intelligent demonstration contents based on ARCore to provide object and scene information as well as display simple virtual objects.","","978-1-6654-0857-8","10.1109/ICCE-Asia53811.2021.9641972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9641972","Augmented Reality;Lightweight Deep learning;Object Detection","Deep learning;Fuses;Conferences;Object detection;Mobile handsets;Object recognition;Augmented reality","augmented reality;image segmentation;learning (artificial intelligence);mobile computing;object detection;virtual reality","intelligent mobile AR technology;scene information;lightweight object detection;scene segmentation techniques;mobile phones;scene segmentation capabilities;effective model structure improvements;model compression-based deep learning models;deep-learning models;intelligent demonstration contents;display simple virtual objects;lightweight deep;intelligent mobile augmented reality;reality technology","","","","6","IEEE","15 Dec 2021","","","IEEE","IEEE Conferences"
"A Research Agenda for Enterprise Augmented Reality","C. Perey; W. Z. Bernstein",PEREY Research and Consulting; Air Force Research Laboratory,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","477","480","Over the past decade, Augmented Reality (AR) has seen significant adoption to address diverse needs in many industries including aviation, automotive, power & energy, oil & gas, manufacturing, and healthcare. However, the more practitioners leverage AR, the more industrial research focuses on domain-specific challenges. In response, the Augmented Reality for Enterprise Alliance (AREA), a program of the Object Management Group (OMG), sponsored research to develop a domain-neutral and objective, data-driven research agenda for enterprise augmented reality. This paper summarizes the contributions of that effort, including (i) an automated approach for gathering and hierarchically organizing state-of-the-art research about enterprise AR, (ii) a method for identifying research gaps and opportunities, and (iii) set of promising research topics from which the IEEE VGTC community could choose for future study.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757694","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed/augmented reality;Enterprise Augmented Reality;Industrial Augmented Reality;Research Agenda;Data-Driven Gap Analysis","Industries;Three-dimensional displays;Conferences;Oils;Medical services;User interfaces;Manufacturing","augmented reality;virtual enterprises","industrial research;domain-specific challenges;enterprise alliance;object management group;enterprise AR;promising research topics;enterprise augmented reality","","","","4","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Egocentric space-distorting visualizations for rapid environment exploration in mobile mixed reality","C. Sandor; A. Dey; A. Cunningham; S. Barbier; U. Eck; D. Urquhart; M. R. Marner; G. Jarvis; S. Rhee","University of South Australia, Magic Vision Laboratory, Australia; University of South Australia, Magic Vision Laboratory, Australia; University of South Australia, Magic Vision Laboratory, Australia; University of South Australia, Magic Vision Laboratory, Australia; University of South Australia, Magic Vision Laboratory, Australia; University of South Australia, Magic Vision Laboratory; University of South Australia, Magic Vision Laboratory, Australia; University of South Australia, Magic Vision Laboratory, Australia; Department of Computer Science and Engineering, Kyungnam University, South Korea","2010 IEEE Virtual Reality Conference (VR)","8 Apr 2010","2010","","","47","50","Most of today's mobile internet devices contain facilities to display maps of the user's surroundings with points of interest embedded into the map. Other researchers have already explored complementary, egocentric visualizations of these points of interest using mobile mixed reality. Being able to perceive the point of interest in detail within the user's current context is desirable, however, it is challenging to display off-screen or occluded points of interest. We have designed and implemented space-distorting visualizations to address these situations. While this class of visualizations has been extensively studied in information visualization, we are not aware of any attempts to apply them to augmented or mixed reality. Based on the informal user feedback that we have gathered, we have performed several iterations on our visualizations. We hope that our initial results can inspire other researchers to also investigate space-distorting visualizations for mixed and augmented reality.","2375-5334","978-1-4244-6238-4","10.1109/VR.2010.5444815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444815","H.5.1. [Information Interfaces and Presentation]: Multimedia Information Systems-[Artificial, augmented and virtual realities];I.3.6 [Computer Graphics]: Methodology and Techniques-[Interaction Techniques]","Visualization;Virtual reality;Displays;Mobile computing;Image reconstruction;Solid modeling;Internet;Feedback;Augmented reality;Wearable computers","augmented reality;cartography;data visualisation;mobile computing","egocentric space-distorting visualizations;rapid environment exploration;mobile mixed reality;mobile internet devices;information visualization;augmented reality","","18","1","12","IEEE","8 Apr 2010","","","IEEE","IEEE Conferences"
"Creating Augmented Reality Experiences for Enterprise: Good practices, lessons learned, and technological insights","M. Sage",Augmented Reality for Enterprise Alliance,"IEEE Consumer Electronics Magazine","16 Dec 2016","2017","6","1","42","44","Creating augmented reality (AR) experiences for enterprise use cases is a complex process that involves meeting many requirements. In particular, industrial environments can offer developers and user experience (UX) design teams many restrictions and unforeseeable obstacles. Designing and developing AR experiences is an iterative process, during which the design team faces critical decision-making points that, if completed correctly, lead to the success of the project. However, making the right decisions in the correct order seems currently to be the privilege of a small number of experienced designers and developers, who make great treasure from that expertise.","2162-2256","","10.1109/MCE.2016.2614651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7786812","","Augmented reality;Business;Decision making;Object recognition","augmented reality;decision making;design;human factors;iterative methods;production engineering computing","augmented reality;enterprise;good practices;lessons learned;technological insights;industrial environments;user experience design;UX design;iterative process;decision-making points","","7","","","IEEE","16 Dec 2016","","","IEEE","IEEE Magazines"
"A Light-Field Journey to Virtual Reality","J. Yu","University of Delaware, Newark, DE, US","IEEE MultiMedia","10 May 2017","2017","24","2","104","112","Producing ultra-high-quality content is the next grand challenge for the VR industry. Creating a virtual reality that even the human eye cannot distinguish from the real world will require light-field technology--3D imaging technology that captures the light rays people perceive from different locations and directions. When combined with computer vision and machine learning, light-field technology provides a viable path for producing low-cost, high-quality VR content.","1941-0166","","10.1109/MMUL.2017.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7924239","virtualization;visualization;augmented reality;virtual reality;VR;graphics;multimedia;light field;pervasive computing;head-mounted display","Cameras;Virtual reality;Three-dimensional displays;Microoptics;Augmented reality;Multimedia communication;Pervasive computing;Virtual reality","computer vision;learning (artificial intelligence);virtual reality","virtual reality;VR industry;light-field technology;3D imaging technology;light rays;computer vision;machine learning","","40","","","IEEE","10 May 2017","","","IEEE","IEEE Magazines"
"Study of augmented gesture communication cues and view sharing in remote collaboration","S. Kim; G. A. Lee; N. Sakata; A. Dünser; E. Vartiainen; M. Billinghurst","HIT Lab NZ; HIT Lab NZ; HIT Lab, Osaka University; CCI, CSIRO; ABB Corporate Research; HIT Lab NZ","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","261","262","In this research, we explore how different types of augmented gesture communication cues can be used under different view sharing techniques in a remote collaboration system. In a pilot study, we compared four conditions: (1) Pointers on Still Image, (2) Pointers on Live Video, (3) Annotation on Still Image, and (4) Annotation on Live Video. Through this study, we found three results. First, users collaborate more efficiently using annotation cues than pointer cues for communicating object position and orientation information. Second, live video becomes more important when quick feedback is needed. Third, the type of gesture cue has more influence on performance and user preference than the type of view sharing method.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671795","Video Conferencing;Augmented Reality","Collaboration;Portable computers;Streaming media;Visualization;Augmented reality;Speech","augmented reality;gesture recognition;video communication;video signal processing","augmented gesture communication cues;view sharing techniques;remote collaboration system;still image annotation;live video annotation;still image pointers;live video pointers;annotation cues;pointer cues;object position;orientation information;quick feedback;user preference;video conferencing","","12","","4","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Contextual in-situ visualization for port placement in keyhole surgery: Evaluation of three target applications by two surgeons and eighteen medical trainees","C. Bichlmeier; S. Holdstock; S. M. Heining; S. Weidert; E. Euler; O. Kutter; N. Navab","Computer Aided Medical Procedures & Auqmented Reality (CAMP), TUM, Munich, Germany; Computer Aided Medical Procedures & Auqmented Reality (CAMP), TUM, Munich, Germany; Trauma Surgery Department, Klinikum Innenstadt, LMU, Munich, Germany; Trauma Surgery Department, Klinikum Innenstadt, LMU, Munich, Germany; Trauma Surgery Department, Klinikum Innenstadt, LMU, Munich, Germany; Computer Aided Medical Procedures & Auqmented Reality (CAMP), TUM, Munich, Germany; Computer Aided Medical Procedures & Auqmented Reality (CAMP), TUM, Munich, Germany","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","173","174","Port position in minimally invasive surgeries is chosen to minimize the lesion of tissue and maximize the movability for endoscopic instruments. In this study, we present an evaluation of the potential of a 3D contextual in-situ visualization of the anatomic target region to help surgeons for three different surgical procedures decide where best to create ports and incisions to enable the insertion of a specific set of instruments.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336474","K.3.1 [Computer Uses in Education];H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities","Visualization;Minimally invasive surgery;Surgical instruments;Target tracking;Testing;Computer vision;Augmented reality;Lesions;Cameras;Imaging phantoms","augmented reality;data visualisation;medical computing","contextual in-situ visualization;port placement;keyhole surgery;medical trainees;minimally invasive surgeries;3D contextual in-situ visualization","","","","6","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Augmented Reality in Reality","H. Ling",HiScene,"IEEE MultiMedia","1 Aug 2017","2017","24","3","10","15","In this survey of academic contributions driving augmented reality's commercial potential and of the industry trends advancing software and hardware developments and emerging applications, the author offers advice on how startups hoping to leverage these advances can compete against senior tech tycoons.","1941-0166","","10.1109/MMUL.2017.3051517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7999155","multimedia;augmented reality;startups;hardware;sensors;computer vision;visualization;virtualization;graphics","Semantics;Augmented reality;Commercialization;Two dimensional displays;Algorithm design and analysis;Three-dimensional displays","augmented reality;software engineering","augmented reality;software developments;hardware developments","","26","","20","IEEE","1 Aug 2017","","","IEEE","IEEE Magazines"
"From reality to augmented reality: Rapid strategies for developing marker-based AR content using image capturing and authoring tools","J. D. Camba; M. Contero","College of Architecture University of Houston, Houston, TX; Instituto de Investigacion en Bioingenieríay Tecnología Orientada al Ser Humano (I3BH), Universitat Politècnica de València, Valencia, Spain","2015 IEEE Frontiers in Education Conference (FIE)","7 Dec 2015","2015","","","1","6","This paper builds on the authors' previous work with Augmented Reality (AR) technology, where interactive three-dimensional (3D) content was developed and combined with traditional printed materials to enhance the visualization and understanding of technical information. In this study, we describe a method to rapidly create custom marker-based AR content using 3D data from real objects and an authoring tool developed in-house. We present a two step process, where 3D geometry is generated automatically by capturing and processing a series of photographs of a real object and subsequently converted to an AR element that can be linked to a unique marker and used with a marker-based AR system. This system provides an opportunity for instructors to quickly and effortlessly create their own AR content to support their innovative teaching practices.","","978-1-4799-8454-1","10.1109/FIE.2015.7344162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344162","augmented reality;image-based modeling;3D content creation","Three-dimensional displays;Solid modeling;Augmented reality;Cameras;Computational modeling;Software;Education","augmented reality;authoring systems;data visualisation;image processing","image capturing;authoring tools;augmented reality technology;interactive three-dimensional content;traditional printed materials;visualization enhancement;real objects;3D geometry;two step process;photographs;AR element;innovative teaching practices;technical information;custom marker-based AR content;3D data","","8","","37","IEEE","7 Dec 2015","","","IEEE","IEEE Conferences"
"A framework for volume segmentation and visualization using Augmented Reality","T. Tawara; K. Ono","RIKEN, Japan; RIKEN, Japan","2010 IEEE Symposium on 3D User Interfaces (3DUI)","29 Apr 2010","2010","","","121","122","We propose a two-handed direct manipulation system to achieve complex volume segmentation of CT/MRI data in Augmented Reality with a remote controller attached to a motion tracking cube. At the same time segmented data is displayed by direct volume rendering using a programmable GPU. Our system achieves visualization of real time modification of volume data with complex shading including transparency control by changing transfer functions, displaying any cross section, and rendering multi materials using a local illumination model. Our goal is to build a system that facilitates direct manipulation of volumetric CT/MRI data for segmentation in Augmented Reality. Volume segmentation is a challenging problem and segmented data has an important role for visualization and analysis.","","978-1-4244-6847-8","10.1109/3DUI.2010.5444707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444707","","Augmented reality;Data visualization;Data mining;Magnetic resonance imaging;Tracking;Humans;Motion control;Control systems;Shape control;Needles","augmented reality;biomedical MRI;computerised tomography;data visualisation;image segmentation;medical image processing","volume segmentation;volume visualization;augmented reality;direct manipulation system;CT/MRI data;motion tracking cube;real time modification","","5","","4","IEEE","29 Apr 2010","","","IEEE","IEEE Conferences"
"Coordinated and Multiple Views in Augmented Reality Environment","R. M. Casseb do Carmo; B. S. Meiguins; A. S. G. Meiguins; S. C. V. Pinheiro; L. H. Almeida; P. I. A. Godinho","Centro de Ciências Exatas e Naturais – Universidade Federal do Pará (UFPA), Belém, PA, Brasil; Centro de Ciências Exatas e Naturais – Universidade Federal do Pará (UFPA), Belém, PA, Brasil; Área de Ciências e Tecnologia – Centro Universitário do Pará (CESUPA), Bclém, PA, Brasil; Centro de Ciências Exatas e Naturais – Universidade Federal do Pará (UFPA), Belém, PA, Brasil; Centro de Ciências Exatas e Naturais – Universidade Federal do Pará (UFPA), Belém, PA, Brasil; Centro de Ciências Exatas e Naturais – Universidade Federal do Pará (UFPA), Belém, PA, Brasil","2007 11th International Conference Information Visualization (IV '07)","16 Jul 2007","2007","","","156","162","The paper presents a prototype that implements multiple coordinated views to information visualization in augmented reality environments. Augmented reality provides more intuitive and easy interaction. It also reduces the limitations of visualization and enhances the collaborative aspect. A modified version of ARToolKit has been used to create the augmented environment, and the 3D scatter plot technique has been developed to represent the multiple views of data. The coordination between views supported dynamic queries, data selection, and the configuration of views and of the detail on demand feature. This paper also reproduces literature usability tests based on tasks in order to analyze the viability to implement multiple coordinated views in augmented environments for information visualization.","1550-6037","0-7695-2900-3","10.1109/IV.2007.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4271976","Information Visualization;Augmented;Reality;Multiple Coordinated Views.","Augmented reality;Data visualization;Prototypes;Scattering;Information analysis;Data analysis;Collaboration;Usability;Testing;Computer interfaces","augmented reality;data visualisation","augmented reality environment;multiple coordinated views;ARToolKit;augmented environment;3D scatter plot technique;dynamic queries;data selection;information visualization","","8","1","16","IEEE","16 Jul 2007","","","IEEE","IEEE Conferences"
"Distributed model for realtime augmented reality","S. Khan; S. Dholay","Computer Engineering Sardar Patel Institute of Technology; Computer Engineering Sardar Patel Institute of Technology, Mumbai, India","2015 1st International Conference on Next Generation Computing Technologies (NGCT)","11 Jan 2016","2015","","","104","108","This paper presents a Networked system of Multiple Smartphones trying to augment information residing over Server, based on current Camera Environment of the Smartphone. A Feasible solution for simulating Augmented Reality over Distributed System with Accuracy high performance has to be presented. The environment has to be accurately determined by using efficient feature matching techniques of the current camera scene and database. Smartphones have high bandwidth camera and have limited computational Compatibilities. To achieve this, real-time camera frames of smartphones are processed to extract their own set of compact and efficient feature descriptors along with location data, which are sent to the server over Wi-Fi. Computationally Heavy Feature Matching algorithms are run on the server to match the data sent from Smartphone with the Database of different Environments.","","978-1-4673-6809-4","10.1109/NGCT.2015.7375092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375092","Distributed Augmented Reality;Camera Data Processing;Pose Estimation;Feature Matching","Smart phones;Servers;Cameras;Augmented reality;Feature extraction;Three-dimensional displays;Computational modeling","augmented reality;cameras;distributed processing;feature extraction;image matching;smart phones;visual databases;wireless LAN","distributed model;realtime augmented reality;multiple smartphone networked system;camera environment;augmented reality;distributed system;feature matching techniques;camera scene;high bandwidth camera;computational compatibilities;feature matching algorithms","","2","","13","IEEE","11 Jan 2016","","","IEEE","IEEE Conferences"
"Poster: Manipulating virtual objects in hand-held augmented reality using stored snapshots","M. Sukan; S. Feiner; S. Energin","Columbia University, USA; Columbia University, USA; Columbia University, USA","2012 IEEE Symposium on 3D User Interfaces (3DUI)","19 Apr 2012","2012","","","165","166","We describe a set of interaction techniques that allow a user of a magic-lens style augmented reality application to take snapshots of an augmented scene and revisit them virtually for interaction at a later time. By storing a still image of the background along with the camera pose, this approach allows augmentations to remain dynamic and interactive. This makes it possible for the user to manipulate virtual objects from the vantage points of different locations without the overhead of physically traveling between those locations. Preliminary results from a user study show that participants were able to complete an alignment task significantly faster and as accurately when using snapshots as opposed to physical travel. Qualitative questionnaire answers showed that participants preferred using snapshots over walking and found it less demanding.","","978-1-4673-1205-9","10.1109/3DUI.2012.6184213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184213","Augmented reality;viewpoint switching","Cameras;Switches;Augmented reality;Visualization;Presses;Mobile communication;Design automation","augmented reality;cameras;user interfaces","virtual object manipulation;hand-held augmented reality;stored snapshots;interaction techniques;magic-lens style augmented reality application;camera pose;qualitative questionnaire answers","","1","","6","IEEE","19 Apr 2012","","","IEEE","IEEE Conferences"
"iSarProjection: A KinectFusion Based Handheld Dynamic Spatial Augmented Reality System","M. Tan; W. Xu; D. Weng","Department of Optoelectronic Engineering, Beijing Institute of Technology, Beijing, China; Department of Optoelectronic Engineering, Beijing Institute of Technology, Beijing, China; Department of Optoelectronic Engineering, Beijing Institute of Technology, Beijing, China","2013 International Conference on Computer-Aided Design and Computer Graphics","15 May 2014","2013","","","425","426","We introduce a general technique of dynamically augmenting physical models. Using a handheld projector attached with an RGBD camera, we map the physical model with corresponding textures, and develop a real-time dynamic spatial augmented reality (SAR) system named iSarProjection. Compared to traditional huge and complex tracking system, this technique, based on KinectFusion, supports precise registration between the physical model point cloud and the reconstructed 3D scene, and provides real-time pose estimation to track the physical display surface effectively. Through projecting medical anatomy visualizations on a white body model, it presents that we ease the development of dynamic SAR system and make it possible to be applied in various research fields.","","978-1-4799-2576-6","10.1109/CADGraphics.2013.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815043","Spatial Augmented Reality;Dynamic Projection;KinectFusion;Medical AR","Augmented reality;Cameras;Head;Three-dimensional displays;Surface reconstruction;Biomedical imaging;Real-time systems","augmented reality;cameras;image reconstruction;image registration;image texture;medical computing;pose estimation","iSarProjection;KinectFusion-based handheld dynamic spatial augmented reality system;dynamically physical model augmentation;handheld projector;RGBD camera;texture mapping;real-time dynamic spatial augmented reality system;physical model point cloud;reconstructed 3D scene;real-time pose estimation;physical display surface tracking;medical anatomy visualization;white body model;dynamic SAR system","","1","1","7","IEEE","15 May 2014","","","IEEE","IEEE Conferences"
"Realization of Multilayer Occlusion between Real and Virtual Scenes in Augmented Reality","Y. Feng; W. Du; X. Guan; F. Gao; Y. Chen","School of Computer Computer Engineering and Science, Shanghai University, Shanghai, China; Business College, Shanghai Normal University, Shanghai, China; School of Computer Computer Engineering and Science, Shanghai University, Shanghai, China; School of Computer Computer Engineering and Science, Shanghai University, Shanghai, China; School of Computer Computer Engineering and Science, Shanghai University, Shanghai, China","2006 10th International Conference on Computer Supported Cooperative Work in Design","4 Dec 2006","2006","","","1","5","Augmented reality system is well suited for Computer Supported Cooperative Work. For achieving visual realism, correctly handling and representing occlusion between virtual and real objects in Augmented Reality scene is essential. Here, we present an approach for realizing multilayer occlusion. Differing qualitatively from previous work in AR occlusion, our algorithm realizes multilayer occlusion, and its application domain involves indoor-field occluded objects, which are several meters distant from the viewer. Previous related work has focused on monolayer occlusion, and near-field occluded objects, which are within or just beyond arm's reach. We designed a special scene graph tree comprised of some special nodes, namely EMO nodes. According to the location of real moving object, different EMO node will be activated in real-time, consequently realizing the multilayer occlusion. Experimental results are provided to demonstrate the multilayer indoor-field occlusion.","","1-4244-0164-X","10.1109/CSCWD.2006.253124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4019160","Augmented Reality;Multilayer Occlusion;Alpha Channel;EMO Node;Scene Graph Tree","Nonhomogeneous media;Layout;Augmented reality;Collaborative work;Virtual reality;Collaboration;Displays;Computer interfaces;Tree graphs;Collaborative tools","augmented reality;graph theory;groupware;human computer interaction;visual perception","multilayer occlusion;real scenes;virtual scenes;augmented reality system;computer supported cooperative work;indoor-field occluded objects;scene graph tree;EMO nodes","","3","3","13","IEEE","4 Dec 2006","","","IEEE","IEEE Conferences"
"Interactive augmented reality environments for engineering with open systems","M. S. Sidhu; L. C. Kang","Department of Graphics and Multimedia, Universiti Tenaga National (UNITEN), Kajang, Selangor, Malaysia; Department of Information Technology, University Tunku Abdul Rahman (UTAR), Perak, Malaysia","2011 IEEE Conference on Open Systems","14 Nov 2011","2011","","","1","5","Authoring tools are becoming more powerful nowadays due to technological advancements. In a virtual augmented Reality (AR) environment, authoring tools can be used to imitate reality to a certain point. However by employing open systems as an alternative platform for authoring learning contents, developers need to be aware of the options available to them in the development process. This paper reviews some commonly used open source software that could be employed in developing interactive environments for learning and discusses the potential benefits of these authoring tools for simulating engineering problems.","","978-1-61284-931-7","10.1109/ICOS.2011.6079279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079279","augmented reality;interactivity;virtual;engineering;education","Three dimensional displays;Education;Augmented reality;Visualization;Solid modeling;Multimedia communication","augmented reality;computer aided instruction;interactive systems;open systems","interactive augmented reality environments;open systems;authoring tools;virtual augmented Reality;AR;open source software;interactive environments;computer aided instruction","","3","","15","IEEE","14 Nov 2011","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality Applied in Power Electric Utilities for Human Interface Improvement – A Study Case for Best Practices","D. V. João; P. Z. Lodetti; M. A. I. Martins; J. F. B. Almeida","Sustainable Energy Center CERTI Foundation, Florianópolis-SC, Brazil; Sustainable Energy Center CERTI Foundation, Florianópolis-SC, Brazil; Sustainable Energy Center CERTI Foundation, Florianópolis-SC, Brazil; NT&I - Smart Grid Brasil Enel Distribuição São Paulo, Sao Paulo, Brazil","2020 IEEE Technology & Engineering Management Conference (TEMSCON)","15 Jul 2020","2020","","","1","4","With the emergence of new technologies and the need to make processes more sustainable, cities and utilities tend to become increasingly “smarter”. It is no different for electric power system and its grid services. Therefore, the digitalization of the electrical Utilities is more and more assiduous. It contributes to a better supply of energy with more reliability, as well as the reduction of operational and maintenance cost. For what concerns the grid services, the workforce is a constantly target to improvement. Doing so, the Utilities Human Interface sector can be enhanced with digital technological trends. For instance, virtual and augmented realities is used to sharpening cognitive and on-field operational aspects. These technologies have applicability that involves learning process, training improvement, faster problem solution, facilitation of operations, etc. This paper aims to evaluated VR and AR looking at its trends toward an innovative technology applied to Electrical Utilities. Likewise, indicate the best practice application that was find during a Brazilian R&D project, named Urban Futurability, developed in a Brazilian Electrical Distribution Company.","","978-1-7281-4224-1","10.1109/TEMSCON47658.2020.9140129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140129","virtual reality;augmented reality;power systems trends;human interface;workforce;digital twin;Industry 4.0","Eye protection;Market research;Augmented reality;Visualization;Power industry;Best practices;Companies","augmented reality;electricity supply industry;grid computing;human computer interaction;human factors;power engineering computing","electric power system;grid services;digitalization;operational maintenance cost;digital technological trends;virtual realities;augmented realities;on-field operational aspects;innovative technology;Electrical Utilities;Brazilian Electrical Distribution Company;human interface improvement;human interface sector","","3","","16","IEEE","15 Jul 2020","","","IEEE","IEEE Conferences"
"Real-Time Tracking for Augmented reality","M. Badeche; M. Benmohamed","Department of computer science, Hadj Lakhdar University, Batna, Algeria; Lire Laboratory, University of Mentouri, Constantine, Algeria","2006 2nd International Conference on Information & Communication Technologies","16 Oct 2006","2006","1","","1773","1778","In real time applications of augmented reality, it is always matter of tracking; one of the most promising techniques in this sense is tracking based pattern. In this paper we describe a method based on the discrete Kalman filter for a real-time tracking of a 2D pattern for augmented reality. Objective being to make real-time tracking of a 2D pattern through a video stream on the simple personal computer; the process can be resumed as follow: in each frame we do an estimation by Kalman filter of predict corner location, after we proceed to correct this estimation by a measure around predict location, with Harris corner detection. the results obtains are very satisfactory, because all the process precede on real time and succeed to accurately track the pattern through video stream","","0-7803-9521-2","10.1109/ICTTA.2006.1684654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1684654","Augmented reality;corner tracking;Realtime tracking;Kalm an filter;corner detection","Augmented reality;Streaming media;Nonlinear filters;State estimation;Biomedical imaging;Real time systems;X-rays;Laboratories;Microcomputers;Virtual reality","augmented reality;Kalman filters;real-time systems;tracking filters;video streaming","real-time tracking;augmented reality;tracking based pattern;discrete Kalman filter;2D pattern;video stream;Harris corner detection;corner tracking","","1","","7","IEEE","16 Oct 2006","","","IEEE","IEEE Conferences"
"A new optical tracking system for virtual and augmented reality applications","M. Ribo; A. Pinz; A. L. Fuhrmann","Center for Virtual Reality and Visualization, Vienna, Austria; Institute of Electrical Measurement and Measurement Signal Processing, Graz University of Technology, Austria; Center for Virtual Reality and Visualization, Vienna, Austria","IMTC 2001. Proceedings of the 18th IEEE Instrumentation and Measurement Technology Conference. Rediscovering Measurement in the Age of Informatics (Cat. No.01CH 37188)","7 Aug 2002","2001","3","","1932","1936 vol.3","A new stereo vision tracker setup for virtual and augmented reality applications is presented in this paper. The performance, robustness and accuracy of the system are achieved under real-time constraints. The method is based on blobs extraction, two-dimensional prediction, the epipolar constraint and three-dimensional reconstruction. Experimental results using a stereo rig setup (equipped with IR capabilities) and retroreflective targets are presented to demonstrate the capabilities of our optical tracking system. The system tracks up to 25 independent targets at 30 Hz.","1091-5281","0-7803-6646-8","10.1109/IMTC.2001.929537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=929537","","Augmented reality;Target tracking;Virtual reality;Layout;Optical signal processing;Real time systems;Visualization;Electric variables measurement;Stereo vision;Robustness","virtual reality;augmented reality;interactive devices;image scanners;stereo image processing;optical tracking;visual perception;calibration","stereo vision tracker setup;augmented reality;virtual reality;optical tracking system;performance;robustness;real-time constraints;blobs extraction;two-dimensional prediction;epipolar constraint;three-dimensional reconstruction;IR capabilities;retroreflective targets;digital image analysis;progressive scan CCD;3D interaction devices;calibration","","43","4","18","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Implementation of image processing and augmented reality programs for smart mobile device","Jaeyoung Kim; Heesung Jun","School of Electrical Engineering, University of Ulsan, Ulsan, Korea; School of Electrical Engineering, University of Ulsan, Ulsan, Korea","Proceedings of 2011 6th International Forum on Strategic Technology","15 Sep 2011","2011","2","","1070","1073","We implemented real-time image processing program using OpenCV library for Apple's iPhone4 smart mobile phone. Our image processing program can do various operations such as thresholding, adaptive thresholding, edge detection and contour detection. Convenient user interface was developed using Objective-C. Also, we implemented augmented reality program on iPhone4. ARToolKitPlus by Wagner was analyzed for each stage of the library before the implementation. Also, we experimented on augmented reality with smart phone by using VRToolKit which is implemented by Loulier. We confirmed that our created earth model with OpenGL ES is augmented smoothly in real-time. This research will be a basis for developing smart phone programs such as face recognition, marker recognition and augmented reality program.","","978-1-4577-0399-7","10.1109/IFOST.2011.6021205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021205","smart phone;iPhone;image processing;augmented reality;marker recognition;OpenCV;OpenGL","Augmented reality;Smart phones;Real time systems;Three dimensional displays;Image edge detection","augmented reality;edge detection;image segmentation;mobile computing;mobile handsets;software libraries;user interfaces","image processing;augmented reality program;smart mobile device;OpenCV library;Apple iPhone4 smart mobile phone;adaptive thresholding;edge detection;contour detection;user interface;Objective-C;ARToolKitPlus;VRToolKit;OpenGL ES","","3","3","10","IEEE","15 Sep 2011","","","IEEE","IEEE Conferences"
"Word recognition incorporating augmented reality for linguistic E-conversion","R. F. J. Rose; G. Bhuvaneswari","Department of Computer Science and Engineering, DMI College of Engineering; Department of Computer Science and Engineering, DMI College of Engineering","2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT)","24 Nov 2016","2016","","","2106","2109","Augmented Reality (AR) is one of the Ubiquitous Computing Technologies that can be used for realizing Internet of Things (IoT) application. The fact is to create an artificial world that provides sense of a real world where a real life is enhanced by virtual elements in real times. This project deals with the development and implementation of Augmented Reality software for linguistic conversion on smart phones. This exploits smart phone's processing capabilities for sensing external objects using camera, to augment the real world objects with virtual data for character recognition and conversion from English Text to Tamil Language. The Tamil Text is overlaid on the captured English Text by providing the meaning to the word captured in modern language. Image processing and image analysis tend to focus on 2D images, how to transform one image to another, e.g., by pixel-wise operations such as contrast enhancement, local operations such as edge extraction or noise removal, or geometrical transformations such as rotating the image. This characterization implies that image processing/analysis neither require assumptions nor produce interpretations about the image content. The scope for this paper is to make an application for a phone using mobile OS, with the subject of augmented reality. The application should be a prototype using a library. This will be done by implementing several modules that serves as a basis to augment the reality, by using the phone's camera.","","978-1-4673-9939-5","10.1109/ICEEOT.2016.7755061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7755061","Augmented Reality;Mobile Learning;Ubiquitous Computing;Internet of Things(IoT);Android;Camera Sensor;Tamil Language Learning","Smart phones;Augmented reality;Mobile communication;Cameras;Image recognition;Character recognition;Text recognition","augmented reality;character recognition;edge detection;image denoising;image enhancement;Internet of Things;language translation;linguistics;natural language processing;smart phones","word recognition;linguistic E-conversion;ubiquitous computing technology;Internet of Things;IoT application;virtual elements;augmented reality software;smart phone processing capability;virtual data;character recognition;English text to Tamil language conversion;word capture;image processing;image analysis;image transformätion;pixel-wise operation;contrast enhancement;edge extraction;noise removal;geometrical transformation;image rotation;image content;mobile OS;phone camera","","3","","11","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"An Experimental Research of Augmented Reality Technology from the Perspective of Mobile Learning","W. Cai; Q. Chen","South China Normal University, Guangzhou, CN; Ministry of Information Technology, Shenzhen Longhua Institue of Education Sciences, Shenzhen, China","2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)","17 Jan 2019","2018","","","912","915","Currently, mobile learning is a more and more common way of learning. However, mobile learning itself has the problem that the learners' knowledge learning is lack of depth, which cannot be overcome by mobile learning for a long time. Augmented Reality is a technology which can blend reality and virtual environment together to strengthen learners' visual impression and help them immerse themselves in learning. The study starts from two aspects of definition and characteristics to explore the fit between the mobile learning and Augmented Reality, in order to lay a theoretical foundation for subsequent application research. And then the micro lessons based on augmented reality technology are applied on college students. From the experiment, the study explores the way to fully ingrate Augmented Reality and colleges and universities education. The research shows, the application of AR in the field of mobile learning has gradually matured and the prospects for development are broad.","2470-6698","978-1-5386-6522-0","10.1109/TALE.2018.8615146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615146","Augmented Reality;mobile learning;education;experiment","Augmented reality;Education;Standards;Wireless communication;Internet;Mobile handsets;Australia","augmented reality;computer aided instruction;educational institutions;mobile computing","learners visual impression;virtual environment;micro lessons;AR;augmented reality technology;mobile learning","","1","","10","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"A Study on Effective Visual Communication Method with the ""Pictomation' Contents in Augmented Reality Environment","H. -S. Myung; B. -G. Lee; H. -W. Kim; S. -H. Kang","Department of Visual Contents, Dong Seo University, South Korea; Department of Visual Contents, Dong Seo University, South Korea; Department of Multimedia Design, Dong Seo University, South Korea; Department of Multimedia Design, Dong Seo University, South Korea","2009 13th International Conference Information Visualisation","4 Aug 2009","2009","","","274","279","This paper analyzes visual communication elements of pictogram, and proposes efficient expression method in argument reality environment. Pictogram should be recognized the meaning by everybody in the world, and must be designed with fairness and objectivity as visual communication medium with correct information for unspecific users. Pictomation in this paper is produced by animation with grafting together actions that could find within standard pictogram and culture in order to elevate information transmission realization to user, and expressed with augmented reality technology which is applied in various study fields. Augmented reality offers human-computer interaction for method that can prove user realization about visual information of three-dimensional space based on reality environment as user-contents information communication medium.Pictomation uses various pictograms that can see everywhere in order to utilize by marker. And you can experience contents with Pictomation that is manufactured under AR environment through UMPC or PDA. Pictomation can increase effect about visual communication, and gives user freedom of selection that can forecast kind of contents. This paper tried to integrate amused element through contents with multimedia elements and real-time interaction, and find the method for effective communication with users through Pictomation in augmented reality.","2375-0138","978-0-7695-3733-7","10.1109/IV.2009.104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5190857","Pictogram;Visual Communication;Pictomation;Augmented Reality;ARToolkit","Visual communication;Augmented reality;Information systems;Intelligent structures;Internet;Data mining;Information technology;Information analysis;Natural languages;Databases","augmented reality;computer animation;human computer interaction","visual communication method;pictomation contents;augmented reality environment;pictogram;human-computer interaction;user-contents information communication medium","","1","","6","IEEE","4 Aug 2009","","","IEEE","IEEE Conferences"
"Indoor location identification with better outlook through Augmented Reality","Leeladevi B; Rahul Raj CP; S. Tolety","Siemens Technology and Services, Bangalore, India; Siemens Technology and Services, Bangalore, India; Siemens Technology and Services, Bangalore, India","2014 IEEE International Conference on Advanced Communications, Control and Computing Technologies","26 Jan 2015","2014","","","398","401","Augmented Reality is one of the emerging powerful technologies which superimpose digitally rendered images onto our real-world surroundings, thereby enhancing one's current perception of reality [1]. Augmented reality has proven very useful on a day to day basis when laid with location based technology. However, this technology is limited to popular buildings or outdoor locations and will not be able to provide information for indoor locations. The identification of current location using GPS has a limitation when it comes to indoor environment. This paper elicits a technique for location identification for an indoor environment and displaying the location information in the most usable way using the Augmented Reality.","","978-1-4799-3914-5","10.1109/ICACCCT.2014.7019471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7019471","Augmented Reality;GPS;Indoor location identification;Identification using mobile phones;indoor navigation","Augmented reality;Mobile communication;Cameras;Global Positioning System;Visualization;Buildings;Computers","augmented reality;indoor navigation;rendering (computer graphics)","indoor environment;GPS;rendered images;augmented reality;indoor location identification","","1","","10","IEEE","26 Jan 2015","","","IEEE","IEEE Conferences"
"Augmented reality and application areas","M. Kanmaz","Istanbul Universitesi, Fatih, Istanbul, TR","2017 International Conference on Computer Science and Engineering (UBMK)","2 Nov 2017","2017","","","954","956","The concept of augmented reality, which we have often heard about in recent years, means to reflect on the real world the objects created in the virtual environment with the help of mobile devices, to create a sense of reality. The concept of augmented reality, which allows many technological developments, has started to be used in many fields of education industry and applications have been made to make life easier. In this study, general information about the augmented reality has been given and the applications made in this subject have been mentioned and no new method has been proposed.","","978-1-5386-0930-9","10.1109/UBMK.2017.8093578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093578","Augmented Reality","Augmented reality;Google;Education;Glass;Computational modeling;Mathematical model;Nanoelectromechanical systems","augmented reality;mobile computing","augmented reality;application areas;virtual environment;education industry","","","","","IEEE","2 Nov 2017","","","IEEE","IEEE Conferences"
"Augmented-Reality Computer-Vision Assisted Disaggregated Energy Monitoring and IoT Control Platform","J. A. Purmaissur; P. Towakel; S. P. Guness; A. Seeam; X. A. Bellekens","Middlesex University (Mauritius) Uniciti, Flic en Flac, Mauritius; Middlesex University (Mauritius) Uniciti, Flic en Flac, Mauritius; Middlesex University (Mauritius) Uniciti, Flic en Flac, Mauritius; Middlesex University (Mauritius) Uniciti, Flic en Flac, Mauritius; University of Abertay, Dundee, Scotland","2018 International Conference on Intelligent and Innovative Computing Applications (ICONIC)","6 Jan 2019","2018","","","1","6","The aim of this research is to develop an innovative low cost and affordable platform for smart home control and energy monitoring interfaced with augmented reality. This method will educate people about energy use at a time when fuel costs are rising and create novel methods of interaction for those with disabilities. In order to increase the awareness of energy consumption, we have developed an interactive system using Augmented Reality to show live energy usage of electrical components. This system allows the user to view his real time energy consumption and at the same time offers the possibility to interact with the device in Augmented Reality. The energy usage was captured and stored in a database which can be accessed for energy monitoring. We believe that the combinations of both, complex smart home applications and transparent interactive user interface will increase the awareness of energy consumption.","","978-1-5386-6477-3","10.1109/ICONIC.2018.8601199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601199","Air Quality;Augmented Reality;Presence detection;Sensor","Smart homes;Augmented reality;Monitoring;Energy consumption;Plugs;Computer vision;Cameras","augmented reality;computer vision;control engineering computing;energy consumption;Internet of Things;user interfaces","reality computer-vision assisted disaggregated energy monitoring;IoT control platform;innovative low cost;affordable platform;smart home control;augmented reality;fuel costs;interactive system;live energy usage;time energy consumption;complex smart home applications;transparent interactive user interface","","8","","29","IEEE","6 Jan 2019","","","IEEE","IEEE Conferences"
"Combined with augmented reality navigation applications in the library","D. -Y. Liu","Department of Applied Geoinformatics, Chia Nan University of Pharmacy & Science, Taiwan","2016 International Conference on Advanced Materials for Science and Engineering (ICAMSE)","6 Feb 2017","2016","","","441","443","Due to the increasing popularity of mobile devices and network caused by the traditional way of navigation has been gradually combined with the convenience of mobile devices, and the integration of voice, video, wireless transmission and database technology, through real-time Internet transmission to develop a mobile navigation system. Mobile navigation system does not require a lot of written information, they provide a lot of information can be stored and organized, and can be combined with virtual reality and augmented reality technology, when the navigation application can be used as large-scale exhibition. Currently mobile navigation systems are also widely used in museums, galleries, libraries and other exhibitions in historic buildings. Thus, in the case of scientific and technological progress, more diversified ways of learning, and the library is also actively provide opportunities for mobile learning through mobile devices. This article will explore the current situation combined with augmented reality mode library in navigating, and future trends provide mobile learning in the library.","","978-1-5090-3869-5","10.1109/ICAMSE.2016.7840320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840320","Augmented Reality;Mobile navigation","Libraries;Navigation;Mobile communication;Augmented reality;Mobile handsets;Computers","augmented reality;digital libraries;information retrieval;Internet;mobile computing;museums;real-time systems","augmented reality navigation;mobile devices;real-time Internet transmission;mobile navigation system;virtual reality;museums;galleries;libraries;historic buildings","","3","","7","IEEE","6 Feb 2017","","","IEEE","IEEE Conferences"
"Future Agriculture Farm Management Using Augmented Reality: A Study","S. T; N. B; N. H. Shahapure; N. S; S. S. Shashidhara","Vilcart Solutions Pvt Ltd, Bangalore, India; Dept. of ISE, JSS Academy of Technical Education, Bangalore, India; Dept. of ISE, JSS Academy of Technical Education, Bangalore, India; Dept. of ISE, JSS Academy ofTechnical Education, Bangalore, India; Dept. of Electrical engineeringand Computer Science, Syracuse University, NY","2022 Fourth International Conference on Cognitive Computing and Information Processing (CCIP)","31 Mar 2023","2022","","","1","4","Augmented reality is a live direct or indirect view of physical-word. ‘Augment’ by computer generated or extracted real word sensory. Augmented Reality supplement your word with digital object of any sort. It combines physical and virtual word. This is one of the immersive technologies that will change your lifestyle in the near future. AR technology has the positive opportunity and service to educate change. Agriculture has been an important source of food and has always been a very important aspect. Agriculture is highly labor-intensive and highly dependent on the knowledge of individual farmers, causing management problems. It can make a decisive input to the best possible operation management of AR. Improve farmers reality in insect research and pest control AR correction compared to orthodox techniques and teaching methods (circles, speeches, etc.). In the eyes of the overall public, agriculture has a tendency to be easier. This is just like the easy case of sowing and reaping seeds. Agriculture is absolutely the becoming a member of collectively of diverse sciences and is a completely complicated manufacturing system. The demanding situations dealing with in enterprise appear like exacerbated with the aid of using the extra of a well-skilled team of workers in at the upward thrust countries. It isn't unusual for uneducated humans to interact in agriculture the use of suspicious archaic techniques. Not surprisingly, they fail, which ends up in diverse demographic demanding situations for society.","","978-1-6654-5648-7","10.1109/CCIP57447.2022.10058665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10058665","Agriculture;Augmented reality technology;headmounted","Insects;Education;Information processing;Pest control;Agriculture;Seeds (agriculture);Cognitive systems;Augmented reality;Manufacturing systems","agriculture;augmented reality;farming;pest control;teaching","Augmented Reality supplement your word;digital object;future agriculture farm management;immersive technologies;improve farmers reality;indirect view;individual farmers;live direct view;management problems;physical-word;positive opportunity;possible operation management;virtual word;word sensory","","","","18","IEEE","31 Mar 2023","","","IEEE","IEEE Conferences"
"Heart Care Augmented Reality Mobile Simulation (heARt)","F. Mohamed; S. C. Chaic Tong; B. Tomi; M. K. Mokhtar; Y. A. Yusoff","UTM-IRDA Digital Media Centre, Universiti Teknologi Malaysia, Johor Darul Takzim, Malaysia; UTM-IRDA Digital Media Centre, Universiti Teknologi Malaysia, Skudai, Johor, MY; UTM-IRDA Digital Media Centre, Universiti Teknologi Malaysia, Johor Darul Takzim, Malaysia; UTM-IRDA Digital Media Centre, Universiti Teknologi Malaysia, Johor Darul Takzim, Malaysia; UTM-IRDA Digital Media Centre, Universiti Teknologi Malaysia, Johor Darul Takzim, Malaysia","2015 4th International Conference on Interactive Digital Media (ICIDM)","21 Jul 2016","2015","","","1","6","Heart Care Augmented Reality Mobile Simulation (heARt) is an edutainment mobile based application that will helps in gaining such awareness of maintaining a healthy heart among the society. This application are augmented reality application that will combined both reality world and virtual reality world in order to give the users an interactive content of information. This application are developed to replace a traditional pamphlets or brochures that have no interactive content within it. HeARt, allows users to interact with the information that presented virtually on their phone screen. This kind of features are believed to be a lot more interesting in contrast with traditional brochures and pamphlets.","","978-1-5090-1669-3","10.1109/IDM.2015.7516351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516351","Medical;Augmented Reality;heARt","Augmented reality;Surgery;Heart;Biomedical imaging;Mobile communication;Operating systems","augmented reality;cardiology;digital simulation;graphical user interfaces;human computer interaction;medical computing;mobile computing","heart care augmented reality mobile simulation;edutainment mobile based application;healthy heart maintenance awareness;virtual reality world;interactive information content;phone screen;HeARt","","","","14","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"Augmented and virtual reality approaches to help with peripheral vision loss","O. Younis; W. Al-Nuaimy; M. A. Al-Taee; A. Al-Ataby","Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, UK; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, UK; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, UK; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, UK","2017 14th International Multi-Conference on Systems, Signals & Devices (SSD)","7 Dec 2017","2017","","","303","307","Peripheral vision loss (also called tunnel vision) is one of the main visual field disorders that can be very frustrating, and affect confidence and main activities of the patient. In this paper, two promising solutions for the peripheral vision loss are presented and discussed. The first one uses optical see-through glasses that are augmented by computer-generated images to notify the user about any moving parts the peripheral vision area. The second solution is to create a complete artificial reality scene and display it in the healthy area of the eye. In this case, the lost part of the vision is provided by: (i) augmenting the captured scenes (via built-in cameras) and (ii) generating an artificial image for the peripheral vision. For both scenarios, a unit of ubiquitous computing is proposed to process and present the captured images in a way tailored to individual needs of the patients. Technical requirements and psychological aspects of the proposed solutions are also presented and discussed in this paper.","2474-0446","978-1-5386-3175-1","10.1109/SSD.2017.8166993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8166993","Augmented reality;low vision;peripheral vision loss;vision rehabilitation;vision model;visual field","Visualization;Glass;Cameras;Streaming media;Augmented reality;Organic light emitting diodes","augmented reality;psychology;ubiquitous computing;vision defects","complete artificial reality scene;augmented reality approaches;virtual reality approaches;peripheral vision loss;tunnel vision;visual field disorders;optical see-through glasses;computer-generated images;ubiquitous computing","","5","","22","IEEE","7 Dec 2017","","","IEEE","IEEE Conferences"
"Walk-Centric User Interfaces","W. S. Lages","Center for Human-Computer Interaction, USA Universidade Federal de Minas Gerais, Brazil","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","825","826","Walking is bound to become a common activity in wearable augmented reality. Compared to walking in virtual reality, walking in augmented reality is very simple and uncomplicated. The ability to use AR in different places and even while walking is likely to deeply impact the way users will experience this technology. The research on walk-centric interfaces has the goal to explore this design space, and bring about a better understanding of how walking affects the design of augmented reality applications. This paper outlines the design space, preliminary, and future work on this topic.","","978-1-5386-3365-6","10.1109/VR.2018.8446426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446426","Augmented reality;interaction;walking.: H5.1 [Information interfaces and presentation]: Multimedia Information Systems. - Artificial;augmented;and virtual realities. H.5.2: User Interfaces","Legged locomotion;Task analysis;Augmented reality;Visualization;User interfaces;Mobile handsets","augmented reality;user interfaces;virtual reality","walk-centric user interfaces;wearable augmented reality;virtual reality;design space;augmented reality applications","","3","","5","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Preliminary Evaluation on User Acceptance of the Augmented Reality Use for Education","D. D. Sumadio; D. R. A. Rambli","Computer and Information System Department, Universiti Teknologi Petronas, Bandar Seri Iskandar, Bandar Seri Iskandar, Perak, Malaysia; Computer and Information System Department, Universiti Teknologi Petronas, Bandar Seri Iskandar, Bandar Seri Iskandar, Perak, Malaysia","2010 Second International Conference on Computer Engineering and Applications","12 Apr 2010","2010","2","","461","465","Augmented reality is a technology that enables user to interact with 3D virtual object and real world in real time application. The use of Augmented Reality (AR) in education shows a potential to enhance traditional learning method. The purpose of this study is to observe the familiarity of AR application especially its implementation in learning environment, and to determine the usefulness of AR application in education. The study was conducted during Malaysia Technology Expo 2009 in small scale participants consists of students, teachers, and industrial people. The result showed that most of the participants never been experienced with AR application before, but the idea to implement AR for education are well accepted with a very positive feedback. Based on the findings, some issues and user expectation for further development of AR application in learning environment are being discussed.","","978-1-4244-6080-9","10.1109/ICCEA.2010.239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5445691","Augmented Reality in Education;Usability;User acceptance","Augmented reality;Usability;Prototypes;Educational technology;Educational institutions;Learning systems;Physics;Computer applications;Application software;Computer science education","augmented reality;computer aided instruction;virtual reality","preliminary evaluation;user acceptance;augmented reality;education;3D virtual object;user interaction","","52","","18","IEEE","12 Apr 2010","","","IEEE","IEEE Conferences"
"Markerless Augmented Reality based application for E-Commerce to Visualise 3D Content","Y. Desai; N. Shah; V. Shah; P. Bhavathankar; K. Katchi","Department Of Information Technology, Sardar Patel Institute Of Technology, Mumbai, Maharashtra; Department Of Information Technology, Sardar Patel Institute Of Technology, Mumbai, Maharashtra; Department Of Information Technology, Sardar Patel Institute Of Technology, Mumbai, Maharashtra; Department Of Information Technology, Sardar Patel Institute Of Technology, Mumbai, Maharashtra; Department of Applied Sciences and Humanities, Sardar Patel Institute of Technology, Mumbai, Maharashtra","2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Oct 2021","2021","","","756","760","Augmented reality has three principal features: combining the real world environment with the virtual world, real-time interaction for users, and accurate representation of 3D objects. Augmented Reality in E-commerce allows customers to view products or experience services in their physical space before purchasing the required items. Current online shopping services only allow customers to see 2D images of the products they are buying. This type of experience is not personalized and sometimes leads to bad shopping choices choices; the customers find it difficult to shop only with a static image view available. Customers cannot accurately predict whether the product they purchase will fit their home environment. This results in a lot of people returning or exchanging the things their purchases. AR resolves these issues. Thus, a method has been proposed for adding a virtual object in the real world by just using a real-time camera. The main aim of this paper is to provide user visualization of high resolution E-commerce products in a real environment.","","978-1-6654-3877-3","10.1109/ICIRCA51532.2021.9545009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545009","Augmented Reality;E-commerce;virtual","Visualization;Three-dimensional displays;Image resolution;Cameras;Real-time systems;Electronic commerce;Augmented reality","augmented reality;data visualisation;electronic commerce;Internet;retail data processing;virtual reality","world environment;virtual world;real-time interaction;experience services;physical space;required items;current online shopping services;bad shopping choices choices;static image view;home environment;things their purchases;virtual object;high resolution E-commerce products;markerless augmented Reality based application;visualise 3D;principal features","","4","","13","IEEE","1 Oct 2021","","","IEEE","IEEE Conferences"
"Drunken Dragon Cyber Dance: Application of Augmented Reality Technology in Drunken Dragon Cultural Heritage Education","S. Xu; P. -W. Hsiao; C. Li; J. Zhang","School of Design and Art, Beijing Institute of Technology, Zhuhai, China; Department of Visual Arts, Macao Polytechnic University, Macau, China; School of Design and Art, Beijing Institute of Technology, Zhuhai, China; School of Design and Art, Beijing Institute of Technology, Zhuhai, China","2022 2nd International Conference on Social Sciences and Intelligence Management (SSIM)","23 Feb 2023","2022","","","36","40","The Drunken Dragon Festival is a traditional folk sacrificial activity that originated in Xiangshan, Guangdong Province, China. After foreign migrant residents moved to Macao, they brought customs such as the drunken dragon dance in the Drunken Dragon Festival into Macao. Under the influence of subsequent foreign culture and urbanization development, the traditional culture gradually became silent. This research plans to use augmented reality technology to protect the drunken dragon dance and build it into an android app with interaction design enhancement. Then, children can interactively understand the Drunken Dragon Festival anytime, anywhere. The research design is divided into three major parts: field investigation, 3d modeling, and AR interaction design. In the beginning, we obtained the basic gestures of drunken dragon dance from professional performers through field investigation. They were then transferred into an action sequence and 3D model. Finally, user interaction design and augmented reality were used to generate an android application. The generated AR application is used for children’s cultural heritage education.","","978-1-6654-9830-2","10.1109/SSIM55504.2022.10047939","Beijing Institute of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10047939","Drunken Dragon Festival;culture heritage education;3D modeling;augmented reality","Solid modeling;Three-dimensional displays;Social sciences;Cultural differences;Augmented reality","Android (operating system);augmented reality;history;human computer interaction;mobile computing;virtual reality","augmented reality technology;children;Drunken Dragon cultural heritage education;Drunken Dragon cyber dance;drunken dragon dance;Drunken Dragon Festival;subsequent foreign culture;traditional folk sacrificial activity","","","","14","IEEE","23 Feb 2023","","","IEEE","IEEE Conferences"
"Memory Task Performance Across Augmented and Virtual Reality","P. Willemsen; W. Jaros; C. McGregor; E. Downs; M. Berndt; A. Passofaro","Department of Computer Science, University of Minnesota, Duluth; Department of Computer Science, University of Minnesota, Duluth; Department of Computer Science, University of Minnesota, Duluth; Department of Communication, University of Minnesota, Duluth; Department of Communication, University of Minnesota, Duluth; Department of Communication, University of Minnesota, Duluth","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","723","724","As commodity virtual reality and augmented reality hardware becomes more accessible, the opportunity to use these systems for learning and training will increase. This study provides an exploratory look at performance differences for a simple memory matching task across four different technologies that could easily be used for learning and training. We compare time and number of attempts to successfully complete a memory matching game across virtual reality, augmented reality, a large touchscreen table-top display and a real environment. The results indicate that participants took more time to complete the task in both the augmented reality and real conditions. Augmented reality and real environments were statistically different than the fastest two conditions, which occurred in the virtual reality and table-top touch display conditions.","","978-1-5386-3365-6","10.1109/VR.2018.8446457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446457","Human-centered computing [Human computer interaction (HCI)]: Empirical studies in HCI- [Applied computing]: Education-Interactive learning environments","Task analysis;Touch sensitive screens;Augmented reality;Face;Training;Human computer interaction","augmented reality","memory task performance;augmented reality;virtual reality;learning;memory matching task;simple memory matching game;large touchscreen table-top display","","2","","5","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"A Mixed Presence Collaborative Mixed Reality System","M. Norman; G. Lee; R. T. Smith; M. Billinqhurs",University of South Australia; University of South Australia; University of South Australia; University of South Australia,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1106","1107","Research has shown that Mixed Presence Groupware (MPG) systems are a valuable collaboration tool. However research into MPG systems is limited to a handful of tabletop and Virtual Reality (VR) systems with no exploration of Head-Mounted Display (HMD) based Augmented Reality (AR) solutions. We present a new system with two local users and one remote user using HMD based AR interfaces. Our system provides tools allowing users to layout a room with the help of a remote user. The remote user has access to a marker and pointer tools to assist in directing the local users. Feedback collected from several groups of users showed that our system is easy to learn but could have increased accuracy and consistency.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797966","Augmented Reality;remote collaboration;mixed presence;H.5.3 [Information Interfaces and Presentation]: Group and Organization Interfaces;Collaborative computing;H.l.2 [Models and Principles]: User/Machine Systems;Human Factors","Collaboration;Resists;Prototypes;Tools;Augmented reality;Webcams","augmented reality;groupware;helmet mounted displays","HMD based AR interfaces;pointer tools;mixed presence collaborative mixed reality system;MPG systems;augmented reality solutions;collaboration tool;virtual reality systems;head-mounted display;mixed presence groupware systems","","4","","7","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Poster: A comparative study of metaphors for investigating augmented reality artifacts","K. Zeitz; R. Zeitz; Congwu Tao; N. Polys","Advanced Research Computing and Computer Science, Virginia Polytechnic Institute and State University; Advanced Research Computing and Computer Science, Virginia Polytechnic Institute and State University; Advanced Research Computing and Computer Science, Virginia Polytechnic Institute and State University; Advanced Research Computing and Computer Science, Virginia Polytechnic Institute and State University","2014 IEEE Symposium on 3D User Interfaces (3DUI)","17 Apr 2014","2014","","","179","180","Augmented Reality applications allow users to view real-world elements augmented by virtual content. Providing appropriate manipulation techniques for virtual objects has the potential to enhance user performance, decrease task completion time, and elicit a more positive user experience. With a goal of establishing guidelines to inform the selection of manipulation metaphors for the development of AR interfaces, we compared physical and touch manipulation metaphors for zoom and rotation techniques. Qualitative and quantitative data on user preferences and performance were gathered from a within-subjects user study that utilized frame markers for registering and rendering 3D artifacts. Results indicated that the non-mixed metaphor interfaces performed the best with regard to task completion time, accuracy, and user preference in terms of intuitiveness and ease of use.","","978-1-4799-3624-3","10.1109/3DUI.2014.6798879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6798879","","Three-dimensional displays;Accuracy;Augmented reality;Cultural differences;Electronic mail;User interfaces;Solid modeling","augmented reality;graphical user interfaces;human computer interaction;rendering (computer graphics)","augmented reality artifacts;real-world element augmentation;virtual content;manipulation techniques;virtual objects;user performance enhancement;task completion time reduction;user experience;manipulation metaphor selection;AR interfaces;physical manipulation metaphors;touch manipulation metaphors;zoom techniques;rotation techniques;qualitative data;quantitative data;user preferences;user performance;3D artifact rendering;3D artifact registration;nonmixed metaphor interfaces;intuitiveness factor;ease-of-use factor","","","","6","IEEE","17 Apr 2014","","","IEEE","IEEE Conferences"
"A note on hybrid control of robotic spatial augmented reality","J. -H. Lee; J. Kim; H. Kim","Robot & Cognitive System Research Department, Electronics and Telecommunications Research Institute, Daejeon, South Korea; School of Computer Science, Kookmin University, Seoul, South Korea; Robot & Cognitive System Research Department, Electronics and Telecommunications Research Institute, Daejeon, South Korea","2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","6 Feb 2012","2011","","","621","626","A robotic spatial augmented reality (RSAR) system combines robotics with spatial augmented reality (SAR) where cameras are used to recognize real objects, and projectors augment information and user interface directly on the surface of the real objects, rather than relying on mobile or wearable display devices. Hence, the control of a RSAR system requires handling of different types of control schemes at once such as classical inverse kinematics of simply linked bodies, inverse projections to find appropriate internal/external parameters of a projector, and geometric manipulation of a projection source image to increase the flexibility in control. In this paper, we outline a hybrid approach to control relevant control components in a coordinated manner, specially focused on application in a prototype RSAR system developed in ETRI.","","978-1-4577-0723-0","10.1109/URAI.2011.6145895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6145895","inverse projection;inverse kinematics;image manipulation;spatial augmented reality;robotic computer","Kinematics;Robot kinematics;Prototypes;Redundancy;Augmented reality;Mobile communication","augmented reality;computational geometry;control engineering computing;image sensors;object recognition;robot kinematics;user interfaces","hybrid control;robotic spatial augmented reality system;RSAR system;object recognition;projectors augment information;user interface;mobile devices;wearable display devices;inverse kinematics;inverse projections;geometric manipulation;projection source image;ETRI","","2","","20","IEEE","6 Feb 2012","","","IEEE","IEEE Conferences"
"Plants and zombies: Two use cases for on-location panorama viewing in handheld mobile AR","I. Kulka; B. MacIntyre; M. Gandy; J. D. Bolter","Augmented Environments Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; Interactive Media Technology Center, Georgia Institute of Technology, Atlanta, GA, USA; Digital Media Program, Georgia Institute of Technology, Atlanta, GA, USA","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","103","104","Panoramas, as a medium, have traditionally provided viewers with an encompassing experience of distant locations. In recent years, this experience has been augmented by combining handheld orientation sensors with digital panoramas to create mixed reality experiences that transform mobile devices into windows to the remote. Less explored, have been the mixed reality opportunities afforded through the viewing of mobile panoramas non-remotely, at or near their real world epicenters. This paper presents two handheld AR web applications, running on publicly available hardware and software, that utilize panoramas to facilitate both remote and on-location AR experiences. It explores how the experience and the utility of a panorama differ depending on the location in which it is viewed.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6484002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6484002","augmented reality;panorama;transmedia","Augmented reality;Legged locomotion;TV;Mobile communication;Media;Transforms","augmented reality;image sensors;Internet;mobile computing;mobile handsets","on-location panorama viewing;handheld mobile AR;handheld orientation sensors;digital panoramas;mixed reality experiences;mobile devices;windows;real world epicenters;handheld AR Web applications;publicly available hardware;publicly available software;plants;zombies;remote AR experiences","","1","","9","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Towards a smart classroom: Development of an augmented reality application for education and tele-education","P. Bernal Onate; R. Lara-Cueva; J. Rivadeneira","Electrical and Electronic Department, Universidad de las Fuerzas Armadas ESPE, Quito-Ecuador, 171- 5-231B, Ecuador; Grupo de Investigación en Sistemas Inteligentes (WiCOM) and Centro de Investigaciones de Redes Ad Hoc, Departmento de Eléctrica y Electrónica, Universidad de las Fuerzas Armadas ESPE, Sangolquí-171-5-231B, Ecuador; Electrical and Electronic Department, Universidad de las Fuerzas Armadas ESPE, Quito-Ecuador, 171- 5-231B, Ecuador","2015 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON)","15 Feb 2016","2015","","","395","400","Augmented Reality complements the perception and interaction with the real world and allows the end-user to be in an augmented real environment with additional information generated by the computer. This work is divided into two main parts: First, we studied the digital image processing used in the detection and recognition markers, the methods for creating bookmarks with high contrast by generating useful matrices, in order to calculate the position of these markers in the scene, and the creation of 3D models that will be later rendered. Second, we developed an augmented reality application for education and tele-education with the aforementioned tools. We present an introduction for existing libraries in different programming languages, which help us to develop this application for Science subject, with an aggregate value of user interactivity by the use of the same markers. The application showed an interesting form of education in children of 6 years, and a new opportunity towards a smart classroom.","","978-1-4673-8756-9","10.1109/Chilecon.2015.7400407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7400407","Augmented Reality;markers;image processing;tele-education","Three-dimensional displays;Solid modeling;Monitoring;Linux;Augmented reality;Education;MATLAB","augmented reality;computer aided instruction;distance learning;human computer interaction;image recognition","smart classroom;augmented reality application;tele-education;augmented real environment;digital image processing;detection markers;recognition markers;bookmarks;3D models;rendering;libraries;programming languages;science subject;user interactivity","","1","","","IEEE","15 Feb 2016","","","IEEE","IEEE Conferences"
"Campus Guide Using Augmented Reality Techniques","A. A. Almjawel; N. A. Alerbeed; A. S. Alogily; G. M. Alotaibi","Shaqra University College of Computer and Information Technology, Shaqra, Kingdom of Saudi Arabia; Shaqra University College of Computer and Information Technology, Shaqra, Kingdom of Saudi Arabia; Shaqra University College of Computer and Information Technology, Shaqra, Kingdom of Saudi Arabia; Shaqra University College of Computer and Information Technology, Shaqra, Kingdom of Saudi Arabia","2020 3rd International Conference on Computer Applications & Information Security (ICCAIS)","20 May 2020","2020","","","1","4","Nowadays, many students and staff struggle to find specific information about classes or teachers whether in their colleges or any other institution on campus. Therefore, in this research, a mobile application (College Guide) was built to address this need. College Guide was developed as a guide for members and visitors to the College of Computer and Information Technology (CC&IT). The underlying technology upon which the application was based is augmented reality, which was used to enhance the quality and ease of use of the application, as users could get the information easily and contact others effectively. Five steps were carried out to develop the application: determine the problem and write the objectives and solution, analyze the system, gather requirements, design the interfaces, and implement the app. The results of using the system indicated that most users found it easy to use as the complete process included just three steps: open app, scan QR code, and show information. In addition, users found the design of the interfaces to be user-friendly, and no one suffered from using the application. Many users found it fun to use the augmented reality technique. Communication with staff was much faster than in the traditional way. In future work, we intend to extend the system to include all faculties and add more features, like 3D objects and live chat with the administration. We also want to involve the IT department in developing the application so that any faults can be reported and data updated directly.","","978-1-7281-4213-5","10.1109/ICCAIS48893.2020.9096723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096723","augmented reality;virtual reality;QR code","Augmented reality;Information technology;Global Positioning System;Cameras;Two dimensional displays;Tools","augmented reality;educational administrative data processing;educational institutions;mobile computing","mobile application;College Guide;campus guide;augmented reality techniques","","","","11","IEEE","20 May 2020","","","IEEE","IEEE Conferences"
"Integration of Augmented Reality and Assistive Devices for Post-Stroke Hand Opening Rehabilitation","Xun Luo; T. Kline; H. C. Fischer; K. A. Stubblefield; R. V. Kenyon; D. G. Kamper","Rehabilitation Institute of Chicago and Northwestern University, Chicago, IL, USA; Neuromechanics Laboratory, Department of Biomedical Engineering, Marquette University, Milwaukee, WI, USA; Rehabilitation Institute of Chicago and Northwestern University, Chicago, IL, USA; Rehabilitation Institute of Chicago and Northwestern University, Chicago, IL, USA; Computer Science Department, University of Illinois, Chicago, Chicago, IL, USA; Rehabilitation Institute of Chicago and Northwestern University, Chicago, IL, USA","2005 IEEE Engineering in Medicine and Biology 27th Annual Conference","10 Apr 2006","2005","","","6855","6858","Impairment of hand function is prevalent among stroke survivors, motivating the search for effective rehabilitation therapy. Recent studies have suggested that for upper extremity functional recovery, repetitive training with virtual reality is helpful. Repetitive training can be facilitated with assistance from mechanical devices. Thus, we have developed a training environment that integrates augmented reality (AR) with assistive devices for post-stroke hand rehabilitation. The AR element of our environment utilizes head mounted display and virtual objects for reach-and-grasp task training. The assistive device consists of either a body-powered orthosis (BPO) or a pneumatic-powered device (PPD), both of which are incorporated into gloves. This environment can be easily set up and calibrated, is customizable for individual users, and requires active user participation. Additionally, it can be used with both real and virtual objects, as desired. We are currently conducting pilot case studies to assess ease of use and efficacy. At present, one stroke survivor from each of the three training conditions, AR-with-BPO, AR-with-PPD and AR-only (acting as the control), has completed the 6-week training paradigm. Preliminary findings suggest user acceptance of the technology and some potential for beneficial effects","1558-4615","0-7803-8741-4","10.1109/IEMBS.2005.1616080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1616080","Stroke;Hand Rehabilitation;Augmented Reality;Assistive Device;Feedback Control","Augmented reality;Fingers;Virtual reality;Layout;Neodymium;USA Councils;Haptic interfaces;Displays;Biomedical engineering;Electromyography","augmented reality;biomechanics;medical control systems;orthotics;patient rehabilitation;pneumatic control equipment","augmented reality;assistive devices;post-stroke hand opening rehabilitation;impaired hand function;upper extremity functional recovery;repetitive training;post-stroke hand rehabilitation;head mounted display;virtual objects;reach-and-grasp task training;body-powered orthosis;pneumatic-powered device","","19","","16","IEEE","10 Apr 2006","","","IEEE","IEEE Conferences"
"The Acceptance of Learning Augmented Reality Environments: A Case Study","M. B. Ibáñez; Á. Di Serio; D. Villarán; C. Delgado-Kloos","Departamento de Ingenier??a Telem??tica, Universidad Carlos III de Madrid, Madrid, Spain; Dept. de Ing. Telematica, Universidad Carlos III de Madrid, Madrid, Madrid, ES; Departamento de Ingenier??a Telem??tica, Universidad Carlos III de Madrid, Madrid, Spain; Departamento de Ingenier??a Telem??tica, Universidad Carlos III de Madrid, Madrid, Spain","2016 IEEE 16th International Conference on Advanced Learning Technologies (ICALT)","1 Dec 2016","2016","","","307","311","The aim of this study was to investigate the attitude of learners toward an augmented reality learning activity designed to help engineering students to solve an electromagnetic problem. The sample was 122 students. Students were asked to complete a survey questionnaire based on the Technology Acceptance Model (TAM) enhanced with perceived enjoyment items. The results of the evaluation show that intention of use the system is dependent of perceived enjoyment but not from perceived usefulness of the learning tool.","2161-377X","978-1-4673-9041-5","10.1109/ICALT.2016.124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7756984","Augmented reality;assessment;interactive learning environments;technology acceptance model","Conferences;Augmented reality","augmented reality;computer aided instruction;electromagnetism;engineering computing;engineering education;human factors","learning tool;perceived enjoyment;TAM;technology acceptance model;electromagnetic problem;engineering students;augmented reality learning activity;learner attitude;learning augmented reality environment","","18","","21","IEEE","1 Dec 2016","","","IEEE","IEEE Conferences"
"Comparing “pick and place” task in spatial Augmented Reality versus non-immersive Virtual Reality for rehabilitation setting","M. Khademi; H. M. Hondori; L. Dodakian; S. Cramer; C. V. Lopes","Donald Bren School of Information and Computer Sciences, University of California, Irvine, CA, USA; School of Medicine and Donald Bren School of Information and Computer Sciences, University of California, Irvine, CA, USA; School of Medicine, University of California, Irvine, CA, USA; School of Medicine, University of California, Irvine, CA, USA; Donald Bren School of Information and Computer Sciences, University of California, Irvine, CA, USA","2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","26 Sep 2013","2013","","","4613","4616","Introducing computer games to the rehabilitation market led to development of numerous Virtual Reality (VR) training applications. Although VR has provided tremendous benefit to the patients and caregivers, it has inherent limitations, some of which might be solved by replacing it with Augmented Reality (AR). The task of pick-and-place, which is part of many activities of daily living (ADL's), is one of the major affected functions stroke patients mainly expect to recover. We developed an exercise consisting of moving an object between various points, following a flash light that indicates the next target. The results show superior performance of subjects in spatial AR versus non-immersive VR setting. This could be due to the extraneous hand-eye coordination which exists in VR whereas it is eliminated in spatial AR.","1558-4615","978-1-4577-0216-7","10.1109/EMBC.2013.6610575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6610575","","Augmented reality;Medical treatment;Monitoring;Training;Educational institutions;Visualization","augmented reality;computer games;patient rehabilitation","spatial augmented reality;nonimmersive virtual reality;virtual reality training applications;activities of daily living;stroke patients;extraneous hand-eye coordination;VR;AR;computer games;pick and place task","Activities of Daily Living;Adult;Algorithms;Exercise;Female;Hand;Humans;Male;Middle Aged;Movement;Ocular Physiological Phenomena;Stroke Rehabilitation;User-Computer Interface;Video Games;Virtual Reality Exposure Therapy","18","","24","IEEE","26 Sep 2013","","","IEEE","IEEE Conferences"
"The impact of augmented reality software with inquiry-based learning on students' learning of kinematics graph","T. F. L. Jerry; C. C. E. Aaron","Science Department, Woodgrove Secondary School, Singapore; Science Department, Woodgrove Secondary School, Singapore","2010 2nd International Conference on Education Technology and Computer","29 Jul 2010","2010","2","","V2-1","V2-5","In recent decades, many researches have been done on impact of technology on teaching and learning. However, many such studies were done back in 1990s and to-date technology has since improved by leaps and bounds. Hence, there is a need to look into how schools can tap into the current innovative technology and integrate it into the schools' teaching and learning (T&L). This study uses Augmented Reality (AR) software in the T&L of Science. AR has been widely published in Hollywood movie and often used in the making of special effects in movie. This study uses affordable and powerful AR software that is locally developed and applied on a Physics topic known as Kinematics graph analysis a topic that is difficult for our students to grasp when teaching it. There is also a call for a deeper research work that is not just based on impact of technology, but how to use pedagogy in information communication technology (ICT) based lesson. This study is both qualitative and quantitative that investigates how the impact of technology on the T&L of a Physics topic designed with a sound pedagogy, in form of Inquiry based Learning (IBL). The focus of this study is on the effect of such integration on 40 secondary 3 students' (15 yrs old) learning attitude and academic achievement, in comparison with 40 controlled students.","2155-1812","978-1-4244-6370-1","10.1109/ICETC.2010.5529447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5529447","component;augmented reality;kinematics;inquiry based learning;innovative pedagogy;information communication technology","Augmented reality;Kinematics;Educational technology;Computer aided instruction;Educational institutions;Computer science education;Educational programs;Appropriate technology;Motion pictures;Physics","augmented reality;computer aided instruction;education;graph theory","augmented reality software;inquiry based learning;kinematics graph;innovative technology;augmented reality;information communication technology;ICT;IBL","","17","","16","IEEE","29 Jul 2010","","","IEEE","IEEE Conferences"
"Educ-AR: A tool for assist the creation of augmented reality content for education","L. Farias; R. Dantas; A. Burlamaqui","Departamento de Computação e Automação, Universidade Federal do Rio Grande do Norte, Natal, Brasil; Departamento de Computação e Automação, Universidade Federal do Rio Grande do Norte, Natal, Brasil; Dept. de Comput. e Automacao, Univ. Fed. do Rio Grande do Norte, Natal, Brazil","2011 IEEE International Conference on Virtual Environments, Human-Computer Interfaces and Measurement Systems Proceedings","20 Oct 2011","2011","","","1","5","The article presents a software tool that provides an easy way to creates augmented reality presentations. This tool allows the user to authoring his own presentation without a help of a programmer. The tool is supported by a web portal that provides the account creation and a database to storage the presentations created by the users.","1944-9410","978-1-61284-890-7","10.1109/VECIMS.2011.6053850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6053850","augmented reality;easy-to-use system","Three dimensional displays;Augmented reality;Solid modeling;Java;Unified modeling language;Computer science education;Computational modeling","augmented reality;computer aided instruction;human computer interaction;portals;software tools","Educ-AR;augmented reality content;education;software tool;augmented reality presentations;Web portal;account creation;presentation storage","","16","","13","IEEE","20 Oct 2011","","","IEEE","IEEE Conferences"
"Augmented Reality Experiences in Therapeutic Pedagogy: A Study with Special Needs Students","S. C. Cifuentes; S. G. García; M. P. Andrés-Sebastiá; J. D. Camba; M. Contero","Departamento de Métodos de Investigación y, Universidad de Valencia, Valencia, Spain; Gerald D. Hines College of Architecture and Design, University of Houston, Houston, TX, USA; Departamento de Didáctica General, Universidad Católica de Valencia, Valencia, Spain; Departamento de Didáctica General, Universidad Católica de Valencia, Valencia, Spain; I3B, Universitat Politècnica de València, Valencia, Spain","2016 IEEE 16th International Conference on Advanced Learning Technologies (ICALT)","1 Dec 2016","2016","","","431","435","Information and Communication Technologies (ICTs) have played a major role in shaping our society, affecting nearly all aspects of our daily lives. In educational contexts, the ongoing technological revolution we are experiencing naturally calls for a transformation of traditional teaching and learning processes. The integration and efficient use of emergent technologies have become fundamental challenges in the educational domain. In this paper, we evaluate the use of Augmented Reality (AR) technology in a classroom with middle school special-needs students. Our primary goal is to quantitatively assess whether AR helps special-needs students to improve their results, performance, motivation, and other aspects of the learning process. Information was collected via pre and post questionnaires distributed to participants before and after an intervention. Our results serve as basis for improving future educational AR-related projects and materials.","2161-377X","978-1-4673-9041-5","10.1109/ICALT.2016.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7757016","Augmented Reality;Special Education;Learning and Performance;Information and Communication Technologies","Augmented reality;Education;Conferences;Context;Computers;Software;Three-dimensional displays","augmented reality;computer aided instruction;handicapped aids;teaching","augmented reality experiences;therapeutic pedagogy;special needs students;information and communication technologies;ICTs;educational contexts;technological revolution;teaching process;learning process;educational domain;augmented reality technology;AR technology","","9","","32","IEEE","1 Dec 2016","","","IEEE","IEEE Conferences"
"Augmented reality information registration for head-up display","C. Yoon; K. -H. Kim","Smart Driving Assistance Research Section, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; Smart Driving Assistance Research Section, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea","2015 International Conference on Information and Communication Technology Convergence (ICTC)","17 Dec 2015","2015","","","1135","1137","In this paper, we present an information registration method for an Augmented Reality Head-Up Display (AR-HUD) system. The AR-HUD system superimposes driving assistance warnings and instructions that correctly match the real world according to the driver's view. AR information registration is a necessary procedure prior to the presentation of these warnings and instructions. This need is important in the field of safe driving, where the driver should keep his attention to specific situations and decide the upcoming maneuvers. This paper presents an automated AR information registration method that can establish correspondences between cameras and HUD on the assumption that the view of the driver are fixed toward the front. We also verify some of the use cases in the implemented AR-HUD system based on a test-bed vehicle.","","978-1-4673-7116-2","10.1109/ICTC.2015.7354757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7354757","Augmented reality;head-up display;registration;driving assistance;projective transformation","Cameras;Vehicles;Augmented reality;Telecommunications;Safety;Least squares methods;Image resolution","augmented reality;head-up displays;image registration","augmented reality information registration method;augmented reality head-up display system;AR-HUD system;driving assistance warning;safe driving;test-bed vehicle","","5","1","8","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Marker-based augmented reality application for mobile learning in an urban park: Steps to make it real under the EduPARK project","L. Pombo; M. M. Marques","Research Centre Didactics and Technology in the Education of Trainers (CIDTFF), University of Aveiro, Aveiro, Portugal; Research Centre Didactics and Technology in the Education of Trainers (CIDTFF), University of Aveiro, Aveiro, Portugal","2017 International Symposium on Computers in Education (SIIE)","18 Jan 2018","2017","","","1","5","The gap between the use of mobile devices inside and outside school can lead to students' disengagement with learning activities in formal education. To fill this gap, educators can take advantage of mobile devices' dissemination to give students access to educational Augmented reality (AR) systems. However, this type of exploration is relatively new, and researchers are still studying AR's advantages and challenges in education. In that line, the EduPARK project is developing an interactive AR mobile application to support geocaching activities in outdoor environments, thus creating situated learning opportunities. It is to be explored by students and teachers from basic to higher education, but also by the public. The project follows a design-based research methodology, with several cycles of AR application development, user testing and evaluation. This manuscript is a work-in-progress report of the EduPARK project's options regarding the AR content and triggers, and points out some future directions. The EduPARK's option was to use image-based AR, with marker-based tracking, to display mainly botanical content. In a first implementation experience, 74 pupils (aged 9-10 and 13-14) from two schools tested a beta version of the application and AR markers in an urban park. Some technical issues, related to the markers' recognition, were observed and registered by both pupils and monitors, leading to the revision of the markers' purposes, structure, and content. Examples of refined AR markers and content are presented and discussed in this manuscript. Future work will include developing markerless tracking for this application in the selected urban park. Additionally, a proposal for the installation of the refined markers will be presented to the Park's management entity and the fully developed application will be freely offered to the public, promoting the autonomous exploration of this resource. This work is useful for teachers and both educational technology developers and researchers, as an example of how to successfully develop image-based AR for outdoor settings.","","978-1-5386-0648-3","10.1109/SIIE.2017.8259669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259669","augmented reality;marker-based;mobile learning;science education;outdoor learning environments","Education;Games;Mobile communication;Mobile handsets;Usability;Augmented reality;Aging","augmented reality;computer aided instruction;mobile learning","refined AR markers;selected urban park;Park's management entity;autonomous exploration;educational technology developers;augmented reality application;mobile learning;mobile devices;formal education;educational Augmented reality systems;interactive AR mobile application;geocaching activities;higher education;AR application development;user testing;botanical content;EduPARK project","","5","","26","IEEE","18 Jan 2018","","","IEEE","IEEE Conferences"
"Quality of augmented reality experience: A correlation analysis","U. Engelke; H. Nguyen; S. Ketchell","CSIRO Data61, Sandy Bay, Australia; CSIRO Data61, Sandy Bay, Australia; University of Tasmania Churchill Avenue, Sandy Bay, Australia","2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX)","3 Jul 2017","2017","","","1","3","We performed a user study in which we investigated the user experience of HoloBee, a visual analytics system for the exploration of bee drift data. We compared two user interfaces, a head-mounted augmented reality (aR) interface and a desktop interface. We present here a correlation analysis of the user experience ratings that we collected in a questionnaire: intuitive, easy to use, comfortable, natural, and efficient. All criteria are strongly correlated with an interface preference rating. Efficient and comfortable are, respectively, found to be most and least strongly correlated with interface preference. Furthermore, while all rating criteria are highly correlated amongst themselves for the desktop interface, natural and intuitive are only marginally correlated for the AR interface indicating that natural user interfaces are not necessarily intuitive.","2472-7814","978-1-5386-4024-1","10.1109/QoMEX.2017.7965638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965638","Augmented reality;user experience;user study;correlation analysis","Correlation;Visual analytics;Augmented reality;Australia;Electronic mail;Keyboards;Mice","augmented reality;data visualisation;helmet mounted displays;human computer interaction;user interfaces","augmented reality experience;correlation analysis;HoloBee;visual analytics system;bee drift data exploration;user interfaces;head-mounted augmented reality interface;desktop interface;user experience ratings","","4","","5","IEEE","3 Jul 2017","","","IEEE","IEEE Conferences"
"Augmented Reality App to improve quality of life of people with cognitive and sensory disabilities","M. Rossi; G. D'Avenio; S. Morelli; M. Grigioni","Department of Computer, Control and Management Engineering, Sapienza University of Rome, Rome, Italy; National Center for Technological Innovation in Public Health, Istituto Superiore di Sanità, Rome, Italy; National Center for Technological Innovation in Public Health, Istituto Superiore di Sanità, Rome, Italy; National Center for Technological Innovation in Public Health, Istituto Superiore di Sanità, Rome, Italy","2020 IEEE International Workshop on Metrology for Industry 4.0 & IoT","10 Jul 2020","2020","","","59","62","In the last decades, number of people affected by cognitive decline is rising significantly. The main cause of this problem is believed to be the overall drift of the average population age. In general, cognitive impairment varies from mild to severe with mild represented as people may begin to notice a slight change in their cognitive functions while still be able to conduct their daily activities without major limitations; on the other hand, severe state of cognitive impairment leads to a progressive loss of comprehensive abilities as well as evaluating situations. These impairments may be represented by losing the ability to talk and write that leads to the inability to conduct an independent lifestyle. The decay of intellectual functions is associated with a progressive increase of sensory impairment (vision and hearing). In this paper we present a tool to help and support people who suffer from both mild age-related cognitive decline and sensory impairment. We developed an augmented reality home-made App designed for smart glasses. This App would be a useful tool to provide more independence to patients during actual daily living activities and it will be able to notify users about a potentially dangerous situations, by providing cues in real time. In this way, elderly people, will be able continue their life at home for a longer time before having the need to move into an assisting living facility.","","978-1-7281-4892-2","10.1109/MetroInd4.0IoT48571.2020.9138204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138204","multiple disability;augmented reality;smart glasses","Sociology;Glass;Auditory system;Real-time systems;Statistics;Older adults;Augmented reality","assisted living;augmented reality;cognition;geriatrics;handicapped aids;hearing;home computing","mild age-related cognitive decline;sensory impairment;daily living activities;elderly people;augmented reality app;cognitive disabilities;sensory disabilities;general impairment varies;cognitive impairment varies;augmented reality home-made app;assisting living facility;quality of life","","3","","28","IEEE","10 Jul 2020","","","IEEE","IEEE Conferences"
"Vision-based user tracking for outdoor augmented reality","E. Bostanci; A. F. Clark; N. Kanwal","VASE Laboratory, Computer Science and Electronic Engineering, University of Essex, Colchester, Essex, UK; VASE Laboratory, Computer Science and Electronic Engineering, University of Essex, Colchester, Essex, UK; VASE Laboratory, Computer Science and Electronic Engineering, University of Essex, Colchester, Essex, UK","2012 IEEE Symposium on Computers and Communications (ISCC)","26 Jul 2012","2012","","","000566","000568","This paper examines the use of vision-based localization techniques for indoor environments in outdoor environments. A new method is presented for robust data association and finding camera trajectory; based on these, a simple augmented reality game is implemented.","1530-1346","978-1-4673-2713-8","10.1109/ISCC.2012.6249356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249356","Augmented Reality;Visual SLAM;Outdoor User Tracking","Cameras;Simultaneous localization and mapping;Games;Augmented reality;Robustness;Feature extraction","augmented reality;cameras;computer vision;sensor fusion;SLAM (robots);user interfaces","vision-based user tracking;outdoor augmented reality;vision-based localization technique;indoor environment;outdoor environment;data association;camera trajectory;augmented reality game;vision-based SLAM;simultaneous localisation and mapping","","3","1","9","IEEE","26 Jul 2012","","","IEEE","IEEE Conferences"
"Self-Position Estimation based on Road Sign using Augmented Reality Technology","R. Aoki; H. Tanaka; K. Izumi; T. Tsujimura","Department of Mechanical Engineering, Saga University Saga, Japan; Department of Mechanical Engineering, Saga University Saga, Japan; Department of Mechanical Engineering, Saga University Saga, Japan; Department of Mechanical Engineering, Saga University Saga, Japan","2018 12th France-Japan and 10th Europe-Asia Congress on Mechatronics","18 Oct 2018","2018","","","39","42","Augmented reality technique is applied to conduct self - position estimation for mobile robots using road signs. Using ARtoolkit, we aimed to acquire 3D coordinates from road signs registered as markers and perform mapping. Result of experiments confirms the proposed system successfully acquires the trajectory of the mobile robot and AR processor identifies location of the robot by registering road signs as AR markers create road maps.","","978-1-5386-2982-6","10.1109/MECATRONICS.2018.8495815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8495815","Augmented Reality;Mobile robot;Navigation","Cameras;Estimation;Mobile robots;Roads;Augmented reality;Robot vision systems;Simultaneous localization and mapping","augmented reality;image registration;mobile robots","road sign;augmented reality technology;augmented reality technique;mobile robot;road maps;self-position estimation;AR markers;AR processor","","3","","6","IEEE","18 Oct 2018","","","IEEE","IEEE Conferences"
"Extended web services for remote collaborative manipulation in distributed augmented reality","S. Benbelkacem; N. Zenati-Henda; H. Belghit; A. Bellarbi; S. Otmane","Centre de Développement des Technologies, Avancées CDTA Algiers, Algeria; Centre de Développement des Technologies, Avancées CDTA Algiers, Algeria; Centre de Développement des Technologies, Avancées CDTA Algiers, Algeria; Centre de Développement des Technologies, Avancées CDTA Algiers, Algeria; University of Evry, Paris, France","2015 3rd International Conference on Control, Engineering & Information Technology (CEIT)","3 Sep 2015","2015","","","1","5","In this paper we present an extended formalism of web services for developing a Remote Collaborative Manipulation system in Augmented Reality Environment. This system is an Internet-based virtual 3D environment that provides users a shared space and a collaborative platform for publishing, simulating and analyzing multidimensional data. In this paper, we have constructed our collaborative system using web services technology. The architecture and the system's working mechanisms based on the extended web services were elaborated. To demonstrate Remote Collaborative Manipulation system, we have examined a case study of automotive design.","","978-1-4799-8212-7","10.1109/CEIT.2015.7233075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7233075","web services;remote collaborative manipulation;augmented reality;automotive design","Three-dimensional displays;Collaboration;Servers;Augmented reality;Distributed databases;Simple object access protocol","augmented reality;data analysis;groupware;Web services","extended Web services;distributed augmented reality;remote collaborative manipulation system;augmented reality environment;Internet-based virtual 3D environment;collaborative platform;multidimensional data publishing;multidimensional data simulation;multidimensional data analysis;Web services technology;automotive design","","2","","6","IEEE","3 Sep 2015","","","IEEE","IEEE Conferences"
"Augmented Reality Registration Method Based on Improved LMeds","X. Su; W. Wang; L. Wei; Z. Zhang","Lanzhou Jiaotong University, Lanzhou, Gansu, CN; Lanzhou Jiaotong University, Lanzhou, Gansu, CN; Sch. of Inf. Sci. & Technol., Lanzhou Bocai Technol. Co. Ltd., Lanzhou, China; Sch. of Inf. Sci. & Technol., Lanzhou Bocai Technol. Co. Ltd., Lanzhou, China","2018 IEEE 16th Intl Conf on Dependable, Autonomic and Secure Computing, 16th Intl Conf on Pervasive Intelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)","28 Oct 2018","2018","","","166","172","In view of the problem of low accuracy and poor stability of 3D space registration in mobile augmented reality, an improved registration method based on LMeds (Least Median Squares) is proposed in this paper. The method first uses the ORB (Oriented FAST and Rotated BRIEF) algorithm to carry out the feature detection, and the FREAK (Fast Retina Key-point) algorithm is employed to describe the features. Then the feature points are screened by the hamming distance. In order to obtain good matching points, the Sampson distance estimation is introduced in the LMeds algorithm. By eliminating the mismatch points in time to reduce the cumulative number of calculation cost functions, it not only maintains the good robustness of the LMeds algorithm, but also effectively reduces the computational complexity of the algorithm. Finally, camera pose estimation is conducted to get the absolute attitude of video image relative to the identified image, so as to enhance the scene. Experimental results show that this method improves the precision of feature matching and the accuracy of 3D registration, and also has good real-time performance and robustness when environment changes.","","978-1-5386-7518-2","10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8511882","Augmented reality;Registration;Least median of squares;Feature match","Feature extraction;Three-dimensional displays;Hamming distance;Augmented reality;Cameras;Retina","augmented reality;cameras;computational complexity;feature extraction;image matching;image registration;least squares approximations;pose estimation","augmented reality registration method;mobile augmented reality;video image altitude;computational complexity;camera pose estimation;fast retina key-point algorithm;oriented FAST and rotated BRIEF algorithm;ORB algorithm;3D space registration stability;matching points;Hamming distance;feature matching;calculation cost functions;mismatch points;LMeds algorithm;Sampson distance estimation;feature points;FREAK algorithm;feature detection;Rotated BRIEF;Least Median Squares","","2","","12","IEEE","28 Oct 2018","","","IEEE","IEEE Conferences"
"Kinect augmented reality gear game design","J. -Y. Chen; C. -H. Liu; C. -H. Hsieh; S. -Y. Huang; W. -K. Wang; B. -H. Nien","Department of Electronic Engineering, Ming Chuan University, Taoyuan, Taiwan; Department of Mechatronic Technology, National Taiwan Normal University, Taipei, Taiwan; Department of Computer and Communication Engineering, Ming Chuan University, Taoyuan, Taiwan; Department of Computer and Information Engineering, Ming Chuan University, Taoyuan, Taiwan; Department of Electronic Engineering, Ming Chuan University, Taoyuan, Taiwan; Department of Electronic Engineering, Ming Chuan University, Taoyuan, Taiwan","2017 International Conference on Applied System Innovation (ICASI)","24 Jul 2017","2017","","","373","375","This paper presents an augmented-reality based interaction gear game which is designed to be used as a learning material of Science and Technology course for elementary school students. With this game, the authors hope to increase concentration, interest, and efficiency of learning in class. Basically, through obtaining the coordinates of human skeleton with Kinect sensor, we are able to identify the user's physical movements and postures and design scenarios in the game; the virtual picture is shown in the image, and therefore, the user can interact with the picture in an audio-visual scenario. This game makes learning through interacting possible. It provides a learning course that educates and entertains. In addition, it helps students to learn the scientific concept of gear during the interaction.","","978-1-5090-4897-7","10.1109/ICASI.2017.7988429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988429","Motion Sensing technology;Augmented Reality;Kinect;Interactive game","Games;Augmented reality;Radiation detectors;Sun;Man-machine systems;Cameras","augmented reality;computer aided instruction;computer games;educational courses;human computer interaction;image sensors;technology","Kinect augmented reality gear game design;augmented-reality based interaction gear game;learning material;science and technology course;elementary school students;human skeleton coordinates;Kinect sensor;user physical movement identification;virtual picture;audio-visual scenario;learning course","","1","","5","IEEE","24 Jul 2017","","","IEEE","IEEE Conferences"
"Towards the Design and Evaluation of Delay-based Modeling of Acoustic Scenes in Mobile Augmented Reality","A. Baldwin; S. Serafin; C. Erkut",Aalborg University Copenhagen; Aalborg University Copenhagen; Aalborg University Copenhagen,"2018 IEEE 4th VR Workshop on Sonic Interactions for Virtual Environments (SIVE)","16 Dec 2018","2018","","","1","5","ScatAR is an augmented reality (AR) audio application, where scattering delay networks (SDNs) efficiently generate and organize a reverberator based on room geometry scanned by an AR device. Here we present a perceptual evaluation of the application in terms of auditory object presence. Specifically, we investigate the personal preferences on the auditory registration of a sounding object (a drone transmitting speech) in a room in anechoic versus artificial reverberation conditions. The results indicate a marginal preference of the reverberation, but much less than what we have anticipated. We discuss possible reasons for this, and set to compare our SDN implementation with a Waveguide Web (WGW) simulation in AR. While the WGWs are computationally more demanding, they have a potential to provide more accurate second-order reflections, and therefore, better registering of audio-visual AR scenes.","","978-1-5386-5713-3","10.1109/SIVE.2018.8577129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8577129","Human-centered computing;Mixed / augmented reality;Auditory feedback","Instruction sets;Drones;Three-dimensional displays;Delay lines;Augmented reality;Scattering;Reverberation","acoustic signal processing;augmented reality;reverberation","drone transmitting speech;Waveguide Web simulation;audio-visual AR scenes;delay-based modeling;mobile augmented reality;scattering delay networks;reverberator;augmented reality device;anechoic versus artificial reverberation;auditory registration;auditory object presence;perceptual evaluation","","1","","9","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Interactive augmented reality art book to promote Malaysia traditional game","S. B. binti Mat Sah; N. Teck Chyan; S. binti Hisham","Department of Media Interactive, Universiti Teknikal Malaysia Melaka, Melaka, Malaysia; Department of Media Interactive, Universiti Teknikal Malaysia Melaka, Melaka, Malaysia; Department of Media Interactive, Universiti Teknikal Malaysia Melaka, Melaka, Malaysia","2014 International Conference on Computer, Communications, and Control Technology (I4CT)","2 Oct 2014","2014","","","203","208","Malaysia is a multicultural country and is known for its tourism industry. The uniqueness of Malaysian traditional games is one of the cultural aspects to promote tourism industry in Malaysia. This paper presents a mobile application that combines the use of printed media and marker-based augmented reality (AR) technology as an effective and engaging platform in promoting Malaysian traditional games. The mobile AR application developed in this study provides interactive features that allow users to interact and manipulate the 3D objects including videos using five assigned virtual buttons. User acceptance test was carried out with 15 users including foreigners to verify the effectiveness of the mobile AR application.","","978-1-4799-4555-9","10.1109/I4CT.2014.6914175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6914175","augmented reality;marker-based;tourism","Three-dimensional displays;Mobile communication;Solid modeling;Art;Videos;Augmented reality;Games","art;augmented reality;computer games;cultural aspects;mobile computing;travel industry","interactive augmented reality art book;Malaysia traditional game;multicultural country;tourism industry;cultural aspects;mobile application;printed media;marker-based augmented reality technology;AR technology;interactive features;3D object interaction;3D object manipulation;virtual buttons;user acceptance test","","1","","9","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"CogAR: an augmented reality App to improve quality of life of the people with cognitive impairment","M. Rossi; G. D’Avenio; S. Morelli; M. Grigioni","Department of Computer, Control and Management Engineering, Sapienza University of Rome, Rome, Italy; National Center for Technological Innovation in Public Health, Istituto Superiore di Sanità, Rome, Italy; National Center for Technological Innovation in Public Health, Istituto Superiore di Sanità, Rome, Italy; National Center for Technological Innovation in Public Health, Istituto Superiore di Sanità, Rome, Italy","2020 IEEE 20th Mediterranean Electrotechnical Conference ( MELECON)","15 Jul 2020","2020","","","339","343","The number of people affected by dementia in the world is growing up due to the shift of the population age profile. This paper presents a tool to help and support people who suffer from both cognitive decline age-related and cognitive impairments. Cognitive impairment refers to a person who has trouble remembering, learning, concentrating, or making decisions that affect their daily life. Cognitive impairment varies from mild to severe. With mild impairment, people may begin to notice changes in cognitive functions, while still be able to do their everyday activities; on the other hand, severe levels of impairment can lead to losing the ability to understand the meaning or importance of something in addition to the ability to talk or write, resulting in the inability to live independently. We developed an augmented reality home-made App, CogAR, designed for smart glasses. The App can be a useful tool able to provide more independence to patients during actual daily living activities and in navigating their home, providing cues for memory integration in real time. In this way, elderly people, could stay at home longer without the need to move into a care home environment.","2158-8481","978-1-7281-5200-4","10.1109/MELECON48756.2020.9140554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140554","cognitive impairment;augmented reality;smart glasses","Dementia;Senior citizens;Resists;Tools;Augmented reality;Games;Technological innovation","assisted living;augmented reality;cognition;geriatrics","mild impairment;cognitive functions;augmented reality home-made app;CogAR;elderly people;augmented reality App;population age profile;cognitive impairment;cognitive decline age-related impairment;smart glasses;daily living activities;memory integration","","1","","44","IEEE","15 Jul 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Performance in Detecting Hardware Components Using Marker Based Tracking Method","S. Sendari; D. Anggreani; M. Jiono; A. Nurhandayani; C. Suardi","Departement of Electrical Engineering, State University of Malang, Malang, Indonesia; Departement of Electrical Engineering, State University of Malang, Malang, Indonesia; Departement of Electrical Engineering, State University of Malang, Malang, Indonesia; Departement of Electrical Engineering, State University of Malang, Malang, Indonesia; Departement of Electrical Engineering, State University of Malang, Malang, Indonesia","2020 4th International Conference on Vocational Education and Training (ICOVET)","21 Oct 2020","2020","","","1","5","Computers have been widely used for various activities. The computer is composed of several components, including hardware components. Each piece of hardware has different specifications from the others. So, components that are installed depending on the specifications. Currently, users still don't know the components they use. Introducing hardware components to users can be done using Augmented Reality (AR) technology. The proposed system is developed using research and development (R&D) methods. The system was built using Unity3D and Vuforia SDK. This paper aims to analyze the performance of AR applications in detecting hardware components based on the light intensity, distance, and the angle of detection of a smartphone camera. The result performances show that the system works well in the distance parameters of ± 15 cm and ± 25 cm; while angles parameters in 5 °, 60 °, or 90 °. The proposed system was also working well when the components were partially covered by about 20% and 50%. Furthermore, the proposed system still works well when light intensity decreases by 100 Lux. The result shows that AR is potentially used for the user to know the components.","","978-1-7281-8131-8","10.1109/ICOVET50258.2020.9229895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229895","Computer Hardware;Augmented Reality;R&D;Marker Based Tracking","Augmented reality;Testing;Hardware;Cameras;Three-dimensional displays;Research and development;Training","augmented reality;image sensors;object tracking;smart phones;solid modelling","augmented reality performance;hardware components;augmented reality technology;marker based tracking method;AR;Unity3D;Vuforia SDK;smartphone camera","","1","","22","IEEE","21 Oct 2020","","","IEEE","IEEE Conferences"
"Application of Collision Detection Algorithm and Scoring Health Point in Fighting Games with Android-Based Augmented Reality Technology","A. N. Rachman; R. N. Shofa; E. N. F. Dewi; A. Hidayat","Dept. Informatics, Siliwangi University, Tasikmalaya, Indonesia; Dept. Informatics, Siliwangi University, Tasikmalaya, Indonesia; Dept. Informatics, Siliwangi University, Tasikmalaya, Indonesia; Dept. Informatics, Siliwangi University, Tasikmalaya, Indonesia","2019 2nd International Conference of Computer and Informatics Engineering (IC2IE)","27 Dec 2019","2019","","","216","221","Games are one of the media of technology that is popular among the public, both from children and adults as an entertainment medium. The game itself has a lot of genres or types. One of the types discussed in this study is developing a fighting type game by applying the Augmented Reality (AR) system in making games. Similar games that have been observed have weaknesses where the AR game flow concept is not clearly stated, there are some similarities in the marker but different Attack stats, and there is no one that has raised the character of Betta fish. For this reason, it is necessary to make a similar game by applying a marker-based tracking technique and lifting the game of betta fighting by applying AR technology. In this study, applying the Collision Detection algorithm to detect collisions between objects. In this study succeeded in making Betta Fish Fighter with the Multimedia Development Life Cycle (MDLC) Method. Based on the tests that have been carried out, the alpha test results are functionally appropriate and from the beta testing the results of the User Acceptance Test (UAT) functionalities obtained a value of 90.66% declared feasible to use with the interpretation of “Good” which means the game is suitable developed.","","978-1-7281-2384-4","10.1109/IC2IE47452.2019.8940886","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8940886","Augmented Reality;Betta Fish;Collision Detection;Game Fighting","Games;Augmented reality;Fish;Testing;Three-dimensional displays;Informatics;Collision avoidance","Android (operating system);augmented reality;collision avoidance;computer games","collision detection algorithm;scoring health point;fighting type game;augmented reality system;AR game flow concept;android-based augmented reality technology;multimedia development life cycle;MDLC method;Betta fish","","","","16","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"Extensible Augmented Reality Assisted Contact-Free Patient Surveillance in Emergency Context","R. Roth; T. Pursche; D. Farooghi; R. Möller","Chair of Automation / Computer Science, University of Wuppertal, Wuppertal, Germany; Chair of Automatic Control, University of Wuppertal, Wuppertal, Germany; Chair of Automation / Computer Science, University of Wuppertal, Wuppertal, Germany; Chair of Automation / Computer Science, University of Wuppertal, Wuppertal, Germany","2020 IEEE 10th International Conference on Consumer Electronics (ICCE-Berlin)","17 Feb 2021","2020","","","1","5","We present a concept for a supplementary patient monitoring and emergency alerting system. It renders hot pluggability of sensors possible by taking a modular design as a basis. Specialized sensor modules detect the occurrence of particular emergencies such as excessive increasing or decreasing heart rate. The observers operating the system can receive and easily react to these emergencies using augmented reality headsets without having to interrupt their routine. Means to monitor multiple patients per sensor are discussed in this paper as well.","2166-6822","978-1-7281-5885-3","10.1109/ICCE-Berlin50680.2020.9352178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9352178","augmented reality;AR;medical;user interface","Patient monitoring;Surveillance;Observers;Streaming media;Sensors;Biomedical monitoring;Augmented reality","augmented reality;biomedical measurement;cardiology;emergency services;medical computing;patient monitoring;sensors;surveillance","heart rate;augmented reality headsets;extensible augmented reality assisted contact-free patient surveillance;patient monitoring;sensor modules;emergency alerting system","","","","24","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"A Demonstration of the Taxonomy of Functional Augmented Reality for Human-Robot Interaction","O. Phaijit; M. Obaid; C. Sammut; W. Johal","Univ. of New South Wales, Sydney, Australia; Interaction Design, CSE, Chalmers Univ. of Technology, Gothenburg, Sweden; Univ. of New South Wales, Sydney, Australia; Univ. of Melbourne, Melbourne, Australia","2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","29 Sep 2022","2022","","","981","985","With the rising use of Augmented Reality (AR) technologies in Human-Robot Interaction (HRI), it is crucial that HRI research examines the role of AR in HRI to better define AR-HRI systems and identify potential areas for future research. A taxonomy for AR in HRI has recently been proposed for the field. However, it was limited to the definition of the framework, and exemplifying its use was missing. In this paper, we perform a demonstration of how the aforementioned taxonomy of AR in HRI can be used to analyse an existing AR-HRI system and come up with questions for alternative ways AR-HRI could be designed and further extended.","","978-1-6654-0731-1","10.1109/HRI53351.2022.9889390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889390","Human-robot interaction;augmented reality;taxonomy;demonstration","Taxonomy;Augmented reality","augmented reality;control engineering computing;human-robot interaction","functional Augmented Reality;human-robot interaction;augmented reality technologies;HRI research;AR-HRI systems;taxonomy;alternative ways AR-HRI","","","","21","IEEE","29 Sep 2022","","","IEEE","IEEE Conferences"
"Computer vision for green and secure cooperative augmented reality in Next Generation Converged Wireless Networks","K. Bhosale; V. Rohokale","Vishwaniketan Institute of Management Entrepreneurship Engineering and Technology, Khalapur, Maharashtra, India; SKN, Sinhgad Institute of Technology & science, Lonavala, Maharashtra, India","2015 International Conference on Pervasive Computing (ICPC)","16 Apr 2015","2015","","","1","5","With the help of digital resources, self-description of smart objects causes some limitation into the input qualities because of the long established physical appearances. Also to realize the capability of objects to understand and recognize the data. If an uninstrumented surface is provided, the object should be able to sense gestures and touches upon the surface. To design an area for supporting whole body metaphors physical movements and position of entire body .Objects such as sensors, processors and radios are integrated invisibly into smart sensitive objects for user interaction. In this paper, we propose to rectify the excitation and response imbalance by augmentation of smart objects with natural appearance of it. To achieve this, we propose the implementation of computer vision for cooperative augmented reality by open CV using matlab.","","978-1-4799-6272-3","10.1109/PERVASIVE.2015.7087189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087189","Smartobjects;Computervision;augmented reality;Open CV","Cameras;Augmented reality;Three-dimensional displays;Sensors;Computer vision;Mice;Mobile communication","augmented reality;computer vision;cooperative communication;gesture recognition;green computing;human computer interaction;next generation networks;radio networks;telecommunication security","computer vision;green cooperative augmented reality;secure cooperative augmented reality;next generation converged wireless networks;digital resources;data recognition;smart sensitive objects;user interaction;excitation imbalance rectification;response imbalance rectification;Open CV;Matlab","","","","20","IEEE","16 Apr 2015","","","IEEE","IEEE Conferences"
"A Metalens-Based Virtual Reality (VR) / Augmented Reality (AR) System","Z. Li; P. Lin; Y. -W. Huang; J. -S. Park; W. T. Chen; Z. Shi; J. -X. Cheng; F. Capasso","Harvard John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Department of Electrical and Computer Engineering, Boston University, Boston, MA, USA; Harvard John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Harvard John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Harvard John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Harvard John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Department of Electrical and Computer Engineering, Boston University, Boston, MA, USA; Harvard John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA","2020 Conference on Lasers and Electro-Optics (CLEO)","10 Sep 2020","2020","","","1","2","We demonstrated a large and RGB-achromatic metalens by novel design methods. Furthermore, we realized a compact platform for a virtual reality / augmented reality system based on an RGB metalens and a fiber scanning display.","2160-8989","978-1-943580-76-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9192603","","Lenses;Bars;Optical fiber dispersion;Image color analysis;Augmented reality;Optical fibers","augmented reality;lenses;optical design techniques;virtual reality","compact platform;virtual reality;RGB metalens;augmented reality system;large RGB-achromatic metalens;design methods;fiber scanning display","","","","5","","10 Sep 2020","","","IEEE","IEEE Conferences"
"Implementation of mobile augmented reality based on Vuforia and Rawajali","C. Xiao; Z. Lifeng","School of Information Science and Technology, Jiujiang University, Jiujiang, Jiangxi Province, China; School of Information Science and Technology, Jiujiang University, Jiujiang, Jiangxi Province, China","2014 IEEE 5th International Conference on Software Engineering and Service Science","23 Oct 2014","2014","","","912","915","Due to the limits of large computer and head mounted personal display systems, augmented reality technology is applied in limited area scene. With the development of smart phone technology, augmented reality technology is applied to a broader range. Aim to application of mobile augmented reality, an implementation project based on Vuforia and Rawajali is designed. The Vuforia uses image recognition to trace and register image marker, the Rawajali manages and uses 3D model flexibly. This paper proposes an application framework, the function of system core class and application workflow. The test result shows that the project has the strong availability and applicability, at the same time, it owns good application foreground.","2327-0594","978-1-4799-3279-5","10.1109/ICSESS.2014.6933713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933713","Augmented Reality;Android;Vuforia;3D Modeling","Three-dimensional displays;Augmented reality;Mobile communication;Solid modeling;Smart phones;Unified modeling language;Target tracking","augmented reality;image recognition;image registration;mobile computing;smart phones;solid modelling","mobile augmented reality;Vuforia;Rawajali;computer display system;head mounted personal display system;smart phone technology;image recognition;image marker registration;image marker tracing;3D model","","33","","9","IEEE","23 Oct 2014","","","IEEE","IEEE Conferences"
"Augmented Reality Application for Preschool Children with Unity 3D Platform","B. A. Koca; B. Çubukçu; U. Yüzgeç","Computer Engineering Department, Bilecik Seyh Edebali University, Bilecik, Türkiye; Computer Engineering Department, Bilecik Seyh Edebali University, Bilecik, Türkiye; Computer Engineering Department, Bilecik Seyh Edebali University, Bilecik, Türkiye","2019 3rd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)","16 Dec 2019","2019","","","1","4","In recent years, Augmented Reality (AR) applications have been introduced especially in a number of different areas by being used more advanced lenses in the cameras in addition to the processor and image processing capacities of smart phones. Nowadays, from Mobile AR games to entertainment applications, from online shopping to Industry 4.0 solutions, Augmented Reality has become one of the most used technologies. Within the scope of this study, the principle of the fun learning of children in preschool age in Turkey has been discussed. An AR application was developed for preschool children to make their learning more fun. In this AR application, Unity 3D platform and Vuforia SDK Augmented Reality Library were utilized.","","978-1-7281-3789-6","10.1109/ISMSIT.2019.8932729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932729","Unity 3D;Augmented Reality;Vuforia","Three-dimensional displays;Augmented reality;Animals;Games;Smart phones;Solid modeling;Engines","augmented reality;computer aided instruction;mobile learning","preschool children;unity 3D platform;image processing capacities;smart phones;mobile AR games;entertainment applications;online shopping;AR application;Unity 3D platform;Vuforia SDK Augmented Reality Library","","18","","10","IEEE","16 Dec 2019","","","IEEE","IEEE Conferences"
"Smart learning based on augmented reality with android platform and its applicability","Y. Bahuguna; A. Verma; K. Raj","Department of Electronics and Communication, Tula’s Institute, Dehradun, India; Department of Electronics and Communication, Tula’s Institute, Dehradun, India; Department of Electronics and Communication, Tula’s Institute, Dehradun, India","2018 3rd International Conference On Internet of Things: Smart Innovation and Usages (IoT-SIU)","4 Nov 2018","2018","","","1","5","Since last few decades, AR technology has visualized fabulous growth, now it is ready to be used in consumable electronic items like PCs, computer and android phones. Here the aim is to showcase an overview of basic aspects of Augmented Reality and the main concepts of this technology. Now a day AR finds its involvement in various fields along with its smart application software which can be used in different fields including education, medical and many more. Augmented reality, better known as AR is a step towards latest technology enhancement program which enables us to experience virtual things in real world. By the introduction of Augmented reality into the education system teachers can convey their knowledge more preciously and in a very attractive manner. Students will understand more easily if this technology is introduced to them. Hereby in this manuscript, we are proposing an idea to use AR on Android platform which is more widely used now-a-days.","","978-1-5090-6785-5","10.1109/IoT-SIU.2018.8519853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519853","Augmented Reality;HMDs;GPS;pattern recognition;astronomy","Augmented reality;Solid modeling;Education;Three-dimensional displays;Smart phones;Software","Android (operating system);augmented reality;computer aided instruction;mobile learning","augmented reality;AR technology;consumable electronic items;smart application software;Android platform;Android phones;smart learning","","14","","23","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Mobile augmented reality on web-based for the tourism using HTML5","P. Dangkham","Information and Communication Engineering, Thepsatri Rajabhat University, Lopburi, Thailand","2018 International Conference on Information Networking (ICOIN)","23 Apr 2018","2018","","","482","485","This research presents the development of the augmented reality (AR) for the tourism in Lopburi ancient city. The main objective is to inform the attraction place's data to the tourist. The interaction with the tourist and the environment is possible in the real time. There are many AR platforms which can be used for the various functions. Each of AR platforms requires specific application. The users need to install the AR application before using. It is not suitable for tourists. The HTML5 application development is allowed in a cross-platform manner. The advantage of HTML5 is that the users can access the application immediately without installation application required. This research uses HTML5 and JavaScript to develop the augmented reality into web-based for support of mobile devices. The attraction place's data will be displayed on the mobile web browser. It is the same as browsing the internet. There are 6 points of interests in this work. The result shows that the augmented reality technology can be used in tourism effectively.","","978-1-5386-2290-2","10.1109/ICOIN.2018.8343165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8343165","Augmented Reality;HTML5;Mobile Application","Augmented reality;Urban areas;Sensors;Cameras;Browsers;Mobile applications;Global Positioning System","augmented reality;hypermedia markup languages;Internet;mobile computing;online front-ends;travel industry","tourism;Lopburi ancient city;attraction place;tourist;AR platforms;specific application;AR application;HTML5 application development;cross-platform manner;installation application;mobile devices;mobile web browser;augmented reality technology","","14","","12","IEEE","23 Apr 2018","","","IEEE","IEEE Conferences"
"Development of lane-level guidance service in vehicle augmented reality system","J. -W. Lee; C. -R. Yoon; J. Kang; B. -J. Park; K. -H. Kim","Industries IT Convergence Department, Electronics and Telecommunications Research Institute, Korea; Industries IT Convergence Department, Electronics and Telecommunications Research Institute, Korea; Industries IT Convergence Department, Electronics and Telecommunications Research Institute, Korea; Industries IT Convergence Department, Electronics and Telecommunications Research Institute, Korea; Industries IT Convergence Department, Electronics and Telecommunications Research Institute, Korea","2015 17th International Conference on Advanced Communication Technology (ICACT)","27 Aug 2015","2015","","","263","266","A driver should always pay attention to various situations which he faces inside and outside the car while driving and always keep eyes forward for safe driving. A vehicle augmented reality system provides the driver with safe and convenience information which matched with the real world through HUD. It makes the driver keep eyes forward road and other cars. We have developed the vehicle augmented reality system and various services and tested them on an indoor testbed This system provides driver with the forward situation awareness service, the lane change service, the lane departure service and so on displayed as the vehicle augmented reality. We describe the development contents and results of the developed vehicle augmented reality system focused on the lane-level guidance technology which determines the lane change or the lane departure using route information, road properties, the driving lane information, position, and so on.","1738-9445","978-8-9968-6505-6","10.1109/ICACT.2015.7224799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224799","vehicle;augmented reality;lane change;lane departure;route guidance","Vehicles;Augmented reality;Roads;Navigation;Sensors;Optimization","augmented reality;driver information systems;road safety;road vehicles","lane-level guidance service;vehicle augmented reality system;safe driving;forward situation awareness service;lane change service;lane departure service;route information;road properties;driving lane information","","13","1","16","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Applying Augmented Reality Technology to Book Publication Business","A. S. Y. Lai; C. Y. K. Wong; O. C. H. Lo","Department of Information and Communications Technology, Hong Kong Institute of Vocational Education, HONG KONG; Department of Information and Communications Technology, Hong Kong Institute of Vocational Education, HONG KONG; Department of Information and Communications Technology, Hong Kong Institute of Vocational Education, HONG KONG","2015 IEEE 12th International Conference on e-Business Engineering","10 Dec 2015","2015","","","281","286","Augmented Reality is an emerging technology and the applications of technology are still not fully unveiled. This paper explores a new application of augmented reality for a new direction in educational book publishing, which aims to bring interactive learning experience to life. The project takes printed images on book to the next level by applying Augmented Reality technology to provide a unique fascinating experience to its readers on mobile devices. Augmented Reality (AR) technology composing with animation brings new digital entertainment experience to the reader of books. The key feature of this paper uses the technology presents auxiliary information in the field of view of an object printed on book automatically without human intervention. The project uses the technology with iPad mobile device to display 3D models, 3D animations, video splaying, websites and web server connectivity for children education. The results and evaluation of the project shows the interactive 3D animation and self-assessment functions significantly support students to improve their learning experience and performance. The software product of this project, from the business perspective, creates a new business marketing dimension in digital publishing and increases the selling profits in the book publication business.","","978-1-4673-8002-7","10.1109/ICEBE.2015.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349981","Augmented Reality;Mobile Computing;Multimedia Services;E-Learning","Three-dimensional displays;Augmented reality;Engines;Animation;Target tracking;Databases;Solid modeling","augmented reality;computer aided instruction;computer animation;electronic commerce;interactive systems;marketing;publishing","augmented reality technology;book publication business;educational book publishing;interactive learning;AR technology;digital entertainment;iPad mobile device;interactive 3D animation;business marketing dimension;digital publishing","","10","","10","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"Smart augmented reality glasses in cybersecurity and forensic education","N. Kommera; F. Kaleem; S. M. Shah Harooni","Information and Computer Sciences, Metropolitan State University, Minnesota, United States; Information and Computer Sciences, Metropolitan State University, Minnesota, United States; Information and Computer Sciences, Metropolitan State University, Saint Paul, MN, US","2016 IEEE Conference on Intelligence and Security Informatics (ISI)","17 Nov 2016","2016","","","279","281","Augmented reality is changing the way its users see the world. Smart augmented-reality glasses, with high resolution Optical Head Mounted display, supplements views of the real-world using video, audio, or graphics projected in front of user's eye. The area of Smart Glasses and heads-up display devices is not a new one, however in the last few years, it has seen an extensive growth in various fields including education. Our work takes advantage of a student's ability to adapt to new enabling technologies to investigate improvements teaching techniques in STEM areas and enhance the effectiveness and efficiency in teaching the new course content. In this paper, we propose to focus on the application of Smart Augmented-Reality Glasses in cybersecurity education to attract and retain students in STEM. In addition, creative ways to learn cybersecurity education via Smart Glasses will be explored using a Discovery Learning approach. This mode of delivery will allow students to interact with cybersecurity theories in an innovative, interactive and effective way, enhancing their overall live experience and experimental learning. With the help of collected data and in-depth analysis of existing smart glasses, the ongoing work will lay the groundwork for developing augmented reality applications that will enhance the learning experiences of students. Ultimately, research conducted with the glasses and applications may help to identify the unique skillsets of cybersecurity analysts, learning gaps and learning solutions.","","978-1-5090-3865-7","10.1109/ISI.2016.7745489","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745489","Smart Augmented-Reality Glasses;cybersecurity education;characteristics of cybersecurity analysts","Glass;Computer security;Forensics;Education;Augmented reality;Mobile handsets;Computers","augmented reality;computer aided instruction;computer science education;digital forensics;helmet mounted displays;STEM;teaching","smart augmented reality glasses;forensic education;cybersecurity education;STEM;discovery learning;cybersecurity theories;experimental learning;learning experiences;cybersecurity analysts;learning gaps;learning solutions;high resolution optical head mounted display;heads-up display devices;teaching","","8","","12","IEEE","17 Nov 2016","","","IEEE","IEEE Conferences"
"Development Actuality and Application of Registration Technology in Augmented Reality","L. Yi-bo; K. Shao-peng; Q. Zhi-hua; Z. Qiong","Department of Auto-control, Shenyang Institute of Aeronautical Engineering, Shenyang, China; Department of Auto-control, Shenyang Institute of Aeronautical Engineering, Shenyang, China; Department of Auto-control, Shenyang Institute of Aeronautical Engineering, Shenyang, China; Department of Auto-control, Shenyang Institute of Aeronautical Engineering, Shenyang, China","2008 International Symposium on Computational Intelligence and Design","22 Dec 2008","2008","2","","69","74","The registration in augmented reality is a process which merges virtual objects generated by computer with real world image caught by camera. This paper describes the tracker-based registration and the knowledge-based registration, and analyzes the process and current approaches of computer vision-based registration. In consideration of current research challenges, the outdoor registration technology in augmented reality is discussed in detail, and some typical applications are introduced. Then, on the basis of the development background of ""UAV teleoperation and simulation system"", an augmented reality method for UAV teleoperation based on Vega is illustrated. At last, it indicates that correct 3D registration in outdoor complex environment with large area and the application in teleoperation of robot or UAV is an important developing tendency in the research field of registration technology in augmented reality.","","978-0-7695-3311-7","10.1109/ISCID.2008.120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725459","augmented reality;registration technology;application;Vega","Augmented reality;Computer vision;Cameras;Calibration;Magnetic fields;Application software;Unmanned aerial vehicles;Delay effects;Layout;Intelligent robots","augmented reality;image registration","development actuality;registration technology;augmented reality;virtual objects;tracker-based registration;knowledge-based registration;computer vision-based registration;outdoor registration technology;UAV teleoperation system;simulation system","","7","","30","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"A mobile application for an ecological campus navigation system using augmented reality","K. -M. Yu; J. -C. Chiu; M. -G. Lee; S. -S. Chi","Computer Science and Information Engineering, Chung Hua University, Hsinchu, Taiwan; Computer Science and Information Engineering, Chung Hua University, Hsinchu, Taiwan; Leisure and Recreation Management, Chung Hua University, Hsinchu, Taiwan; Computer Science and Information Engineering, Chung Hua University, Hsinchu, Taiwan","2015 8th International Conference on Ubi-Media Computing (UMEDIA)","15 Oct 2015","2015","","","17","22","With the recent advances in technology, the number of smart mobile device functions is constantly increasing. Furthermore, with Wi-Fi and the popularity of smart mobile devices, supplying information using the smart mobile has been receiving a lot of attention from technology developers. The combining of technology and education is constantly being explored in various fields. Because of the convenience provided by smart mobile devices, many of them are equipped with augmented reality techniques. This study investigated the use of augmented reality technology when applied to the ecological environment for the purpose of campus navigation, and the application of the augmented reality and location-based service incorporated with audio and visual information about special flora and fauna in a campus ecological environment to establish an ecologically friendly environment navigation and retrieval system. The augmented reality technology was used to render 3D animation models and video playback with the ability to identify images of animals and plants as well as providing directives for users when getting near birds or plants.","","978-1-4673-8270-0","10.1109/UMEDIA.2015.7297421","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7297421","Augmented Reality;Global Positioning System;Electronic compass;Location-base Service","Augmented reality;Three-dimensional displays;Mobile handsets;Birds;Global Positioning System;Animation;Solid modeling","augmented reality;computer aided instruction;computer animation;ecology;mobile computing;rendering (computer graphics);smart phones","mobile application;ecological campus navigation system;augmented reality;smart mobile device function;location-based service;3D animation model rendering","","7","","8","IEEE","15 Oct 2015","","","IEEE","IEEE Conferences"
"Augmented Reality based Multimedia Learning for Dyslexic Children","Z. Bhatti; M. Bibi; N. Shabbir","Institute of Information and Communication, Technology University of Sindh, Jamshoro, Pakistan; Institute of Information and Communication, Technology University of Sindh, Jamshoro, Pakistan; Institute of Information and Communication, Technology University of Sindh, Jamshoro, Pakistan","2020 3rd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)","23 Apr 2020","2020","","","1","7","Augmented reality is a visual technology which combines virtual objects into the real environment, in real time. In this research work, a heuristic model of multimedia learning would be developed using Augmented Reality for a type of neurological disorder known as Dyslexia. Dyslexia is complex mental brain related syndromes, affecting the children in various ways including verbal and nonverbal communications, social interactions, understanding instructions, reading, writing, learning, problems, etc. The use of interactive Augmented Reality based multimedia application to facilitate and provide pedagogy for such type of special children would ascertain a unique and new dimension of treating and helping such young hearts in overcoming their disabilities in a very fun and easy way. The research encompasses designing a framework based on cognitive learning for interactive multimedia learning app using augmented reality technology, that would be centric to autism effected children's and would enable them to interact with such system.","","978-1-7281-4970-7","10.1109/iCoMET48670.2020.9073879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073879","Dyslexia;Augmented Reality;Multimedia Learning;Serious Games","Augmented reality;Three-dimensional displays;Education;Solid modeling;Shape;Real-time systems","augmented reality;cognition;computer aided instruction;human computer interaction;medical disorders;multimedia computing;neurophysiology","dyslexic children;special children;cognitive learning;interactive augmented reality based multimedia application;mental brain related syndromes;interactive multimedia learning app;heuristic model;visual technology;virtual objects","","6","","18","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Application of the Augmented Reality Technology to Training Future Electrical Engineers","T. Poyasok; V. Chenchevoi; O. Bespartochna; O. Chencheva","Department of psychology, pedagogy and philosophy, Kremenchuk Mykhailo Ostrohradskyi National University, Kremenchuk, Ukraine; Systems of Automatic Control and Electric Drive department, Kremenchuk Mykhailo Ostrohradskyi National University, Kremenchuk, Ukraine; Department of psychology, pedagogy and philosophy, Kremenchuk Mykhailo Ostrohradskyi National University, Kremenchuk, Ukraine; Machine tools and machine complexes department, Kremenchuk Mykhailo Ostrohradskyi National University, Kremenchuk, Ukraine","2020 IEEE Problems of Automated Electrodrive. Theory and Practice (PAEP)","2 Nov 2020","2020","","","1","4","The features of professional training future electrical engineers are analyzed. Advantages and disadvantages of the introduction of AR technology in the educational process are researched. Approaches to the design and implementation of the augmented reality technology are studied. A model of realization of the access to the augmented reality technology based on dynamic markers and mobile devices is developed. The methodology of application of augmented reality supplements in the guidelines and manuals for teaching students of electromechanical specialties is described. The results of the research of the effectiveness of augmented reality application to the professional training of future electrical engineers are presented.","","978-1-7281-9935-1","10.1109/PAEP49887.2020.9240788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240788","augmented reality technology;mobile devices;dynamic markers;professional training of future electrical engineers","Training;Computational modeling;Organizations;Mobile handsets;Browsers;Mobile applications;Augmented reality","augmented reality;educational computing;electrical engineering;electrical engineering computing;electrical engineering education;professional aspects;teaching;training","electrical engineers;augmented reality;AR technology;professional training","","5","","21","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"A study of the factors impacting the adoption of augmented reality in online purchases in India","S. Chakraborty; D. Gupta","Amrita School of Business, Coimbatore, Amrita Vishwa Vidyapeetham University; Amrita School of Business, Coimbatore, Amrita Vishwa Vidyapeetham University","2017 2nd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","15 Jan 2018","2017","","","1526","1529","The advent of opportunities to shop online has made inroads into virtually all modes of businesses worldwide. The success and future of online businesses depends on how well they adopt newer technologies. The online platforms give a faster and convenient option to buy, but have not been able to deliver the experience of shopping to its customers. Technologies such as Augmented Reality (AR)are steps in this direction - bringing an entirely new dimension to the online selling platforms. Among the questions that are yet to be answered are how widely will this technology be adopted by Indian consumers and what factors influence their relative preference for AR. This study aims to understand the factors influencing the adoption of Augmented Reality while shopping online by Indian consumers. The factors like Personality, Innovation Seeking Behaviour, Tech Savviness and Shopping Experience Seeking Behaviour were measured with the 127 respondents who took part in the survey online. The collected data was analysed using Logistic Regression. The results indicated that people who are Gadget Lovers and those who prefer to buy online frequently were more likely to try Augmented Reality.","","978-1-5090-3704-9","10.1109/RTEICT.2017.8256853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8256853","Augmented Reality;Personality;Innovation Seeking Behaviour;Tech Savviness;Shopping Experience Seeking Behaviour","Augmented reality;Technological innovation;Conferences;Market research;Communications technology;Advertising","augmented reality;consumer behaviour;electronic commerce;Internet;purchasing;regression analysis;retail data processing","augmented reality;online purchases;Indian consumers;online selling platforms;online platforms;online businesses;Shopping Experience Seeking Behaviour;Innovation Seeking Behaviour;Logistic Regression","","5","","8","IEEE","15 Jan 2018","","","IEEE","IEEE Conferences"
"Towards Enhancing User Experience through a Web-Based Augmented Reality Museum","A. S. M. Venigalla; S. Chimalakonda","Department of Computer Science and Engineering, Indian Institute of Technology, Tirupati, India; Department of Computer Science and Engineering, Indian Institute of Technology, Tirupati, India","2019 IEEE 19th International Conference on Advanced Learning Technologies (ICALT)","2 Sep 2019","2019","2161-377X","","357","358","Museums act as a vehicle to collect, preserve and demonstrate historical, cultural and scientific heritage to a larger community of end users. However, there is neither increase in the number of physical visitors nor visitors to online museum, despite their availability on the web. On the other hand, Augmented Reality has emerged as a potential technology to support and enhance experience of end users in different communities especially in digital heritage. In this paper, we propose Augmented Reality Museum (ARM) as an application that can enhance online museum visitor experience. Augmented Reality can be integrated as a mobile application that provides 3D view of an artifact, along with information about its historic, artistic and/or scientific importance. We present the design and development of ARM and demonstrate it for the case study of Online British Museum. Our user experience study conducted with 21 volunteers shows that ARM is potentially a good way to enhance user experience.","2161-377X","978-1-7281-3485-7","10.1109/ICALT.2019.00110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820834","Augmented Reality;Museums;Web;Unity 3D","Three-dimensional displays;Solid modeling;Augmented reality;Two dimensional displays;Cultural differences;User experience;Visualization","augmented reality;Internet;mobile computing;museums","cultural heritage;scientific heritage;digital heritage;online museum visitor experience;mobile application;Online British Museum;museums act;historical heritage;user experience;Web-based augmented reality museum","","4","","10","IEEE","2 Sep 2019","","","IEEE","IEEE Conferences"
"Short paper: Calory Battle AR: An extensible mobile augmented reality exergame platform","J. Westlin; T. H. Laine","Department of Information and Computer Engineering, Ajou University, Suwon, South-Korea; Department of Information and Computer Engineering, Ajou University, Suwon, South-Korea","2014 IEEE World Forum on Internet of Things (WF-IoT)","24 Apr 2014","2014","","","171","172","We proposed an extensible mobile augmented reality exergame platform which utilizes augmented reality and sensors to connect virtual game content to the real world. We analyzed the current state of augmented reality and exergaming research before describing the Calory Battle AR concept along with its technical details. Extensibility of the platform is threefold: 1) players can create and share game maps; 2) developers can create new task types for game maps; and 3) developers can create context-sensing modules based on wearable technologies.","","978-1-4799-3459-1","10.1109/WF-IoT.2014.6803144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6803144","augmented reality;exercise;game;architecture","Games;Augmented reality;Mobile communication;Obesity;Pediatrics;Google;Computers","augmented reality;computer games;mobile computing","extensible mobile augmented reality exergame platform;sensors;virtual game content;exergaming research;Calory Battle AR concept;game maps;context-sensing modules;wearable technologies","","4","","11","IEEE","24 Apr 2014","","","IEEE","IEEE Conferences"
"Offline mobile application for places identification with augmented reality","M. Díaz H.; K. Barberán C.; D. Martínez-M.; G. López F.","Escuela Politecnica Nacional, Quito, Pichincha, EC; Escuela Politecnica Nacional, Quito, Pichincha, EC; Escuela Politecnica Nacional, Quito, Pichincha, EC; Escuela Politecnica Nacional, Quito, Pichincha, EC","2017 Fourth International Conference on eDemocracy & eGovernment (ICEDEG)","3 Jul 2017","2017","","","261","264","As it can be seen in a developed society, the cities grow day to day, it gives the idea that in the future the major part of the people around the world will live in a city. The term digital city was given to know how the cities will be able to receive these people. Hence, it is important to study how new technologies can improve life quality in several aspects, including the tourism. About tourism, one important aspect to consider is the available information about different places in a city to guide visitors. With the aim to provide information about the different places in a city, usually there are several signs to help visitors. However, it has not been enough. Thus, the existing technologies like the Augmented Reality (AR) are mainly focused in providing this type of information. Taking advantage of the wide diffusion of the mobile devices, it is possible to use Augmented Reality technology in a mobile device to identify a place. Currently, there are some applications that provide places identification, but they only work with an Internet connection. This article proposes an offline mobile application for places identification with Augmented Reality. This solution can be replicated by any organization that desires to give a pleasant experience to their visitors.","","978-1-5090-4830-4","10.1109/ICEDEG.2017.7962546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7962546","Augmented Reality;Vuforia;places identification;mobile application;tourism;smart cities","Mobile applications;Augmented reality;Cameras;Urban areas;Internet;Smart phones","augmented reality;information retrieval;mobile computing;smart cities;travel industry","offline mobile application;place identification;augmented reality;digital city;life quality;mobile devices;Internet connection","","4","","8","IEEE","3 Jul 2017","","","IEEE","IEEE Conferences"
"Relational localization based Augmented reality Interface for IOT applications","S. Baskaran; H. K. Nagabushanam","Research Ericsson India Global Services Pvt Ltd, Chennai, India; Research Ericsson India Global Services Pvt Ltd, Chennai, India","2018 International Conference on Information and Communication Technology Convergence (ICTC)","18 Nov 2018","2018","","","103","106","Augmented Reality today operates around building environments over predefined image, model or object targets. This results in extensive utilization of device and network resources in a system. Millions of connected IOT devices are being deployed every year and with that there is increasing complexities in representing the data generated in human correlate-able form. Augmented Reality visual interface for IOT device data helps in better user experience and enables easy interaction or actuation. Training Augmented Reality interface for each of the IOT device is a tedious task and with dynamically changing networks it is not judicious or reliable. In this paper, we propose a system and a technique to blend Augmented Reality as a generic form of representation for IOT devices using relational localization methods along with metadata information of the sensors. This eliminates the necessity of pre-training the AR devices and also creates the ability to visualize data from any IOT device participating in the network.","2162-1233","978-1-5386-5041-7","10.1109/ICTC.2018.8539469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539469","Augmented Reality;Indoor localization (ranging);Internet of Things (IOT);Machine Learning;Recommender Systems","Logic gates;Temperature sensors;Wireless sensor networks;Sensor phenomena and characterization;Metadata;Augmented reality","augmented reality;Internet of Things","IOT applications;connected IOT devices;IOT device data;relational localization methods;AR devices;augmented reality visual interface","","4","","4","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"Review of augmented reality agent in education","B. S. Hantono; L. E. Nugroho; P. I. Santosa","Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia; Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia; Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia","2016 6th International Annual Engineering Seminar (InAES)","19 Jan 2017","2016","","","150","153","Augmented reality becomes mature enough to create various applications for end users especially in education field. This is also supported by the presence of more affordable smart phones. The features offered by augmented reality applications could make students more easily understand the lessons and the learning process more fun. Most of current augmented reality applications still present information that is always the same from time to time, there is no personalization in order to obtain an appropriate learning experience for each student. Most of the studies concentrate on the aspect of personalization assures that agents approach is needed to make the learning experience more personal and exciting. This paper aims to review the literature concerning augmented reality agents, its earlier and possible usages in educational setting.","","978-1-5090-0741-7","10.1109/INAES.2016.7821924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821924","agents;augmented reality;learning;review","Augmented reality;Three-dimensional displays;Software agents;Computers;Games;Seminars","augmented reality;computer aided instruction;smart phones","augmented reality agent;education field;smart phones","","4","","38","IEEE","19 Jan 2017","","","IEEE","IEEE Conferences"
"Campus Navigation System Based on Mobile Augmented Reality","Q. Yong-Xu; L. Jia-Min; Q. Hui; Y. Bo; J. Chang-Xu","School of Information Science and Technology, Shenyang University of Technology, Shenyang, China; School of Information Science and Technology, Shenyang University of Technology, Shenyang, China; School of Information Science and Technology, Shenyang University of Technology, Shenyang, China; School of Information Science and Technology, Shenyang University of Technology, Shenyang, China; School of Information Science and Technology, Shenyang University of Technology, Shenyang, China","2013 6th International Conference on Intelligent Networks and Intelligent Systems (ICINIS)","24 Jul 2014","2013","","","139","142","Due to the limited of precision, navigation technology in the local area cannot accurately locate each building and obtain the functions related to the building. This paper investigates augmented reality and navigation technologies and realizes the campus internal navigation on a mobile phone. In the campus, the exact position and detail data of every school can be obtained by using the augmented reality technology. The navigation system merged with augmented reality makes navigation technique in the local application more exact, humanized and convenient.","","978-1-4799-2809-5","10.1109/ICINIS.2013.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754691","mobile device;augmented reality;campus navigation","Buildings;Navigation;Augmented reality;Educational institutions;Cameras;Mobile communication;Mobile handsets","augmented reality;educational institutions;Global Positioning System;image registration;mobile computing","image processing technology;mobile augmented reality technology;school;mobile phone;campus internal navigation system","","4","","10","IEEE","24 Jul 2014","","","IEEE","IEEE Conferences"
"Augmented reality based mass casualty incident training system","H. Dong; J. Schafer; A. Ganz","Electrical and Computer Engineering Department, University of Massachusetts, Amherst, MA; Electrical and Computer Engineering Department, University of Massachusetts, Amherst, MA; Electrical and Computer Engineering Department, University of Massachusetts, Amherst, MA","2016 IEEE Symposium on Technologies for Homeland Security (HST)","15 Sep 2016","2016","","","1","4","In this paper we introduce the first augmented reality based training system for Mass Casualty Incidents (MCI). Our system enables the trainees to train in the physical environment while the disaster related objects and events such as victims, fire, tornadoes are digitally overlaid in the Smartphone camera view using Augmented Reality (AR). Using this system the trainees can experience the real physical environment while saving the cost of setting up disaster related objects and events. We view that this AR based training will not replace MCI live training in real physical environments with physical disaster related objects and events but will facilitate more frequent training sessions at lower cost. Moreover, this system is more affordable than virtual reality based environments due to the high cost of designing virtual environments. In addition, this system provides the trainees a more realistic experience than virtual reality based training since the trainees train in the physical environment.","","978-1-5090-0770-7","10.1109/THS.2016.7568946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568946","Augmented Reality;MCI Training","Training;Games;Fires;Augmented reality;Tornadoes;Cameras","augmented reality;computer based training;emergency management;smart phones","mass casualty incident training system;augmented reality based training system;MCI;disaster related objects;disaster related events;smartphone camera view","","4","","9","IEEE","15 Sep 2016","","","IEEE","IEEE Conferences"
"Utilizing Augmented Reality to Support Students' Learning in Popular Science Courses","W. Guo; Y. Xue; H. Sun; W. Chen; S. Long","Department of Education Information Technology, East China Normal University, Shanghai, China; Department of Education Information Technology, East China Normal University, Shanghai, China; Management School, Shanghai University, Shanghai, China; Department of Education Information Technology, East China Normal University, Shanghai, China; Department of Education Information Technology, East China Normal University, Shanghai, China","2017 International Conference of Educational Innovation through Technology (EITT)","12 Mar 2018","2017","","","311","315","Augmented reality is an emerging technology for the connection between the real world and the virtual world. The applications of the augmented reality technology in education field have profoundly changed the traditional education pattern. It is pointed out that utilizing augmented reality in class can increase the effectiveness and attractiveness of teaching and learning activities. In this paper, a case study of learning about dinosaurs in popular science courses of middle school based on the augmented reality technology is taken as an example. The samples of students' feedback show that this instructional design was conducive to resulting in a high-quality learning experience, active classroom atmosphere, and good learning performance.","","978-1-5386-0629-2","10.1109/EITT.2017.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8308566","augmented reality;instructional software;instructional design;experiential learning","Augmented reality;Education;Software;Dinosaurs;Three-dimensional displays;Solid modeling;Tools","augmented reality;computer aided instruction;educational courses;educational institutions;palaeontology;teaching","learning activities;augmented reality technology;high-quality learning experience;virtual world;teaching activities;science courses;student learning performance;middle school;student feedback","","3","","11","IEEE","12 Mar 2018","","","IEEE","IEEE Conferences"
"Augmented Reality Based Learning Media as Interactive Learning Innovation to Enhanced Vocational School Learning Outcomes","I. Brilian; A. Bagus Nur Rahma Putra; S. Suhartadi; P. Partono","Teknik Mesin, Universitas Negeri Malang, Malang, Indonesia; Teknik Mesin, Universitas Negeri Malang, Malang, Indonesia; Teknik Mesin, Universitas Negeri Malang, Malang, Indonesia; Teknik Mesin, Universitas Negeri Malang, Malang, Indonesia","2020 4th International Conference on Vocational Education and Training (ICOVET)","21 Oct 2020","2020","","","97","100","Progress in the industrial world has reached industry 4.0, in this progress it has led to the development of education as well as entering the era of education 4.0. One of the advances in the era of education 4.0 is the Augmented Reality learning media. The purpose of the study was to test the effectiveness of the effects of Augmented Reality Learning media that are in line with the needs of current and future students, the ARTorque application product as an interactive learning innovation to improve the learning outcomes of SMK students. The Quasi Experiment research design with steps: Determination of the experimental and control class, Instrument Testing, The experimental class was given the treatment of Augmented Reality learning media and the control class was not given treatment and used conventional learning. Output results obtained are normality test, homogeneity test and t test results.","","978-1-7281-8131-8","10.1109/ICOVET50258.2020.9229922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229922","Impact;Learning Media;Augmented Reality;Learning Outcomes","Media;Augmented reality;Industries;Technological innovation;Distributed databases;Electronic learning;Training","augmented reality;computer aided instruction;educational courses;multimedia computing;vocational training","interactive learning innovation;augmented reality learning media;conventional learning;enhanced vocational school learning outcome;SMK student;normality test;homogeneity test;t test;Industry 4.0;Education 4.0","","2","","9","IEEE","21 Oct 2020","","","IEEE","IEEE Conferences"
"Development of Interactive Mobile Application with Augmented Reality for Tourism Sites in Batam","R. E. Saragih; Suyoto","Department of Informatics, Universitas Atma Jaya Yogyakarta, Yogyakarta, Indonesia; Department of Informatics, Universitas Atma Jaya Yogyakarta, Yogyakarta, Indonesia","2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)","1 Oct 2020","2020","","","512","517","Batam is one of the tourist destinations in Indonesia, with the arrival of foreign tourists' numbers, reaches above one million. The COVID-19 pandemic brings a negative impact on tourism in Indonesia, including Batam. The focus of this study is to propose an interactive mobile application and Augmented Reality for tourism sites in Batam. The interactive mobile app uses the marker-based Augmented Reality and provides information and map of tourism sites in Batam. This study utilizes the Android Studio to develop the mobile application prototype, Kudan AR SDK for the Augmented Reality, and Adobe XD to create the interface design. The target users of this interactive application are foreign tourists as well as local tourists. The Augmented Reality provides interactive participation of visitors in the tourism site. The proposed mobile apps expect to be an approach of new normal in the tourism sector after the COVID-19 pandemic in Batam.","","978-1-7281-6823-4","10.1109/WorldS450073.2020.9210300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210300","COVID-19;Mobile Application;Augmented Reality;Tourism","Augmented reality;Mobile applications;Industries;Urban areas;Prototypes;Government;Smart phones","augmented reality;mobile computing;travel industry","tourism site;Batam;mobile application prototype;interactive application;foreign tourists;local tourists;mobile apps;tourism sector;COVID-19 pandemic;interactive mobile application;tourist destinations;Indonesia;interactive mobile app;marker-based augmented reality;Kudan AR SDK","","2","","23","IEEE","1 Oct 2020","","","IEEE","IEEE Conferences"
"Application of contextual QR codes to augmented reality technologies","F. Gutiérrez; M. A. Abud; F. Vera; J. A. Sánchez","División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Veracruz, Mexico; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Veracruz, Mexico; Laboratory of Interactive and Cooperative Technologies, Universidad de las Américas Puebla, Puebla, Mexico; Laboratory of Interactive and Cooperative Technologies, Universidad de las Américas Puebla, Puebla, Mexico","CONIELECOMP 2013, 23rd International Conference on Electronics, Communications and Computing","13 Jun 2013","2013","","","264","269","Augmented reality is a technology that involves digital content deployed in the physical world in real time through the use of devices and sensors that allow users to interact with the resulting hybrid environment. Likewise, QR codes have become popular and accepted by the general public. They are useful for conveying information in the physical world and thus connect to the digital world in a practical and simple way. This paper presents an application of QR codes for generating augmented reality environments. Using the notion of contexts, a complete user interaction is enabled in terms of the relationship of QR codes and augmented reality. We present an analysis of augmented reality technologies supported by this approach as well as the architecture and operation of a system that implements these concepts.","","978-1-4673-6155-2","10.1109/CONIELECOMP.2013.6525798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525798","Contextual QR Code;Augmented Reality;Ubiquitous computing","Augmented reality;Context;XML;Hardware;Real-time systems;Software;Uniform resource locators","augmented reality;codes;human computer interaction","contextual QR codes;augmented reality technologies;digital content;digital world;complete user interaction","","2","2","17","IEEE","13 Jun 2013","","","IEEE","IEEE Conferences"
"School of the Future: Using Augmented Reality for Contextual Information and Navigation in Academic Buildings","S. Vert; R. Vasiu","Faculty of Electronics and Telecommunications, Polytechnic University of Timisoara, Timisoara, Romania; Faculty of Electronics and Telecommunications, Polytechnic University of Timisoara, Timisoara, Romania","2012 IEEE 12th International Conference on Advanced Learning Technologies","16 Aug 2012","2012","","","728","729","This paper is a brief presentation of augmented reality solutions. Augmented reality is nowadays used in various domains with incipient but spectacular results. We question the implementation of augmented reality applications for smartphones designed to help students retrieve contextual information and navigate inside campuses and buildings. We present the research methodology and the expected contributions and results.","2161-377X","978-1-4673-1642-2","10.1109/ICALT.2012.156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268239","augmented reality;learning spaces;indoor navigation","Augmented reality;Educational institutions;Smart phones;Buildings;Global Positioning System;Libraries","augmented reality;educational institutions;information retrieval;smart phones","school;navigation;academic buildings;augmented reality solutions;smartphones;contextual information retrieval;campuses","","2","","6","IEEE","16 Aug 2012","","","IEEE","IEEE Conferences"
"Machine Maintenance Using Augmented Reality","K. Sabarinathan; N. Kanagasabapathy; V. D. Ambeth Kumar; P. K. Rishikesh; R. V. Priyadharshan; A. Abirami","Associate Software Engineer, Accenture, Chennai; Associate Software Engineer, Accenture, Chennai; Panimalar Engineering College, Chennai, Tamil Nadu, IN; Panimalar Engineering College, Chennai, Tamil Nadu, IN; Panimalar Engineering College, Chennai, Tamil Nadu, IN; Panimalar Institute of Technology, Chennai, Tamil Nadu, IN","2018 3rd International Conference on Communication and Electronics Systems (ICCES)","30 May 2019","2018","","","613","618","Augmented Reality is a technology which can superimpose 2D or 3D objects in real time for users view. Augmented Reality for maintenance is solely for reducing the time required for maintenance operation. The user of the system has to point his Smartphone camera over the machine and the image is recognized and then the user can view the details of the machine. Then the components of the machine are labeled in real time and the user views demo videos in real time if required. The main aim of this system is to make maintenance operation easier and to reduce the cost of the operation. Due to the intervention of Augmented Reality in a maintenance operation, the cost and the time required for maintenance is reduced and the intractability and the work efficiently is increased.","","978-1-5386-4765-3","10.1109/CESYS.2018.8723900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723900","Machine maintenance;Augmented Reality;Mobile Solution","Maintenance engineering;Augmented reality;Task analysis;Real-time systems;Image recognition;Training;Videos","augmented reality;image recognition;maintenance engineering;production engineering computing;smart phones","machine maintenance;maintenance operation;smartphone camera;augmented reality","","1","","10","IEEE","30 May 2019","","","IEEE","IEEE Conferences"
"Mobile Application for Visualization of the Advertising Booklet Using Augmented Reality","N. G. Babak; A. F. Kryukov","National Research University «Moscow Power Engineering Institute», Moscow, Russia; National Research University «Moscow Power Engineering Institute», Moscow, Russia","2018 IV International Conference on Information Technologies in Engineering Education (Inforino)","20 Dec 2018","2018","","","1","4","The article provides a comparative analysis of the platforms of augmented reality, the choice of environment and means for the implementation of a mobile application for visualization of the advertising booklet of the National Research University “Moscow Power Engineering Institute”. The booklet is refined to apply for it modern technology of augmented reality. The features of the implemented mobile application are shown. Using modern technology augmented reality will make it more attractive to work with applicants.","","978-1-5386-5832-1","10.1109/INFORINO.2018.8581841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8581841","augmented reality;mobile application;cross-platform engine Unity;advertising booklet;target","Augmented reality;Mobile applications;Three-dimensional displays;Cameras;Smart phones;Power engineering;Watermarking","advertising;augmented reality;data visualisation;mobile computing;power engineering","advertising booklet;National Research University;augmented reality;mobile application;Moscow Power Engineering Institute","","1","","11","IEEE","20 Dec 2018","","","IEEE","IEEE Conferences"
"Stereoscopic Augmented Reality for Single Camera Endoscope Using Optical Tracker: A Study on Phantom","A. Kumar; Y. -Y. Wang; K. -C. Liu; S. -W. Huang; W. -N. Lie; C. -C. Huang","Department of Medical Imaging, IRCAD, Changhua, Taiwan; Department of Medical Imaging, IRCAD, Changhua, Taiwan; Department of Medical Imaging, IRCAD, Changhua, Taiwan; Department of Medical Imaging, IRCAD, Changhua, Taiwan; Department of Electrical Engineering, National Chung Cheng University, Taiwan; Department of Electrical Engineering, National Chung Cheng University, Taiwan","2015 Third International Conference on Robot, Vision and Signal Processing (RVSP)","4 Feb 2016","2015","","","55","58","Introduction: Endoscopic surgery causes reduced injury to tissues which helps in rapid recovery and less painful post-operative period of patients. However, its narrow field of view and loss of depth perception in endoscope image make surgeon's task difficult. Moreover, in endoscopic surgery surgeons can only see the surface of the surgical anatomy. In this study these limitations have been addressed with the development of an augmented reality system with 3D visualization. Method: The system is comprising of infrared based optical tracker, 2D endoscope system, computer and a 3D monitor. The system was calibrated to bring all the components to a single reference frame of the optical tracker. A phantom and its 3D CT model were used, respectively, to form the real and virtual part of the augmented reality. The endoscope camera position was tracked in 3D using a tracker tool mounted on it. The camera in the virtual environment was updated with the new positions of the endoscope camera. The endoscope video frame and the virtual model rendered image were superimposed to form augmented reality view. The depth map of the virtual scene was further used to make an stereo pair of the augmented reality. Results: The AR system was examined with endoscope video of phantom. It could produce well aligned real and virtual component. The contour different of the two components was 5 to 10 mm. Conclusion: An AR system for endoscopic surgery was successfully implemented on a phantom. It needs to include motion and deformation model to be applied on real patients.","2376-9807","978-1-4673-9647-9","10.1109/RVSP.2015.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399146","endoscopic surgery;augmented reality;stereo endoscopy","Endoscopes;Cameras;Surgery;Three-dimensional displays;Augmented reality;Visualization;Solid modeling","augmented reality;data visualisation;endoscopes;infrared imaging;medical image processing;optical tracking;phantoms;rendering (computer graphics);stereo image processing;surgery","stereoscopic augmented reality;single camera endoscope;phantom;endoscopic surgery;3D visualization;infrared based optical tracker;2D endoscope system;3D CT model;endoscope camera position tracking;endoscope video frame;virtual model rendered image;virtual scene depth map","","1","","10","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"Teaching Marker-based Augmented Reality in a PBL Based Online Robotics Competition","A. Sarkar; K. Arya","Department of Computer Science & Engineering, Indian Institute of Technology Bombay, Powai Mumbai, India; Department of Computer Science & Engineering, Indian Institute of Technology Bombay, Powai Mumbai, India","2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)","4 Aug 2020","2020","","","338","340","e-Yantra is a robotics outreach project funded by MHRD, Govt of India, and hosted at IIT Bombay. It organizes e-Yantra Robotics Competition (eYRC), an annual robotics competition that teaches robotics concepts scalably to college students. Last year 34500+ students registered in the competition out of which 800 students participated in a theme called “Thirsty Crow” which taught augmented reality concepts. In this paper, we illustrate how “project-based learning” may be used to teach complex skills in a “game-like” context. We demonstrate how we designed, experimented and implemented the concepts of “Marker Based Augmented Reality” using open source technologies such as OpenCV, OpenGL, and Blender. We demonstrate in this paper that the average completion rate of our theme (which is essentially a hardware-based MOOC) is 11% which is greater than the overall average completion rate of all themes in eYRC-2018 (which is 6.2%). Our work is useful to anyone wishing to incorporate augmented reality in teaching courses, generally in the area of computer science.","2161-377X","978-1-7281-6090-0","10.1109/ICALT49669.2020.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155685","Project Based Learning (PBL);Online Competition;Robotics Competition;eYRC;e-Yantra;Augmented Reality","Task analysis;Robots;Augmented reality;Three-dimensional displays;Education;Software;Solid modeling","augmented reality;computer aided instruction;control engineering computing;control engineering education;educational courses;educational institutions;educational robots;engineering education;student experiments;teaching","average completion rate;teaching courses;robotics outreach project;IIT Bombay;e-Yantra Robotics Competition;annual robotics competition;robotics concepts;college students;Thirsty Crow;open source technologies;marker based augmented reality teaching;hardware-based MOOC;online robotics competition;OpenCV;OpenGL;Blender","","1","","8","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Experiencing Augmented Reality in Power Engineering Education","I. Opriș; S. Costinaș; C. S. Ionescu; D. E. G. Nistoran","Universitatea din Bucuresti, Bucuresti, RO; Universitatea din Bucuresti, Bucuresti, RO; Universitatea din Bucuresti, Bucuresti, RO; Universitatea din Bucuresti, Bucuresti, RO","2019 11th International Symposium on Advanced Topics in Electrical Engineering (ATEE)","30 May 2019","2019","","","1","6","Augmented Reality is one of the emerging technologies with promising results in engineering education. While increasing the learning commitment and motivation, additional information is available and interdisciplinary links with connected domains are easier. Especially within laboratory experiments, augmented reality may show views of inner or unapproachable devices, field views, equipment handling and support lab experiments with guidance and supplementary information. The paper presents the results of the first stage implementation of Augmented Reality within laboratories in the field of power engineering. The feedback survey showed that students consider Augmented Reality to be a useful tool, best suited to allow a closer connection to practice and a faster learning for the lab work.","2159-3604","978-1-7281-0101-9","10.1109/ATEE.2019.8724992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8724992","augmented reality;education;power engineering;lab work","Power engineering;Visualization;Augmented reality;Videos;Power engineering education","augmented reality;computer aided instruction;power engineering education","augmented reality;power engineering education","","1","","15","IEEE","30 May 2019","","","IEEE","IEEE Conferences"
"Augmented Reality Musical Service Part 1 for Non-face-to-face Watching by Multiple Audiences","Y. -S. Yoon; H. Cho; C. Park; S. Park","Content Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea; Content Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea; Content Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea; Content Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea","2021 Twelfth International Conference on Ubiquitous and Future Networks (ICUFN)","13 Sep 2021","2021","","","219","224","We propose an augmented reality(AR) musical service in which virtual actors perform on the stage of the real world, even if actors and audiences do not meet. The AR musical service proposed in this paper applied augmented reality technology using an AR platform we are developing. Here, part 1 of the augmented reality musical service is defined as the main performance of the augmented reality based musicals. First, we generated a map of a real stage space in the real world that can provide non-face-to-face musicals using AR technology. In addition, we created an AR application that can show virtual actors, their performance, their songs, and virtual stage props and effects appearing in the proposed AR musical service. Finally, we used AR technology to allow multiple audiences to enjoy the proposed AR musical service together in the stage space of the real world. In this paper, it was possible to confirm whether multiple audiences could watch the proposed AR musical service together in which the virtual actors perform on a real stage as if it were real musicals.","2165-8536","978-1-7281-6476-2","10.1109/ICUFN49451.2021.9528585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528585","Augmented Reality(AR);Musicals;AR Musical Service;Multiple Audiences;Virtual Actor","Music;Augmented reality","augmented reality;music","nonface-to-face watching;multiple audiences;virtual actors;AR musical service;stage space;nonface-to-face musicals;virtual stage props;augmented reality musical service;AR technology","","","","14","IEEE","13 Sep 2021","","","IEEE","IEEE Conferences"
"Registered Localization Method-based on OpenCV for Augmented Reality","J. Dai; L. -f. Zhang","College of Information Science and Technology, Jiujiang University, Jiujiang, China; College of Information Science and Technology, Jiujiang University, Jiujiang, China","2011 International Conference of Soft Computing and Pattern Recognition (SoCPaR)","1 Dec 2011","2011","","","492","495","Augmented Reality is a kind of technique combining a virtual world with a real environment. This paper tells that OpenCV is applied to the realization of Registration Technique which is key to Augmented Reality. It studies the implementation of the camera calibration, the extraction of characteristic target and its recognition. This paper improved the efficiency of the exploitation and laid a foundation for the exploitation and application of Augmented Reality.","","978-1-4577-1196-1","10.1109/SoCPaR.2011.6089144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6089144","Augmented Reality;OpenCV;registration;calibration;Object Extraction","Feature extraction;Cameras;Augmented reality;Calibration;Target recognition;Lenses;Computer vision","augmented reality;cameras;computer vision;image registration","registered localization method;OpenCV;augmented reality;virtual world;real environment;registration technique;camera calibration","","","","11","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"A Framework for Risk Assessment in Augmented Reality-Equipped Socio-Technical Systems","S. Sheikh Bahaei","School of Innovation, Malardalen University, Vasteras, Sweden","2020 50th Annual IEEE-IFIP International Conference on Dependable Systems and Networks-Supplemental Volume (DSN-S)","5 Aug 2020","2020","","","77","78","New technologies, such as augmented reality (AR) are used to enhance human capabilities and extend human functioning; nevertheless they may cause distraction and incorrect human functioning. Systems including socio entities (such as human) and technical entities (such as augmented reality) are called socio-technical systems. In order to do risk assessment in such systems, considering new dependability threats caused by augmented reality is essential, for example failure of an extended human function is a new type of dependability threat introduced to the system because of new technologies. In particular, it is required to identify these new dependability threats and extend modeling and analyzing techniques to be able to uncover their potential impacts. This research aims at providing a framework for risk assessment in AR-equipped socio-technical systems by identifying AR-extended human failures and AR-caused faults leading to human failures. Our work also extends modeling elements in an existing metamodel for modeling socio-technical systems, to enable AR-relevant dependability threats modeling. This extended metamodel is expected to be used for extending analysis techniques to analyze AR-equipped socio-technical systems.","","978-1-7281-7260-6","10.1109/DSN-S50200.2020.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159164","augmented reality, immersive visual technology, socio-technical systems, risk assessment, safety modeling","Sociotechnical systems;Augmented reality;Taxonomy;Risk management;Safety;Analytical models;Visualization","augmented reality;human factors;risk analysis;risk management;security of data;socio-economic effects","technical entities;risk assessment;dependability threat;extended human function;AR-equipped socio-technical systems;AR-extended human failures;AR-relevant dependability threats;augmented reality-equipped socio-technical systems;human capabilities","","","","12","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Research on Interactive Design of Tourism Brand Based on Augmented Reality Technology","G. Juan; H. Xiaoli","School of Art and Design, Wuhan University of Technology Xiamen University Tan Kah Kee College, Wuhan, Zhangzhou, China, china; School of Humanities and Communication, Xiamen University Tan Kah Kee College, Zhangzhou, China","2021 International Symposium on Computer Technology and Information Science (ISCTIS)","19 Nov 2021","2021","","","36","39","This thesis researches how the interactive design rebranding tourism brands. It proposes the use of augmented reality cascading technology and multi-dimensional information display technology to sort out human information, geographic information, ecological information, cultural traditions and other information for tourist destinations, and finally use Professional development technology displays this information in a visual design. This study mainly discusses from three aspects: 1. Augmented reality technology enables tourism interactive experience to realize the transformation from surface to three-dimensional; 2. Augmented reality technology enhances the versatility of travel interaction; 3. Augmented reality technology optimizes the visitor experience of digital travel, thus driving the transformation of travel brands and realizing the new mode of tourism interaction and integration.","","978-1-6654-1441-8","10.1109/ISCTIS51085.2021.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9603435","Augmented reality technology;Tourism brand;Interactive experience","Visualization;Information science;Globalization;Immersive experience;Cultural differences;Augmented reality","augmented reality;geographic information systems;human computer interaction;interactive systems;travel industry;user experience","tourism brand;interactive design;augmented reality cascading technology;multidimensional information display technology;human information;geographic information;ecological information;tourism interactive experience;tourism interaction;professional development technology displays;cultural traditions;travel interaction","","","","12","IEEE","19 Nov 2021","","","IEEE","IEEE Conferences"
"Large scale treasure hunt games assisted by an augmented reality system","G. Felgueiras; J. Fonseca; P. M. Moreira","DEI-Departamento de Engenharia Informática, Universidade do Minho, Braga, Portugal; DEI-Departamento de Engenharia Informática, Universidade do Minho, Braga, Portugal; Universidade do Porto, Porto, Porto, PT","2013 8th Iberian Conference on Information Systems and Technologies (CISTI)","17 Oct 2013","2013","","","1","4","This paper presents and describes the implementation of an augmented reality system to assist a user in a treasure hunt gaming activity. The concept proposed here, essentially serves to support a practitioner of a form of territorial exploitation. The case study applies to global scale territories where a large number of `treasures' are hidden in different locations for a subsequent hunt. The developed application provides two modules of augmented reality, one based on GPS coordinates provided by the current smartphones, the other in the extraction of additional information of treasure. This extraction uses two-dimensional quick response codes (QR Code), to serve two purposes; provide additional information to the treasure hunt be used as a augmented reality marker. The results are quite encouraging thus enabling the continuation of this project in the near future.","2166-0727","978-989-98434-0-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6615885","Augmented Reality;Geocaching;QR Code;Treasure Hunting Games;Mobile Computing","Global Positioning System;Augmented reality;Smart phones;Visualization;Androids;Humanoid robots;Games","augmented reality;computer games;Global Positioning System;smart phones","large scale treasure hunt games;augmented reality system;territorial exploitation;global scale territories;GPS coordinates;smartphones;treasure information extraction;two-dimensional quick response codes;QR code","","","","11","","17 Oct 2013","","","IEEE","IEEE Conferences"
"Implementation of Augmented Reality in Ablution Learning Based on Android","Y. Syarofi; A. J. P. Sibarani","Information Technology Department, Universitas Budi Luhur, Jakarta, Indonesia; Information Technology Department, Universitas Budi Luhur, Jakarta, Indonesia","2020 International Conference on Information Management and Technology (ICIMTech)","2 Oct 2020","2020","","","11","16","This study discusses the development of Augmented Reality technology in ablution procedures that can be useful in children's education. The use of Augmented Reality is expected to be able to attract interest in learning and add insight to children in terms of introducing the procedures for ablution to be more effective. This Augmented Reality application uses the Marker Based Tracking method. This method was chosen because it is able to read objects that will later bring up 3-dimensional virtual objects from the procedures for ablution. The initial step in solving this problem is done by making animations using the Blender application, then determining the image that will be used as a Marker and then exported to Unity to become an Augmented Reality application for ablution procedures. The testing method used on the implementation of this application is to use ISO 9126 and a questionnaire with a total of 10 respondents. Based on the results of tests that have been carried out based on functionality, reliability, usability, and efficiency tests, it shows that the application is going well and 88% of respondents said they were satisfied with the benefits of the application of the ablution procedure.","","978-1-7281-7071-8","10.1109/ICIMTech50083.2020.9211168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9211168","augmented reality;marker;ablution","Augmented reality;Education;Cameras;Testing;Three-dimensional displays;Information technology;Lighting","augmented reality;computer aided instruction;computer animation;ISO standards;mobile computing","ablution learning;children education;augmented reality;3-dimensional virtual objects;blender application;Android;marker based tracking;animations;ISO 9126","","","","16","IEEE","2 Oct 2020","","","IEEE","IEEE Conferences"
"Training System for Endoscopic Surgery by Using Augmented Reality and Forceps Control Devices","T. Tokuyasu; W. Okamura; T. Kusano; M. Inomata; N. Shiraishi; S. Kitanou","Dept. of Information and Systems Engineering, Fukuoka Institute of Technology, Fukuoka, Japan; Dept. of Information and Systems Engineering, Fukuoka Institute of Technology, Fukuoka, Japan; Dept. of Gastroenterological and Pediatric Surgery, Oita University Oita, Japan; Dept. of Gastroenterological and Pediatric Surgery, Oita University Oita, Japan; Dept. of Gastroenterological and Pediatric Surgery, Oita University Oita, Japan; Oita Daigaku, Oita, JP","2014 Ninth International Conference on Broadband and Wireless Computing, Communication and Applications","22 Jan 2015","2014","","","541","544","Endoscopic surgery is one of minimally invasive medical treatments, which reduces both physical and mental burdens of a patient than conventional abdominal operations. At present, a variety of training environments for endoscopic surgery, such as a dry box, a virtual reality (VR) simulator, and an animal experiment have been prepared to cultivate certifying physicians of endoscopic surgery. Even now, more effective training environments have been requested from the surgeons. Thus, this study proposes an application of augmented reality to establish a novel training environment of endoscopic surgery. We focused on one of Japanese learning styles in writing, in which children repeatedly trace the letters written on a sheet in order to learn how to use a pencil to write neatly without concerning the meanings of the letters. This study applies this learning style to our training system by using a dry box and augmented reality (AR). In our training system, AR Toolkit is utilized to describe a target trajectory which is displayed on a monitor and is refereed by a trainee. And we originally develops the devices which detect the motions of endoscopic forceps while training. This paper introduces the basic constitution of our training system and discusses about the training effects obtained from the experimental results with beginner subjects.","","978-1-4799-4173-5","10.1109/BWCCA.2014.113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7016131","Augmented reality;endoscopic surgery;surgical simulator;medical education","Training;Surgery;Trajectory;Cameras;Augmented reality;Animals","augmented reality;computer based training;endoscopes;medical computing;surgery","training system;endoscopic surgery;augmented reality;forceps control devices;minimally invasive medical treatments;conventional abdominal operations;virtual reality simulator;animal experiment;Japanese learning styles;AR Toolkit;target trajectory;monitor;endoscopic forceps","","6","","5","IEEE","22 Jan 2015","","","IEEE","IEEE Conferences"
"Props Alive: A Framework for Augmented Reality Stop Motion Animation","L. Casas; M. Kosek; K. Mitchell",Edinburgh Napier University; Edinburgh Napier University; Edinburgh Napier University,"2017 IEEE 10th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS)","1 Sep 2020","2017","","","1","4","Stop motion animation evolved in the early days of cinema with the aim to create an illusion of movement with static puppets posed manually each frame. Current stop motion movies introduced 3D printing processes in order to acquire animations more accurately and rapidly. However, due to the nature of this technique, every frame needs to be computer-generated, 3D printed and post-processed before it can be recorded. Therefore, a typical stop motion film could require many thousands of props to be created, resulting in a laborious and expensive production. We address this with a real-time interactive Augmented Reality system which generates virtual in-between poses according to a reduced number of key frame physical props. We perform deformation of the surface camera samples to accomplish smooth animations with retained visual appearance and incorporate a diminished reality method to allow virtual deformations that would, otherwise, reveal undesired background behind the animated mesh. Underpinning this solution is a principled interaction and system design which forms our Props Alive framework. We apply established models of interactive system design, drawing from an information visualisation framework which, appropriately for Augmented Reality, includes consideration of the user, interaction, data and presentation elements necessary for real-time. The rapid development framework and high performance architecture is detailed with an analysis of resulting performance.","2328-7829","978-1-5386-6274-8","10.1109/SEARIS41720.2017.9183487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183487","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation;I.3.8 [Computer Graphics]: Applications","Real-time systems;Animation;Augmented reality;Strain;Cameras;Feeds;Three-dimensional displays","augmented reality;computer animation;data visualisation","static puppets;3D printing processes;key frame physical props;visual appearance;diminished reality method;virtual deformations;animated mesh;interactive system design;information visualisation;Props Alive;real-time interactive augmented reality system;stop motion film;stop motion movies;stop motion animation;virtual in-between poses;surface camera samples","","3","","7","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Data-driven augmented reality display and operations for UAV ground stations","X. Ji; X. Xiang; T. Hu","College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; College of Mechatronics and Automation, National University of Defense Technology, Changsha, China","2017 6th Data Driven Control and Learning Systems (DDCLS)","16 Oct 2017","2017","","","557","560","The commonly used 2D Display is limited in aiding operators to control unmanned aerial vehicles (UAVs) within complex environments, due to its weak immersion. This paper proposes a data-driven 3D augmented reality approach. Pre-known data and experience can be integrated into to constructing a 3D virtual scenario. Furthermore, the on-board sensor data is continuously updated to this scenario during the task process. Under such circumstance, the static scenario and dynamic data are fused together by using the UAV's position and orientation. Task-associated information, e.g. route points and flying status, is simultaneously imported into the scenario to augment the virtual reality and to support the operator as well. Eventually, the AR ground station prototype is designed and implemented. Experimental results of quad rotors demonstrate that the developed system is feasible and effective to strengthen immersion with the virtual reality glasses.","","978-1-5090-5461-9","10.1109/DDCLS.2017.8068132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8068132","Data-driven;Augmented reality (AR);Unmanned aerial vehicle (UAV);Ground station","Unmanned aerial vehicles;Cameras;Augmented reality;Virtual environments;Real-time systems","aerospace control;augmented reality;control engineering computing;mobile robots;remotely operated vehicles;telerobotics","complex environments;weak immersion;3D augmented reality approach;3D virtual scenario;on-board sensor data;dynamic data;UAV's position;route points;flying status;AR ground station prototype;virtual reality glasses;UAV ground stations;commonly used 2D Display;aiding operators;unmanned aerial vehicles","","3","","8","IEEE","16 Oct 2017","","","IEEE","IEEE Conferences"
"Innovative augmented reality system for automotive assembling processes and maintenance: An entrepreneurial case at Tec de Monterrey","E. G. Mendívil; R. E. N. Solís; H. Ríos","Instituto Tecnológico y de Estudios Superiores de Monterrey, Monterrey, Nuevo Leon, Mexico; Instituto Tecnológico y de Estudios Superiores de Monterrey, Monterrey, Nuevo Leon, Mexico; Instituto Tecnológico y de Estudios Superiores de Monterrey, Monterrey, Nuevo Leon, Mexico","2013 15th International Conference on Transparent Optical Networks (ICTON)","19 Sep 2013","2013","","","1","4","Augmented Reality (AR) is a particularly fascinating field due to its innovative technology that allows a person to experience the sensation of living in a computer-generated environment. AR integrates Virtual Reality (VR) into the real-world, enhancing the users experience with the objects surrounding them in real-time. A state-of-the-art technique is presented in this paper, implemented by students in the Business Incubator from Tecnológico de Monterrey with the collaboration of experts and supported by the Research Chair at Campus Monterrey. This paper presents an interactive instructions manual using AR, which will guide the user through the assembly or disassembly of a car engine. The use of augmented reality in manufacturing activities, especially in the automotive industry, increases the productivity by the simulation of parts undergoing their manufacturing process, reducing the need to create physical prototypes. This article describes the way entrepreneurs explore new technologies, using the resources available at the R&D department, to develop an AR system for the assembly of a monobloc engine. A bright future is perceived for life enhancing AR systems. Industrial applications could vary from engine systems, as presented in this paper, to medical or aerospace training programs, imagination is the limit.","2161-2064","978-1-4799-0683-3","10.1109/ICTON.2013.6602689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6602689","Augmented Reality;digital instructions manual;car engine;assembly;disassembly;entrepreneurship;innovation","Assembly;Augmented reality;Business;Manuals;Engines;Pistons;Automotive engineering","assembling;augmented reality;automobile industry;automobile manufacture;automobiles;automotive engineering;computer aided instruction;human computer interaction;internal combustion engines;maintenance engineering;mechanical engineering computing;production engineering computing;user interfaces","innovative augmented reality system;automotive assembling processes;automotive assembling maintenance;entrepreneurial case;Tec de Monterrey;innovative technology;computer-generated environment;virtual reality;Business Incubator;Tecnológico de Monterrey;Research Chair;Campus Monterrey;car engine assembly;car engine disassembly;interactive instructions manual;manufacturing activities;automotive industry;manufacturing process;R&D department;AR systems","","","","7","IEEE","19 Sep 2013","","","IEEE","IEEE Conferences"
"Bridging the Gap Across Realities: Visual Transitions Between Virtual and Augmented Reality","F. Pointecker; J. Friedl; D. Schwajda; H. -C. Jetter; C. Anthes","University of Applied Sciences, Upper Austria; University of Applied Sciences, Upper Austria; University of Applied Sciences, Upper Austria; University of Lübeck; University of Applied Sciences, Upper Austria","2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","27 Dec 2022","2022","","","827","836","Cross-Virtuality applications enabling users to move between different stages of Milgram’s reality-virtuality continuum are a rapidly growing field of research. Modern video see-through head-mounted displays allow users to switch between augmented and virtual reality without removing the headset. This enables for the first time a fluent transition between augmented and virtual reality. Based on insights from literature and preliminary experiments we designed and implemented four transitions: Fade, SimpleCut, TeleportBeam and Portal. These techniques were expected to represent the best suitable concepts for transitioning seamlessly between augmented and virtual reality. After incorporating results from a pre-study, the transition techniques were evaluated in a qualitative user study regarding user experience, simulator sickness, continuity and applicability. Participants were able to freely move between both realities during the study in an immersive analytics scenario for logistics data. In the user study, users preferred Fade in a workplace setting due to its efficiency and simplicity when transitioning frequently between realities. The Portal technique was deemed visually exciting and suitable for infrequent transitions between realities that differ greatly.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995285","Human-centered computing;Mixed / augmented reality;Virtual reality;User studies","Headphones;Visualization;Head-mounted displays;Employment;Switches;User experience;Haptic interfaces","augmented reality;data visualisation;helmet mounted displays;human computer interaction;user interfaces;virtual reality","augmented reality;Cross-Virtuality applications;fluent transition;Milgram's reality-virtuality continuum;qualitative user study;realities;transition techniques;virtual reality;visual transitions","","1","","53","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"Augmented assembly using a mobile phone","M. Hakkarainen; C. Woodward; M. Billinghurst","VTT Technical Research Center of Finland, Finland; VTT Technical Research Center of Finland, Finland; The HIT Laboratory New Zealand, University of Canterbury, New Zealand","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","167","168","We present a mobile phone based augmented reality (AR) assembly system that enable users to view complex models on their mobile phones. It is based on a client-server architecture, where complex model information is located on a PC, and a mobile phone with the camera is used as a thin client access device to this information. With this system users are able to see an AR view that provides step by step guidance for a real world assembly task. We also present results from a pilot user study evaluating the system, showing that people felt the interface was intuitive and very helpful in supporting the assembly task.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637349","","Assembly;Mobile handsets;Servers;Augmented reality;Maintenance engineering;Solid modeling;Software","assembling;augmented reality;mobile handsets","augmented assembly system;mobile phone based augmented reality;client-server architecture;complex model information;thin client access device;augmented reality view;assembly task","","46","1","9","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"SWAG Demo: Smart Watch Assisted Gesture Interaction for Mixed Reality Head-Mounted Displays","H. -i. Kim; J. Lee; H. -S. Yeo; A. Quigley; W. Woo","UVR Lab, KAIST, Republic of Korea; UVR Lab, KAIST, Republic of Korea; SACHI, University of St Andrews, Scotland, UK; SACHI, University of St Andrews, Scotland, UK; UVR Lab, KAIST, Republic of Korea","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","428","429","In this demonstration, we will show a prototype system with sensor fusion approach to robustly track 6 degrees of freedom of hand movement and support intuitive hand gesture interaction and 3D object manipulation for Mixed Reality head-mounted displays. Robust tracking of hand and finger with egocentric camera remains a challenging problem, especially with self-occlusion – for example, when user tries to grab a virtual object in midair by closing the palm. Our approach leverages the use of a common smart watch worn on the wrist to provide a more reliable palm and wrist orientation data, while fusing the data with camera to achieve robust hand motion and orientation for interaction.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699201","Augmented Reality;Wearable Computing;3D User Interfaces;Hand Interaction;Virtual 3D Object Manipulation;H.5.2 [Information Interfaces and Presentation]: User interfaces—Input interaction styles","Augmented reality","augmented reality;gesture recognition;helmet mounted displays;human computer interaction;image motion analysis;object tracking;sensor fusion;wearable computers","SWAG demo;smart watch assisted gesture interaction;sensor fusion approach;3D object manipulation;robust tracking;robust hand motion;finger tracking;intuitive hand gesture interaction;mixed reality head-mounted displays;robust hand movement tracking;egocentric camera;self-occlusion;palm orientation data;wrist orientation data","","1","","3","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Merging visible and invisible: two Camera-Augmented Mobile C-arm (CAMC) applications","N. Navab; A. Bani-Kashemi; M. Mitschke","Siemens Corporate Research, Inc., Princeton, NJ, USA; NA; Siemens AG Medical Engineering Group, Erlangen, Germany","Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99)","6 Aug 2002","1999","","","134","141","This paper presents the basic concept of CAMC and some of its applications. A CCD camera is attached to a mobile C-arm fluoroscopy X-ray system. Both optical and X-ray imaging systems are calibrated in the same coordinate system in an off-line process. The new system is able to provide X-ray and optical images simultaneously. The CAMC framework has great potential for medical augmented reality. We briefly introduce two new CAMC applications to the augmented reality research community. The first application aims at merging video images with a pre-computed tomographic reconstruction of the 3D volume of interest. This is a logical continuation of our work on 3D reconstruction using a CAMC (1999). The second approach is a totally new CAMC design where using a double mirror system and an appropriate calibration procedure the X-ray and optical images are merged in real-time. This new system enables the user to see an optical image, an X-ray image, or an augmented image where both visible and invisible are combined in real-time. The paper is organized in two independent sections describing each of the above. Experimental results are provided at the same time as the methods and apparatus are described for each section.","","0-7695-0359-4","10.1109/IWAR.1999.803814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=803814","","Merging;X-ray imaging;Biomedical optical imaging;Augmented reality;Image reconstruction;Real time systems;Charge coupled devices;Charge-coupled image sensors;Biomedical imaging;Tomography","augmented reality;medical image processing;X-ray imaging;CCD image sensors;computerised tomography;image reconstruction","Camera-Augmented Mobile C-arm;CAMC;CCD camera;mobile C-arm fluoroscopy X-ray system;X-ray imaging;optical imaging;coordinate system;medical augmented reality;augmented reality;video images;tomographic reconstruction;3D volume of interest;double mirror system;calibration procedure;real-time systems","","34","4","9","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"The ARC Display: an augmented reality visualization center","F. G. Hamza-Lup; L. Davis; J. P. Rolland","School of Electrical Engineering and Coniputer Science, University of Central Florida, Orlando, FL, USA; School of Electrical Engineering and Coniputer Science, University of Central Florida, Orlando, FL, USA; School of Electrical Engineering and Coniputer Science, University of Central Florida, Orlando, FL, USA","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","2 pp.","","The ARC Display represents a significant advancement towards our vision of wearable displays for multimodal augmented reality systems. The ARC Display currently provides a unique theatre for stereoscopic viewing of computer-generated objects. Moreover, users within the environment may be tracked using commercially available tracking systems. In our environment, we use custom designed probes built on the Polaris optical tracking system.","","0-7803-7680-3","10.1109/ART.2002.1106976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106976","","Displays;Augmented reality;Visualization;Optical design;Probes;Optical devices;Application software;Collaboration;Optical polarization;Eyes","augmented reality;data visualisation;computer displays;wearable computers;optical tracking","ARC Display;augmented reality visualization center;wearable displays;multimodal augmented reality systems;stereoscopic viewing;computer-generated objects;user tracking;custom designed probes;Polaris optical tracking system","","1","","6","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Implementing Augmented Reality Using OpenCV","D. S. Asanvitha Gundala; S. S. Alamuri; A. Firdaus; G. K. Kumar","Dept. of CSE, VR Siddhartha Engineering College(A), Vijayawada, India; Dept. of CSE, VR Siddhartha Engineering College(A), Vijayawada, India; Dept. of CSE, VR Siddhartha Engineering College(A), Vijayawada, India; Dept. of CSE, VR Siddhartha Engineering College(A), Vijayawada, India","2022 IEEE Delhi Section Conference (DELCON)","20 Apr 2022","2022","","","1","4","Continuous attempts have been made to make livelihood efficient and effortless. Augmented reality (AR) provides extra information to the user by applying virtual image onto the real environment. Augmenting the real world around us with computer-generated perceptual information can simplify the way we interact with our surroundings. This will help in comprehending concepts in an immersive environment. Thus, simplifying concepts and making learning, visualization and representation easy. People's ability to understand what they've learned could be enhanced by a combination of interactivity and engagement, resulting in rapid acquisition of information and skills. The ability to engage yourself in the data within our own comfortable surroundings, sharing and discussing the knowledge and visualization with others in the same room is not only a fantastic experience, but it also leads to an increased incentive to discuss the data with others. A three-dimensional image helps students understand abstract concepts. The paper deals with a proposed model that shall inculcate Marker detection algorithm for image projection on the target surface.","","978-1-6654-5883-2","10.1109/DELCON54057.2022.9753233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9753233","Image projection;Augmented Reality;Homography;ArUco Markers","IEEE Sections;Conferences;Data visualization;Detection algorithms;Augmented reality","augmented reality;computer aided instruction;computer graphics;data visualisation;virtual reality","three-dimensional image;image projection;augmented reality;OpenCV;continuous attempts;livelihood;virtual image;computer-generated perceptual information;immersive environment;simplifying concepts;visualization;comfortable surroundings","","","","13","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Towards Wireless Augmented Reality A Review of its Enabling Technologies","I. Lee","University of South Australia, Mawson Lakes, SA, Australia","2009 International Symposium on Ubiquitous Virtual Reality","4 Sep 2009","2009","","","25","28","Mixed and augmented reality is an emerging technology with growth popularities in recent years. This paper presents the challenges of designing next generation wireless devices to facilitate applications on mixed and augmented reality. A review of leading mobile system architecture, user interface, and communication protocols, are discussed in this paper. The review of current and previous research in the field provides the design guidelines for the future of ubiquitous augmented reality.","","978-1-4244-4437-3","10.1109/ISUVR.2009.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232248","","Augmented reality;Wearable computers;Handheld computers;Layout;Mobile computing;Video compression;Pervasive computing;Application software;Central Processing Unit;User interfaces","augmented reality;mobile computing;protocols;software architecture;user interfaces","wireless augmented reality;next generation wireless devices;mobile system architecture;user interface;communication protocols;ubiquitous augmented reality","","1","","22","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"Visual Longitudinal and Lateral Driving Assistance in the Head-Up Display of Cars","M. Tonnis; C. Lange; G. Klinker","Fakultät für Informatik, Technische Universität München, Munich, Germany; Fakultät für Informatik, Technische Universität München, Munich, Germany; Fakultät für Informatik, Technische Universität München, Munich, Germany","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","91","94","Most car accidents occur due to longitudinal collisions or lane departure. We assume that the number of such accidents can be reduced, if the driver knows more precisely, where the car is heading and at which distance it can stop. To provide drivers with this kind of anticipation, we have developed two augmented reality based visualization schemes for longitudinal and lateral driver assistance in the head-up display (HUD) of cars. One presentation scheme indicates the braking distance by a virtual bar on the road. The second scheme adds the visualization of a drive-path between the car and the bar, zoning the entire region that the car will pass before coming to a complete halt. We have tested both schemes in a driving simulator in comparison to a baseline without visual assistance. Our results show, among other findings, that the bar is preferred, that it supports driving performance and that it does not increase mental workload.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538831","Augmented Reality;Mixed Reality;Head-Up Display;Usability;Advanced Driver Assistance Systems;Human Factors","Displays;Road accidents;Driver circuits;Visualization;Augmented reality;Testing;Traffic control;Virtual reality;Usability;Human factors","augmented reality;computer vision;data visualisation;driver information systems","lateral driving assistance;visual longitudinal driving assistance;head-up display;longitudinal collisions;augmented reality;visualization schemes","","55","1","12","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Do You Know What I Mean? An MR-Based Collaborative Platform","P. Wang; S. Zhang; X. Bai; M. Billinghurst; W. He; L. Zhang; J. Du; S. Wang","Cyber-Physical Interaction Lab., Northwestern Polytechnical University; Cyber-Physical Interaction Lab., Northwestern Polytechnical University; Cyber-Physical Interaction Lab., Northwestern Polytechnical University; Cyber-Physical Interaction Lab., Northwestern Polytechnical University; Cyber-Physical Interaction Lab., Northwestern Polytechnical University; Cyber-Physical Interaction Lab., Northwestern Polytechnical University; Cyber-Physical Interaction Lab., Northwestern Polytechnical University; Cyber-Physical Interaction Lab., Northwestern Polytechnical University","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","77","78","The Mixed Reality (MR) technology can be used to create unique collaborative experiences. In this paper, we propose a new remote collaboration platform using MR and eye-tracking that enables a remote helper to assist a local worker in an assembly task. We present results from research exploring the effect of sharing virtual gaze and annotations cues in an MR-based projector interface for remote collaboration. The key advantage compared to other remote collaborative MR interfaces is that it projects the remote expert's eye gaze into the real worksite to improve co-presence. The prototype system was evaluated with a pilot study comparing two conditions: POINTER and ET (eye-tracker cues). We observed that the task completion performance was better in the ET condition. And that sharing gaze significantly improved the awareness of each other's focus and co-presence.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699227","Remote collaboration;Eye gaze;Augmented Reality;Mixed Reality;H.5.1 [User Experience Design]: Collaborative interfaces—Collaboration, augmented and virtual realities","Augmented reality","augmented reality;gaze tracking;groupware;object tracking;user interfaces;video signal processing;virtual reality","collaborative platform;unique collaborative experiences;remote collaboration platform;eye-tracking;remote helper;local worker;assembly task;virtual gaze;annotations cues;projector interface;remote collaborative MR interfaces;remote expert;eye-tracker cues;task completion performance;mixed reality technology;ET;POINTER;MR","","6","","6","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Architectural Model for VR and AR Applications in the Cloud","E. C. Freiberger; R. Nakamura; R. Tori","Departamento da Area de Informática, Instituto Federal de Mato Grosso - IFMT Interlab POLIIUSP, são Paulo, Brasil; Sistemas Digitais Escola Politécnica da USP Interlab POLIIUSP são Paulo, Brasil; Sistemas Digitais Escola Politécnica da USP Interlab POLIIUSP são Paulo, Brasil","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","280","283","Virtual and Augmented Reality are used in the production of complex virtual environments, using non-trivial input and output devices to provide users with a sense of immersion in real-time synthetic worlds. Consequently, the design and development of such applications becomes complex where the software component reuse is not an option, but rather a necessity to enable development. In this paper we present an architectural model for a platform for the production, sharing and implementation of Virtual and Augmented Reality applications called NRVA. In this work we present the description of the main elements of the proposed architectural model and preliminary results of the research. The results point to the feasibility of the proposed model.","","978-0-7695-5001-5","10.1109/SVR.2013.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655799","Virtual Reality;Augmented Reality;Service-Oriented Computing;Reuse","Computational modeling;Three-dimensional displays;Web 2.0;Augmented reality;Solid modeling;Middleware","augmented reality;cloud computing;service-oriented architecture","NRVA;software component reuse;complex virtual environment;augmented reality;virtual reality;cloud computing;AR application;VR application;architectural model","","","","13","IEEE","7 Nov 2013","","","IEEE","IEEE Conferences"
"Dimension of structural usability for Augmented Reality system","B. A. Talip","Faculty of Computing & Informatics, Multimedia University, Cyberjaya, Malaysia","2015 IEEE Conference on Open Systems (ICOS)","11 Jan 2016","2015","","","34","39","Augmented Reality (AR) was a result of scientist vision where earlier application was for composition of augmented image. Since 1960s, the development progression has been focused on improving accuracy in object registration. But people are often incapable of considering the long-term implications for using such technology thus jeopardize overall usability of AR in real world context. However, integration of AR with web 2.0 solutions has permit users to receive virtual information while viewing actual items within a frame of see-through display that has been ergonomically improved. Synthesized view of the real world with AR technology has been seen as futuristic interface for information acquisition. Therefore, this study has been performed to identify factors that affect usability of AR as everyday application prior to actual deployment and evaluation with AR related technology.","","978-1-4673-9434-5","10.1109/ICOS.2015.7377274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377274","Augmented Reality;Synthetic Experience;Information Acquisition;Augmented Information;Usability","Usability;Augmented reality;Context;Open systems;Imaging;Conferences;Subspace constraints","augmented reality;ergonomics;image registration;object detection","structural usability;augmented reality;AR system;image augmentation;object registration;ergonomics","","","","50","IEEE","11 Jan 2016","","","IEEE","IEEE Conferences"
"Integration of georegistered information on a virtual globe","Z. Ai; M. A. Livingston","3D Virtual and Mixed Environments Information Management and Decision Architectures, U.S. Naval Research Laboratory, Washington D.C., DC, USA; 3D Virtual and Mixed Environments Information Management and Decision Architectures, U.S. Naval Research Laboratory, Washington D.C., DC, USA","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","169","170","In collaborative augmented reality (AR) missions, much georegistered information is collected and sent to a command and control center. This paper describes the concept and prototypical implementation of a mixed reality (MR) based system that integrates georegistered information from AR systems and other sources on a virtual globe. The application can be used for a command and control center to monitor the field operation where multiple AR users are engaging in a collaborative mission. Google Earth is used to demonstrate the system, which integrates georegistered icons, live video streams from field operators or surveillance cameras, 3D models, and satellite or aerial photos into one MR environment.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336478","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems;Artificial, augmented, and virtual realities; H.5.3 [Information Interfaces and Presentation]: Group and Organization Interfaces;Computer-supported cooperative work","Virtual reality;Collaboration;Command and control systems;Augmented reality;Virtual prototyping;Earth;Streaming media;Surveillance;Cameras;Satellites","augmented reality;geographic information systems","georegistered information integration;virtual globe;collaborative augmented reality;mixed reality based system;collaborative mission;Google Earth;georegistered icons;live video streams;surveillance cameras;3D models","","3","2","6","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"AR-Mote: A wireless device for Augmented Reality environment","G. Caruso; G. M. Re","Department of Mechanical Engineering, Politecnico di Milano, Italy; Department of Mechanical Engineering, Politecnico di Milano, Italy","2010 IEEE Symposium on 3D User Interfaces (3DUI)","29 Apr 2010","2010","","","99","102","One of the open issues in Augmented Reality (AR) applications is certainly related to interaction techniques. In these years many different solutions have been proposed with the intent of providing user interfaces that allow users to interact with the AR environment in a natural and intuitive way. Most of them have addressed the issue of representing users' hands in the AR environment. We propose the use of a commercial and low-cost wireless device to use as input device for AR. This paper describes the integration of this device into an AR application, and some preliminary tests aiming at evaluating the tracking accuracy and precision. In addition, we demonstrate the usability of our system through a preliminary testing session with users.","","978-1-4244-6847-8","10.1109/3DUI.2010.5444714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444714","","Augmented reality;Infrared sensors;User interfaces;Testing;Accelerometers;Usability;Design automation;Displays;Infrared detectors;Acceleration","augmented reality;tracking;user interfaces","AR-Mote;wireless device;augmented reality environment;user interfaces;tracking accuracy;preliminary testing session","","4","","16","IEEE","29 Apr 2010","","","IEEE","IEEE Conferences"
"New augmented reality application in E-commerce and M-commerce","M. Atalar; M. Özcan","Technology Director Biritek LLC, Ankara, Turkey; Sales Director Biritek LLC, California, USA","2017 International Conference on Computer Science and Engineering (UBMK)","2 Nov 2017","2017","","","332","336","Nowadays, Virtual Reality (VR) and Augmented Reality (AR) offer new and extend existing customer experience in web and mobile environment. VR has been practiced a good start with game applications. By increasing interaction with user or equipment motion, applications have been strongly continuing to produce and reach more user experience target. In this paper, we would like to announce and introduce you our new AR application platform, called as Lify. Lify's exceptional features will also be introduced for a noval electronic or mobile commerce experience in our paper.","","978-1-5386-0930-9","10.1109/UBMK.2017.8093403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093403","Augmented Reality;Virtual Reality;Electronic Commerce;Mobile Commerce;Artificial Intelligence","Mobile communication;Social network services;Business;Augmented reality;Mobile applications;Image recognition","augmented reality;mobile commerce","e-commerce;m-commerce;VR;mobile environment;game applications;AR application platform;mobile commerce experience;augmented reality application;customer experience;user experience;electronic commerce experience","","8","","22","IEEE","2 Nov 2017","","","IEEE","IEEE Conferences"
"3D modeling with the Tinmith mobile outdoor augmented reality system","W. Piekarski","University of South Australia, Australia","IEEE Computer Graphics and Applications","10 Jan 2006","2006","26","1","14","17","At the Wearable Computer Lab at the University of South Australia, we have been performing research into outdoor augmented reality (AR) systems for the last seven years. During this time the technology has vastly improved, resulting in more accurate systems that have better quality output. While tracking and registration are important issues in the area of AR, it's also important that we have suitable user interfaces that let people effectively view information and control the computer to get the desired output. Therefore, the Tinmith project explores the problem of interacting with a mobile AR system outdoors and the types of possible applications.","1558-1756","","10.1109/MCG.2006.3","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1573626","3D modeling;augmented reality;mobile outdoor systems","Augmented reality;Fingers;Object oriented modeling;Virtual reality;Mobile computing;User interfaces;Thumb;Copper;File systems;Best practices","solid modelling;mobile computing;augmented reality;user interfaces","3D modeling;Tinmith mobile outdoor augmented reality system;AR systems;user interfaces","Clothing;Computer Graphics;Computer Simulation;Environment;Equipment Design;Equipment Failure Analysis;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Theoretical;User-Computer Interface","15","","3","IEEE","10 Jan 2006","","","IEEE","IEEE Magazines"
"Assembly Design and Evaluation Based on Bare-Hand Interaction in an Augmented Reality Environment","Z. Wang; Y. Shen; S. K. Ong; A. Y. -C. Nee","Mechanical Engineering Department, Faculty of Engineering, National University of Singapore, Singapore; Mechanical Engineering Department, Faculty of Engineering, National University of Singapore, Singapore; Mechanical Engineering Department, Faculty of Engineering, National University of Singapore, Singapore; Mechanical Engineering Department, Faculty of Engineering, National University of Singapore, Singapore","2009 International Conference on CyberWorlds","6 Oct 2009","2009","","","21","28","Augmented Reality (AR) is an increasingly important application domain for computer graphics and user interface design. In this paper, the authors propose an AR interface for assembly design and evaluation. The methodologies to establish an AR assembly environment and the architecture of the proposed system are presented. A key novelty of this research is the use of bare hands for human-computer interaction in the AR assembly environment. An effective hand segmentation method based on a Restricted Coulomb Energy (RCE) neural network is developed. Experimental results show that the proposed hand segmentation method is effective and robust and the finger tracking algorithm runs in real time under a wide range of lighting conditions. An experiment using two fingertips to control virtual objects to simulate assembly in a 2D space is conducted.","","978-1-4244-4864-7","10.1109/CW.2009.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5279716","Augmented reality;assembly evaluation;bare-hand interaction","Augmented reality;Assembly systems;Virtual prototyping;Prototypes;Virtual reality;Computational modeling;Design engineering;Product development;Virtual environment;Feedback","assembling;augmented reality;CAD;human computer interaction;user interfaces","assembly design;bare-hand interaction;augmented reality environment;computer graphics;user interface design;human-computer interaction;hand segmentation method;finger tracking algorithm","","11","2","24","IEEE","6 Oct 2009","","","IEEE","IEEE Conferences"
"Using augmented reality gaming system to enhance hand rehabilitation","Hsian-shen Wang; Chaoli Hsu; D. Chiu; S. -N. Tsai","Department of Digital Content & Technology, National Taichung University, Taichung, Taiwan; Center for Faculty Development, Wenzao Ursuline College of Language, Kaohsiung, Taiwan; Department of Digital Content & Technology, National Taichung University, Taichung, Taiwan; Taichung Municipal Chung-Cheng Elementary School, Taichung, Taiwan","2010 2nd International Conference on Education Technology and Computer","29 Jul 2010","2010","3","","V3-243","V3-246","For those people who suffer from major hand injury, encouraging them to carry out rehabilitation is an important therapeutic activities. However, it is a repetitious routine for patients who easily get tired and bored. This study developed a system that combined the technology of augmented reality (AR) with air pressure detecting device and the concept of game based learning. In this AR gaming system, patients with different extent of hand injuries can squeeze toys ball, through ball pressure control, and manipulate a fish tank computer game, in order to achieve the rehabilitation of hand function.","2155-1812","978-1-4244-6370-1","10.1109/ICETC.2010.5529553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5529553","Augmented Reality;Computer game;the rehabilitation of hand","Augmented reality;Medical treatment;Injuries;Muscles;Educational technology;Electronic mail;Layout;Computer science education;Virtual reality;Military computing","augmented reality;computer aided instruction;computer games;injuries;patient rehabilitation","augmented reality;patient rehabilitation;hand injury;air pressure detecting device;game based learning;computer game","","6","","8","IEEE","29 Jul 2010","","","IEEE","IEEE Conferences"
"Infrared Marker Based Augmented Reality System for Equipment Maintenance","T. Wang; Y. Liu; Y. Wang","School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China","2008 International Conference on Computer Science and Software Engineering","22 Dec 2008","2008","5","","816","819","In this paper, we propose augmented reality (AR) applications for equipment maintenance. The system is based on the projection and detection of infrared markers. We use an infrared projector to project markers onto the surface of the equipment to be maintained. These markers are invisible to the human-eye, but they could be clearly identified by the infrared camera. As a proof of concept, we have implemented a prototype camera system consisting of a conventional camera (scene camera) and an infrared camera (tracking camera). The systempsilas viewpoint could be calculated and the visible image is captured simultaneously when using such a camera system. Some 3D models are overlaid on top of a video image. We demonstrate several applications of our method, including air filter replacement and gear-box maintenance for a milling machine.","","978-0-7695-3336-0","10.1109/CSSE.2008.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4723028","augmented reality;infrared marker;project","Augmented reality;Cameras;Layout;Infrared detectors;Prototypes;Infrared imaging;Virtual reality;Computer aided manufacturing;CADCAM;Light emitting diodes","augmented reality;infrared detectors;maintenance engineering;mechanical engineering computing","infrared marker;augmented reality;equipment maintenance;infrared camera;tracking camera;3D models;video image;air filter replacement;gear-box maintenance;milling machine","","5","9","11","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"An empirical study on tangible augmented reality learning space for design skill transfer","R. Chen; X. Wang","Design Lab., Faculty of Architecture, Design and Planning, The University of Sydney, Sydney NSW 2006, Australia; Design Lab., Faculty of Architecture, Design and Planning, The University of Sydney, Sydney NSW 2006, Australia","Tsinghua Science and Technology","17 Jan 2012","2008","13","S1","13","18","Tangible augmented reality (TAR) technology opens a novel realm which integrates the computergenerated elements into the real word. Its applications into design education have been explored with a limitation to this entire area. TAR offers an innovative learning space by merging digital learning materials into the format of media with tools or objects which are direct parts of the physical space. It is therefore conceived that such combination opens new perspectives in teaching and learning. This paper presented and evaluated one TAR system to improve the pedagogical effectiveness of experiential and collaborative learning process in urban design education. The results from the experiments were analyzed under a previously developed theoretical framework, which show that TAR can enhance the design activities in some collaborative work.","1007-0214","","10.1016/S1007-0214(08)70120-2","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6072951","tangible interface;augmented reality;tangible augmented reality;design learning;physicality","Education;Augmented reality;Visualization;Context;Testing;Computers;Materials","","","","5","3","","","17 Jan 2012","","","TUP","TUP Journals"
"Design for the Cockpit Intelligent Tutoring System Based on Augmented Reality","Y. -j. Qiao; X. -f. Xie; T. Sun","Graduate Students' Brigade, Naval Aeronautical Engineering Institute, Yantai, China; Department of Ordnance Science and Technology, Naval Aeronautical Engineering Institute, Yantai, China; Graduate Students' Brigade, Naval Aeronautical Engineering Institute, Yantai, China","2008 International Symposium on Computational Intelligence and Design","22 Dec 2008","2008","2","","224","227","Tracking the position and orientation of learner's head, the cockpit intelligent tutoring system (CITS) based on augmented reality perceives the learner's interest, and then displays corresponding teaching information on the head mounted display (HMD). The system modeling involves the depiction of main framework and the mathematical solutions of subsystems. Cockpit components can be abstractly regarded as spatial planes, this paper presents two methods to establish planar equation in cockpit coordinate system and tracker coordinate system. To estimate the transition matrices, the method of least squares is introduced.","","978-0-7695-3311-7","10.1109/ISCID.2008.141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725495","Cockpit Intelligent Tutoring System;Augmented Reality;modeling;tracker;least square method","Intelligent systems;Augmented reality;Aerospace engineering;Magnetic heads;Virtual reality;Computer displays;Computational intelligence;Competitive intelligence;Modeling;Equations","aerospace computing;aircraft displays;augmented reality;helmet mounted displays;intelligent tutoring systems;least squares approximations;matrix algebra;teaching","cockpit intelligent tutoring system design;augmented reality;teaching;head mounted display;system modeling;subsystem mathematical solution;planar equation;cockpit coordinate system;tracker coordinate system;transition matrix;least square approximation","","1","","8","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"LcAR — Low cost augmented reality for the automotive industry","K. S. Ramasubramaniam; R. Bhat","L&T Technological Services, Bangalore, INDIA; Cisco Video Technologies Pvt Ltd, Bangalore, INDIA","2018 IEEE International Conference on Consumer Electronics (ICCE)","29 Mar 2018","2018","","","1","3","Currently, AR (Augmented Reality) technologies for the automotive industry are available mostly for high-end luxury vehicles in developed countries where the nature of the solution is such that it is very costly to install and the repair cost is high. However, for developing countries, there is a huge and ever-increasing population that drives at night in low-light conditions where vehicle accidents are almost usually fatal. For developed countries too, the fatalities due to animal crossings etc is high. This paper presents a mechanism to drastically improve the visibility in low-light conditions using Augmented Reality where the real-time video is analyzed, and augmented with the highlights indicating obstacles if any. Our system uses an IR camera with suitable range. This video is then processed to identify the obstacles via machine learning frameworks, classified appropriately and augmented by highlighting the obstacles in the driver's path either visually or audio feedback or both. Our system can build upon previous knowledge to enable constant learning and improvement in the detection accuracy.","2158-4001","978-1-5386-3025-9","10.1109/ICCE.2018.8326234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326234","automotive augmented reality;machine learning in AR;automotive AR","Roads;Augmented reality;Accidents;Automotive components;Automobiles;Training;Automotive engineering","augmented reality;automotive electronics;cameras;collision avoidance;driver information systems;learning (artificial intelligence);road accidents;road safety;traffic engineering computing","automotive industry;Augmented Reality;high-end luxury vehicles;low-light conditions;LcAR;real-time video;IR camera;infrared camera;machine learning;audio feedback","","2","","4","IEEE","29 Mar 2018","","","IEEE","IEEE Conferences"
"Design and Development of AR-PlaSys: Augmented Reality Based Plant Monitoring System","H. Shah; J. Gurnani; S. Gajjar","Electronics and Communication Engineering Department, Institute of Technology, Nirma University, Ahmedabad, India; Electronics and Communication Engineering Department, Institute of Technology, Nirma University, Ahmedabad, India; Electronics and Communication Engineering Department, Institute of Technology, Nirma University, Ahmedabad, India","2020 IEEE 17th India Council International Conference (INDICON)","5 Feb 2021","2020","","","1","5","This paper presents the design of the Augmented Reality Plant System (AR-PlaSys). AR-PlaSys is designed by merging Augmented Reality (AR) and the Internet of Things (IoT). A proficient observing framework is required for easy and long-term plant monitoring in industries such as nurseries and at domestic level. AR-PlaSys is an innovative and viable solution for the same. The humidity and temperature data from plant is collected by a DHT11 sensor and uploaded to Particle Photon cloud. The screen to be augmented is built in Unity 3D which is a real-time 3D development platform and is connected to the Particle Cloud. An android application file (APK) is developed which can be installed in all android cell phones. Whenever the camera detects the target image data is retrieved from the cloud and augmented on the screen. This system is unique, compact, cost and energy-efficient which can be deployed for domestic and industrial purposes.","2325-9418","978-1-7281-6916-3","10.1109/INDICON49873.2020.9342166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342166","Augmented Reality;IoT;Particle Photon;Unity 3D;DHT11","Cloud computing;Three-dimensional displays;Humidity;Augmented reality;Smart phones;Monitoring;Photonics","augmented reality;computer based training;computerised monitoring;industrial plants;Internet of Things;medical computing;mobile computing;smart phones","Plant monitoring System;Augmented Reality Plant System;AR-PlaSys;proficient observing framework;long-term plant monitoring;innovative solution;humidity;temperature data;DHT11 sensor;Particle Photon cloud;real-time 3D development platform;Particle Cloud","","2","","12","IEEE","5 Feb 2021","","","IEEE","IEEE Conferences"
"Interactional promotion content using augmented reality technology","D. -Y. Kim; C. -M. Oh; K. Hossain; C. -W. Lee","Computer Engineering, Chonnam University, Gwang, South Korea; Computer Engineering, Chonnam University, Gwang, South Korea; Computer Engineering, Chonnam University, Gwang, South Korea; Computer Engineering, Chonnam University, Gwang, South Korea","The 19th Korea-Japan Joint Workshop on Frontiers of Computer Vision","28 Mar 2013","2013","","","42","45","In this paper, we described making process of interactional promotion content using augmented reality technology. I used QualComm's Augmented Reality (QCAR) technology to make promotion content. Because QCAR had presented button function to manipulate augmented object, I could have added interactional factor to the content. Also, I added game content to the augmenting object because QCAR library could be used in the Unity3D game making tool. By utilizing these characteristic, I implemented Interactional promotional content based on the image marker.","","978-1-4673-5621-3","10.1109/FCV.2013.6485457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6485457","augmented reality;Interaction promotional content;QCAR","Augmented reality;Games;Videos;Educational institutions;Joints;Conferences;Computer vision","augmented reality;computer games;marketing","interactional promotion content;QualComm augmented reality technology;QCAR technology;button function;interactional factor;game content;QCAR library;Unity3D game making tool","","1","1","11","IEEE","28 Mar 2013","","","IEEE","IEEE Conferences"
"Large Scale Mobile and Pervasive Augmented Reality Games","P. M. F. M. Ferreira; J. M. Orvalho; F. Boavida","Centre of Informatics and Systems, University of Coimbra, Portugal; Superior Polytechnic Institute of Coimbra, Portugal; Department of Informatics, University of Coimbra, Portugal","EUROCON 2005 - The International Conference on "Computer as a Tool"","15 May 2006","2005","2","","1775","1778","Ubiquitous or pervasive computing is a new kind of computing, where specialized elements of hardware and software will have such high level of deployment that their use will be fully integrated with the environment. Augmented reality extends reality with virtual elements but tries to place the computer in a relatively unobtrusive, assistive role. To our knowledge, there is no specialized network middleware solution for large-scale mobile and pervasive augmented reality games. We present here work that focus on the creation of such network middleware for mobile and pervasive entertainment, applied to the area of large scale augmented reality games. In, this context, mechanisms are being studied, proposed and evaluated to deal with issues such as scalability, multimedia data heterogeneity, data distribution and replication, consistency, security, geospatial location and orientation, mobility, quality of service, management of networks and services, discovery, ad-hoc networking and dynamic configuration","","1-4244-0049-X","10.1109/EURCON.2005.1630321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1630321","Pervasive networking;augmented reality;middleware;entertainment;gaming","Large-scale systems;Augmented reality;Pervasive computing;Middleware;Hardware;Context-aware services;Scalability;Data security;Quality of service;Quality management","ad hoc networks;augmented reality;computer games;entertainment;middleware;mobile computing;multimedia computing;quality of service;security of data;telecommunication network management;telecommunication security","Pervasive networking;augmented reality;middleware;entertainment;gaming","","3","","13","IEEE","15 May 2006","","","IEEE","IEEE Conferences"
"Detection time of machine by posit algorithm through augmented reality","S. Bhakar; D. P. Bhatt","Department of Computer Science, Manipal University, Jaipur, India; Department of Computer Science, Manipal University, Jaipur, India","2017 International Conference on Intelligent Communication and Computational Techniques (ICCT)","26 Mar 2018","2017","","","71","78","Augmented Reality is the combination of virtual scene generated from computer with the user's real world. Nowadays, many applications apply augmented reality technology in defense sector, traffic management, which uses real time system, where time is an important factor. In this paper, an efficient augmented reality system is suggested to compute the response time of machine to detect the marker. Luminous affecting computing of glyph recognition and detection of glyph by marker at different challenging distance (feet) has been processed. Glyph is created for augmented process through image processing and glyph matrix representation has been structured. Here, Posit algorithm is used to detect the position and orientation of marker with respect to camera. A prototype structure is created to compute the detection response time of machine under different challenging conditions. Our experimental result shows minimum computation Detection time is 5400 millisecond at lux 13490 (ambient light) and maximum computation detection time is 12000 millisecond at Lux 10.3 (no tube-light) to detect the fiducial marker.","","978-1-5386-3030-3","10.1109/INTELCCT.2017.8324023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8324023","augmented reality;posit;detection time;camera processing","Augmented reality;Cameras;Servomotors;Libraries;Time factors;Military aircraft;Mathematical model","augmented reality;image processing;matrix algebra","posit algorithm;virtual scene;defense sector;traffic management;glyph recognition;image processing;fiducial marker;augmented reality system;glyph matrix representation","","2","","16","IEEE","26 Mar 2018","","","IEEE","IEEE Conferences"
"Augmented Reality application: A new implementation chain","S. Nazir; A. Assoum; B. El Hassan; F. Dornaika","Universite Libanaise, Beirut, LB; Universite Libanaise, Beirut, LB; Universite Libanaise, Beirut, LB; Ikerbasque, Bilbao, Bizkaia, ES","2016 IEEE International Multidisciplinary Conference on Engineering Technology (IMCET)","8 Dec 2016","2016","","","69","74","Augmented Reality (AR) is a live view of a real-world environment. With advanced AR technology, artificial information about the environment and its objects can be overlaid on the real world. This paper presents a complete augmented reality process for a video sequence captured by a moving camera. The main goal is to construct a full chain composed of 4 blocks that correspond to the main steps of augmented reality process: feature detection, feature extraction, feature matching and image registration. Our work proposes an improved technique for image augmentation, starting from feature detection and ending by image registration. We used the well-known techniques (e.g. SIFT, SURF, etc.) for features detection and extraction in order to compare their performance. Furthermore, we added a features learning step (using SVM, KNN and SRC) to improve the image registration process. The final full chain uses the best method in each block. This best combination is then applied on all video frames taken by the camera. Thereafter, we obtain a video showing the augmented object instead of the real one.","","978-1-5090-5281-3","10.1109/IMCET.2016.7777429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7777429","Augmented reality;image processing;machine learning;features extraction and detection;image registration","Feature extraction;Image registration;Augmented reality;Detectors;Transforms;Classification algorithms;Histograms","augmented reality;cameras;feature extraction;image capture;image matching;image registration;image sequences;learning (artificial intelligence);object detection;support vector machines;transforms;video signal processing","augmented reality;video frames;SRC;KNN;SVM;feature learning;SURF;SIFT;image augmentation;image registration;feature matching;feature extraction;feature detection;moving camera;video sequence;artificial information;AR technology","","1","","","IEEE","8 Dec 2016","","","IEEE","IEEE Conferences"
"An intelligent and modular sensing system for Augmented Reality application","M. F. Alam; S. Katsikas; S. Hadjiefthymiades","Pervasive Computing Research Dept. of Informatics and Telecommunications, National Kapodistrain University of Athens; Head of Research and Development Electronics, Informatics and Telecommunications Prisma Electronics SA Athens; Pervasive Computing Research Dept. of Informatics and Telecommunications, National Kapodistrain University of Athens","2015 9th International Conference on Sensing Technology (ICST)","24 Mar 2016","2015","","","850","855","The scientific objective of this paper is to describe an innovative architecture of modular form in sensing and supervision system. In our study, a maintenance work at ATLAS detector in Large Hadron Collider at European Organization for Nuclear Research (CERN), Geneva, Switzerland has been considered. The research challenges lie in the development of real-time data-transmission, instantaneous analysis of data coming from different inputs, local intelligences in low power embedded system, interaction with augmented reality in multiple on-site users, complex interfaces, and portability. The proposed architecture is allocated with modular form. The prototype of this modular device is named a PSS (Personnel Supervision System) module. The hardware of the modular system includes with many sensor modules, cameras, IMU (Inertial Measurement Unit) sensors, processors, Wi-Fi module, laser, LED light plus its associated software. The mobile PSS module is responsible for local data processing for various sensors, image processing, 3D pose estimation, audio data acquisition, visualization and wireless interfaced devices. The advantage of modular concept is that it can work independently or together. The Head Mounted Display (HMD) includes HW and SW to communicate the augmented reality content to the user and to display visual information on a worker's field of view (FOV). The module serves as a supervision post, providing sensor data, video and audio stream to the supervisor. It stores data and provide the means for the supervisor to easily communicate and instruct the worker. It decides, selects and serves the AR (Augmented) content on multiple PTUs, automatically or with minor supervisor intervention. The development of this system to be compatible with a wearable use in a highly challenging environment presents an excellent opportunity to integrate today's leading technical knowledge in a product which can become accessible to industry and general public. This study is a part of the EDUSAFE project, a Marie Curie ITN project focusing on research into the use of Virtual and Augmented Reality (VR/AR) during planned and emergency maintenance in extreme environments.","2156-8073","978-1-4799-6314-0","10.1109/ICSensT.2015.7438515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7438515","Modular system;Sensors;Augmented Reality;Supervision","Temperature sensors;Program processors;Pins;Augmented reality;Cameras","augmented reality;helmet mounted displays;intelligent sensors","intelligent sensing system;modular sensing system;augmented reality application;head mounted display;personnel supervision system module","","","","26","IEEE","24 Mar 2016","","","IEEE","IEEE Conferences"
"Virtual redlining for civil engineering in real environments","G. Schall; E. Mendez; D. Schmalstieg","Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","95","98","Field workers of utility companies are regularly engaged in outdoor tasks such as network planning and inspection of underground infrastructure. Redlining is the term used for manually annotating either printed paper maps or a 2D geographic information system on a notebook computer taken to the field. Either of these approaches requires finding the physical location to be annotated on the physical or digital map. In this paper, we describe a mobile Augmented Reality (AR) system capable of supporting virtual redlining. The AR visualization delivered by the system is constructed from data directly extracted from a GIS used in day-to-day production by utility companies. We also report on encouraging trials and interviews performed with professional field workers from the utility sector.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637332","underground infrastructure visualization;redlining;mobile augmented reality;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities","Geographic information systems;Augmented reality;Three dimensional displays;Solid modeling;Data visualization;Companies;Planning","augmented reality;civil engineering computing;data visualisation;engineering graphics;geographic information systems;microcomputer applications;public utilities","virtual redlining;civil engineering;network planning;underground infrastructure inspection;2D geographic information system;notebook computer;digital map;Augmented Reality system;AR visualization","","21","20","13","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Augmented reality for underwater activities with the use of the DOLPHYN","A. Bellarbi; C. Domingues; S. Otmane; S. Benbelkacem; A. Dinis","Centre de Developpement des Technologies Avancées, Algiers, Algeria; IBISC EA 4526, University of Evry, France; IBISC EA 4526, University of Evry, France; Centre de Developpement des Technologies Avancées, Algiers, Algeria; VirtualDive SAS, Versailles, France","2013 10th IEEE INTERNATIONAL CONFERENCE ON NETWORKING, SENSING AND CONTROL (ICNSC)","27 Jun 2013","2013","","","409","412","The objective of this work is to introduce Augmented and Mixed Reality technologies in aquatic leisure activities. We have proposed a new device which is autonomous, mobile and easily transportable by one person. It can also be easily installed, equipped with GPS and wireless systems, and has positive buoyancy. The device will be used at water surface as well as underwater using a tuba. Moreover, the device is equipped with one (can be upgraded for more) video camera pointing downwards. Augmented Reality contents combining actual underwater images with 3D animated images will be one of the preferred ways to use the device.","","978-1-4673-5200-0","10.1109/ICNSC.2013.6548773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6548773","Augmented Reality;Underwater;Human machine Interaction","Cameras;Games;Marine animals;Augmented reality;Underwater vehicles;Three-dimensional displays","augmented reality;computer animation;humanities;solid modelling","augmented reality;mixed reality technology;aquatic leisure activity;DOLPHYN device;buoyancy;3D animated image;underwater image;video camera","","19","","9","IEEE","27 Jun 2013","","","IEEE","IEEE Conferences"
"Intelligent predictive maintenance control using augmented reality","M. Kostoláni; J. Murín; Š. Kozák","Faculty of Electrical Engineering and Information Technology, Slovak University of Technology in Bratislava, Bratislava, Slovak Republic; Faculty of Electrical Engineering and Information Technology, Slovak University of Technology in Bratislava, Bratislava, Slovak Republic; Faculty of Informatics, Pan-European University, Bratislava, Slovak Republic","2019 22nd International Conference on Process Control (PC19)","29 Aug 2019","2019","","","131","135","Modern manufacturing industry is currently facing significant challenges with regard to the concept of Industry 4.0. The promise of increased productivity and flexibility in manufacturing processes can not be achieved without implementation of systems and advance methods based on smart technologies. Implementation of Industrial Internet of Things (IIoT), Condition Monitoring, Big Data, Cloud computing, virtual and augmented reality in maintenance processes will significantly increase the effectivy and quality of manufacturing processes as well as eliminate the human factor. Under this perspective, cyber- physical systems can be accessible from remote location; process paramters can be visualized at real time and prediction of unexpected production stop due to machine breakdown will be significantly reduced. The paper deals with the development of effective approach to real-time process control using parameters visualization of manufacturing process with the use of augmented reality smart glasses. Collected data from condition monitoring sensors from electric monorail system are evaluated in real time and visualized in the field of maintainer view. Critical values from field of sensors are highlighted and enable to predict manufacturing breakdowns. On real example from automotive industry will be demonstrated the signification and effectivity for maintenance of electric monorail system and potential for application in different types of modern industrial processes with the focus on rule-based intelligent predictive maintenance control.","","978-1-7281-3758-2","10.1109/PC.2019.8815042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815042","Industry 4.0;Intelligent control;Smart maintenance;Augmented reality;Condition Monitoring;cyber-physical systems","Augmented reality;Industries;Real-time systems;Predictive maintenance;Data visualization;Sensors","augmented reality;automobile industry;Big Data;cloud computing;condition monitoring;control engineering computing;cyber-physical systems;flexible manufacturing systems;intelligent control;Internet of Things;maintenance engineering;predictive control;process control;production engineering computing;productivity;quality control;rails;real-time systems;sensors","real-time process control;parameters visualization;augmented reality smart glasses;condition monitoring sensors;electric monorail system;automotive industry;smart technologies;Big Data;cyber-physical systems;productivity;flexible manufacturing;cloud computing;intelligent predictive maintenance control;Industry 4.0;virtual reality;quality control;machine breakdown;Industrial Internet of Things","","9","","7","IEEE","29 Aug 2019","","","IEEE","IEEE Conferences"
"A proposed use of Virtual and Augmented Reality for supporting inquiry based learning","S. Creane; Y. Crotty; M. Farren","International Centre for Innovation and Workplace Learning School of Education Studies, Dublin City University (DCU), Ireland; International Centre for Innovation and Workplace Learning School of Education Studies, Dublin City University (DCU), Ireland; International Centre for Innovation and Workplace Learning School of Education Studies, Dublin City University (DCU), Ireland","2015 International Conference on Interactive Mobile Communication Technologies and Learning (IMCL)","17 Dec 2015","2015","","","393","395","The research proposed in this paper will embrace the possibilities that eLearning tools can bring to Science education. A number of Virtual and Augmented Reality (VR and AR) devices are appearing on the market for research and development. The plan is to develop an Augmented Reality learning object, a software that will enable students to interact with learning resources and scenarios and allow them to experience inquiry-based learning (IBL) in science education.","","978-1-4673-8243-4","10.1109/IMCTL.2015.7359628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359628","virtual and augmented reality;learning about inquiry;learning to do inquiry;practitioner research","Europe;Electronic learning;Augmented reality;Problem-solving;Software;Technological innovation","augmented reality;computer aided instruction","science education;augmented reality learning object;eLearning tool;supporting inquiry based learning;virtual reality","","2","","16","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Interfacing with Global Collective Intelligence Using Virtual Assistants","S. Cöté; J. St-Pierre",Bentley Systems; Independentresearcher,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","373","376","The evolution of our society and of humans as individuals is hindered by the widely distributed aspect of human knowledge. Humans often need to re-invent the wheel, because they are unaware of existing solutions already found by many other humans. In this paper, we propose the concept of an Artificial Intelligence, interfaced through Intelligent Virtual Agents displayed in Augmented Reality, that would collect all human knowledge, and distribute it freely to all humans, when they need it. We argue that the proposed system would have significant very positive impacts on Humanity, and put it on a path of peaceful enhanced evolution.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699184","Intelligent Virtual Agents;Augmented Reality;Collective Intelligence;Human-centered computing-Mixed / augmented reality;Computing methodologies∼Intelligent agents","Augmented reality","artificial intelligence;augmented reality;software agents","global collective intelligence;virtual assistants;artificial intelligence;intelligent virtual agents;augmented reality","","","","17","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Collaborative Augmented Reality Approach for Multi-user Interaction in Urban Simulation","A. W. Ismail; M. S. Sunar","Department of Computer Graphic and Multimedia, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia; Department of Computer Graphic and Multimedia, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia","2009 International Conference on Information and Multimedia Technology","15 Jan 2010","2009","","","19","23","Augmented reality (AR) environment allows user or multi-user to interact with 2D and 3D data. AR simply can provide a collaborative interactive AR environment for urban simulation, where users can interact naturally and intuitively. AR collaboration approach can be effectively used to develop face to face interfaces. This is because AR provides seamless interaction between real and virtual environments, the ability to enhance reality, the presence of spatial cues for face-to-face and remote collaboration, support of a tangible interface metaphor, the ability to transition smoothly between reality and virtuality. The fusion between real and virtual world, existed in AR environment, achieves higher interactivity as a key features of collaborative AR. Collaborative AR approach allows multi-user to simultaneously share a real world surrounding them and a virtual world. The features of collaboration in AR environment will be identified. The key for the proposed technique of precise registration between both worlds and multi-user are emphasized for the collaborations using AR environment. Common problems in AR environment and issues in collaborative AR will be discussed. This paper will give an overview for collaborative AR framework employed in urban simulation and the multi-user interaction on how to share these virtual spaces with other users in collaboration. The work will also cover numerous systems in different cases of collaborative AR environments for multiuser interaction.","","978-0-7695-3922-5","10.1109/ICIMT.2009.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5381253","Augmented Reality;Multi-User Interaction;Collaborative;Urban Simulation","Augmented reality;Collaborative work;Collaborative tools;Multimedia systems;Urban planning;International collaboration;Computational modeling;Computer graphics;Computer science;Information systems","augmented reality;digital simulation;groupware","collaborative augmented reality;multiuser interaction;urban simulation;face to face interfaces;spatial cues;virtual reality;interface metaphor","","2","2","28","IEEE","15 Jan 2010","","","IEEE","IEEE Conferences"
"A User Study Trends in Augmented Reality and Virtual Reality Research: A Qualitative Study with the Past Three Years of the ISMAR and IEEE VR Conference Papers","S. J. J. Kim","Human-Computer Interaction Lab, Digital Media, School of Visual Arts and Design, University of Central Florida, Orlando, FL, USA","2012 International Symposium on Ubiquitous Virtual Reality","10 Sep 2012","2012","","","1","5","Augmented reality (AR) and virtual reality (VR) are becoming a part of everyday life with the advance of other technologies such as computer vision systems, sensing technologies, graphics, mobile computing, etc. Their primary goal is to help users achieve their goals effectively and efficiently with satisfaction. This paper describes the trends of how user studies have been incorporated into AR and VR papers published in two major conferences over the past three years. In addition, this paper presents implications on what needs to be taken into account when planning a user study in the field of AR and VR research.","","978-1-4673-2258-4","10.1109/ISUVR.2012.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6296796","","Usability;Augmented reality;Conferences;Market research;Humans","augmented reality","user study trends;augmented reality research;virtual reality research;ISMAR;IEEE VR conference papers;AR;VR","","15","","10","IEEE","10 Sep 2012","","","IEEE","IEEE Conferences"
"Wearable RemoteFusion: A Mixed Reality Remote Collaboration System with Local Eye Gaze and Remote Hand Gesture Sharing","P. Sasikumar; L. Gao; H. Bai; M. Billinghurst","Auckland Bioengineering Institute, University of Auckland; HIT Lab NZ, University of Canterbury; Auckland Bioengineering Institute, University of Auckland; Auckland Bioengineering Institute, University of Auckland","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","393","394","We present a wearable Mixed Reality (MR) remote collaboration system called Wearable RemoteFusion. The system supports spatial annotation and view frustum sharing, and enables natural non-verbal communication cues (eye gaze and hand gesture) for visual assistance in a stitched live dense scene. We describe the design and implementation details of the prototype system, and report on a pilot user study investigating how sharing natural gaze and gesture cues affects collaborative performance and the user experience. We found that by sharing augmented natural cues like the local eye gaze and remote hand gesture, participants had a stronger feeling of Co-presence, and the remote user could guide the local user to complete tasks with less physical workload. We discuss implications for collaborative interface design and directions for future research.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.000-3","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951977","Mixed Reality, Augmented Reality, remote collaboration, eye gaze, hand gesture","Collaboration;Virtual reality;Task analysis;Three-dimensional displays;Annotations;Biomedical engineering","augmented reality;gesture recognition;groupware;human computer interaction","spatial annotation;view frustum sharing;nonverbal communication cues;visual assistance;wearable mixed reality remote collaboration system;wearable RemoteFusion;remote hand gesture sharing;collaborative interface design;local eye gaze;augmented natural cues;user experience;collaborative performance;gesture cues;natural gaze;stitched live dense scene","","7","","4","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Shared Augmented Reality Experience Between a Microsoft Flight Simulator User and a User in the Real World","C. Leuze; M. Leuze",Nakamir Inc; Alpinschule Innsbruck,"2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","767","767","Our video shows an application where a user with an augmented reality (AR) display watches another user, flying an airplane in the Microsoft Flight Simulator 2020 (MSFS), at their respective location in the real world. To do that, we take the location data of a virtual 3D airplane model in a virtual representation of the world of a user playing MSFS, and stream it via a server to a mobile AR device. The mobile device user can then see the same 3D airplane model at exactly that real world location, that corresponds to the location of the virtual 3D airplane model in the virtual representation of the world. The mobile device user can also see the plane movement updated according to the 3D airplane movement in the virtual world. We implemented the application on both a cellphone and the Hololens 2.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419091","Augmented reality;Gaming;Multiplayer;Multiverse","Airplanes;Solid modeling;Three-dimensional displays;Atmospheric modeling;Conferences;User interfaces;Mobile handsets","aerospace simulation;aircraft;augmented reality;mobile computing;solid modelling;user interfaces;wearable computers","virtual representation;mobile device user;virtual world;shared augmented reality experience;Microsoft Flight Simulator user;augmented reality display;Microsoft Flight Simulator 2020;MSFS;location data;mobile AR device;augmented reality display watches;virtual 3D airplane model;real world location;plane movement;3D airplane movement","","","","0","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"[Poster] Touch gestures for improved 3D object manipulation in mobile augmented reality","P. Tiefenbacher; A. Pflaum; G. Rigoll","Institute for Human-Machine Communication, Technische Universität München; Institute for Human-Machine Communication, Technische Universität München; Institute for Human-Machine Communication, Technische Universität München","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","315","316","This work presents three techniques for 3D manipulation on mobile touch devices, taking the specifics of mobile AR scenes into account. We compare the common direct manipulation technique with two indirect techniques, which utilize only the thumbs to perform the transformations. The evaluation of the manipulation variants is conducted in a mixed reality (MR) environment which takes advantage of the controlled conditions of a full virtual reality (VR) system. A study with 18 participants shows that the two-thumb method tops the other techniques. It performs better with respect to the total manipulation time and total number of gestures.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948467","H.5.2 [Information Interfaces and Presentation];User Interfaces — Interaction styles","Three-dimensional displays;Thumb;Mobile communication;Mobile handsets;Tracking;Virtual reality;Performance evaluation","augmented reality;gesture recognition;mobile computing","touch gesture;3D object manipulation;mobile augmented reality;mobile touch devices;direct manipulation technique;mixed reality environment;MR environment;full virtual reality system;VR system;two-thumb method","","4","","5","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Research on visual art design of children’s picture books based on Augmented Reality Technology","P. Fu","Changchun Humanities and Sciences College, Changchun, China","2022 5th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","16 Nov 2022","2022","","","789","793","With the progress and development of science and technology, the sales of traditional paper books will inevitably be affected, and because of the popularization of science and technology, traditional paper books began to add AR technology to supplement their shortcomings. AR technology is augmented reality technology, which integrates a large number of real scenes into virtual parts for interaction through the device screen. This topic studies the application of AR technology in the visual design of traditional children’s picture book art. Using the advantages of AR technology to change the limitations of traditional children’s picture book design, let children’s picture book design blend the virtual part and the real part, and present a three-dimensional story effect that fits the content of the picture book.","","978-1-6654-8474-9","10.1109/AEMCSE55572.2022.00158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9948420","AR technology;Children’s picture book;visual arts;Augmented reality technology","Computers;Visualization;Art;Augmented reality;Software engineering","art;augmented reality;computer aided instruction;electronic publishing;virtual reality","AR technology;augmented reality technology;picture book;traditional children;traditional paper books;virtual part;visual art design;visual design","","","","5","IEEE","16 Nov 2022","","","IEEE","IEEE Conferences"
"ARtect, an augmented reality educational prototype for architectural design","M. Velaora; R. van Roy; F. Guéna","Laboratory Map-Maacc École Nationale Supérieure d'Architecture de Paris-La Villette, Paris, France; Independent Researcher Informatics, Hjotronic, Eindhoven, Netherlands; Laboratory Map-Maacc École Nationale Supérieure d'Architecture de Paris-La Villette, Paris, France","2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)","1 Oct 2020","2020","","","110","115","ARtect is an Augmented Reality application developed with Unity 3D, which envisions an educational interactive and immersive tool for architects, designers, researchers, and artists. This digital instrument renders the competency to visualize custom-made 3D models and 2D graphics in interior and exterior environments. The user-friendly interface offers an accurate insight before the materialization of any architectural project, enabling evaluation of the design proposal. This practice could be integrated into learning architectural design process, saving resources of printed drawings, and 3D carton models during several stages of spatial conception.","","978-1-7281-6823-4","10.1109/WorldS450073.2020.9210302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210302","2d graphic;3d models;application;architecture;augmented reality;education;design","Three-dimensional displays;Solid modeling;Tools;Two dimensional displays;Computer architecture;Augmented reality;Visualization","architecture;augmented reality;CAD;computer aided instruction;data visualisation;rendering (computer graphics);solid modelling;user interfaces;virtual reality","ARtect;augmented reality educational prototype;Unity 3D;immersive tool;artists;digital instrument;exterior environments;user-friendly interface;architectural project;design proposal;architectural design process;3D carton models;educational interactive tool;custom-made 3D model visualisation;2D graphic visualisation","","","","21","IEEE","1 Oct 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Based Surgical Training and Education System for Neurosurgery","S. Cai; Y. Zhou; J. Shen; J. Guo; X. Xiong; X. Jiang","School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Chipeye Microelectronics Foshan Ltd, Foshan, China; Department of Neurosurgery/Neuro-oncology, Sun Yat-sen University Cancer Center","2022 International Conference on Advanced Robotics and Mechatronics (ICARM)","29 Nov 2022","2022","","","678","681","Surgical simulation helps trainees to explore many clinical scenarios before experiencing them with patients. Augmented reality (AR) based on patients’ medical data is an innovative technique for medical education and neurosurgical practice outside the operating room. We propose an AR application for surgical training of pituitary tumor resection in order to help trainees understand different conditions of pituitary tumors and nearby vessels, especially arteries. Virtual objects of pituitary tumors and nearby arteries and veins are created from the image segmentation of multiple patients’ MRI data. To provide an immersive learning environment, we develop a gesture-based user interface based on a head-mounted display HoloLens2 which allows trainees to manipulate the visualization of virtual objects in real time, such as zooming in/out, panning and rotating the virtual objects. The proposed AR application can be used to simulate pituitary tumor resection at different levels of difficulty based on our database which contains various virtual models of pituitary tumors and the nearby vessels.","","978-1-6654-8306-3","10.1109/ICARM54641.2022.9959349","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9959349","Augmented reality;pituitary tumor surgery;surgical training;user interaction","Training;Learning systems;Veins;Real-time systems;Neurosurgery;Augmented reality;Arteries","augmented reality;biomedical education;biomedical MRI;blood vessels;computer based training;helmet mounted displays;image segmentation;medical computing;medical image processing;surgery;tumours;user interfaces;virtual reality","AR application;augmented reality;clinical scenarios;education system;gesture-based user interface;head-mounted display HoloLens2;immersive learning environment;innovative technique;medical education;multiple patients;nearby arteries;nearby vessels;neurosurgical practice;operating room;pituitary tumor resection;pituitary tumors;surgical simulation;surgical training;trainees;virtual objects","","","","20","IEEE","29 Nov 2022","","","IEEE","IEEE Conferences"
"Augmented Reality Circuit Learning","H. Wang; S. -C. S. Cheung","Electrical and Computer Engineering, University of California, Davis, CA, USA; Electrical and Computer Engineering, University of Kentucky, KY, USA","2021 IEEE International Symposium on Circuits and Systems (ISCAS)","27 Apr 2021","2021","","","1","5","Building electronic circuits is one of the most common hands-on activities in learning STEM subjects. Beginning students often find it difficult to translate a circuit schematic into the construction of the physical circuit on a breadboard. In this paper, we describe an Augmented Reality circuit learning software that can provide students with step-by-step instructions by placing virtual circuit components on a physical breadboard. We propose a novel image processing pipeline that can robustly identify the planar structure of a breadboard, even in the presence of occluding circuit components on the breadboard. Using a commercially available library of 3D circuit component models, the estimated 3D structure of the breadboard allows us to render arbitrary circuit components on it in real time. Experimental results demonstrate that our algorithms are accurate and can produce realistic-looking virtual circuits.","2158-1525","978-1-7281-9201-7","10.1109/ISCAS51556.2021.9401464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9401464","vision-based circuit inspection;augmented reality;circuit learning","Solid modeling;Three-dimensional displays;Pipelines;Breadboard;Software;Real-time systems;Augmented reality","augmented reality;computer aided instruction;electronic engineering education;image processing;rendering (computer graphics);software libraries;solid modelling;virtual reality","electronic circuits;common hands-on activities;STEM subjects;beginning students;physical circuit;Augmented Reality circuit learning software;virtual circuit components;physical breadboard;image processing pipeline;occluding circuit components;estimated 3D structure;arbitrary circuit components;virtual circuits","","","","16","IEEE","27 Apr 2021","","","IEEE","IEEE Conferences"
"Designing of Chinese Ancient Poetry App Based on iOS Platform Augmented Reality and Machine Learning","F. Yang; J. M. Caballero; R. A. Juanatas","Technological University of the Philippines, Manila, Philippines; Technological University of the Philippines, Manila, Philippines; Technological University of the Philippines, Manila, Philippines","2022 7th International Conference on Business and Industrial Research (ICBIR)","8 Jun 2022","2022","","","285","288","An application program named Poetry in Painting integrating the listening, speaking, reading, painting, and testing skills were designed based on the technology of augmented reality and machine learning in the iOS mobile operating system, and also combined with Chinese traditional culture and ancient poetry. The app is full of attraction and creativity, which can not only cultivate users’ academic literacy, but also cultivate their imagination and creativity.","","978-1-6654-9475-5","10.1109/ICBIR54589.2022.9786385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9786385","augmented reality;machine learning;poetry;app;culture","Technological innovation;Operating systems;Government;Machine learning;Cultural differences;Creativity;Augmented reality","augmented reality;computer aided instruction;learning (artificial intelligence);literature;mobile computing;virtual reality","testing skills;machine learning;iOS mobile operating system;Chinese traditional culture;Chinese ancient Poetry app;iOS platform augmented reality;application program;painting;listening speaking","","","","16","IEEE","8 Jun 2022","","","IEEE","IEEE Conferences"
"On Sharing Physical Geometric Space between Augmented and Virtual Reality Environments","W. Chun; G. Choi; J. An; W. Seo; S. Park; I. Ihm","Sogang University, Mapo-gu, Seoul, KR; Sogang University, Mapo-gu, Seoul, KR; Sogang University, Mapo-gu, Seoul, KR; Sogang University, Mapo-gu, Seoul, KR; Dongguk University, Jung-gu, Seoul, KR; Sogang University, Mapo-gu, Seoul, KR","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","884","885","Despite the expected synergistic effects, augmented and virtual reality (AR and VR, respectively) technologies still tend to be discrete entities. In this paper, we describe our effort to enable both AR and VR users to share the same physical geometric space. The geometric transformation between two world spaces, defined separately by AR and VR systems, are estimated using a specially designed tracking board. Once initially obtained, the transformation will allow users to collaborate with each other within an integrated physical environment while making the best use of both AR and VR technologies.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798228","Human-centered computing—Human computer interaction—Interaction paradigms—Mixed/augmented reality","Geometry;Virtual reality;Estimation;Solid modeling;Three-dimensional displays;Visualization;Aerospace electronics","augmented reality","geometric transformation;virtual reality;augmented reality;tracking board;physical geometric space","","1","","1","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Augmented Reality-based Worker Assistance for People with Cognitive Disabilities","M. Jost; A. Luxenburger; S. Knoch; J. Mohr; M. Wolf; J. Alexandersson; R. Jost; K. Posselt","Cognitive Assistants, German Research Center for AI (DFKI GmbH), Saarbrücken, Germany; Cognitive Assistants, German Research Center for AI (DFKI GmbH), Saarbrücken, Germany; Cognitive Assistants, German Research Center for AI (DFKI GmbH), Saarbrücken, Germany; Cognitive Assistants, German Research Center for AI (DFKI GmbH), Saarbrücken, Germany; Cognitive Assistants, German Research Center for AI (DFKI GmbH), Saarbrücken, Germany; Cognitive Assistants, German Research Center for AI (DFKI GmbH), Saarbrücken, Germany; Lebenshilfe Obere Saar e.V, Saarbrücken, Germany; Lebenshilfe Obere Saar e.V, Saarbrücken, Germany","2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","30 Jan 2023","2022","","","216","218","This paper and the accompanying demonstration video showcase an interactive counting aid implemented with PARTAS, our personalizable, Augmented Reality-based worker assistance system. PARTAS combines contour-based instructions with a pick-by-projection approach and is particularly designed to be adaptable for people with different cognitive disabilities.","2771-7453","978-1-6654-5725-5","10.1109/AIVR56993.2022.00044","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024450","Augmented Reality;Personalization;Worker Assistance;Inclusion;Empowerment","Virtual reality;Artificial intelligence","augmented reality;handicapped aids;personnel","augmented reality-based worker assistance system;cognitive disabilities;contour-based instructions;interactive counting aid;PARTAS;personalizable reality-based worker assistance system;pick-by-projection approach","","","","4","IEEE","30 Jan 2023","","","IEEE","IEEE Conferences"
"EYEPLY: Baseball proof of concept — Mobile augmentation for entertainment and shopping venues","A. Hurwitz; A. Jeffs",EYEPLY; EYEPLY,"2009 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media and Humanities","17 Nov 2009","2009","","","55","56","EYEPLY, a marketing technologies enterprise, in conjunction with Pepperdine University (Malibu, California) and other partners, is developing a groundbreaking mobile platform that will create added value for marketers and consumers. By augmenting entertainment and shopping venues and their events, EYEPLY will generate compelling propositions for stadiums, amusement parks, concerts, conventions, fundraisers, superstores, shopping malls, and more. For its first offering, EYEPLY proudly introduces its baseball proof of concept: The only application with a multi-faceted revenue model that uses contemporary technologies, including the latest in smart phone-compatible augmented reality (MAR) and a patented point-based platform, to enhance in-stadium landscapes and the overall game day experience. The EYEPLY platform applies existing third-party data, introduces new social activities and marketing and promotions opportunities, and allows spectators to control access and interaction with what matters most to them. As spectators were once accustomed to bringing their binoculars to sporting events to get visually closer to the action, EYEPLY acts as a special lens to magnify and reveal objects and information invisible to the naked eye. Working from the location of the spectator, content displayed on-screen is relevant and personal to its user within a vast and populated stadium facility. In this paper, EYEPLY will outline how its baseball proof of concept, on contemporary mobile smart phones, magnifies and reveals data and engaging activities, in real-time, based on a spectator's physical gestures toward physical world people and objects, in a simple, accessible, and fun manner. The result is of profound value for captive audiences, as well as venue management and its partners, in stadium environments. Fundamentally, the proof of concept reflects an appreciation for live sporting events, and it is designed to seamlessly augment and elegantly enhance the live sporting experience rather than replace it. However, the EYEPLY platform is being designed to work with entertainment (not just sports- or one sport) and shopping venues, worldwide, with plans to be demonstrated and marketed at various events within these areas of focus in 2010.","2381-8360","978-1-4244-5508-9","10.1109/ISMAR-AMH.2009.5336723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336723","Artificial;augmented;virtual reality;commercial services;human factors;H. Information Systems;H.5 Information Interfaces and Presentation (I.7);H.5.1 Multimedia Information Systems","Smart phones;Games;Augmented reality;Information systems;Multimedia systems;Avatars;Lenses;Environmental management;Virtual reality;Human factors","augmented reality;entertainment;marketing;mobile computing;sport","EYEPLY;mobile augmentation;entertainment;marketing technologies enterprise;Pepperdine University;mobile platform;amusement parks;concerts;conventions;fundraisers;superstores;shopping malls;multifaceted revenue model;smart phone-compatible augmented reality;patented point-based platform;in-stadium landscape;game day experience;social activities;promotion opportunities;object magnification;on-screen content;captive audience;venue management;stadium environment;live sporting events;live sporting experience","","8","","","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Diminishing Real Objects and Adding Virtual Objects Using a RGB-D Camera","H. Sasanuma; Y. Manabe; N. Yata",Chiba University; Chiba University; Chiba University,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","117","120","AR technology is often used in applications that simulate an arrangement of furniture. These applications superimpose CG furnitures on any place. These applications cannot replace the CG furniture with a real furniture if there is a real furniture. To solve this problem, this paper proposes a method that can erase real object from the real environment (Diminished Reality) and add virtual object to the real environment (Augmented Reality) including the region of erased object using RGB-D camera.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836476","Augmented Reality;Diminished Reality;RGB-D camera","Surface treatment;Cameras;Augmented reality;Image segmentation;Three-dimensional displays;Surface texture;Real-time systems","augmented reality;furniture;image colour analysis;object detection","real objects;virtual objects;RGB-D camera;AR technology;CG furnitures;diminished reality;augmented reality","","2","","9","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Distributed System for Collaborative Authorship: Integrating ""Client/Server"" and Mobile Agents","N. Calonego; P. Lacerda Da Silva; W. De Freitas; R. Cividini Matthiesen","Univ. do Estado de Mato Grosso - UNEMAT, Brazil; Univ. do Estado de Mato Grosso - UNEMAT Caceres, Caceres, Brazil; Univ. do Estado de Mato Grosso - UNEMAT Caceres, Brazil; Fac. Anhanguera de Limeira, Brazil","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","333","336","This paper discusses a technique for developing collaborative authoring tool in distributed virtual reality and augmented reality systems. The prototype for the rendering servers (3D UI) implements message queue interface, enabling it to answer requests from client and agents. The same requests were performed by both, agents and clients. The agent should migrate to the machine where the service is available, while the client uses a cascade mechanism of ""proxies"" for distributing messages. Results point to greater efficiency with the use of clients. However, the autonomy of agents is quite significant in the context of interaction between users.","","978-1-4799-4261-9","10.1109/SVR.2014.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913110","Agent; Client-Server; Authoring Tool; Distributed System; Virtual Reality; Augment Reality","Computational modeling;Augmented reality;Solid modeling;Three-dimensional displays;Java;Visualization","augmented reality;message passing;mobile computing;rendering (computer graphics)","collaborative authorship;mobile agents;distributed virtual reality system;augmented reality system;rendering servers;message queue interface;cascade mechanism;message distribution","","1","","11","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"Augmented Reality in the Classroom","M. Billinghurst; A. Duenser","The HIT Lab NZ, University of Canterbury, New Zealand; University of Canterbury","Computer","29 Jun 2012","2012","45","7","56","63","Evaluations of AR experiences in an educational setting provide insights into how this technology can enhance traditional learning models and what obstacles stand in the way of its broader use. A related video can be seen here: http://youtu.be/ndUjLwcBIOw. It shows examples of augmented reality experiences in an educational setting.","1558-0814","","10.1109/MC.2012.111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171143","augmented reality;education technology;augmented books;mobile AR applications","Education;Augmented reality;Performance evaluation;Mobile communication","augmented reality;computer aided instruction","augmented reality;classroom;AR;learning model;educational setting","","306","","11","IEEE","19 Mar 2012","","","IEEE","IEEE Magazines"
"Location-Based Mobile Augmented Reality Application for Tourism","Y. K. Cheah; O. Baker","School of Computing, Southern Institute of Technology, Invercargill, New Zealand; School of Computing, Southern Institute of Technology, Invercargill, New Zealand","2020 IEEE Graphics and Multimedia (GAME)","15 Jan 2021","2020","","","37","42","New Zealand is a popular tourist destination for global tourists, where several cities in New Zealand attract a multitude of tourists annually. This research aims to exploit mobile technologies, including mobile augmented reality (MAR) and location-based service to implement a mobile tourist guide known as InvercARgill, to help promote tourism in Invercargill. The research focuses on the design and implementation of InvercARgill, where the functionality and usability are prioritised. Besides, the client-server architecture of InvercARgill, along with various SDKs and APIs exploited for the implementation are discussed in this paper. Lastly, results of the research reveal that InvercARgill could enhance the tourist's travel experience in Invercargill by distributing tourist information of various attractions through MAR and location-based service on the smartphone, as well as reducing the travel time to various attractions in Invercargill.","","978-1-7281-9244-4","10.1109/GAME50158.2020.9315096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315096","Augmented Realty;Mobile Augmented Reality;Mobile Tourist Guide;Tourism;Location-Based Service","Unified modeling language;Mars;Internet;Augmented reality;Object oriented modeling;Knowledge based systems;Ontologies","application program interfaces;augmented reality;client-server systems;location based services;mobile computing;smart phones;travel industry","tourism;mobile technologies;location based service;mobile tourist guide;InvercARgill;tourist information;location based mobile augmented reality;New Zealand;client server architecture;SDKs;APIs;smartphone","","1","","23","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"Supporting Visual Annotation Cues in a Live 360 Panorama-based Mixed Reality Remote Collaboration","T. Teo; G. A. Lee; M. Billinghurst; M. Adcock","University of South Australia, Adelaide, SA, AU; University of South Australia, Adelaide, SA, AU; University of South Australia, Adelaide, SA, AU; CSIRO","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1187","1188","We propose enhancing live 360 panorama-based Mixed Reality (MR) remote collaboration through supporting visual annotation cues. Prior work on live 360 panorama-based collaboration used MR visualization to overlay visual cues, such as view frames and virtual hands, yet they were not registered onto the shared physical workspace, hence had limitations in accuracy for pointing or marking objects. Our prototype system uses spatial mapping and tracking feature of an Augmented Reality head-mounted display to show visual annotation cues accurately registered onto the physical environment. We describe the design and implementation details of our prototype system, and discuss on how such feature could help improve MR remote collaboration.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798128","Mixed Reality;remote collaboration;360 panorama;annotation;H.5.3 [Information Interfaces and Presentation]: Group and Organization Interfaces—Collaborative computing;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities","Visualization;Collaboration;Resists;Three-dimensional displays;Prototypes;Augmented reality","augmented reality;helmet mounted displays;object tracking","visual annotation cues;MR visualization;visual cues;MR remote collaboration;augmented reality head-mounted display;live 360 panorama-based mixed reality remote collaboration;view frames;virtual hands","","","","9","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Mixed reality in the 3D virtual room arrangement","D. Herumurti; A. Yuniarti; I. Kuswardayan; W. Nurul; R. R. Hariadi; N. Suciati; M. G. Manggala","Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2017 11th International Conference on Information & Communication Technology and System (ICTS)","22 Jan 2018","2017","","","303","306","This research implements Mixed Reality to develop an innovative application in the virtual room arrangement in order to plan, design, and arrange the furniture at home. Mixed reality is a technology that combines the Virtual Reality (VR) and Augmented Reality (AR). Mixed Reality is also described as VR that is used in the real environment and it also implements the AR that is used in the VR additional device. This research aims to explore the Mixed Reality technology in the virtual room arrangement application using the Google Card Board. The result shows that this research can be a new innovation in the human-computer interaction using the Mixed Reality technology. In this research, the fingertip is used as input pointer to interact with the virtual environment. This methodology represents the combination of the VR technology and the AR technology. The methodology that is used to implement this fingertip in this Mixed Reality environment is called hand segmentation. This application developed is Android platform. Unity 3D is the game engine used in this research.","2338-185X","978-1-5386-2827-0","10.1109/ICTS.2017.8265688","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8265688","Room Arrangement;Mixed Reality;Virtual Reality;Augmented Reality;Google Card Board","Information and communication technology;Augmented reality;Google;Technological innovation;Virtual environments","Android (operating system);augmented reality;search engines;solid modelling","Mixed Reality technology;virtual environment;VR technology;Mixed Reality environment;3D virtual room arrangement;augmented reality;Google card board;Android platform;game engine","","5","","7","IEEE","22 Jan 2018","","","IEEE","IEEE Conferences"
"Usage of Mixed Reality for Military Simulations","W. G. R. M. P. S. Rathnayake","Faculty of Information Technology, University of Moratuwa, Sri Lanka","2018 International Conference on Current Trends towards Converging Technologies (ICCTCT)","29 Nov 2018","2018","","","1","5","Today, Mixed Reality is one of most enhanced, attractive method to simulate a virtual thing as real. Mixed Reality has two separated technologies; Virtual Reality (VR) and Augmented Reality (AR). This paper presents, Usage of Mixed Reality for Military Simulations in the ground field, benefits of Mixed Reality in Military and Drawbacks of Mixed Reality in Military. On the ground, most of soldiers has to put their life on the fence which has two sides, life and Death. To bring them to the live side, they need a large amount of training regarding the battlefield. This research paper presents how mixed reality helps them to train accurately, what are the drawbacks and how they can improve.","","978-1-5386-3702-9","10.1109/ICCTCT.2018.8550993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550993","Augmented Reality;Mixed Reality;Virtual Reality;Military;Battlefield;Simulation","Training;Global Positioning System;Solid modeling;Augmented reality;Military aircraft;Conferences","augmented reality;military computing","mixed reality;military simulations;virtual reality;augmented reality;VR;AR","","5","","11","IEEE","29 Nov 2018","","","IEEE","IEEE Conferences"
"Towards an AR game for walking rehabilitation: Preliminary study of the impact of augmented feedback modalities on walking speed","A. -L. Guinet; G. Bouyer; S. Otmane; E. Desailly","Pôle Recherche et Innovation, Fondation Ellen Poidatz &; IBISC, Univ Evry, Université Paris-Saclay, Evry, France; IBISC, Univ Evry, Université Paris-Saclay, Evry, Francee; IBISC, Univ Evry, Université Paris-Saclay, Evry, Francee; Pôle Recherche et Innovation, Fondation Ellen, Poidatz, France","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","264","268","Designing a serious game for walking rehabilitation requires compliance with the theory of motor learning. Motivation, repetition, variability and feedback are key elements in improving and relearning a new walking pattern. As a preamble to the development of an AR rehabilitation game, and in order to choose the most effective feedback to provide to the patient, this article presents a preliminary study on the impact of presentation modalities on walking speed. We investigate which visual concurrent feedback modalities allows to reach and maintain a target speed (maximum or intermediate). Our first results on children with motor disabilities (n=10) show that some modalities improved walking performance and helped patients to better control their walking speed. In particular, a combination of targets anchored in the real world with a time indication seems to be effective in maintaining maximum walking speed, while simple moving objects could be used to control speed.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288377","Cerebral palsy;walking rehabilitation;augmented reality;serious game;feedback","Legged locomotion;Visualization;Pediatrics;Design methodology;Games;Augmented reality","augmented reality;control engineering computing;feedback;gait analysis;handicapped aids;medical computing;patient rehabilitation;serious games (computing);velocity control","visual concurrent feedback modalities;maximum walking speed;AR game;augmented feedback modalities;serious game;walking pattern;AR rehabilitation game;children with motor disabilities;speed control;motor learning theory;motivation;repetition;variability;feedback","","","","34","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Real time stereo rendering for augmented reality on 3DTV system","Y. Li; D. -X. Li; L. -H. Wang; M. Zhang","Institute of Information and Communication Engineering, University of Zhejiang, Hangzhou, China; Institute of Information and Communication Engineering, University of Zhejiang, Hangzhou, China; Institute of Information and Communication Engineering, University of Zhejiang, Hangzhou, China; Institute of Information and Communication Engineering, University of Zhejiang, Hangzhou, China","2012 International Conference on Systems and Informatics (ICSAI2012)","25 Jun 2012","2012","","","2125","2129","Recent computer vision technology has made great progress in 3DTV industry. The advent of 3DTV to the home raises a number of challenges beyond the basic display of an available stereo pair. One of them is the production of 3D augmented contents. To present virtual objects over the real world, the existing method is offline processing in postproduction. It is a difficult and expensive work since flexible equipments are required and the cost of postproduction is high. In this paper, low cost approaches to product 3D augmented contents in real time are proposed. In order to make such application running in real time, we use OpenGL to render the stereo pair of 3D augmented contents. Specific rendering order is needed to avoid the flicker of compositing image. As camera moves, the image of virtual objects must be generated and combined perspectively correct with the real image. We use marker tracking technology for real time camera tracking. The experimental results show that our method is suitable for rendering the stereo pair of 3D augmented contents in real time. Running on an NVIDIA Quadro FX4800 graphic card, for each 640×360 stereo pair of 3D augmented contents, the proposed method reaches the speed of 16 ms for rendering two views.","","978-1-4673-0199-2","10.1109/ICSAI.2012.6223472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6223472","augmented reality;camera tracking;stereo rendering;3DTV","Cameras;Real time systems;Rendering (computer graphics);Image color analysis;Stereo image processing;Augmented reality","application program interfaces;augmented reality;computer vision;object tracking;peripheral interfaces;rendering (computer graphics);stereo image processing;three-dimensional television","real time stereo rendering;augmented reality;3DTV system;computer vision technology;3DTV industry;stereo pair;3D augmented content production;OpenGL;flicker avoidance;marker tracking technology;real time camera tracking;NVIDIA Quadro FX4800 graphic card","","1","","8","IEEE","25 Jun 2012","","","IEEE","IEEE Conferences"
"Collaborative Augmented Reality on Smartphones via Life-long City-scale Maps","L. Platinsky; M. Szabados; F. Hlasek; R. Hemsley; L. D. Pero; A. Pancik; B. Baum; H. Grimmett; P. Ondruska",NA; NA; NA; NA; NA; NA; NA; NA; NA,"2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","533","541","In this paper we present the first published end-to-end production computer-vision system for powering city-scale shared augmented reality experiences on mobile devices. In doing so we propose a new formulation for an experience-based mapping framework as an effective solution to the key issues of city-scale SLAM scalability, robustness, map updates and all-time all-weather performance required by a production system. Furthermore, we propose an effective way of synchronising SLAM systems to deliver seamless real-time localisation of multiple edge devices at the same time. All this in the presence of network latency and bandwidth limitations. The resulting system is deployed and tested at scale in San Francisco where it delivers AR experiences in a mapped area of several hundred kilometers. To foster further development of this area we offer the data set to the public, constituting the largest of this kind to date.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284751","Computer vision;Augmented reality;Structure from motion;Large-scale SLAM;Computing methodologies;Artificial intelligence;Computer vision;Tracking and Reconstruction;Computing methodologies-Mixed/augmented Reality","Production systems;Simultaneous localization and mapping;Scalability;Collaboration;Robustness;Augmented reality;Smart phones","augmented reality;Global Positioning System;groupware;mobile computing;robot vision;SLAM (robots);smart phones","multiple edge devices;AR experiences;collaborative augmented reality;life-long city-scale maps;city-scale shared augmented reality experiences;mobile devices;experience-based mapping framework;city-scale SLAM scalability;map updates;end-to-end production computer-vision system;all-time all-weather performance;smartphones","","10","","40","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Body Language and Augmented Reality Learning Environment","K. -F. Hsiao; H. F. Rashvand","Department of Information Management, Ming-Chuan University, Gwei-Shan, Taiwan; School of Engineering, University of Warwick, Coventry, UK","2011 Fifth FTRA International Conference on Multimedia and Ubiquitous Engineering","18 Aug 2011","2011","","","246","250","A recent national survey of Taiwanese students shows that their physical health condition has been worsening more than many other countries. In this study we examine use of a new learning system enhanced with augmented reality (AR) to address this growing global problem. In order to apply three different physical activities for the experiment the learners use their body language for interacting with the computer. In order to increase effectiveness of the AR system, we then combine students' academic achievement and their preferences for using the system. The experimental results from 419 students indicate much higher achievements in their academic work and gain significantly more those who come with their minds set for stronger challenging preferences in the seven subscales.","","978-1-4577-1228-9","10.1109/MUE.2011.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5992197","augmented reality;virtual reality;learning;education;preference","Learning systems;Augmented reality;Educational institutions;Animation;Conferences","augmented reality;computer aided instruction","body language;augmented reality learning environment;physical health condition;student academic achievement","","13","","21","IEEE","18 Aug 2011","","","IEEE","IEEE Conferences"
"Collaborative Development of an Augmented Reality Application for Digestive and Circulatory Systems Teaching","D. Pérez-López; M. Contero; M. Alcañiz","Instituto de Investigación en Bioingeniería y Tecnología Orientada al Ser Humano (I3BH), Universidad Politecnica de Valencia, Valencia, Spain; Instituto de Investigación en Bioingeniería y Tecnología Orientada al Ser Humano (I3BH), Universidad Politecnica de Valencia, Valencia, Spain; Instituto de Investigación en Bioingeniería y Tecnología Orientada al Ser Humano (I3BH), Universidad Politecnica de Valencia, Valencia, Spain","2010 10th IEEE International Conference on Advanced Learning Technologies","16 Sep 2010","2010","","","173","175","Augmented Reality (AR) appears as a promising technology to improve students motivation and interest and support the learning and teaching process in educational contexts. We present the collaborative development of an AR application to support the teaching of the digestive and circulatory systems. We developed this system with the support of a private Spanish school. The main objective of the application is to show the student in primary school, in the most accurate way, digestive and circulatory systems. By other hand, we also develop our own AR library, HUMANAR, in order to ensure the integration of AR into our game engine and to overcome some drawbacks present in some public libraries. Moreover, our system provides several advantages over the traditional learning as books, videos or practice with animal organs.","2161-377X","978-1-4244-7145-4","10.1109/ICALT.2010.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571227","component;education;augmented reality;mixed reality;interactive 3D graphics;virtual learning environment (VLE);edutainment;circulatory system;digestive system","Education;Circulatory system;Animation;Augmented reality;Digestive system;Three dimensional displays;Cameras","academic libraries;augmented reality;biomedical education;computer aided instruction;game theory;groupware","collaborative development;augmented reality application;digestive system teaching;circulatory system teaching;learning process;Spanish school;AR library;HUMANAR;game engine;public library","","12","","11","IEEE","16 Sep 2010","","","IEEE","IEEE Conferences"
"Design of VR headset using augmented reality","J. J. Aloor; P. S. Sahana; S. Seethal; S. Thomas; M. T. R. Pillai","Dept. of CSE, Jyothi Engineering College, Thrissur, India; Dept. of CSE, Jyothi Engineering College, Thrissur, India; Dept. of CSE, Jyothi Engineering College, Thrissur, India; Dept. of CSE, Jyothi Engineering College, Thrissur, India; HOD, Jyothi Engineering College, Thrissur, India","2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT)","24 Nov 2016","2016","","","3540","3544","Our intention is to develop an android application that gives the users a virtual environment with the help of VR headset. With this application, it allows users to generate an object which doesn't exist in real environment. In Augmented Reality (AR), the interfaces comprises of merging both real and virtual objects. In this project we examine existing gaming styles that are played in the real world or on computers. With the help of advanced AR technology the information about the real world that surrounds the user becomes interactive and digitally manipulable. Artificial information about the environment and its objects can thus be overlaid on the real world. A key distinction to VR purists is the fact that the user is completely immersed in the computer simulation. All our senses are focused on visiting this new place. It provides the following features i.e. Full field of vision display, usually produced by the wearing of a Head Mounted Display, tracking of the location and attitude of the contributor's body, computer tracking of the participant's movements and actions along with some negligible delay in updating the display with feedback from the body's movements and actions. This enables users to visualize what if an object an object actually exists there without its actual existence.","","978-1-4673-9939-5","10.1109/ICEEOT.2016.7755363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7755363","Augmented Reality;Rendering;Tracking;Virtual Reality;Vuforia SDK","Solid modeling;Rendering (computer graphics);Computational modeling;Real-time systems;Accelerometers;Augmented reality;Smart phones","Android (operating system);augmented reality","augmented reality;VR headset design;android application;virtual environment;advanced AR technology;artificial information","","5","","12","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"Educating students in remote areas using augmented reality","S. Ghulamani; S. Zareen","Department of Computer Science, SZABIST Hyderabad Campus, Hyderabad, Pakistan; Department of Computer Science, SZABIST Hyderabad Campus, Hyderabad, Pakistan","2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)","26 Apr 2018","2018","","","1","6","Augmented Reality(AR) technology nowadays is widely used in various fields of education. Students have been learning from books and videos but with AR they can see objects right in front of them, which can make learning more interesting. Companies like Microsoft, google, Facebook and apple are making their products more interactive by providing their customers real life look while using their products. In this paper, a new method of education with the help of AR technology has been proposed for the students in remote areas, to whom proper education is not provided. Further in this paper related work which has already been done and what outcomes can be expected if this method would be implemented done has discussed. Students wearing AR glasses would be able to attend lectures recorded from teachers at far distance, with view as if teacher is present at that moment. Students can be grouped together to see same lectures and discuss with each other. Teachers from various places can also give live lectures to different group of students with AR glasses and give them answers to their questions.","","978-1-5386-1370-2","10.1109/ICOMET.2018.8346350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8346350","Hologram;Microsoft HoloLens;AR;Augmented Reality;Education;VR;Virtual Reality","Education;Three-dimensional displays;Augmented reality;Glass;Videos;Tools","augmented reality;distance learning;social networking (online);wearable computers","apple;customers real life look;AR technology;remote areas;proper education;AR glasses;teacher;live lectures;books;videos;Microsoft;google;Augmented Reality technology","","4","","16","IEEE","26 Apr 2018","","","IEEE","IEEE Conferences"
"Development of educational resources with virtual and augmented reality: Challenges and perspectives","A. Cardoso; I. F. Mackenzie; C. Kirner; R. Tori","Universidade Federal de Uberlandia, Uberlandia, MG, BR; Universidade Presbiteriana Mackenzie, Sao Paulo, SP, BR; UNIFEI Universidade Federal de Itajubá, Itajubá, Brasil; USP Universidade de São Paulo - USP, São Paulo, Brasil","2017 XLIII Latin American Computer Conference (CLEI)","21 Dec 2017","2017","","","1","6","This paper discusses the challenges related to the insertion of Virtual and Augmented Reality in the teaching and learning processes, considering their multidisciplinary aspect, the adherence to Web 3.0 and a scenario of possible gains and results with such an insertion. There will be pointed out the features that made VR and AR solutions with a potential big impact, despite not properly explored. as well as the challenges that are presented to Computers and Education field, and possible approaches to solve them.","","978-1-5386-3057-0","10.1109/CLEI.2017.8226390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8226390","Virtual Reality;Augmented Reality;Educational Resources","Three-dimensional displays;Visualization;Augmented reality;Software;Internet;Smart phones;Education","augmented reality;computer aided instruction;teaching","educational resources;augmented reality;learning processes;teaching processes;computers and education field","","2","","","IEEE","21 Dec 2017","","","IEEE","IEEE Conferences"
"Error Detection using Augmented Reality in the Subtractive Manufacturing Process","M. H. Sreekanta; A. Sarode; K. George","Computer Engineering, California State University Fullerton, Fullerton, California; Electrical Engineering, California State University Fullerton, Fullerton, California; Computer Engineering, California State University Fullerton, Fullerton, California","2020 10th Annual Computing and Communication Workshop and Conference (CCWC)","12 Mar 2020","2020","","","0592","0597","A small error in subtractive manufacturing can adversely impact an entire production if not caught right away. By utilizing an Augmented Reality (AR) simulation, workers can view in real-time when the machine malfunctions, stop the process and correct it. AR will also improve the visualization of the object. This paper sets the initial stage for our future work in which the manufacturing defects can be detected in real-time. In this paper, error detection in dimensions was tested using OpenCV-Python and compared using a single web camera and intel real-sense D435i stereo camera, Augmenting AR block over the original block using Unity software in real-time, and operation of the switch to control the machine using AR was successfully tested.","","978-1-7281-3783-4","10.1109/CCWC47524.2020.9031141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031141","Augmented Reality;Intel Real-Sense D435i Camera;OpenCV;Computer Vision;Error Detection;Unity;Python;Subtractive Manufacturing Error Detection","Cameras;Plugs;Three-dimensional displays;Augmented reality;Real-time systems;Python;Solid modeling","augmented reality;cameras;object detection;production engineering computing;stereo image processing","error detection;subtractive manufacturing process;augmented reality simulation;machine malfunctions;manufacturing defects;Web camera;OpenCV-Python;Intel real-sense D435i stereo camera;Augmenting AR block","","2","","9","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"A Low cost Augmented Reality system for Wide Area Indoor Navigation","V. Dosaya; S. Varshney; V. K. Parameshwarappa; A. Beniwal; S. Tak","Department of Information Science and Engineering, Ramaiah Institute of Technology, Bangalore, India; Department of Information Science and Engineering, Ramaiah Institute of Technology, Bangalore, India; Department of Information Science and Engineering, Ramaiah Institute of Technology, Bangalore, India; Department of Information Science and Engineering, Ramaiah Institute of Technology, Bangalore, India; Department of Information Science and Engineering, Ramaiah Institute of Technology, Bangalore, India","2020 International Conference on Decision Aid Sciences and Application (DASA)","15 Jan 2021","2020","","","190","195","In today's world, there are a lot of outdoor navigation apps for visually challenged people, but there are none that can precisely tell a user's location inside a large structure. Indoor navigation is a complex task for the visually challenged as well as for the general public, especially in large structures like malls, airports, museums, factories, etc. Present solutions and technologies are not cost-effective as well as complex. Hence, we are proposing a low-cost model that uses Augmented Reality to place virtual anchors across a structure, so a person can navigate from one location to another with the help of these anchors. The model doesn't use technologies like GPS. Machine Learning, and Artificial Intelligence but here, the anchors placed are pervasive and persistent across the indoor environment for smooth navigation. Once placed, these virtual anchors remain at their location and can be used at any time by any person registered on our app. This model can be extended for the general public in any indoor space and also can be enhanced by gamification for better user interaction and retention. This model can also be extended to collaborate with the Aarogya Setu app, which can help us identify routes that go through spaces through which covid positive patients have passed which in turn helps us avoid those routes in real-time navigation.","","978-1-7281-9677-0","10.1109/DASA51403.2020.9317014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317014","Augmented reality;GPS;Blind Navigation;Indoor Navigation;Mixed Reality;Unity;Covid-19;Vector Mapping","Augmented reality;Smart phones;Mobile applications;Indoor navigation;Global Positioning System;Cloud computing;COVID-19","augmented reality;computer games;handicapped aids;learning (artificial intelligence);mobile computing","wide area indoor navigation;outdoor navigation apps;visually challenged people;complex task;general public;low-cost model;virtual anchors;machine learning;artificial intelligence;indoor environment;smooth navigation;indoor space;user interaction;Aarogya Setu app;real-time navigation;low cost augmented reality system","","2","","10","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"Augmented Reality and Sensory Technology for Treatment of Anxiety Disorders","P. Arquissandás; D. Lamas; J. Oliveira","COFAC/ ULHT - University Lusófona, COPELABS, Lisbon, Portugal; COPELABS, COFAC/ ULHT - University Lusófona, Lisbon, Portugal; HEI-LAB, COFAC / ULHT - University Lusófona, Lisbon, Portugal","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","4","This solution aims at promoting well-being through Augmented Reality (AR) Sensing Based Technology, by developing a predictive system for treatment of specific phobias. Treatment of such mental disorders involves exposure therapy, which is usually conducted on a gradual and systematic basis, allowing modifications in the therapeutic setting with different exposure sessions. To meet these conditions, the therapist needs to evaluate the patient's responses in the previous sessions to define the content of the subsequent sessions. Therefore, we intend to use the psycho-physiological responses from the participants during the sessions through peripheral (i.e. ECG, EDA, EMG) and central nervous system responses (i.e. EEG) associated with emotional expression, as well as the participatory input to a visual analog scale (i.e. tactile feedback input system, avoiding huge hands movements and interruptions during carrying session) as an indicator of the subjective experience of emotions during the session (i.e. figures with different moods). This data will be also used to define the contents of each session, through a decision algorithm based on the history of the previous sessions for the same individual. All data resulting from this application will be recorded in a database to create individual reports on the session outcomes. The hardware to be used for psycho-physiological recording will be the Bitalino system (Plux) and the software for the AR development the NyARToolkit and Unity 3D software. We plan to carry out a pilot study with data collection in the laboratory setting to test the module related to the integration of psycho-physiological and participatory data in the AR system.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760859","Augmented Reality;Virtual Reality;Anxiety Disorder;NyARToolkit;Unity 3D;Bitalino;Sensors","Medical treatment;Stress;Sensors;Augmented reality;Visualization;Three-dimensional displays;Task analysis","augmented reality;electroencephalography;electromyography;medical disorders;medical signal processing;neurophysiology;patient treatment;psychology","psychophysiological responses;exposure sessions;hands movements;psychophysiological recording;psychophysiological data;central nervous system responses;decision algorithm;EEG;visual analog scale;ECG;EDA;EMG;tactile feedback input system;carrying session;systematic basis;gradual basis;exposure therapy;mental disorders;predictive system;anxiety disorders;sensory Technology;Augmented Reality;AR system;Bitalino system;feedback input system","","1","","32","","15 Jul 2019","","","IEEE","IEEE Conferences"
"Identifying Usability Issues of Software Analytics Applications in Immersive Augmented Reality","D. Baum; S. Bechert; U. Eisenecker; I. Meichsner; R. Müller","Leipzig University, Leipzig, Germany; Leipzig University, Leipzig, Germany; Leipzig University, Leipzig, Germany; Leipzig University, Leipzig, Germany; Leipzig University, Leipzig, Germany","2020 Working Conference on Software Visualization (VISSOFT)","30 Oct 2020","2020","","","100","104","Software analytics in augmented reality (AR) is said to have great potential. One reason why this potential is not yet fully exploited may be usability problems of the AR user interfaces. We present an iterative and qualitative usability evaluation with 15 subjects of a state-of-the-art application for software analytics in AR. We could identify and resolve numerous usability issues. Most of them were caused by applying conventional user interface elements, such as dialog windows, buttons, and scrollbars. The used city visualization, however, did not cause any usability issues. Therefore, we argue that future work should focus on making conventional user interface elements in AR obsolete by integrating their functionality into the immersive visualization.","","978-1-7281-9914-6","10.1109/VISSOFT51673.2020.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240485","usability evaluation;software analytics;software visualization;augmented reality;mixed reality","Visualization;Urban areas;User interfaces;Software;Usability;Augmented reality;Standards","augmented reality;data visualisation;software engineering;user interfaces","qualitative usability evaluation;usability issues;user interface elements;immersive visualization;software analytics;immersive augmented reality;AR user interfaces;iterative usability evaluation;city visualization","","1","","18","IEEE","30 Oct 2020","","","IEEE","IEEE Conferences"
"A study on instruction of three dimensional motion for task support using augmented reality","K. Iwamoto","National Institute of Advanced Industrial Science and Technology, Tsukuba-shi, Japan","2017 6th International Conference on Electrical Engineering and Informatics (ICEEI)","12 Mar 2018","2017","","","1","6","Studies on manufacturing task support that can present appropriate task instructions to the workers according to the situation using augmented reality are being advanced. Thereby, even a worker who is not an expert can perform various manufacturing tasks. In this technique, a task instructions are superimposed on the captured image of the work object. Then, by presenting the synthesized image to the worker through the visual display, the task instructions are performed. Recently, the application of this technology to various manufacturing tasks has been studied. In the conventional task instruction presentation research, the presentation information was mainly static information such as mounting position of the parts, place of the operation switch and presentation of operation procedure. However, in some manufacturing tasks, it is important to operate a work tool along a three-dimensional trajectory such as assembly task, soldering, welding task, pouring task and so on. In such tasks, it is necessary to present the three-dimensional position, orientation and trajectory of the work tool to the operator. In contrast to the static information mentioned above, these can be said to be the manufacturing task support technology to present dynamic information. In this paper, an instruction of presenting three-dimensional motion for task support is examined. Then, in order to confirm its effectiveness, the results of the evaluation experiments using the operators are reported.","2155-6830","978-1-5386-0475-5","10.1109/ICEEI.2017.8312379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8312379","Manufacturing support;Task support;Augmented reality;Virtual reality;Video see-through display","Tools;Three-dimensional displays;Trajectory;Erbium;Task analysis;Augmented reality","augmented reality;image capture;manufacturing processes;production engineering computing","augmented reality;manufacturing tasks;presentation information;static information;work tool;assembly task;manufacturing task support technology;task instructions;three-dimensional position;three-dimensional motion;three-dimensional orientation;three-dimensional trajectory;captured image","","1","","10","IEEE","12 Mar 2018","","","IEEE","IEEE Conferences"
"Theoretical Foundations of Virtual and Augmented Reality-Supported Learning Analytics","A. Christopoulos; N. Pellas","Dept. of Future Technologies Center for Learning Analytics, University of Turku, Turku, Finland; Dept. of Communication and Digital Media, University of Western Macedonia, Kastoria, Greece","2020 11th International Conference on Information, Intelligence, Systems and Applications (IISA","11 Dec 2020","2020","","","1","4","A significant body of literature documents the numerous benefits that Virtual (VR) and Augmented Reality (AR) supported interventions have brought to the educational scenery, especially with regards to the attainment of the underpinning objectives. At the same time, the vast evolution of Information and Communication Technology (ICT) has led to the emergence of a newly formed discipline, the so-called Learning Analytics (LA), which suggests the collection of big data' for the assessment and the evaluation of the educational practices. However, by examining the relevant literature it became apparent that the attempts to blend these topics are limited. Motivated by this shortcoming, we propose a theoretical framework which accounts the elements that influence the educational processes and the unique features that immersive technologies have. On the grounds of this framework, an effort will be made to design and develop a universal LA system which will support the conduct and evaluation of such interventions in different educational contexts and scientific fields.","","978-1-6654-2228-4","10.1109/IISA50023.2020.9284410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284410","Virtual Reality;Augmented Reality;Instructional Design;Learning Analytics;STEM Education","Education;Information and communication technology;Augmented reality","augmented reality;computer aided instruction","educational scenery;information and communication technology;big data;educational practices;educational processes;immersive technologies;augmented reality-supported learning analytics;educational contexts","","1","","24","IEEE","11 Dec 2020","","","IEEE","IEEE Conferences"
"Multi-scale panoramic Augmented Reality","E. Arican; K. E. Özden; S. Oğuz","Bilgisayar Mühendisliği Bölümü, Bahçeşehir Üniversitesi, Istanbul, Turkey; Bilgisayar Mühendisliği Bölümü, Bahçeşehir Üniversitesi, Istanbul, Turkey; Bilgisayar Mühendisliği Bölümü, Bahçeşehir Üniversitesi, Istanbul, Turkey","2013 21st Signal Processing and Communications Applications Conference (SIU)","13 Jun 2013","2013","","","1","4","We are describing an Augmented Reality (AR) system which uses a panoramic representation and aims at easy interaction with the environment. The final target is to render meta data about the environment in the right place on the images coming from the mobile device's camera. The local feature points on the images coming from a rotating camera with varying zoom levels are put into a hierarchical tree structure which represents a panoramic image. Panoramic images as anchor is getting more attention in AR field and novel aspects of our work can be described as follows: 1- Panoramic representation is multi-scale, tree structured and consists of local image features 2-The proposal of multi-scale “Augmented Knowledge”. Our system can achieve lower error rates for close-up scenes in comparison to classical non-vision techniques and image lookup is efficient thanks to the tree structure. Since only local images features are kept, many complicated steps for actual panorama creation are avoided while the need for global optimization of the computed geometry is minimized.","","978-1-4673-5563-6","10.1109/SIU.2013.6531539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6531539","multi scale augmented reality;panaromic images;computer vision","Augmented reality;Cameras;Geometry;Computer vision;Google;Abstracts;Mobile communication","augmented reality;feature extraction;image representation;meta data","multiscale panoramic augmented reality;AR system;panoramic representation;meta data;mobile device camera;local feature points;rotating camera;varying zoom levels;hierarchical tree structure;panoramic image;local image features;multiscale augmented knowledge;close-up scenes;classical nonvision techniques;image lookup;panorama creation;global optimization;computed geometry","","","","12","IEEE","13 Jun 2013","","","IEEE","IEEE Conferences"
"Towards training an agent in augmented reality world with reinforcement learning","V. V. R. M. K. R. Muvva; N. Adhikari; A. D. Ghimire","Department of Computer Science, Mississippi State University, Starkville, MS, USA; Department of Computer Science, Mississippi State University, Starkville, MS, USA; Department of Computer Science, Mississippi State University, Starkville, MS, USA","2017 17th International Conference on Control, Automation and Systems (ICCAS)","14 Dec 2017","2017","","","1884","1888","Reinforcement learning (RL) helps an agent to learn an optimal path within a specific environment while maximizing its performance. Reinforcement learning (RL) plays a crucial role on training an agent to accomplish a specific job in an environment. To train an agent an optimal policy, the robot must go through intensive training which is not cost-effective in the real-world. A cost-effective solution is required for training an agent by using a virtual environment so that the agent learns an optimal policy, which can be used in virtual as well as real environment for reaching the goal state. In this paper, a new method is purposed to train a physical robot to evade mix of physical and virtual obstacles to reach a desired goal state using optimal policy obtained by training the robot in an augmented reality (AR) world with one of the active reinforcement learning (RL) techniques, known as Q-learning.","","978-89-93215-14-4","10.23919/ICCAS.2017.8204283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8204283","Reinforcement Learning;Virtual Reality;Augmented Reality;Fiducial Markers","Artificial intelligence;Augmented reality;Robots","augmented reality;learning (artificial intelligence);multi-agent systems","augmented reality;Q-learning;active reinforcement learning techniques;virtual environment;cost-effective solution;intensive training;optimal policy;RL","","","","12","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Transfer Learning algorithm in image analysis with Augmented Reality headset for Industry 4.0 technology","M. Kozek","Faculty of Mechanical Engineering and Robotics, AGH University of Science and Technology, Krakow, Poland","2020 International Conference Mechatronic Systems and Materials (MSM)","22 Sep 2020","2020","","","1","5","Modern technology lines in Industry 4.0 standard use many complex smart systems to improve the speed of production. Manufacturing becomes more flexible and, on the other hand, more demanding for a process operator. This article presents mixed reality glasses that supports the work of the operator integrated via a cloud with a technology line. Transfer learning algorithm is shown in a set of artificial neural network algorithms belonging to the Deep Learning class to analyze the image from ML headset. This algorithm is designed to recognize the current occupation of the storage tray with direct transmission of information to the control and measurement system.","","978-1-7281-6956-9","10.1109/MSM49833.2020.9201739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201739","machine learning;Industry 4.0;Augmented Reality;Mixed Reality","Robots;Industries;Training;Augmented reality;Headphones;Neural networks","augmented reality;flexible manufacturing systems;image processing;learning (artificial intelligence);neural nets;production engineering computing","cloud computing;flexible manufacturing;smart systems;Industry 4.0 standard;augmented reality headset;image analysis;ML headset;deep learning;artificial neural network;transfer learning;mixed reality glasses","","5","","13","IEEE","22 Sep 2020","","","IEEE","IEEE Conferences"
"An Augmented Reality 3D Pop-Up Book: The Development of a Multimedia Project for English Language Teaching","P. Vate-U-Lan","College of Internet Distance Education, Assumption University, Bangkok, Thailand","2012 IEEE International Conference on Multimedia and Expo","13 Sep 2012","2012","","","890","895","Augmented Reality (AR) for academic purposes is growing in the same upward direction as the expansion of smart multimedia into education and lifelong learning. This paper reports on an AR curriculum materials research and development project which employs storytelling as a teaching technique in a blended learning environment for Grade Three students in Bangkok learning English. It involved an AR 3D pop-up book as a tool for teachers to deliver the story of a children's book, namely The Seed Shooting Game, to teach various English language aspects to young children. The primary rationale supporting this research was the high demand and appreciation of the potential to integrate Augmented Reality into classrooms effectively to enhance learning. This article aims to detail each phase of the production process: pre-production, production and post production. The population for this study were 484 Grade Three Thai students of whom 99 were purposively selected. An added finding was the depth of learning - comprehension and engagement gained from the English lesson were higher than their pre-test scores. The majority of participants indicated that the Augmented Reality book was a stimulating educational resource that increased the desire to learn.","1945-788X","978-1-4673-1659-0","10.1109/ICME.2012.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6298515","3D pop-up book;Augmented Reality;blended learning;children's book;e-learning;elementary level;multimedia;storytelling;teaching English as a foreign language","Multimedia communication;Materials;Education;Games;Augmented reality;Production","augmented reality;computer aided instruction;computer games;educational courses;multimedia computing;natural languages;teaching","augmented reality;smart multimedia;AR curriculum material;storytelling;blended learning environment;AR 3D pop-up book;seed shooting game;learning enhancement;educational resource;English language teaching","","34","","14","IEEE","13 Sep 2012","","","IEEE","IEEE Conferences"
"Mobile augmented reality based on cloud computing","B. -R. Huang; C. H. Lin; C. -H. Lee","Department of Electronic Engineering and Computer, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Electronic Engineering and Computer, National Taiwan University of Science and Technology, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan","Anti-counterfeiting, Security, and Identification","11 Oct 2012","2012","","","1","5","In this paper, we implemented a mobile augmented reality system based on cloud computing. This system uses a mobile device with a camera to capture images of book spines and sends processed features to the cloud. In the cloud, the features are compared with the database and the information of the best matched book would be sent back to the mobile device. The information will then be rendered on the display via augmented reality. In order to reduce the transmission cost, the mobile device is used to perform most of the image processing tasks, such as the preprocessing, resizing, corner detection, and augmented reality rendering. On the other hand, the cloud is used to realize routine but large quantity feature comparisons. Using the cloud as the database also makes the future extension much more easily. For our prototype system, we use an Android smart phone as our mobile device, and Chunghwa Telecoms hicloud as the cloud.","2163-5056","978-1-4673-2145-7","10.1109/ICASID.2012.6325354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6325354","cloud computing;augmented reality;fast corner detection","Augmented reality;Mobile handsets;Databases;Books;Cloud computing;Performance evaluation;Servers","augmented reality;cameras;cloud computing;edge detection;image matching;mobile computing;rendering (computer graphics);smart phones","mobile augmented reality rendering system;cloud computing;mobile device;cameras;image capturing;book spine matching;transmission cost reduction;image preprocessing;image resizing;image corner detection;feature comparisons;Android smart phone;Chunghwa Telecoms hicloud","","21","","17","IEEE","11 Oct 2012","","","IEEE","IEEE Conferences"
"The Development and Evaluation of an Educational Game Integrated with Augmented Reality and Virtual Laboratory for Chemistry Experiment Learning","H. -T. Hou; Y. -C. Lin","National Taiwan University of Science and Technology, Taipei, TW; National Taiwan University of Science and Technology, Taipei, TW","2017 6th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","16 Nov 2017","2017","","","1005","1006","Virtual laboratory helps students' learning of experiment manipulation and scientific concepts before they actually enter the real chemistry laboratory. It also helps reduce the risks in conducting the real chemistry experiments and reduce the cost for chemistry experiment materials. This study developed an educational game ""O2 LAB©"", on the mobile device that combined augmented reality and virtual laboratory. It is's a game-based learning system integrated with augmented reality, anchored instruction, and virtual laboratory. The game includes two stages (the AR exploration stage and the virtual experiment stage). Fifty-two senior high school students participated in this study. The results show that the students improved their learning significantly after the game and the scores in each dimension of flow and acceptance are both high.","","978-1-5386-0621-6","10.1109/IIAI-AAI.2017.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113394","game-based learning;flow;virtual laboratory;augmented reality","Chemistry;Games;Augmented reality;Security;Mobile handsets;Tablet computers;Reflection","augmented reality;chemistry computing;educational institutions;laboratories;learning management systems;serious games (computing);student experiments;virtual instrumentation","augmented reality;virtual laboratory;chemistry experiment learning;experiment manipulation;chemistry laboratory;chemistry experiment materials;virtual experiment stage;educational game;scientific concepts;O2 LAB;mobile device;game-based learning system;anchored instruction;senior high school students","","16","","6","IEEE","16 Nov 2017","","","IEEE","IEEE Conferences"
"Augmented Reality in agriculture","A. Nigam; P. Kabra; P. Doke","TCS Innovation Laboratories, Tata Consultancy Services Limited, Thane, India; TCS Innovation Laboratories, Tata Consultancy Services Limited, Thane, India; TCS Innovation Laboratories, Tata Consultancy Services Limited, Thane, India","2011 IEEE 7th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)","21 Nov 2011","2011","","","445","448","This paper presents a prototype Augmented Reality system which we have developed for farmers. It uses Augmented Reality for aiding the farmers in insect identification and pest management. Traditionally, farmers in India are not trained entomologists and tend to destroy insects found in their fields. However, not all bugs deserve this treatment and are in fact sometimes needed for the wellbeing of the farm and the ecosystem. With an innovative application of Augmented Reality, we intend to aid the rural farmer in identification of the bugs and pest management. This identification system would suggest the farmers appropriate pesticides and treatments for the bugs. This concept can be later extended to catalogue and educate the rural population about India's rich flora and fauna.","2160-4894","978-1-4577-2014-7","10.1109/WiMOB.2011.6085361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6085361","Rural;Augmented Reality;Agriculture;Entomology;ICT;ICT4D","Augmented reality;Insects;Computer bugs;Agriculture;Mobile communication;Mobile handsets;Databases","agriculture;augmented reality;innovation management;pest control","agriculture;augmented reality system;farmers;insect identification;pest management;entomologists;ecosystem;innovative application;India","","16","","17","IEEE","21 Nov 2011","","","IEEE","IEEE Conferences"
"A Convenient Method of Video See-Through Augmented Reality Based on Image-Guided Surgery System","L. Hu; M. Wang; Z. Song","Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai, China; Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai, China; Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai, China","2013 Seventh International Conference on Internet Computing for Engineering and Science","12 Dec 2013","2013","","","100","103","Augmented Reality (AR) is a technology which is widely used in medical area, especially in surgery room. In many cases, cumbersome equipments or complicated algorithm are introduced to establish the whole system, which would make it inefficient and unsuitable for surgery environment. This paper presents a convenient method for video see-through augmented reality on the basis of existing image-guided surgery system developed by our research center. We describe the prototype of the system, the registration of virtual objects in a marker coordinate system, and the motion tracking of the Head Mounted Display (HMD) using A Toolkit. Finally, we present the experiment results which show that the proposed AR technology can provide augmented information for the surgeons and work well with existing image-guided surgery system.","2330-9857","978-0-7695-5118-0","10.1109/ICICSE.2013.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680063","Augmented reality;Image-guided surgery;Tracking system","Surgery;Augmented reality;Tracking;Biomedical optical imaging;Optical imaging;Calibration;Cameras","augmented reality;helmet mounted displays;image motion analysis;image registration;medical image processing;object tracking;surgery;video signal processing","medical area;surgery room;video see-through augmented reality;image-guided surgery system;virtual objects registration;marker coordinate system;motion tracking;head mounted display;HMD;AR technology","","11","20","10","IEEE","12 Dec 2013","","","IEEE","IEEE Conferences"
"Developing Augmented Reality book for deaf in science: The determining factors","N. M. M. Zainuddin; H. B. Zaman; A. Ahmad","Department of Information Science, Universiti Kebangsaan Malaysia, Bangi, Selangor Darul Ehsan, Malaysia; Department of Information Science, Universiti Kebangsaan Malaysia, Bangi, Selangor Darul Ehsan, Malaysia; Department of Information Science, Universiti Kebangsaan Malaysia, Bangi, Selangor Darul Ehsan, Malaysia","2010 International Symposium on Information Technology","2 Sep 2010","2010","1","","1","4","Augmented Reality book is one of augmented reality applications. Augmented reality is a current technology which is based on visually oriented technique. Its visual capability is useful in many applications such as in teaching abstract concepts in learning Science. This article is a part of continuous work in the development of AR book for deaf students. This paper describes the investigation conducted in identifying the determining factors in designing the AR book for deaf students. The qualitative approaches such as observation and interaction techniques were conducted with three deaf students. From the observation and interaction, the researcher found that they preferred to use sign language video compared to text. The students preferred English text to Malay text and they preferred to watch the Whole Communication sign language video instead of the American Sign Language video. However, their performance was not so much different in their given answer. This prompted the researcher to design and develop an AR-Book called AR-SiD in two languages; Bahasa Malaysia and English. The designed AR-SiD is aimed to enhance the understanding of deaf students in learning Microorganisms topic in Science.","2155-899X","978-1-4244-6718-1","10.1109/ITSIM.2010.5561325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561325","Augmented reality;deaf;special education","Handicapped aids;Books;Education;Augmented reality;Pediatrics;Visualization;Microorganisms","augmented reality;computer aided instruction;handicapped aids;microorganisms;natural sciences computing","augmented reality book;science;visually oriented technique;deaf students;sign language video;AR-SiD;microorganisms topic","","10","","25","IEEE","2 Sep 2010","","","IEEE","IEEE Conferences"
"ARmatika: 3D game for arithmetic learning with Augmented Reality technology","J. C. Young; M. B. Kristanda; S. Hansun","Department of Computer Science, Universitas Multimedia Nusantara, Tangerang; Department of Computer Science, Universitas Multimedia Nusantara, Tangerang; Department of Computer Science, Universitas Multimedia Nusantara, Tangerang","2016 International Conference on Informatics and Computing (ICIC)","24 Apr 2017","2016","","","355","360","Learning mathematics is one of the most important aspects that determine the future of learners. However, mathematics as one of the subjects is often perceived as being complicated and not liked by the learners. Therefore, we need an application with the use of appropriate technology to create visualization effects which can attract more attention from learners. The application of Augmented Reality technology in digital game is a series of efforts made to create a better visualization effect. In addition, the system is also connected to a leaderboard web service in order to improve the learning motivation through competitive process. Implementation of Augmented Reality is proven to improve student's learning motivation moreover implementation of Augmented Reality in this game is highly preferred by students.","","978-1-5090-1648-8","10.1109/IAC.2016.7905744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7905744","Mathematics Learning;Visualization Effect;Digital Games;Augmented Reality;Arithmetic","Games;Augmented reality;Mathematics;Pressing;Informatics;Education","augmented reality;computer aided instruction;computer games;human factors;mathematics computing;Web services","ARmatika;3D game;arithmetic learning;augmented reality technology;mathematic learning;digital game;visualization effect;student learning motivation improvement;leaderboard Web service","","9","","22","IEEE","24 Apr 2017","","","IEEE","IEEE Conferences"
"MUZZEUM — Augmented Reality and QR codes enabled mobile platform with digital library, used to Guerrilla open the National Museum of Serbia","V. Jevremovic; S. Petrovski","Department of Archaeology, Faculty of Philosophy, University of Belgrade, Belgrade, Serbia; Department of Anthropology, Faculty of Philosophy, University of Belgrade, Belgrade, Serbia","2012 18th International Conference on Virtual Systems and Multimedia","3 Dec 2012","2012","","","561","564","Serbian National Museum has been closed for past 10 years for renovation. Furthermore, certain inadequate actions of the Government and national cultural institutions have been made. A group of activists decided to make a statement and perform a virtual exhibition in front of the National museum by using QR codes and Augmented Reality. This paper focuses on technical and social implications of consumption and implementation of QR codes and Augmented Reality in terms of museology, cultural heritage, objects and relationship they create with people who are their potential consumers. In the case study, we are tackling here, we investigate the transformation in definitions of space, artifacts, visitor and the power of representation in terms of museology. Since the artifacts which represent the Serbian national heritage of the highest rank are being held in museum depots far from the eyes of the public for such a long time, the project team has produced QR codes which will bring some of the masterpieces back to its audience. The objects from different museums will be represented by special ARQR codes outside of the museum building, reachable by smartphones. This socially engaged project sends direct message to the wider public that usage of IT, mobile technologies, Augmented Reality and QR codes can potentially transform the way we communicate cultural heritage.","","978-1-4673-2563-9","10.1109/VSMM.2012.6365977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365977","MUZZEUM;Augmented;Reality;QR;Code;Cultural;Heritage;National;Museum;Serbia;Mobile;Internet;3D;objects","Cultural differences;Augmented reality;Mobile communication;Libraries;Internet;Global communication;Art","augmented reality;codes;digital libraries;exhibitions;government;history;Internet;mobile computing;museums;smart phones","MUZZEUM project;augmented reality;QR codes;digital library;guerrilla open;museum renovation;government;national cultural institutions;virtual exhibition;museology;cultural heritage;Serbian national heritage;museum depots;masterpieces;ARQR codes;museum building;smartphones;IT;mobile technology;Internet;National Museum of Serbia","","7","","10","IEEE","3 Dec 2012","","","IEEE","IEEE Conferences"
"Development trend analysis of augmented reality system in educational applications","Y. -S. Lai; J. -M. Hsu","Shin-Guang Elementary School, Yunlin, Taiwan; Department of Computer Science and Information Engineering, National Chiayi University, Chiayi, Taiwan","2011 International Conference on Electrical and Control Engineering","24 Oct 2011","2011","","","6527","6531","With the rapid development of information technology, computer-assisted learning and instruction integrated with information technology, these technologies have been widely used in the traditional classroom. The concept of augmented reality is to place computer graphics on the real environment. It provides an interactive and intuitional interface to help users for observing the three-dimensional virtual objects in the real world. Currently, most of augmented reality (AR) applications focus on the research issues, such as military, medicine, and game. This study investigates the educational development and application of AR system in recent years. This study also analyzes the acceptance and effectiveness of augmented reality as well as the trend in education.","","978-1-4244-8165-1","10.1109/ICECENG.2011.6056941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6056941","multimedia learning;augmented reality;e-Learning;learning strategy","Augmented reality;Educational institutions;Three dimensional displays;Computer science;Computers;Games","augmented reality;computer aided instruction;graphical user interfaces;interactive systems","information technology;computer assisted learning;computer assisted instruction;augmented reality;computer graphics;interactive interface;intuitional interface;three-dimensional virtual objects;educational application","","5","","","IEEE","24 Oct 2011","","","IEEE","IEEE Conferences"
"Multi-Object Oriented Augmented Reality for Location-Based Adaptive Mobile Learning","W. Chang; Q. Tan; F. W. Tao","School of computing and information systems, Athabasca University, Athabasca, Canada; School of computing and information systems, Athabasca University, Athabasca, Canada; Centre of network and information, Chongqing University, Chongqing, China","2010 10th IEEE International Conference on Advanced Learning Technologies","16 Sep 2010","2010","","","450","451","This research aims to bring up a strategy called Multi-Object Oriented Augmented Reality, based on the Augmented Reality technique and the location of Mobile Learning Objects, which allows learner to see the suitable learning contents superimposed upon the specific learning objects and enhance the interactive in a mobile learning environment. The three characteristics of the proposed approach, Learning-Object Oriented, Guidance Ability and Highly Interactive will enhance Mobile Learning in a more adaptive and interesting way.","2161-377X","978-1-4244-7145-4","10.1109/ICALT.2010.130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5573236","Multi-Object Oriented;Augmented Reality;Location Awareness;Adaptive Moble learning","Mobile communication;Augmented reality;Adaptive systems;Learning systems;Object recognition;Computer architecture;Educational institutions","adaptive systems;augmented reality;computer aided instruction;distance learning;mobile computing;object-oriented methods","multiobject oriented augmented reality;location based adaptive mobile learning;learning content;guidance ability","","4","","4","IEEE","16 Sep 2010","","","IEEE","IEEE Conferences"
"Virtual Design Review and Planning Using Augmented Reality and Drones","S. Sreeram; K. K. Nisha; R. Jayakrishnan","Dept. of CSE, Rajiv Gandhi Institute Of Tech., Kottayam, India; Dept. of CSE, Rajiv Gandhi Institute Of Tech., Kottayam, India; Innovation Labs Ernst and Young, Trivandrum","2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)","10 Mar 2019","2018","","","915","918","Drone with Augmented Reality could, conceivably allow a complete fly-over of a building, bridge or other structure before actually building it in areas where human access is difficult. Engineers, Architects, Planners, and Site foremen can use augmented reality to visualize the various phases in the project beforehand. Launch the drone interacting with the software where a 3D model of the building is included, and we can see the future building from different angles as the drone flies around. Move drone to see complete picture and fitment of the model in the scenario from all directions. After such a virtual tour in the real environment, we can understand and get a better information on the building architecture and location. Augmented Reality is the technology used to provide an immersive experience for Constructors and Engineers. Drones can fly into areas where human access is difficult. Similarly construction of bridges, roads etc will be helpful with this technology.","","978-1-5386-2842-3","10.1109/ICCONS.2018.8662919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8662919","Augmented Reality;Drones;SLAM;Unity","Drones;Solid modeling;Buildings;Three-dimensional displays;Sensors;Computational modeling;Augmented reality","augmented reality;autonomous aerial vehicles;CAD;civil engineering computing;control engineering computing;solid modelling","virtual design review;augmented reality;bridge;future building;building architecture;drone","","4","","12","IEEE","10 Mar 2019","","","IEEE","IEEE Conferences"
"Design of learning media for fish classification with augmented reality technology","K. T. Martono; A. Fauzi","Department of Computer Engineering, Diponegoro University, Semarang, Indonesia; Department of Computer Engineering, Diponegoro University, Semarang, Indonesia","2017 4th International Conference on Information Technology, Computer, and Electrical Engineering (ICITACEE)","15 Jan 2018","2017","","","270","275","The learning process is currently experiencing significant changes, various methods are used to make learning more interesting. The development of computer technology also affects changes in the learning process. The use of multimedia technology, the improvement of the interaction system between human and computer becomes one of the factors in the change of learning process. The use of multimedia technologies such as animation, video or by using slide shows can affect students or students in the learning process Augmented reality is one of the technologies that can be developed in the design of learning media. In this research, the learning media design process using augmented reality technology is used. Learning topics taken are the introduction of fish species. The system design method used is to use waterfall. The result of this research is the application of Augmented reality-based learning media has been successfully implemented by using ARToolkit library. The minimum distance for 3D object can be displayed is at 10 Cm and the minimum angle is 300 to 900 and to see 3D objects. The result of rotation the marker successfully displays every part of the 3D object.","","978-1-5386-3947-4","10.1109/ICITACEE.2017.8257716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8257716","Learning;Augmented Reality;ARToolKit","Media;Cameras;Augmented reality;Multimedia communication;Three-dimensional displays;Fish;Streaming media","augmented reality;computer aided instruction;human computer interaction;image classification","augmented reality technology;system design method;computer technology;multimedia technology;learning media design process;ARToolkit library;3D object;fish classification","","4","","9","IEEE","15 Jan 2018","","","IEEE","IEEE Conferences"
"Augmented Reality Intelligent Lighting Smart Spaces","J. Purmaissur; A. Seeam; S. Guness; X. Bellekens","School of Science and Technology, Middlesex University Mauritius, Vacoas, Mauritius; School of Science and Technology, Middlesex University Mauritius, Vacoas, Mauritius; Department of Computer Science, African Leadership University, Pamplemousses, Mauritius; Division of Cyber-Security, University of Abertay, Dundee, UK","2019 Conference on Next Generation Computing Applications (NextComp)","28 Oct 2019","2019","","","1","5","Building services have come to a stage where they are closely being integrated with ICT infrastructure. The aim of this research is to develop an innovative and affordable platform for business services interfaced with augmented reality. This paper provides an innovative way of interaction between building services lighting systems through augmented reality. The system allows users to show their availability status in real time using an intelligent lighting system projected into Augmented Reality (AR) which changes color according to their availability. Furthermore, the different status and availability status can also be manipulated through an interactive interface, creating a smart space.","","978-1-7281-1460-6","10.1109/NEXTCOMP.2019.8883577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883577","Internet;Intelligent lighting infrastructure;IoT;Connected Lighting;Augmented Reality;Smart Buildings;Automation","Lighting;Augmented reality;Image color analysis;Strips;Smart phones;Bridges;Graphical user interfaces","augmented reality;building management systems;lighting;power engineering computing;Web services","building services;ICT infrastructure;business services;intelligent lighting system;augmented reality intelligent lighting smart spaces;AR","","3","","21","IEEE","28 Oct 2019","","","IEEE","IEEE Conferences"
"Introduction to Mask Malangan with Augmented Reality Technology","D. Pratama; S. V. Karya; F. I. Maulana; M. Ramadhani; F. Permana; G. Pangestu","Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2021 International Conference on Information Management and Technology (ICIMTech)","14 Sep 2021","2021","1","","364","368","Indonesia has a diverse culture, but nowadays the demand for it is decreasing. This is because the method for introducing culture is less attractive. By using Augmented Reality, the introduction of culture becomes more interesting. So that it can increase interest in learning about existing cultures. The concept of augmented reality is inspired by Malang mask tourism. We use Malang masks because we see the potential of users so that it makes it easier to introduce them. The process of making augmented reality is to create 3d assets on 3d paint, we try make 2 assets as a first step. followed by designing a prototype design using Figma. the last step is to use unity to combine all aspects and start making AR based on face recognition. we use the AR kit face tracking package to help detect faces. We also provide history and music background to introduce more Malang masks. Our application uses the base android. After exporting to android, we do tests based on distance and angle, and the result is our AR mask appears under certain conditions.","","978-1-6654-4937-3","10.1109/ICIMTech53080.2021.9534939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534939","mask;culture;augmented reality;Malang;application","Three-dimensional displays;Face recognition;Prototypes;Information management;History;Augmented reality;Paints","augmented reality;face recognition;humanities;travel industry","diverse culture;Malang mask tourism;AR mask;augmented reality technology;Figma;AR kit face tracking package;music background;base android","","3","","18","IEEE","14 Sep 2021","","","IEEE","IEEE Conferences"
"Cultural Tourism Web Service via Augmented Reality for Public Relations in Prachuapkhirikhan Province","P. Nusawat; A. Kwangsawad; N. Saikatikorn","Department of Business Information Technology, Faculty of Business Administration Rajamangala University of Technology Rattanakosin Wang Klai Kangwon Campus Prachuapkhirikhan, Thailand; Department of Business Information Technology, Faculty of Business Administration Rajamangala University of Technology Rattanakosin Wang Klai Kangwon Campus Prachuapkhirikhan, Thailand; Department of Business Information Technology, Faculty of Business Administration Rajamangala University of Technology Rattanakosin Wang Klai Kangwon Campus Prachuapkhirikhan, Thailand","2019 4th Technology Innovation Management and Engineering Science International Conference (TIMES-iCON)","5 Mar 2020","2019","","","1","5","This research aims to develop a Cultural Tourism Web Service via Augmented Reality for Public Relations in Prachuapkhirikhan Province and to evaluate the performance of the system the satisfaction of tourists about the system. The Cultural Tourism Web Service System was developed using WordPress program. The cultural tourist attractions in Prachuapkhirikhan province was presented via Augmented Reality. A questionnaire for evaluating system performance was considered by three experts choosing by the purposive sampling method, and a questionnaire for examining the satisfaction with the system was carried out by 400 tourists selected using a random sampling method. The statistical data analysis was used to calculate the mean and standard deviation. The results indicated that the developed system with an Augmented Reality web service is able to present information concerning cultural tourism in a new and interesting platform. The overall system performance showed a high level, and the tourist satisfaction with the system exhibited the highest level.","","978-1-7281-3755-1","10.1109/TIMES-iCON47539.2019.9024571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9024571","Cultural Tourism;Augmented Reality;Public Relations;Web Service","Cultural differences;Augmented reality;Web services;Public relations;Global communication;Videos;Media","augmented reality;data analysis;sampling methods;travel industry;Web services","cultural tourist attractions;Prachuapkhirikhan province;system performance;tourist satisfaction;Public Relations;augmented reality Web service;cultural tourism Web service system;WordPress program;purposive sampling method;random sampling method;statistical data analysis","","3","","11","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"Implementation of Augmented Reality Globe in Teaching-Learning Environment","H. Mayilyan","YoungZone Culture Co. Ltd, Shanghai, P.R. China","2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)","25 Apr 2019","2019","","","389","390","The purpose of the present study is to investigate the effect of Augmented Reality emerging technology into teaching-learning process. Augmented Reality, a technology that delivers information in form of text, audio, visual and 3D animated data engages learner's visual, auditorily, and kinesthetic learning styles. In this study ""AR Globe"" project is proposed to reveal learners attitude towards AR content integration into existing learning environment that can enhance learner's VAK learning styles.","","978-1-7281-1198-8","10.1109/MIPR.2019.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695347","Augmented Reality, educational technology, AR in education, AR Globe, VAK learning styles","Augmented reality;Visualization;Three-dimensional displays;Hardware;Software;Educational technology","augmented reality;computer aided instruction;computer animation;teaching","teaching-learning environment;AR Globe project;3D animated data;augmented reality","","3","","8","IEEE","25 Apr 2019","","","IEEE","IEEE Conferences"
"Augmented reality on HbbTV, an Hypervideo approach","T. Bibiloni; M. Mascaró; P. Palmer; A. Oliver","Universitat de les Illes Balears, Palma de Mallorca, Illes Balears, ES; Universitat de les Illes Balears, Palma de Mallorca, Illes Balears, ES; Universitat de les Illes Balears, Palma de Mallorca, Illes Balears, ES; Universitat de les Illes Balears, Palma de Mallorca, Illes Balears, ES","2014 9th Iberian Conference on Information Systems and Technologies (CISTI)","14 Aug 2014","2014","","","1","6","In this paper, an Augmented Reality system for the Connected TV is presented through a Hypervideo platform implementation. The Hypervideo platform consists of a backoffice to manage audiovisual content and hot-spots, and an interactive video player based in HbbTV technology. The player lets the user get additional information of the points of interest which are displayed over the images. This project presents a useful platform to audiovisual production teams, letting them mix, in an easy way, these three technological concepts: interactive video, augmented reality and connected television. This paper concludes with some improvement possibilities and extension to other devices.","2166-0727","978-9-8998-4343-1","10.1109/CISTI.2014.6877013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6877013","Augmented Reality;HbbTV;Hypervideo;Interactive Digital Storytelling","Visualization;TV;Augmented reality;Silicon;Global Positioning System;Laboratories;Multimedia communication","audio-visual systems;augmented reality;digital television;interactive television;interactive video","interactive digital storytelling;interactive video;audiovisual production;video player;hot-spot management;audiovisual content management;augmented reality system;hypervideo approach;HbbTV technology","","2","","16","","14 Aug 2014","","","IEEE","IEEE Conferences"
"Additive and Subtractive Manufacturing Augmented Reality Interface (ASMARI)","M. Borish; J. Westfall","Manufacturing Demonstration Facility, Oak Ridge National Lab, Knoxville, USA; Computer & Information Science &Engineering, Unviersity of Florida, Gainesville, USA","2020 SoutheastCon","13 Nov 2020","2020","","","1","6","Industry 4.0 represents the next evolution of industrial technology. Some of the key characteristics of Industry 4.0 include augmented reality and additive manufacturing. In support of this evolution, researchers at (blinded) created a prototype augmented reality (AR) interface, ASMARI. This prototype acts as a common interface for both industrial additive and subtractive machines. Additionally, in the changing industrial workspace of Industry 4.0, the role of humans will also change. This interface focuses on increasing productivity and situational awareness, while providing new interaction modalities for interacting with hardware. The prototype was also evaluated by multiple users who provided positive feedback on the system. Ultimately, the prototype represents a first step towards significant integration between augmented reality and additive manufacturing.","1558-058X","978-1-7281-6861-6","10.1109/SoutheastCon44009.2020.9249710","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9249710","Augmented Reality;Additive Manufacturing;Industry 4.0;HoloLens;3D Printing","Industries;Productivity;Additives;Prototypes;Three-dimensional printing;Manufacturing;Augmented reality","augmented reality;production engineering computing;rapid prototyping (industrial)","additive manufacturing;Industry 4.0;industrial workspace;additive and subtractive manufacturing augmented reality interface;situational awareness;subtractive machines;industrial technology;ASMARI","","2","","13","IEEE","13 Nov 2020","","","IEEE","IEEE Conferences"
"Mobile augmented reality on electric circuits","F. R. Avilés; C. A. Cruz","Universidad Autónoma Metropolitana Azcapotzalco, Ciudad de México, México; Universidad Autónoma Metropolitana Azcapotzalco, Ciudad de México, México","2017 Computing Conference","11 Jan 2018","2017","","","660","667","This paper presents an implementation of a mobile augmented reality system, which was designed to help the understanding of resistive electric circuits. The system employs a smartphone, a measuring instrument, and an electric circuit built on a breadboard. The smartphone captures a photograph of the circuit and receives data from the measuring instrument, which it uses to generate a layer of augmented reality information that is merged with the original image and displayed on the screen of the smartphone. In order to display augmented reality on a real circuit, it was developed a markerless method to identify resistors from a photograph of the circuit and set virtual objects over it. The results showed that the AR system is stable enough to be considered as a good first step in the development of a markerless AR system which works on real resistive circuits.","","978-1-5090-5443-5","10.1109/SAI.2017.8252166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252166","Augmented Reality;Electric Circuits;Image Processing;Mobile Systems","Resistors;Voltage measurement;Current measurement;Instruments;Augmented reality;Image color analysis;Mobile communication","augmented reality;mobile computing;resistors;smart phones","measuring instrument;AR system;mobile augmented reality system;resistive electric circuits;smartphone;breadboard;virtual objects","","2","","8","IEEE","11 Jan 2018","","","IEEE","IEEE Conferences"
"An efficient augmented reality method for sports scene visualization from single moving camera","S. Monji-Azad; S. Kasaei; A. -M. Eftekhari-Moghadam","Faculty of Computer and Information Technology Engineering Qazvin Branch, Islamic Azad University, Qazvin, Iran; Department of Computer Engineering, Sharif University of Technology, Tehran, Iran; Faculty of Computer and Information Technology Engineering Qazvin Branch, Islamic Azad University, Qazvin, Iran","2014 22nd Iranian Conference on Electrical Engineering (ICEE)","5 Jan 2015","2014","","","1064","1069","An algorithm to insert augmented reality in sports scenes is presented. The goal is to augment an image to the scene so that it appears as a part of the original scene. The proposed algorithm uses the homography relationship between the image coordinates and the world coordinates, then utilizes the Sift algorithm to find the corresponding points between two frames. By using the homography map we can detect the interested insertion region in each frame. To insert the virtual content, the algorithm segments the foreground and then uses the inverse homography map to insert the augmented reality in the original frame. The proposed algorithm is robust against camera movements. As shown in experimental results, the augmented image is well placed in the desired location. The experimental results show the strengths of the proposed method.","2164-7054","978-1-4799-4409-5","10.1109/IranianCEE.2014.6999693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6999693","Augmented Reality;Homography;Moving Camera;Sports Scene;Virtual Content","Cameras;Augmented reality;Educational institutions;Algorithm design and analysis;Estimation;Computers;Robustness","augmented reality;cameras;data visualisation;image segmentation;sport;transforms","sports scene visualization;single moving camera;augmented reality;image augmentation;homography relationship;image coordinates;world coordinates;SIFT algorithm;insertion region;virtual content;foreground segmentation;inverse homography map;camera movements","","2","","13","IEEE","5 Jan 2015","","","IEEE","IEEE Conferences"
"Design Research and Practice of Augmented Reality Textbook","L. Zhou; S. Zhang","Sch. of Educ. Sci., Nanjing Normal University, Nanjing, Jiangsu, CN; Sch. of Educ. Sci., Nanjing Normal University, Nanjing, Jiangsu, CN","2014 International Conference of Educational Innovation through Technology","15 Dec 2014","2014","","","16","20","The research of augmented reality textbook is an important way to make the teaching content vivid and three-dimensional, but its development is lagging behind. This research analyzes on the basis of the principle of the augmented reality technology and its advantages for textbook development, through the case study of children's English textbook design based on augmented reality technology solutions, so as to provide implementation pattern and technical reference for development of similar textbooks.","","978-1-4799-4230-5","10.1109/EITT.2014.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982557","Augmented Reality;Textbook;Design Research","Augmented reality;Three-dimensional displays;Solid modeling;Cameras;Animation;Educational institutions","augmented reality;computer aided instruction","design research;augmented reality textbook;teaching content;textbook development;English textbook design","","2","","14","IEEE","15 Dec 2014","","","IEEE","IEEE Conferences"
"Using Augmented Reality in the Corporate Environment: A Proposed Study Protocol","K. Larson","Department of Learning Technologies, University of North Texas, Denton, TX, USA","2019 Eighth International Conference on Educational Innovation through Technology (EITT)","5 Dec 2019","2019","","","245","249","AR provides opportunities to not only acquire information, but to experience it through visual, spatial, and sensorimotor feedback. Though this technology has been around for years and is professionally recognized as an effective tool to improve and enhance the learning experience, its benefits have gone widely unknown and underappreciated in the field of training and development. In order to maintain an advantage in a global economy, companies are always looking for more engaging and motivating training experiences for employees. As it becomes more accessible and popular, companies are enticed by the potentialities of Augmented Reality. The combination of print materials and augmented reality in education is becoming increasingly manageable due to advances in mobile technologies. This paper presents a proposed study protocol on an Augmented Reality training to deliver just-in-time training in the corporate environment using a marker-based system to enhance training in the context of the Human Capital Management industry.","2166-0549","978-1-7281-4288-3","10.1109/EITT.2019.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924094","augmented reality, AR, corporate training, modern learning, mobile training","Training;Augmented reality;Software;Companies;Mobile handsets;Tools;Task analysis","augmented reality;computer based training;human resource management;mobile computing;personnel;training","corporate environment;study protocol;visual sensorimotor feedback;learning experience;engaging training experiences;motivating training experiences;mobile technologies;augmented reality training;just-in-time training;spatial sensorimotor feedback;human capital management industry","","1","","40","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"InterAKT: A mobile augmented reality browser for geo-social mashups","F. Meawad","School of Computing, University of Glasgow, Singapore","2016 4th International Conference on User Science and Engineering (i-USEr)","20 Feb 2017","2016","","","167","171","Current Mobile Augmented Reality (AR) browsers do not reflect users' immediate contexts and lack support for contextual interaction. Such limitations turn users away from the experience, even those who are genuinely interested in the technology. Mobile AR needs a serious move towards a better experience driven by user generated content. This paper discusses InterAKT, a mobile augmented reality browser that extends existing crowd sourced geo-tagged data while enabling in-situ content creation. Bringing such capabilities together in a lightweight solution introduces many challenges on the architectural and the user interface level. InterAKT is designed to enhance content display, navigation and interaction for mobile AR users, while enabling them to create their own AR experiences. In this paper, we discuss how InterAKT was designed to overcome the challenges for mobile augmented reality, such as noisy sensor data, limited display and the lack of relevant content. We discuss the results of an initial evaluation conducted remotely with users in different countries. The results show success in engaging users in mobile AR using crowd sourced content.","","978-1-5090-2631-9","10.1109/IUSER.2016.7857954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7857954","Mobile Augmented Reality;Location based services;Crowd sourcing;Mobile Usability","Mobile communication;Browsers;Augmented reality;Mashups;Cameras;Three-dimensional displays;Satellites","augmented reality;crowdsourcing;mobile computing;online front-ends;user interfaces","InterAKT;mobile augmented reality browser;geosocial mashups;user generated content;crowd sourced geotagged data;in-situ content creation;user interface level;content display;mobile AR user interaction","","1","","14","IEEE","20 Feb 2017","","","IEEE","IEEE Conferences"
"IdeAR: Augmented Reality Applied to Reading Comprehension Stories","J. P. Cruzado; D. H. Huaman; J. R. Capa; M. Q. Bellizza","Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú","2020 IEEE Engineering International Research Conference (EIRCON)","17 Nov 2020","2020","","","1","4","A problem in many schools is the difficulty of students to understand texts, which is due to multiple factors, including habits and motivation to read. On the other hand, augmented reality is a didactic technology which, when applied to the educational area, becomes a dynamic, interactive activity and arouses interest in the student. This study shows the results obtained after the application of augmented reality for reading comprehension through stories in fourth grade primary students. A mobile application based on augmented reality named “IdeAR” was implemented using Mobile-D methodology. For empirical demonstration the statistical sample included two sections of students from a public school in Lima city, where the experimental group showed improvements in memory level and content understanding. Finally, this work is important for the educational sector because it provides a tool that favors teaching with a STEAM approach.","","978-1-7281-8367-1","10.1109/EIRCON51178.2020.9254048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9254048","augmented reality;reading comprehension","Conferences;Urban areas;Education;Tools;Mobile applications;Augmented reality","augmented reality;computer aided instruction;mobile computing;teaching","Lima city;STEAM approach;reading comprehension stories;interactive activity;IdeAR;fourth grade primary students;augmented reality","","1","","11","IEEE","17 Nov 2020","","","IEEE","IEEE Conferences"
"A Human-Computer Interaction Method with Multi-Dimensional Information in the Teleoperation Augmented Reality System","G. Xin; J. Qingxuan; H. Huan; S. Hanxu; S. Jingzhou","School of Automation, Beijing University of Posts and Telecommunications, Beijing, China; School of Automation, Beijing University of Posts and Telecommunications, Beijing, China; School of Automation, Beijing University of Posts and Telecommunications, Beijing, China; School of Automation, Beijing University of Posts and Telecommunications, Beijing, China; School of Automation, Beijing University of Posts and Telecommunications, Beijing, China","2011 Seventh International Conference on Computational Intelligence and Security","12 Jan 2012","2011","","","180","184","In order to further improve the operating performance of teleoperation robot system, and give full play to the advantages of augmented reality technology, this paper presents a human-computer interaction method with multi-dimensional information in the teleoperation augmented reality scenario. This method not only synthesizes the information the operator can directly perceive, but also the information that operators can not directly perceive is also conveyed to the operator by an intuitive way, and finally establishes the multi-dimensional information interaction channel between implement-side and host-side. Firstly the composition of the model's information content, the information acquisition way, and a way to convey information of the model are analyzed, and then several aspects of visual information interaction, the show mechanism of text prompts and voice prompts, hap tic interaction method, etc are analyzed in-depth separately. Experimental results show the teleoperation augmented reality system with multi-dimensional information could increase the operating accuracy and reduce the procedure time.","","978-1-4577-2008-6","10.1109/CIS.2011.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128101","teleoperated robotic system;augmented reality;human-computer interaction;multi-dimensional information;force feedback","Augmented reality;Force feedback;Calibration;Robot kinematics;Three dimensional displays;Force","augmented reality;control engineering computing;haptic interfaces;human computer interaction;telerobotics","human computer interaction method;multidimensional information;teleoperation augmented reality system;teleoperation robot system;multidimensional information interaction channel;text prompts;voice prompts;haptic interaction method","","1","","11","IEEE","12 Jan 2012","","","IEEE","IEEE Conferences"
"Design of an Augmented Reality Application Framework to Mobile Device","Y. -Y. Fanjiang; S. -C. Lin; Y. -Z. Lin","Department of Computer Science and Information Engineering, Fu Jen Catholic University, New Taipei, Taiwan; Department of Computer Science and Information Engineering, Fu Jen Catholic University, New Taipei, Taiwan; Department of Computer Science and Information Engineering, Fu Jen Catholic University, New Taipei, Taiwan","2012 Sixth International Conference on Genetic and Evolutionary Computing","7 Feb 2013","2012","","","177","179","In order to quickly and easily create Augmented Reality and real-time dynamic sharing applications, we design an Augmented Reality application framework to handheld devices in this paper. It can create customized AR and combine point of interest anywhere. One can use the real-time updating to share information with friends anytime.","","978-1-4673-2138-9","10.1109/ICGEC.2012.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6457144","Augmented reality;mobile computing;application framework","XML;Augmented reality;Social network services;Mobile handsets;Educational institutions;Servers;Real-time systems","augmented reality;human computer interaction;mobile computing;user interfaces","augmented reality application framework;mobile device;real-time dynamic sharing applications;handheld devices;information sharing","","1","","7","IEEE","7 Feb 2013","","","IEEE","IEEE Conferences"
"The application of Augmented Reality technology for the exibition at archaeological site Medijana","D. Tatić; D. Tatić","Elektronski fakultet, Univerzitet u Nišu, Serbia; Dragon Multimedia, Nis, Serbia","2012 20th Telecommunications Forum (TELFOR)","24 Jan 2013","2012","","","1327","1330","Augmented Reality (AR) becomes more popular and used in the field of digitization of national heritage. In this paper we used AR browser to enrich and improve the content presentation of the archaeological sites. By using this AR technology, applications for Median archeological site in Niš is implemented. The application allows the visitor, by using a mobile device, to reconstruct the objects at the place where they once existed. Viewing the objects or other archaeological artifacts is done on the mobile device in the form of 3D models. In this way, by using augmented reality technology, it is possible to upgrade objects at the archaeological sites that are protected or do not exist and whose reconstruction is complex.","","978-1-4673-2984-2","10.1109/TELFOR.2012.6419461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6419461","AR browser;arheološki nalazište Medijana;Augmented reality;multimedia;proširena stvarnost","Augmented reality;Browsers;Solid modeling;Media;Electronic mail;Virtual environments;Computers","archaeology;augmented reality;history;mobile computing;solid modelling","national heritage digitization;AR browser;content presentation;median archeological site;Niš;mobile device;archaeological artifacts;3D models;augmented reality technology","","1","","12","IEEE","24 Jan 2013","","","IEEE","IEEE Conferences"
"Augmented Reality applied to the teaching/learning environment","P. Magalhães; A. Castro; C. V. Carvalho","GILT (Graphics, Interaction and Learning Technologies), Instituto Superior de Engenharia do Porto, Porto, Portugal; GILT (Graphics, Interaction and Learning Technologies), Instituto Superior de Engenharia do Porto, Porto, Portugal; GILT (Graphics, Interaction and Learning Technologies), Instituto Superior de Engenharia do Porto, Porto, Portugal","6th Iberian Conference on Information Systems and Technologies (CISTI 2011)","4 Aug 2011","2011","","","1","5","In the last decades we have witnessed a technological advancement at all levels with particular emphasis in hardware and mobile devices. These became increasingly lighter and cheaper, and transferred from the office to the car, to equipment and other utensils. The amount of (digital) information available in the environment has increased exponentially, requiring a technological response in order to improve and facilitate its access and assimilation. The concept of Augmented Reality acts as a bridge between real and digital inviting to new models of user interaction. The AR incorporation is intended primarily to make systems more usable by decreasing the need of cognitive load inherent to their use. This paper presents a case study, proposing a model for a Learning Object using Augmented Reality, studying the integration of augmented reality and multimedia techniques combined with other conventional materials researching how they may contribute to increase motivation and perceived towards knowledge.","2166-0735","978-989-96247-5-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974235","Learning Objects;Human-Computer Interaction;Augmented Reality;Usability;Health","Visualization;Augmented reality;Software;Biological system modeling;Laboratories;Browsers","augmented reality;computer aided instruction;multimedia systems;user interfaces","augmented reality;teaching-learning environment;user interaction;learning object model;multimedia technique","","1","","8","","4 Aug 2011","","","IEEE","IEEE Conferences"
"Marker tracking for video-based augmented reality","Y. -F. Gao; H. -Y. Wang; X. -N. Bian","College of Science, Beijing University of Civil Engineering and Architecture, Beijing, China; College of Science, Beijing University of Civil Engineering and Architecture, Beijing, China; Department of Mathematics and Statistics, Dalhousie University, Nova Scotia, Canada","2016 International Conference on Machine Learning and Cybernetics (ICMLC)","9 Mar 2017","2016","2","","928","932","In augmented reality (AR) systems, virtual objects, graphics or texts are added to the real scene to improve the person's perception. Virtual and real information must be aligned strictly in the combination of scenes. The key of augmented reality is 3D registration technology which is based on tracking the artificial marker in the scene effectively. Using linear programming theory, this paper presents a tracking method which can recognize the vertices of any convex polygon in augmented reality system since most of the markers are squares. The transformation matrix of camera can be estimated at the aid of coordinates of the four vertices.","2160-1348","978-1-5090-0390-7","10.1109/ICMLC.2016.7873011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7873011","Augmented reality;3D registration;Linear programming;Marker tracking","Cameras;Augmented reality;Linear programming;Three-dimensional displays;Cybernetics;Transmission line matrix methods;Computer vision","augmented reality;convex programming;linear programming;video signal processing","marker tracking;video-based augmented reality;AR systems;virtual objects;3D registration technology;linear programming theory;convex polygon vertices;camera transformation matrix","","1","","13","IEEE","9 Mar 2017","","","IEEE","IEEE Conferences"
"Augmented reality for solar system learning","J. L. H. Salazar; R. Pacheco-Quispe; J. D. Cabeza; M. J. H. Salazar; J. P. Cruzado","Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú","2020 IEEE ANDESCON","1 Dec 2020","2020","","","1","4","The learning process has difficulties due to an excess of theory and low use of teaching materials. Augmented reality in education would provide a new approach to learning, bringing virtual objects into the real world, improving interaction, increasing interest and improving the understanding of the topic to be taught. The research aimed at measuring the level of influence of the use of a mobile application with augmented reality in the learning of the solar system; the design was quasi-experimental with a control group and an experimental group, each of them consisted of 27 students. It was possible to demonstrate a significant improvement in the values of the indicators of the Post-test with respect to those of the Pre-test, which allows us to conclude that the augmented reality application significantly influences the learning of the solar system in primary school students.","","978-1-7281-9365-6","10.1109/ANDESCON50619.2020.9272008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272008","augmented reality;mobile app;learning;geography;solar system;mobile-d","Augmented reality;Education;Solar system;Mobile applications;Three-dimensional displays;Target tracking;Tools","astronomy computing;augmented reality;computer aided instruction;mobile computing;solar system;teaching","solar system learning;teaching materials;virtual objects;augmented reality application;mobile application;primary school students","","1","","16","IEEE","1 Dec 2020","","","IEEE","IEEE Conferences"
"Analysis of Ways to Create Augmented Reality","I. V. Ozhiganov; E. I. Tumanova","The Bonch-Bruevich Saint-Petersburg State University of Telecommunications, St. Petersburg, Russia; The Bonch-Bruevich Saint-Petersburg State University of Telecommunications, St. Petersburg, Russia","2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus)","19 Mar 2020","2020","","","59","61","Augmented reality is an actively developing technology that allows increasing the amount of information received by a person about objects that he perceives with his senses. There are several ways to create augmented reality images. One of them is the selection of a simple geometric shape (marker). Another method is based on finding the features of the image and their numerical description. In this paper, both methods are described and a comparative analysis of the results is made, on the basis of which it can be concluded that it is advisable to use one or another method in a particular AR-system.","2376-6565","978-1-7281-5761-0","10.1109/EIConRus49466.2020.9039370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9039370","augmented reality;optical systems;comparison of projection matrices","Streaming media;Augmented reality;Cameras;Feature detection;Detectors;Approximation algorithms","augmented reality;geometry;numerical analysis;shape recognition","actively developing technology;augmented reality images;geometric shape;numerical description;comparative analysis","","","","7","IEEE","19 Mar 2020","","","IEEE","IEEE Conferences"
"Processing video frames in iPad for augmented reality applications","C. D. Corona Arzola; L. G. de la Fraga","Computer Science Department, Cinvestav, Mexico, D.F., México; Computer Science Department, Cinvestav, Mexico, D.F., México","2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)","1 May 2014","2014","","","155","159","In this work we document the necessary image processing steps to recognize fiducial markers for augmented reality applications. Although we use ARToolKitPlus, we believe that it is not well, neither documented all details about how this library works. We create a new simplified library for the iPad and now it is public available. Besides, we set out some criteria for the development of augmented reality systems on iPad, a restricted device in both computing power and memory storing. iPad is a tablet with a very intuitive use and has the advantage of incorporating a display screen -with the proper size for augmented reality applications-, a camera and the necessary sensors to interact by touching the screen, a gyroscope and an accelerometer. We present three applications created with this library: (1) a booklet of species for children, where the model of the species appears virtually on a marker; (2) Japanese language learning application through cards, where the meaning of the symbols is shown using virtual models on a marker; and (3) a virtual ball on a maze, which additionally uses iPad's gyroscope and accelerometer.","","978-1-4799-3469-0","10.1109/CONIELECOMP.2014.6808583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6808583","Augmented reality;image processing;fiducial marker;marker's detection;principal component analysis","Tablet computers;Augmented reality;Libraries;Cameras;Principal component analysis;Three-dimensional displays;Calibration","augmented reality;principal component analysis;video signal processing","video frames processing;iPad;augmented reality;image processing;ARToolKitPlus;computing power;memory storing;camera;gyroscope;accelerometer;Japanese language learning;virtual models","","","","13","IEEE","1 May 2014","","","IEEE","IEEE Conferences"
"Demo Abstract: Enhanced Real-Time Machine Inspection with Mobile Augmented Reality for Maintenance and Repair","I. Wijesooriya; D. Wijewardana; T. De Silva; C. Gamage; M. Jayaweera","Dept. of Comput. Sci. & Eng., Univ. of Moratuwa, Moratuwa, Sri Lanka; Department of Computer Science and Engineering, University of Moratuwa, Sri Lanka; Department of Computer Science and Engineering, University of Moratuwa, Sri Lanka; Department of Computer Science and Engineering, University of Moratuwa, Sri Lanka; Department of Computer Science and Engineering, University of Moratuwa, Sri Lanka","2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI)","15 Jun 2017","2017","","","287","288","We describe a system that we have built called ARIOT, an IoT (Internet of Things) enabled AR (Augmented Reality) wearable system to enhance the capabilities of machine operators and repairmen. ARIOT is a solution to the limited availability of highly capable and highly experienced machine inspectors in industrial environments.The outcome of this research and development project is an evaluation of the possibility of using a mobile Augmented Reality (AR)system, which communicates with various components of a machine to visualise real-time data pertaining to those components. For example, if there is an error or a potential error, the machine operator will be notified with a prompt to further instructions allowing a relatively inexperienced operator to learn on the job and for an expert to save valuable time.Also we focus on the modularity, extendability and security of communications within the system.","","978-1-4503-4966-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7946891","Internet of Things;Augmented Reality;Real-Time Machine Inspection","Maintenance engineering;Inspection;Augmented reality;Headphones;Real-time systems;Internet","augmented reality;inspection;Internet of Things;maintenance engineering;mobile computing;production engineering computing;real-time systems","machine operator;real-time data;AR system;industrial environments;machine inspectors;ARIOT;wearable system;Internet of Things;mobile augmented reality;real-time machine inspection","","","2","5","","15 Jun 2017","","","IEEE","IEEE Conferences"
"Mobile Application for Practical Skills Testing Based on Augmented Reality","A. Pukas; V. Smal; I. Voytyuk; L. Honchar; V. Hrytskiv; B. Maslyiak","Department of Computer Science, Ternopil National Economic University, Ternopil, Ukraine; Department of Computer Science, Ternopil National Economic University, Ternopil, Ukraine; Department of Computer Science, Ternopil National Economic University, Ternopil, Ukraine; Department of Computer Science, Ternopil National Economic University, Ternopil, Ukraine; Department of Computer Science, Ternopil National Economic University, Ternopil, Ukraine; Department of Computer Science, Ternopil National Economic University, Ternopil, Ukraine","2019 9th International Conference on Advanced Computer Information Technologies (ACIT)","1 Aug 2019","2019","","","312","315","Advanced technologies of virtualization and digital realization of the real world find their application in a wide variety of practical fields, including entertainment; medicine; education; military; repair services; aviation; vehicle operations; security services; transport companies; construction, etc. Recently, technologies of virtual and augmented reality and their application in education are rapidly developing. Application of technologies of virtual and augmented reality in education gives many additional advantages over traditional media, in particular the development of spatial imagery, which enhances the deep understanding of processes, properties, and so on. Particularly relevant in this context is the issue of improving the skills of workers in industries that require substantial expenditure on training systems, in particular aircraft construction. Therefore, the task of creating a new software system for testing the skills in aircraft engineering based on the means of augmented reality and mobile devices described in this paper.","","978-1-7281-0450-8","10.1109/ACITT.2019.8779879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8779879","augmented reality;Microsoft HoloLens;mobile application;skills testing;aircraft engineering","Economics;Augmented reality;Mobile applications;Testing;Aircraft;Aircraft propulsion","aerospace engineering;augmented reality;computer based training;mobile computing","mobile application;augmented reality;virtualization;digital realization;aircraft construction;practical skills testing;workers skill improvement;aircraft engineering;training systems","","","","12","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"Object Recognition on Augmented Reality Glasses","M. S. Albayrak; A. ö. ner; H. K. Ekenel","ATA Technology Platforms, Innovation and Transformation Department, Istanbul, Turkey; ATA Technology Platforms, Innovation and Transformation Department, Istanbul, Turkey; Istanbul Teknik Universitesi, Istanbul, TR","2019 27th Signal Processing and Communications Applications Conference (SIU)","22 Aug 2019","2019","","","1","4","Employee training in fast-food restaurants is a long, practice-based process which is mainly done on the job. Employee performance during training directly affects service quality and customer satisfaction. In this study, it is aimed to optimize the training process in fast-food restaurants with use of augmented reality glasses. For this purpose, a comparative study is performed to determine the most suitable model of augmented reality glasses in the market. It is aimed to shorten the training period of the employee, to help the employee in this process and to introduce the objects around him. Light convolutional neural networks are compared to solve the object recognition problem on augmented reality glasses. As a result, MobileNet model is selected and fine-tuned to recognize the objects in a restaurant kitchen. The outcomes of this study will be used to fully train and supervise the employees without the need for a trainer in the future.","2165-0608","978-1-7281-1904-5","10.1109/SIU.2019.8806255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806255","Fast food employee training;augmented reality glasses;convolutional neural networks;deep learning","Dogs;Augmented reality;Glass;Training;Random access memory;Industries;Object recognition","augmented reality;catering industry;computer based training;convolutional neural nets;customer satisfaction;customer services;human computer interaction;learning (artificial intelligence);object recognition;personnel","augmented reality glasses;employee training;fast-food restaurants;practice-based process;employee performance;service quality;customer satisfaction;object recognition problem;convolutional neural networks;MobileNet model;restaurant kitchen","","","","","IEEE","22 Aug 2019","","","IEEE","IEEE Conferences"
"A path generation method for path tracking algorithms that use the augmented reality","M. -H. Kim; M. -C. Lee","Department of Mechanical Engineering, Pusan National University, Busan, South Korea; Department of Mechanical Engineering, Pusan National University, Busan, South Korea","ICCAS 2010","17 Dec 2010","2010","","","1487","1490","Nowadays, the research of the unmanned vehicle robots is increased, especially in the military fields. Some of these robots use path tracking algorithm, so the path generation method is needed. Now we suggest that the path generation method could be used into augmented reality using the B-spline curve equation. Therefore we can make the robot can track the virtual path in real time by obtaining the error distance between the path in the augmented reality and the robot.","","978-89-93215-02-1","10.1109/ICCAS.2010.5670133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670133","Path Generation;B-Spline Curve;Path Tracking Algorithm;Augmented Reality","Equations;Mathematical model;Vehicles;Spline;Robots;Augmented reality;Interpolation","augmented reality;military vehicles;mobile robots;path planning;remotely operated vehicles;splines (mathematics)","path generation method;path tracking algorithm;augmented reality;unmanned vehicle robots;military fields;B-spline curve equation","","","","6","","17 Dec 2010","","","IEEE","IEEE Conferences"
"Image Recognition on Rupiah Currency using Augmented Reality for Learning Media","D. Tresnawati; A. Mulyani; D. G. Pramudita","Department of Informatics, Sekolah Tinggi Teknologi Garut, Garut, Indonesia; Department of Informatics, Sekolah Tinggi Teknologi Garut, Garut, Indonesia; Department of Informatics, Sekolah Tinggi Teknologi Garut, Garut, Indonesia","2021 International Conference on ICT for Smart Society (ICISS)","13 Sep 2021","2021","","","1","4","The use of technology in learning media has been widely used. One of the technologies that can be used to support the learning process is Augmented Reality technology. So far, the way of working done in Augmented Reality is by scanning a marker that is made specifically to be able to bring up scanned information. Therefore, a design was made to create an Augmented Reality application that does not require a special marker but simply by utilizing existing objects, in this case using banknotes in rupiah currency and then displaying information about the images contained in the banknotes. The results of the study indicate that the application can run, and can help in learning the introduction of currency and culture according to the images contained in the banknotes.","2640-0545","978-1-6654-1697-9","10.1109/ICISS53185.2021.9533193","Sekolah Tinggi Teknologi Garut; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533193","Augmented Reality;image recognition;learning media;Multimedia Development Life Cycle","Image recognition;Media;Augmented reality;Currencies","augmented reality;computer aided instruction;image recognition","scanned information;augmented reality application;banknotes;Rupiah currency;image recognition;learning media;learning process","","","","26","IEEE","13 Sep 2021","","","IEEE","IEEE Conferences"
"Science Zone: An Augmented Reality based Mobile Application for Science","W. De Silva; P. Naranpanawa; U. Hettihewa; P. Liyanage; U. Samarakoon; N. Amarasena","Faculty of Computing Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Faculty of Computing Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Faculty of Computing Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Faculty of Computing Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Faculty of Computing Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Faculty of Computing Sri Lanka Institute of Information Technology, Malabe, Sri Lanka","2020 2nd International Conference on Advancements in Computing (ICAC)","26 Feb 2021","2020","1","","222","227","In recent years, technology has rapidly developed, and it has provided many technological advancements for the field of education with an attempt to improve and overcome its limitations. Augmented Reality is among these latest technologies which support to improve learning environment around the world. It can bring education to a new level which can help students in many significant ways. In Sri Lanka, augmented reality is rarely been used for the purpose of educational enhancements. Therefore, it was decided to develop an augmented reality embedded mobile application for the G.C.E Ordinary Level Students in order to make it easy for them to learn Science with more enthusiasm and interest. This research has been used marker-based approach to transmit images or objects in the text book into the real-world scenes in order to create a more productive learning environment for the students. The first version of the application covers four main areas in the Science curriculum, such as; Preparation of Acids, Human Anatomy, Organization of Plants and Biosphere Cycles. Feedback for the application was taken from randomly selected ten science teachers and twenty grade eleven students and accordingly the application was further developed. Their feedback proves that the application would satisfy the common requirements of students, and it would be an immense support in scoring good results for science.","","978-1-7281-8412-8","10.1109/ICAC51239.2020.9357153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357153","Augmented Reality;Science;Education;Technology","Human anatomy;Animals;Education;Organizations;Biosphere;Mobile applications;Augmented reality","augmented reality;computer aided instruction;educational courses;mobile computing;natural sciences computing","augmented reality;mobile application;technological advancements;educational enhancements;productive learning environment;science curriculum;Sri Lanka;G.C.E ordinary level students;marker-based approach;text book;real-world scenes;acids preparation;human anatomy;plants;biosphere cycles;Science Zone","","","","13","IEEE","26 Feb 2021","","","IEEE","IEEE Conferences"
"Visualization of Classical Chinese Poetry with Augmented Reality Technology","O. R. Mardasari; A. Ventivani; K. F. L. Sakti; L. Ul Muyassaroh; M. Kharis; A. Ahmadi","Chinese Education Dept., Universitas Negeri Malang, Malang, Indonesia; Chinese Education Dept., Universitas Negeri Malang, Malang, Indonesia; Chinese Education Dept., Universitas Negeri Malang, Malang, Indonesia; Chinese Education Dept., Universitas Negeri Malang, Malang, Indonesia; German Education Dept., Universitas Negeri Malang, Malang, Indonesia; Indonesia Education Dept., Universitas Negeri Surabaya, Surabaya, Indonesia","2021 Universitas Riau International Conference on Education Technology (URICET)","26 Aug 2022","2021","","","1","5","This study aims to describe the effectiveness of Augmented Reality technology-based Classical Chinese Poetry visualization in literature learning. The population of this study were 46 students of Universitas Negeri Malang and Universitas Negeri Surabaya. This research is a pre-experimental study using the One Group Pretest-Posttest Design. Learning using modules accompanied by Augmented Reality Technology-based applications is carried out in three face-to-face and one post-test. The instrument used in this study was a multiple choice formative test. The results showed a significant change in the mean value between the pre-test and post-test, namely an increase of 14 with an average pre-test of 65.75 to 79.75 on the average post-test. The N-gain calculation is in the medium category. Paired Sample T-test results obtained a significance level (effective). Based on the results of several tests, it was concluded that the visualization of Classical Chinese Poetry based on Augmented Reality could be used as a companion medium for textbooks or as a medium that can help students become learning subjects.","","978-1-6654-2096-9","10.1109/URICET53378.2021.9865972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9865972","Augmented Reality;Classical Chinese Poetry;visualization of literature learning","Visualization;Instruments;Sociology;Education;Media;Statistics;Augmented reality","augmented reality;computer aided instruction;educational institutions;literature","literature learning;Universitas Negeri Malang;Universitas Negeri Surabaya;group pretest-posttest design;multiple choice formative test;augmented reality technology-based classical Chinese poetry visualization","","","","21","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"The influence of Augmented Reality in the teaching and learning process in the 1st Cycle of Basic Education","H. Gil; T. Barata","Age.Comm – Instituto Politécnico de Castelo Branco, Castelo Branco, Portugal; Age.Comm – Instituto Politécnico de Castelo Branco, Castelo Branco, Portugal","2021 16th Iberian Conference on Information Systems and Technologies (CISTI)","12 Jul 2021","2021","","","1","6","Information and Communication Technologies (ICT) in general and Augmented Reality (AR) have a major impact on the teaching and learning process of pupils. The AR is still little known and exploited in an educational context in Portugal, and for this reason a qualitative study has been chosen on: ""The Augmented Reality as the enabler of learning in the 1st Cycle of Basic Education"". The study was carried out in a group of 21 students from the second year of schooling in the methodology of Distance Learning (E@D). This study has allowed us to reflet that the integration of AR into the teaching and learning process allows pupils to increase their motivation for learning through a more motivating approach. The RA can be a learning tool, and it is a valid support for the teacher in the monopolization of pedagogical activities. The results obtained, after analyzing and processing the data, have enabled us to verify that the AR can be a enabler of learning, in that it promotes new learning contexts, more innovative and motivating for today's students. The study concluded that ICT and AR integrated into an educational environment can create a more stimulating and interactive environment by promoting richer and more meaningful learning for pupils, given their involvement in the various activities proposed to them.","2166-0727","978-989-54659-1-0","10.23919/CISTI52073.2021.9476321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476321","Information and Communication Technologies (ICT);Augmented Reality (AR);teaching and learning process;1st Cycle of Basic Education (1st CEB)","Computer aided instruction;Education;Tools;Information and communication technology;Pupils;Augmented reality;Information systems","augmented reality;computer aided instruction;data analysis;distance learning;human factors;interactive systems;teaching","augmented reality;teaching process;learning process;educational context;learning tool;learning context;1st Cycle of Basic Education;distance learning;information and communication technologies;Portugal;learning motivation;ICT;AR;data analysis;data processing;interactive environment","","","","0","","12 Jul 2021","","","IEEE","IEEE Conferences"
"Implementation of Augmented Reality in E-Commerce Applications","B. E. Singgih; L. Yudistira; H. Wijaya; M. S. Anggreainy","Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2021 2nd International Conference on Innovative and Creative Information Technology (ICITech)","9 Nov 2021","2021","","","136","139","The internet as a medium of shopping and buying has become a widely researched media theme. Augmented reality is a breakthrough technology that helps deliver an e-commerce online shopping experience using the internet with the quality of offline shopping. That is possible thanks to the ability of augmented reality technology which allows consumers to associate and try the product through cyberspace, as well as online stores. This study aims to implement AR in e-commerce applications. The e-commerce application here is a Web-based application that is segmental into the online shopping site with expected features to give the appearance of a new product, unique and exciting in online shopping activity. With the existence of augmented reality, it will make it easier to use web-based applications so that it helps customers find the desired product.","","978-1-7281-9747-0","10.1109/ICITech50181.2021.9590104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590104","Implementation;Augmented Reality;Web-Based Applications;Electronic Commerce;Marker Detection","Cyberspace;Media;Electronic commerce;Information technology;Augmented reality","augmented reality;electronic commerce;Internet;retail data processing","e-commerce application;buying;widely researched media theme;breakthrough technology;offline shopping;augmented reality technology;online stores;Web-based application;online shopping site;online shopping activity;web-based applications","","","","17","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Teachers’ perceptions on the use of Augmented Reality in students with Autism Spectrum Disorder","A. Gilabert-Cerdá; G. L. Lledó; A. L. Carreres","Department of Evolutionary Psychology and Didactics, University of Alicante, Alicante, Spain; Department of Evolutionary Psychology and Didactics, University of Alicante, Alicante, Spain; Department of Evolutionary Psychology and Didactics, University of Alicante, Alicante, Spain","2022 XII International Conference on Virtual Campus (JICV)","16 Nov 2022","2022","","","1","4","In the inclusive educational context, the technological revolution has generated a progressive incorporation of emerging technologies, among which is Augmented Reality (AR). Augmented Reality offers great learning possibilities for students with Autism Spectrum Disorder (ASD) because it adapts to their cognitive style. In this sense, the aim of this study was to examine the perceptions of Primary and Secondary Education teachers about AR as a didactic resource for intervention with students with ASD. From a descriptive approach using the survey technique, a 10-item questionnaire designed ad hoc was applied to a sample of 140 teachers from Denmark, selected by accidental non-probabilistic sampling. The results show that teachers are not fully aware of the didactic potential of the AR tool with students with ASD and have misconceptions about it. As a future line of research, teachers should be trained in the use of this tool so that they can put Augmented Reality into practice with students with ASD.","","978-1-6654-5106-2","10.1109/JICV56113.2022.9934687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9934687","Augmented Reality;Autism Spectrum Disorder;perceptions;usefulness;technologies","Autism;Education;Augmented reality","augmented reality;computer aided instruction;handicapped aids","ASD;Augmented Reality;Autism Spectrum Disorder;great learning possibilities;inclusive educational context;Primary Education teachers;Secondary Education teachers;technological revolution","","","","23","IEEE","16 Nov 2022","","","IEEE","IEEE Conferences"
"Methodological Proposal for the development of Computerized Educational Materials based on Augmented Reality","E. J. de Atocha Sosa Jiménez; R. A. Aguilar Vera; J. L. López Martínez; J. C. Díaz Mendoza","Cuerpo Académico de Ingeniera de Software Para la Educación, Universidad Autónoma de Yucatán, Mérida, Yucatán; Cuerpo Académico de Ingeniera de Software Para la Educación, Universidad Autónoma de Yucatán, Mérida, Yucatán; Cuerpo Académico de Ciencias de la Computación Unidad Tizimín, Universidad Autónoma de Yucatán, Mérida, Yucatán; Cuerpo Académico de Ingeniera de Software Para la Educación, Universidad Autónoma de Yucatán, Mérida, Yucatán","2021 Mexican International Conference on Computer Science (ENC)","13 Sep 2021","2021","","","1","6","This article describes a research work in progress, in which a methodology for the development of computerized educational materials based on augmented reality is proposed. The development of the proposal is preceded by a systematic review of the literature in which the convenience of having a methodology that assists teachers and developers interested in the development of educational materials related to augmented reality technology is concluded. The proposed methodology consists of four stages: (1) initiation, (2) design of the learning scenario, (3) implementation and (4) evaluation, as well as specific elements that must be considered in each of them for their correct fulfillment. Finally, the article briefly describes the validation strategy designed to evaluate this methodological proposal.","2332-5712","978-1-6654-2612-1","10.1109/ENC53357.2021.9534798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534798","Augmented Reality;Computerized Educational Material;Methodology;Software Engineering","Computer science;Systematics;Proposals;Augmented reality","augmented reality;computer aided instruction","computerized educational materials;systematic review;augmented reality technology;methodological proposal","","","","0","IEEE","13 Sep 2021","","","IEEE","IEEE Conferences"
"ARAnimals: Mobile Application with Augmented Reality for the Learning of Vertebrate Animals","J. P. Cruzado; N. De La Cruz; J. L. H. Salazar; J. Tarazona","Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Peru; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Peru; Faculty of Engineering and Business, Universidad Norbert Wiener, Lima, Peru; Faculty of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Peru","2020 IEEE Congreso Bienal de Argentina (ARGENCON)","13 Aug 2021","2020","","","1","4","This work shows the results of an application of augmented reality for learning about vertebrate animals in preschool children. A mobile application with augmented reality, called ARAnimals, was implemented following the agile Scrum methodology. The research design was quasi-experimental, where the sample consisted of two classrooms of 5-year-old students from a private school in the city of Lima. The experimental group improved by 33.04% compared to the control group, which only improved by 14.56%. Furthermore, the difference in the average time it took to evaluate the subject in the experimental group and in the control group was significant. The time for the experimental group was 13.3 min., and the time for the control group was 16.7 min. It is concluded that the use of a mobile application with augmented reality satisfactorily influences the learning of vertebrate animals, specifically in four aspects that are included in the dimensions to which they correspond.","","978-1-7281-5957-7","10.1109/ARGENCON49523.2020.9505519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9505519","Augmented reality;mobile application;learning","Animals;Design methodology;Urban areas;Mobile applications;Augmented reality","augmented reality;biology computing;computer aided instruction;educational institutions;zoology","mobile application;augmented reality;vertebrate animals;5-year-old students;control group;ARAnimals;private school;Lima","","","","13","IEEE","13 Aug 2021","","","IEEE","IEEE Conferences"
"Growing interest of Augmented Reality in retail: A Literature Review","F. Oliveira; R. Raposo; V. S. Carlos; M. Au-Yong-Oliveira","DEGEIT, Departamento de Economia, Gestão, Engenharia industrial e Turismo, Universidade de Aveiro, Aveiro, Portugal; Departamento de Comunicação e Arte, DigiMedia, Universidade de Aveiro, Aveiro, Portugal; DEGEIT, Departamento de Economia, Gestão, Engenharia industrial e Turismo, Universidade de Aveiro, Aveiro, Portugal; INESC TEC, GOVCOPP, DEGEIT, Universidade de Aveiro, Aveiro, Portugal","2022 17th Iberian Conference on Information Systems and Technologies (CISTI)","14 Jul 2022","2022","","","1","6","The experience of purchasing a good is highly influenced by various technologies that have not only impacted the shopping experience but have also significantly changed the way brands work on their digital presence. Augmented reality, a technology that delivers multisensory experiences that merge the real world with the digital, discussed in this article, is gaining presence in retail. The multidisciplinary teams of companies in this field, often through their branders and brand managers, have proposed creating and promoting distinctive technological experiences that put the user/customer at the centre. This trend has taken hold in physical retail and increasingly in online retail, which has experienced an unpredictable surge prior to the pandemic associated with COVID19. This paper aims to provide a literature review to understand better the state of the art of Augmented Reality (AR) in the retail space and its evolution in recent years and to identify the brands that have invested the most in this technology. Using SCOPUS and Web of Science as a research base, the work presented here shows that although research in this area already exists, it is perhaps still in an introductory phase in this field and is still looking for greater maturity in the use of AR in the consumer experience.","2166-0727","978-9-8933-3436-2","10.23919/CISTI54924.2022.9820340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9820340","Augmented Reality;Retail;Customer Experience;Consumer behaviour;Brands","COVID-19;Pandemics;Bibliographies;Companies;Market research;Surges;Augmented reality","augmented reality;epidemics;Internet;online shopping","online retail;physical retail;consumer experience;distinctive technological experiences;brand managers;branders;multisensory experiences;digital presence;shopping experience;augmented reality","","","","0","","14 Jul 2022","","","IEEE","IEEE Conferences"
"Use of augmented reality in teaching management of anaphylactic shock to family doctors","Š. Tevžič; Z. K. Ketiš; A. P. Susič; U. Zafošnik; P. Selič; Š. Mirošević; N. R. Gorenjec","Community health centre Ljubljana, Slovenia; Community health centre Ljubljana, Slovenia; Community health centre Ljubljana, Slovenia; Community health centre Ljubljana, Slovenia; Department of Family Medicine, Medical faculty, University of Ljubljana, Slovenia; Department of Family Medicine, Medical faculty, University of Ljubljana, Slovenia; Community health centre Ljubljana, Slovenia","2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)","15 Nov 2021","2021","","","794","797","Augmented reality (AR) is one of the emerging technologies of today. It has the potential to offer a novel approach to medical training that supplements conventional training methods with gamification and a more interactive learning experience. In emergency medicine, AR has benefits and feasibility in the clinical care of patients, in operating rooms and inpatient facilities, and in the education and training of emergency care providers. To further explore the role of AR in teaching management of anaphylactic shock to family doctors a single blinded, randomized controlled trial will be conducted. All participants will be involved in a one-day education program, consisting of lectures and skills practice. The test group will additionally engage in education about anaphylactic shock in augmented reality. The baseline will be assessed in a learning environment through a simulation based on the developed scenario. The simulation will be independently assessed with a developed evaluation scale by three experts. Participants will perform the simulation again after the intervention. After 1 and 12 months a simulation will be repeated in the participants' workplace with a standardized patient. We expect to prove that augmented reality is an efficient educational tool for emergency care at the primary health care level.","2623-8764","978-953-233-101-1","10.23919/MIPRO52101.2021.9596765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596765","augmented reality;medical education;primary care;emergency medicine;anaphylaxis;simulation","Training;Electric shock;Employment;Medical services;Tools;Augmented reality","augmented reality;biomedical education;computer aided instruction;health care;medical computing;teaching","augmented reality;teaching management;anaphylactic shock;family doctors;medical training;interactive learning experience;emergency medicine;emergency care providers;single blinded trial;randomized controlled trial;one-day education program;standardized patient","","","","22","","15 Nov 2021","","","IEEE","IEEE Conferences"
"Evaluation of the Motivation of University Students in the Learning of Industrial Design Through Augmented Reality","L. Laurens-Arredondo","Facultad de Cs. de la Ingeniería, Universidad Católica del Maule, Talca, Chile","2021 40th International Conference of the Chilean Computer Science Society (SCCC)","22 Dec 2021","2021","","","1","8","This article investigates the effects on the motivation and learning of the implementation of augmented reality as a pedagogical tool in the university context. A methodology focused on motivation called ARCS was implemented. The motivation of university students was measured with the Instructional Material Motivational Survey (IMMS) instrument, which was applied to a group of 96 students. The results show that augmented reality is accepted and valued positively by students, evidencing the positive stimulation of interest in learning after its use, with which it was intended to promote the use of this type of technology by teachers. This research provide a validated measurement model, as well as solid scientific references that aim to stimulate the use of m-learning, as it has been shown that its implementation favorably stimulates students, as well as their interest in learning and confidence in themselves.","2691-0632","978-1-6654-0956-8","10.1109/SCCC54552.2021.9650416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650416","ARCS;Motivation;university students;augmented reality","Computer science;Solid modeling;Instruments;Solids;Augmented reality","augmented reality;computer aided instruction;design engineering;human factors","university students;industrial design;augmented reality;pedagogical tool;ARCS;instructional material motivational survey instrument;IMMS","","","","0","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Parallax Occlusion Mapping in augmented reality case study on facade of Sino Portuguese Architecture Phuket, Thailand","K. Kalarat","Multimedia Technology and Animation, Walailak University, Nakhon Si Thammarat, Thailand","2015 Digital Heritage","25 Feb 2016","2015","1","","293","296","Sino Portuguese Architecture is a unique building in Thailand which combines with style of Chinese and European construction built around A.D.1890-1920. There are many details of bas-relief on the facade of the building. Currently, some of them have been destroyed or changed by the time. To preserve the buildings, which are houses, the digital data was established to collect the information of the houses and create to 3D virtual building represented by Augmented Reality (AR) technology. Using Augmented Reality with handheld devices is very popular because most people, nowadays, have smart phone or mobile phone. Thus, they can see the 3D houses via their handheld devices' camera and observe the building interacting with perspective changing in real-time. Therefore, the observers are able to view around the details of the virtual building easily. However, because of real-time interaction, handheld device have to render the visualization image as fast as changing point of view. Particularly, 3D model with many details, it takes load for handheld device computational time in case there are many details in 3D AR content because it cannot respond to the user simultaneously. This paper applies Parallax Occlusion Mapping (POM), which is well known technique for fast rendering of geometric detail and reducing a geometric complexity of model using surface detail information in a texture encoded, to 3D model of Sino Portuguese Architecture, which consists of many bas-relief patterns on the facade, in order to reduce the number of polygons. The system uses game engine, Unity3D, and Vuforia SDK implemented augmented reality application on handheld device. The result of this research use 1 polygon/ 1 bas-relief and the quality of visualization is compatible to each other on AR application.","","978-1-5090-0048-7","10.1109/DigitalHeritage.2015.7413885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7413885","Augmented Reality;Sino Portuguese Architecture;Bas-relief;Mapping algorithm;Game Engine","Three-dimensional displays;Augmented reality;Buildings;Architecture;Solid modeling;Computer architecture;Handheld computers","architecture;augmented reality;humanities;smart phones;solid modelling","parallax occlusion mapping;Sino Portuguese architecture facade;Phuket;Thailand;Chinese construction;European construction;digital data;3D virtual building;3D AR content;handheld devices;smart phone;mobile phone;virtual building;visualization image;3D model;POM;geometric complexity;bas-relief patterns;game engine;Unity3D;Vuforia SDK;augmented reality application","","","","11","IEEE","25 Feb 2016","","","IEEE","IEEE Conferences"
"Vehicle Insurance Calculator Using Augmented Reality","N. Jayanthi; I. Kala; P. S. Sunantha; A. Sukra","Department of computer science and engineering, SNS College Of Engineering, Coimbatore, India; Department of computer science and engineering, SNS College Of Engineering, Coimbatore, India; Department of computer science and engineering, SNS College Of Engineering, Coimbatore, India; Department of computer science and engineering, SNS College Of Engineering, Coimbatore, India","2019 5th International Conference on Advanced Computing & Communication Systems (ICACCS)","6 Jun 2019","2019","","","766","770","The important factor to calculate insurance is to inspect the damage of a vehicle for that the client has to migrate to the insurance company and have to wait for the arrival of the inspecting person. To make this ease for the client, he does not need to wait until the insurer calculates the amount of insurance to recover the damage happened. The core technique of this process is augmented reality. Once the dent images are uploaded then it produces the predicted cost. This predicted cost is produced as per the percentage of dent calculated using augmented reality image processing. Then as per the insurance claimed by the client, it is mapped with the amount calculated using augmented reality. This paper presents an innovative approach to detect vehicle's body damage and cost estimation for the vehicle insurance with using 2D images.","2575-7288","978-1-5386-9533-3","10.1109/ICACCS.2019.8728395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8728395","Vehicle dent detection;Cost prediction;Augmented reality","Insurance;Augmented reality;Inspection;Patents;Three-dimensional displays;Automobiles;Cameras","augmented reality;costing;image processing;inspection;insurance data processing;traffic engineering computing","vehicle insurance calculator;insurance company;inspecting person;augmented reality image processing;cost estimation;dent images;2D images","","","","24","IEEE","6 Jun 2019","","","IEEE","IEEE Conferences"
"The Integration of Augmented Reality (AR) in Learning Environment","A. A. Zambri; M. F. Kamaruzaman","Faculty of Art & Design, Formgiving Design Research Group, Universiti Teknologi MARA, Malaysia; Faculty of Art & Design, Formgiving Design Research Group, Universiti Teknologi MARA, Malaysia","2020 Sixth International Conference on e-Learning (econf)","1 Apr 2021","2020","","","194","198","In the uncertainty environment of today's world due to the Covid-19 pandemic, the education sector also shifting the teaching and learning technique to cater all the student learning needs. The Ministry of Education (MOE), Malaysia recommends all schools under MOE to use Open Distance Learning (ODL) which is part of the e-learning method during this critical period of time. With the advancement of the Internet of Things (IoT) and the integration of technology know-how, it will make every aspect of learning possible. This study goes some way to bridging the gap by exploring students' engagement and motivation towards Augmented Reality (AR). Findings showed encouraging learning outcomes as quantified by data analysis. This unique feature of Augmented Reality had led it to be implemented in education as it is able to convey abstract knowledge to a comprehensible context. Augmented Reality provides an exciting and fascinating learning environment as it increases the motivation and attractiveness of teaching and learning in real-life scenarios for students.","","978-1-6654-1550-7","10.1109/econf51404.2020.9385487","Universiti Teknologi MARA (UiTM); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385487","E-Learning;Augmented Reality;Multimedia Elements;Learning;Motivation","Electronic learning;Uncertainty;Pandemics;Education;Tools;Internet of Things;Augmented reality","augmented reality;diseases;distance learning;educational courses;Internet of Things;mobile computing;multimedia computing;teaching","augmented reality;uncertainty environment;Covid-19 pandemic;education sector;teaching;learning technique;MOE;open distance learning;e-learning method;students;encouraging learning outcomes;exciting learning environment;fascinating learning environment;AR","","","","27","IEEE","1 Apr 2021","","","IEEE","IEEE Conferences"
"The research and application of the augmented reality technology","J. He; P. Han; H. Liu; S. Men; L. Ju; P. Zhen; T. Wang","North Information Control Research Academy Group Co., Ltd, Nanjing, China; North Information Control Research Academy Group Co., Ltd, Nanjing, China; North Information Control Research Academy Group Co., Ltd, Nanjing, China; North Information Control Research Academy Group Co., Ltd, Nanjing, China; North Information Control Research Academy Group Co., Ltd, Nanjing, China; North Information Control Research Academy Group Co., Ltd, Nanjing, China; North Information Control Research Academy Group Co., Ltd, Nanjing, China","2017 IEEE 2nd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)","8 Feb 2018","2017","","","496","501","With the rapid development of computer 3D processing capacity and the emergence of low-cost sensors, the technology of augmented reality (AR) and virtual reality (VR) has advanced quickly in recent years, especially in combination with real-world technologies. Firstly, the concepts are summarized, and the difference and connection are analyzed between AR and VR. Then, a typical AR system with software and hardware architecture was presented based on the current research achievements. Three key techniques and related research are introduced in detail. Finally, application of AR in various areas is introduced, especially in the field of military system, equipment support and training simulation.","","978-1-5090-6414-4","10.1109/ITNEC.2017.8284781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8284781","augmented reality;system architecture;technology application","Augmented reality;Human computer interaction;Hardware;Real-time systems;Three-dimensional displays;Cameras","augmented reality;computer based training;military computing;military equipment","virtual reality;VR;hardware architecture;augmented reality technology;computer 3D processing capacity;low-cost sensors;software architecture;AR system;military system;equipment support;training simulation","","7","","9","IEEE","8 Feb 2018","","","IEEE","IEEE Conferences"
"Integrating augmented reality into female hairstyle try-on experience","W. -C. Wang; Y. -H. Chen; C. -Y. Kao","Hwa Hsia Institute of Technology Taipei, Taiwan; National Cheng Kung University Tainan, Taiwan; National Cheng Kung University Tainan, Taiwan","2011 Seventh International Conference on Natural Computation","19 Sep 2011","2011","4","","2125","2127","In the modern society, hairstyling is one of the leading fashions. Not only it plays an important role for social relationship, it also affects individual's perspective on his or her own look; therefore, it might change how people feel about each other. To women, hairstyle not only shows their confidence but also a symbol of beauty. Augmented Reality (AR) is an extension of virtual reality (VR) which focuses on the real-time interaction under real environment. Our study will focus on females' hairstyle “try-on” experience integrated with AR, utilizing the AR system to increase females' interaction with hairstyle “tryon” operating model and process. We hope the study will provide valuable information for future digitized hair salon business and consumer-related studies.","2157-9563","978-1-4244-9953-3","10.1109/ICNC.2011.6022427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022427","Experience;Consumer;Augmented Reality","Three dimensional displays;Cameras;Augmented reality;Solid modeling;Sprites (computer);Media","augmented reality;marketing","augmented reality integration;female hairstyle try-on experience;social relationship;virtual reality;hairstyle try-on operating model;digitized hair salon business","","4","","15","IEEE","19 Sep 2011","","","IEEE","IEEE Conferences"
"Comparing Augmented Reality-based Display Methods to Present Guiding Information","R. Horikawa; M. Ito; K. Komiya; T. Nakajima; H. Yamana","Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan","2022 IEEE 4th Global Conference on Life Sciences and Technologies (LifeTech)","14 Apr 2022","2022","","","22","25","In recent years, a variety of Augmented Reality (AR) contents have emerged, and it will not be long before we get to use AR devices like a head-mounted display (HMD), or glasses in our daily lives. With such AR devices, we receive a lot of information from them, especially in outdoor situations. In order to find the best way to display virtual contents, in this study, we compare two methods: the ""canvas-fixed"" method and the ""screen-fixed"" method with experiments by simulating AR situations in a virtual reality (VR) world, and we discuss the opportunities of the methods.","","978-1-6654-1904-8","10.1109/LifeTech53646.2022.9754903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754903","Augmented Reality;Outdoor AR;Notification;User Study","Head-mounted displays;Conferences;Resists;Glass;Life sciences;Augmented reality","augmented reality;helmet mounted displays","screen-fixed method;virtual reality;guiding information;AR devices;head-mounted display;outdoor situations;virtual contents;canvas-fixed method;augmented reality-based display methods;HMD","","","","4","IEEE","14 Apr 2022","","","IEEE","IEEE Conferences"
"Setforge - Synthetic RGB-D Training Data Generation to Support CNN-Based Pose Estimation for Augmented Reality","S. Zhang; C. Song; R. Radkowski","Iowa State University, Virtual Reality Applications Center; Iowa State University, Virtual Reality Applications Center; Iowa State University, Virtual Reality Applications Center","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","237","242","The objective of this contribution is to introduce setforge, a set of software tools for synthetic data generation for convolutional neural network (CNN) training. Our focus is on CNNs for 6-degree-of-freedom pose estimation using RGB-D data. To determine the pose of physical objects in 6-degree-of-freedom is an essential task for many augmented reality applications. The recent years have shown the advent of trainable methods such as CNNs and others. However, those approaches require training data. The tools, this paper introduces, allow one to generate training data from 3D models. They come with plenty of features for random data generation and augmentation, adapting colors, hue, and noise. We contribute these tools as open-source software available on Github. A prototype CNN demonstrates how one can utilize it. An augmented reality demo application also shows its real-time pose estimation performance.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951897","Augmented Reality;6 DoF Pose Estimation;Convolutional Neural Network;Synthetic data;Synthetic data training;open-source software","Rendering (computer graphics);Tools;Image color analysis;Cameras;Training;Training data;Augmented reality","augmented reality;convolutional neural nets;feature extraction;image colour analysis;pose estimation;software tools","CNN-based pose estimation;software tools;convolutional neural network training;RGB-D data;random data generation;Setforge;synthetic RGB-D training data generation;augmented reality;data augmentation;open-source software","","","","29","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Real-Time Augmented Reality Visual-Captions for Deaf and Hard-of-Hearing Children in Classrooms","J. Li","School of Architecture and Art, Beijing Jiaotong University, Beijing, China","2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","641","642","Deaf and hard-of-hearing (DHH) children experience difficulties in mainstream classrooms since they cannot access audio information effectively. Although tools like captions are developed specifically to assist DHH individuals, primary school children have trouble to read or understand the text. To address this challenge, this paper develops an AR-based visual-captions, which will transfer the speech to text and images in real-time and display the information around the teacher in classrooms. The AR visual-captions aims to help DHH children better receive information and enhance their classroom experience. We describe the concept, design and implementation of our prototype, and discuss future research directions.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108869","Augmented Reality;Accessibility;DHH;Children;Captions;K.6.1 [Management of Computing and Information Systems]: Project and People Management—Life Cycle;K.7.m [The Computing Profession]: Miscellaneous—Ethics","Three-dimensional displays;Conferences;Prototypes;User interfaces;Real-time systems;Augmented reality;Information systems","augmented reality;computer aided instruction;handicapped aids;natural language processing","AR visual-captions;audio information;classroom experience;DHH children;DHH individuals;hard-of-hearing children experience difficulties;mainstream classrooms;primary school children;reality visual-captions","","","","10","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Recording and reproducing high order surround auditory scenes for mixed and augmented reality","Zhiyun Li; R. Duraiswami; L. S. Davis","Perceptual Interfaces and Reality Laboratory, UMIACS University of Maryland, College Park, MD, USA; Perceptual Interfaces and Reality Laboratory, UMIACS University of Maryland, College Park, MD, USA; Perceptual Interfaces and Reality Laboratory, UMIACS University of Maryland, College Park, MD, USA","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","240","249","Virtual reality systems are largely based on computer graphics and vision technologies. However, sound also plays an important role in human's interaction with the surrounding environment, especially for the visually impaired people. In this paper, we develop the theory of recording and reproducing real-world surround auditory scenes in high orders using specially designed microphone and loudspeaker arrays. It is complementary to vision-based technologies in creating mixed and augmented realities. Design examples and simulations are presented.","","0-7695-2191-6","10.1109/ISMAR.2004.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383061","","Layout;Augmented reality;Microphone arrays;Loudspeakers;Virtual reality;Computer graphics;Computational modeling;Computer displays;Robustness;Laboratories","augmented reality;computer vision;audio signal processing;computer graphics","high order surround auditory scene;mixed reality;augmented reality;virtual reality system;computer graphics;vision technology;microphone array;loudspeaker array","","2","1","11","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"Providing a Wide Field of View for Effective Interaction in Desktop Tangible Augmented Reality","S. Jeon; G. J. Kim","Department of Computer Science and Engineering, Haptics and Virtual Reality Laboratory, Republic of Korea; Department of Computer Science and Engineering, Korea University, Republic of Korea","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","3","10","This paper proposes to generate and provide wide field of view (FOV) augmented reality (AR) imagery by mosaicing images from smaller fields of moving views in ""desktop"" tangible AR (DTAR) environments. AR systems usually offer a limited FOV into the interaction space, constrained by the FOV of the camera and/or the display, which causes serious usability problems especially when the interaction space is large and many tangible props/markers are used. This problem is more apparent in DTAR environments in which an upright frontal display is used, instead of a head mounted display. This can be solved partly by placing the camera at a relatively far location or by using multiple cameras and increasing the working FOV. However, as for the former solution, the large distance between the interaction space and the fixed camera decreases the tracking and recognition reliability of the tangible markers, and the latter solution introduces significant additional set-up, cost, and computational load. Thus, we propose to use a mosaiced image to provide wide FOV AR imagery. We experimentally compare our solution, i.e. to offer the entire view of the interaction space at once, to other nominal AR set-ups. The experimental results show that, despite some amounts of visual artifacts due to the imperfect mosaicing, the proposed solution can improve task performance and usability for a typical DTAR system. Our findings should contribute to making AR systems more practical and usable for the mass.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480743","Mosaicing;Augmented Reality;Desktop AR;Usability;Interaction Space;H.5.1 [INFORMATION INTERFACES AND PRESENTATION]: Multimedia Information Systems-Artificial;augmented;and virtual realities","Augmented reality;Cameras;Virtual reality;Usability;Head;Computer displays;Switches;Computer science;Haptic interfaces;Computational efficiency","augmented reality;image segmentation;image sensors","desktop tangible augmented;field of view augmented reality imagery;image mosaicing;upright frontal display;recognition reliability","","9","","27","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"Development of a Mixed Reality System Based on IoT and Augmented Reality","D. Jenzeri; A. Chehri; G. Jeon","National Engineering School of Monastir, Ibn El Jazzar Street, Monastir, Tunisia, University of UQAC, Chicoutimi, Canada; Department of Mathematics and Computer Science, Royal Military College of Canada, Kingston, Ontario, Canada; Department of Embedded Systems Engineering, Incheon National University, Incheon, Korea","2022 IEEE 96th Vehicular Technology Conference (VTC2022-Fall)","18 Jan 2023","2022","","","1","5","The Internet of Things or IoT describes the network of physical terminals, the “objects” that integrate sensors, software, and other technologies to connect to different terminals and systems on the Internet and exchange data with them. These terminals can be simple household appliances and industrial tools of great complexity. Augmented Reality (AR) provides operators with information directly in their field of vision, using a helmet or adapted glasses. The obstacles to the adoption of Augmented Reality are related to several factors. First, the devices do not yet offer efficient and discreet ergonomics and are still expensive. While IoT and sensors are focused on the productivity of machines, Augmented Reality makes it possible to increase the performance of a human. Industrial Augmented Reality aims to improve the factory’s economic performance. This article proposes a hybrid solution between mixed Reality and IIoT for industrial applications.","2577-2465","978-1-6654-5468-1","10.1109/VTC2022-Fall57202.2022.10012824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012824","Augmented Reality;Mixed Reality;IIoT;Industry 4.0","Performance evaluation;Cloud computing;Vehicular and wireless technologies;Mixed reality;Glass;Software;Sensor systems","augmented reality;Internet of Things;production engineering computing","exchange data;IIoT;industrial applications;industrial augmented reality;Internet of Things;mixed reality system;physical terminals","","","","13","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"Synthesizing reality for realistic physical behavior of virtual objects in augmented reality applications for smart-phones","N. Amar; M. Raviv; B. David; O. Chernoguz; J. El-Sana","Computer Science, Ben-Gurion University of the Negev, Israel; Computer Science, Ben-Gurion University of the Negev, Israel; Computer Science, Ben-Gurion University of the Negev, Israel; Computer Science, Ben-Gurion University of the Negev, Israel; Computer Science, Ben-Gurion University of the Negev, Israel","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","123","124","This paper presents a framework for augmented reality applications that runs on smart mobile phones and enables realistic physical behavior of the virtual objects in the real-world. The used mobile phone is equipped with two cameras and provides stereo images and live video. The two images are used to reconstruct a 3D representation of the real world, which is good enough to enable physical interaction between the virtual and the real-world objects, but not fine enough to synthesize the real-world view for back projection. The visual synthesis of the real-world view is done through the video stream. The constructed 3D representation is registered in the real-world view and used to place the virtual objects, determine their physical behavior, and detect collision with objects in the realworld view. The 3D reconstruction is not performed at each frame, but applied when necessary based on the position of the dynamic objects. Pose estimation is determined based on the movement of the mobile phone (gyroscope and accelerometer) and the viewed images. A physics engine, which utilizes the gravity vector obtained from the accelerometer sensor of the mobile device, is integrated into our framework. The physics engine equips virtual objects with realistic physical behavior.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549393","I.2.10 [Computing Methodologies]: Vision and Scene Understanding-3D/stereo scene analysis","Three-dimensional displays;Cameras;Mobile handsets;Augmented reality;Streaming media;Feature extraction;Estimation","accelerometers;augmented reality;cameras;image reconstruction;image representation;pose estimation;smart phones;stereo image processing;video signal processing","reality synthesis;realistic physical behavior;virtual-real-world objects physical interaction;augmented reality applications;smart mobile phones;cameras;stereo images;live video;image reconstruction;3D real world representation;real-world view visual synthesis;video stream;collision detection;pose estimation;physics engine;gravity vector;accelerometer sensor","","3","21","11","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"Large Scale Information Marker Coding for Augmented Reality Using Graphic Code","B. Patrão; L. Cruz; N. Gonçalves","Institute of Systems and Robotics, University of Coimbra - Portugal; Institute of Systems and Robotics, University of Coimbra - Portugal; Portuguese Mint and Official Printing Office, University of Coimbra - Portugal","2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","17 Jan 2019","2018","","","132","135","In this work, we will present some Graphic Code1 uses related to large scale information coding applied to Augmented Reality. Machine Readable Codes(MRCs) are broadly used form any reasons. However, they are mostly based on small information (like URLs, id numbers, phone numbers, visit card, etc.). The recently introduced Graphic Code differs from classical MRCs because it is very well integrated with images for aesthetic control(Graphic Code has its aesthetic value than classical MRCs). Furthermore, it is able to code a large amount of information, thus it can also store other kinds of models (like meshes, images, sketches, etc.) for applications that are unusual for classical MRCs. The main advantage of using our approach as an Augmented Reality marker is the possibility of creating generic applications that can read and decode these Graphic Code markers, which might contain 3D models and complex scenes encoded in it. Additionally, the resulting marker has strong aesthetic characteristics associated to it once it is generated from any chosen base image.","","978-1-5386-9269-1","10.1109/AIVR.2018.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613646","Augmented Reality;Machine Readable Codes;Large Information Coding;Graphic Pattern;Steganography","Conferences;Artificial intelligence;Virtual reality","augmented reality;bar codes;image processing","machine readable codes;large scale information marker coding;augmented reality marker;graphic code markers;classical MRC;aesthetic control;3D models;complex scenes;aesthetic characteristics","","","","9","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Registration for outdoor augmented reality applications using computer vision techniques and hybrid sensors","R. Behringer","Rockwell Science Center, Thousand Oaks, CA, USA","Proceedings IEEE Virtual Reality (Cat. No. 99CB36316)","6 Aug 2002","1999","","","244","251","Registration for outdoor systems for Augmented Reality (AR) cannot rely on the methods developed for indoor use (e.g., magnetic tracking, fiducial markers). Although GPS and the earth's magnetic field can be used to obtain a rough estimate of position and orientation, the precision of this registration method is not high enough for satisfying AR overlay. Computer vision methods can help to improve the registration precision by tracking visual clues whose real world positions are known. We have developed a system that can exploit horizon silhouettes for improving the orientation precision of a camera which is aligned with the user's view. It has been shown that this approach is able to provide registration even as a stand-alone system, although the usual limitations of computer vision prohibit to use it under unfavorable conditions. This paper describes the approach of registration by using horizon silhouettes. Based on the known observer location (from GPS), the 360 degree silhouette is computed from a digital elevation map database. Registration is achieved, when the extracted visual horizon silhouette segment is matched onto this predicted silhouette. Significant features (mountain peaks) are cues which provide hypotheses for the match. Several criteria are tested to find the best matching hypothesis. The system is implemented on a PC under Windows NT. Results are shown in this paper.","1087-8270","0-7695-0093-5","10.1109/VR.1999.756958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=756958","","Augmented reality;Application software;Computer vision;Displays;Global Positioning System;Virtual reality;Virtual prototyping;Inspection;Data visualization;Magnetic sensors","augmented reality;computer vision;navigation","outdoor augmented reality applications;computer vision techniques;hybrid sensors;outdoor systems;magnetic tracking;fiducial markers;registration method;horizon silhouettes;orientation precision;computer vision;observer location;digital elevation map database","","33","88","39","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Augmented and Virtual Reality Interfaces for Crowd Simulation Software-A Position Statement for Research on Use-Case-Dependent Interaction","W. Hürst; R. Geraerts","Utrecht University, Netherlands; Utrecht University, Netherlands","2019 IEEE Virtual Humans and Crowds for Immersive Environments (VHCIE)","16 May 2019","2019","","","1","3","In this position paper, we claim that immersive technologies, such as Augmented and Virtual Reality, are well-suited interfaces for the usage of crowd simulation software in different contexts. We introduce three use cases; planning, awareness creation, and education. Based on an overview of different Augmented and Virtual Reality approaches, we identify the ones most suitable for each of the three scenarios and illustrate related implementations. Initial observations with their usage confirm our statements, but also highlight areas to explore with future research.","","978-1-7281-3219-8","10.1109/VHCIE.2019.8714733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8714733","Human-centered computing-Mixed / augmented reality-Virtual reality;Computing methodologies-Simulation types and techniques;Software and its engineering-Virtual worlds software","Software;Solid modeling;Planning;Three-dimensional displays;Computational modeling;Education;Virtual reality","augmented reality","virtual reality interfaces;crowd simulation software;position statement;use-case-dependent interaction;immersive technologies;awareness creation;augmented reality approaches;virtual reality approaches;augmented reality interfaces;planning case;awareness creation case;education case","","4","","4","IEEE","16 May 2019","","","IEEE","IEEE Conferences"
"Augmented Reality for Human-Robot Cooperation in Aircraft Assembly","A. Luxenburger; J. Mohr; T. Spieldenner; D. Merkel; F. Espinosa; T. Schwartz; F. Reinicke; J. Ahlers; M. Stoyke","Cognitive Assistants; Cognitive Assistants; Agents and Simulated Reality German Research Center for AI (DFKI GmbH), Saarbrücken, Germany; Cognitive Assistants; Cognitive Assistants; Cognitive Assistants; Technology / Development Broetje Automation GmbH, Rastede, Germany; Technology / Development Broetje Automation GmbH, Rastede, Germany; Technology / Development Broetje Automation GmbH, Rastede, Germany","2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","263","2633","Augmented Reality (AR) is often discussed as one of the enabling technologies in Industrie 4.0. In this paper, we describe a practical application, where Augmented Reality glasses are used not only for assembly assistance, but also as a means of communication to enable the orchestration of a hybrid team consisting of a human worker and two mobile robotic systems. The task of the hybrid team is to rivet so-called stringers onto an aircraft hull. While the two robots do the physically demanding, unergonomic and possibly hazardous tasks (squeezing and sealing rivets), the human takes over those responsibilities that need experience, multi-sensory sensitiveness and specialist knowledge. We describe the working scenario, the overall architecture and give design and implementation details on the AR application.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942239","Augmented Reality, aircraft manufacture, mobile robots, teamwork, hybrid teams, Industrie 4.0, worker assistance","Task analysis;Robots;Three-dimensional displays;Aircraft;Visualization;Data models;Solid modeling","aircraft manufacture;augmented reality;control engineering computing;human-robot interaction;mobile robots;production engineering computing;robotic assembly","augmented reality glasses;human worker;mobile robotic systems;aircraft hull;human-robot cooperation;aircraft assembly","","5","","9","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"When AR meets food: A structural overview of the research space on multi-facets of food","Jun Wei; Shengdong Zhao; R. Nakatsu; H. B. L. Duh","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","97","98","Food has always been interwoven with the human life, biologically and emotionally. Recently, there has been growing research interest in the various aspects of food itself and the food-related activities, in both physical and digital format. Yet, the progress made and the key research questions for these researches are rarely analyzed systematically. In this paper, we summarized the characteristics of food from different perspectives and provided a survey of existing works. We categorized the functions of food into biological, psychological and cultural, and described how augmented and mixed reality technologies have been applied to various aspects of food. We then discussed about the structural research space based on the literatures to address the opportunities and challenges for further development around augmented food experience. The main purpose is to highlight the expressiveness of technology-enhanced food and engage people's emotional perception and experience with food.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483999","Food;Augmented Reality;smell;taste;entertainment","Augmented reality;Cultural differences;Biology;Psychology;Visualization;Shape","augmented reality;cultural aspects;food products;psychology","food-related activities;mixed reality technologies;augmented reality technology;biological technology;psychological technology;cultural technology;structural research space;augmented food experience;technology-enhanced food;people emotional perception;AR","","2","","12","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"DOMUS R.A. and DOMUS REDUX: Cyber-Archeology Extended to Education","A. Da Silva Martire; T. Bina","LARP, Univ. de Sao Paulo Sao Paulo, Sao Paulo, Brazil; Museu de Arqueologia e Etnologia, Universidade de São Paulo, São Paulo, SP, Brasil","2015 XVII Symposium on Virtual and Augmented Reality","26 Oct 2015","2015","","","133","136","This paper presents the development of two applications elaborated by the Laboratory for Roman Provincial Archaeology (LARP-USP) named DOMUS R.A. and DOMUS REDUX: two mobile applications that allow the public to experience an ancient Roman house (domes, in Latin) in both Augmented and Virtual Realities environments. Starting from the discussion of our previous application (DOMUS, released in 2013), we describe why we decided to reformulate the original application and how we did it. Finally, we present the educational activities based on DOMUS, DOMUS R.A. and DOMUS REDUX that are now being developed with students and teachers.","","978-1-4673-7204-6","10.1109/SVR.2015.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300738","cyber-archaeology;augmented reality;simulation;virtual reality;application","Augmented reality;Solid modeling;Three-dimensional displays;Computers;History;Education","archaeology;augmented reality;computer aided instruction;mobile computing","DOMUS R.A;DOMUS REDUX;cyber-archeology;education;Laboratory for Roman Provincial Archaeology;LARP-USP;mobile applications;ancient Roman house;Roman domes;augmented realities;virtual realities","","","","4","IEEE","26 Oct 2015","","","IEEE","IEEE Conferences"
"Augmented standardized patients now virtually a reality","F. D. McKenzie; H. M. Garcia; R. J. Castelino; T. W. Hubbard; J. A. Ullian; G. A. Gliva","Virginia Modeling Analysis and Simulation Center (VMASC), Old Dominion University, USA; Virginia Modeling Analysis and Simulation Center (VMASC), Old Dominion University, USA; Virginia Modeling Analysis and Simulation Center (VMASC), Old Dominion University, USA; Theresa A. Thomas Professional Skills Teaching & Assessment Center, Eastern Virginia Medical School, USA; Theresa A. Thomas Professional Skills Teaching & Assessment Center, Eastern Virginia Medical School, USA; Theresa A. Thomas Professional Skills Teaching & Assessment Center, Eastern Virginia Medical School, USA","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","270","271","Standardized patients (SPs), individuals who realistically portray patients, are widely used in medical education to teach and assess communication skills, eliciting a history, performing a physical exam, and other important clinical skills. One limitation is that each SP can only portray a limited set of physical symptoms. Finding SPs with the abnormalities students need to encounter is typically not feasible. This project augments the SP by permitting the learner to hear abnormal heart and lung sounds in a normal SP.","","0-7695-2191-6","10.1109/ISMAR.2004.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383071","","Lungs;Computational modeling;Medical simulation;Heart;Medical diagnostic imaging;History;Stethoscope;Education;Computer simulation;Augmented reality","medical diagnostic computing;computer aided instruction;augmented reality;patient care;biomedical education","augmented standardized patients;medical education;communication skills;physical exam;clinical skills;abnormal heart;lung sounds","","5","","2","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"[POSTER] Mixed-Reality Store on the Other Side of a Tablet","M. Ohta; S. Nagano; H. Niwa; K. Yamashita","Graduate School of Engineering, Osaka Prefecture University; Graduate School of Engineering, Osaka Prefecture University; Graduate School of Engineering, Osaka Prefecture University; Graduate School of Engineering, Osaka Prefecture University","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","192","193","This paper proposes a mixed-reality shopping system for users who do not own a PC but do own a tablet. In this system, while viewing panoramic images photographed along the aisles of a real store, the user can move freely around the store. Products can be selected and freely viewed from any angle. Furthermore, by utilizing a Photo-based augmented reality (Photo AR) technology the product can be displayed as if it were in the hands of the user. The results of a user evaluation showed that even though the proposed system uses a tablet with a smaller screen it was preferred over a conventional e-commerce site using a larger monitor.","","978-1-4673-7660-0","10.1109/ISMAR.2015.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328100","Shopping system;EC sites;Panoramic photos;Store interior;Tablet;Photo AR","Monitoring;Cameras;Augmented reality;Face;Browsers;Switches","augmented reality;electronic commerce;notebook computers;retail data processing","mixed-reality store;tablet;mixed-reality shopping system;panoramic image;photo AR technology;photo-based augmented reality technology;user evaluation;e-commerce site","","3","","7","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Spatial Augmented Reality","",,"Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","306","306","","","0-7695-2191-6","10.1109/ISMAR.2004.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383090","","Augmented reality","","","","","","","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"Design of an Integration Model for Multimedia Systems for Alternative Reality Games","J. S. V. V.; C. A. R. C.","Programa de Ingeniería en Multimedia, Universidad Militar Nueva Granada, Bogotá, Colombia; Programa de Ingeniería en Multimedia, Universidad Militar Nueva Granada, Bogotá, Colombia","2020 IEEE Games, Multimedia, Animation and Multiple Realities Conference (GMAX)","18 Nov 2020","2020","","","1","4","Alternative reality video games (ARG) have emerged thanks to their flexibility when using as a platform in the real world, proposing new forms of interaction. The objective of this study is to determine how a multimedia systems integration model can be integrated into an ARG game. To this end, the research question is as follows: How can a multimedia system be integrated into an alternative reality game? The research question is answered through the development of an integration model that is supported by the network narrative, which is generally the most widely used in this type of game, giving the possibility of integrating multimedia systems such as nodes of diffusion and interaction of the game narrative.","","978-1-7281-6147-1","10.1109/GMAX49668.2020.9256832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256832","Multimedia Systems;ARG;Augmented Reality;Transmedia","Games;Multimedia systems;Prototypes;Augmented reality;Solid modeling;Media;Computational modeling","augmented reality;computer games;multimedia systems","game narrative;alternative reality game;alternative reality video games;multimedia systems integration model;ARG game;network narrative;augmented reality","","","","7","IEEE","18 Nov 2020","","","IEEE","IEEE Conferences"
"Touching an ancient stone: 3d modeling and augmented reality techniques for a collection of petroglyphs from State Hermitage Museum","N. Pikov; M. Rumyantsev; M. Vishniakova; I. Kizhner; D. Hookk","Mania Vishniakova, Inna Kizhner Siberian Federal University Krasnoyarsk, Russia; Mania Vishniakova, Inna Kizhner Siberian Federal University Krasnoyarsk, Russia; Sibirskij federal'nyj universitet, Krasnoarsk, KrasnoÃ¢Ì�rskij kraj, RU; Sibirskij federal'nyj universitet, Krasnoarsk, KrasnoÃ¢Ì�rskij kraj, RU; Gosudarstvennyj Ermitaz, Sankt-Peterburg, RU","2015 Digital Heritage","25 Feb 2016","2015","2","","739","740","Displaying collections of petroglyphs in a museum so that the exhibits inspire interest in the public can be considered an interesting task of turning the traditional exhibition space into the augmented space with exciting objects providing evidence of cultural developments in the Bronze Age. The paper discusses the workflow of acquiring, processing and displaying 3D data for a collection of petroglyphs with carved images (Okunev stones) from the State Hermitage Museum in Saint Petersburg, Russia","","978-1-5090-0048-7","10.1109/DigitalHeritage.2015.7419613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419613","Okunev culture;State Hermitage Museum;3D modeling;Augmented Reality","Three-dimensional displays;Solid modeling;Rocks;Art;Cultural differences;Augmented reality;Image resolution","augmented reality;exhibitions;history;museums;solid modelling","3D modeling;augmented reality;State Hermitage Museum;petroglyph collection display;augmented space;exhibition space;cultural developments;Bronze Age;3D data display;3D data processing;3D data acquisition;carved images;Okunev stones;Saint Petersburg;Russia","","","","9","IEEE","25 Feb 2016","","","IEEE","IEEE Conferences"
"Exploring augmented reality benefits in collaborative conceptualization","Xiangyu Wang","Key Centre of Design Computing and Cognition, Faculty of Architecture, Design and Planning, University of Sydney, Australia","2008 12th International Conference on Computer Supported Cooperative Work in Design","10 Jun 2008","2008","","","699","704","This paper reveals the preliminary results of an experiment that studied designer and client communication and interaction during the conceptual stage of design. This study analysed the most fundamental components of the ‘common language’ in the designer-client relationship, including voice dialogue, visual gestures and other communication cues. The purpose of the experiment was to explore the idea of virtual environments as a viable method of communication, and to quantify the benefits of virtual environments as a design facilitator between designer and client in the conceptual design phase.","","978-1-4244-1650-9","10.1109/CSCWD.2008.4537063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4537063","Design Process;Virtual Environment (VE);Virtual Reality (VR);Augmented Reality (AR);Communication;Immersion;Collaboration;Interaction","Augmented reality;Collaboration;Process design;Virtual environment;Virtual reality;Appropriate technology;Cognition;Computer architecture;Speech analysis;Problem-solving","augmented reality;groupware;user interfaces","augmented reality;collaborative conceptualization;designer-client relationship;voice dialogue;visual gestures","","","","4","IEEE","10 Jun 2008","","","IEEE","IEEE Conferences"
"Vertical Vergence Calibration for Augmented Reality Displays","M. A. Livingston; S. R. Ellis; S. M. White; S. K. Feiner; A. Lederer","Adam Lederer, Naval Research Laboratory, USA; Virtual Reality Lab, Naval Research Laboratory, Inc., USA; Human Information Processing Research Branch, NASA Ames Research Center, USA; Department of Computer Science, Columbia University, USA; NA","IEEE Virtual Reality Conference (VR 2006)","7 Aug 2006","2006","","","287","288","Stereo and bi-ocular head-mounted displays (HMDs) require the user to fuse two images into a coherent picture of the threedimensional world. The human visual system performs this task constantly, but when the input images contain both real and graphical depictions, the problem becomes more difficult. A vertical disparity in the graphics causes diplopia for users trying to fuse the real and virtual objects simultaneously. We implement three methods to measure and correct this disparity and assess them with a collection of a single model of optical see-through HMD.","2375-5334","1-4244-0224-7","10.1109/VR.2006.142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1667663","augmented reality;head-mounted display;vergence","Calibration;Augmented reality;Fuses;Eyes;Computer displays;Humans;Visual system;Computer graphics;Image segmentation;Virtual reality","","augmented reality;head-mounted display;vergence","","2","10","10","IEEE","7 Aug 2006","","","IEEE","IEEE Conferences"
"StereoChem: Augmented Reality 3D Molecular Model Visualization App for Teaching and Learning Stereochemistry","N. Swamy K L; P. S. Chavan; S. Murthy","IDP-Educational Technology, IIT Bombay; IDP-Educational Technology, IIT Bombay; IDP-Educational Technology, IIT Bombay","2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT)","13 Aug 2018","2018","","","252","256","Understanding stereochemistry is of critical importance for students aiming to be future chemists, molecular biologists, pharmacists, pharmacologists or physicians. Stereochemistry focuses on the study of the stereoisomers which have the same molecular formula but differ only in the spatial orientation of their atoms resulting in different physical, chemical or biological properties. Hence spatial thinking skill is essential for students to interpret stereoisomers. Augmented reality helps enhance the spatial perception of 3D molecules. StereoChem, our mobile app for visualizing augmented 3D molecular models harnesses this advantage of augmented reality to aid teaching and learning of stereochemistry. This paper gives a brief introduction to the significance and challenges of learning stereochemistry. It describes the design inputs that were considered for encouraging the ubiquitous use of our app by chemistry teachers and students, then discusses the development of the StereoChem app and the teaching-learning contexts in which it can be used. Finally, it gives an account of the user experience study done with 50 chemistry teachers.","2161-377X","978-1-5386-6049-2","10.1109/ICALT.2018.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8433508","Augmented Reality;Stereochemistry;Spatial thinking;Jmol;Unity 3D;Vuforia","Three-dimensional displays;Chemicals;Two dimensional displays;Augmented reality;Visualization;Solid modeling;Task analysis","augmented reality;chemistry computing;computer aided instruction;data visualisation;mobile learning;teaching","biological properties;spatial thinking skill;stereoisomers;spatial perception;teaching-learning contexts;molecular formula;spatial orientation;different physical properties;chemical properties;mobile application;3D molecular models;stereochemistry learning;StereoChem application;augmented reality 3D molecular model visualization application","","8","","12","IEEE","13 Aug 2018","","","IEEE","IEEE Conferences"
"A collaborative augmented reality system using transparent display","M. Hirakawa; S. Koike","Interdisciplinary Faculty of Science and Engineering, Shimane University, Matsue, Japan; Interdisciplinary Faculty of Science and Engineering, Shimane University, Matsue, Japan","IEEE Sixth International Symposium on Multimedia Software Engineering","17 Jan 2005","2004","","","410","416","Augmented reality is a technique to integrate the virtual (i.e., computer-generated) information with objects in the real world. Real world objects can thus be augmented in their properties and functions with the help of a computer. One of the authors has proposed an augmented reality system in which a transparent display is used as a means of integration of the real world and the virtual world. This paper discusses an extension of the system so that it can be used in a collaborative working environment. Capturing the gesture as a means of user interaction is realized by a single camera, aiming at simplifying the system setup and image analysis. We propose an idea of utilizing statistical data of human body and human's perceptional characteristics, as well as vision techniques. Two applications are presented to explain the usefulness of the system: one is a game-like application, which we call mind-to-mind communication, and the other a messenger object.","","0-7695-2217-3","10.1109/MMSE.2004.2","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1376689","augmented reality;transparent display;collaboration;single camera tracking","Collaboration;Augmented reality;Application software;Computer displays;Collaborative work;Cameras;Image analysis;Humans;Books;Biomedical imaging","augmented reality;groupware;video cameras;computer vision;gesture recognition;image motion analysis","collaborative augmented reality system;computer-generated information;transparent display;user interaction;image analysis;single camera tracking;computer vision;gesture recognition;human perception","","7","2","19","IEEE","17 Jan 2005","","","IEEE","IEEE Conferences"
"‘Street Smart’: Safe Street App for Women Using Augmented Reality","P. Chaudhari; R. Kamte; K. Kunder; A. Jose; S. Machado","Department of Computer Engineering, St. Francis Institute of Technology, Mumbai, India; Department of Computer Engineering, St. Francis Institute of Technology, Mumbai, India; Department of Computer Engineering, St. Francis Institute of Technology, Mumbai, India; Department of Computer Engineering, St. Francis Institute of Technology, Mumbai, India; Department of Computer Engineering, St. Francis Institute of Technology, Mumbai, India","2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)","25 Apr 2019","2018","","","1","6","Over the past few years, women safety has become a prominent issue all over the world. Today's women are empowered and they are independent too. But still, they are concerned about their safety against the violence and the harassment as they have to travel late night through unknown areas. Even if it is true that men and women are equal in every field like men women are not so strong physically in the emergency situations. Women should be provided with some helping hand to relieve them in the risky situations. As there is a tremendous increase in a number of Android users, an android phone can be used to protect the women in the risky situation. This paper presents a women safety Android application which is developed by using a number of features in smartphones like GPS navigation, digital camera, high-speed internet connectivity and many more. The proposed work helps the user to get articles and reviews about the place by just holding the camera at the location. These articles and reviews are augmented with the real scene in the camera by integrating the augmented reality. Augmented reality can be integrated into women safety app using Wikitude SDK which helps to place articles and reviews related to the current location of the user. Along with articles and reviews, the recommendation about the place such as `Safe Street' or `Unsafe Street' is also provided to the user based on the available data. The articles, reviews as well as the recommendation given by the system help the user to decide how safe or how dangerous a particular street/place is. Furthermore, the user can send calls/messages to the police and the listed contact numbers using this app in case of emergency. The message contains details about the current location of the user. If the user wants to share his experience about the place, he can post his reviews through this app.","","978-1-5386-5257-2","10.1109/ICCUBEA.2018.8697863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8697863","Augmented Reality;GPS;Wikitude","Law enforcement;Safety;Augmented reality;Smart phones;Cameras;Databases;Global Positioning System","augmented reality;Global Positioning System;Internet;mobile computing;smart phones","risky situation;Android users;women safety Android application;augmented reality;women safety app;particular street/place;Street smart;safe street app;Wikitude SDK","","6","","13","IEEE","25 Apr 2019","","","IEEE","IEEE Conferences"
"Mobile augmented reality system for Design Drawing visualization","Y. -J. Oh; K. -Y. Park; E. -K. Kim","Department of Computer Engineering, Sunchon National University, Sunchon-si, Jeollanam-do, Republic of Korea; Division of Culture Content, Chonnam National University, Yeosu-si, Jeollanam-do, Republic of Korea; Department of Computer Engineering, Sunchon National University, Sunchon-si, Jeollanam-do, Republic of Korea","16th International Conference on Advanced Communication Technology","27 Mar 2014","2014","","","1296","1300","This paper suggests 3D Model Visualization System of Design Drawing based on Mobile Augmented Reality which supports information needed in real environment, which is made with adding virtual 3D objects to the 2D drawing by applying technology of augmented reality. The proposed visual system makes those who don't have any specialized knowledge understand the drawing easily, because 3D model is augmented over the drawing through camera of smart phone was added without any marker. Recognition time of suggested 3D model visualization system is reduced roughly 4 to 33 % compared with the existing method by extracting and matching feature point only in ROI, and recognition rate shows improvement of 5 to 15% Performance testing on the Android phone of the proposed system shows display of video faster over 7 to 8 frame per second compared to the existing method.","1738-9445","978-89-968650-3-2","10.1109/ICACT.2014.6779169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6779169","Augmented Reality;Ship Design;Virtual Design;Design Visualization;Digital Shipbuilding","Three-dimensional displays;Solid modeling;Feature extraction;Mobile communication;Augmented reality;Visualization;Educational institutions","augmented reality;CAD;cameras;data visualisation;feature extraction;image matching;mobile computing;smart phones","mobile augmented reality system;design drawing visualization;3D model visualization system;virtual 3D objects;2D drawing;visual system;smart phone camera;feature point matching;feature point extraction;ROI;recognition rate;performance testing;Android phone","","3","","11","","27 Mar 2014","","","IEEE","IEEE Conferences"
"State of the Art and Current Perception of Augmented Reality in Honduras","M. E. Perdomo; M. Cardona; L. D. Romero; N. S. Barnica","Universidad Tecnológica Centroamericana (UNITEC), San Pedro Sula, Honduras; Universidad Don Bosco (UDB), El Salvador; Universidad Tecnológica Centroamericana (UNITEC), San Pedro Sula, Honduras; Universidad Tecnológica Centroamericana (UNITEC), San Pedro Sula, Honduras","2022 IEEE International Conference on Machine Learning and Applied Network Technologies (ICMLANT)","2 Jan 2023","2022","","","1","5","The research was conducted on Augmented Reality (AR), its concept, its precedents, the fields of application in which it is presented, and the advantages it has at the time this technology is implemented. It also analyzes the implementation of AR in the world in various sectors such as education, medicine, and industry. The applications of augmented reality in Honduras were identified. And the factors why Honduras has not implemented AR are analyzed. AR is a human-computer interface design strategy aimed at enhancing a user's visual perception by superimposing computer graphics on the user's view. AR has a series of devices, and software, among other elements that operate as development tools making the experience with this reality more attractive. In the fields of application four areas stand out: Education, Textile, Marketing, and Manufacturing. By evaluating the sectors and fields where AR is applied worldwide, a comparison and analysis are made to define which would be the best option to develop this technology in the best way in Honduras.","","978-1-6654-8701-6","10.1109/ICMLANT56191.2022.9996462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9996462","Augmented Reality (AR);Technology;Application;Industry;Honduras","Industries;Training;Software;Fourth Industrial Revolution;Statistics;Augmented reality;Textiles","augmented reality;user interfaces","augmented reality;computer graphics;education;Honduras;human-computer interface design strategy;manufacturing;marketing;textile;user visual perception","","","","25","IEEE","2 Jan 2023","","","IEEE","IEEE Conferences"
"Development of Augmented Reality Based Mobile Robot Maintenance Software","H. GENÇTÜRK; U. YAYAN","Ar-Ge Bölümü, İnovasyon Mühendislik Ltd. Şti., Eskişehir, TÜRKİYE; Ar-Ge Bölümü, İnovasyon Mühendislik Ltd. Şti., Eskişehir, TÜRKİYE","2019 Innovations in Intelligent Systems and Applications Conference (ASYU)","2 Jan 2020","2019","","","1","5","Augmented Reality (AR) helps to increase the perception of reality by adding digital data to the real world. Nowadays, AR is used effectively in many areas from entertainment sectors to health and education applications. In this study, a mobile application has been developed by using Augmented Reality technology for maintenance and repair of the mobile robot (evarobot). In this study, battery, motor, sensor and electronic card replacement scenarios of Evarobot and maintenance and repair steps were determined. These steps are supported with visuals in accordance with the instructions given and are intended to enable the user to carry out the maintenance process easily without the need for an expert or maintenance document. At the end of the study, the digitization of the experience and the transfer of the information without getting lost has been realized in an easy way.","","978-1-7281-2868-9","10.1109/ASYU48272.2019.8946359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946359","augmented reality;digitalization of experience maintenance;mobile robot;android","Maintenance engineering;Augmented reality;Robot sensing systems;Three-dimensional displays;Service robots;Mobile robots","Android (operating system);augmented reality;control engineering computing;maintenance engineering;mobile robots;robot programming;user experience","mobile robot maintenance software;digital data;mobile application;Augmented Reality technology;evarobot;electronic card replacement scenarios;maintenance process;digitization of experience;Android","","","","31","IEEE","2 Jan 2020","","","IEEE","IEEE Conferences"
"Principles for Applying Augmented Reality in Manufacturing","A. Rohrer; R. Hendrix","Human Centered Design and Engineering Department, University of Washington, Seattle, USA; Mechanical Engineering Department, University of Washington, Seattle, USA","2018 IEEE MIT Undergraduate Research Technology Conference (URTC)","4 Nov 2020","2018","","","1","4","Augmented Reality, the superimposition of digital features into the real world environment, has already made great strides in fields such as entertainment and advertising. However, the use of compound technology that bridges reality and the digital world has yet to be implemented cogently and thoroughly into the manufacturing field. This paper proposes a set of four principles for designing Augmented Reality implementations in manufacturing developed from a review of prior work in the area and related fields.","","978-1-5386-9374-2","10.1109/URTC45901.2018.9244801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244801","augmented reality;manufacturing;interface design;human-computer interaction;graphics","Bridges;Conferences;Entertainment industry;Hardware;Manufacturing;Compounds;Augmented reality","augmented reality;production engineering computing","superimposition;digital features;real-world environment;entertainment;compound technology;digital world;manufacturing field;augmented reality implementations","","","","12","IEEE","4 Nov 2020","","","IEEE","IEEE Conferences"
"Plane-dominant object reconstruction for robotic spatial augmented reality","Changwoo Nam; Min-Hyuk Sung; J. -H. Lee; J. Kim","School of Computer Science, Kookmin University, Seoul, South Korea; School of Computer Science, Kookmin University, Seoul, South Korea; Imaging Media Research Center, KIST, Seoul, South Korea; Department of Robot & Cognitive Systems, Electronics and Telecommunications Research Institute, Daejeon, South Korea","2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","6 Feb 2012","2011","","","627","630","We present a simple reconstruction algorithm of a plane-dominant 3D environment for the robotic spatial augmented reality (RSAR). In spatial augmented reality, a projector renders virtual objects onto 3D objects in the real space. To watch the augmented virtual objects from a viewpoint without distortions, the final image should be pre-distorted based on the geometry information of the 3D objects in the real world. In our RSAR setting, we assume that a robot is equipped with the devices such as a projector, low-cost depth cameras, and the sensor of capturing 3D position of the viewpoint. The robot captures the 3D environment with as a point cloud and reconstructs the geometry of 3D objects in the real world with a set of planes. In order that the viewer can see the distortion-free virtual objects, we compute the pre-warped images of virtual objects for a projector. Finally, we provide an efficient algorithm using GPU shaders to compute the pre-warped images for a projector. In experiments, we provide some results of preliminary simulations for our RSAR scenario.","","978-1-4577-0723-0","10.1109/URAI.2011.6145896","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6145896","Robotic spatial augmented reality;Plane-dominant surface reconstruction;Projective texture","Three dimensional displays;Image reconstruction;Cameras;Augmented reality;Robot vision systems","augmented reality;cameras;computational geometry;image reconstruction;optical projectors;rendering (computer graphics);robot vision","plane-dominant object reconstruction;robotic spatial augmented reality;plane-dominant 3D environment;virtual object rendering;low-cost depth cameras;3D position capturing sensor;distortion-free virtual objects;GPU shaders;prewarped images","","","","15","IEEE","6 Feb 2012","","","IEEE","IEEE Conferences"
"Augmented reality for ndimensional building information modelling : Contextualization, Customization and Curation","X. S. Lee; M. F. Khamidi; Z. S. See; T. J. Lees; C. Chai","School of Built Environment University of Reading Malaysia Educity, Iskandar Puteri, Johor, Malaysia; School of Built Environment University of Reading Malaysia Educity, Iskandar Puteri, Johor, Malaysia; Centre for Research-Creation, Digital Media Sunway University Bandar Sunway, Selangor, Malaysia; School of Construction Management and Engineering, University of Reading Whiteknights, Reading Berkshire, United Kingdom; Department of Structure and Materials, Universiti Teknologi Malaysia, Johor, Malaysia","2016 22nd International Conference on Virtual System & Multimedia (VSMM)","28 Feb 2017","2016","","","1","5","This paper presents an experimental method and apparatus of augmented reality (AR) for nDimensional (nD) building information modeling (BIM). BIM allows nD information to be visualized simultaneously by architects, engineers and constructors to gain a synchronized understanding viewing from different perspectives. However, BIM is conventionally being operated on a desktop-based computer which makes collaboration less flexible, and it also creates an isolation gap between the model and reality. This isolation gap does not severely affect experienced and skilled professionals, as they can bridge the isolation gap with their intuition developed over the years. Nevertheless, users who are lack of such experience will feel the isolation gap between the digital realm and practicable reality, which could be the hurdle in project participation and decision making. AR allows virtual content to be mixed with real environment for user experience. In the context of our study, AR is functional to present the nD information of BIM, at the same time retaining users' connection with the reality. It is not just being utilized solely for presentation, but also to maximize the potential for communication, interaction and experience. This pilot study investigates effective technological approach of using AR as an effective collaboration technology combining with BIM through proposed key aspects of contextualization, customization and curation. Contextualization is significant to enable users to understand the AR content by making the presented information meaningful to the target audience, implemented thru the means of 2D annotations, animations and options comparison. This study compares both AR BIM with and without contextualization. Customization can generate unique virtual environment and content for different level of users tailored to their needs and preference to create intuitive interaction with AR BIM. Curation is crucial to provide users with a reliable experience, and to formulate a continually improving AR BIM thru log data and users' feedback. All in all, this paper explores the major aspects of contextualization, customization and curation, to distinguish effective approach in the currently “free for all” AR BIM development. Finally, an implication is provided for future study in terms of balance in information sufficiency and complexity for AR BIM.","2474-1485","978-1-4673-8993-8","10.1109/VSMM.2016.7863152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7863152","augmented reality;building information modelling;contextualization;customization;curation","Solid modeling;Geometry;Augmented reality;Buildings;Context modeling;Visualization;Interviews","architecture;augmented reality;buildings (structures);civil engineering computing;computer animation;data visualisation;human computer interaction","augmented reality;n-dimensional building information modelling;contextualization;customization;curation;information visualization;architects;engineers;constructors;desktop-based computer;isolation gap;project participation;decision making;user experience;collaboration technology;meaningful information;2D annotation;animation;option comparison;virtual environment;virtual content;intuitive interaction;AR BIM;information sufficiency","","","","23","IEEE","28 Feb 2017","","","IEEE","IEEE Conferences"
"AR360: Dynamic Illumination for Augmented Reality with Real-Time Interaction","A. Alhakamy; M. Tuceryan","Computer and Information Science Department., Indiana University - Purdue University (IUPUI), Indianapolis, USA; Computer and Information Science Department, Indiana University - Purdue University (IUPUI), Indianapolis, USA","2019 IEEE 2nd International Conference on Information and Computer Technologies (ICICT)","13 May 2019","2019","","","170","174","Current augmented and mixed reality systems suffer a lack of correct illumination modeling where the virtual objects render the same lighting condition as the real environment. While we are experiencing astonishing results from the entertainment industry in multiple media forms, the procedure is mostly accomplished offline. The illumination information extracted from the physical scene is used to interactively render the virtual objects which results in a more realistic output in real-time. In this paper, we present a method that detects the physical illumination with dynamic scene, then uses the extracted illumination to render the virtual objects added to the scene. The method has three steps that are assumed to be working concurrently in real-time. The first is the estimation of the direct illumination (incident light) from the physical scene using computer vision techniques through a 360° live-feed camera connected to AR device. The second is the simulation of indirect illumination (reflected light) from the real-world surfaces to virtual objects rendering using region capture of 2D texture from the AR camera view. The third is defining the virtual objects with proper lighting and shadowing characteristics using shader language through multiple passes. Finally, we tested our work with multiple lighting conditions to evaluate the accuracy of results based on the shadow falling from the virtual objects which should be consistent with the shadow falling from the real objects with a reduced performance cost.","","978-1-7281-3323-2","10.1109/INFOCT.2019.8710982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710982","illumination;augmented reality;image-based lighting;incident light;reflected light","Lighting;Cameras;Rendering (computer graphics);Real-time systems;Light sources;Augmented reality;Estimation","augmented reality;cameras;computer vision;image texture;lighting;rendering (computer graphics)","virtual objects;direct illumination;physical scene;dynamic illumination;mixed reality systems;illumination information;physical illumination;dynamic scene;extracted illumination;lighting conditions;augmented reality systems;illumination modeling","","5","","11","IEEE","13 May 2019","","","IEEE","IEEE Conferences"
"Smart Augmented Reality Self-Guiding Application for Museum Visitors of Different Age Groups","C. -Y. Zhou; N. -C. Tai","Department of Interaction Design, National Taipei University of Technology, Taipei, Taiwan; Department of Interaction Design, National Taipei University of Technology, Taipei, Taiwan","2022 IEEE 11th Global Conference on Consumer Electronics (GCCE)","18 Jan 2023","2022","","","629","630","At present, museums are attempting to create interactive augmented reality (AR) contents for different target audiences to enhance the self-guided visiting experience. Such AR applications often focus on one group at a time to ensure proper content. However, in many cases, young children share a device with their adult family members, which makes the switching of the AR content a deciding factor for an enjoyable shared AR self-guided tour. This study presents a working prototype that uses a gyroscope to detect the user’s height and automatically switch the AR content to that suitable for the user’s knowledge level. The field test exhibits promising results, suggesting that the implementation of natural user interface in AR applications can ensure a smooth shared self-guided tour.","2378-8143","978-1-6654-9232-4","10.1109/GCCE56475.2022.10014144","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10014144","museum;self-guided tour;augmented reality;mobile learning;natural user interface","Prototypes;Switches;User interfaces;Museums;Gyroscopes;Augmented reality;Consumer electronics","augmented reality;museums;user interfaces","adult family members;AR applications;AR content;deciding factor;different target audiences;enjoyable shared AR self-guided tour;interactive augmented reality contents;museum visitors;museums;natural user interface;proper content;reality self-guiding application;smooth shared self-guided tour;working prototype;young children share","","","","9","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"Degraded Reality: Using VR/AR to simulate visual impairments","P. R. Jones; G. Ometto","UCL Institute of Ophthalmology; City, University of London","2018 IEEE Workshop on Augmented and Virtual Realities for Good (VAR4Good)","16 Dec 2018","2018","","","1","4","The effects of eye disease cannot be depicted accurately using traditional media. Consequently, public understanding of eye disease is often poor. We present a VR/AR system for simulating common visual impairments, including disability glare, spatial distortions (Metamorphopsia), the selective blurring and filling-in of information across the visual field, and color vision deficits. Unlike most existing simulators, the simulations are informed by patients' self-reported symptoms, can be quantitatively manipulated to provide custom disease profiles, and support gaze-contingent presentation (i.e., when using a VR/AR headset that contains eye-tracking technology, such as the Fove0). Such a simulator could be used as a teaching/empathy aid, or as a tool for evaluating the accessibility of new products and environments.","","978-1-5386-5977-9","10.1109/VAR4GOOD.2018.8576885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576885","Computing methodologies—Graphics systems and interfaces—Mixed / augmented reality;Computing methodologies— Computer graphics—Image manipulation—Image processing;Modeling and simulation—Simulation types and techniques—Real-time simulation","Visualization;Kernel;Image color analysis;Diseases;Distortion;Augmented reality;Retina","augmented reality;digital simulation;diseases;eye;handicapped aids;vision defects;visual perception","custom disease profiles;gaze-contingent presentation;eye-tracking technology;degraded reality;eye disease;traditional media;public understanding;simulating common visual impairments;disability glare;spatial distortions;selective blurring;visual field;color vision deficits;existing simulators;VR-AR system;VR-AR headset","","10","","11","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"[Poster] A Mobile Augmented reality system to assist auto mechanics","D. Stanimirovic; N. Damasky; S. Webel; D. Koriath; A. Spillner; D. Kurz",Metaio GmbH; Metaio GmbH; Metaio GmbH; Volkswagen AG; Volkswagen AG; Metaio GmbH,"2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","305","306","Ground-breaking technologies and innovative design of upcoming vehicles introduce complex maintenance procedures for auto mechanics. In order to present these procedures in an intuitive manner, the Mobile Augmented Reality Technical Assistance (MARTA) project was initiated. The goal was to create an Augmented Reality-aided application running on a tablet computer, which shows maintenance instructions superimposed on a live video feed of the car. Robust image-based tracking of specular surfaces using both edge and texture features as well as the software framework are the most important aspects of the project, which are presented here. The resulting application is deployed and used productively to support maintenance of the Volkswagen XL1 vehicle across the world.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948462","","Maintenance engineering;Solid modeling;Three-dimensional displays;Tablet computers;Image edge detection;Cameras;Computational modeling","augmented reality;automobile industry;feature extraction;image texture;maintenance engineering;mobile computing;object tracking;production engineering computing","mobile augmented reality system;auto mechanics;MARTA;mobile augmented reality technical assistance;augmented reality-aided application;tablet computer;maintenance instructions;robust image-based tracking;specular surface tracking;edge feature;texture feature;Volkswagen XL1 vehicle","","13","2","8","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"A Comparative Analysis of Augmented Reality Frameworks Aimed at Diverse Computing Applications","M. A. Maneli; O. E. Isafiade","Department of Computer Science, Faculty of Natural Science, University of the Western Cape, South Africa; Department of Computer Science, Faculty of Natural Science, University of the Western Cape, South Africa","2022 ITU Kaleidoscope- Extended reality – How to boost quality of experience and interoperability","2 Jan 2023","2022","","","1","8","Immersive systems such as Augmented Reality (AR) and Virtual Reality (VR) have proven useful in diverse computing domains. However, there is little effort on accuracy measurements within AR applications, which could greatly impact outcomes and decisions in certain domains, such as crime scene investigations, among others. This paper aims to analyze and evaluate two existing prominent AR frameworks, ARCore and ARKit, which support the development of diverse mobile computing applications for immersive systems. This research developed prototype applications and conducted comparison tests of measurement accuracy within the applications. The accuracy was tested using four distance criteria across six different devices, spanning ARCore and ARKit frameworks. A control experiment was used to benchmark the measurement accuracy. Relatively, an instance of the experiment presented ARCore as reliable. Overall, ARKit proved to be more accurate between the two frameworks, with an average accuracy of 99.36% as opposed to 89.42% scored by ARCore. The obtained results can give insight on the choice of framework to consider during AR application development for a specific domain, hence boosting quality of experience.","","978-92-61-36151-8","10.23919/ITUK56368.2022.10003046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10003046","ARCore;ARKit;AR measurements;augmented reality;crime scene investigation","Extended reality;Prototypes;Benchmark testing;Boosting;ITU;Quality of experience;Reliability","augmented reality;mobile computing","AR application development;AR applications;ARCore;ARKit frameworks;augmented reality frameworks;comparative analysis;crime scene investigations;diverse computing applications;diverse computing domains;diverse mobile computing applications;immersive systems;measurement accuracy;prototype applications;spanning ARCore","","1","","19","","2 Jan 2023","","","IEEE","IEEE Conferences"
"Meta-Analysis of Learning Strategies in Teaching Using: Augmented Reality Technology","S. Yadav; Z. Aalam","Computer Science and Engineering, SGT University, Gurugram; Computer Science and Engineering, SGT University, Gurugram","2021 4th International Conference on Recent Developments in Control, Automation & Power Engineering (RDCAPE)","10 Dec 2021","2021","","","224","229","With the arrival of the Fourth Industrial Revolution, the learning environment is rapidly changing. Augmented Reality is a popular educational technology. It has benefitted Education a lot, be it inside the classroom or outside, interactive experiences have been promoted. Users can communicate with unreal things which are merged in the actual world and be visible in similar place that too in actual environment utilizing Augmented Reality technology. This meta-analysis aims to find out the several forms of learning methodologies that have been used, based on Augmented Reality. The technique of research is dependent onto doing a thorough and detailed literature hunt on these databases available online such as IEEE, Scopus, Google Scholar, Directory of Open Access Journals (DOAJ) and Springer, as well as in the print journals. Learning based on Games, Learning based on Interaction, Learning based on Cooperation and solving the problems are the most common Augmented Reality tactics in education, according to the findings of this meta-analysis. Such findings will give educators information on Augmented Reality-based learning techniques and their educational potential, leading to more research on how Augmented Reality-based learning methods can be effectively utilized in learning and teaching.","","978-1-6654-1429-6","10.1109/RDCAPE52977.2021.9633600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633600","Augmented reality;learning strategies;technology in education;learning tactics;augmented reality in education","Learning systems;Power engineering;Open Access;Collaboration;Games;Production;Internet","augmented reality;computer aided instruction;educational technology;electronic publishing;learning (artificial intelligence);teaching;virtual reality","meta-analysis;teaching;Augmented Reality technology;Fourth Industrial Revolution;learning environment;popular educational technology;actual world;actual environment;common Augmented Reality tactics;educators information;educational potential;Augmented Reality-based learning methods","","","","42","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"Learning a Foreign Language in a Mixed-Reality Environment","M. Ibanez; C. Delgado Kloos; D. Leony; J. J. Garcia Rueda; D. Maroto","Universidad Carlos III de Madrid, Spain; Universidad Carlos III de Madrid, Spain; Universidad Carlos III de Madrid, Spain; Universidad Carlos III de Madrid, Spain; Universidad Carlos III de Madrid, Spain","IEEE Internet Computing","31 Oct 2011","2011","15","6","44","47","This article describes a mixed-reality experience for learning Spanish as a foreign language, which takes place in a virtual world that mirrors a boulevard in Madrid. To this end, the authors have extended the capabilities of an open source multiuser 3D virtual world platform to orchestrate learning activities and use augmented reality and augmented virtuality. The results of their evaluation show positive effects on student motivation and improvement in learning outcomes.","1941-0131","","10.1109/MIC.2011.78","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5892930","artificial reality;augmented reality;virtual reality;virtual worlds;computer-supported cooperative work","Decision support systems;Natural language processing;Virtual environments;Augmented reality;Learning systems;Virtual reality","augmented reality;computer aided instruction;human computer interaction;natural language processing","foreign language learning;mixed-reality environment;Spanish;open source multiuser 3D virtual world platform;Madrid;augmented reality;augmented virtuality","","29","","6","IEEE","16 Jun 2011","","","IEEE","IEEE Magazines"
"Reconstruction and Accurate Alignment of Feature Maps for Augmented Reality","F. Wientapper; H. Wuest; A. Kuijper","Department for Virtual and Augmented Reality, Fraunhofer IGD, Darmstadt, Germany; Department for Virtual and Augmented Reality, Fraunhofer IGD, Darmstadt, Germany; Department for Virtual and Augmented Reality, Fraunhofer IGD, Darmstadt, Germany","2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission","18 Jul 2011","2011","","","140","147","This paper focuses on the preparative process of retrieving accurate feature maps for a camera-based tracking system. With this system it is possible to create ready-to use Augmented Reality applications with a very easy setup work-flow, which in practice only involves three steps: filming the object or environment from various viewpoints, defining a transformation between the reconstructed map and the target coordinate frame based on a small number of 3D-3D correspondences and, finally, initiating a feature learning and Bundle Adjustment step. Technically, the solution comprises several sub-algorithms. Given the image sequence provided by the user, a feature map is initially reconstructed and incrementally extended using a Simultaneous-Localization-and-Mapping (SLAM) approach. For the automatic initialization of the SLAM module, a method for detecting the amount of translation is proposed. Since the initially reconstructed map is defined in an arbitrary coordinate system, we present a method for optimally aligning the feature map to the target coordinated frame of the augmentation models based on 3D-3D correspondences defined by the user. As an initial estimate we solve for a rigid transformation with scaling, known as Absolute Orientation. For refinement of the alignment we present a modification of the well-known Bundle Adjustment, where we include these 3D-3D-correspondences as constraints. Compared to ordinary Bundle Adjustment we show that this leads to significantly more accurate reconstructions, since map deformations due to systematic errors such as small camera calibration errors or outliers are well compensated. This again results in a better alignment of the augmentations during run-time of the application, even in large-scale environments.","1550-6185","978-1-61284-429-9","10.1109/3DIMPVT.2011.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5955354","Augmented Reality;Reconstruction;Structure- From-Motion (SfM);SfM-Initialization;Simultaneous Localization;Mapping (SLAM);Feature-Map Alignment;Constrained Bundle Adjustment;(Monocular) Camera Tracking","Image reconstruction;Cameras;Three dimensional displays;Augmented reality;Simultaneous localization and mapping;Solid modeling;Buildings","augmented reality;cameras;object tracking","augmented reality;feature map alignment;feature map reconstruction;camera based tracking system;bundle adjustment step;simultaneous-localization-and-mapping approach;augmentation models;3D-3D correspondences;absolute orientation","","13","1","21","IEEE","18 Jul 2011","","","IEEE","IEEE Conferences"
"Doctoral Colloquium—A Snapshot of the Future: Virtual and Augmented Reality Training for Radiology","X. Xu; E. Mangina; D. Kilroy; K. M. Curran; J. J. Healy; A. G. Campbell","University College, Dublin, Ireland; University College, Dublin, Ireland; University College, Dublin, Ireland; University College, Dublin, Ireland; University College, Dublin, Ireland; University College, Dublin, Ireland","2020 6th International Conference of the Immersive Learning Research Network (iLRN)","4 Aug 2020","2020","","","407","410","Advances in virtual immersive and augmented reality technology, commercially available for the entertainment and gaming industry, hold potential for education and clinical use in medicine and the field of radiology. Radiology departments have begun exploring the use of these technologies to help with radiology education and training. The purpose of this article is to address how skills have been developed in the gaming world and how these can be adopted for radiology education. Radiology is rapidly evolving with the use of AI for more effective diagnostic and prognostic clinical assessment. Advances in computing technology have enabled widespread availability of simulated reality technologies, including virtual reality (VR) and augmented reality (AR). This work in progress paper describes VR and AR technologies as novel means to communicate and have potential for supplementing radiology training; communicating with colleagues, referring clinicians, and patients; and aiding in interventional radiology procedures.","","978-1-7348995-0-4","10.23919/iLRN47897.2020.9155131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155131","virtual reality;augmented reality;holoLens;oculus quest;radiology training","Radiology;Virtual reality;Biomedical imaging;Training;Solid modeling;Surgery","augmented reality;biomedical education;computer based training;computer games;medical computing;radiology","doctoral colloquium;augmented reality training;virtual immersive reality technology;augmented reality technology;entertainment;gaming industry;clinical use;radiology departments;radiology education;gaming world;effective diagnostic assessment;prognostic clinical assessment;computing technology;simulated reality technologies;radiology training;interventional radiology procedures;AR technologies;VR technologies","","3","","17","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Poster: ARLIST - an Augmented Reality Environment for Life Support Training","F. Pretto; I. H. Manssour; E. R. da Silva; M. H. I. Lopes; M. S. Pinho","FACIN-PUCRS, Brazil; FACIN-PUCRS, Brazil; HSL-PUCRS, Brazil; FAMED-PUCRS, Brazil; FACIN-PUCRS, Brazil","2008 IEEE Symposium on 3D User Interfaces","31 Mar 2008","2008","","","139","140","The main goal of the ARLIST project is to qualify the traditional training environment currently used for Life Support training, introducing image and sound resources into the training manikins. Using these tools we can simulate some aspects such as facial expressions, skin color changes and scratches and skin injuries through image projection over the manikin body, and also play sounds like cries of pain or groans of an injured man.","","978-1-4244-2047-6","10.1109/3DUI.2008.4476606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4476606","Medical Education;Augmented Reality;Emergency Training;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;Augmented;and Virtual Realities;I.3.6 [Computer Graphics]: Methodology and Techniques-Interaction Techniques","Augmented reality;Skin;Injuries;Pain;Management training;Medical simulation;Computational modeling;Biomedical imaging;Computer science education;State feedback","augmented reality;biomedical education;computer aided instruction;medical image processing;training","augmented reality environment for life support training;ARLIST;manikin training;image projection","","","","3","IEEE","31 Mar 2008","","","IEEE","IEEE Conferences"
"War Children: Using AR in a Documentary Context","C. Zimmer; N. Ratz; M. Bertram; C. Geiger",Hochschule Duesseldorf; Hochschule Duesseldorf; Hochschule Duesseldorf; Hochschule Duesseldorf,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","390","394","The goal of the project “War Children” is to tell stories of survivors of the Second World War by means of augmented reality. We want to make memories persistent, accessible and comprehensible to users that do not yet have access to these memories, e.g., digital natives. The application of immersive technologies provides us with new ways to tell stories about the past in an empathic way by augmenting the narration with audio-visual assets. In order to provide an immersive reference to the story, the user can visually place a contemporary witness in his environment using a mobile device. As a result, the user can listen to the respective witness sitting in front of him / her and beginning to describe their wartime experiences as a child. During the narration, the user's real environment is augmented by AR content that illustrates the narration. The project was developed as the result of an iterative design process for WDR, a German public broadcasting institution. An initial prototype was presented at the re:publica 2018 festival to the public and tested by more than 500 people. 160 of them were interviewed and provided feedback about their experience.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699203","Augmented Reality—AR Documentation—Documentary Context;—Mixed Reality—Human-centered storytelling","Cameras;Three-dimensional displays;Image color analysis;Visualization;Augmented reality;Calibration;Production","augmented reality;history;mobile computing;multimedia computing","War Children;documentary context;augmented reality;memories;digital natives;immersive technologies;narration;audio-visual assets;immersive reference;contemporary witness;mobile device;Second World War survivors;wartime experiences;AR content;iterative design process;German public broadcasting institution","","5","","5","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Towards object based manipulation in remote guidance","D. Ranatunga; D. Feng; M. Adcock; B. Thomas","CSIRO, Australian National University, Canberra, Australia; CSIRO, Australian National University, Canberra, Australia; CSIRO, University of South Australia, Canberra, Australia; University of South Australia, Mawson Lakes, Australia","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","1","6","This paper presents a method for using object based manipulation and spatial augmented reality for the purpose of remote guidance. Previous remote guidance methods have typically not made use of any semantic information about the physical properties of the environment and require the helper and worker to provide context. Our new prototype system introduces a level of abstraction to the remote expert, allowing them to directly specify the object movements required of a local worker. We use 3D tracking to create a hidden virtual reality scene, mirroring the real world, with which the remote expert interacts while viewing a camera feed of the physical workspace. The intended manipulations are then rendered to the local worker using Spatial Augmented Reality (SAR). We report on the implementation of a functional prototype that demonstrates an instance of this approach. We anticipate that techniques such as the one we present will allow more efficient collaborative remote guidance in a range of physical tasks.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671839","Spatially Augmented Reality;Remote Guidance;Object Manipulation;Multi touch interaction;3D CHI","Cameras;Feeds;Three-dimensional displays;Visualization;Australia;Augmented reality;Prototypes","augmented reality;hidden feature removal;human computer interaction","object based manipulation;spatial augmented reality;semantic information;physical property;prototype system;remote expert;3D tracking;hidden virtual reality scene;camera feed;physical workspace;SAR;collaborative remote guidance","","7","","14","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Multiple 3D Object tracking for augmented reality","Y. Park; V. Lepetit; Woontack Woo","U-VR Laboratory, GIST; CVLaboratory, EPF Lausanne, Switzerland; U-VR Laboratory, GIST","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","117","120","We present a method that is able to track several 3D objects simultaneously, robustly, and accurately in real-time. While many applications need to consider more than one object in practice, the existing methods for single object tracking do not scale well with the number of objects, and a proper way to deal with several objects is required. Our method combines object detection and tracking: Frame-to-frame tracking is less computationally demanding but is prone to fail, while detection is more robust but slower. We show how to combine them to take the advantages of the two approaches, and demonstrate our method on several real sequences.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637336","Augmented Reality;Computer Vision;Tracking","Three dimensional displays;Robustness;Feature extraction;Tracking;Target tracking;Solid modeling;Object detection","augmented reality;computer vision;object detection;tracking","multiple 3D object tracking;augmented reality;object detection;frame-to-frame tracking;computer vision","","75","2","12","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"[POSTER] Augmented Reality for Radiation Awareness","N. Leucht; S. Habert; P. Wucherer; S. Weidert; N. Navab; P. Fallavollita","Technische Universität, München, Germany; Technische Universität, München, Germany; Technische Universität, München, Germany; Klinikum der Universität, München, Germany; Johns Hopkins University, USA; Technische Universität, München, Germany","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","60","63","C-arm fluoroscopes are frequently used during surgeries for intraoperative guidance. Unfortunately, due to X-ray emission and scattering, increased radiation exposure occurs in the operating theatre. The objective of this work is to sensitize the surgeon to their radiation exposure, enable them to check on their exposure over time, and to help them choose their best position related to the C-arm gantry during surgery. First, we aim at simulating the amount of radiation that reaches the surgeon using the Geant4 software, a toolkit developed by CERN. Using a flexible setup in which two RGB-D cameras are mounted to the mobile C-arm, the scene is captured and modeled respectively. After the simulation of particles with specific energies, the dose at the surgeon's position, determined by the depth cameras, can be measured. The validation was performed by comparing the simulation results to both theoretical values from the C-arms user manual and real measurements made with a QUART didoSVM dosimeter. The average error was 16.46% and 16.39%, respectively. The proposed flexible setup and high simulation precision without a calibration with measured dosimeter values, has great potential to be directly used and integrated intraoperatively for dose measurement.","","978-1-4673-7660-0","10.1109/ISMAR.2015.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328061","radiation exposure;dose measurement;C-arm fluoroscopy;augmented reality;visualization","Surgery;Cameras;X-ray imaging;Photonics;Manuals;Computational modeling;Calibration","augmented reality;diagnostic radiography;medical computing;surgery","augmented reality;radiation awareness;C-arm fluoroscopes;intraoperative surgery guidance;radiation exposure;C-arm gantry;Geant4 software;RGB-D camera;red-green-blue-depth camera;QUART didoSVM dosimeter;dose measurement","","2","","16","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Integrating augmented reality to enhance expression, interaction & collaboration in live performances: A ballet dance case study","A. Clay; G. Domenger; J. Conan; A. Domenger; N. Couture","ESTIA, Bidart, France; CCN Malandain Ballet Biarritz, Biarritz, France; ESTIA, Bidart, France; CCN Malandain Ballet Biarritz, France; LaBRI, UMR, Talence, France","2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design (ISMAR-MASH'D)","27 Oct 2014","2014","","","21","29","The democratization of high-end, affordable and off-the-shelf sensors and displays triggered an explosion in the exploration of interaction and projection in arts. Although mostly witnessed in interactive artistic installations (e.g. museums and exhibitions), performing arts also explore such technologies, using interaction and augmented reality as part of the performance. Such works often emerge from collaborations between artists and scientists. Despite being antonymic in appearance, we advocate that both fields can greatly benefit from this type of collaboration.","2381-8360","978-1-4799-6887-9","10.1109/ISMAR-AMH.2014.6935434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935434","augmented performance;movement interaction;dance;augmented reality","Three-dimensional displays;Augmented reality;Avatars;Art;Visualization;Collaboration","art;augmented reality;human computer interaction;image motion analysis;stereo image processing","expression;live performances;ballet dance;interactive artistic installations;museums;exhibitions;performing arts;ballet performance;dancer movements;high-end motion capture;projection systems;virtual elements;augmented stage;augmented reality engineer;augmented reality systems design;aesthetic message;choreographic message;light technicians;sound technicians;Debussy3.0;augmented ballet;La Mer;Claude Debussy;body interactions;backstage interactions;3D stereoscopy;display technique;Biarritz Casino;arts-science collaboration;stereoscopy techniques;live show","","7","","20","IEEE","27 Oct 2014","","","IEEE","IEEE Conferences"
"Anywhere Interfaces Using Handheld Augmented Reality","M. Gervautz; D. Schmalstieg","Qualcomm Research, Vienna, Austria; Graz University of Technology, Austria","Computer","29 Jun 2012","2012","45","7","26","31","An investigation of the technology and human factors that drive augmented reality research describes recent developments in handheld AR, concentrating on localization, tracking, interaction, and visualization, and offers several examples illustrating the vast potential and important applications of AR. A related video can be seen here: http://youtu.be/ol371rIyUFY. It shows several real-world examples illustrating the vast potential and important applications of augmented reality.","1558-0814","","10.1109/MC.2012.72","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155710","augmented reality;embodied interaction;localization;tangible interaction tracking","Augmented reality;Mobile handsets;Sensors;Cameras;Visualization;Navigation;Games;Human factors","augmented reality;data visualisation;human factors;tracking;user interfaces","anywhere interfaces;handheld augmented reality;human factors;localization;tracking;interaction;visualization","","60","15","11","IEEE","21 Feb 2012","","","IEEE","IEEE Magazines"
"An Augmented Reality System for Learning the Interior of the Human Body","C. Juan; F. Beatrice; J. Cano","UPV, DSIC, Spain; UPV, DSIC, Spain; UPV, Escola d''Estiu, Spain","2008 Eighth IEEE International Conference on Advanced Learning Technologies","15 Jul 2008","2008","","","186","188","Augmented Reality has been used for developing systems with learning purposes. In this paper, we present an Augmented Reality system for learning the interior of the human body. We have tested the system with children of the Summer School of the Technical University of Valencia. In this test we have analysed if the use of a Head-Mounted Display or a typical monitor influence in the experience of the children. Results do not offer statistical significant differences using both visualization systems and confirm that children enjoyed learning with the system and consider it as useful tool not only for learning the interior of the human body but also for learning other subjects.","2161-377X","978-0-7695-3167-0","10.1109/ICALT.2008.121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4561662","Augmented Reality;tangible interfaces;human body","Augmented reality;Humans;Cameras;Firewire;Application software;Books;Intestines;Stomach;Abdomen;System testing","augmented reality;biomedical education;computer aided instruction;computer displays;data visualisation;helmet mounted displays;human factors;medical computing","augmented reality system;human body interior learning system;head-mounted display;visualization system;children learning tool;computer monitor","","44","","5","IEEE","15 Jul 2008","","","IEEE","IEEE Conferences"
"Augmented reality with tangible auto-fabricated models for molecular biology applications","A. Gillet; M. Sanner; D. Stoffler; D. Goodsell; A. Olson","Scripps Research Institute, USA; Scripps Research Institute, USA; Scripps Research Institute, USA; Scripps Research Institute, USA; Scripps Research Institute, USA","IEEE Visualization 2004","28 Feb 2005","2004","","","235","241","The evolving technology of computer auto-fabrication (""3D printing"") now makes it possible to produce physical models for complex biological molecules and assemblies. We report on an application that demonstrates the use of auto-fabricated tangible models and augmented reality for research and education in molecular biology, and for enhancing the scientific environment for collaboration and exploration. We have adapted an augmented reality system to allow virtual 3D representations (generated by the Python Molecular Viewer) to be overlaid onto a tangible molecular model. Users can easily change the overlaid information, switching between different representations of the molecule, displays of molecular properties such as electrostatics, or dynamic information. The physical model provides a powerful, intuitive interface for manipulating the computer models, streamlining the interface between human intent, the physical model, and the computational activity.","","0-7803-8788-0","10.1109/VISUAL.2004.7","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1372202","Molecular Modeling;Molecular Visualization;Augmented Reality","Augmented reality;Biological system modeling;Computational biology;Physics computing;Application software;Power system modeling;Computer interfaces;Biology computing;Printing;Assembly","augmented reality;molecular biophysics;data visualisation;user interfaces;biology computing;genetics","auto-fabricated tangible model;augmented reality;molecular biology;virtual 3D representation;physical model;molecular visualization","","40","1","15","IEEE","28 Feb 2005","","","IEEE","IEEE Conferences"
"What Wearable Augmented Reality Can Do for You","B. H. Thomas; C. Sandor","Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia","IEEE Pervasive Computing","17 Apr 2009","2009","8","2","8","11","This paper focuses on the present and near-future possibilities and technologies for wearable augmented reality. The paper provides an overview of the concept of wearable augmented reality and describes a current state-of-the-art system Tinmith. A number of benefits are presented, such as in situ information presentation, hands-free operation, ability to multitask, and navigation aids. The following five major application domains are examined as a means of highlighting the effectiveness of this technology: consumer help, entertainment, manufacturing, medicine, and navigation. The article provides some insights into technological hurdles yet to be overcome.","1558-2590","","10.1109/MPRV.2009.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814931","Computer System Implementation: Wearable Computers;Information Interfaces and Representation (HCI): Artificial;augmented;and virtual realities","Augmented reality;Automobile manufacture;Pervasive computing;Shape;Multitasking;Image processing;Color;Navigation;Real time systems;Paints","augmented reality;wearable computers","wearable augmented reality;state-of-the-art system;Tinmith;information presentation;hands-free operation;navigation aids","","23","","6","IEEE","17 Apr 2009","","","IEEE","IEEE Magazines"
"A marker-based augmented reality system for mobile devices","A. Gherghina; A. -C. Olteanu; N. Tapus","Computer Science and Engineering Department, University Politehnica of Bucharest, Bucharest, Romania; Computer Science and Engineering Department, University Politehnica of Bucharest, Bucharest, Romania; Computer Science and Engineering Department, University Politehnica of Bucharest, Bucharest, Romania","2013 11th RoEduNet International Conference","2 May 2013","2013","","","1","6","Given the rate at which mobile devices are adopted by the general public, we are at a point where many of us own a smart phone. Currently, this makes them the most affordable interfaces for augmented reality. However, with respect to augmented reality, smartphones present some limitations: location tracking is, on a large scale, supported only for outdoor environments and the content types that can be displayed to the user are generally limited. We therefore propose a marker-based tracking system which detects QR-codes on the camera capture and overlays rich media obtained from a server. We further analyze the performance implications of such a system, by breaking down the processing into pipelined stages and providing a mechanism of skipping frames from the capture in order to give a fast on-screen response.","2068-1038","978-1-4673-6116-3","10.1109/RoEduNet.2013.6511731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6511731","augmented reality;surface detection;performance;smartphone","Videos;Cameras;Servers;Bar codes;Augmented reality;Animation;Smart phones","augmented reality;mobile computing;smart phones","marker-based augmented reality system;mobile device;smart phone;location tracking;outdoor environment;content type;marker-based tracking system;QR-code detection;camera capture;fast on-screen response","","19","","13","IEEE","2 May 2013","","","IEEE","IEEE Conferences"
"Augmented reality based indoor positioning navigation tool","L. C. Huey; P. Sebastian; M. Drieberg","Electrical and Electronic Engineering Department, Universiti Teknologi PETRONAS, Tronoh, Perak, Malaysia; Electrical and Electronic Engineering Department, Universiti Teknologi PETRONAS, Tronoh, Perak, Malaysia; Electrical and Electronic Engineering Department, Universiti Teknologi PETRONAS, Tronoh, Perak, Malaysia","2011 IEEE Conference on Open Systems","14 Nov 2011","2011","","","256","260","Indoor positioning has gained popularity recently due to its potential to be used in the increasing complexity of indoor environment. Unfortunately GPS signals are restricted to outdoor purposes. The main objective of this work is to design a new method to develop indoor positioning navigation system without using wireless technology through image processing. Apart from that, the work also aims to develop an interactive indoor navigation system. Augmented reality is being used to superimpose the directional signage on the real view of the indoor environment in 3D form. Along with the 3D guides, voice guidance will be output from the system to assist users in identifying their locations easily. Overall, the scope of study involves research on augmented reality, audio API, and other additional techniques that can improve the program in computing the route. The idea of this work can be broadly applied to mobile devices such as mobile phones and PDA as an added indoor navigation functionality without the use of GPS and wireless communication. The proposed system has been tested at the ground floor of the Information Resource Centre (IRC) in Universiti Teknologi PETRONAS and the results show the flexibility of the system in navigating 12 locations and ability to handle up to 30 possible routes.","","978-1-61284-931-7","10.1109/ICOS.2011.6079276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079276","augmented reality;video;positioning","Cameras;Three dimensional displays;Augmented reality;Accuracy;Rendering (computer graphics);Global Positioning System","augmented reality;Global Positioning System;image processing","augmented reality;indoor positioning navigation tool;GPS signals;wireless technology;image processing;interactive indoor navigation system;audio API;information resource centre;IRC","","19","","9","IEEE","14 Nov 2011","","","IEEE","IEEE Conferences"
"AREEF Multi-player Underwater Augmented Reality experience","L. Oppermann; L. Blum; Jun-Yeong Lee; Jung-Hyub Seo","Fraunhofer FIT, Schloss Birlinghoven, Sankt Augustin, Germany; Fraunhofer FIT, Schloss Birlinghoven, Sankt Augustin, Germany; UD4M, Gangnam, Seoul, Korea; UD4M, Gangnam, Seoul, Korea","2013 IEEE International Games Innovation Conference (IGIC)","11 Nov 2013","2013","","","199","202","This paper reports on AREEF, the world's first multi-player Under Water Augmented Reality (UWAR) experience. The underlying mission of this work was to bring computer games and entertainment applications from traditional settings into the water using Augmented Reality (AR) technology. We provide an application overview and present findings from our participatory design process that involved engineers and designers, as wells as end-users and water-park experts. The paper closes with a brief discussion of technical aspects that relate to Wi-Fi communication and computer vision tracking, and provides an outlook for future work.","2166-675X","978-1-4799-1245-2","10.1109/IGIC.2013.6659137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6659137","games;multi-player;under water;tablet;augmented reality;system;design","Games;Augmented reality;Marine animals;Base stations;IEEE 802.11 Standards;Prototypes;Visualization","augmented reality;computer games;computer vision;entertainment;wireless LAN","AREEF framework;multiplayer underwater augmented reality experience;multiplayer UWAR experience;computer games;entertainment applications;Wi-Fi communication;computer vision tracking","","19","","19","IEEE","11 Nov 2013","","","IEEE","IEEE Conferences"
"Evaluating gesture-based augmented reality annotation","Y. S. Chang; B. Nuernberger; B. Luan; T. Höllerer","University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara","2017 IEEE Symposium on 3D User Interfaces (3DUI)","6 Apr 2017","2017","","","182","185","Drawing annotations with 3D hand gestures in augmented reality are useful for creating visual and spatial references in the real world, especially when these gestures can be issued from a distance. Different techniques exist for highlighting physical objects with hand-drawn circle and arrow annotations from a distance, assuming an approximate 3D scene model (e.g., as provided by the Microsoft HoloLens). However, little is known about user preference and performance of such methods for annotating real-world 3D environments. In this paper, we compare different annotation methods using the HoloLens augmented reality development platform: Surface-Drawing and Air-Drawing, with either raw but smoothed or interpreted and beautified gesture input. For the Surface-Drawing method, users control a cursor that is projected onto the world model, allowing gesture input to occur directly on the surfaces of real-world objects. For the Air-Drawing method, gesture drawing occurs at the user's fingertip and is projected onto the world model on release. The methods have different characteristics regarding necessitated vergence switches and afforded cursor control. We performed an experiment in which users draw on two different real-world objects at different distances using the different methods. Results indicate that Surface-Drawing is more accurate than Air-Drawing and Beautified annotations are drawn faster than Non-Beautified; participants also preferred Surface-Drawing and Beautified.","","978-1-5090-6716-9","10.1109/3DUI.2017.7893337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893337","Augmented Reality;Annotations;Spatial Referencing;HoloLens;User Study","Three-dimensional displays;Two dimensional displays;Surface treatment;Augmented reality;Niobium;Solid modeling;Atmospheric measurements","augmented reality;gesture recognition","gesture evaluation;drawing annotations;3D hand gestures;visual reference;spatial reference;hand-drawn circle;arrow annotations;3D scene model;air-drawing;surface-drawing;HoloLens augmented reality development platform","","17","","10","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Augmented Reality in a Public Space: The Natural History Museum, London","A. Barry; G. Thomas; P. Debenham; J. Trout","National History Museum, London, UK; National History Museum, London, UK; BBC Research and Development, UK; BBC Research and Development, UK","Computer","29 Jun 2012","2012","45","7","42","47","In addition to seamlessly integrating virtual and real content, augmented reality systems in museums must provide a viewing interface that is flexible and robust enough for thousands of people to use. A related video can be seen here: http://youtu.be/KJEfkljZ0Tk. It shows how augmented reality systems in museums can provide a viewing interface that is flexible and robust enough for thousands of people to use.","1558-0814","","10.1109/MC.2012.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165244","augmented reality;museum technology;camera tracking;LED markers;interactive media","Cameras;Augmented reality;Virtual environments;Tracking;Light emitting diodes;Three dimensional displays;History;Interactive systems","augmented reality;museums;user interfaces","public space;augmented reality systems;natural history museum;London;viewing interface","","16","","6","IEEE","6 Mar 2012","","","IEEE","IEEE Magazines"
"ARKit and ARCore in serve to augmented reality","Z. Oufqir; A. El Abderrahmani; K. Satori","LIIAN, USMBA Faculty of Sciences Fes, Morocco; LIIAN, USMBA Faculty of Sciences Fes, Morocco; LIIAN, USMBA Faculty of Sciences Fes, Morocco","2020 International Conference on Intelligent Systems and Computer Vision (ISCV)","23 Sep 2020","2020","","","1","7","Many libraries are available in the development world to create augmented reality applications, their functionality differs depending on the technology used to detect and track an object, points or features in a scene. In this article, we will discover ARKit, ARCore two open source libraries that display a virtual object in the real world. Their goal is to merge digital content and information with the real world. They can interact with the components of the device (camera and screen) to detect and track characteristics of the scene in order to insert virtual content. This study implements and concretizes the different functionalities available in augmented reality to enrich the real world with additional information.","","978-1-7281-8041-0","10.1109/ISCV49265.2020.9204243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204243","arkit;arcore;augmented reality;real world;virtual 3D object","Augmented reality;Cameras;Three-dimensional displays;Tracking;Feature extraction;Faces;Games","augmented reality;public domain software","ARKit;development world;augmented reality applications;functionality differs;ARCore;virtual object;digital content;virtual content;open source libraries","","15","","40","IEEE","23 Sep 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Interactive Storytelling Systems Using Tangible Cubes for Edutainment","C. Juan; R. Canu; M. Giménez","DSIC, UPV, Spain; DSIC, UPV, Spain; Escola d'Estiu, UPV, Spain","2008 Eighth IEEE International Conference on Advanced Learning Technologies","15 Jul 2008","2008","","","233","235","Augmented Reality has been used in many areas and it has proved to be useful for storytelling. These systems are adequate for edutainment. In this paper, we present two Augmented Reality interactive storytelling systems that use tangible cubes. The first shows the story in only one face of the cube and the second presents the story in all visible faces of the cube. The progress of the story can be chosen using two different tangible interfaces. We have tested the systems with the children of the Summer School of the Technical University of Valencia. In these tests we have analysed if the use of a Head-Mounted Display or a typical monitor influence in the experience of the user. Results do not offer statistical significant differences using both visualization systems and confirm that children enjoyed playing with the systems.","2161-377X","978-0-7695-3167-0","10.1109/ICALT.2008.122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4561673","Augmented Reality;storytelling;tangible interfaces;edutainment","Augmented reality;Cameras;System testing;Displays;Visualization;Sun;Books;Geometry;Universal Serial Bus;Rendering (computer graphics)","augmented reality;computer aided instruction;interactive systems","augmented reality interactive storytelling systems;tangible cubes;edutainment;Summer School;Technical University of Valencia;visualization system","","15","3","6","IEEE","15 Jul 2008","","","IEEE","IEEE Conferences"
"AR_Dehaes: An Educational Toolkit Based on Augmented Reality Technology for Learning Engineering Graphics","J. Martín-Gutiérrez; J. L. Saorín; M. Contero; M. Alcaniz","Dpto. Expresión Gráfica en Arquitectura e Ingeniería Universidad de La Laguna, La Laguna, Spain; Dpto. Expresión Gráfica en Arquitectura e Ingeniería Universidad de La Laguna, La Laguna, Spain; Instituto en Bioingeniería y Tecnología Orientada al Ser Humano Universidad Politécnica de Valencia, Valencia, Spain; Instituto en Bioingeniería y Tecnología Orientada al Ser Humano Universidad Politécnica de Valencia, Valencia, Spain","2010 10th IEEE International Conference on Advanced Learning Technologies","16 Sep 2010","2010","","","133","137","Augmented reality provides solutions and benefits in many areas of knowledge. In the field of education, we can apply this technology for learning contents and for developing skills in an engaging way. Engineering educators are aware of the need for spatial vision skills in order to project and interpret drawings and plans. We propose an educational kit for use at university-level with contents based on engineering graphics. Preliminary results of a validation study with first year Mechanical Engineering students indicate that this augmented reality training has a positive impact on students' spatial ability and learning for basic engineering graphics contents.","2161-377X","978-1-4244-7145-4","10.1109/ICALT.2010.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571198","Augmented Reality;Spatial Abilities;Engineering Graphics","Cameras;Augmented reality;Training;Books;Visualization","augmented reality;computer aided instruction;educational aids;engineering education","AR Dehaes;educational toolkit;augmented reality technology;learning engineering graphics;learning content;spatial vision skill;mechanical engineering student","","14","","15","IEEE","16 Sep 2010","","","IEEE","IEEE Conferences"
"Augmented reality system based on hand gestures for remote maintenance","N. Zenati-Henda; A. Bellarbi; S. Benbelkacem; M. Belhocine","Centre de Développemeut des Technologies Avancées, CDTA, Algiers, Algeria; Centre de Développemeut des Technologies Avancées, CDTA, Algiers, Algeria; Centre de Développemeut des Technologies Avancées, CDTA, Algiers, Algeria; Centre de Développemeut des Technologies Avancées, CDTA, Algiers, Algeria","2014 International Conference on Multimedia Computing and Systems (ICMCS)","29 Sep 2014","2014","","","5","8","In the industry, complex technologies are introduced to improve the productivity. Because of the maintenance tasks can be very complex, technicians can be assisted by remote experts to perform their physical tasks. Maintenance can be supported by augmented reality technology that directly links instructions on how to perform maintenance tasks. This paper presents a real time collaboration system for remote assistance where hand gestures based mobile augmented reality are used by a remote helper. This method can be used to assist a distant worker to perform manual tasks.","","978-1-4799-3824-7","10.1109/ICMCS.2014.6911258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911258","Augmented reality;hand gesture recognition;interactive table;remote maintenance","Maintenance engineering;Collaboration;Gesture recognition;Augmented reality;Mobile communication;Usability;Real-time systems","augmented reality;gesture recognition;groupware;mobile computing;real-time systems","hand gestures;remote maintenance;physical tasks;real time collaboration system;remote assistance;mobile augmented reality","","12","","12","IEEE","29 Sep 2014","","","IEEE","IEEE Conferences"
"Design and Implement Augmented Reality for Supporting Driving Visual Guidance","J. -H. Lin; C. -M. Lin; C. -R. Dow; C. -Q. Wang","Department of Electrical Engineering, Nankai University of Technology, Caotun, Nantou, Taiwan; Department of Computer and Communication Engineering, Nankai University of Technology, Caotun, Nantou, Taiwan; Department of Information Engineering and Computer Science, Feng-Chia University, TaiChung, Taiwan; Graduate Institute of Information Engineering and Computer Science, Feng-Chia University, TaiChung, Taiwan","2011 Second International Conference on Innovations in Bio-inspired Computing and Applications","2 Jan 2012","2011","","","316","319","It is an important issue that let drivers obtain driving information easily. There are many advanced electronic devices used for driving safety assistance. During driving a car, the driver receives the information passed by these systems. But with more functionality, more and more information will be generated and make the driving environment very complicated that makes it very difficult for the drivers to digest and response to all of the information. This highlights the importance of integrating all of the driving information. Augmented Reality (AR) with Head-Up Displays (HUDs) has recently attracted the attention in the field of automotive research. In this work, we design and implement AR for supporting driving visual guidance. We integrate driving information from Controller Area Network (CAN), Global Positioning System (GPS), navigation system, and other related information and use HUD technology to project it to the windscreen. This technique improves driver's situation awareness by dynamically combining more information imaging, called Point of Interest (POI), with global maps. The driver can easily see his/her driving guidance without having to turn his/her head off the driving direction using our augmented reality guidance, drivers can drive more easily.","","978-1-4577-1219-7","10.1109/IBICA.2011.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118782","Augmented Reality;Head-Up Display;Controller Area Network;Global Positioning System;Point of Interest","Vehicles;Visualization;Smart phones;Global Positioning System;Augmented reality;Automotive components","augmented reality;automobiles;controller area networks;driver information systems;Global Positioning System;head-up displays","driving visual guidance;advanced electronic devices;driving safety assistance;car;head-up displays;automotive research;controller area network;Global Positioning System;navigation system;windscreen;information imaging;point of interest;augmented reality guidance","","12","2","9","IEEE","2 Jan 2012","","","IEEE","IEEE Conferences"
"Learning Geometry with Augmented Reality to Enhance Spatial Ability","Y. -T. Liao; C. -H. Yu; C. -C. Wu","Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan; Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan; Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan","2015 International Conference on Learning and Teaching in Computing and Engineering","18 Jun 2015","2015","","","221","222","Spatial ability is considered essential in learning many disciplines. Studies have shown that providing students with geometry learning activities would help them develop spatial ability. Augmented Reality (AR) provides a combination of real and virtual worlds and allows students to view the spatial relationship of real world objects that is impossible to be implemented in traditional textbooks. This study have two purposes: (1) to develop an augmented reality system to assist students solve the Rubik's cube and learn the geometry concepts of volume and surface area, and (2) to examine the effects of using the system in terms of students' improvement on spatial ability, geometry achievement, and attitudes toward learning. The system is still under development and the evaluation is yet to be done.","","978-1-4799-9967-5","10.1109/LaTiCE.2015.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7126265","spatial ability;augmented reality;geometry;Rubik's cube","Geometry;Augmented reality;Visualization;Training;Surface treatment;Psychology","augmented reality;computer aided instruction;geometry;mathematics computing","spatial ability enhancement;geometry learning activities;virtual worlds;augmented reality system;Rubik's cube;surface area;student improvement","","12","","9","IEEE","18 Jun 2015","","","IEEE","IEEE Conferences"
"Augmented reality based on driving situation awareness in vehicle","B. -J. Park; C. Yoon; J. -W. Lee; K. -H. Kim","IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon; IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon; IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon; IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon","2015 17th International Conference on Advanced Communication Technology (ICACT)","27 Aug 2015","2015","","","593","595","In this paper, we introduce a vehicle augmented reality (AR) system to present information of driving situation awareness in a vehicle. Today, manufacturers related with vehicles have been pointing to AR as a next-generation visualization technology for in-car driving displays. Such in-vehicle AR-based display systems are helpful in reducing driver distractions, thereby increasing driver safety, and provide intelligent interactions for enhancing driver convenience. The proposed system offers information of driving situation and warning to a driver through the augmented reality using head-up display. The system consists of several sub-modules such as sensor, vehicle/pedestrian recognition, vehicle state information, driving information, time to collision (TTC), threat assessment, warning strategy, and display modules. We have defined the threat level and the presentation of AR information based on TTC values and driver's preference throughout experiments. The proposed system have been installed to a test vehicle with a vehicle AR information system prototype and carried out in the real road environments. The proposed system demonstrates to offer intuitively danger information according to the presentation rules to a driver on real road.","1738-9445","978-8-9968-6505-6","10.1109/ICACT.2015.7224865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224865","Augmented Reality;Time to Collision;Head-Up Display;Situation Awareness;Warning Strategy","Vehicles;Augmented reality;Safety;Roads;Automotive components;Acceleration;Convergence","augmented reality;data visualisation;driver information systems;helmet mounted displays;intelligent transportation systems;road vehicles","vehicle augmented reality;vehicle AR system;driving situation awareness;next-generation visualization technology;in-car driving display;driver safety;head-up display;vehicle AR information system;road environment","","12","","8","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Dense Stereo Matching with Application to Augmented Reality","N. Zenati; N. Zerhouni","Development Centre of Advanced Technology, France; Development Centre of Advanced Technology, France","2007 IEEE International Conference on Signal Processing and Communications","22 Dec 2008","2007","","","1503","1506","This work presents two techniques for computing dense disparity maps from two or more images. These methods are exploited in an application of augmented reality in order to add a virtual object with proper occlusions in the real scene. The proposed stereo matching techniques are based on area matching. We first present an implementation of the dynamic programming which produces a high quality of dense disparity map. Furthermore, in order to improve both the time computing and the map quality, we propose a hierarchical approach which combines the multi-resolution and the dynamic programming. The disparity maps thus obtained are applied in augmented reality in order to integrate in a realistic way the virtual objects. The applicability of the method is shown on many sequences of images.","","978-1-4244-1235-8","10.1109/ICSPC.2007.4728616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4728616","Augmented reality;image matching;dynamic programming;hybrid approach;dense disparity map","Augmented reality;Dynamic programming;Layout;Iterative algorithms;Application software;Signal processing;Laboratories;Image matching;Digital images;Feature extraction","augmented reality;hidden feature removal;image matching;image sequences;stereo image processing","dense stereo matching;augmented reality;dense disparity maps;virtual object;occlusions;map quality;image sequences","","12","","15","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"Augmented reality and representation in vehicle for safe driving at night","B. -J. Park; J. -W. Lee; C. Yoon; K. -H. Kim","IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea","2015 International Conference on Information and Communication Technology Convergence (ICTC)","17 Dec 2015","2015","","","1261","1263","To reduce traffic accidents at night driving, we introduce an augmented reality system using head-up display (HUD) in a vehicle and discuss the effectiveness and usefulness of the proposed system with representation strategy. The proposed system embraces recognition of dynamic object by radar-vision fusion, forward collision warning by threat assessment, and representation strategy using HUD. For warning information to prevent collision at night driving, an augmented reality information aligned at driver's eye and overlapped with real world is shown through the proposed system, and the usefulness of the system is validated in the experiments.","","978-1-4673-7116-2","10.1109/ICTC.2015.7354791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7354791","Augmented reality;forward collision warning;time to collision;head-up display;night driving","Vehicles;Augmented reality;Automotive components;Safety;Accidents;Night vision;Radar","augmented reality;head-up displays;image representation;intelligent transportation systems;object recognition;radar imaging","collision warning;radar-vision fusion;dynamic object recognition;HUD;head-up display;night driving;traffic accidents;safe driving;augmented reality system","","12","2","8","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Development of an augmented reality based remedial course to improve the spatial ability of engineering students","M. Contero; J. M. Gomis; F. Naya; F. Albert; J. Martin-Gutierrez","I3BH, Universitat Politècnica de València, Valencia, Spain; I3BH, Universitat Politècnica de València, Valencia, Spain; I3BH, Universitat Politècnica de València, Valencia, Spain; I3BH, Universitat Politècnica de València, Valencia, Spain; Departamento de Expresión Gráfica en Arquitectura e Ingeniería, Universidad de La Laguna, La Laguna, Spain","2012 Frontiers in Education Conference Proceedings","18 Feb 2013","2012","","","1","5","This paper presents the results of a pilot study designed to evaluate the effect of attending an intensive remedial course (8 hours worth of work during one week) based on desktop augmented reality exercises to improve the spatial ability of freshman engineering students. Activities based on practice with an augmented reality enhanced exercise book had a positive effect on students' spatial ability, measured by both MRT and DAT:SR tests. To promote students' autonomy, a YouTube tutorial for each type of exercise was developed. This allowed greater freedom for students to advance at their own pace during the training sessions. An evaluation and satisfaction questionnaire based on a five level Likert scale was submitted by participants. The experience was considered very positive by students.","2377-634X","978-1-4673-1352-0","10.1109/FIE.2012.6462312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6462312","Augmented reality;spatial skills;remedial course","Augmented reality;Training;Solid modeling;Visualization;Games;Engineering students","augmented reality;computer based training;educational courses;engineering education;social networking (online)","remedial course;spatial ability improvement;engineering student;desktop augmented reality exercise development;freshman engineering student;DAT:SR testing;MRT testing;YouTube tutorial;training session;five level Likert scale;time 8 hour","","11","","19","IEEE","18 Feb 2013","","","IEEE","IEEE Conferences"
"The Feasibility Study of Augmented Reality Technology in Early Childhood Education","Y. Kuang; X. Bai","Institute of Education, Jiang Xi Science and Technology Normal University, NanChang, China; Institute of Education, Jiang Xi Science and Technology Normal University, NanChang, China","2019 14th International Conference on Computer Science & Education (ICCSE)","23 Sep 2019","2019","","","172","175","With the rapid development of science and technology, the development and improvement of hardware and software make the cost of developers and users greatly reduced, educational knowledge and learning environment and communication methods have undergone great changes. Based on the characteristics of augmented reality technology and the characteristics of children's psychology, this paper puts forward the feasibility analysis of augmented reality technology in the field of early childhood education.","2473-9464","978-1-7281-1846-8","10.1109/ICCSE.2019.8845339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845339","augmented reality;early childhood education;feasibility component","Augmented reality;Education;Psychology;Software;Games;Solid modeling","augmented reality;computer aided instruction","augmented reality technology;early childhood education;educational knowledge;learning environment;communication methods;childrens psychology characteristics","","10","","5","IEEE","23 Sep 2019","","","IEEE","IEEE Conferences"
"A review of research on emerging technologies of the Internet of Things and augmented reality","S. Lanka; S. Ehsan; A. Ehsan","Computer Science, Himalayan university, Itanagar, India; Computer Science, FCIT College King Abdulaziz university Jeddah, Saudi Arabia; Information Technology, FCIT College/ King Abdul Aziz University, Jeddah, KSA","2017 International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)","5 Oct 2017","2017","","","770","774","The Internet of Things (IoT) is the way of changing the style we communicate with the world. Which can make an abstract idea where the object in our environment, through some introduced properties, develops into smarter and begin independently communicating with each other and persons, through networks maintained by interfaces. On the other phase Augmented reality (AR) blurs the line between our real world and the internet. Still smart watches, smart phones, home security systems are well developed simply called Embracing technology. Businesses are just looking into the value and are beginning to equipment production of embedded sensors. Enormous data will be produced by these devices. Currently, IoT and AR technologies already exist and available services can be found. If IoT and AR combines, a revolution will create beyond smart phone automate business processes in ways never possible before. This paper describes the architecture, technology networks, applications of IoT and Augmented reality systems. However, there is so much additional to come in IoT and AR technologies, which is why it is so important to grasp what can be provided through these technologies and how these technologies work.","","978-1-5090-3243-3","10.1109/I-SMAC.2017.8058283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8058283","Internet of Things;Augmented Reality;smart devices;sensors;Interface;computing","Cloud computing;Augmented reality;Wireless sensor networks;Internet of Things;Intelligent sensors;Mobile communication","augmented reality;business data processing;intelligent sensors;Internet of Things;mobile computing;smart phones","smart watches;smart phones;home security systems;Embracing technology;IoT;AR technologies;smart phone automate business processes;Augmented reality systems;Internet of Things","","9","","21","IEEE","5 Oct 2017","","","IEEE","IEEE Conferences"
"Incorporating augmented reality content in Engineering Design Graphics materials","J. Dorribo-Camba; M. Contero","Engineering Design Graphics, Texas A&M University, College Station, TX; Universitat Politecnica de Valencia, Valencia, Valenciana, ES","2013 IEEE Frontiers in Education Conference (FIE)","19 Dec 2013","2013","","","35","40","This paper describes the development and integration of augmented reality content with traditional Engineering Design Graphics materials, and presents the results of a preliminary usability study conducted with Freshman Engineering students. The resources developed combine printed text and images with interactive three-dimensional content with the purpose of enhancing the understanding of technical graphics concepts and improving the students' visualization skills. In general, students had a very positive reaction when first presented with the materials and showed an optimistic attitude while interacting with the content. Additionally, augmented reality materials promote the development of self-directed learning skills and self-assessment.","2377-634X","978-1-4673-5261-1","10.1109/FIE.2013.6684784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6684784","augmented reality;spatial skills;engineering graphics","Visualization;Bismuth;Artificial intelligence;Software;Augmented reality","augmented reality;CAD;computer aided instruction;computer graphics;design engineering","self-assessment development;self-directed learning skills;student visualization skills improvement;technical graphics concepts;interactive three-dimensional content;freshman engineering students;engineering design graphics materials;augmented reality content incorporation","","9","","32","IEEE","19 Dec 2013","","","IEEE","IEEE Conferences"
"Mobile outdoor augmented reality project for historic sites in Tainan","P. -Y. Hu; P. -F. Tsai","Kun Shan University, Yongkang Dist., Tainan, Taiwan; Kun Shan University, Yongkang Dist., Tainan, Taiwan","2016 International Conference on Advanced Materials for Science and Engineering (ICAMSE)","6 Feb 2017","2016","","","509","511","This paper discusses the development of an interactive mobile application based on Augmented Reality (AR) Technologies to enhance tourism experiences and make them more enjoyable. The main idea is to integrate actual historic monuments with Augmented Reality games. The goal of this project is to both entertain and educate visitors through mobile AR games while they visit historic sites. We introduce the design and concept of the project and aim to present a new tourism experience for Tainan City.","","978-1-5090-3869-5","10.1109/ICAMSE.2016.7840184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840184","mobile;augmented reality;historic sites","Augmented reality;Games;Urban areas;Mobile communication;Poles and towers;Mobile handsets;Cultural differences","augmented reality;computer aided instruction;computer games;history;interactive systems;mobile computing;travel industry","historic sites;Tainan City;interactive mobile application;augmented reality games;AR;tourism experience","","9","","6","IEEE","6 Feb 2017","","","IEEE","IEEE Conferences"
"An Empirical Study of the Use of an Augmented Reality Simulator in a Face-to-Face Physics Course","M. -B. Ibáñez; A. J. De Castro; C. Delgado Kloos","Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Madrid, Spain; Dept. de Fis., Universidad Carlos III de Madrid, Madrid, Madrid, ES; Dept. de Ing. Telematica, Universidad Carlos III de Madrid, Madrid, Madrid, ES","2017 IEEE 17th International Conference on Advanced Learning Technologies (ICALT)","7 Aug 2017","2017","","","469","471","This paper reports empirical evidence on using an augmented reality based simulator in a face-to-face learning environment. The simulator was used in a Physics course to allow students (N=112) to gain insight into the way in which magnetic fields interact with charged particles by watching in 3D the corresponding trajectories. Results suggest that augmented reality technology has a positive impact on students' motivation. It would, however, be necessary to consider reinforcement activities to improve learning effectiveness.","2161-377X","978-1-5386-3870-5","10.1109/ICALT.2017.105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8001835","Augmented reality;interactive learning environments;learning motivation;simulations for science learning","Augmented reality;Tools;Physics;Magnetic fields;Electronic mail;Three-dimensional displays;Trajectory","augmented reality;computer aided instruction;educational courses;human factors;magnetic fields;physics computing","augmented reality simulator;face-to-face physics course;face-to-face learning environment;magnetic fields;charged particles;students motivation","","8","","8","IEEE","7 Aug 2017","","","IEEE","IEEE Conferences"
"A Portable Framework Design to Support User Context Aware Augmented Reality Applications","J. Lewandowski; H. E. Arochena; R. N. G. Naguib; K. -M. Chao","Department of Computing and the Digital Environment, Coventry University, Coventry, UK; Department of Computing and the Digital Environment, Coventry University, Coventry, UK; Biomedical Computing and Engineering Technologies Applied Research Group (BIOCORE), Coventry University, Coventry, UK; Department of Computing and the Digital Environment, Coventry University, Coventry, UK","2011 Third International Conference on Games and Virtual Worlds for Serious Applications","28 Jul 2011","2011","","","144","147","This paper describes a portable framework to support augmented reality applications with user context information. It combines user's body responses with a virtual world by monitoring user's physical activity and vital signs in order to reflect real body status in a virtual world. In this paper we present a design of our portable vital signs monitoring framework, which can be applied to support physiological or affective user context information in augmented reality applications. The pivotal part of our system consists of multiple sensor nodes, and a PDA/smart phone device that aggregates and analyses data before sending it to the virtual world's controlling device as game play parameters. The malleability of the framework's communication's channels makes it compatible with most known game/ serious applications platforms.","","978-1-4577-0316-4","10.1109/VS-GAMES.2011.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5962099","ubiquitous computing;WBAN network;vital signs monitoring;augmented reality;serious games","Sensors;Servers;Games;Monitoring;Augmented reality;Biomedical monitoring;Wireless sensor networks","augmented reality;computer games;data analysis;medical computing;patient monitoring;ubiquitous computing","portable framework design;user context aware augmented reality;physical activity monitoring;portable vital signs monitoring framework;physiological user context information;affective user context information;sensor node;PDA;smart phone device;data analysis;game play parameter","","8","","19","IEEE","28 Jul 2011","","","IEEE","IEEE Conferences"
"A Gamified Mobile Augmented Reality System for the Teaching of Astronomical Concepts","J. M. Patrício; M. C. Costa; A. Manso","Instituto Politecnico de Tomar, Tomar, SantarÃ©m, PT; Universidade Nova de Lisboa, Lisboa, Lisboa, PT; Instituto Politecnico de Tomar, Tomar, SantarÃ©m, PT","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","5","In this paper we present the first version of the PlanetarySystemGO project, an evolution of SolarSystemGO, a Mobile Augmented Reality game previously created with the Unity3D/Vuforia game engine. While both projects aim at providing awareness of several Astronomy concepts, for PlanetarySystemGO a web based back-end system was implemented, developed under the. NET technology, that allows the instructor to manage several aspects of the game. Augmented Reality (AR) is a technology that elevates the possibilities of current Mobile Applications by superposing digital content to real world objects. The mobile devices that run these applications are increasingly powerful regarding their computational resources, allowing widespread adoption of the AR paradigms. The system presented can be enjoyed by players of all ages, but our main target are school children and young adults, as an application tool or even for learning purposes. A set of field tests was conducted, validating the presented design, and allowing continuous improvement of the system.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760658","Mobile games;augmented reality;location-based;gamification;didactic software;Unity3D;.NET","Games;Planets;Planetary orbits;Augmented reality;Education;Software","astronomy computing;augmented reality;computer aided instruction;educational institutions;Internet;mobile computing;serious games (computing);teaching","astronomical concepts;PlanetarySystemGO project;NET technology;mobile devices;mobile augmented reality game;teaching;Unity3D-Vuforia game engine;web based back-end system;school children;young adults","","8","","22","","15 Jul 2019","","","IEEE","IEEE Conferences"
"AuGeo: A geolocation-based augmented reality application for vocational geodesy education","A. Delić; M. Domančić; P. Vujević; N. Drljević; I. Botički","Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; University of Applied Sciences, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia","Proceedings ELMAR-2014","16 Oct 2014","2014","","","1","4","This paper discusses the possibilities of using augmented reality (AR) in geodesy vocational education through a geolocation-based AR application AuGeo. Augmented reality has been rapidly evolving ever since smart mobile phones became equipped with hardware and software which support AR application development. In educational AR current findings suggest that the best approach to application development is iterative co-design with teachers. That approach is incorporated into design of AuGeo by conducting a teacher focus group interview which is discussed and analyzed in the paper.","1334-2630","978-953-184-199-3","10.1109/ELMAR.2014.6923372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6923372","Augmented Reality;Geopositioning;Vocational Eduacation;Mobile Learning","Augmented reality;Global Positioning System;Geodesy;Education;Servers;Mobile communication;Sensors","augmented reality;computer aided instruction;geodesy;geographic information systems;mobile computing;smart phones;vocational training","AuGeo;geolocation-based augmented reality application;vocational geodesy education;geolocation-based AR application;smart mobile phones;AR application development;educational AR;iterative codesign;teacher focus group interview","","8","","21","","16 Oct 2014","","","IEEE","IEEE Conferences"
"Blind Reader: An Object Identification Mobile- based Application for the Blind using Augmented Reality Detection","J. Y. Mambu; E. Anderson; A. Wahyudi; G. Keyeh; B. Dajoh","Fakultas Ilmu Komputer, Universitas Klabat, Airmadidi, Indonesia; Fakultas Ilmu Keperawatan, Universitas Klabat, Airmadidi, Indonesia; Fakultas Ilmu Komputer, Universitas Klabat, Airmadidi, Indonesia; Fakultas Ilmu Komputer, Universitas Klabat, Airmadidi, Indonesia; Fakultas Ilmu Komputer, Universitas Klabat, Airmadidi, Indonesia","2019 1st International Conference on Cybernetics and Intelligent System (ICORIS)","21 Oct 2019","2019","1","","138","141","Eyes are our window to this world, however not for everyone. Visual impairments can highly disrupt human's normal activities as simple as recognize all the things around them properly. Technological development of augmented reality is one of the fastest growing technology. Augmented reality, which combines the real world and the virtual world, allows interactivity between both including as an assistive tool such for those who are visually impaired. In this research, we propose a mobile application that identifies objects using smartphone camera by utilizing markerless detection. We used Unity 3D and Vuforia SDK as the place to make the dataset of the marker and running on the Android-based smartphone. The result of this research is an android application that can identify objects and produce a sound output of the product name.","","978-1-7281-1474-3","10.1109/ICORIS.2019.8874906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8874906","assistive technology;assistive application;augmented reality;visually impaired;object recognition","Augmented reality;Blindness;Object recognition;Unified modeling language;Visualization;Testing;Cameras","augmented reality;handicapped aids;human computer interaction;mobile computing;smart phones","markerless detection;Android-based smartphone;android application;blind reader;object identification mobile-based application;augmented reality detection;visual impairments;technological development;virtual world;assistive tool;mobile application;Unity 3D;Vuforia SDK","","8","","16","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Proposal of methodology for learning of standard mechanical elements using augmented reality","J. Martín-Gutiérrez","Universidad de La Laguna, Spain","2011 Frontiers in Education Conference (FIE)","2 Feb 2012","2011","","","T1J-1","T1J-6","Learning and teaching procedures need to evolve, considering the high technological profile most students have. Today's university students are steeped in a culture of technology and new devices such as smartphones, PDAs and laptops. These have found a place in students' lives as an important tool for studying. The use of these devices is widely used and seen when entering a first-year class, and most students work or take notes with them. This paper describes a physical interface (augmented book) based on augmented reality technology for learning standard mechanical elements. This book was included in the curriculum of an engineering graphics subject in a Mechanical Engineering Degree of a Spanish University. A validation study of didactic material was carried out by Twenty-five students that used this augmented book for studying the representation and designation of standard mechanical elements. A control group consisting of twenty-two students used traditional class notes with static images to study the same contents. We have analyzed the results through an evaluation test and a usability survey. The results show that the experimental group students enjoyed studying through the use of AR technology and even obtained better results in a contents evaluation test.","2377-634X","978-1-61284-469-5","10.1109/FIE.2011.6142708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6142708","Academic Performance;Augmented Reality;Engineering Education;Standard Mechanical Elements","Augmented reality;Materials;Education;Cities and towns;Three dimensional displays;Visualization","augmented reality;computer aided instruction;engineering education","standard mechanical elements;augmented reality;teaching procedures;learning procedures;smartphones;PDA;laptops;physical interface;engineering graphics subject;mechanical engineering degree;Spanish University;didactic material","","8","","25","IEEE","2 Feb 2012","","","IEEE","IEEE Conferences"
"Preliminary user experience framework for designing mobile augmented reality technologies","S. Irshad; D. R. A. Rambli","Department of Computer And Information Sciences, Universiti Teknologi PETRONAS, Malaysia; Universiti Teknologi PETRONAS, Seri Iskandar, Perak, MY","2015 4th International Conference on Interactive Digital Media (ICIDM)","23 Aug 2016","2015","","","1","4","User eXperience (UX) is identified as the characteristics of the designed system, the result of user's internal state, and the context within which the interaction between the system and user occurs. UX is becoming increasingly diverse and well established field especially in the context of its usage. Nevertheless, this field of research lack conceptual and practical frameworks to be followed while designing for emerging technologies like Augmented Reality (AR). This paper presents an early framework for designing and evaluating the UX of Mobile Augmented Reality (MAR) applications. The credibility of this work-in-progress UX frame-work is supported by recent validated research on UX and MAR studies.","","978-1-5090-1669-3","10.1109/IDM.2015.7547833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547833","User eXperience (UX);Mobile Augmented Reality (MAR);Framework;User interface (UI);Design;Evaluation","Mars;Mobile communication;Augmented reality;Context;Usability;Human computer interaction","augmented reality;mobile computing","UX framework;MAR;user internal state;preliminary user experience framework;mobile augmented reality technologies","","7","","22","IEEE","23 Aug 2016","","","IEEE","IEEE Conferences"
"Augmented reality enhanced computer aided learning for young children","M. Ati; K. Kabir; H. Abdullahi; M. Ahmed","College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates; College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates; College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates; College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates","2018 IEEE Symposium on Computer Applications & Industrial Electronics (ISCAIE)","9 Jul 2018","2018","","","129","133","Learning to write can be exhausting for young children. In Traditional teaching, children with a different learning abilities are taught with the same rubric. This, in turn, impacts children that need extra attention to catch up with their pairs, which leads children to suffer right from the early learning stages. Traditional teaching methods also are so rigid that makes them unable to automatically identify those children with less abilities and in need of extra work. Hence, with the rapid development of ICT, an innovative learning methods are sought to be important to allow children to be taught with different rubrics. The aim of this research is to improve learning process for pre-school children via introducing Augmented Reality (AR) in the process which, in turn, simplify the learning process as well as identifying children abilities. The research introduces gamification to the process in order to ease the burden on children. Furthermore, we are trying to involve both school as well home to be part of the educational cycle that makes parents to be part of the learning/educational process of their young children. Augmented reality combined with pleasing sound make the learning more interactive and enjoyable. The outcome of this research also helps parents to keep track of their children's learning. The paper also describes the deployment of the application in a local schools as a pilot study so teachers can get feedback on student's learning curve and to fine tune the work further.","","978-1-5386-3527-8","10.1109/ISCAIE.2018.8405457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405457","Augmented Reality;Education;Cloud Computing;Mobile Application","Writing;Education;Games;Augmented reality;Mobile applications;Servers;Task analysis","augmented reality;computer aided instruction;computer games;educational institutions;learning (artificial intelligence);teaching","young children;innovative learning methods;learning process;pre-school children;children abilities;learning abilities;learning stages;teaching methods;augmented reality;computer aided learning;educational process;gamification;educational cycle;students learning curve","","7","","14","IEEE","9 Jul 2018","","","IEEE","IEEE Conferences"
"Control of a remote laboratory by augmented reality","J. Cubillo; S. Martín; M. Castro; R. Meier","Electrical and Computer Engineering Department, National University of Distance Education, Madrid, Spain; Electrical and Computer Engineering Department, National University of Distance Education, Madrid, Spain; Electrical and Computer Engineering Department, National University of Distance Education, Madrid, Spain; Electrical Engineering and Computer Science Department, Milwaukee School of Engineering, Milwaukee, WI, USA","Proceedings of IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE) 2012","24 Nov 2012","2012","","","W2B-11","W2B-15","A variety of advanced learning technologies has emerged to enhance learning, promote hands-on experiences, and increase interest in engineering and technical education. The possibility of access to a superior education is on hands of a great number of students while the resources which are available do not increase in the same way, limiting the quality of the teaching, so, it is necessary to look for alternatives that insure an access to the resources of a way regular, monitored an efficient. The remote laboratories avoid these gaps, however the development of these laboratories is of a great cost and their application is very specific. The fact of adding virtual information to the observed results by the students increases the quantity of information, provides us a great absorption of the contents and an expansion of the case studies. That is why it is possible to add the answer to questions like why this happens, or what would happen if the conditions of the experiment were different. The augmented reality provides an easy way to control a remote laboratory, creating a realist, simple and practical interface from any place in the world. To achieve the objectives mentioned above, this document shows how you can control a remote laboratory with augmented reality.","","978-1-4673-2418-2","10.1109/TALE.2012.6360297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360297","artificial;augmented;virtual realities;educational technologies;learning technologies;Engineering education;interactive environments;remote systems","Augmented reality;Education;Remote laboratories;Software;Conferences","augmented reality;computer aided instruction;distance learning;engineering education","remote laboratory;augmented reality;learning technology;teaching quality;virtual information","","7","","21","IEEE","24 Nov 2012","","","IEEE","IEEE Conferences"
"An Augmented Reality to Support Mobile Game-Based Learning in Science Museum on Biodiversity","N. Meekaew; W. Ketpichainarong","Institute for Innovative Learning, Mahidol University, Nakon Pathom, Thailand; Institute for Innovative Learning, Mahidol University, Nakon Pathom, Thailand","2018 7th International Congress on Advanced Applied Informatics (IIAI-AAI)","18 Apr 2019","2018","","","250","255","The aim of this study was to compared the results of using mobile game-based learning (MG) and mobile game-based learning integrated with Augmented Reality (MGAR) on understanding of biodiversity and learning motivation in museum. Both MG and MGAR were designed according to curricular objectives and the subject matter of secondary Thailand core curriculum. The participants were 96 grade 9 students who were randomly assigned in 2 groups, one of them used mobile game-based learning (N=50) and another used mobile game-based learning integrated with Augmented Reality (N=46). The experimental instruments were the pre-test and post-test of understanding, the learning motivation questionnaire, and semi-structure interview to gather both quantitative and qualitative data. The result shows that the effect of MGAR in enhancing students' understanding of biodiversity and provided more motivational than MG significantly.","","978-1-5386-7447-5","10.1109/IIAI-AAI.2018.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693370","Augmented reality, Biodiversity, Mobile Game-based Learning, Museum learning","Biodiversity;Games;Augmented reality;Land mobile radio;Organisms;Interviews","augmented reality;computer aided instruction;mobile computing;museums;serious games (computing)","augmented reality;biodiversity;learning motivation questionnaire;mobile game-based learning;MG;museum;quantitative data;qualitative data","","6","","28","IEEE","18 Apr 2019","","","IEEE","IEEE Conferences"
"Augmented reality as an instrument for teaching industrial automation","J. Martin; J. Bohuslava","Institute of Applied Informatics, University of Technology in Bratislava, Trnava, Slovakia; Institute of Applied Informatics, University of Technology in Bratislava, Trnava, Slovakia","2018 Cybernetics & Informatics (K&I)","16 Apr 2018","2018","","","1","5","Augmented Reality is a progressive tool in the field of education and learning systems. The subject of the article is the introduction of a learning system focused on the teaching of subjects from the field of industrial automation. However, the modularity and versatility of its design mean that the system is universally applicable to the teaching of any technical subject matter. The solution is built on an open source platform, which underlines the low cost of the system. The use of the A-Frame framework in combination with the AR.js project allows for a combination of learning information and real-world images on commonly available mobile devices in augmented reality to be offered. Additionally, the information is supplemented by real-time process information from the process level control elements of selected subsystems of the complex production line AFB Factory by Festo Didactics.","","978-1-5386-4421-8","10.1109/CYBERI.2018.8337535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8337535","augmented reality;industrial automation;learning system","Automation;Augmented reality;Production facilities;Training;Solid modeling;Manufacturing","augmented reality;computer aided instruction;control engineering education;industrial engineering;production engineering computing;public domain software;teaching;virtual manufacturing","augmented reality;learning systems;learning system;technical subject matter;open source platform;education systems;industrial automation teaching","","5","","12","IEEE","16 Apr 2018","","","IEEE","IEEE Conferences"
"The Seed Shooting Game: An Augmented Reality 3D pop-up book","P. Vate-U-Lan","Graduate School of eLearning, Assumption University of Thailand, Bangkok, Thailand","2013 Second International Conference on E-Learning and E-Technologies in Education (ICEEE)","24 Oct 2013","2013","","","171","175","The purpose of this research paper was to demystify: 1) a convergence of Augmented Reality (AR) technology as an educational multimedia and instructional design principles and 2) a divergence of learning outcomes and findings based upon the utilization of Augmented Reality 3D pop-up book, namely The Seed Shooting Game. This AR 3D pop-up book employed a storytelling technique for teaching English as a foreigner language for Year Three students, in Bangkok, Thailand. The population of this quasi experimental research was 484 Year Three Thai students who were studying in the second semester of 2011. 99 students were derived from purposive selection method as the samples. The statistics used to present data of this current paper were mean, standard deviation, t-test and bivariate correlation. This innovation was designed for blended learning environment which combined electronic curriculum material in traditional teaching mode. The research results presented the divergence between pre-test and post-test score of participants, the diversity of satisfaction levels of students who studied in this blended learning environment. This paper also presented the correlation between achievement and satisfaction towards to the developed curriculum material which reflected the confident to use AR technology for education in future.","","978-1-4673-5094-5","10.1109/ICeLeTE.2013.6644368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6644368","Augmented Reality;blended learning;e-learning;elementary level;innovation;multimedia;teaching English as a second language;3D pop-up book","Three-dimensional displays;Education;Augmented reality;Games;Materials;Multimedia communication;Computers","augmented reality;computer aided instruction;computer games;multimedia systems;natural language processing;statistical testing;teaching","augmented reality 3D pop-up book;educational multimedia;Seed Shooting Game;AR technology;instructional design principles;learning outcome divergence;storytelling technique;English as a foreigner language;Bangkok;Thailand;purposive selection method;statistics;mean;standard deviation;t-test;bivariate correlation;blended learning environment;electronic curriculum material;teaching mode","","5","","18","IEEE","24 Oct 2013","","","IEEE","IEEE Conferences"
"Development of immersive augmented reality interface for construction robotic system","Jinki Moon; Youngwan Son; Shinsuk Park; Jinwook Kim","Department of Mechanical Engineering, Korea University, Seoul, South Korea; Department of Mechanical Engineering, Korea University, Seoul, South Korea; Department of Mechanical Engineering, Korea University, Seoul, South Korea; Imaging Media Research Center, Korea Institute of Science and Technology, Seoul, South Korea","2007 International Conference on Control, Automation and Systems","26 Dec 2007","2007","","","1192","1197","This paper presents a human-machine interface for tele-operated construction robot systems. By using augmented reality techniques, we developed an immersive interface for tele-operated construction robot system. Compared to the traditional interface using a monitor view only, the developed AR interface system allows the operator to see the invisible image out of camera view by using a virtual 3D model. Also, this AR system notifies the operator of a danger area and gives the operator a guide for completion of task by using the augmented reality. For these reasons, the operator can rapidly and accurately recognize depth information of structure in construction site. Therefore, the operator can easily and safely complete construction operation. Also, the efficiency of construction operation can be improved and the construction period can be decreased.","","978-89-950038-6-2","10.1109/ICCAS.2007.4406515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4406515","Construction automation;Tele-operated robot;Augmented reality;Immersive interface","Augmented reality;Robotics and automation;Robot vision systems;Cameras;Service robots;Orbital robotics;Control systems;Construction industry;Safety;Power generation economics","augmented reality;construction industry;control engineering computing;industrial robots;telerobotics;user interfaces","immersive augmented reality interface;human-machine interface;teleoperated construction robot systems;virtual 3D model","","5","","10","","26 Dec 2007","","","IEEE","IEEE Conferences"
"Ubiquitous hybrid tracking techniques for augmented reality applications","G. Singh; A. Mantri","School of Electronics and Electrical Engineering, Chitkara University, Rajpura, Punjab, India; CURIN, Chitkara University, Rajpura, Punjab, India","2015 2nd International Conference on Recent Advances in Engineering & Computational Sciences (RAECS)","19 Apr 2016","2015","","","1","5","Augmented reality is a technology in which computer generated virtual objects interacts with the real time physical objects. Tracking is one of most sensitive issue in augmented reality based system. Without high accurate tracking of physical objects available in real environment, it is not possible to overlay virtual objects. The alignment of virtual and real environment depends upon the accuracy of tracking system. In this paper, we have carried out extensive literature survey of various tracking techniques, such as sensor based, vision and hybrid and limitations of present tracking techniques are discussed. Also proposes to use multiple sensors and camera vision for ubiquitous hybrid tracking system.","","978-1-4673-8253-3","10.1109/RAECS.2015.7453420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7453420","Augmented Reality;feature based tracking;hybrid tracking;inertial sensors;marker based tracking","Augmented reality;Global Positioning System;Cameras;Tracking;Robustness;Solid modeling;Real-time systems","augmented reality;computer vision;object tracking;sensor fusion","ubiquitous hybrid tracking techniques;augmented reality applications;computer generated virtual objects;real time physical objects;physical object tracking;sensor based tracking techniques;vision based tracking techniques;multiple sensors;camera vision","","5","","29","IEEE","19 Apr 2016","","","IEEE","IEEE Conferences"
"Multi-source information fusion augmented reality benefited decision-making for unmanned aerial vehicles: A effective way for accurate operation","Z. Cai; M. Chen; L. Yang","Institute of unmArmed aerial vehicles, Beihang University, Beijing, China; Institute of unmArmed aerial vehicles, Beihang University, Beijing, China; Department of automation science and electrical engineering, Beihang University, Beijing, China","2011 6th IEEE Conference on Industrial Electronics and Applications","4 Aug 2011","2011","","","174","178","Augmented reality UAV multi-source information is obtained by overlaying a variety of other sensors and the database data in the airborne video of CCD sensor. More substantial and credible information display can then be obtained. Our research includes the establishment of binocular stereo camera, improved feature matching algorithm with high matching speed and robustness, pose measurement methods making control operators observation immersion better. The method used for manipulation of augmented reality provides enhanced decision support information to improve the personnel control decision's speed and accuracy.","2158-2297","978-1-4244-8756-1","10.1109/ICIEA.2011.5975574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975574","data fusion;augmented reality;decision-making;unmanned aerial vehicles","Augmented reality;Sensors;Target tracking;Navigation;Cameras;Real time systems","aerospace computing;augmented reality;CCD image sensors;control engineering computing;decision making;image matching;pose estimation;remotely operated vehicles;sensor fusion;space vehicles;stereo image processing;video signal processing","multisource information fusion;augmented reality;decision making;unmanned aerial vehicle;UAV;airborne video;CCD sensor;binocular stereo camera;feature matching;pose measurement;decision support information","","5","1","6","IEEE","4 Aug 2011","","","IEEE","IEEE Conferences"
"Augmented reality and image recognition based framework for treasure hunt games","Z. Bálint; B. Kiss; B. Magyari; K. Simon","Babeş-Bolyai University, Computer Science Department, Cluj-Napoca, Romania; Babeş-Bolyai University, Computer Science Department, Cluj-Napoca, Romania; Babeş-Bolyai University, Computer Science Department, Cluj-Napoca, Romania; Babeş-Bolyai University, Computer Science Department, Cluj-Napoca, Romania","2012 IEEE 10th Jubilee International Symposium on Intelligent Systems and Informatics","25 Oct 2012","2012","","","147","152","The scavenger hunt and treasure hunt game categories are relatively well-known. The main idea of these games is to reach different checkpoints and execute specific tasks at these locations. There are many successful games based on this idea, like Geocaching. There are also some frameworks for building games, like Scvngr, but generally these frameworks have some disadvantages. The placement of real physical objects (“treasures”) could be expensive, GPS-based localization cannot be used inside buildings etc. The lack of generality could be a problem, as well. A general framework for the development of augmented reality-based, multiplayer adventure games is proposed. The framework can be used for creating online treasure hunt or scavenger hunt games for mobile devices. The “treasures” can be virtual 3D objects, appearing as a part of the augmented reality. The integrated image recognition support offers new possibilities in game creation and customization. GPS-based localization is combined with image recognition based localization, in this way the created applications can be used inside buildings, as well.","1949-0488","978-1-4673-4750-1","10.1109/SISY.2012.6339504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6339504","treasure hunt game;scavenger hunt game;augmented reality;image recognition;Android;iOS;Vuforia framework","Games;Augmented reality;Servers;Image recognition;Androids;Humanoid robots;Cameras","augmented reality;computer games;Global Positioning System;image recognition;mobile computing","augmented reality-based multiplayer adventure games;image recognition based localization framework;treasure hunt games;scavenger hunt game;geocaching;Scvngr;online treasure hunt;mobile devices;virtual 3D objects;game creation;game customization;GPS-based localization","","5","2","11","IEEE","25 Oct 2012","","","IEEE","IEEE Conferences"
"Key technology and application research on mobile augmented reality","J. Yu; L. Fang; C. Lu","Henan University of Technology, Zhengzhou, Henan, CN; College of Information Science and Engineering, Henan University of Technology, Zhengzhou, Henan Province, China; College of Information Science and Engineering, Henan University of Technology, Zhengzhou, Henan Province, China","2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS)","23 Mar 2017","2016","","","547","550","The rapid developments in both hardware and software of mobile intelligent devices enable the mobile augmented reality (MAR) systems and applications. People using MAR systems can enhance and extend the experience in both real and virtual spaces. This paper introduces the concept and characteristics of mobile augmented reality (MAR). Then we focus on the key technologies which have great impact on the MAR systems, including track registration, object detection and recognition, calibration, and model rendering etc. We present some typical MAR cases in different fields to show the ideas that are currently used. Finally, we provide an overview about the possibilities and future applications of MAR.","2327-0594","978-1-4673-9904-3","10.1109/ICSESS.2016.7883129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883129","mobile augmented reality;tracking registration;feature detection;model rendering","Computational modeling;Mobile communication;Image recognition;Augmented reality;Scalability;Calibration;Reliability","augmented reality;mobile computing","mobile augmented reality;MAR systems;mobile intelligent devices;virtual spaces;track registration;object detection;object recognition;model rendering","","5","","17","IEEE","23 Mar 2017","","","IEEE","IEEE Conferences"
"The use of augmented reality enhanced flashcards for arabic vocabulary acquisition","N. Zainuddin; R. M. Idrus","Faculty of Major Languages, Universiti Sains Islam Malaysia, Bandar Baru Nilai, Malaysia; Faculty of Major Languages, Universiti Sains Islam Malaysia, Bandar Baru Nilai, Malaysia","2016 13th Learning and Technology Conference (L&T)","12 Sep 2016","2016","","","1","5","This study describes the development process of an augmented reality (AR) enhanced flashcards for non-native students of Universiti Sains Islam Malaysia (USIM) students to enhance their knowledge and memorization of basic Arabic Vocabulary. An application namely Aurasma was used in the development process. This study was conducted with 20 elementary-level students in USIM by observing their response and their understanding in using the AR enhanced flashcards for Arabic vocabulary acquisition. Findings indicated that AR enhanced flashcards help in scaffolding the knowledge of students regarding the Arabic vocabulary acquisition. Furthermore, from the data collected through the questionnaires, the researchers found that the process of learning is being much easier with the help of the AR enhanced flashcards. The augmented reality considered as one of the platform that can be used to help the students in memorizing certain information and maintained their knowledge of Arabic vocabulary. In addition, students created novel sentences using the target vocabulary words more than half of the time.","","978-1-5090-3394-2","10.1109/LT.2016.7562857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562857","Augmented Reality;Arabic vocabulary;Scaffolding;systematic approaches;non-native students","Vocabulary;Augmented reality;Education;Videos;Tablet computers;Mobile communication;Browsers","augmented reality;computer aided instruction;educational institutions;linguistics;natural languages;vocabulary","augmented reality enhanced flashcards;Arabic vocabulary acquisition;AR enhanced flashcards;nonnative students;Universiti Sains Islam Malaysia;USIM students;student knowledge;student memorization;Aurasma;elementary-level students;learning","","4","","25","IEEE","12 Sep 2016","","","IEEE","IEEE Conferences"
"Picture puzzle augmented reality system for infants creativity","Y. -J. Oh; Young-Sang Suh; E. -K. Kim","Department of Computer Engineering, Sunchon National University, Republic of Korea; Division of a Visual Design, Chonnam National University, Republic of Korea; Department of Computer Engineering, Sunchon National University, Republic of Korea","2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN)","11 Aug 2016","2016","","","343","346","Recently there are various researches on educations using augmented reality and learners can enhance learning effects by interest and immersion via direct and indirect experience learning they can touch, catch, and feel by using five senses such as vision, auditory sense, sense of touch, and etc. This paper designs the block puzzle education system based on augmented reality to educate creativity, growth of small muscles, cognition of things, and English simultaneously","2165-8536","978-1-4673-9991-3","10.1109/ICUFN.2016.7537045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7537045","Block Puzzle Education System;Educations using Augmented Reality;Enhance Learning Effects;Creativity of Infants","Education;Three-dimensional displays;Augmented reality;Creativity;Solid modeling;Visualization;Mobile communication","augmented reality;computer aided instruction","direct experience learning;English learning;block puzzle education system;indirect experience learning;infants creativity;picture puzzle augmented reality system","","4","","9","IEEE","11 Aug 2016","","","IEEE","IEEE Conferences"
"Advanced image tracking approach for augmented reality applications","I. M. Gorovyi; D. S. Sharapov","It-Jim, Kharkiv, Ukraine; It-Jim, Kharkiv, Ukraine","2017 Signal Processing Symposium (SPSympo)","2 Oct 2017","2017","","","1","5","Augmented reality is popular and rapidly growing direction. It is successfully used in medicine, education, engineering and entertainment. In the paper, basic principles of typical augmented reality system are described. An efficient hybrid visual tracking algorithm is proposed. The approach is based on combining of the optical flow technique with direct tracking methods. It is demonstrated that developed technique allows to achieve stable and precise results. Comparative experimental results are included.","","978-1-5090-6755-8","10.1109/SPS.2017.8053687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8053687","augmented reality;marker;visual tracking;local features;optical flow;direct tracking","Cameras;Algorithm design and analysis;Computer vision;Augmented reality;Estimation;Transmission line matrix methods;Robustness","augmented reality;image sequences;object tracking","optical flow technique;direct tracking methods;augmented reality system;image tracking;hybrid visual tracking algorithm","","4","","16","IEEE","2 Oct 2017","","","IEEE","IEEE Conferences"
"RAD-AR: RADiotherapy - Augmented Reality","F. Cosentino; N. W. John; J. Vaarkamp","Wales Cancer Treatment Centre, University of Chester and North, Chester, United Kingdom; University of Chester, Chester, United Kingdom; North Wales Cancer Treatment Centre, Bodelwyddan, United Kingdom","2017 International Conference on Cyberworlds (CW)","30 Nov 2017","2017","","","226","228","We have developed an augmented reality tool for radiotherapy to view the real world scene, i.e. the patient on a treatment couch, combined with computer graphics content, such as planning image data and any defined outlines of organ structures. We have deployed our software to a number of consumer electronics devices (iPad, Android tablets, MS HoloLens). We suggest that, in contrast to other augmented reality tools explored for radiotherapy [1], due to the wide availability and low cost of the hardware platforms considered, associated with their increasing computational and graphic power, our system has strong potential as a tool for visualization of medical information for clinicians and other radiotherapy professionals, as a device for patient positioning for radiotherapy treatment, and as an educational tool for patients to visualize their treatment and demonstrate to patients e.g. the importance of compliance with instructions around bladder filling and rectal suppositories. Accuracy of virtual content placement and user evaluation of our system has been experimentally investigated.","","978-1-5386-2089-2","10.1109/CW.2017.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8120331","component;Augmented Reality;tablet computers;HoloLens;consumer electronics;radiotherapy","Computed tomography;Tools;Augmented reality;Tablet computers;Linear particle accelerator;Visualization","augmented reality;biological organs;consumer electronics;medical computing;radiation therapy","image data;organ structures;consumer electronics devices;augmented reality tool;graphic power;radiotherapy professionals;patient positioning;radiotherapy treatment;educational tool;computer graphics content;computational power;virtual content placement","","4","","6","IEEE","30 Nov 2017","","","IEEE","IEEE Conferences"
"Use and re-use of data how Collection Management Systems, Transmedia and Augmented Reality impact the future of museum","H. Kraemer; N. Kanter","School of Creative Media City, University of Hong Kong, Hong Kong; zetcom Ltd Berlin, Germany","2014 International Conference on Virtual Systems & Multimedia (VSMM)","29 Jun 2015","2014","","","214","216","The first of the core challenges, museums and archives have to face today is getting oversight and control, and an idea about the usefulness of the exponentially growing amount of digital data. The second core challenge is the defining of strategies for the use and re-use of the existing data in IT Systems like Collection Management Software. And the third one is how a museum can find a unique position as content provider and producer in the growing field of transmedia (formerly multimedia). The authors will give an overview about the current situation and show on several case studies where museums and archives are headed. This paper will have two parts. iIn Part 1: 'Digital Strategies in Museums' Norbert Kanter, international renown expert in Museum Informatics, will give an insight why museums need more than ever digital strategies. Furthermore he is explaining how the latest Collection Management Systems can support the use and re-use of different kind of data for different purposes. The workshop part 1 will give a comprehensive overview of tools and possibilities used by museums today to deliver their wealth of digital data and create transformations of these in all kinds of technologies-from databases to re-use and re-creation with technologies like portal sites, 3D-printing or Google Glass. In Part 2 'Transmedia vs. Augmented Reality' Harald Kraemer, producer, director as well as critical observer of online and offline Multimedia applications for and in museums, introduces into the problems of archiving multimedia content and methods to analyse these masterpieces of interactive applied arts. Meanwhile different forms of transmedia like interactive narrations told by interactive narrators, serious games or apps as well as Augmented Reality-driven 3D events become a progressive factor for a successful knowledge transfer of cultural heritage. As keepers of authentic artefacts and the related informations and narrations, museums increasingly have the obligation to define strategies for their digital future. In this paper the authors show and discuss some options.","","978-1-4799-7227-2","10.1109/VSMM.2014.7136693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7136693","digital strategies;future of museum;use and re-use of digital data;Collection Management System;Transmedia;interactive narrations and narrators;serious games;Augmented Reality","Media;Multimedia communication;Cultural differences;Art;Augmented reality;Standards;Navigation","augmented reality;history;interactive systems;museums","multimedia content;interactive narrators;cultural heritage;serious game;offline multimedia application;online multimedia application;Transmedia;3D-printing;Google glass;museum informatics;digital strategy;augmented reality;collection management software;IT system;digital data","","4","","16","IEEE","29 Jun 2015","","","IEEE","IEEE Conferences"
"Augmented reality for science instructional media in primary school","T. Maijarern; N. Chaiwut; R. Nobnop","Mae Fah Luang University, Chiang Rai, TH; Mae Fah Luang University, School of Information Technology, Chiang Rai, Thailand; Mae Fah Luang University, School of Information Technology, Chiang Rai, Thailand","2018 International Conference on Digital Arts, Media and Technology (ICDAMT)","11 Jun 2018","2018","","","198","201","Publishing is used to be a media in education for a long time. Due to the limitation of publishing, that cannot attach content in another format. Recently, the diversity of the instructional media has been developed. In this research, the author developed augmented reality to use as a media in science subject for a student in primary school years 4. The author designed and used a software to develop the augmented reality with the impressive and natural. From the test and questionnaire, this media enhances the student's interest and understanding.","","978-1-5386-0573-8","10.1109/ICDAMT.2018.8376523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8376523","Augmented Reality;Learning media","Augmented reality;Media;Education;Vocabulary;Conferences;Animation;Digital art","augmented reality;computer aided instruction;educational institutions;publishing","augmented reality;science instructional media;publishing;science subject;primary school","","4","","7","IEEE","11 Jun 2018","","","IEEE","IEEE Conferences"
"Exploring possible applications of augmented reality in education","N. Gupta; M. K. Rohil","Dept. of Computer Science & Information System, Birla Institute of Technology & Science Pilani, Pilani, India; Dept. of Computer Science & Information System, Birla Institute of Technology & Science Pilani, Pilani, India","2017 4th International Conference on Signal Processing and Integrated Networks (SPIN)","28 Sep 2017","2017","","","437","441","In recent years, use of Augmented Reality (AR) has been explored in a wide range of applications in various fields. Among these, one of the most inquired is the field of education. Many of these studies have shown that the use of AR in any learning environment promotes critical thinking, better understanding and motivates the learner for further studies. This is due to the real-time experience that AR brings with it to the learners. This paper reports some of the recent studies that list positive and negative impact of AR in an educational setting and how beneficial the employment of this technology is. The paper also gives an overview of some of the possible and promising applications of AR in the fields of science, social science, mathematics and language. Furthermore, the paper discusses trends and the vision towards future opportunities for possible research in augmented reality for education.","","978-1-5090-2797-2","10.1109/SPIN.2017.8049989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8049989","Augmented Reality;Education;Applications","Education;Visualization;Augmented reality;Buildings;Three-dimensional displays;Feature extraction;Signal processing","augmented reality;computer aided instruction","augmented reality;AR;educational setting;learning environment","","4","","25","IEEE","28 Sep 2017","","","IEEE","IEEE Conferences"
"Augmented Reality and Usability Best Practices: A Systematic Literature Mapping for Educational Videogames","A. Chang; F. Paz; J. Jesús Arenas; J. Díaz","Departamento de Ingeniería, Pontificia Universidad Católica del Perú, Lima, Perú; Departamento de Ingeniería, Pontificia Universidad Católica del Perú, Lima, Perú; Departamento de Ingeniería, Pontificia Universidad Católica del Perú, Lima, Perú; Departamento de Cs. de la Computació n e Informática, Universidad de La Frontera, Temuco, Chile","2018 IEEE Sciences and Humanities International Research Conference (SHIRCON)","30 Dec 2018","2018","","","1","5","Human-Computer Interaction and technology-aided instruction are beginning to focus on Augmented Reality (AR) path due to its ability to support different approaches for learning and entertainment. This kind of technology facilitates the student's attention by merging the real-world with virtual attributes. This paper presents a systematic mapping study of the use of Augmented Reality within video games and educational purposes.","","978-1-5386-8375-0","10.1109/SHIRCON.2018.8592976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8592976","Human computer interaction;usability heuristics;educational technology;augmented reality","Games;Augmented reality;Usability;Systematics;Guidelines;Proposals;Human computer interaction","augmented reality;computer aided instruction;computer games;human computer interaction","systematic literature mapping;educational videogames;technology-aided instruction;augmented reality;human-computer interaction;virtual attributes","","4","","28","IEEE","30 Dec 2018","","","IEEE","IEEE Conferences"
"Enhancing STEM Education using Augmented Reality and Machine Learning","I. J. X. Ang; K. H. Lim","Department of Electrical and Computer Engineering, Curtin University, Malaysia, Miri, Sarawak, Malaysia; Department of Electrical and Computer Engineering, Curtin University, Malaysia, Miri, Sarawak, Malaysia","2019 7th International Conference on Smart Computing & Communications (ICSCC)","19 Sep 2019","2019","","","1","5","Learning Science, Technology, Engineering and Mathematics (STEM) in the 21st century has been evolved from the conventional textbook to the interactive platform using electronic devices. This paper presents the implementation of a mobile application system, named AUREL (Augmented Reality Learning) in enhancing the learning experience by projecting Augmented Reality (AR) objects onto 2D images. This AR visualization is used to improve the understanding of STEM subjects and increases the enthusiasm of students towards STEM subjects. In this implementation, Google's Cloud Tensor Processing Units (TPUs) are used to train specific datasets alongside Cloud Vision API to detect a wide range of objects. ML Kit for Firebase is used to host the custom TensorFlow Lite models for specific use cases for better accuracy. On the other hand, Google Cloud Platform (GCP) is used to harvest STEM data, manage STEM 3D information and data processing. Subsequently, the processed information will be displayed in AR in the mobile application using ARCore's Sceneform SDK. The application of AUREL could be extended to all science subjects so that students can learn using an interactive platform.","","978-1-7281-1557-3","10.1109/ICSCC.2019.8843619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8843619","Augmented Reality;Machine Learning;STEM Education","Cloud computing;Training;Computational modeling;Augmented reality;Google;Mobile applications","application program interfaces;augmented reality;cloud computing;computer aided instruction;computer science education;interactive systems;learning (artificial intelligence);mobile learning;public domain software;STEM","STEM education;Augmented Reality;machine Learning;interactive platform;electronic devices;mobile application system;learning experience;AUREL;STEM 3D information;ARCore's Sceneform SDK;data processing;STEM data;Google Cloud Platform;Cloud Vision API;Google's Cloud Tensor Processing Units;STEM subjects","","4","","15","IEEE","19 Sep 2019","","","IEEE","IEEE Conferences"
"Design and development of intelligent operation and maintenance training system for substation based on augmented reality","Y. Peng; G. Yu; W. Ni; Z. Lv; Y. Jiang; J. Chen","State Grid Shanghai Municipal Electric Power Company, Shanghai, China; State Grid Shanghai Municipal Electric Power Company, Shanghai, China; State Grid Shanghai Municipal Electric Power Company, Shanghai, China; State Grid Shanghai Municipal Electric Power Company, Shanghai, China; State Grid Shanghai Municipal Electric Power Company, Shanghai, China; State Grid Shanghai Municipal Electric Power Company, Shanghai, China","2017 Chinese Automation Congress (CAC)","1 Jan 2018","2017","","","4765","4769","This paper presents an intelligent operation and maintenance training system for power grid operation staff of substation based on augmented reality (AR), whose functions, characteristics, software configuration and implementation are introduced in details. As the training and examination system for operation and maintenance personnel, the system was composed of intelligent training system and intelligent operation and maintenance system. The realistic settings are re-created by augmented reality effectively, which could realize the “panoramic” experience, in order to strengthen the operability of the training process. Based on this, the intelligent level of skills training continues to make progress. While the intelligent training simulation system with the operation and maintenance mode of state maintenance is built based on big data analysis, which conducts to provide strong support for intelligent substation engineering applications and practice.","","978-1-5386-3524-7","10.1109/CAC.2017.8243621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8243621","augmented reality;big data analysis;intelligent substation;operation and maintenance","Training;Substations;Maintenance engineering;Big Data;Augmented reality;Solid modeling","augmented reality;Big Data;computer based training;maintenance engineering;power engineering computing;power grids;substation automation","maintenance system;augmented reality;training process;intelligent training simulation system;intelligent substation engineering applications;intelligent operation;maintenance training system;power grid operation staff;maintenance personnel","","4","","7","IEEE","1 Jan 2018","","","IEEE","IEEE Conferences"
"Analysis of Auto Generation of 3D Model Using Multiple 2D Graphics to Manifest Through Augmented Reality","M. Khedwala; F. Momin; U. Pachhapure; S. Shaikh","Anjuman-I-Islam Kalsekar Technical Campus, University of Mumbai, New Panvel, India; Anjuman-I-Islam Kalsekar Technical Campus, University of Mumbai, New Panvel, India; Anjuman-I-Islam Kalsekar Technical Campus, University of Mumbai, New Panvel, India; Anjuman-I-Islam Kalsekar Technical Campus, University of Mumbai, New Panvel, India","2018 International Conference on Smart City and Emerging Technology (ICSCET)","18 Nov 2018","2018","","","1","5","Images are more ambiance than words similarly the 3D models are more descriptive than 2D pictures. 3D model of any product will give the enhanced information about it. The main objective of generating the 3D model is to reduce the amount of time by automating the process of generating the 3D model. Augmented Reality (AR) technologies have been recognized as offering great benefit to almost every field and organizations, although they are not easy to implement. AR provides enhanced information of the product by overlaying the 3D model into the real world. 3D models can express the shape and dimensions of the products with greater precision and they are being extensively used these days. In this paper, we are proposing a 3D modeling application which will take only a few 2D images as input from any image capturing device taken from different angles and it will automatically convert it into a 3D model. The first step towards generating the 3D model from the images is to establish point correspondence which includes feature extraction and feature matching. Then refining correspondence is done followed by de-calibration of 3D structure and camera pose. The final step is texture mapping and rendering. We are using an E-commerce portal as an example to display the 3D models generated by our 3D Modeling application. Most often customers shopping on E-commerce websites do not get complete information about the product by only viewing the 2D images. They can get a better understanding of the product by using AR View. The adaptation of Augmented Reality (AR) will take E-commerce to the next level.","","978-1-5386-1185-2","10.1109/ICSCET.2018.8537310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8537310","Augmented Reality;model;2D;3D","Three-dimensional displays;Solid modeling;Two dimensional displays;Augmented reality;Adaptation models;Computational modeling;Cameras","augmented reality;cameras;electronic commerce;feature extraction;image matching;image texture;rendering (computer graphics);stereo image processing","E-commerce websites;E-commerce portal;texture rendering;texture mapping;3D structure de-calibration;feature matching;feature extraction;2D images;auto generation analysis;camera pose;augmented reality;image capturing device;3D modeling application;multiple 2D graphics","","4","","7","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"Augmented reality based teaching pendant for industrial robot","S. M. Abbas; S. Hassan; J. Yun","School of Mechanical and Aerospace Engineering, Gyeongsang National University, Jinju, Korea; NA; School of Mechanical Engineering & ReCAPT, Gyeongsang National University, Jinju, Korea","2012 12th International Conference on Control, Automation and Systems","31 Dec 2012","2012","","","2210","2213","Robots have been used in various fields such as homes, manufacturing, and business. Remote robot control has been actively studied. Most of industrial robots are still programmed using the typical teaching process, through the use of the robot teach pendant. New and more intuitive ways for robot programming and control are required, smart phone are being used for controlling and programming industrial robot. In this research work, we present an idea of augmented reality based teaching pendant on smart phone. Incorporation of augmented reality into Smartphone based teaching pendant will help user to program industrial robot more intuitively.","","978-89-93215-04-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6393222","Augmented Reality (AR);Teaching Pendant;Smartphone Application","Service robots;Education;Augmented reality;Smart phones;Joints","augmented reality;control engineering computing;industrial robots;robot programming;smart phones;teaching;telerobotics","augmented reality based teaching pendant;remote robot control;teaching process;industrial robot programming;industrial robot control;smartphone based teaching pendant","","4","1","9","","31 Dec 2012","","","IEEE","IEEE Conferences"
"The Augmented Reality in Lisbon Tourism","J. N. Azevedo; B. Alturas","Instituto Universitário de Lisboa (ISCTE-IUL), ISTAR-IUL, Lisboa, Portugal; Instituto Universitário de Lisboa (ISCTE-IUL), ISTAR-IUL, Lisboa, Portugal","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","4","Augmented reality (RA) in tourism has contributed to revolutionizing the way tourists and visitors access information, acquire knowledge and integrate into the physical spaces and destinations visited. The studies produced concerning this field are still limited, particularly in the perception of how users adopt technology and what use they make of it. On the other hand, even more limited are the studies that consider the role of stakeholders in the implementation of AR technology. Thus, this study proposes a new Augmented Reality Technology Adoption Model, based on the adaptation of the Technology Adoption Model [11, 12, 13] and also by the applying of tourist surveys in the city of Lisbon and structured interviews to public and private agents operating in the tourist context of the city of Lisbon, in order to study the use and effects of AR technology.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760706","augmented reality;tourism;technology adoption model;smart tourism;smart destination","Adaptation models;Augmented reality;Stakeholders;Context modeling;Urban areas;Information systems;Visualization","augmented reality;social aspects of automation;travel industry","Lisbon tourism;visitors access information;physical spaces;tourist surveys;tourist context;augmented reality technology adoption model;AR technology adoption model","","4","","","","15 Jul 2019","","","IEEE","IEEE Conferences"
"Machine Fault Diagnostics and Condition Monitoring Using Augmented Reality and IoT","V. Rajan; N. V. Sobhana; R. Jayakrishnan","Dept. of CSE, RIT, Kottayam; Dept. of CSE, RIT, Kottayam; Dept. of CSE, RIT, Kottayam","2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)","10 Mar 2019","2018","","","910","914","Machine monitoring has its importance in determining conditions of different machine parts for forecasting various mechanical failures. With the view of eliminating undesired maintenance costs and production loss, condition monitoring has been adopted in different sectors. For predicting the life of different machine components a method called “Machine Fault Diagnostics and Condition Monitoring using Augmented Reality and Internet of Things” is proposed here. The main objective of the method proposed here is to diagnose a machine and its parts by monitoring different parameters like temperature, pressure, speed, vibration noise etc., to predict overheating, wear and tear or any other kinds of defects. The values of these parameters will be taken to analyze the working conditions of different machine components and finally to predict their life. IoT has its importance in making the machines connected by employing sensors which are mounted onto the machine parts for collecting data from them. Sensors like temperature sensors, pressure sensors, vibration sensors, proximity sensors etc., are most commonly used for condition monitoring. Machine parts that can be taken for monitoring may include gearbox, engine parts or even any kinds of pumps can be used. Data collected will be deployed to cloud servers like Thingspeak or MQTT Broker for further analysis in the future. Thingspeak with the assistance of Mathlab, allows visualization of data. These data will be taken and visualized using augmented reality in any devices like hololens, tablets or smartphones by buiding an android application with the help of a developing environment called Unity. The users will be able to see a visual overlay of the collected data which gives the health information of the machines that help them to infer whether a component is to be replaced or not. Thus continuous evaluation is made possible and minute defects can be detected before the occurrence of a catastrophic breakdown. The benefits of this type of method include reducing downtimes of machinery along with production losses and an accurate maintenance scheduling is possible.","","978-1-5386-2842-3","10.1109/ICCONS.2018.8663135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663135","Augmented Reality;Internet of Things;Sensors;MQTT Broker;Unity","Temperature sensors;Monitoring;Augmented reality;Temperature measurement;Chemical sensors;Fans","augmented reality;cloud computing;computerised monitoring;condition monitoring;fault diagnosis;Internet of Things;machinery;maintenance engineering;mechanical engineering computing;pressure sensors;signal processing;temperature sensors","condition monitoring;augmented reality;monitoring different parameters;working conditions;temperature sensors;pressure sensors;vibration sensors;machine monitoring;machine components;machine fault diagnostics","","4","","12","IEEE","10 Mar 2019","","","IEEE","IEEE Conferences"
"Color recognition system with augmented reality concept and finger interaction: Case study for color blind aid system","A. S. Manaf; R. F. Sari","Electrical Engineering Department, Universitas Indonesia, Depok, Indonesia; Electrical Engineering Department, Universitas Indonesia, Depok, Indonesia","2011 Ninth International Conference on ICT and Knowledge Engineering","16 Feb 2012","2012","","","118","123","Color blindness is an anomaly which happened in retinal of eye(s) which prevent the patient to recognize or differentiate certain colors. The disability of the patient to recognize color is potential to cause problems to the patient in daily life. Color blind cannot be cured. Therefore, the only method to help color blind people to recognize or differentiate color is with a vision aid kit. In this work, color blind aid system for embedded platform based on Windows Embedded Standard 2009, .NET Framework, OpenCV library and EmguCV Wrapper developed. We create color recognition features implemented with augmented reality concept in the system. In this work, we developed a sound augmented reality concept and finger interaction between user and colored object. Test result according to system testing which has been done from 10 respondents resulting good feedback. The result of finger interaction test shows that the fingertip detection rate reaches 89.6% for skin classification method with HSV color space. Meanwhile, fingertip detection rate reaches 87.5% for skin classification method with YCbCr color space. Furthermore, color recognition rate achieved good result for the majority of tested color types.","2157-099X","978-1-4577-2162-5","10.1109/ICTKE.2012.6152389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6152389","color blindness;augmented reality;embedded system;Windows Embedded;.NET Platform;OpenCV;EmguCV;finger interaction;color recognition","Color;Image color analysis;Skin;Thumb;Augmented reality;Cameras","augmented reality;handicapped aids;image colour analysis;interactive systems;mobile computing","color recognition system;augmented reality concept;finger interaction;color blind aid system;vision aid kit;Windows Embedded Standard 2009;.NET Framework;OpenCV library;EmguCV Wrapper;fingertip detection rate;skin classification method;HSV color space;YCbCr color space;eye retina","","4","","7","IEEE","16 Feb 2012","","","IEEE","IEEE Conferences"
"Applying Augmented Reality Technology to E-Learning: Science Educational AR Products as an Example","Z. Rongting; S. Yiran; H. Tongliang; F. Asmi","Department of Science and Technology Policy and Communication, USTC, Hefei, China; Department of Science and Technology Policy and Communication, USTC, Hefei, China; Department of Science and Technology Policy and Communication, USTC, Hefei, China; School of Public Affairs, USTC, Hefei, China","2016 IEEE 13th International Conference on e-Business Engineering (ICEBE)","9 Jan 2017","2016","","","129","133","The utility of augmented reality (AR) in educational application is under heated discussion. A brief review of augmented reality (AR) and e-learning is given. Taking a series of AR products including chemistry textbook and some derivatives developed or supported by the Institute of Knowledge Management of USTC as example, we made a detailed description of their system design, user interface and the principle of operation. We collected user feedback of above-mentioned products and similar products in order to analyze the user experience. Thus we considered the possibility of applying AR technology to e-learning. In this article, we emphasized the advantage of AR products in the domains of science and history.","","978-1-5090-6119-8","10.1109/ICEBE.2016.030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809911","augmented reality;e-learning;science education","Electronic learning;Augmented reality;Engines;Three-dimensional displays;Databases;Animals","augmented reality;computer aided instruction;user interfaces","augmented reality technology;e-learning;science educational AR products;Institute of Knowledge Management;USTC;user interface;system design","","4","","9","IEEE","9 Jan 2017","","","IEEE","IEEE Conferences"
"Poster: Spatial Augmented Reality user interface techniques for room size modeling tasks","M. R. Marner; B. H. Thomas","University of South Australia, Australia; University of South Australia, Australia","2013 IEEE Symposium on 3D User Interfaces (3DUI)","5 Sep 2013","2013","","","155","156","This poster presents results of our investigations into using Spatial Augmented Reality (SAR) to improve kitchen design and other interior architecture tasks. We present new user interface techniques for room sized modeling tasks, including cabinet layout, viewing and modifying preset designs, and modifying finishes. These tools and techniques address key user interface issues for spatial augmented reality systems, and we discuss how they can be generalized for other applications. The techniques have been developed in the context of a demonstration application, PimpMyKitchen, which allows architects to design kitchens, working with clients in an interactive SAR environment.","","978-1-4673-6098-2","10.1109/3DUI.2013.6550225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6550225","Spatial Augmented Reality;User Interfaces;Architecture","User interfaces;Layout;Augmented reality;Educational institutions;Solid modeling;Visualization;Australia","architecture;augmented reality;user interfaces","spatial augmented reality user interface technique;room size modeling task;kitchen design;interior architecture;cabinet layout;preset design viewing;preset design modification;finish modification;PimpMyKitchen;interactive SAR environment","","3","","7","IEEE","5 Sep 2013","","","IEEE","IEEE Conferences"
"Integration of cyber-physical systems technology with augmented reality in the pre-construction stage","C. M. Lukman Khalid; M. S. Fathi; Z. Mohamed","UTM Razak School of Engineering & Advanced Technology, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Construction Research Alliance, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; UTM Razak School of Engineering & Advanced Technology, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia","2014 2nd International Conference on Technology, Informatics, Management, Engineering & Environment","19 Jan 2015","2014","","","151","156","Cyber-Physical Systems (CPS) is a computerized networking system that integrates with physical processes. The lack of theoretical foundation in CPS has resulted with this study, which aims to provide a holistic view of Cyber-Physical Systems and its integration with Augmented Reality (AR) as a decision support tool in the pre-construction stage. It will then discuss the problems that arise and propose the use of location aware mobile augmented reality handheld system as a support tool to provide users with an intuitive information visualization of local network infrastructures.","","978-1-4799-4805-5","10.1109/TIME-E.2014.7011609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7011609","Cyber Physical Systems;Augmented Reality;Pre-Construction Stage;Underground networks","Augmented reality;Prototypes;Sensors;Mobile handsets;Mobile communication;Three-dimensional displays;Data models","augmented reality;mobile computing","cyber-physical systems technology;CPS;computerized networking system;location aware mobile augmented reality handheld system;intuitive information visualization;local network infrastructures;decision support tool;AR","","3","","34","IEEE","19 Jan 2015","","","IEEE","IEEE Conferences"
"Research on interaction in virtual assembly based on augmented reality","Wei Wei; Guo Chen","College of Information Science and Technology, Dalian Maritime University, Dalian, China; College of Information Science and Technology, Dalian Maritime University, Dalian, China","2010 2nd International Conference on Computer Engineering and Technology","17 Jun 2010","2010","6","","V6-341","V6-345","This paper presented a methodology of interaction between hand and a virtual object based on augmented reality during the procedure of virtual assembly. The effective size of the grasped object is proposed to match with the flexion of the hand during the procedure of the grasping. Meanwhile, the method for judging the motion of grasping occurrence, recognizing user's intention of assembling and detecting the geometrical congruence of the components is discussed in detail. The methodology is experimented in virtual assembly and is proved to be efficient for grasping and assembling the virtual component in augmented reality.","","978-1-4244-6349-7","10.1109/ICCET.2010.5486209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486209","virtual assembly;augmented reality;interaction","Assembly;Augmented reality;Layout;Grasping;Power engineering and energy;Space technology;Computer graphics;Humans;Design engineering;Cameras","assembling;augmented reality;user interfaces","virtual assembly interaction;augmented reality;virtual object;virtual component assembling","","3","","11","IEEE","17 Jun 2010","","","IEEE","IEEE Conferences"
"User interface model for Indonesian Animal apps to kid using Augmented Reality","A. Selviany; E. R. Kaburuan; D. Junaedi","School of Computing Telkom University, Bandung, Indonesia; Informatics Department, IDEAS - LAB, Bandung, Indonesia; School of Computing Telkom University, Bandung, Indonesia","2017 International Conference on Orange Technologies (ICOT)","12 Apr 2018","2017","","","134","138","Concentrations possessed on children are minimal compared to adults. It affects the learning patterns for the children. The applied model of learning should be more interesting. The problem that occurs in the study of Indonesian's animals for a child, that children can't imagine or visualize the forms, movements, and sounds of animals. Therefore, it needs other instructional media for learning animal such as smartphone apps. This study is about designing apps for Indonesian Animal Introduction using Augmented Reality Technology. With Augmented reality technology in the apps give a good impact to the child because with AR children can feel the real shape of the animal and can help children to remember and imagine the shape of the object quickly. The approach is taken to design the application prototype is Goal-Directed Design following the needs and goals of users in learning about the animal from Indonesia. The prototype tested its usability level using QUIM. From prototype test results get the value with a percentage of 91%, so it concluded that the usability level of the application of learning to know animals from Indonesia is following the characteristics of early childhood.","","978-1-5386-3276-5","10.1109/ICOT.2017.8336106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336106","Animal Introduction;Augmented Reality;Goal Directed Design;User Interface","Animals;Task analysis;Prototypes;User interfaces;Testing;Augmented reality;Usability","age issues;augmented reality;computer aided instruction;human computer interaction;mobile computing;user interfaces;zoology","user interface model;Indonesian animal apps;learning patterns;child;Indonesian Animal Introduction;Augmented reality technology;instructional media","","3","","6","IEEE","12 Apr 2018","","","IEEE","IEEE Conferences"
"The design of immersive English learning environment using augmented reality","K. -C. Li; C. -W. Tsai; C. -T. Chen; S. -Y. Cheng; J. -S. Heh","Dept. of Information Management; Dept. of Information Management; Dept. of Information Management; Dept. of Information and Computer Engineering, Chung-Yuan Christian University, Taiwan; Dept. of Information and Computer Engineering, Chung-Yuan Christian University, Taiwan","2015 8th International Conference on Ubi-Media Computing (UMEDIA)","15 Oct 2015","2015","","","174","179","The study uses augmented reality (AR) technology to integrate virtual objects into the real learning environment for language learning. The English AR classroom is constructed using the system prototyping method and evaluated by semi-structured in-depth interviews. According to the flow theory by Csikszenmihalyi in 1975 along with the immersive factors from Trevino and Webster in 1992, the proposed system uses the computer information systems with augmented reality technology to create flow experiences and embodied cognition. The effects of the English AR classroom are evaluated by semi-structured in-depth interviews. Based on the opinions of the domain experts, the AR prototype system validates the possibility of carrying out digital immersive language learning and embodied cognition. In addition, the concerns of the curriculum designs based on this system are discussed to show the intension of the practical uses.","","978-1-4673-8270-0","10.1109/UMEDIA.2015.7297450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7297450","Digital Language Learning;Flow theory;Augmented Reality","Education;Computers;Media;Augmented reality;Avatars;Interviews;Internet","augmented reality;computer aided instruction","immersive English learning environment;augmented reality;AR technology;language learning;English AR classroom;system prototyping method;flow theory;immersive factors;computer information systems;embodied cognition;curriculum design","","3","","24","IEEE","15 Oct 2015","","","IEEE","IEEE Conferences"
"An online top-down SSVEP-BMI for augmented reality","J. -W. Kim; M. -N. Kim; D. -H. Kang; M. -H. Ahn; H. -S. Kim; B. -K. Min","Department of Brain and Cognitive Engineering, Korea University, Seoul, Korea; Totalsoftbank Bio-medical Engineering Institute, Busan, Korea; Totalsoftbank Bio-medical Engineering Institute, Busan, Korea; Institute for Brain and Cognitive Engineering, Korea University, Seoul, Korea; Institute for Brain and Cognitive Engineering, Korea University, Seoul, Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, Korea","2019 7th International Winter Conference on Brain-Computer Interface (BCI)","17 Jun 2019","2019","","","1","3","Augmented reality (AR) technology using a head mounted display (HMD) is one of the fundamental tools in the next smart internet of things (IoT) society. Nowadays, portable brain-machine interfaces (BMIs) using an HMD have been studied for the future of BMI interlocked with the present IoT technology. In order to investigate the feasibility of the top-down SSVEP (steady-state visual evoked potential) BMI embedded in an HMD, SSVEP stimuli was presented in a HoloLens (Microsoft) for augmented reality (AR) constructed by holography. Electroencephalogram (EEG) was measured during the top-down SSVEP-based BMI performance, where a grid-shaped flickering visual stimulus was presented in the display of HoloLens. We examined its feasibility in a real-time basis by its decoding accuracy. We found that the top-down SSVEP-BMI could be efficiently embedded in an AR-based HMD, and thus it can be applied for the AR-based device-control automation in an IoT space using EEG signals.","2572-7672","978-1-5386-8116-9","10.1109/IWW-BCI.2019.8737348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737348","BMI;BCI;HoloLens;Augmented Reality;AR;EEG;SSVEP;top-down","Electroencephalography;Augmented reality;Resists;Decoding;Internet of Things;Electrodes;Magnetic heads","augmented reality;brain-computer interfaces;electroencephalography;helmet mounted displays;holographic displays;Internet of Things;medical signal processing;neurophysiology;visual evoked potentials","portable brain-machine interfaces;IoT technology;SSVEP BMI;steady-state visual evoked potential;HoloLens;SSVEP-based BMI performance;IoT space;augmented reality technology;online top-down SSVEP-BMI;head mounted display;smart internet of things society;SSVEP stimuli;electroencephalogram;AR-based HMD;AR-based device-control automation;EEG signals","","3","","8","IEEE","17 Jun 2019","","","IEEE","IEEE Conferences"
"Market potential for a location based and augmented reality system for utilities management","R. J. Perez Jimenez; E. M. -D. Becerril; R. M. Nor; K. Smagas; E. Valari; E. Stylianidis","Research Consultant; Account Executive - Public Sector Andalusia; Researcher - Institute of Social Informatics and Technological Innovations (ISITI); GeoImaging Ltd, Nicosia, Cyprus; GeoImaging Ltd, Nicosia, Cyprus; H2020 LARA Project Coordinator","2016 22nd International Conference on Virtual System & Multimedia (VSMM)","28 Feb 2017","2016","","","1","4","LARA project is an innovative combination of different emerging technologies to develop a hand-held and mobile device that integrates state-of-the-art technologies in the domains of mobility, positioning and sensors (Global Navigation Satellite System - GNSS), Augmented Reality (AR) and 3D Geographic Information System (GIS) geo-databases. The vision of the system is to develop a system that simulates an `x-ray camera' and is able to guide utility field workers to `see beneath the ground' the buried infrastructures. The system renders, in high accuracy 3D models, all the complexity of the different underground grids (water, gas, sewerage, electricity, etc.) that are stored in the 3D GIS geo-database. The project has a clear intention to commercialize the products and services built therefore a detailed market analysis for the system and the definition of the appropriate business models is required. In order to prepare the commercialization strategy of the final location based and augmented reality assistive system, during the project lifetime, all consortium partners are defining and agreeing the marketing strategy and the collaborative business models that best fit system requirements and needs developed through end user workshops and technical consultations. The project has received funding from the European GNSS Agency (GSA) under the European Union's Horizon 2020 research and innovation program; specifically, grant agreement no. 641460.","2474-1485","978-1-4673-8993-8","10.1109/VSMM.2016.7863171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7863171","Location Based Services;LBS;Global Navigation Satellite System;GNSS;Augmented Reality;AR;Geographic Information System;GIS;Geo-database;Mobility;Buried Infrastructures;Underground Grids;Utilities Management;High Accuracy 3D Model;LARA;H2020 Co-funded Project;European GNSS Agency;Collaborative Business Model;Marketing Strategy","Augmented reality;Geographic information systems;Companies;Three-dimensional displays;Commercialization;Europe;Global Positioning System","augmented reality;business data processing;geographic information systems;geophysical image processing;groupware;image registration;mobile computing;public utilities;rendering (computer graphics);satellite navigation;solid modelling;visual databases","market potential;location based services;augmented reality assistive system;utilities management;LARA project;mobile device;mobility domains;positioning;sensors;global navigation satellite system;GNSS;3D geographic information system geodatabase;3D GIS geodatabase;X-ray camera;system renders;3D models;business models;image based registration camera","","3","","11","IEEE","28 Feb 2017","","","IEEE","IEEE Conferences"
"Augmented Reality-based application to foster sustainable agriculture in the context of aquaponics","J. Garzón; S. Baldiris; J. Acevedo; J. Pavón",Universidad Católica de Oriente; Universidad Internacional de la Rioja; Universidad Católica de Oriente; Universidad Complutense de Madrid,"2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)","4 Aug 2020","2020","","","316","318","Population growth implies the need to produce more food. This increases pressure on the planet’s resources, which drives climate change and challenges environmental sustainability. Hence, it is important to promote sustainable agriculture strategies that contribute to global food and nutrition security while protecting natural resources. These strategies should be guided from an educational perspective that motivates people to develop positive bonds with nature. In this regard, augmented reality has emerged as a technology with the potential to improve environmental education programs. This paper presents the development and evaluation of an augmented reality-based educational application, whose purpose is to foster sustainable agriculture in the context of aquaponics. The application was developed using Unity and Vuforia following the principles of instructional design. To evaluate the effectiveness of the application, we designed a pilot study with 10 volunteers. The results indicate that the application has the potential to motivate users to learn, which suggests that it is appropriate to foster sustainable agriculture strategies in the context of aquaponics.","2161-377X","978-1-7281-6090-0","10.1109/ICALT49669.2020.00101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156064","aquaponics;augmented reality;environmental education;sustainable agriculture","Agriculture;Education;Augmented reality;Climate change;Software;Sociology;Statistics","agriculture;augmented reality;climate mitigation;computer aided instruction;environmental factors;natural resources;sustainable development","educational perspective;environmental education programs;aquaponics;climate change;nutrition security;augmented reality;sustainable agriculture;environmental sustainability;food security;natural resources protection;Unity;Vuforia","","3","","15","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"ARC: Augmented Reality for Catering","L. B. Cassar; F. Inguanez","Institute of Information & Communication Technology, University College Malta College of Arts, Science & Technology, Paola, Malta; Institute of Information & Communication Technology, University College Malta College of Arts, Science & Technology, Paola, Malta","2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)","16 Dec 2018","2018","","","1","5","Augmented reality is establishing itself evermore as a fundamental tool in the modern world, not only as a recreational tool but also in the educational, medical and tourism sectors. In this research we demonstrate how to have an industry level augmentable representation of meals, propose a solution for customers to place orders in a modern restaurant, and gathered feedback. In this research we had to use different techniques such as laser scanning and photogrammetry, utilising Unity, Vuforia and Remake. Having demonstrated our prototype and surveyed around 70 individuals and interviewed a restaurant owner we are confident that Augmented Reality can really be a great tool in the catering industry.","2166-6822","978-1-5386-6095-9","10.1109/ICCE-Berlin.2018.8576165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576165","augmented reality;catering;photogeometry","Smart phones;Business;Cameras;Augmented reality;Three-dimensional displays;Laser modes;Solid modeling","augmented reality;catering industry;photogrammetry;travel industry","recreational tool;educational tourism sectors;medical tourism sectors;modern restaurant;catering industry;augmented reality;photogrammetry;laser scanning;Unity;Vuforia;Remake","","3","","14","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Artificial Intelligence and Augmented Reality driven Home Automation","A. Natarajan; A. Saideep; K. S. Reddy","Department of ECE, Guru Nanak Institute of Technology, Hyderabad, India; Department of ECE, Guru Nanak Institute of Technology, Hyderabad, India; Department of ECE, Guru Nanak Institute of Technology, Hyderabad, India","2020 International Conference on Electronics and Sustainable Communication Systems (ICESC)","4 Aug 2020","2020","","","23","28","Living in an age of rapid digitization where technology has infiltrated every field there is, and our homes are no different. Internet of Things, Artificial Intelligence and Augmented Reality are in the boom, now more so than ever, highly popular among both giant corporations and aspiring young engineers, especially because of the continuous experimentations that are being done and the success it has been garnering. In this project, Raspberry Pi is the heart of the setup, to which various electronic components are connected. By giving voice-activated commands, you can remotely operate them with just the use of your smartphone, this setup also includes a Gas sensor which will effectively detect any leakage of cooking gas and promptly inform the residents of the house with a voice alert and turns on the exhaust automatically; Doors that can open or shut as and when you wish. Taking this to a whole another level is the use of Augmented Reality by Image Processing-through which we are able to simply point our smartphone at an object, which will be processed, recognized, matched to the database and correspondingly be able to perform either of the toggle operations. Our major goal was aimed at making this project accessible to everybody despite any physical shortcomings or impediments.","","978-1-7281-4108-4","10.1109/ICESC48915.2020.9155916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155916","Internet of Things;Artificial Intelligence;Augmented Reality;Home Automation","Artificial intelligence;Augmented reality;Home automation;Internet of Things;Image processing;Smart phones;Conferences","artificial intelligence;augmented reality;gas sensors;home automation;image processing;Internet of Things;smart phones","cooking gas;toggle operations;image processing;voice alert;Gas sensor;smartphone;voice-activated commands;Raspberry Pi;aspiring young engineers;giant corporations;internet of Things;rapid digitization;home automation;Augmented Reality;Artificial Intelligence","","3","","16","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Assembly instruction with augmented reality on Android application “assembly with AR”","I. E. Nugraha; T. W. Sen; R. B. Wahyu; B. Sulistyo; Rosalina","Faculty of Computing, President University, Cikarang, Bekasi, Indonesia; Faculty of Computing, President University, Cikarang, Bekasi, Indonesia; Faculty of Computing, President University, Cikarang, Bekasi, Indonesia; Faculty of Computing, President University, Cikarang, Bekasi, Indonesia; Faculty of Computing, President University, Cikarang, Bekasi, Indonesia","2017 4th International Conference on New Media Studies (CONMEDIA)","22 Jan 2018","2017","","","32","37","Assembly instruction is an activity of collecting or grouping parts/objects/components that fit together to form a self-contained unit through assembly operations. Conventional object assembly instruction were usually illustrated in a paper manual. In this paper, augmented reality is presented for a user to interact with objects and proposed for enhancing assembly task. Augmented Reality (AR) integrates virtual information (computer graphics, text, sound) into the physical environment so that the user can percieve that information as existing in real life. Assembly with AR is the application that provides virtual 3D model and combine it into real live environment using their smartphone to help people who sometimes have a problem with the assembly instruction. The 3D model will be shown on the target marker which is the marker and the tracker for the model. By using this application, the users now will be able to see the models and its animation in other perspectives by moving around the target marker.","","978-1-5090-6284-3","10.1109/CONMEDIA.2017.8266027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8266027","assembly intruction;augmented reality;android","Three-dimensional displays;Solid modeling;Augmented reality;Animation;Cameras;Engines;Real-time systems","Android (operating system);augmented reality;mobile computing;smart phones","augmented reality;assembly operations;conventional object assembly instruction;assembly task;Android application;virtual information;physical environment;virtual 3D model;smartphone;target marker;animation","","3","","9","IEEE","22 Jan 2018","","","IEEE","IEEE Conferences"
"Augmented Reality in Web: Results and Challenges","R. Timchenko; O. Grechnyev; S. Skuratovskyi; Y. Chyrka; I. Gorovyi","It-Jim, Kharkiv, Ukraine; It-Jim, Kharkiv, Ukraine; It-Jim, Kharkiv, Ukraine; It-Jim, Kharkiv, Ukraine; It-Jim, Kharkiv, Ukraine","2020 IEEE Third International Conference on Data Stream Mining & Processing (DSMP)","23 Sep 2020","2020","","","211","216","The paper presents basic concepts of augmented reality applications and challenges in building them in the web. We describe the technical and algorithmic stack required to develop, implement and deploy the augmented reality application. Theoretical concepts behind marker detection and tracking are discussed. Two different pipelines are implemented: server-based with algorithms execution in the cloud and completely front-end solution that runs on a user device. We show advantages and disadvantages of each approach and analyze experimental results as well.","","978-1-7281-3214-3","10.1109/DSMP47368.2020.9204240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204240","augmented reality;visual tracking;image marker;webAR","Cameras;Pipelines;Three-dimensional displays;Transmission line matrix methods;Augmented reality;Solid modeling;Browsers","augmented reality;client-server systems;cloud computing","marker detection;algorithm execution;augmented reality application;technical stack;algorithmic stack;marker tracking","","2","","29","IEEE","23 Sep 2020","","","IEEE","IEEE Conferences"
"Application of Augmented Reality Technology in the Study of Electrical Engineering","N. S. Rigenkov; V. N. Tulsky; S. V. Borisova","National Research University “Moscow Power Engineering Institute”, Moscow, Russia; National Research University “Moscow Power Engineering Institute”, Moscow, Russia; National Research University “Moscow Power Engineering Institute”, Moscow, Russia","2018 IV International Conference on Information Technologies in Engineering Education (Inforino)","20 Dec 2018","2018","","","1","4","The article deals with the technology of augmented reality in relation to the process of teaching students. The application of this approach in the development of manuals and methodical materials is shown on the example of studying of work of the transformer. Developed mobile application for smartphone with Android operating system that visualizes the operation of the transformer with the help of augmented reality. Physical processes are shown with the help of animation and 3D models.","","978-1-5386-5832-1","10.1109/INFORINO.2018.8581764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8581764","augmented reality;transformer;electrical engineering;mobile application;3D models","Augmented reality;Windings;Three-dimensional displays;Operating systems;Solid modeling;Electrical engineering;Engines","Android (operating system);augmented reality;computer aided instruction;data visualisation;electrical engineering education;mobile computing;smart phones;teaching","transformer;Android operating system;augmented reality technology;electrical engineering;teaching students;mobile application","","2","","8","IEEE","20 Dec 2018","","","IEEE","IEEE Conferences"
"Augmented reality “Another level of education”","S. Alvarado; W. Gonzalez; T. Guarda","Universidad Estatal Peninsula de Santa Elena, Santa Elena, Santa Elena, EC; Universidad Estatal Peninsula de Santa Elena, Santa Elena, Santa Elena, EC; Universidad Estatal Peninsula de Santa Elena, Santa Elena, Santa Elena, EC","2018 13th Iberian Conference on Information Systems and Technologies (CISTI)","28 Jun 2018","2018","","","1","5","Secondary Education is one of the bases for academic excellence, despite this there are certain difficulties in understanding textbooks based on their content and the low motivation of reading. However, we have a technology, which is the Augmented Reality, which has gradually developed within the field of education, revolutionizing new teaching methods along with their learning processes, facilitating an understanding of complex factors in education, through a graphic representation of images based on real world information. In this work we link the Augmented Reality within the knowledge environment in Secondary Education, and its influence on academic performance, showing how the manipulation of virtual objects is done as if it were a real one.","","978-989-98434-8-6","10.23919/CISTI.2018.8399331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8399331","Education;New Technologies;Augmented Reality;Academic Performance","Education;Augmented reality;Three-dimensional displays;Silicon compounds;Visualization;Solid modeling;Biological system modeling","augmented reality;computer aided instruction;teaching","academic excellence;academic performance;augmented reality;secondary education;textbooks;learning processes;images graphical representation;virtual objects manipulation;teaching methods","","2","","","","28 Jun 2018","","","IEEE","IEEE Conferences"
"An imitation of 3D projection mapping using augmented reality and shader effects","H. -y. Pai","Department of Multimedia Design, National Formosa University, Yunlin County, Taiwan","2016 International Conference on Applied System Innovation (ICASI)","11 Aug 2016","2016","","","1","4","Nowadays, 3D projection mapping is known for amazing visual performance, and animated content on a structure or building has become very popular for larger brands and corporate campaigns. Because it is limited by the environment and the lighting, the cost can be still high for a person to own a combination of high-lumen projectors and a Multi-projector Seamless Display System. In this paper, we want to pay attention to the visual effect part of Augmented Reality (AR) applications and imitate 3D projection mapping by using the technologies of augmented reality and shader effects. We present an AR framework that uses the shading control technique to make AR scene as realistically as 3D projection mapping as possible. This framework offers people a more convenient way of accessing 3D projection mapping experiences on their mobile devices. The prototypes based on these techniques show the advantages and disadvantages of the technologies while superimposing virtual objects onto a real picture.","","978-1-4673-9888-6","10.1109/ICASI.2016.7539879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539879","Augmented Reality;3d Projection Mapping;Shader;Non-Photorealistic Rendering","Decision support systems;Three-dimensional displays;XML;Load modeling;Solid modeling;Databases;Augmented reality","augmented reality;mobile computing;optical projectors","3D projection mapping;augmented reality;shader effects;amazing visual performance;animated content;corporate campaigns;high-lumen projectors;multiprojector seamless display system;AR applications;AR framework;shading control;AR scene;mobile devices;superimposing virtual objects","","2","","8","IEEE","11 Aug 2016","","","IEEE","IEEE Conferences"
"Handheld augmented reality supported immersive ubiquitous learning system","T. -Y. Liu; Y. -L. Chu","Lunghwa University of Science and Technology, Taoyuan, Taiwan; Taipei Municipal Chengyuan High School, Taipei, Taiwan","2008 IEEE International Conference on Systems, Man and Cybernetics","7 Apr 2009","2008","","","2454","2458","This paper reports a study that aims to construct a handheld augmented reality supported ubiquitous learning system, called HELLO (Handheld English Language Learning Organization), to enhance students' English learning. The HELLO integrates the sensor, augmented reality, ubiquitous computing and information technologies, and consists of two subsystems: an English learning management system and learning tools. A case study of English learning was conducted in junior high school. The evaluation result reveals that the proposed system can improve learning.","1062-922X","978-1-4244-2383-5","10.1109/ICSMC.2008.4811663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811663","English learning;immersive learning;ubiquitous learning;2D barcode;augmented reality","Augmented reality;Learning systems;Natural languages;Mobile computing;Educational institutions;Handheld computers;Ubiquitous computing;Personal digital assistants;Pervasive computing;Information technology","augmented reality;computer aided instruction;natural languages;ubiquitous computing","handheld augmented reality;ubiquitous learning;Handheld English Language Learning Organization;English learning management system","","2","","15","IEEE","7 Apr 2009","","","IEEE","IEEE Conferences"
"Development of Adaptive Information Visualization Systems with Augmented Reality","E. R. Zorzal; C. A. R. d. Sousa; A. Cardoso; C. Kirner; E. A. Lamouner; M. G. Quiles","Institute of Science and Technology Federal University of São Paulo (UNIFESP), São José dos Campos, Brazil; Universidade de Sao Paulo, Sao Paulo, SÃ£o Paulo, BR; Department of Electrical Engineering, Federal University of Uberlândia (UFU), Uberlândia, Brazil; Department of Mathematics and Computer Science, Federal University of Itajubá (UNIFEI), Itajubá, Brazil; Universidade Federal de Uberlandia, Uberlandia, MG, BR; Institute of Science and Technology Federal University of São Paulo (UNIFESP), São José dos Campos, Brazil","2014 18th International Conference on Information Visualisation","22 Sep 2014","2014","","","211","216","Augmented Reality combined with adaptive hypermedia plays an important role on providing effective information visualization systems. In this paper, we propose a comprehensive architecture model in order to provide adaptive information visualization systems with augmented reality. We also provide a novel visual metaphor for real-valued, low-dimensional data with optimal values for each feature inspired on the pseudo-flower metaphor.","2375-0138","978-1-4799-4103-2","10.1109/IV.2014.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6902905","Augmented reality;adaptive systems;information visualization;system architecture","Adaptation models;Data visualization;Navigation;Augmented reality;Visualization;Adaptive systems;Image color analysis","augmented reality;data visualisation;hypermedia;software architecture","adaptive information visualization systems;augmented reality;adaptive hypermedia;comprehensive architecture;pseudo-flower metaphor","","2","","15","IEEE","22 Sep 2014","","","IEEE","IEEE Conferences"
"Product Application to Recognize the Marker Through Augmented Reality","S. Bhakar; D. Pallavi Bhatt","Department of Computer Science, Manipal University of Jaipur, Jaipur, India; Department of Computer Science, Manipal University of Jaipur, Jaipur, India","2019 6th International Conference on Signal Processing and Integrated Networks (SPIN)","13 May 2019","2019","","","594","601","This paper presents a methodology to recognize the matrix marker at minimum latency time. Latency is the biggest challenge in the field of Augmented Reality (AR). Marker detection approach in AR has been conducted for several years, but there is no system or method to reduce the latency. Although, currently some methods use marker-less augmented reality system, but complexity in detection process, the marker based recognise approach is proposed. Here, we propose matrix marker recognise algorithm and mathematical formulation to detect the marker at different distance and luminous conditions. The position and quadrilateral areas which may seem like marker have been processed by posit class & IP prototype tool from Aforge.net framework. Experimental results compare the latency using rectifier, without rectifier and ideal value of system under different distance and luminous conditions.","","978-1-7281-1380-7","10.1109/SPIN.2019.8711584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8711584","Marker;Delay;Detection time;Web Camera;Augmented reality","Augmented reality;Cameras;Mathematical model;Rectifiers;Robots;Servomotors;Image color analysis","augmented reality;object detection;object recognition","minimum latency time;marker detection approach;detection process;matrix marker recognise algorithm;Aforge.net framework;marker-less augmented reality system;product application","","2","","20","IEEE","13 May 2019","","","IEEE","IEEE Conferences"
"Augmented reality system for maintenance of high-voltage systems","R. Oliveira; J. T. Farinha; I. Fonseca; F. M. Barbosa","CEMUC, Portugal; ISEC, Portugal; ISEC, Portugal; FEUP & INESC, Porto","2016 51st International Universities Power Engineering Conference (UPEC)","20 Nov 2017","2016","","","1","5","Augmented Reality (AR) promises to revolution the maintenance field in general with relevant contributions to High-Voltage Systems. The value-added can came from several aspects, namely the increasing security and reducing time and costs of intervention. However there are some aspects related to AR state-of-the-art that do not permit yet to reach all of their potential, namely the necessity of use of markers in many situations and the necessity of 3D modeling for markeless situations. These are the main aspects presented in this paper as well as the nowadays main trends. Several experiments are also detailed and referenced to attest the benefits and actual restrictions and gaps of Augmented Reality applied on industrial scenarios. Close to teleoperations, it is demonstrated how solutions that combine virtual and real scenes may improve technicians' performance and reduce the risk of fatal accidents by improving training conditions.","","978-1-5090-4650-8","10.1109/UPEC.2016.8114019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114019","Maintenance engineering;Augmented reality;Power industry;Training;Power system simulation","Training;Maintenance engineering;Augmented reality;Electric potential;Three-dimensional displays;Tools;Accidents","augmented reality;high-voltage engineering;power engineering computing;power system management;power system reliability","Augmented reality system;high-voltage system maintenance","","2","","19","IEEE","20 Nov 2017","","","IEEE","IEEE Conferences"
"Augmented Reality on Construction Sites Using a Smartphone-Application","K. Kirchbach",Karlsruhe Institute of Technology,"2013 17th International Conference on Information Visualisation","2 Dec 2013","2013","","","398","403","Civil Engineering is characterized by the ineffectiveness of production planning and control. The origins of these problems lie in unclear and late information. Augmented Reality (AR) can tackle these problems and help to improve the information flow. This paper describes the benefits of Augmented Reality on construction sites and introduces a smartphone application for an intuitive information retrieval on construction sites. It explains the structure of the application, especially the mathematical calculation of the AR view, and demonstrates its use in a practical case.","2375-0138","978-0-7695-5049-7","10.1109/IV.2013.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676592","augmented reality;visualisation;smartphone;construction site;information flow","Buildings;Vehicles;Augmented reality;Sensors;Global Positioning System;Earth;Mobile communication","augmented reality;civil engineering computing;construction industry;information retrieval;mobile computing;smart phones","augmented reality;construction sites;smart phone;civil engineering;production planning;information flow;intuitive information retrieval","","2","","34","IEEE","2 Dec 2013","","","IEEE","IEEE Conferences"
"Augmented reality as an educational tool of M-learning focused on architecture and urban planning","A. Mesárošová; M. F. Hernandez; P. Mesároš","Universidad Politécnica de Valencia/Facultad de Bellas Artes, Valencia, Spain; Universidad Politécnica de Valencia/Facultad de Bellas Artes, Valencia, Spain; Technical University of Košice/Civil Engineering Faculty, Research Institute of ICT in Construction, Ltd., Košice, Slovakia","2014 IEEE 12th IEEE International Conference on Emerging eLearning Technologies and Applications (ICETA)","14 May 2015","2014","","","325","330","This paper presents Augmented Reality as a tool for educational tool used for teaching of subject like history, chemistry or ecology as well as the original Augmented Reality tool centered on education in the field of the architecture and urban planning.","","978-1-4799-7740-6","10.1109/ICETA.2014.7107605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7107605","Augmented Reality;M-learning;hybrid urban space","Augmented reality;Mobile handsets;Mobile communication;Electronic learning;Cities and towns;Computer architecture","architecture;augmented reality;computer aided instruction;mobile learning;teaching;town and country planning","augmented reality;educational tool;architecture;urban planning;m-learning;history teaching;chemistry teaching;ecology teaching","","2","2","12","IEEE","14 May 2015","","","IEEE","IEEE Conferences"
"AST[AR] – Towards Using Augmented Reality and Abstract Syntax Trees for Teaching Data Structures To Novice Programmers","V. Agrahari; S. Chimalakonda","Research in Intelligent Software & Human(RISHA) Lab, Indian Institute of Technology Tirupati, India; Research in Intelligent Software & Human(RISHA) Lab, Indian Institute of Technology Tirupati, India","2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)","4 Aug 2020","2020","","","311","315","Augmented Reality (AR) is one of the emerging technologies which helps in enhancing user experience by providing a composite view of the real-world objects. It supports the user with superimposed information on top of the object, thus creating a live experience. Besides, coding is pervasive in today's world, and there is a strong need for well-equipped developers with thorough theoretical and practical knowledge. Data Structures and Abstract Syntax Trees are two of the fundamental topics of the computer science domain. Data structures help in the organization of data, whereas, Abstract Syntax Trees (ASTs) enable better comprehension of source code by syntactically analyzing it. In this paper, we propose an augmented reality-based software application AST[AR] to teach data structures with the help of ASTs. We conducted a user experience study with 30 volunteers and got positive feedback from 80.6% of the participants. We believe that this software application will help in bifold learning of data structures as well as ASTs with exciting and enjoyable user experience.","2161-377X","978-1-7281-6090-0","10.1109/ICALT49669.2020.00100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155868","Augmented Reality;Abstract Syntax Trees;Data Structures;Software Application","Data structures;Syntactics;Image color analysis;Augmented reality;Software;Education","augmented reality;computer aided instruction;computer science education;data structures;teaching","Abstract Syntax Trees;augmented reality-based software application AST;user experience study;exciting user experience;enjoyable user experience;teaching data Structures;real-world objects;live experience","","2","","20","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"A Context-Aware Progressive Inquiry-Based Augmented Reality System to Improving Students' Investigation Learning Abilities for High School Geography Courses","H. -C. Chu; Y. -H. Sung","Department of Computer Science and Information Management, Soochow University, Taipei, Taiwan; Department of Computer Science and Information Management, Soochow University, Taipei, Taiwan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","1 Sep 2016","2016","","","353","356","Engaging students in constructing their knowledge during real-world observation and inquiry-based learning activities has been recognized as an important issue for improving students' learning achievement and motivation. However, researchers have indicated that due to a lack of effectively connection between observation in real-world and inquiry problems, it is a challenge to lead an effective outdoor inquiry-based learning activity. In this study, a progressive inquiry-based approach with augmented reality technology is proposed for improving students' high-level thinking and problem solving abilities by asking students to answer different layer of questions in in-field inquiry learning activities. An experiment will be conducted to evaluate its performance on high school geography courses. A total of 60 first-grade high school students from two classes will participant in this experiment. The students in the experimental group will learn with the progressive inquiry-based augmented reality system, while those in the control group will learn with the conventional AR contextual u-learning approaches. The students' learning achievements, learning attitudes, learning motivation, and problem solving ability will be investigated after the experiment. It is expected that the proposed approach will effectively enhance the students' learning achievement in comparison with the control group.","","978-1-4673-8985-3","10.1109/IIAI-AAI.2016.112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557632","progressive inquiry-based learning;augmented reality;context-aware u-learning;geography course","Education;Augmented reality;Computers;Problem-solving;Geography;Mobile communication;Context","augmented reality;computer aided instruction;educational courses;geography;ubiquitous computing","learning motivation;learning attitudes;AR contextual u-learning approaches;in-field inquiry learning activities;problem solving abilities;student high-level thinking;progressive inquiry-based approach;outdoor inquiry-based learning activity;student learning achievement;real-world observation;high school geography courses;student investigation learning abilities;context-aware progressive inquiry-based augmented reality system","","2","","31","IEEE","1 Sep 2016","","","IEEE","IEEE Conferences"
"Improvement of occupational safety systems by the aplication of augmented reality technologies","D. Tatić; B. Tešić","Univerzitet u Nisu, Nis, RS; Rudnik i termoelektrana Ugljevik, Bosna i Hrecegovina","2015 23rd Telecommunications Forum Telfor (TELFOR)","11 Jan 2016","2015","","","962","965","The paper explores possibilities for application of Augmented reality technologies in systems for occupational safety in the technological process of Power plant Ugljevik. We first analyze factors specific for this technological process and then specify and define factors that cause the increase of risk in the work at particular work places. The specified sources of risk and an estimate of their influence to the total risk are a basis upon which the necessary protection measures are defined including both the organizational and technical aspects of the related procedures. It is proposed an improvement of the occupational safety systems by the usage of Augmented Reality (AR) technologies. As a case study, it is developed the occupational safety system for the work at the universal lathe that is an element of the technological process at the Power plant Ugljevik.","","978-1-5090-0055-5","10.1109/TELFOR.2015.7377625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377625","proširena stvarnost;augmented reality;zaštita na radu;mobilni sistemi","Augmented reality;Postal services;Three-dimensional displays;Telecommunications;Buildings;Solid modeling;Androids","augmented reality;occupational safety;power engineering computing;power plants;power system protection;risk management","occupational safety system improvement;augmented reality technology aplication;power plant Ugljevik technological process;universal lathe;source risk","","2","","","IEEE","11 Jan 2016","","","IEEE","IEEE Conferences"
"NHE: Collaborative Virtual Environment with Augmented Reality on Web","A. C. M. Tavares; S. M. M. Fernandes; M. Lencastre P. de Menezes Cruz","Department of Computer Science, University of Pernambuco (UPE), Recife, Pernambuco, Brazil; Department of Computer Science, University of Pernambuco (UPE), Recife, Pernambuco, Brazil; Department of Computer Science, University of Pernambuco (UPE), Recife, Pernambuco, Brazil","2010 International Conference on Cyberworlds","3 Dec 2010","2010","","","438","444","Interfaces in two dimensions, like buttons and menus, are been used for 35 years. Technologies have been developed to extend interfaces for tridimensional environment. One of them, called Augmented Reality, is being viewed due to the ease on interaction with the virtual environment. By other side, due to complexity of human tasks, people are getting together to perform tasks through collaborative groups, named groupware. This article proposes a system that does collaboration and has easy interactivity and immersion, by using augmented reality resources. This integration is not so easy to find out on current market, and it is a great motivation for this innovation. The project can help several areas like, for example, distance education, engineering, architecture and marketing. Results show the viability of the system, and its efficiency in applications that needs easy manipulation of projects and high degree of immersion of users, offering facility to activities at real time, without network congestion and in a collaborative way.","","978-1-4244-8301-3","10.1109/CW.2010.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5656154","Virtual Collaborative Spaces;Networked Collaboration;Computer vision;augmented;mixed and virtual reality","Servers;Augmented reality;Collaboration;Computers;Software;Browsers;Databases","augmented reality;groupware;user interfaces","NHE;collaborative virtual environment;augmented reality;tridimensional environment;virtual environment;collaborative groups;distance education;network congestion;collaborative way","","2","","15","IEEE","3 Dec 2010","","","IEEE","IEEE Conferences"
"Registration with linear regression model in augmented reality","D. -y. Ma; Y. -m. Chen; Q. -m. Li; C. Huang; S. Xu; Y. -b. Zou","Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, Shanghai, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, Shanghai, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, Shanghai, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, Shanghai, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, Shanghai, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, Shanghai, China","2011 IEEE International Conference on Computer Science and Automation Engineering","14 Jul 2011","2011","2","","520","523","Precise registration is very important in augmented reality. The magnetic tracking is a normal instrument to measure position and orientation. This paper presents a novel registration method with linear regression model in augmented reality. Based on the data, which are measured by the magnetic tracking, a linear regression model is set up. Through the linear regression model, the world coordinate and the magnetic tracking coordinate are one-to-one. The theory analysis and simulation prove the feasibility of this brand new method. The system is more precise and robust with linear regression model.","","978-1-4244-8728-8","10.1109/CSAE.2011.5952521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5952521","Augmented reality;Registration;Linear regression model","Linear regression;Augmented reality;Analytical models;Solid modeling;Interpolation;Real time systems;Maintenance engineering","augmented reality;regression analysis","linear regression model;augmented reality registration;magnetic tracking instrument;world coordinate;magnetic tracking coordinate","","2","","9","IEEE","14 Jul 2011","","","IEEE","IEEE Conferences"
"Design of an Augmented Reality-based Application for Quito’s Historic Center","D. Alulema; B. Simbaña; C. Vega; D. Morocho; A. Ibarra; V. Alulema","Departamento de Eléctrica, Electrónica Universidad de las Fuerzas Armadas ESPE Sangolquí, Ecuador; Departamento de Eléctrica, Electrónica Universidad de las Fuerzas Armadas ESPE Sangolquí, Ecuador; Departamento de Eléctrica, Electrónica Universidad de las Fuerzas Armadas ESPE Sangolquí, Ecuador; Departamento de Eléctrica, Electrónica Universidad de las Fuerzas Armadas ESPE Sangolquí, Ecuador; Departamento de Eléctrica, Electrónica Universidad de las Fuerzas Armadas ESPE Sangolquí, Ecuador; Departamento de Eléctrica, Electrónica Universidad de las Fuerzas Armadas ESPE Sangolquí, Ecuador","2018 IEEE Biennial Congress of Argentina (ARGENCON)","21 Feb 2019","2018","","","1","5","The following paper presents an application for Android devices which involves Augmented Reality. This application shows the user data and information regarding heritage buildings of Quito's Historic Center, which can be useful to tourists that visit the city. Moreover, the application is compatible with Android devices running 3.0 Honeycomb version or later, and it was developed on the programming languages JAVA and HTML. The information is collected through a database using a web service. To work with Augmented Reality the SDK Wikitude was used, because it allows the development of applications based on geolocation and benefits such as student licenses. The interfaces were developed using the programming languages JavaScript and HTML. Finally, a series of tests were done to validate the application's functions like memory, mobile data consumption and Wi-Fi.","","978-1-5386-5032-5","10.1109/ARGENCON.2018.8646296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8646296","component;Augmented Reality;Web Services;Java;MySQL;Android","Augmented reality;Smart phones;Random access memory;Cameras;Databases;Web services","augmented reality;buildings (structures);history;Java;mobile computing;smart phones;user interfaces;Web services","Android devices;user data;heritage buildings;interface development;SDK Wikitude;JavaScript;Web service;Quito Historic Center;augmented reality-based application;programming languages;HTML","","2","","5","IEEE","21 Feb 2019","","","IEEE","IEEE Conferences"
"Geobook: Mobile App with Augmented Reality for Learning Geometry","J. P. Cruzado; T. L. Céspedes; G. P. Bohorquez Coria; J. L. Herrera Salazar","Faculty of Engineering, Autonoma University of Peru, Lima, Peru; Faculty of Engineering, Autonoma University of Peru, Lima, Peru; Faculty of Engineering, Autonoma University of Peru, Lima, Peru; Faculty of Engineering, Autonoma University of Peru, Lima, Peru","2020 IEEE Engineering International Research Conference (EIRCON)","17 Nov 2020","2020","","","1","4","This study shows the results obtained after the application of augmented reality - AR in the learning of descriptive geometry in elementary level students. The use of Mobile-D methodology facilitated the rapid development of mobile applications with augmented reality called Geobook. The statistical sample involved two sections in 6th-grade elementary school students from a public school in Lima city, where the experimental group improved by 82.18% with respect to the learning levels of the control group. It is concluded that the use of an AR-based mobile application significantly enhances learning in three aspects of descriptive geometry, included in the experimental and test dimensions.","","978-1-7281-8367-1","10.1109/EIRCON51178.2020.9253759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9253759","augmented reality;learning;geometry","Geometry;Conferences;Urban areas;Mobile applications;Augmented reality","augmented reality;computer aided instruction;geometry;mobile computing","learning levels;public school;6th-grade elementary school students;statistical sampling;Mobile-D methodology;elementary level students;descriptive geometry;augmented reality;geometry learning;Mobile app;Geobook","","2","","10","IEEE","17 Nov 2020","","","IEEE","IEEE Conferences"
"Assessment of communicative learning via Augmented Reality versus traditional method for aeronautical transportation","F. Suárez-Warden; C. Yocelin; G. M. Eduardo","ITESM-campus Monterrey (Monterrey Tech). Centro de innovación en diseño y tecnología (CIDYT), Aerospace Competence Development Center (ACDC). Cátedra de investigación en Máquinas Inteligentes, Av. Eugenio Garza Sada 2501, NL. 64849. MEXICO; ITESM-campus Monterrey (Monterrey Tech). Centro de innovación en diseño y tecnología (CIDYT), Aerospace Competence Development Center (ACDC). Cátedra de investigación en Máquinas Inteligentes, Av. Eugenio Garza Sada 2501, NL. 64849. MEXICO; ITESM-campus Monterrey (Monterrey Tech). Centro de innovación en diseño y tecnología (CIDYT), Aerospace Competence Development Center (ACDC). Cátedra de investigación en Máquinas Inteligentes, Av. Eugenio Garza Sada 2501, NL. 64849. MEXICO","2011 13th International Conference on Transparent Optical Networks","1 Aug 2011","2011","","","1","4","Advances in Augmented Reality (AR) applied to learning the assembly operation for Maintenance and Repair Operations (MRO), in terms of productivity, must certainly be evaluated. Having this in mind, we propose a congruent sequence of statistical procedures that lead us to our target of comparing the hypotheses for the mean time of training via Augmented Reality (AR) versus traditional method, in an aeronautical case of assembly of a component. We are going to do this because we think AR techniques provide an advanced and advantageous achievement in productivity for getting the training process. It has been endeavors to determine the work sample size for small sample cases at aeronautical sector with significance level (α) of 1%. Based on a good estimation of sample size (n), we determined the combined standard deviation ŝ which is required in the application of the Student t distribution. This distribution is used to perform our test of hypotheses: the learning via AR is faster than that acquired by mean of traditional method for a case of assembly of an aeronautical component using a RV-10 airplane kit.","2161-2064","978-1-4577-0882-4","10.1109/ICTON.2011.5970860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5970860","Augmented Reality (AR);Test of Hypotheses;Student t distribution;Maintenance and Repair Operations (MRO)","Training;Maintenance engineering;Augmented reality;Assembly;Atmospheric modeling;Data models;Estimation","aerospace computing;augmented reality;learning (artificial intelligence)","communicative learning assessment;augmented reality;aeronautical transportation;aeronautical component;RV-10 airplane kit","","2","","9","IEEE","1 Aug 2011","","","IEEE","IEEE Conferences"
"Shooting simulator system design based on augmented reality","K. T. Martono; O. D. Nurhayati","Computer Engineering Department, Diponegoro University, Semarang, Indonesia; Computer Engineering Department, Diponegoro University, Semarang, Indonesia","2016 3rd International Conference on Information Technology, Computer, and Electrical Engineering (ICITACEE)","6 Apr 2017","2016","","","377","382","Development of computer technology today has a major role in the development process of interaction in computer-based applications. Various innovations in creating the user experience of applications began are increasing. Augmented reality is a technology model the interaction between humans and computers by using a model of a merger between the real world with the virtual world. This development certainly can help people or community in various fields, especially in the field of shooting. Shooting is one of the many activities carried out by members of the TNI, POLRI and PERBAKIN. Activities in course are requires skill and a good psychological condition. To obtain good craftsmanship, each member takes a routine of training activities. Computer graphics technology is use in the process of shooting practice. This process utilizes Augmented Reality technology roles. With this technology in practice shooting environment can be created artificially or virtually. Methodology used in this research is system software of development, it is called waterfall model. The use of this method is to generate a reliable system so that the system can work according to the needs. Based on testing the functionality of the system has meet the initial needs, the system works in accordance with the scenario. The minimum distance of the camera to the marker to be recognized is 20 cm and the maximum distance is 300 cm.","","978-1-5090-0890-2","10.1109/ICITACEE.2016.7892475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892475","shooting;Augmented Reality;marker;Computer graphics","Computers;Cameras;Augmented reality;Libraries;Testing;Three-dimensional displays;Computational modeling","augmented reality;computer graphics;digital simulation;police data processing","shooting simulator system design;augmented reality;computer technology development;computer-based applications;virtual world;TNI;POLRI;PERBAKIN;training activities;computer graphics technology;waterfall model","","2","","8","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"The management control system for plant factory that uses the IoT technology in combination with Augmented Reality technology","T. -H. Wang; X. -R. Dai; P. -Y. Wang; Y. -X. Hong; Z. -X. Su; S. -W. Gao; S. -L. Wang","Department of Computer Science & Information Engineering, Taipei City University of Science and Technology, Taipei, Taiwan, R.O.C.; Department of Computer Science & Information Engineering, Taipei City University of Science and Technology, Taipei, Taiwan, R.O.C.; Department of Computer Science & Information Engineering, Taipei City University of Science and Technology, Taipei, Taiwan, R.O.C.; Department of Computer Science & Information Engineering, Taipei City University of Science and Technology, Taipei, Taiwan, R.O.C.; Department of Computer Science & Information Engineering, Taipei City University of Science and Technology, Taipei, Taiwan, R.O.C.; Department of Computer Science & Information Engineering, Taipei City University of Science and Technology, Taipei, Taiwan, R.O.C.; Department of Computer Science & Information Engineering, Taipei City University of Science and Technology, Taipei, Taiwan, R.O.C.","2020 International Symposium on Computer, Consumer and Control (IS3C)","8 Apr 2021","2020","","","1","4","The Internet of Things (IoT) technology is widely used in various fields and continues to develop rapidly. However, the IoT has always been confined to the stage where things are connected by things. This plan applies IoT technology in combination with Augmented Reality(AR) technology into management control system for plant factory. This system includes an environmental parameter monitoring system and a navigation information system. The IoT technology is used to integrate environmental parameters and the status of various equipment in the control parameters to achieve things and things connection. Using augmented reality technology can directly integrate various information Intuitive feedback to the operator that complete the connection between people and things. This project uses the ESP8266 development platform as the main control core of device, The system uses a cloud database to receive, store, and judge information. The WiFi is used for wirelessly transmit data. The ESP8266 development platform is expected to be used in the environmental parameter monitoring system to complete offline sensors and equipment control units. The AR technology is used in the navigation information system to provide real-time interactive information. You can use APP on the mobile device to inquire about the growth analysis and related information of various crops in plant factories in real time. The plan uses IoT technology and AR technology that can reduce the manpower requirements and improve the control performance of plant factories.","","978-1-7281-9362-5","10.1109/IS3C50286.2020.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394013","Internet of Things (IoT);Augmented Reality(AR);plant factory;ESP8266;mobile","Navigation;Production facilities;Real-time systems;Temperature control;Internet of Things;Monitoring;Augmented reality","augmented reality;computerised monitoring;control engineering computing;Internet of Things","navigation information system;plant factory;IoT technology;management control system;augmented reality technology;Things technology;environmental parameter monitoring system;control parameters;things connection;ESP8266 development platform;equipment control units;AR technology","","2","","9","IEEE","8 Apr 2021","","","IEEE","IEEE Conferences"
"A case study: Mobile augmented reality system for visualization of large buildings","T. Rößler; S. Rogge; C. Hentschel","Media Technology, Brandenburg University of Technology, Cottbus, Germany; Media Technology, Brandenburg University of Technology, Cottbus, Germany; Media Technology, Brandenburg University of Technology, Cottbus, Germany","2011 IEEE International Conference on Consumer Electronics -Berlin (ICCE-Berlin)","29 Sep 2011","2011","","","311","314","CE consumer devices are becoming powerful enough to realize augmented reality (AR) systems on mobile devices, and to visualize complex virtual scenes. This is not limited to CE and increasingly demanded for professional applications. One of them is to visualize power transmission lines and their impact on the landscape. This might help discuss diverse opinions and to optimize the planning in various directions. We propose a mobile augmented reality system by utilizing a consumer Tablet-PC. A main task of AR is camera-pose estimation which can be computational intensive. For that reason we decided to use a marker-based approach with four color spheres.","2166-6822","978-1-4577-0234-1","10.1109/ICCE-Berlin.2011.6031827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6031827","augmented reality;outdoor;mobile;real-time visualization","Cameras;Image color analysis;Image edge detection;Estimation;Visualization;Buildings;Augmented reality","augmented reality;consumer products;data visualisation;mobile computing;notebook computers;power transmission lines","mobile augmented reality systems;mobile devices;complex virtual scene;power transmission line visualization;consumer Tablet-PC;camera pose estimation;marker based approach;CE consumer devices","","1","","5","IEEE","29 Sep 2011","","","IEEE","IEEE Conferences"
"Implementation of Hololens2-Based Augmented Reality Technology in Non-automated Warehouse Picking","W. Tang; F. Liu","School of Computer Engineering and Science, Shanghai University, Shanghai, China; School of Computer Engineering and Science, Shanghai University, Shanghai, China","2021 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA)","2 Nov 2021","2021","","","811","815","To solve the problem of low efficiency of picking in non-automated logistics warehousing, this paper proposes an augmented reality application ‐‐ logistics warehousing picking system based on HoloLens 2. In this application, the administrator operates the background management system to manage the background data, and the staff completes the picking according to the visual picking function based on the HoloLens 2 device. In order to verify the effectiveness of the method, the method is implemented and an experiment is carried out. The experimental results show that the picking operation based on HoloLens augmented reality technology is more efficient than that based on traditional paper orders.","","978-1-6654-3561-1","10.1109/AEECA52519.2021.9574354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9574354","Hololens2;Augmented Reality;Non-automated Warehouse;visual picking","Electrical engineering;Visualization;Conferences;Warehousing;Computer applications;Augmented reality;Logistics","augmented reality;logistics;production engineering computing;warehouse automation;warehousing","background data;visual picking function;nonautomated warehouse picking;background management system;HoloLens2-based augmented reality technology;logistics warehousing picking system","","1","","9","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Real-time Recognition and Information Extraction on C++ Syntax with Augmented Reality","J. M. S. Waworundeng; A. K. Wahyudi; D. H. Mudjiono","Computer Science, Faculty Universitas, Klabat Airmadidi, Indonesia; Computer Science, Faculty Universitas, Klabat Airmadidi, Indonesia; Computer Science, Faculty Universitas, Klabat Airmadidi, Indonesia","2018 Third International Conference on Informatics and Computing (ICIC)","1 Aug 2019","2018","","","1","6","This paper presented Augmented Reality implemented in an application called ARC++ with real-time recognition and information extraction. Application recognized the C++ syntax and displayed the information details of syntax through Smartphone to the user. In purpose of real-time recognition, we use Optical Character Recognition. Method to design and build the application is based on Prototyping model. Using markerless Augmented Reality, Optical Character Recognition and Vuforia, the application was built, installed and running on Android operating system. C++ syntax as markerless object target, use a handwritten or printed syntax. The functionality of application has been tested with various syntax categories to gain results of how well the application detect, recognize and extract information from object target syntax that has been scanned. The testing of ARC++ application is measured by the accuracy of detection and recognition. Based on the testing scenario, this application shows significantly recognitions about 70% to 100% for handwritten syntax, printed syntax with different sizes, colors, styles and special characters. Although there is only 30% successful recognition while using underline syntax as object targeted syntax, but ARC++ can detect, recognized and extract additional information from C++ syntax. ARC++ application potentially can be used as an attractive of learning C++ syntax.","","978-1-5386-6921-1","10.1109/IAC.2018.8780473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780473","Augmented Reality;ARC++;C++ syntax;information extraction;real-time recognition","Syntactics;Testing;C++ languages;Optical character recognition software;Cameras;Augmented reality;Character recognition","Android (operating system);augmented reality;C++ language;computer aided instruction;computer science education;mobile computing;optical character recognition;smart phones","real-time recognition;information extraction;C++ syntax;printed syntax;ARC++ application;handwritten syntax;underline syntax;object targeted syntax;optical character recognition;markerless augmented reality;smartphone;Vuforia;Android operating system","","1","","28","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"Implementation of Augmented Reality Geolocation Application Based on Android for Searching Hospital Location","Nurhayati; A. Faridy; R. P. Iswara","Department of Informatics, Syarif Hidayatullah State Islamic University, Jakarta, Indonesia; Department of Informatics, Syarif Hidayatullah State Islamic University, Jakarta, Indonesia; Department of Informatics, Syarif Hidayatullah State Islamic University, Jakarta, Indonesia","2019 7th International Conference on Cyber and IT Service Management (CITSM)","23 Jan 2020","2019","7","","1","7","A navigation field now has been dominated by Google Maps, where the conventional map information is converted into a digital map. The disadvantages of that digital maps are the user cannot find out the real direction to the destination, whether it located in the front, in the back, in the right, or in the left of user. Technology of augmented reality can be used to cover the lack of digital maps. It requires access to the camera, accelerometer sensor, digital compass, and GPS that are embedded in the android smartphone. Data from the GPS generate the azimuth angle and the angle of inclination that formed between the positions of the user with location and then converted to the form of augmented reality marker on the screen. According to the azimuth angle and direction of the compass, it can be known the horizontal position of the hospital on the screen. While the angle of inclination and orientation of the accelerometer determines the vertical position of the hospital on the screen.","","978-1-7281-2909-9","10.1109/CITSM47753.2019.8965327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965327","Geolocation;Augmented Reality;GPS based tracking method;Haversine formula","Hospitals;Augmented reality;Global Positioning System;Accelerometers;Azimuth;Compass;Cameras","accelerometers;Android (operating system);augmented reality;Global Positioning System;hospitals;mobile computing;smart phones;terrain mapping","azimuth angle;Android;augmented reality geolocation application;Google Maps;conventional map information;digital map;digital compass;hospital location searching;GPS data","","1","","18","IEEE","23 Jan 2020","","","IEEE","IEEE Conferences"
"Application of Augmented Reality in The Adventure Kelana Application (Travel Agent)","M. Ramadhani; Y. A. Pada; G. S. Putra; A. William; B. Moses; F. I. Maulana","Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2021 International Conference on Information Management and Technology (ICIMTech)","14 Sep 2021","2021","1","","250","255","This paper discusses the design of the Kelana Adventure application that applies AR or augmented reality technology. Kelana adventure is a mobile-based travel agency application that uses augmented reality as a superior feature in providing better visualization of tourist objects than various similar applications. This study discusses the methods used in designing applications and their steps in order to obtain a model / prototype that is as close as possible to user needs. From the method used, a mockup of the adventure rover application was formed to provide a visualization of the application layout. The results of the mock up will then become the standard framework for the development of the adventure rover application","","978-1-6654-4937-3","10.1109/ICIMTech53080.2021.9534924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534924","Augmented Reality;Kelana Adventure","Visualization;Layout;Prototypes;User experience;Information management;Augmented reality;Standards","augmented reality;data visualisation;mobile computing;travel industry","Adventure Kelana application;travel agent;Kelana Adventure application;augmented reality technology;mobile-based travel agency application;tourist object visualization;application layout visualization;adventure rover application development","","1","","7","IEEE","14 Sep 2021","","","IEEE","IEEE Conferences"
"A Mobile Augmented Reality Service Model Based on Street Data, and Its Implementation","J. Lee; J. Lee; S. Lim; Y. Kwon","Department of Telecomm. and Info. Engineering, Korea Aerospace University, Goyang-city, Gyeonggi-do, Korea; Department of Telecomm. and Info. Engineering, Korea Aerospace University, Goyang-city, Gyeonggi-do, Korea; Department of Telecomm. and Info. Engineering, Korea Aerospace University, Goyang-city, Gyeonggi-do, Korea; Dept. of Telecomm. & Inf. Eng., Korea Aerospace University, Goyang, Gyeonggi-do, KR","2015 IEEE 39th Annual Computer Software and Applications Conference","24 Sep 2015","2015","3","","240","247","The popularity of smart devices and Location Based Services (LBSes) is increasing in part due to users demand for personalized information associated with their location. These services provide intuitive and realistic information by adopting Augmented Reality(AR) technology. This technology utilizes various sensors embedded in the mobile devices. However, these services have inherent problems due to the devices small screen size and the complexity of the real world environment, overlapping content on a small screen and placing icons without considering the user's possible movement. In order to solve these problems, this paper proposes a Mobile Augmented Reality Model with the application of Street Data. The model consists of two layers ""Real-world layer"" and ""Information layer"". In the model, a user creates a query by scanning the nearby street with a camera in real space and searches accessible content along the street through the use of the information space. Furthermore, the results are placed on both sides of the street to solve the issue of Overlapping. Also, the proposed model is implemented for region ""Aenigol"", and the efficiency and usefulness of the model are verified.","0730-3157","978-1-4673-6564-2","10.1109/COMPSAC.2015.280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273361","Mobile Augmented Reality;Location Based Services;Street Data;Numerical Map","Mobile communication;Augmented reality;Data models;Sensors;Cameras;Mobile handsets;Global Positioning System","augmented reality;mobile computing","mobile augmented reality service model;street data;smart devices;location based services;LBSes;AR technology;real-world layer;information layer;Aenigol","","1","","16","IEEE","24 Sep 2015","","","IEEE","IEEE Conferences"
"A Survey on FPGA Implementations in Embedded Augmented Reality Applications","A. Kaur","Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India","2018 6th Edition of International Conference on Wireless Networks & Embedded Systems (WECON)","1 Aug 2019","2018","","","23","26","Since a long ago, most of the Augmented Reality (AR) applications are built using some general purpose devices such as computers and handhelds. In such general purpose devices, tasks are being processed using different softwares that make it difficult to obtain the real time results with high resolution and frame rate. There is a need to maintain a good performance but it invariably results into high cost of the overall project due to the requirement of higher clock frequency and high power. Mobility and processing power are the two basic requirements of an augmented reality application to provide an efficient immersion to the end user. An embedded architecture developed on Field Programmable Gate Array Logic (FPGA) can supply both mobility and processing power to the AR applications. FPGA is a tiny chip that has the efficiency of hardware level executions. This paper gives a detailed account of FPGAs in AR applications in the field of computer vision & image processing, multimedia & computer graphics, communication and wearable computing.","","978-1-5386-7050-7","10.1109/WECON.2018.8782056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782056","FPGA;augmented reality;embedded systems;reconfigurable hardware;parallelism","Field programmable gate arrays;Real-time systems;Augmented reality;Hardware;Image processing;Task analysis","augmented reality;computer vision;embedded systems;field programmable gate arrays;image resolution;wearable computers","wearable computing;FPGA implementations;general purpose devices;higher clock frequency;embedded architecture;AR applications;embedded augmented reality applications;field programmable gate array logic;hardware level executions","","1","","48","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"Gait Analysis System by Augmented Reality","R. Ortega-Palacios; J. C. Salgado-Ramírez; J. A. Valdez-Hernández","Universidad Politécnica de Pachuca, Zempoala, Hidalgo, Mexico; Universidad Politécnica de Pachuca, Zempoala, Hidalgo, Mexico; Universidad Politécnica de Pachuca, Zempoala, Hidalgo, Mexico","2015 Pan American Health Care Exchanges (PAHCE)","24 Aug 2015","2015","","","1","4","Gait analysis is the systemic study of human walking. In this paper we present the development of a 3D gait analysis system based on Augmented Reality (AR). AR allows a user to see a real world with virtual elements overlapped upon it in real time. To build the 3D Gait Analysis system was necessary to determine markers position for gait analysis, develop an electronic circuit with Arduino technology to control accelerometers and infrared leds to feed the virtual 3D scene, develop human-machine interface to establish a communication protocol between the electronic circuit and the computer and generate augmented reality based on accelerometers and infrared leds.","2327-817X","978-1-4673-6969-5","10.1109/PAHCE.2015.7173340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7173340","Gait analysis;Augmented Reality;accelerometer;infrared led","Three-dimensional displays;Accelerometers;Augmented reality;Light emitting diodes;Cameras;Electronic circuits;Stereo image processing","acceleration measurement;accelerometers;augmented reality;biomedical optical imaging;gait analysis;infrared imaging;man-machine systems;medical diagnostic computing","augmented reality;human walking;3D gait analysis system;virtual elements;markers position;electronic circuit;Arduino technology;control accelerometers;infrared leds;virtual 3D scene;human-machine interface;communication protocol","","1","","9","IEEE","24 Aug 2015","","","IEEE","IEEE Conferences"
"A spoken dialogue system using virtual conversational agent with augmented reality","S. Miyake; A. Ito","Graduate School of Engineering, Tohoku University, Sendai, Japan; Graduate School of Engineering, Tohoku University, Sendai, Japan","Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference","17 Jan 2013","2012","","","1","4","We have developed a spoken dialogue system using virtual conversational agent with augmented reality. The proposed system has architecture based on question and answer database that contains many question and answer pairs. Additionally, we have developed two agents displayed using augmented reality, which behave as avatars of objects to be operated. We evaluated user's impression as well as response accuracy of our proposed system. As a result, the existence of an agent increased user's feeling of vividness of conversation and easiness to talk to the system. In addition, the system with an agent showed better response accuracy than the system without agents.","","978-0-6157-0050-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6411769","Spoken dialogue system;Virtual agent;Augmented reality","Accuracy;TV;Databases;Speech;Augmented reality;Cameras;Indium tin oxide","augmented reality;avatars;interactive systems;question answering (information retrieval)","spoken dialogue system;virtual conversational agent;augmented reality;question and answer database;avatars","","1","","16","","17 Jan 2013","","","IEEE","IEEE Conferences"
"Using Augmented Reality Technology in Pathfinding","F. Abuhashish; H. Kolivand","Department of Animation and Multimedia, University of Petra, Amman, Jordan; Department of Computer Science, Liverpool John Moores University, Liverpool, UK","2019 12th International Conference on Developments in eSystems Engineering (DeSE)","23 Apr 2020","2019","","","1042","1046","Nowadays advanced technologies with a variety of enormous capabilities and superior quality characteristics enables software product developers to produce the finest developments in software regardless of the underlying challenge. The invention of augmented reality (AR) is often used in almost every field of this era. AR is a brazen phenomenon with smart systems and mobile devices as part of everyday life. In this sense the accessibility navigation intelligence AR system for the University of Petra in Amman-Jordan has been created, allowing students, guests and staff to find a specific position within the campus and to navigate its environment. In addition, the UOP-WF-AR application of Augmented Reality will gather knowledge about campus lecturers and officials and give guidance in the open air area. The UOP-WF-AR application is expected to help and direct students, guests and staff in the university, by providing useful details regarding outdoor mobility positions and by providing information on lecturers and officials who are not in their offices at all times.","2161-1351","978-1-7281-3021-7","10.1109/DeSE.2019.00193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073156","Augmented Reality, pathfinding, azimuth","Cameras;Global Positioning System;Augmented reality;Sensors;Radar tracking;Azimuth","augmented reality;computer aided instruction;educational institutions;information retrieval;Internet;mobile computing","smart systems;mobile devices;accessibility navigation intelligence AR system;Amman-Jordan;UOP-WF-AR application;campus lecturers;outdoor mobility positions;augmented reality technology;software product developers","","1","","22","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Learning Resources in Anatomy","L. F. García Arias; N. D. Duque Méndez; C. Dias Flores","Universidad Nacional de Colombia, Bogota, CO; Universidad Nacional de Colombia, Bogota, CO; Universidade Federal de Ciencias da Saude de Porto Alegre, Porto Alegre, RS, BR","2018 XIII Latin American Conference on Learning Technologies (LACLO)","1 Aug 2019","2018","","","476","483","Augmented reality can be applied in different areas of knowledge and one of the most explored fields has been health. The objective of this article is to present the results obtained from the evaluation of learning resources developed using augmented reality technology. The evaluation was made by students of health undergraduate programs who participated in the Academic Day of the Biomedicine program of a Brazilian higher education institution. 8 educational resources were evaluated, all related to the area of general anatomy. The resources were evaluated by 41 students who answered a validated questionnaire for the evaluation of educational resources with questions about: learning, interactivity, engagement, attractiveness, functionality and autonomy. The evaluation was considered valid. The challenge is to find interactive alternatives that stimulate and simultaneously incorporate content, with a depth appropriate to the objective of the subject. Critics in the evaluation will serve as the basis for adjustments in the next learning resources to be developed.","","978-1-7281-0382-2","10.1109/LACLO.2018.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8783620","Augmented reality;general anatomy;learning resource","Three-dimensional displays;Visualization;Augmented reality;Education;Solid modeling;Software;Two dimensional displays","augmented reality;biomedical education;computer aided instruction;educational institutions;further education","Brazilian higher education institution;augmented reality learning resources;health undergraduate programs;biomedicine program","","1","","","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"The Development and Application of a Repertory Grid-Oriented Ubiquitous Augmented Reality Learning System","H. -C. Chu; C. -W. Lin","Department of Computer Science and Information Management, Soochow University, Taipei, Taiwan; Department of Computer Science and Information Management, Soochow University, Taipei, Taiwan","2013 Second IIAI International Conference on Advanced Applied Informatics","15 Oct 2013","2013","","","207","210","In this study, an augmented reality system is developed for context-aware ubiquitous learning by integrating a repertory grid oriented Mind tools to facilitate the students to observe the learning targets and organize what they have learned during the u-learning process. To evaluate the effectiveness of the proposed approach, an experiment has been conducted in an elementary school natural science course to examine the students' performance in terms of their learning attitudes, learning motivation, self-efficacy, cognitive load and learning achievements. From the experimental results, it is found that the Mind tools-integrated augmented reality system has drawn much attention from the students, and their learning attitudes were very high.","","978-0-7695-5071-8","10.1109/IIAI-AAI.2013.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6630347","context-aware ubiquitous learning;augmented reality;repertory grid;cognitive load","Augmented reality;Mobile communication;Computers;Environmental factors;Learning systems;Educational institutions","augmented reality;computer aided instruction;grid computing;ubiquitous computing","context-aware ubiquitous learning;repertory grid-oriented ubiquitous augmented reality learning system;repertory grid oriented Mind tools;u-learning process;elementary school natural science course;learning attitudes;learning motivation;cognitive load;learning achievements;self-efficacy","","1","","30","IEEE","15 Oct 2013","","","IEEE","IEEE Conferences"
"Augmented Reality Application for Solar System Learning: A Research in Progress","M. I. M. Ariff; M. L. H. Rohaizi; K. A. Salleh; J. A. Wahab; N. L. Adam; N. I. Arshad","Department of Computer Science, Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA Perak Branch, Tapah Campus, Malaysia; Department of Computer Science, Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA Perak Branch, Tapah Campus, Malaysia; Department of Computer Science, Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA Perak Branch, Tapah Campus, Malaysia; Department of Mathematics, Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA Perak Branch, Tapah Campus, Malaysia; Center of Computer Science Studies Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Malaysia; Department of Computer and Information Sciences, Faculty of Science and Information Technology, Universiti TEKNOLOGI PETRONAS, Seri Iskandar, Perak, Malaysia","2021 IEEE Region 10 Symposium (TENSYMP)","4 Oct 2021","2021","","","1","4","This paper presents a research in progress of a mobile application development that features the use of Augmented Reality (AR). In recent times, the use of technology in education has gained much interest among researchers and practitioners. Augmented Reality (AR) is one of the technologies that has attracted most attention. The use of AR has been shown to produce positive improvement to both teachers and students in a learning environment. For students, the use of AR provides them with an immersive environment thus making their learning experience more enjoyable. AR based learning application may also help teachers in explaining complex topics such as the concept of solar system. Thus, this paper proposes a development of a mobile application to aid students in learning process with the help of AR. The development of this mobile application utilizes the solar system topic as a medium of proof of concept.","2642-6102","978-1-6654-0026-8","10.1109/TENSYMP52854.2021.9550832","Universiti Teknologi MARA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9550832","Augmented Reality;mobile application;Solar system;learning technology","Education;Mobile communication;Solar system;Mobile applications;Augmented reality;IEEE Regions;Application programming interfaces","augmented reality;computer aided instruction;mobile computing","learning environment;immersive environment;learning experience;learning application;help teachers;solar system topic;Augmented reality application;solar system learning;mobile application development;positive improvement","","1","","22","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"Augmented Reality for Office and Basic Programming Laboratory Peripheral","M. B. Firdaus; E. Budiman; J. A. Widians; N. M. Sinaga; S. Fadli; F. Alameka","Faculty of Computer Science and Information Technology, Mulawarman University, Samarinda, Indonesia; Faculty of Computer Science and Information Technology, Mulawarman University, Samarinda, Indonesia; Faculty of Computer Science and Information Technology, Mulawarman University, Samarinda, Indonesia; Faculty of Computer Science and Information Technology, Mulawarman University, Samarinda, Indonesia; Informatics Engineering, STMIK Lombok, Lombok Tengah, Indonesia; Faculty of Computer Science and Information Technology, Mulawarman University, Samarinda, Indonesia","2018 2nd East Indonesia Conference on Computer and Information Technology (EIConCIT)","24 Oct 2019","2018","","","41","45","Submission of information can use 3-dimensional (3D) images that will make information clearer and more interesting. Faculty of Computer Science and Information Technology (FKTI) one of the faculties located at Mulawarman University. Base rooms and laboratories are often used and if someone wants to do peripherals then he will look for additional peripherals. However, they do not have a device that can be used to know the pattern of each room function and the learning environment must have additional devices to facilitate the use of Augmented Reality 3D media. Therefore, it is necessary to have augmented reality media to provide an understanding of visual information for the faculty room and the basic laboratory of the FKTI program. Each scheme of determining markers is adjusted to the point where the camera will scan. Tests are carried out to show the results are done on plain paper that already has their own floor plan and in each room partition can display basic information about the room. Light testing is also done with the result that if the light is $\gt300$ lux then it can be ascertained that AR visibility will appear quickly.","","978-1-5386-8050-6","10.1109/EIConCIT.2018.8878527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878527","augmented reality;3d media;laboratory peripheral","Three-dimensional displays;Augmented reality;Information technology;Cameras;Testing","augmented reality;cameras;educational institutions","programming laboratory;3-dimensional images;Faculty of Computer Science and Information Technology;Mulawarman University;visual information;faculty room;FKTI program;augmented reality 3D media;camera","","1","","26","IEEE","24 Oct 2019","","","IEEE","IEEE Conferences"
"Improved teaching and conservation of natural sites through augmented reality","R. Montenegro; L. Muñoz","Facultad de Ingeniería de Sistemas Computacionales, Universidad Tecnológica de Panamá, Panamá, República de Panamá; Grupo de Investigación en Tecnologías Computacionales Emergentes, Universidad Tecnológica de Panamá, Panamá, República de Panamá","2017 12th Iberian Conference on Information Systems and Technologies (CISTI)","13 Jul 2017","2017","","","1","6","Augmented Reality is a technology that complements the perception and interaction with the real world and allows the user to be in an enhanced environment with additional information generated by the computer. In recent years the development of this technology in the educational field has taken a big rise. This article presents the development of scenarios for the conservation of natural sites through the Augmented Reality. For this purpose, a set of slides and a mobile application have been developed that allow elementary students to know about the importance and conservation of the natural sites of the province of Chiriquí, in the Republic of Panama. The evaluation of the resulting products was carried out third grade students, obtaining excellent results.","","978-9-8998-4347-9","10.23919/CISTI.2017.7975707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975707","augmented reality;Conservation;education;natural sites","Three-dimensional displays;Augmented reality;Visualization;Education;Irrigation;Mobile applications;Geology","augmented reality;computer aided instruction;mobile computing;natural sciences;teaching","natural site teaching;natural site conservation;augmented reality;enhanced environment;computer generated information;educational field;scenarios development;mobile application;elementary students;Chiriquí province;Panama Republic","","1","","16","","13 Jul 2017","","","IEEE","IEEE Conferences"
"The influence of gender in the use of Augmented Reality in Education: A Systematic Literature Review","A. J. A. Valencia; D. Burgos; J. W. Branch","Research Institute for Innovation & Technology in Education (UNIR iTED), Universidad Internacional de La Rioja, Logroño, Rioja, Spain; Research Institute for Innovation & Technology in Education (UNIR iTED), Universidad Internacional de La Rioja, Logroño, Rioja, Spain; Facultad de Minas, Universidad Nacional de Colombia, Sede Medellin, Colombia","2021 XI International Conference on Virtual Campus (JICV)","11 Nov 2021","2021","","","1","4","Augmented Reality (AR) is a technology that is gaining a greater prominence in schools and universities in recent years. For this reason, it is necessary to know the scientific production on this technological resource based on the gender influence shown by the students. The objective of this research is to analyze the repercussion that the gender of the students presents with the use of Augmented Reality in different educational stages, in the Scopus and Web of Science (WoS) databases. To do this, a systematic review of the literature was carried out using the Kitchenham protocol, analysing a total of 66 articles published between 2017 and 2021. The main findings show that gender presents an important significant difference in relation to student motivation. However, there are no relevant or considerable differences regarding the acceptance and acquisition of knowledge.","","978-1-6654-3703-5","10.1109/JICV53222.2021.9600362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9600362","augmented reality;gender;technological acceptance;performance;education","Systematics;Protocols;Databases;Bibliographies;Production;Augmented reality","augmented reality;citation analysis;computer aided instruction;educational institutions;electronic publishing;gender issues;research and development","technological resource;gender influence;students presents;Augmented Reality;different educational stages;systematic review;student motivation;systematic literature review;greater prominence;universities;scientific production","","1","","31","IEEE","11 Nov 2021","","","IEEE","IEEE Conferences"
"Tracking Registration Algorithm for Augmented Reality based on Random Fern","P. Cao; W. Li; W. Ma","China Academy of Space Technology, Lanzhou Institute of Physics, Lanzhou, China; China Academy of Space Technology, Lanzhou Institute of Physics, Lanzhou, China; China Academy of Space Technology, Lanzhou Institute of Physics, Lanzhou, China","2019 2nd International Conference on Safety Produce Informatization (IICSPI)","19 May 2020","2019","","","357","362","For markerless tracking registration methods, there exist a lot of problems like tracking registration failure and slow speed in the complex environment. To solve the problem, a random fern classifier is applied to the process of the markerless augmented reality tracking registration. This method uses a target object image in a real scene as a template, and the target of each frame of image is detected by the random fern classifier. By estimating the three-dimensional pose, the registered virtual object can be rendered to implement the augmented reality tracking registration. This method can solves the problems of tracking registration failures due to the change of ambient lighting or the targets were occluded. It has better real-time performance than the traditional wide baseline matching algorithm.","","978-1-7281-4566-2","10.1109/IICSPI48186.2019.9095911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095911","Markerless;Augmented Reality;Tracking Registration;Random Fern;Wide Baseline Matching","Training;Feature extraction;Target tracking;Classification algorithms;Augmented reality;Real-time systems;Mathematical model","augmented reality;image classification;image registration;learning (artificial intelligence);object tracking;pose estimation;rendering (computer graphics)","complex environment;random fern classifier;markerless augmented reality tracking registration;target object image;registered virtual object;tracking registration algorithm;markerless tracking registration methods;tracking registration failure;three-dimensional pose estimation;object rendering;real-time performance","","1","","18","IEEE","19 May 2020","","","IEEE","IEEE Conferences"
"MOW: Augmented Reality game to learn words in different languages: Case study: Learning English names of animals in elementary school","J. Barreira; M. Bessa; L. C. Pereira; T. Adão; E. Peres; L. Magalhães","INESC TEC (formerly INESC Porto), ECT UTAD, Portugal; INESC TEC (formerly INESC Porto), ECT UTAD, Portugal; CEL, CITCEM, UTAD, Portugal; INESC TEC (formerly INESC Porto), ECT UTAD, Portugal; INESC TEC (formerly INESC Porto), ECT UTAD, Portugal; INESC TEC (formerly INESC Porto), ECT UTAD, Portugal","7th Iberian Conference on Information Systems and Technologies (CISTI 2012)","30 Aug 2012","2012","","","1","6","Recent digital games have been developed not only for entertainment purposes, but also to promote learning. This paper presents MOW (Matching Objects and Words), which is an Augmented Reality (AR) game for learning words in different languages. Experimental tests were performed with Portuguese children during English classes. We have compared the results from using MOW along with traditional teaching methods. The results indicate that children who used the Augmented Reality games had a superior learning progress than those who used only traditional methods.","2166-0735","978-989-96247-7-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6263236","Augmented Reality;educational games;learning words","Games;Animals;Educational institutions;Augmented reality;Visualization;Cameras","augmented reality;computer aided instruction;computer games;humanities;natural languages;teaching","MOW;augmented reality game;words learning;English names learning;elementary school;digital games;matching objects and words;AR game;Portuguese children;English classes;teaching methods;animal names","","1","","21","","30 Aug 2012","","","IEEE","IEEE Conferences"
"Pedagogical Innovative Research Endeavor: Visualization of Streamed Big Data through Augmented Reality","S. North; M. Verma; S. Saffan; V. Orellana; M. Alyward; R. Brooks","Department of Computer Science, Kennesaw State University, Georgia, USA; Department of Computer Science, Kennesaw State University, Georgia, USA; Department of Computer Science, Kennesaw State University, Georgia, USA; Department of Computer Science, Kennesaw State University, Georgia, USA; Department of Computer Science, Kennesaw State University, Georgia, USA; Department of Computer Science, Kennesaw State University, Georgia, USA","2019 SoutheastCon","5 Mar 2020","2019","","","1","6","The speed of technical and scientific innovation is accelerating much faster than humans can learn. Thus, there is a need for innovative pedagogical research to decrease this gap. Toward that goal, the approach of pedagogical component experiment was to design, develop, and measure the effectiveness of an augmented reality (AR) application for the visualization of streamed network traffic data to create an innovative pedagogical research environment and opportunities for learners. Specifically, this experiment was developed for the Microsoft HoloLens, with several AR models of data visualization. The effectiveness of this application was measured. Preliminary results showed that using augmented reality to visualize network data enhances comprehension of the data, though, results using statistical analysis were inconclusive, and further research is needed to determine whether using AR to visualize streaming data is more efficient than other methods of visualization. However, in spite of the outcome of this research experiment, a pedagogical environment was positively created for learners that most likely increased their involvement in research and learning.","1558-058X","978-1-7281-0137-8","10.1109/SoutheastCon42311.2019.9020576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020576","Pedagogical Techniques;Data Visualization Augmented Reality (AR);GUI (Graphical User Interface)","Data visualization;Augmented reality;Two dimensional displays;Big Data;Education;Telecommunication traffic","augmented reality;Big Data;data analysis;data visualisation;learning (artificial intelligence);statistical analysis;telecommunication traffic","scientific innovation;pedagogical component experiment;augmented reality application;streamed network traffic data;innovative pedagogical research environment;data visualization;network data;pedagogical environment;pedagogical innovative research endeavor;streamed big data;technical innovation;Microsoft HoloLens","","1","","15","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"An application towards the combination of augment reality and mobile guidance","D. -Y. Huang; K. -H. Hsu","Department of Computer Science, National Taichung University of Education, Taichung, Taiwan; Department of Computer Science, National Taichung University of Education, Taichung, Taiwan","2013 International Conference on High Performance Computing & Simulation (HPCS)","21 Oct 2013","2013","","","627","630","In recent years, as the capabilities of smart phones increase, such as equipped with more powerful processors, a higher resolution camera, and sensors that are capable of tracking location and orientation, the implementation of augmented reality (AR) is becoming easier and applicable. Compared with navigation guidance, mobile guidance has more potential usability in it. In this paper, as an attempt towards the combination of augmented reality, navigation and guidance on modern smart phones, a prototype of AR guidance system is built in NTCU to illustrate the feasibility of the proposed concept.","","978-1-4799-0838-7","10.1109/HPCSim.2013.6641481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6641481","Augmented Reality;Mobile Guidance;Smart Phone","Augmented reality;Smart phones;Sensors;Global Positioning System;Buildings;Cameras","augmented reality;cameras;image sensors;mobile computing;smart phones","augment reality;mobile guidance;smart phones;resolution camera;sensors;location tracking;orientation tracking;AR guidance system;NTCU","","1","2","11","IEEE","21 Oct 2013","","","IEEE","IEEE Conferences"
"Envision of Solar System using Augmented Reality","S. Sathish; P. L. K; S. P","School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India","2022 First International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT)","10 May 2022","2022","","","1","5","The potential for using augmented reality (AR) technology is investigated in this article, and the solar system is constructed as a software model. The software tools for modelling the solar system that are currently available are explored. The software programme created using augmented reality technology depicts the behavior of solar system objects in great detail. By reading the object's description, primary characteristics, and intriguing information, as well as daily updates of NASA's tweets on the dashboard, users may visually and informatively explore each planet. The AR models are built utilizing Newtonian physics, as well as the proper proportions in object size, velocity, form, and distance between orbits of celestial bodies.","","978-1-6654-3647-2","10.1109/ICEEICT53079.2022.9768607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768607","Newtonian Physics;Augmented Reality;Vuforia;Solar System;Twitter","Planets;NASA;Information and communication technology;Planetary orbits;Software tools;Augmented reality;Physics","astronomy computing;augmented reality;social networking (online);software tools;solar system","solar system;software tools;software programme;augmented reality technology;NASA's tweets;celestial bodies","","","","18","IEEE","10 May 2022","","","IEEE","IEEE Conferences"
"Desktop Artillery Simulation Using Augmented Reality","M. U. Yavuz; R. Sayar; B. Yilmaz; E. Bostanci; M. S. Güzel; A. A. Yilmaz","Computer Engineering Department, Ankara University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey","2019 6th International Conference on Electrical and Electronics Engineering (ICEEE)","12 Aug 2019","2019","","","79","85","Augmented reality (AR) is a popular subject that is commonly associated with entertainment purposes. However, it can be practically useful in many other areas, from medicine to military technologies. Creating an interactive 3D ballistics simulation on a table is one of those purposes. In this paper, we present the work we carried out for designing and developing an augmented reality military game. The game is an artillery simulation where the player controls cannons and tries to take successful shots. The key feature of the game is that it utilizes AR technologies to place the game environment in the player's real life environment through smart AR glasses. The terrain where all the action takes place, is perceived to be on the table or floor in player's room. A specific 2D image is used to track the position and orientation of the surface where the game environment is placed. A general research about the background of AR technologies and game development, and detailed walk-through of the project's development are provided in the following sections.","","978-1-7281-3910-4","10.1109/ICEEE2019.2019.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792535","serious games;augmented reality;tactical decision making;simulations;artillery;game development","Games;Three-dimensional displays;Augmented reality;Solid modeling;Cameras;Glass;Computational modeling","augmented reality;ballistics;computer games;military computing;weapons","desktop artillery simulation;military technologies;interactive 3D ballistics simulation;augmented reality military game;AR technologies;game development","","","","10","IEEE","12 Aug 2019","","","IEEE","IEEE Conferences"
"Secure Domotics using Augmented Reality","A. Prasad; A. G. Rao; D. Dubey; V. K. Chaubey; A. Kumar","Department of ED&T, National Institute of Electronic and Information Technology, Gorakhpur, (UP), India; Department of ED&T, National Institute of Electronic and Information Technology, Gorakhpur, (UP), India; Department of ED&T, National Institute of Electronic and Information Technology, Gorakhpur, (UP), India; Department of ED&T, National Institute of Electronic and Information Technology, Gorakhpur, (UP), India; Department of ECE, Amity University, Greater Noida, India","2022 2nd International Conference on Technological Advancements in Computational Sciences (ICTACS)","28 Dec 2022","2022","","","367","370","We always upgrade our system with new technologies similarly whenever new technologies appear at home automatic system also upgrades with them to give a better feature while enhancing the security. In this paper, we upgrade the home automation with augmented reality while overcoming the security lack in the normal IOT-based home automation system. Basically, in the IOT base system, there is no security after the cloud processing, and that loophole we going to solve through marker-based augmented reality technique to add an extra layer of security after the cloud processing. Here AR marker is used as a key without that marker no virtual buttons will appear on the AR application. We design an IOT device controlled by an ESP32.","","978-1-6654-7657-7","10.1109/ICTACS56270.2022.9988070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9988070","Augmented Reality Home;IOT Home;Cloud Security;ESP-32;Home Automation","Cloud computing;Home automation;Automation;Security;Internet of Things;Augmented reality","augmented reality;cloud computing;home automation;Internet of Things;microcontrollers","AR marker;cloud processing;ESP32;home automatic system;IOT device;marker-based augmented reality technique;normal IOT-based home automation system;secure domotics","","","","10","IEEE","28 Dec 2022","","","IEEE","IEEE Conferences"
"Application of Spatial Registration Algorithm Based on ORB Features in Augmented Reality","X. Li; X. Wang","Institute of Smart City, Shanghai University, Shanghai, China; Institute of Smart City, Shanghai University, Shanghai, China","2018 International Conference on Audio, Language and Image Processing (ICALIP)","6 Sep 2018","2018","","","257","261","In consideration of problems with traditional augmented reality, including inaccuracy, untimeliness and instability of 3D spatial registration results, this paper proposes an improved algorithm based on ORB (Oriented FAST and Rotated BRIEF) features, which improves recursive adjustment procedures for decision trees during feature point extraction and makes up deficiencies of conventional ORB algorithms such as high computation load and inadequate feature point extraction. In terms of 3D spatial registration, this paper establishes an augmented reality system by RANSAC optimization algorithm. The experimental results suggest that it costs relatively short time to process complicated natural images with the algorithm proposed in this paper, which is highly timely and robust for processing scene images.","","978-1-5386-5195-7","10.1109/ICALIP.2018.8455357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8455357","Augmented Reality;Natural Features;Spatial Registration;Virtual-real Fusion","Feature extraction;Augmented reality;Cameras;Three-dimensional displays;Real-time systems;Decision trees","augmented reality;decision trees;feature extraction;image registration;optimisation","decision trees;conventional ORB algorithms;high computation load;RANSAC optimization algorithm;spatial registration algorithm;spatial registration;Oriented FAST and Rotated BRIEF;feature point extraction;augmented reality;scene images;natural images","","","","14","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"Augmented Reality Applications for Urban Cultural Heritage Sites: An Overview","A. Vlachos; M. Perifanou; A. A. Economides","Dept. of Mediterranean Studies, University of the Aegean, Chios, Greece; SMILE Lab, University of Macedonia, Thessaloniki, Greece; SMILE Lab, University of Macedonia, Thessaloniki, Greece","2022 International Conference on Advanced Learning Technologies (ICALT)","17 Aug 2022","2022","","","322","324","Augmented Reality applications have become the newest technology used in the Cultural Heritage domain. These applications can be used in education and tourism. Various methods and software tools provide the means of designing such applications. This study provides an overview of the most recent Augmented Reality projects in Cultural Heritage sites in urban environments, comparing tracking methods, devices, themes, and settings used in each project. The most frequently used tracking method is camera-based, with handheld devices being almost entirely preferred in such projects. There is an even distribution of themes, while outdoor scenarios are the preferred setting.","2161-377X","978-1-6654-9519-6","10.1109/ICALT55010.2022.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853833","Applications;Augmented Reality;Cultural Heritage;Education;Exhibition;Exploration","Urban areas;Education;Cultural differences;Software tools;Augmented reality","augmented reality;history;travel industry","handheld devices;camera-based devices;tourism;tracking methods;augmented reality projects;software tools;urban cultural heritage sites","","","","16","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"TIP: Tangible Interactive Projector with Projection Touch Tracking and Spatial Augmented Reality","Y. Wang; C. Feng; J. Guo; Y. Ma","College of Software, Beihang University, China; College of Software, Beihang University, China; College of Software, Beihang University, China; College of Software, Beihang University, China","2020 4th Annual International Conference on Data Science and Business Analytics (ICDSBA)","27 Sep 2021","2020","","","50","53","Projection interaction is a new method of human-computer interaction which creates viewable screen in the actual space and can be directly touched and interacted by users, which can be universally used in the field of robotics and consumer electronics. In this work, we propose a new device named tangible interactive projector to effectively enable projection touch tracking and spatial augmented reality, in which we use object detection, instance segmentation and keypoints detection to improve the efficiency of touch detection and reduce the probability of misrecognition. We implement the spatial augmented reality method with the combination of the projection unit, computing unit, and perception unit. The perception unit consists of a high definition camera and an infrared camera, providing more modal data for touch recognition, which also makes it possible to display the projection adaptively according to the type and shape of the object in the field view using the bounding box output by object detection. The experiments show that our proposed equipment and interactive method perform significantly better than existing equipment or methods.","","978-1-7281-8164-6","10.1109/ICDSBA51020.2020.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546310","Projection Touch Tracking;Tangible Interaction Projector;Spatial Augmented Reality;Instance Segmentation;Keypoints Detection","Performance evaluation;Human computer interaction;Shape;Spatial augmented reality;Object detection;Production;Interference","augmented reality;cameras;object detection;touch sensitive screens","projection interaction;human-computer interaction;viewable screen;actual space;tangible interactive projector;projection touch tracking;object detection;instance segmentation;keypoints detection;touch detection;spatial augmented reality method;projection unit;perception unit;touch recognition;interactive method","","","","20","IEEE","27 Sep 2021","","","IEEE","IEEE Conferences"
"Utilization of Augmented Reality-Based Application to Promote Digital Citizenship","A. K. Pamudji; C. T. Murniati; H. Hartono; A. Riyandari; R. R. Saptaastuti","Department of Information System, Faculty of Computer Science, Soegijapranata Catholic University, Semarang, Indonesia; Department of English, Faculty of Language and Arts, Soegijapranata Catholic University, Semarang, Indonesia; Department of English, Faculty of Language and Arts, Soegijapranata Catholic University, Semarang, Indonesia; Department of English, Faculty of Language and Arts, Soegijapranata Catholic University, Semarang, Indonesia; Library, Soegijapranata Catholic University, Semarang, Indonesia","2022 6th International Conference on Information Technology (InCIT)","21 Mar 2023","2022","","","347","351","The purpose of this paper is to describe the process of creating an Android-based application with Augmented Reality feature as well as the user’s evaluation of the application. The application was created to equip students with some knowledge on digital citizenship. As the users of digital technologies, college students have to have the ability to peruse technology and participate in online activities in a responsible, safe, and legal manner. The augmented reality-based application was designed to teach students the nine elements of digital citizenship. This paper also explains the feedback from the users of the application to further improve the functionalities of the application for future use.","","978-1-6654-8912-6","10.1109/InCIT56086.2022.10067309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10067309","Augmented Reality;Gamification;Digital Citizenship","Law;Information technology;Augmented reality","Android (operating system);augmented reality;computer aided instruction;educational courses;further education;human factors;teaching","Android-based application;augmented reality-based application;college students;digital citizenship;digital technologies;teaching;user evaluation","","","","10","IEEE","21 Mar 2023","","","IEEE","IEEE Conferences"
"Object Management Based on Metadata Registry for Intelligent Mobile Augmented Reality","S. -B. Jang","Department of Industry-Academy, Kumoh National Institute of Technology, Gumi, Gyeongbuk, South Korea","2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)","21 Mar 2019","2019","","","572","574","An intelligent mobile augmented reality (IMAR) can be a useful scheme when users want get additional information about products or objects in a store. One of the problems to be resolved in the service is how to manage huge number of augmented objects. One of the approaches is to separate object's metadata from real objects. By doing this, we can reduce amount of storage and object searching time. However, to apply such scheme seamlessly, we have to well organize each object's metadata and store them efficiently. To do this, this paper present a scheme that is based on metadata registry (MDR). In the scheme, all objects are organized in the ways specified by MDR standards.","","978-1-5386-7822-0","10.1109/ICAIIC.2019.8669074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669074","mobile augmented reality;AR objects management;metadata registry","Metadata;Servers;Augmented reality;Standards organizations;Organizations;ISO Standards","augmented reality;meta data;mobile computing","object management;metadata registry;intelligent mobile augmented reality","","","","8","IEEE","21 Mar 2019","","","IEEE","IEEE Conferences"
"QR Code Augmented Reality tracking with merging on conventional marker based Backpropagation neural network","G. M. Agusta; K. Hulliyah; Arini; R. B. Bahaweres","Department of Computer Science, State Islamic University Syarif Hidayatullah Jakarta, Jakarta, Indonesia; Department of Computer Science, State Islamic University Syarif Hidayatullah Jakarta, Jakarta, Indonesia; Department of Computer Science, State Islamic University Syarif Hidayatullah Jakarta, Jakarta, Indonesia; Department of Computer Science, State Islamic University Syarif Hidayatullah, Jakarta","2012 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","25 Feb 2013","2012","","","245","248","QR Code Augmented Reality (QRAR) is an Augmented Reality does not require preregistration, it has 107089 combination ID-encoded and can be used on the public AR application. The results from previous research are 6 DOF tracking method less accurate, require small computation power and unstable marker. We propose merging conventional marker with QR Code, but it will have noise on the QR Code Finder Patter (QRFP) under perspective distortion, so we propose a Backpropagation method to keep detecting the QRFP and the method preceded by feature extraction with low level image processing. The methods we have proposed, achieve accurate 6 DOF, runs at 35.41 fps and stable marker as conventional marker.","","978-1-4673-3026-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6468772","Augmented Reality;QR Code;QR Code Finder Pattern Detection;Tracking;6 DOF;Backpropagation;Neural Network","Augmented reality;Backpropagation;Merging;Noise;Accuracy;Feature extraction;Biological neural networks","augmented reality;backpropagation;feature extraction;image processing;neural nets","QR code augmented reality tracking;conventional marker based backpropagation neural network;QRAR;ID-encoded;public AR application;QR code finder patter;QRFP;perspective distortion;feature extraction;low level image processing","","","1","10","","25 Feb 2013","","","IEEE","IEEE Conferences"
"Non-rigid registration using AAM and factorization method for augmented reality applications","Yuan Tian; Zhongyi Li; Wei Liu; Lijun Li; Tao Guan","Digital Engineering & Simulation Research Center, Huazhong University of Science and Technology, Wuhan, China; Digital Engineering & Simulation Research Center, Huazhong University of Science and Technology, Wuhan, China; Digital Engineering & Simulation Research Center, Huazhong University of Science and Technology, Wuhan, China; Digital Engineering & Simulation Research Center, Huazhong University of Science and Technology, Wuhan, China; Digital Engineering & Simulation Research Center, Huazhong University of Science and Technology, Wuhan, China","2008 12th International Conference on Computer Supported Cooperative Work in Design","10 Jun 2008","2008","","","705","709","This paper presents a novel non-rigid registration method for augmented reality applications using AAM and factorization method. The method can be divided into two stages: offline construction of 3D shape basis and online estimation of the 3D pose parameters together with the 3D shape coefficients. In offline stage, we get the training data with the use of the AAM algorithm, then we use factorization method to obtain the object 3D shape basis set from image sequences. In online stage, given an initial 3D shape coefficients and the rotation matrix, we can get the non-rigid object coordinates under the world coordinate systems by projecting the 3D points which are the linear combination of the 3D shape basis to the 2D image. Then we use Levenberg-Marquardt algorithm to optimize the 3D shape coefficients and the 3D pose parameters simultaneously. Some experimental results demonstrate this method is effective and useful for augmented reality applications.","","978-1-4244-1650-9","10.1109/CSCWD.2008.4537064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4537064","Augmented Reality;Computer Vision;Registration;Factorization Method;AAM","Active appearance model;Augmented reality;Shape;Computer vision;Image sequences;Application software;Video sequences;Training data;Face detection;Facial features","augmented reality;image registration;image sequences;matrix decomposition;pose estimation","nonrigid image registration;active appearance models;augmented reality;factorization method;3D shape basis;3D pose parameter estimation;image sequences;3D shape coefficients","","","","15","IEEE","10 Jun 2008","","","IEEE","IEEE Conferences"
"Augmented Reality and Gamification technics for visit enhancement in archaeological parks","F. Clarizia; F. Colace; M. D. Santo; A. Lorusso; F. Marongiu; D. Santaniello","DIPSUM, University of Salerno, Fisciano, SA; DIIn, University of Salerno, Fisciano, SA; DIIn, University of Salerno, Fisciano, SA; DIIn, University of Salerno, Fisciano, SA; DIIn, University of Salerno, Fisciano, SA; DIIn, University of Salerno, Fisciano, SA","2022 IEEE 2nd IoT Vertical and Topical Summit for Tourism (IoTT)","25 Oct 2022","2022","","","1","4","The use of innovative technological approaches in the field of cultural heritage is now becoming essential to preserve and enhance tangible and intangible cultural heritage. Special attention can be paid to enhancing the visitor experience using gamification approaches by exploiting new technologies. Augmented reality is one of the most significant tools that enable a special interaction between the user and the environment. The possibility of enriching the real environment with three-dimensional models opens up the possibility of narrating the real place with innovative storytelling not only of the environment itself but also and above all, telling and conveying all that is the intangible heritage that a place inevitably brings with it. To take advantage of this opportunity, the study focused on defining a methodology to apply advanced augmented reality and storytelling techniques combined with gamification techniques to enhance the visitor experience in a medium to large-scale archaeological sites. The methodology was then applied to a case study on the archaeological park of Pompeii, which saw the creation of an application prototype that demonstrated the validity of the approach.","","978-1-6654-5888-7","10.1109/IoTT56174.2022.9925901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9925901","Augmented reality;Cultural Heritage;e-Culture;e-Tourism","Solid modeling;Prototypes;Cultural differences;Global communication;Augmented reality;Smart phones","archaeology;augmented reality;computer games;history;museums","gamification approaches;significant tools;special interaction;three-dimensional models;innovative storytelling;telling conveying;intangible heritage;advanced augmented reality;storytelling techniques;gamification techniques;visitor experience;large-scale archaeological sites;gamification technics;visit enhancement;archaeological parks;innovative technological approaches;tangible heritage;intangible cultural heritage","","","","16","IEEE","25 Oct 2022","","","IEEE","IEEE Conferences"
"Augmented Reality Applications for Children to Learn English Alphabets","A. Sherine; T. A. Olbernt","School of Computing and Creative Media, University of Technology Sarawak, Malaysia; School of Computing and Creative Media, University of Technology Sarawak, Malaysia","2022 International Conference on Green Energy, Computing and Sustainable Technology (GECOST)","12 Jan 2023","2022","","","476","481","The modern era of smartphones and gadgets technology has become a human essential as to communicate, and different mobile application are been developed to make life easier. Hence, these smartphones and gadget will keep gradually upgrade from time to time and nowadays they are most commonly used by almost every age including the children. Nowadays most all of the young generation have their own smartphones and this led to almost all of the young generation are too focused with technological advancement that they loss their interest in learning. The traditional method way of teaching the children is not interesting enough to grab the interest of children. Therefore, this is one the reason why the children are not focused in learning. In consequence, the development of this project is to tackle the problems of children losing their focus on learning plus introduce them new and advanced technology called Augmented Reality. This application will be using Unity 3D as the main software requirement in developing this project application. Besides that, this application is developed to evaluate the user acceptance of augmented reality to learn English alphabets. Thus, with this the application will be available in android phone where android is more popular and easily obtained. Furthermore, not only the application can be educational its also consist gamification-based module. Additionally, this application will grasp the interest of the children where they can learn and have fun at the same time. Apart from that, this application is free to use. Finally, the goal of this project is to help the children in learning English alphabets.","","978-1-6654-8663-7","10.1109/GECOST55694.2022.10010384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010384","Gamification;Augmented Reality;Unity 3D","Three-dimensional displays;Education;Software;Mobile applications;Smart phones;Augmented reality","augmented reality;computer aided instruction;computer games;mobile computing;smart phones","Augmented Reality applications;children;different mobile application;gadgets technology;learning English alphabets;project application;smartphones;young generation","","","","14","IEEE","12 Jan 2023","","","IEEE","IEEE Conferences"
"Demo paper: Particle-based augmented reality interactive system","Pei-Hsuan Chiu; Kai-Ten Feng; Po-Hsuan Tseng","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; National Taipei University of Technology, Taipei, TW","2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)","3 Oct 2013","2013","","","1","2","With enhanced processing capability of mobile platforms, augmented reality (AR) has been considered a promising technology for achieving enhanced user experiences (UX). AR is to impose virtual information onto the real camera view of mobile platforms. In this demonstration, a particle-based augmented reality interactive system (PARIS) is designed to provide interactive AR for enhanced UX. The proposed PARIS consists of two parts, including the markerless pattern recognition (MPR) enabling the projection of recognized 3-D objects onto the real camera view and particle filter based hand tracking algorithms to provide interaction with the 3-D objects. Implementation of PARIS is realized on Android-based mobile platforms, where low computational complexity has been observed for real-time interaction.","","978-1-4799-1604-7","10.1109/ICMEW.2013.6618229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618229","Augmented reality;particle filter","Image color analysis;Augmented reality;Cameras;Mobile communication;Pattern recognition;Real-time systems;Indexes","augmented reality;computational complexity;mobile computing;object recognition;object tracking;particle filtering (numerical methods)","particle-based augmented reality interactive system;user experiences;UX;virtual information;PARIS;markerless pattern recognition;MPR;3D object recognition;particle filter based hand tracking algorithms;Android-based mobile platforms;computational complexity","","","","6","IEEE","3 Oct 2013","","","IEEE","IEEE Conferences"
"DVAR: Data Visualization using Augmented Reality","P. Padwal; Y. Singh; J. Singh; S. Pansambal","Department Of Computer Engineering, Atharva College of Engineering, Mumbai University, Mumbai, India; Department Of Computer Engineering, Atharva College of Engineering, Mumbai University, Mumbai, India; Department Of Computer Engineering, Atharva College of Engineering, Mumbai University, Mumbai, India; Department Of Computer Engineering, Atharva College of Engineering, Mumbai University, Mumbai, India","2021 2nd Global Conference for Advancement in Technology (GCAT)","9 Nov 2021","2021","","","1","6","In this paper, we have discussed the use of augmented reality for data visualization. As we know that data is one of the most valued resources of today’s world, analysis of this data is a task of great importance. Multiple technologies have come up with data visualization for enabling accurate data analysis. Clearer the visualization the easier it is to perform accurate data analysis. Another technology that has grown vastly in various domains is Augmented Reality. It aims to bridge the gap between the physical and the digital world by introducing virtual elements into our environment. Our Implementation is a use case of AR technology in data visualization and analytics. Our proposed system uses mobile AR to perform data visualization giving more engagement and immersion to the users which can be used to gain more human insights over data such as trends and patterns that would otherwise get missed out in a depthless 2D visualization. We have developed an application as a prototype of our proposed system demonstrating different visualization techniques.","","978-1-6654-1836-2","10.1109/GCAT52182.2021.9587831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9587831","Data visualization;Augmented Reality;Unity;AR Core;Mobile Devices;2D;3D;Stepped/Prism Map;Bar Graph;Scatter Plot;Mathematical Surfaces;Machine Learning.","Data analysis;Data visualization;Prototypes;Market research;Task analysis;Augmented reality","augmented reality;data analysis;data visualisation;photography","data visualization;augmented reality;accurate data analysis","","","","19","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"A survey of Interactive Technology in Augmented Reality","J. Zhi; R. Xie; H. liu; X. Wang; G. Yang; P. Peng; X. Luo; Y. Chen","North China Electric Power University, Beijing, China; North China Electric Power University, Beijing, China; North China Electric Power University, Beijing, China; North China Electric Power University, Beijing, China; North China Electric Power University, Beijing, China; State Grid Shanghai Municipal Electric Power Company, Shanghai, China; State Grid Shanghai Municipal Electric Power Company, Shanghai, China; State Grid Shanghai Municipal Electric Power Company, Shanghai, China","2020 2nd International Conference on Information Technology and Computer Application (ITCA)","7 May 2021","2020","","","101","104","Interaction technology is one of the core technologies of augmented reality. With the maturity of augmented reality hardware technology and the expansion of application field, interaction technology has been paid more attention and development. This paper sorts out the classification methods of interaction technology, focuses on the research status of interaction technology based on computer vision, external devices and multi-modal, as well as the selection of 3D objects, introduces the latest typical application of interaction technology. Finally, the interaction technology is summarized and prospected.","","978-1-6654-0378-8","10.1109/ITCA52113.2020.00028","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9422004","augmented reality;interactive technology;computer vision;external devices;multi-modal;target selection","Computer vision;Three-dimensional displays;Computer applications;Hardware;Information technology;Augmented reality","augmented reality;computer vision;feature selection;image classification;interactive devices;stereo image processing","interaction technology;interactive technology;augmented reality;classification methods;computer vision;external devices;multimodal;3D object selection","","","","22","IEEE","7 May 2021","","","IEEE","IEEE Conferences"
"Digital research of Augmented reality Wearable terminal in Power equipment Quality control business","X. Sun; J. Zhao; J. Zhu; X. Zhang; S. Liao; K. Qin","Electric Power Research Institute China Southern Power Grid, Guangzhou, P.R.China; Electric Power Research Institute China Southern Power Grid, Guangzhou, P.R.China; Electric Power Research Institute China Southern Power Grid, Guangzhou, P.R.China; Electric Power Research Institute China Southern Power Grid, Guangzhou, P.R.China; Shenzhen Power Supply Co., Ltd., Shenzhen, P.R.China; Shenzhen Power Supply Co., Ltd., Shenzhen, P.R.China","2022 IEEE 9th International Conference on Power Electronics Systems and Applications (PESA)","15 Feb 2023","2022","","","1","4","The traditional power equipment material quality control business relies on the work experience of field operators, it fails to form standardized digital information records, and has poor traceability. In order to improve the above problems, this paper designed a digital power material quality control information system based on augmented reality technology, and developed an augmented reality wearable intelligent terminal device based on 5G communication and artificial intelligence technology. This has formed an innovative operation mode of audio and video recording of important work information at business key points and remote interactive support of experts; The professional orientation functions such as spatial ranging, vernier caliper reading recognition and partial discharge characteristic spectrum recognition are realized. Relying on the developed system and device, the digital upgrade, cost reduction and efficiency increase of power equipment manufacturing supervision, inspection and detection business are realized.","","978-1-6654-8668-2","10.1109/PESA55501.2022.10038371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10038371","Augmented reality wearable intelligent terminal;audio and video recording;remote interaction","Technological innovation;Wearable computers;Quality control;Inspection;Manufacturing;Character recognition;Augmented reality","5G mobile communication;artificial intelligence;audio recording;augmented reality;cost reduction;information systems;inspection;power apparatus;production engineering computing;quality control;video recording","5G communication technology;artificial intelligence technology;audio recording;augmented reality wearable intelligent terminal device;cost reduction;digital power material quality control information system;innovative operation mode;inspection;partial discharge characteristic spectrum recognition;power equipment quality control business;vernier caliper reading recognition;video recording","","","","5","IEEE","15 Feb 2023","","","IEEE","IEEE Conferences"
"A preliminary study of a hybrid user interface for augmented reality applications","F. Manuri; G. Piumatti","Politecnico di Torino Dipartimento di Automatica e Informatica C.so Duca degli, Torino, Italy; Politecnico di Torino Dipartimento di Automatica e Informatica C.so Duca degli, Torino, Italy","2015 7th International Conference on Intelligent Technologies for Interactive Entertainment (INTETAIN)","12 Nov 2015","2015","","","37","41","Augmented Reality (AR) applications are nowadays largely diffused in many fields of use, especially for entertainment, and the market of AR applications for mobile devices grows faster and faster. Moreover, new and innovative hardware for human-computer interaction has been deployed, such as the Leap Motion Controller. This paper presents some preliminary results in the design and development of a hybrid interface for hand-free augmented reality applications. The paper introduces a framework to interact with AR applications through a speech and gesture recognition-based interface. A Leap Motion Controller is mounted on top of AR glasses and a speech recognition module completes the system. Results have shown that, using the speech or the gesture recognition modules singularly, the robustness of the user interface is strongly dependent on environmental conditions. On the other hand, a combined usage of both modules can provide a more robust input.","","978-1-6319-0061-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325483","Augmented Reality;hybrid user interface;human-computer interaction;speech recognition;gesture recognition","Speech recognition;Gesture recognition;Robustness;Augmented reality;Speech;Glass;Cameras","augmented reality;control engineering computing;entertainment;gesture recognition;human computer interaction;mobile computing;mobile handsets;motion control;speech recognition;user interfaces","hybrid user interface;entertainment;mobile devices;human-computer interaction;leap motion controller;hand-free augmented reality applications;gesture recognition-based interface;speech recognition-based interface;AR glasses;speech recognition module","","","","25","","12 Nov 2015","","","IEEE","IEEE Conferences"
"Augmented Reality Based Platform for Simulation of 3D Models, Generated with a Series of 2D Images, on Real Environment","S. A. D. N. N. Ashinshanie; A. Hazari; H. N. Rupasinghe; D. P. Hettiarchchi; D. I. De Silva","Department of Information Technology, Sri Lanka Institute of Information Technology, Malabe, Colombo, LK; Department of Information Technology, Sri Lanka Institute of Information Technology Malabe, Sri Lanka; Dept. of Inf. Technol., Sri Lanka Institute of Information Technology, Malabe, Colombo, LK; Dept. of Inf. Technol., Sri Lanka Institute of Information Technology, Malabe, Colombo, LK; Dept. of Inf. Technol., Sri Lanka Institute of Information Technology, Malabe, Colombo, LK","2014 European Modelling Symposium","13 Jul 2015","2014","","","77","81","With the need of an Augmented Reality based platform for simulation of three dimension models, generated with a series of two dimension images, on real environment, the main objective of this project is to build a platform for users to use both these functionalities. This is a mobile application which helps people to decide when they are buying household items, whether that item fits their desired place in the house. Three dimension models can be downloaded using the application and it will be simulated in the real time environment using the concept of Augmented Reality. A desktop application will be implemented for sellers to upload their three dimension models and to generate three dimension models using photographs. With the use of the technology people can make their lives easier, and this is another step the development team has taken to help that cause. Main goal is that with the use of this application people will be able to make their decisions easily when they are going to buy large household items.","","978-1-4799-7412-2","10.1109/EMS.2014.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153978","Structure from motion; Augmented Reality; Software Development Kit; Two dimension; Three dimension","Image reconstruction;Augmented reality;Cameras;Three-dimensional displays;Mobile communication;Solid modeling;Software","augmented reality;mobile commerce;purchasing;solid modelling","augmented reality based platform;3D model simulation;2D images;mobile application;3D models;photographs;household items","","","","4","IEEE","13 Jul 2015","","","IEEE","IEEE Conferences"
"Design of Optical System of Augmented Reality Near Eye Device","C. -K. Chang; F. -M. Yeh; J. -H. Lue; H. -F. Wang; Y. -H. Hsieh; C. -Y. Chiang; D. -C. Chen; C. -L. Tien","Department of Optometry, Yuanpei University of Medical Technology, Hsinchu, Taiwan; Department of Optometry, Yuanpei University of Medical Technology, Hsinchu, Taiwan; Department of Optometry, Taiwan University of Science and Technology, Taichung, Taiwan; Department of Aeronautical Engineering, National Formosa University, Yunlin, Taiwan; Department of Healthcare Information and Management, Ming Chuan University, Taoyuan, Taiwan; Ph.D. Program of Electrical and Communications Engineering, Feng Chia University, Taichung, Taiwan; Department of Optometry, Yuanpei University of Medical Technology, Hsinchu, Taiwan; Department of Electrical Engineering, Feng Chia University, Taichung, Taiwan","2023 IEEE 6th Eurasian Conference on Educational Innovation (ECEI)","24 Apr 2023","2023","","","333","335","Augmented reality (AR) is a technology that instantly merges digital pictures with the real scene. The perspective near-eye display is a key module of AR, through which computer-generated pictures or videos can be displayed in the existing environment. The purpose of this research is to establish the system structure of an augmented reality near-eye display device and to design the off-axis two-piece reflective aspherical mirror. Because AR glasses are wearable and are worn close to the eyes, not only the optical performance of the display but also the clear vision of the user needs to be considered. In this study, an off-axis two-piece reflective aspherical mirror is used as the optical system of the AR for displaying the digital image. The micro-display is placed at the focal point of the optical system to form a digital image, and the horizontal movement of the micro-display along the optical axis is controlled by a precise displacement mechanism so that the patient with uncorrected myopia or hyperopia can see the digital picture and real scene. Because the right and left micro-displays move horizontally independently, the user can see the images on the AR device, which becomes the biggest feature of this study.","","979-8-3503-3428-9","10.1109/ECEI57668.2023.10105258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10105258","Augmented reality;parabolic;focal length","Performance evaluation;Technological innovation;Optical design;Digital images;Optical imaging;Optical reflection;Augmented reality","aspherical optics;augmented reality;display devices;eye;mirrors;optical design techniques;vision defects","AR device;augmented reality;computer-generated pictures;digital image;digital picture;eye device;key module;microdisplay;near-eye display device;off-axis two-piece;optical axis;optical performance;optical system;perspective near-eye display;reflective aspherical mirror;system structure","","","","5","IEEE","24 Apr 2023","","","IEEE","IEEE Conferences"
"How different in cultural acceptance of tutoring robots serving augmented reality?","J. Han; E. Hyun; M. Kim; H. Cho; T. Kanda; T. Nomura","Cheongju National University of Education, South Korea; SungKyunKwan University, Seoul, South Korea; SungKyunKwan University, Seoul, South Korea; Hansung University, Seoul, South Korea; ATR Intelligent Robotics and Communication Laboratories, Japan; Ryukoku University, Japan","2009 11th International Conference on Advanced Communication Technology","3 Apr 2009","2009","03","","2006","2008","The difference of user's perception seems to have been well reflected in the development of robot technology. In this study, we attempted to compare and analyze how cultural features in three different countries i.e. Korea, Japan, and Europe affect parents and children in accommodating tutoring robots for education. It was revealed that parents in Europe representing western countries are generally more inflexible and negative on purchasing tutoring robots than those of Korea and Japan. The expectations of parents on the practical use, service of augmented reality, of tutoring robots turned out to be higher in Korea than in Europe and Japan. Japanese and Europe parents hold more conservative attitudes toward tutoring robots than Korean. In contrast, Korean parents are most liberal and less resistant to educating their children by robots, probably due to the fact that e-Learning is widely used and has just begun to enter r-Learning in the Korean society. The fact that a substantial number of students felt pressed despite positive expectation for contents based on identification in a class may provide useful information in setting up new guidelines for children served augmented reality by tutoring robots.","1738-9445","978-89-5519-138-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809473","Tutoring Robots;User Perception;Augmented Reality;e-Learning;r-Learning","Cultural differences;Augmented reality;Educational robots;Intelligent robots;Europe;Educational technology;Technological innovation;Global communication;Electronic learning;Service robots","augmented reality;computer aided instruction;human factors;robots;social aspects of automation","tutoring robots;augmented reality;user perception;robot technology;e-Learning;r-Learning;cultural acceptance","","","","14","","3 Apr 2009","","","IEEE","IEEE Conferences"
"House Hold Guide Using Augmented Reality","S. V. S. Prasanth; A. Sriram; K. Akhila","SRM Institute of Science and Technology, Kancheepuram district, Tamil Nadu; SRM Institute of Science and Technology, Kancheepuram district, Tamil Nadu; SRM Institute of Science and Technology, Kancheepuram district, Tamil Nadu","2018 International Conference on Communication and Signal Processing (ICCSP)","8 Nov 2018","2018","","","0269","0271","Human work produces desired output but we wondered how can a computer understand human thoughts and actions a few years ago. But, in no time, our dream is put in action. Virtual animations and presentations have taken over the traditional man made works. Augmented reality is one such kind in which an image is read and a computer generated replica is displayed. Augmented reality is the technology that superimposes a computer-generated image on a user's view of the real world, thus providing a conventional view. It has its own advantages in various fields like Medicine, Engineering and Science. In the fields of engineering, image processing can be used to improve images in visual courses like tutorials for automation where imagining the working of an automated device is difficult. The same concept can be applied on for house hold devices. House hold devices may develop some technical issues due to wear and tear and need immediate attention. A technician might not be available always at that moment. But, the house hold guide would no longer let you wait until help arrives. It will teach you the whole procedure on how to fix the problem step by step. It requires a portable CPU and a display. Since this device is product oriented, the procedure of fixing any house hold equipment has to be first fed into the device and then can be used at some time later. After the device is taught with the procedure, it will guide the user when he comes across the problem while using that device. For instance, installing a table fan can be taught to any person who has no prior knowledge about it using this house hold guide. In this way, a house hold guide can help every person in all the troublesome equipment in his/her house.","","978-1-5386-3521-6","10.1109/ICCSP.2018.8524213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8524213","Augmented Reality;Raspberry Pi;Image processing","Augmented reality;Image processing;Three-dimensional displays;Transforms;Software;Cameras;Lighting","augmented reality;computer animation;educational courses;handicapped aids;image processing;teaching","house hold devices;house hold guide;house hold equipment;augmented reality;computer-generated image;image processing;automated device;virtual animations;visual courses;tutorials;portable CPU","","","","11","IEEE","8 Nov 2018","","","IEEE","IEEE Conferences"
"Peer to peer media management for augmented reality","R. K. Ege","Dept. of Computer Science, Northern Illinois University, DeKalb, IL, USA","2015 IEEE International Conference on Electro/Information Technology (EIT)","8 Oct 2015","2015","","","095","100","Immersion into rich multimedia is now the norm in today's Internet. Combining multiple streams of textual, audio and media data from a variety of sensors and sources, allow the presentation of a world that is almost “real”. Users equipped with portable and wearable devices can become consumers and contributors to an augmented reality. In this paper we describe a general software architecture for an augmented reality immersion network based on crowd sourced media gathering and distribution. We describe a prototypical implementation with cloud and mobile components to establish a secure sharing network, to coordinate and to synchronize the media streams. Joining the content sharing network is subject to peer-to-peer trust management to protect the content and the participants.","2154-0373","978-1-4799-8802-0","10.1109/EIT.2015.7293423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7293423","Android;augmented reality;multi-media content delivery;securing trust;peer-to-peer systems","Media;Peer-to-peer computing;Java;Augmented reality;Sensors;Streaming media;Mobile communication","augmented reality;cloud computing;media streaming;mobile computing;peer-to-peer computing;software architecture;trusted computing","peer to peer media management;multimedia;Internet;portable device;wearable device;software architecture;augmented reality immersion network;crowd sourced media gathering;cloud component;mobile component;sharing network security;content sharing network;peer-to-peer trust management;content protection;participant protection;media streaming","","","","13","IEEE","8 Oct 2015","","","IEEE","IEEE Conferences"
"Impact of Augmented Reality as an ICT tool to Deliver Engineering Education Content","S. Jacob; M. Warde; P. Dumane","Department of Electronics Engineering, Atharva College of Engineering, Mumbai, India; Eduvance, Mumbai, India; Department of Electronics and Telecommunications Engineering, Don Bosco Institute of Technology, Mumbai, India","2020 International Conference on Convergence to Digital World - Quo Vadis (ICCDW)","20 Jan 2021","2020","","","1","5","Augmented reality has found itself as an excellent candidate to deliver content for education. There is a definite need for improved visualization when it comes to Engineering education. AR could present itself as a good candidate to do so. This paper presents the use of Augmented Reality for engineering education. The need for visualization finds itself at the core of imparting Engineering education and there are various platforms to do so. We continue the work presented in an earlier publication where we have implemented our smartbooks concept for delivering an engaging AR experience. We have presented the use of AR for delivering content for three fundamental engineering subjects: Engineering mechanics, engineering drawing and electrical engineering. We have also explored a different user interface to improve our AR content delivery. Examples for each are demonstrated and so are their use cases. Measuring the impact of using AR was a particular challenge with variable usage across students. We have defined certain metrics (engagement factor) that help us correlate usage with impact. We have measured the impact of our AR implementation through well designed questionnaires, and used the academic scores of the candidates as an output metric to measure impact. The objective of this research is to present a case for the use of AR in being a front-runner ICT technology for delivering engineering education.","","978-1-7281-4635-5","10.1109/ICCDW45521.2020.9318709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318709","augmented reality;electronics;education technology;engineering education","Augmented reality;Three-dimensional displays;Tools;Visualization;Engineering education;Animation;Rendering (computer graphics)","augmented reality;computer aided instruction;engineering education","AR content delivery;augmented reality;improved visualization;engineering mechanics;engineering drawing;electrical engineering;engineering education content","","","","22","IEEE","20 Jan 2021","","","IEEE","IEEE Conferences"
"Augmented Reality Environment for the trajectory tracking of mobile robot","B. IBARI; K. BOUZGOU; R. AYAD; L. BENCHIKH; Z. Ahemed-Foitih; M. BENNAOUM","Dept. of Electrical Engineering, University Mustapha Stambouli of Mascara, Mascara, Algeria; Laboratory of L.E.P.E.S.A, University Mustapha Stambouli of Mascara, Oran, Algeria; Dept. of electronic, Universiry of chlef, Chlef, Algeria; IBISC laboratory, Universiry of chlef, Evry, France; Laboratory of L.E.P.E.S.A, University Mustapha Stambouli of Mascara, Oran, Algeria; University of Mascara, Mascara, France","2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP)","29 Jul 2020","2020","","","278","281","In this paper, we present an Augmented Reality Environment (RAE) to guide a mobile robot. The objective of this work is to allow a user to control and follow a desired trajectory. In this context, we propose a control design based on a Augmented Reality technology to facilitate the piloting of the robot. This work proposes a hardware and software architecture based on Graphic User Interface (GUI)for tracking trajectory using a virtual objects. The results obtained is show the good performances of the proposed AR environment for the simplicity of using the AR system for planning and execution of the robot's trajectories.","","978-1-7281-5835-8","10.1109/CCSSP49278.2020.9151764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151764","Augmented Reality;Mobile Robot;Trajectory tacking","Mobile robots;Augmented reality;Trajectory;Graphical user interfaces;Cameras;Robot vision systems","augmented reality;control engineering computing;control system synthesis;graphical user interfaces;mobile robots;software architecture;trajectory control","AR environment;augmented reality environment;trajectory tracking;mobile robot;control design;graphic user interface;hardware architecture;software architecture;virtual objects;robot trajectories","","","","10","IEEE","29 Jul 2020","","","IEEE","IEEE Conferences"
"A pipelined augmented reality system","Nguyen Quang Tung; Nguyen Thi Ngoc Vinh; Heesung Jun","School of Computer Engineering and Information Technology, University of Ulsan, Ulsan, South Korea; School of Computer Engineering and Information Technology, University of Ulsan, Ulsan, South Korea; School of Computer Engineering and Information Technology, University of Ulsan, Ulsan, South Korea","2008 Third International Forum on Strategic Technologies","19 Aug 2008","2008","","","359","363","Performance is one of critical issues in Augmented Reality (AR) system. In this paper, we introduce a pipeline framework model used for AR system, referenced as Pipelined Augmented Reality System. Pipelining exploits parallel at thread level and each critical process can run on a separate thread. Using pipelining in AR system, we can improve the performance of system significantly. We also use object-oriented concept to design and implement this pipeline framework. The evaluation result shows that the performance of the pipelined AR system is better than that of the normal AR system.","","978-1-4244-2319-4","10.1109/IFOST.2008.4602835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4602835","augmented reality;pipeline framework;parallel processing","Pipeline processing;Pipelines;Object oriented modeling;Three dimensional displays;Augmented reality;Data models;Software","augmented reality;object-oriented programming;pipeline processing","pipelined augmented reality system;system performance improvement;object-oriented concept;pipeline framework design","","","","10","IEEE","19 Aug 2008","","","IEEE","IEEE Conferences"
"Speeded Up Robust Features Algorithm on Augmented Reality for Sirah Nabawiyah Learning Media","D. R. Ramdania; A. Wahana; C. H. Nurulaeni; Y. A. Gerhana; W. B. Zulfikar","Department of Informatics, UIN SunanGunung Djati, Bandung, Indonesia; Department of Informatics, UIN SunanGunung Djati, Bandung, Indonesia; Department of Informatics, UIN SunanGunung Djati, Bandung, Indonesia; Department of Informatics, UIN SunanGunung Djati, Bandung, Indonesia; Department of Informatics, UIN SunanGunung Djati, Bandung, Indonesia","2022 IEEE 8th International Conference on Computing, Engineering and Design (ICCED)","13 Jan 2023","2022","","","1","6","Based on the survey results, 85% of young children do not know about the history of the prophet or the miracles that were revealed to the prophet. Studying the history of the prophet is an embodiment of the 4th pillar of faith, namely Faith in the Prophet. Given the urgency, several learning media in various forms have been created and marketed to introduce Sirah nabawiyah, one of which is Augmented Reality. This study aims to build an application to recognize the history of the prophet using Augmented Reality. The Speeded Up Robust Features (SURF) algorithm is applied to detect AR markers. Based on the effectiveness test results, the application can display objects with an average time of 0.17 seconds for a distance of 10 cm, 0.23 seconds for a distance of 20 cm, and 0.34 seconds for a distance of 30 cm. This shows that the algorithm can function well in detecting objects.","2767-7826","978-1-6654-5389-9","10.1109/ICCED56140.2022.10010625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010625","Augmented Reality;Sirah nabawiyah;speeded up robust features (SURF)","Three-dimensional displays;Technology acceptance model;Media;Feature extraction;Cameras;History;Augmented reality","augmented reality;computer aided instruction;feature extraction","AR markers;augmented reality;robust features algorithm;Sirah nabawiyah learning media;young children","","","","38","IEEE","13 Jan 2023","","","IEEE","IEEE Conferences"
"Augmented Reality and Deep Learning Guided Task Oriented Robot","Q. Duan; X. Zhu; L. Feng; X. Li; Q. Yin; J. Zhao; M. Gao; L. Wang; Q. Luo; J. Wang; R. Li","Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Yingxin Computer Technology Co., Ltd., China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China; Shandong Institute of New Generation Information Industry Technology Co. Ltd, China","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","3241","3245","Robot navigation is one of the key features in robot system, which can be done in several ways. Different approaches show both strength and weakness, and the choice usually relies on the targeted scenario. The current work proposes a robot navigation system that works indoor for a certain specified task. In the system, augmented reality, SLAM (simultaneous localization and mapping) and deep learning are used to guide a robot. Augmented reality acts an interface bridging the physical and virtual world together. SLAM offers the robot the ability to sense the physical world. Deep learning enables the robot to recognize objects. As a result, a robot can follow the expected routine to get a task done without colliding.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9602607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9602607","Augmented Reality;SLAM;Deep Learning;Convolution","Deep learning;Simultaneous localization and mapping;Navigation;Task analysis;Augmented reality","augmented reality;learning (artificial intelligence);mobile robots;path planning;robot vision;SLAM (robots)","robot navigation system;specified task;augmented reality;physical world;virtual world;deep learning;task oriented robot;robot system;targeted scenario","","","","10","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Mobile Application with Augmented Reality for the learning of the cell","J. C. Tazza Alejos; R. Johny Pretell Cruzado; M. Cabanillas-Carbonell; J. L. Herrera Salazar","Facultad de Ingeniería y Arquitectura, Universidad Autónoma del Perú, Lima, Perú; Facultad de Ingeniería y Arquitectura, Universidad Autónoma del Perú, Lima, Perú; Facultad de Ingeniería, Universidad Privada del Norte, Lima, Perú; Facultad de Ingeniería y Negocios, Universidad Norbert Wiener, Lima, Perú","2020 IEEE Congreso Bienal de Argentina (ARGENCON)","13 Aug 2021","2020","","","1","4","This study shows the effects resulting from the implementation of a mobile application with augmented reality for the learning of the cell. The Mobile-D methodology was used for this study, whose focus and properties are mainly targeted at the mobile device market. The quasi-experimental design was used in a sample of 40 fifth-grade students from a private school in Lima, which was divided into two groups of 20 students: a control and an experimental group. And it was found the experimental group achieved a significant improvement in the learning level compared to the control. Lastly, it is concluded that the use of a mobile application with augmented reality has significantly improved in three aspects of learning.","","978-1-7281-5957-7","10.1109/ARGENCON49523.2020.9505321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9505321","Mobile application;Augmented Reality;Learning;Mobile - D","Mobile handsets;Mobile applications;Augmented reality","augmented reality;biology computing;computer aided instruction;educational courses;educational institutions","mobile application;augmented reality;mobile device market;quasiexperimental design;fifth-grade students;learning level;mobile-D methodology","","","","22","IEEE","13 Aug 2021","","","IEEE","IEEE Conferences"
"Community Interaction and Marketing Using 3D Coloring Augmented Reality in Zhongxing New Village","C. -M. Lin; T. -C. Lin; Y. -C. Lin; C. -M. Wang; C. -R. Dow","Department of Digital Living Innovation, Nan Kai University of Technology, Nantou, Taiwan; Department of Digital Media Design, National Yunlin University of Science and Technology, Yunlin, Taiwan; Department of Digital Media Design, National Yunlin University of Science and Technology, Yunlin, Taiwan; Department of Digital Media Design, National Yunlin University of Science and Technology, Yunlin, Taiwan; Department of Information Engineering and Computer Science, Feng-Chia University, Taichung, Taiwan","2018 15th International Symposium on Pervasive Systems, Algorithms and Networks (I-SPAN)","7 Feb 2019","2018","","","272","276","Zhongxing New Village is located in Nantou City, Nantou County, Taiwan. It was given the beautiful name of the Garden City in 1956. Using smart living technology to reproduce the village prosperity is a relevant research topic for this location. This paper discusses 3D coloring augmented reality to increase community interaction and marketing in the village. We innovated three models for three mobile applications, including postcard design for famous attractions, cooperation with local institutions, and cooperation with art workers. This paper will introduce the three modes of application and their advantages and disadvantages. We have found that using augmented reality not only increases interactions with users and illustrates past cultural values, but also preserves cultural assets without destroying historical buildings.","2375-527X","978-1-5386-8534-1","10.1109/I-SPAN.2018.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8636328","Smart Living Technology;Community Interaction;Augmented Reality;Zhongxing New Village","Augmented reality;Three-dimensional displays;Fish;Animation;Cultural differences;Buildings;Government","art;augmented reality;buildings (structures);history;marketing data processing;mobile computing;smart cities;travel industry","marketing;community interaction;3D coloring augmented reality;New Village;Nantou City;Nantou County;Garden City;smart living technology;village prosperity;mobile applications;postcard design;local institutions;art workers;cultural assets;historical buildings","","","","6","IEEE","7 Feb 2019","","","IEEE","IEEE Conferences"
"ARPP: An Augmented Reality 3D ping-pong game system on Android mobile platform","X. Gao; J. Tian; X. Liang; G. Wang","Department of Computer Science New Jersey, Institute of Technology; Department of Computer Science New Jersey, Institute of Technology; Department of Computer Science New Jersey, Institute of Technology; Department of Computer Science New Jersey, Institute of Technology","2014 23rd Wireless and Optical Communication Conference (WOCC)","19 Jun 2014","2014","","","1","6","Ping-pong is a very popular physical game all over the world. People need to play it in some fixed physical locations. Based on Augmented Reality (AR) technology, we provide a more interesting and convenient way for people to play ping-pong game on smartphones. In this paper, we propose an Augmented Reality 3D Ping-Pong game system (ARPP) for two players on Android platform through Wi-Fi Direct. The game is rendered when two players aim their phones' camera at a specific marker. The players can view the virtual table tennis scenario through the screen of their smartphones. They move their phones to control paddles to play ping-pong game. The experiment results show that the proposed game system can work effectively and provide winner results on two Android mobile devices.","2379-1276","978-1-4799-5249-6","10.1109/WOCC.2014.6839917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6839917","Augmented Reality;3D game;ping-pong;table tennis;Android platform;smartphone;tablet;Wi-Fi Direct","Games;Smart phones;IEEE 802.11 Standards;Augmented reality;Cameras;Libraries;Three-dimensional displays","augmented reality;computer games;image sensors;mobile computing","augmented reality 3D ping pong game system;android mobile platform;fixed physical locations;AR technology;smartphones;ARPP;Wi-Fi direct;camera phones;virtual table tennis scenario;Android mobile devices","","","","16","IEEE","19 Jun 2014","","","IEEE","IEEE Conferences"
"Using augmented reality for service discovery in pervasive environments","A. Bouain; A. E. Fazziki; M. Sadgal","Faculty of sciences Marrakech, Cadi Ayyad University, Morocco; Faculty of sciences Marrakech, Cadi Ayyad University, Morocco; Faculty of sciences Marrakech, Cadi Ayyad University, Morocco","2015 Third World Conference on Complex Systems (WCCS)","2 Jun 2016","2015","","","1","5","The appearance of a large number of mobile devices (Smart-phones, Tablets...) has democratized the access to information anywhere and anytime, which makes it possible to have smart environments that are composed of a set of interconnected devices and offers users a set of services called pervasive services. Several techniques and protocols have been proposed to allow users to discover and access these services. In this work, we examine some existing protocols and we discuss the use of augmented reality to discover these services. The idea of using augmented reality for pervasive service discovery derives its legitimacy from the fact that the majority of mobile devices are equipped with cameras, GPS, accelerometer, orientation sensors, etc., which will assist the user in an intelligent way by providing interfaces that combine 2D/3D images and the real environment.","","978-1-4673-9669-1","10.1109/ICoCS.2015.7483240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7483240","Augmented reality;Pervasive services;Service discovery;Ubiquitous computing","Protocols;Servers;Augmented reality;Mobile handsets;Cameras;Global Positioning System;Sensors","augmented reality;mobile computing","augmented reality;pervasive service discovery;mobile devices","","","","24","IEEE","2 Jun 2016","","","IEEE","IEEE Conferences"
"Increasing Awareness of Cellular Signals on Smartphones using Augmented Reality","N. Srithammee; B. Jantarakongkul; K. Kubola; P. Jitngernmadan","Faculty of Informatics, Burapha University, Chon Buri, Thailand; Faculty of Informatics, Burapha University, Chon Buri, Thailand; Faculty of Informatics, Burapha University, Chon Buri, Thailand; Faculty of Informatics, Burapha University, Chon Buri, Thailand","2022 13th International Conference on Information and Communication Technology Convergence (ICTC)","25 Nov 2022","2022","","","412","416","Augmented Reality (AR) can be used to enhance consumed information visually and textually. When it comes to a cellular signal strength, a user might be skeptic how strong it is, actually. Some may concern about good signal receiving in terms of coverage area, whereas some may concern about health affection. In this work, we aimed to increase awareness of cellular signals on smartphones using Augmented Reality (AR) technology. The invisible cellular signal is visualized on smartphones virtually with 3D objects and text information. The System Usability Scale (SUS) score shows that the usability of our application is above average with score of 69.75.","2162-1241","978-1-6654-9939-2","10.1109/ICTC55196.2022.9952858","Burapha University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952858","Mobile Augmented Reality;Cellular Signals;Smartphones;Signal Strength;AR Foundation","Visualization;Three-dimensional displays;Information and communication technology;Usability;Smart phones;Augmented reality;Convergence","augmented reality;data visualisation;smart phones","Augmented Reality technology;cellular signal strength;cellular signals;consumed information;coverage area;good signal;invisible cellular signal;smartphones;text information","","","","13","IEEE","25 Nov 2022","","","IEEE","IEEE Conferences"
"Augmented Reality for the Abstract Paintings: Application Scenarios, Semantic Similarity Analysis and Case Study","O. Golembovska; V. Kharchenko; I. Shostak; M. Danova; O. Feoktystova; V. Plietnov","“Carte Blanche” Magazine, Kyiv, Ukraine; National Aerospace University “KhAI”, Kharkiv, Ukraine; National Aerospace University “KhAI”, Kharkiv, Ukraine; National Aerospace University “KhAI”, Kharkiv, Ukraine; National Aerospace University “KhAI”, Kharkiv, Ukraine; National Aerospace University “KhAI”, Kharkiv, Ukraine","2019 10th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)","5 Dec 2019","2019","2","","1007","1011","The approach to the analysis of the perception by visitors of abstract visual objects of modern art with elements of augmented reality is presented. The methodological basis of the approach are: a set of private scenarios of interaction between individual visitors and their groups with the objects exhibited; generalized scenario of lexico-semantic analysis of the proximity of the visitors verbal assessments to the name of the object; method of verbal semantic differential. Is considered an example of a quantitative assessment obtaining of the semantic proximity verbal assessments of visitors to the name of a visual object. The application of the discussed approach will provide the possibility of automatic adjustment (based on the technology of the Internet of Things) of augmented reality elements in abstract visual objects of art, with a view to a deeper understanding of their audience.","","978-1-7281-4069-8","10.1109/IDAACS.2019.8924411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924411","augmented reality;verbal semantic differential method;abstract paintings;semantic similarity analysis;scenarios approach","Semantics;Visualization;Art;Augmented reality;Internet of Things;Painting;Information systems","art;augmented reality;data visualisation;Internet of Things","abstract paintings;semantic similarity analysis;abstract visual objects;modern art;generalized scenario;lexico-semantic analysis;visitors verbal assessments;quantitative assessment;semantic proximity verbal assessments;visual object;augmented reality elements","","","","10","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Housing Design In Planet Green Tambora Using Augmented Reality For Promotion Media","M. R. Mufid; M. Tahir; D. B. Meiyuana; A. Bhaskara Dwileksa; E. Kumiawaty","Politeknik Elektronika Negeri Surabaya, Indonesia; Politeknik Elektronika Negeri Surabaya, Indonesia; Politeknik Elektronika Negeri Surabaya, Indonesia; Akademi Komunitas Negeri Lamongan, Indonesia; Akademi Komunitas Negeri Lamongan, Indonesia","2020 International Electronics Symposium (IES)","20 Oct 2020","2020","","","669","673","One way of organizing the town to make it look elegant and tidy is to create a housing estate. Planet Green Tambora Housing is a housing estate located in the Tambakboyo area close to the center of Lamongan City. However, in the promotion process, it is still not very attractive, so the demand is still lacking. In this study, the authors use Augmented Reality as an attractive medium for marketing housing products on Planet Green Tambora. This application displays the design of each type of house in a tangible 3-dimensional visual form. Where this housing has 2 types of houses namely types 27 and 42. In addition to displaying a 3-dimensional visual form, it also displays house plans for each type of house. From the results of this Augmented Reality (AR) promotion making research, the results obtained that the response of respondents very interested in this application with a percentage of 97.25%. In addition, we testing too using light and edge detection methods, both showed very well.","","978-1-7281-9530-8","10.1109/IES50839.2020.9231546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231546","Planet Green Tambora;augmented reality;promotion media;housing","Three-dimensional displays;Augmented reality;Image edge detection;Planets;Media;Cameras;Urban areas","augmented reality;data visualisation;edge detection;marketing;property market","edge detection methods;housing product marketing;AR promotion;Planet Green Tambora housing;augmented reality promotion making research;promotion media;housing design;house plans;3-dimensional visual form;housing products;promotion process;housing estate","","","","8","IEEE","20 Oct 2020","","","IEEE","IEEE Conferences"
"Magic Book with Augmented Reality Technology for Introducing Rare Animal","W. N. Hidayat; M. I. Ibad; M. N. Sofiana; M. I. Aulia; T. A. Sutikno; R. Wakhidah","Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Information Technology Department, State Polytechnic of Malang, Malang, Indonesia","2020 3rd International Conference on Computer and Informatics Engineering (IC2IE)","4 Dec 2020","2020","","","355","360","Augmented Reality is a technology that is in great demand by application developers today in all fields, including in the field of education, because it is easier for children to understand while learning an object in 3D visual form to learn some information. Indonesia is a country with animal diversity throughout the island in Indonesia. Unfortunately, many animals in Indonesia are endangered or protected species. This is due to a lack of education that teaches and introduces the diversity of animals that exist in Indonesia so there is a lot of illegal hunting that resulted in some animals becoming rare to find. The aim of this research is to create an android-based application that contains an introduction to endangered species in Indonesia with Augmented Reality named “RaaR”.","","978-1-7281-8247-6","10.1109/IC2IE50715.2020.9274590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274590","Mobile Learning;Augmented Reality;Android;Endangered Animals;Unity 3D","Animals;Augmented reality;Three-dimensional displays;Software;Games;Media;Informatics","augmented reality;data visualisation;environmental science computing;zoology","Indonesia;magic book;augmented reality technology;rare animal;application developers today;3D visual form;animal diversity;endangered species;RaaR;illegal hunting","","","","19","IEEE","4 Dec 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Based Application for Linear Algebra Visualization: Development of Interactive Learning Environment","G. Singh; N. Tuli; A. Mantri","AXG, Intel Technologies India Pvt Ltd; Chitkara University Institute of Engineering and Technology Chitkara University, Punjab, India; Chitkara University Institute of Engineering and Technology Chitkara University, Punjab, India","2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)","18 Jul 2022","2022","","","1400","1404","Linear Algebra has been used in various engineering fields, such as machine learning, robotics, and artificial intelligence. However, learning it geometrically remains a challenging task, because it requires visualizing abstract concepts such as matrices and vector spaces. This paper aims to introduce an augmented reality framework for promoting spatial simulation in engineering students' Linear Algebra classes. In this paper, we provide a mobile-based augmented reality visualization framework of vectors, 2x2 matrix, 3x3 matrix, transformation matrix, determinant and other learning content of linear algebra. The user learns by interpreting the axis for the transformation part of the matrix for scaling, translation and rotation of a 3-D vector space. We then present how the 3x3 matrix and 4x4 matrix can be formulated and described under the proposed approach.","","978-1-6654-3789-9","10.1109/ICACITE53722.2022.9823740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9823740","augmented reality;linear algebra;visualization;mathematics","Visualization;Linear algebra;Machine learning;Task analysis;Engineering students;Augmented reality;Robots","augmented reality;data visualisation;learning (artificial intelligence);linear algebra;matrix algebra","machine learning;artificial intelligence;visualizing abstract concepts;vector spaces;augmented reality framework;spatial simulation;engineering students;transformation matrix;learning content;3-D vector space;Linear Algebra visualization;interactive learning environment","","","","11","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Cultural Heritage Layers: Integrating Historic Media in Augmented Reality","M. Zoellner; J. Keil; T. Drevensek; H. Wuest","Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany","2009 15th International Conference on Virtual Systems and Multimedia","30 Oct 2009","2009","","","193","196","In this paper we are presenting Cultural Heritage Layers, an approach that enables the visualization of historic media like drawings, paintings and photographs of buildings and historic scenes seamlessly superimposed on reality via video see through using X3D. This enables simple, inexpensive and sustainable Augmented Reality applications in the cultural heritage and architectural area based on industry standards. The main idea is to use existing historic media from archives and superimpose them seamlessly on reality at the right spot. These locative layers are context sensitively telling the location's history and create the impression of a virtual time journey. The registration of the virtual objects in the video images is provided by a robust 6DOF tracking framework based on two technologies that work in tandem: an initialization step based on Randomized Trees and a frame-to-frame tracking phase based on KLT. The entire application runs in real time on current Ultra Mobile PCs and MIDs.","","978-0-7695-3790-0","10.1109/VSMM.2009.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5306012","Cultural Heritage;Locative Media;Augmented Reality;Markerless Tracking;UMPC;Mobile","Cultural differences;Augmented reality;Visualization;Painting;Buildings;Layout;History;Robustness;Karhunen-Loeve transforms;Personal communication networks","augmented reality;computer vision;data visualisation;history","cultural heritage layers;historic media visualization;virtual time journey;robust 6DOF tracking framework;randomized trees;frame-to-frame tracking phase;ultra mobile PCs;X3D;augmented reality applications","","23","","10","IEEE","30 Oct 2009","","","IEEE","IEEE Conferences"
"Keynote Talk 4: Virtual and Augmented Reality Animals in Smart and Playful Cities","A. Nijholt",University of Twente,"2020 Joint 9th International Conference on Informatics, Electronics & Vision (ICIEV) and 2020 4th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)","7 Jan 2021","2020","","","1","1","Our future urban environments are smart. Sensors and actuators are embedded in these environments and their inhabitants. We have an Internet of Things, where the `Things' include objects, cars, tools, buildings, street furniture, and w hatever can be equipped with sensors and actuators, including human and non non-human animals. Augmented humans and augmented animals have their senses extended with digital technology. Their smart wearables connected with the smart environment make humans and animals smarter. Rather than on living animals, in this survey paper we focus on non non-living virtual and augmented reality non non-human animals that will inhabit our smart and playable urban environments. They will co co-exist with robotic animals and (digitally augmented) humans and nonhuman animals. We include observations on augmented humans interacting with virtual and augmented reality animals. The paper is meant to raise awareness for the possibilities of augmented reality to introduce virtual animals for s ocial, entertainment, and educational reasons.","","978-1-7281-9331-1","10.1109/ICIEVicIVPR48672.2020.9306546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306546","","Animals;Urban areas;Augmented reality;Computer science;Brain-computer interfaces;Intelligent sensors;Entertainment industry","augmented reality;cognition;computer animation;virtual reality","playable urban environments;robotic animals;nonhuman animals;augmented humans;augmented reality;virtual animals;keynote talk 4;future urban environments;actuators;Internet of Things;street furniture;sensors;nonnonhuman animals;augmented animals;smart wearables;smart environment;living animals;smart environments","","","","","IEEE","7 Jan 2021","","","IEEE","IEEE Conferences"
"Virtual humans for virtual reality and augmented reality","D. Thalmann","VRlab., Ecole Polytech. Fed. de Lausanne, Switzerland","IEEE Virtual Reality, 2003. Proceedings.","2 Apr 2003","2003","","","300","","The tutorial will explain the techniques for integrating virtual humans into virtual and real environments. It will first present the concept of avatars and autonomous virtual actors and the main techniques to create and animate them (body and face). It will present the concepts of behavioral animation, crowd simulation, intercommunication between virtual humans, and interaction between real humans and autonomous virtual humans. The tutorial will also address the advanced topics of real-time cloth animation with application in fashion design. Finally, the tutorial will present the use of the virtual human technology in virtual heritage, social phobia, training, and health emergency.","1087-8270","0-7695-1882-6","10.1109/VR.2003.1191176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191176","","Humans;Virtual reality;Augmented reality;Facial animation;Avatars;Biological system modeling","virtual reality;user interfaces;computer animation;real-time systems;textile industry","virtual humans;virtual reality;augmented reality;avatars;autonomous virtual actors;behavioral animation;crowd simulation;virtual heritage;social phobia;training;health emergency;autonomous virtual humans;real-time cloth animation;fashion design","","","","","IEEE","2 Apr 2003","","","IEEE","IEEE Conferences"
"Providing guidance for maintenance operations using automatic markerless augmented reality system","H. Álvarez; I. Aquinaqa; D. Borro","CEIT and Tecnun, University of Navarra, Spain; Universidad de Navarra, Pamplona, Navarra, ES; CEIT and Tecnun, University of Navarra, Spain","2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","1","1","A real-time Augmented Reality system that assists in maintenance is presented (Figure 1). The novelty of the proposed system relies on its ability of being a complete framework that is self supplied. All the data is extracted automatically during an offlne phase from a collection of 3D parts that are provided as untextured 3D triangle meshes. Our disassembly planning module computes the assembly/disassembly sequence finding collision-free trajectories [1]. Moreover, some basic geometric features, such as edges and junctions, are extracted to address the tracking problem. Additionally, these geometric features let us perform the 3D model recognition, which solves the first camera pose problem and performs the recovery in case of tracking failure [3]. During the online phase, these geometric features are used to build a markerless tracking that updates continuously the camera pose from a monocular image. This markerless tracking combines an edge tracker, a point based tracker and a 3D particle filter to offer a robust 3D tracking against undesirable conditions [2]. Once the camera pose has been computed, the system offers an augmented instruction, indicating how to assemble/disassemble the next part. Thus, the proposed AR system is a complete framework that runs in real-time and tries to facilitate the work of workers, replacing the paper-based documentation.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549440","","Three-dimensional displays;Augmented reality;Feature extraction;Cameras;Electronic mail;Real-time systems;Planning","assembly planning;augmented reality;computational geometry;maintenance engineering;mesh generation;particle filtering (numerical methods);production engineering computing;solid modelling","paper-based documentation;augmented instruction;point based tracker;3D particle filter;tracking failure;camera pose problem;3D model recognition;tracking problem;geometric features;collision-free trajectories;assembly-disassembly sequence;disassembly planning module;untextured 3D triangle meshes;3D parts;offlne phase;automatic markerless augmented reality system;maintenance operations","","2","","3","IEEE","9 Sep 2013","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality System for Preschool Education","S. -M. Hou; Y. -Y. Liu; Q. -B. Tang; X. -G. Guo","School of Computer Science and Technology of Henan, Polytechnic University, Jiaozuo, China; School of Computer Science and Technology of Henan, Polytechnic University, Jiaozuo, China; School of Computer Science and Technology of Henan, Polytechnic University, Jiaozuo, China; School of Computer Science and Technology of Henan, Polytechnic University, Jiaozuo, China","2017 International Conference on Virtual Reality and Visualization (ICVRV)","23 May 2019","2017","","","321","323","The traditional picture book has poor interaction and low learning efficiency. To improve this shortage, a picture book of a mobile augmented reality system (MARS) is presented in this paper. It contains the functions of painting, literacy and listening to the story, which can help children understand things from the perspective of vision, hearing and tactile. This paper designs MARS based on image recognition and Bi-Directional matching technology, and developed interactive AR card named ARMonkey by MARS. Using the AR picture book not only exercises the children's hands-on ability, but also improves their imagination and brings them a lot of fun.","2375-141X","978-1-5386-2636-8","10.1109/ICVRV.2017.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719140","mobile augmented reality;matching algorithm;Preschool education","Conferences;Visualization;X reality","augmented reality;computer aided instruction;image matching;image recognition;mobile computing","interactive AR card;AR picture book;mobile augmented reality system;preschool education;traditional picture book;MARS system;learning efficiency;image recognition;bidirectional matching technology;vision perspective;hearing perspective;tactile perspective;ARMonkey","","1","","9","IEEE","23 May 2019","","","IEEE","IEEE Conferences"
"Exploring the Display Patterns of Object-Centered User Interface in Head-Worn Mixed Reality Environment","Y. Li; Y. Hu; X. Shen","School of New Media Art and Design, Beihang University; School of New Media Art and Design, Beihang University; School of New Media Art and Design, Beihang University","2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","737","738","Object-centered user interface (UI), which UI displayed around real-world objects provides convenience for users to interact with real objects in head-worn Mixed Reality (MR) environment. However, it remains unclear how to design the object-centered UI to reduce the interference of always displayed UI. In this research, we designed two display patterns of object-centered UI and compared them with the basic object-centered UI without any display patterns. Our results demonstrate the trade-offs among the three UIs and collect user preference. Both display patterns can provide better support for users while reducing the occlusion and interference of the UI.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00211","National Key R&D Program of China(grant numbers:2019YFF0301305); Yunnan Provincial Key R&D Program(grant numbers:202103AN080001-003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108668","Human-centered computing—Mixed / augmented reality;Human-centered computing—User interface design","Three-dimensional displays;Conferences;Mixed reality;Virtual reality;Interference;User interfaces","augmented reality;helmet mounted displays;user interfaces","display patterns;head-worn mixed reality environment;MR;object-centered UI;object-centered user interface;real-world objects;user preference","","","","6","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Representing Cross-Cultural Links of Artifacts in Museums with Augmented Reality","P. Zhao; A. Morris","Adaptive Context Environments(ACE) Lab, OCAD University, Toronto, Canada; Adaptive Context Environments(ACE) Lab, OCAD University, Toronto, Canada","2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","30 Jan 2023","2022","","","234","236","Museums play a significant role in collecting and displaying artifacts from different cultures. As public spaces, museums also represent the society we live in and affect the public understanding of the past. Meanwhile, emerging technology such as Augmented Reality (AR) is changing how we perceive information, including in the museum space. This paper explores how AR can better help museum visitors understand the intercultural link between artifacts, by using Blue-and-White porcelain from Ming China and Safavid Iran as a case study. An AR prototype was developed during the process. This paper concludes with a discussion of the potential for AR as a powerful tool to solve problems in the current museology approach.","2771-7453","978-1-6654-5725-5","10.1109/AIVR56993.2022.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024480","Augmented Reality;Museum;Cross-cultural Links;Blue-and-White porcelain","Bridges;Solid modeling;Porcelain;Prototypes;Mixed reality;Museums;Space exploration","augmented reality;cultural aspects;museums","AR prototype;artifact cross-cultural links;augmented reality;blue-and-white porcelain;intercultural link;museology approach;museum space;museum visitors;museums;public spaces","","","","8","IEEE","30 Jan 2023","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality Shopping System","C. Roche; A. Hamam","Computer Science, Florida Polytechnic University, Lakeland, United States; Computer Science, Florida Polytechnic University, Lakeland, United States","SoutheastCon 2023","8 May 2023","2023","","","704","705","This document serves as an extended abstract to detail the architecture for an augmented reality shopping application under current development for a thesis. The system consists of a progressive web app client that presents the augmented view to the user and performs object tracking, and a cloud server that performs object detection, localization, and the necessary product information retrieval and analysis.","1558-058X","978-1-6654-7611-9","10.1109/SoutheastCon51012.2023.10115069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10115069","augmented reality;webAR;object recognition;mobile computing;mobile augmented reality;progressive web app","Location awareness;Cloud computing;Object detection;Computer architecture;Information retrieval;Servers;Object tracking","augmented reality;cloud computing;information retrieval;mobile computing;object detection;object tracking","augmented reality shopping application;augmented view;mobile augmented reality shopping system;progressive web app client","","","","3","IEEE","8 May 2023","","","IEEE","IEEE Conferences"
"A multi-sensor platform for wide-area tracking","C. Waechter; M. Huber; P. Keitler; M. Schlegel; G. Klinker; D. Pustka","Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; Advanced Realtime Tracking GmbH, Germany","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","275","276","Indoor tracking scenarios still face challenges in providing continuous tracking support in wide-area workplaces. This is especially the case in Augmented Reality since such augmentations generally require exact full 6DOF pose measurements in order to continuously display 3D graphics from user-related view points. Many single sensor systems have been explored but only few of them have the capability to track reliably in wide-area environments. We introduce a mobile multi-sensor platform to overcome the shortcomings of single sensor systems. The platform is equipped with a detachable optical camera and a rigidly mounted odometric measurement system providing relative positions and orientations with respect to the ground plane. The camera is used for marker-based as well as for marker-less (feature-based) inside-out tracking as part of a hybrid approach. We explain the principle tracking technologies in our competitive/cooperative fusion approach and show possible enhancements to further developments. This inside-out approach scales well with increasing tracking range, as opposed to stationary outside-in tracking.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643604","","Augmented reality;Robot sensing systems;Cameras;Optical sensors;Mobile communication;Accuracy;Three dimensional displays","augmented reality;cameras;distance measurement;mobile computing;sensor fusion;solid modelling;tracking;wireless sensor networks","wide area tracking;indoor tracking;augmented reality;3D graphics;mobile multisensor platform;optical camera;principle tracking technology;odometric measurement system","","8","","11","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Effects of Virtual Reality and Augmented Reality on Induced Anxiety","S. -C. Yeh; Y. -Y. Li; C. Zhou; P. -H. Chiu; J. -W. Chen","School of Information Science and Technology, Fudan University, Shanghai, China; Department of Psychology, Fudan University, Shanghai, China; Department of Psychology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","6 Jul 2018","2018","26","7","1345","1352","To explore the effects of virtual reality (VR) and augmented reality (AR) in the treatment of claustrophobia, the potential effects of VR and AR on induced anxiety were investigated in this paper. During the experiment, 34 subjects were randomly selected and distributed in AR and VR scenes in a sequence. The skin conductance and heart rates of the subjects were measured throughout the entire process, and the anxiety scale was used to assess the subjective anxiety when the task in each scene was completed. The results showed the following: (1) AR and VR scenes led to feelings of discomfort, but the subjective anxiety scores obtained in the two scenes were not significantly different; (2) the skin conductance level of the subjects significantly increased from the baseline when the subjects entered the experimental scene but remained active in the two scenes without showing significant difference between the scenes; and (3) the heart rate index significantly increased from the baseline after the subjects entered the scene and then gradually decreased. The heart rates of the subjects significantly increased again when the anxiety-induced event was triggered. However, no significant difference was observed between AR and VR scenes. AR and VR have induced obvious anxiety, which was reflected in the subjective and objective physiological indicators. However, no significant difference was found in the effects of AR and VR on the induced anxiety. Considering the cost of building two scenes and other factors, AR was more suitable for the treatment of claustrophobia than VR.","1558-0210","","10.1109/TNSRE.2018.2844083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8375995","Anxiety;augmented reality;claustrophobia;virtual reality","Heart rate;Task analysis;Skin;Fires;Medical treatment;Augmented reality","augmented reality;human factors;patient treatment;physiology;psychology;skin","virtual reality;augmented reality;induced anxiety;VR scenes;anxiety scale;subjective anxiety scores;skin conductance level;heart rate index;anxiety-induced event;obvious anxiety;subjective indicators;objective physiological indicators;AR scenes;claustrophobia treatment","Adult;Anxiety;Female;Galvanic Skin Response;Healthy Volunteers;Heart Rate;Humans;Male;Phobic Disorders;Reality Therapy;Virtual Reality;Young Adult","29","","23","OAPA","8 Jun 2018","","","IEEE","IEEE Journals"
"DigiLog Space: Real-Time Dual Space Registration and Dynamic Information Visualization for 4D+ Augmented Reality","T. Ha; H. Lee; W. Woo","UVR Lab, KAIST, South Korea; UVR Lab, KAIST, South Korea; UVR Lab, KAIST, South Korea","2012 International Symposium on Ubiquitous Virtual Reality","10 Sep 2012","2012","","","22","25","In this paper, we propose a DigiLog space that combines physical real world and its mirrored world to realize a 4D+ augmented reality. To support this, a RGB-D-based feature map is designed which is robust to lighting changes and enables texture-less object detection and tracking. Then we suggest a real-time context of interest (CoI) registration method for dynamic augmented reality (AR) information visualization. Through these technologies, a user wearing AR glasses can seamlessly experience CoI-based AR information of the 4D+ mirror world while moving indoors or outdoors. Therefore, a human's activity can be spatially/temporally extended by sharing and experiencing the mirror world's useful information. This could be applicable to AR-based time/space-transcended smart work, next-generation experimental education, AR simulation, video-based information surveying, AR medical information, and AR entertainment.","","978-1-4673-2258-4","10.1109/ISUVR.2012.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6296801","","Real time systems;Augmented reality;Visualization;Context;Robustness;Cameras;Feature extraction","augmented reality;data visualisation;helmet mounted displays;image registration;object detection;object tracking","DigiLog space;mirror world;real world;real-time dual space registration;dynamic information visualization;4D+augmented reality;RGB-D-based feature map;texture less object detection;object tracking;context of interest;CoI registration method;dynamic augmented reality","","6","","16","IEEE","10 Sep 2012","","","IEEE","IEEE Conferences"
"The implementation of a live interactive augmented reality game creative system","Guoyu Sun; Chu Qiu; Quan Qi; Kaihui Mu; Bo Wang","Communication University of China, Beijing, China; Communication University of China, Beijing, China; Communication University of China, Beijing, China; Communication University of China, Beijing, China; Communication University of China, Beijing, China","International Conference on Cyberspace Technology (CCT 2014)","14 May 2015","2014","","","1","6","Interaction is the most important factor that may much influence gaming experience. Given that Augmented Reality presentations enable the more creation ways of user interactions that expand traditional HCI from 2D to 3D spaces, this offer an ideal opportunity for game developers to design more playful and interesting AR games that embed various interaction forms. In this paper, we build an augmented reality game creative platform, which allows game developers to integrate augmented reality features,spatial human computer interaction mechanism and other advanced interaction techniques into the designed game.In this system, we implement a adopted augmented reality function to help the developers to directly superimpose the visual 3d objects over the live real video image and then port human motion interactive trigger module to this system based on kinect, in which a up-down hierarchy figure description algorithm is proposed to build a common virtual 3d human model prototype that could allow developer ignore the difference of various players' shape and make the players easily to use their actions to interact with the 3d virtual objects to get more unique game experience.","","978-1-84919-928-5","10.1049/cp.2014.1375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106874","augmented reality;motion capture;interactive game design","","augmented reality;computer games;human computer interaction;image motion analysis;solid modelling;user interfaces;video signal processing","live interactive augmented reality game creative system;gaming experience;augmented reality presentations;user interactions;spatial human computer interaction mechanism;augmented reality feature integration;visual 3D objects;live real video image;human motion interactive trigger module;Kinect;up-down hierarchy figure description algorithm;virtual 3D human model","","","","","","14 May 2015","","","IET","IET Conferences"
"Collaborative Production Line Planning with Augmented Fabrication","D. Aschenbrenner; M. Li; R. Dukalski; J. Verlinden; S. Lukosch",TU Delft IDE; TU Delft IDE; TU Delft IDE; TU Delft IDE; TU Delft TPM,"2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","509","510","The project “Factory-in-a-day” aims at reducing the installation time of a new hybrid robot-human production line, from weeks or months that current industrial systems now take, down to one day. The ability to rapidly install (and reconfigure) production lines where robots work alongside humans will strongly reduce operating cost and open a range of new opportunities for industry. In this paper, we explore a method of collaborative fabrication planning with the help of Augmented Reality as part of the concept Augmented Fabrication. In order to plan a new production line, two co-located workers at the factory wear a Microsoft Hololens head-mounted display and thus share a common visual context on the planed position of the robots and the production machines. They are assisted by an external remote expert connected via the Internet who is virtually co-located. We developed three different visualizations of the state of the local collaboration and plan to compare them in a user study.","","978-1-5386-3365-6","10.1109/VR.2018.8446533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446533","Human-centered computing [Mixed / augmented reality];[Social and professional topics]: Computer supported cooperative work;Applied computing [Industry and manufacturing];[Computer systems organization]: Robotics","Planning;Fabrication;Robots;Augmented reality;Three-dimensional displays;Task analysis","augmented reality;helmet mounted displays;Internet;production engineering computing;production planning","local collaboration;collaborative production line planning;installation time;hybrid robot-human production line;operating cost;collaborative fabrication planning;Augmented Reality;concept Augmented Fabrication;factory wear;Microsoft Hololens head-mounted display;production machines;industrial systems;factory-in-a-day","","7","","8","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Continuous natural user interface: Reducing the gap between real and digital world","N. Petersen; D. Stricker","DFKI Kaiserslautern, Germany; DFKI Kaiserslautern, Germany","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","23","26","Augmented reality (AR) presentation enables the creation of natural user interfaces that employ the whole user's environment as interaction device. Additionally, by using hand based 3D interaction with gestures that have a physical meaning like grabbing, dragging, and dropping this leads to a user experience that is intuitive, since close to the real world's behavior. We propose a novel approach to an AR-based natural user interface, that goes one step further by enabling the contents of the interface to switch domains from a virtual instance in AR to a physical instance in the real-world. All instances stay associated and changes made to the physical instance will be reflected on the virtual one. Because the behavior of our interface in AR is in key aspects consistent with the real-world, the gap between those domains is made less salient. To demonstrate our concept, we have implemented an exemplary industrial use case. Our main contribution is the methodology for an intuitive interface we call continuous natural user interface (CNUI). Additionaly, we conducted a user study to investigate the acceptance of this kind of interface. Results indicate an ergonomic ease and after a training period also an increased performance when using our system.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336502","H.5.2 [INFORMATION INTERFACES AND PRESENTATION]: User Interfaces;Input devices and strategies H.5.1 [INFORMATION INTERFACES AND PRESENTATION]:Multimedia Information Systems;Artificial, augmented, and virtual realities I.3.6 [COMPUTER GRAPHICS]: Methodology and Techniques;Interaction techniques","User interfaces;Switches;Augmented reality;Ergonomics;Industrial training;Multimedia systems;Virtual reality;Computer graphics;Mice;Keyboards","augmented reality;gesture recognition;human computer interaction;human factors","continuous natural user interface;real-digital world;augmented reality;3D interaction device;user experience;virtual instance;ergonomic","","23","","16","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Interactive mediated reality","R. Grasset; J. . -D. Gascuel; Schmalstieg","IMAGIS/GRAVIR, INRIA Rhône-Alpes, France; IMAGIS/GRAVIR, INRIA Rhône-Alpes, France; Interactive Media System Group, University of Technology, Vienna, Vienna, Austria","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","302","303","Mediated reality describes the concept of filtering or vision of reality, typically using a head-worn video mixing display. In this paper, we propose a generalized concept and new tools for interactively mediated reality. We present also our first prototype system for painting, grabbing and gluing together real and virtual elements.","","0-7695-2006-5","10.1109/ISMAR.2003.1240731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240731","","Painting;Augmented reality;Computer graphics;Geometry;Brushes;Video sharing;Displays;Virtual prototyping;Information filtering;Information filters","augmented reality;computer graphics;helmet mounted displays;human computer interaction;graphical user interfaces","interactive mediated reality;reality filtering;reality vision;head-worn display;video mixing display;prototype system;computer graphics;painting tool;grab tool;glue tool","","7","","4","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"[POSTER] Deformed Reality: Proof of Concept and Preliminary Results","N. Haouchine; A. Petit; F. Roy; S. Cotin","Inria, Mimesis Group, Strasbourg, France; Inria, Mimesis Group, Strasbourg, France; Inria, Mimesis Group, Strasbourg, France; Inria, Mimesis Group, Strasbourg, France","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","166","167","We introduce “Deformed Reality”, a new paradigm to interactively manipulate objects in a scene in a deformable manner. Using the core principle of augmented reality to estimate rigid pose over time, our method enables the user to deform the targeted object while it is being rendered with its natural texture, giving the sense of a real-time object editing in user environment. The presented results show that our method can open new ways of using augmented reality by not only augmenting the scene but also interacting with it in a non-rigid manner.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088473","","Solid modeling;Three-dimensional displays;Deformable models;Computational modeling;Image edge detection;Real-time systems;Augmented reality","augmented reality;image texture","augmented reality;natural texture;real-time object editing;user environment;deformed reality;proof of concept;interactive object manipulation","","1","","5","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Handheld Augmented Reality: Overcoming Reachability Limitations by Enabling Temporal Switching to Virtual Reality","D. Bambušek; Z. Materna; M. Kapinus; V. Beran; P. Smrž","Faculty of Information Technology, Brno University of Technology, Brno, Czech Republic; Faculty of Information Technology, Brno University of Technology, Brno, Czech Republic; Faculty of Information Technology, Brno University of Technology, Brno, Czech Republic; Faculty of Information Technology, Brno University of Technology, Brno, Czech Republic; Faculty of Information Technology, Brno University of Technology, Brno, Czech Republic","2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","29 Sep 2022","2022","","","698","702","The paper presents an approach for handheld augmented reality in constrained industrial environments, where it might be hard or even impossible to reach certain poses within a workspace. Therefore, a user might not be able to see or interact with some digital content in applications like visual robot programming, robotic program visualizations, or workspace annotation. To overcome this limitation, we propose a temporal switching to a non-immersive virtual reality, enabling the user to see the workspace from any angle and distance. To explore how people would use it and what the benefits would be over pure augmented reality, we chose a representative task of object alignment and conducted a study. The results revealed that mainly physical demands, which is often a limiting factor for handheld augmented reality, could be reduced and that the usability and utility of the approach are rated as high. In the next iteration, we want to investigate other possibilities of controlling the viewpoint in the virtual environment, as the current approach has potential for improvements.","","978-1-6654-0731-1","10.1109/HRI53351.2022.9889434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889434","augmented reality;virtual reality;mixed reality;transitional interface;constrained industrial environments","Visualization;Limiting;Service robots;Virtual environments;Switches;User experience;Usability","augmented reality;groupware;robot programming;virtual reality","limiting factor;virtual environment;handheld augmented reality;reachability limitations;enabling temporal switching;constrained industrial environments;visual robot programming;robotic program visualizations;workspace annotation;nonimmersive virtual reality;pure augmented reality","","","","24","IEEE","29 Sep 2022","","","IEEE","IEEE Conferences"
"[POSTER] Augmented Reality Assistance in the Central Field-of-View Outperforms Peripheral Displays for Order Picking: Results from a Virtual Reality Simulation Study","P. Renner; T. Pfeiffer","Cluster of Excellence Cognitive Interaction Technology, Bielefeld University; Cluster of Excellence Cognitive Interaction Technology, Bielefeld University","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","176","181","One area in which glasses-based augmented reality (AR) is successfully applied in industry is order picking in logistics (pick-byvision). Here, the almost hands-free operation and the direct integration into the digital workflow provided by augmented reality glasses are direct advantages. A common non-AR guidance technique for order picking is pick-by-light. This is an efficient approach for single users and low numbers of alternative targets. AR glasses have the potential to overcome these limitations. However, making a grounded decision on the specific AR device and the particular guidance techniques to choose for a specific scenario is difficult, given the diversity of device characteristics and the lack of experience with smart glasses in industry at larger scale. The contributions of the paper are twofold. First, we present a virtual reality (VR) simulation approach to ground design decisions for AR-based solutions and apply it to the scenario of order picking. Second, we present results from a simulator study with implemented simulations for monocular and binocular head-mounted displays and compared existing techniques for attention guiding with our own SWave approach and the integration of eye tracking. Our results show clear benefits for the use of pick-by-vision compared to pick-by-light. In addition to that, we can show that binocular AR solutions outperform monocular ones in the attention guiding task.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088476","","Glass;Visualization;Three-dimensional displays;Gaze tracking;Two dimensional displays;Augmented reality","augmented reality;helmet mounted displays;logistics","pick-by-vision;pick-by-light;order picking;virtual reality simulation study;augmented reality glasses;nonAR guidance technique;smart glasses;virtual reality simulation approach;augmented reality assistance;AR-based solutions;glasses-based augmented reality","","18","","22","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"[DC] Learning Tornado Formation via Collaborative Mixed Reality","Y. -M. Chiou; R. Barrnaki",University of Delaware; University of Delaware,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1369","1370","With the rise of attention to global warming which brings in more extreme weather and climate conditions, the earth science education would be one of the crucial topics for the next generation. Mixed-Reality has been shown to offer more engaging and effective learning solutions on essential science topics, such as math, physics, and chemistry. However, there are few augmented reality and mixed reality applications on earth science subject. Also, collaborative learning has been shown to be beneficial for student learning by aspiring student curiosity, and the ability of cooperation. In this paper, we propose a Mixed Reality Tornado Simulator which offers an earth science education intervention in a collaborative mixed reality setting. Students and their instructor can wear see-through head-mounted displays to cooperate on learning the knowledge of the formation and its damage cause on human-built structures, farming, and vegetation by using our proposed mixed reality application. Also, for evaluating the learning performance in this mixed reality setting, we will study the students cognitive load using standard survey instruments. We will conduct a controlled study with two conditions to compare the proposed intervention in the head-mounted-display setting, versus a desktop setting to test usability and knowledge gain of the students in those settings.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798339","Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Mixed/augmented reality;Applied computing-Education-Collaborative learning","Tornadoes;Virtual reality;Education;Meteorology;Videos;Three-dimensional displays","augmented reality;cognition;computer aided instruction;geophysics computing;helmet mounted displays;storms;virtual reality","climate conditions;augmented reality;mixed reality application;earth science subject;collaborative learning;student learning;student curiosity;earth science education intervention;collaborative mixed reality setting;learning performance;students cognitive load;head-mounted-display setting;tornado formation;mixed reality tornado simulator","","1","","11","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Virtual reality and augmented reality as a training tool for assembly tasks","A. C. Boud; D. J. Haniff; C. Baber; S. J. Steiner","The School of Manufacturing and Mechanical Engineering, University of Binningham, UK; The School of Manufacturing and Mechanical Engineering, University of Binningham, UK; The School of Manufacturing and Mechanical Engineering, University of Binningham, UK; The School of Manufacturing and Mechanical Engineering, University of Binningham, UK","1999 IEEE International Conference on Information Visualization (Cat. No. PR00210)","6 Aug 2002","1999","","","32","36","In this paper we investigate whether virtual reality (VR) and augmented reality (AR) offer potential for the training of manual skills, such as for assembly tasks, in comparison to conventional media. We present results from experiments that compare assembly completion times for a number of different conditions. We firstly investigate completion times for a task where participants can study an engineering drawing and an assembly plan and then conduct the task. We then investigate the task under various VR conditions and context-free AR. We discuss the relative advantages and limitations of using VR and AR as training media for investigating assembly operations, and we present the results of our experimental work.","1093-9547","0-7695-0210-5","10.1109/IV.1999.781532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=781532","","Virtual reality;Augmented reality;Assembly;Computer displays;Pulp manufacturing;Mechanical engineering;Humans;Head;Mirrors;Computer graphics","virtual reality;augmented reality;computer based training;engineering graphics;assembling","virtual reality;augmented reality;manual skills training;assembly tasks;assembly completion times;engineering drawing;assembly plan;context-free augmented reality;training media","","76","","14","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"New System to Measure Motion Motion-to-Photon Latency of Virtual Reality Head Mounted Display","H. Xun; Y. Wang; D. Weng","Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technoloqy; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technoloqy; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technoloqy","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","58","62","Head mounted display (HMD) is an important part of the virtual reality (VR) system and the main interface of virtual world. During the process of using HMD, there is a certain time gap between the user's movement and the triggered change of display, which is referred to herein as a "" Motion-to- Photon "" latency. The latency may cause cybersickness which has an adverse effect on user experience and even physical health, so it is necessary to evaluate the latency of an HMD. We propose an automated and universal HMD latency measurement system. By simulating a user's motion, we are able to measure ""Motion-to-Photon"" latency using the generated periodic signals in HMD, with accuracy and reliability confirmed by our experiments. The system is fully automatic and easy to use, and suitable for the HMD with inside-out or outside-in positioning methods. It helps to improve both the detection level of existing HMDs and the user experience. It is of guiding significance for the design and manufacture of new HMD.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951925","Measurement;head-mounted-display;virtual-reality;motion-to-photon-latency","Augmented reality","helmet mounted displays;human computer interaction;human factors;user experience;virtual reality","motion-to-photon latency;virtual reality head mounted display;user experience;automated HMD latency measurement system;cybersickness;human-centered computing;human computer interaction","","1","","16","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"OutRun: Exploring seamful design in the development of an augmented reality art project","G. Hertz; J. W. Lee; C. Guevara","Center of Computer Games and Virtual Worlds, Institute of Software Research, University of California, Irvine, USA; Mixed Reality & Integration Laboratory, Sejong University, South Korea; Center of Computer Games and Virtual Worlds, Institute of Software Research, University of California, Irvine, USA","2010 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","22 Nov 2010","2010","","","33","38","This paper outlines the development process of an augmented reality video game prototype that combines a classic arcade driving game with a real world vehicle. In this project the user, or driver, maneuvers the car-shaped arcade cabinet through actual physical space using a screen as a navigational guide which renders the real world in the style of an 8-bit video game. This case study is presented as a seamful augmented reality (AR) system: a project that exploits inevitable technical limitations of AR. We propose that the concept of seamfulness has important design implications for both AR and electronic media art projects and illustrate this through a description of the OutRun system development process.","2381-8360","978-1-4244-9342-5","10.1109/ISMAR-AMH.2010.5643298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643298","Seamfulness;seamful design;game design;game innovation;mixed reality;augmented reality;alternate reality;pervasive gaming;electronic art;experimental interfaces;prototyping","Games;Global Positioning System;Roads;Software;Art;Computer vision;Augmented reality","augmented reality;computer games","augmented reality;video game;electronic media art project;system development process;car shaped arcade cabinet","","2","","28","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"X-Ray Device Positioning with Augmented Reality Visual Feedback","K. Tehlan; A. Winkler; D. Roth; N. Navab","TU München; TU München; Friedrich-Alexander-Universität, Erlangen-Nürnberg; TU München, Johns Hopkins University","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","870","871","In minimally invasive surgeries one common way to verify progress is the use of an intraoperative X-ray device (due to its characteristic shape called a C-arm). Its control, however, remains challenging owing to its complex movements. We propose the use of an Augmented Reality Head-Mounted Display (AR-HMD) to let the surgeon choose a desired X-ray view interventionally providing the corresponding C-arm configuration as visual feedback. The study participants' feedback, despite being critical of the HMD hardware limitations, suggests an inclination towards using AR for orthopaedic surgeries on especially complex or unusual anatomies.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757587","Computing Methodologies-Computer graphics-Graphics Systems and Interfaces-Mixed / Augmented Reality;Human-Centered Computing-Human Computer Interaction (HCI)-Interaction Paradigms-Mixed / Augmented Reality","Visualization;Three-dimensional displays;Minimally invasive surgery;Head-mounted displays;Shape;Conferences;Resists","augmented reality;diagnostic radiography;helmet mounted displays;human computer interaction;medical image processing;orthopaedics;surgery","X-ray device positioning;intraoperative X-ray device;complex movements;augmented reality head-mounted display;HMD hardware limitations;orthopaedic surgeries;complex anatomies;unusual anatomies;augmented reality visual feedback;C-arm configuration;AR-HMD","","","","5","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"A concept for infrastructure independent localization and augmented reality visualization of RFID tags","S. Kunkel; R. Bieber; Ming-Shih Huang; M. Vossiek","Siemens AG, CT PS7, Munich, Germany; Siemens AG, CT PS7, Munich, Germany; Pennsylvania State University, University Park, PA, USA; Institute of Electrical Information Technology, Clausthal University of Technology, Clausthal-Zellerfeld, Germany","2009 IEEE MTT-S International Microwave Workshop on Wireless Sensing, Local Positioning, and RFID","3 Nov 2009","2009","","","1","4","In this paper we present a multi sensor concept for localization and augmented-reality visualization of backscatter RFID tags. The sensor data of a camera and a RFID FMCW reader system are combined based on a synthetic aperture radar principle. The system enables the localization of tagged goods without the use of any installed infrastructure. We integrate a FMCW RFID reader and a camera system into a handheld device. While the handheld device is moved around, radar measurements as well as images of the surrounding area are taken at a number of locations. Thus, a synthetic aperture is generated and the position of the tags is calculated based on a SAR localization algorithm. Based on the imagery of the camera the user receives an augmented visual impression of where to find the RFID transponders.","","978-1-4244-5060-2","10.1109/IMWS2.2009.5307726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5307726","Augmented reality;localization;RFID;synthetic aperture radar;transponders","Augmented reality;RFID tags;Cameras;Radiofrequency identification;Data visualization;Handheld computers;Backscatter;Sensor systems;Radar measurements;Synthetic aperture radar","augmented reality;backscatter;CW radar;data visualisation;FM radar;radar signal processing;radiofrequency identification;sensor fusion;synthetic aperture radar;transponders","infrastructure independent localization;augmented reality visualization;backscatter RFID tag;multisensor concept;RFID FMCW reader system;radar measurement;SAR localization algorithm;synthetic aperture radar principle;RFID transponder","","9","1","9","IEEE","3 Nov 2009","","","IEEE","IEEE Conferences"
"Augmented reality-landmark estimation","S. Suganya; N. R. Raajan","Department of Electronics and communication Engineering, SASTRA University, Tanjore, India; Department of Electronics and communication Engineering, SASTRA University, Tanjore, India","2011 INTERNATIONAL CONFERENCE ON RECENT ADVANCEMENTS IN ELECTRICAL, ELECTRONICS AND CONTROL ENGINEERING","16 Jan 2012","2011","","","517","519","Augmented Reality means interacting with the real world circumstances and virtual objects at the same time which is augmented by system generating inputs. That is, it allows the system generated content to be superimposed over a live camera of the real world. It is an absolutely graphical experience that is combined with real world circumstances. Here, the landmark will be acquired as an input of the image by sight-based camera parameter estimation methods by using SFM (STRUCTURE FROM MOTION) technique. In this paper, we are going to overlay real still images of landmark with virtual computer graphical images. These SFM techniques which have been discussed earlier in some of the previous papers will not work in real time applications because of its high cost. But here, this method will achieve fast and accurate landmark estimation based on SFM and we obtain the 3-D structure of a landmark by using this technique which has no need of information about the scene.","","978-1-4577-2149-6","10.1109/ICONRAEeCE.2011.6129793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129793","Augmented Reality;Camera Parameter Estimation;Landmark database;Natural features","Cameras;Augmented reality;Estimation;Real time systems;Databases;Control engineering","augmented reality;computer graphics;parameter estimation","augmented reality;landmark estimation;virtual objects;sight-based camera parameter estimation;SFM technique;structure from motion technique;virtual computer graphical images","","7","","10","IEEE","16 Jan 2012","","","IEEE","IEEE Conferences"
"Location based augmented reality game using Kudan SDK","H. R. Rahman; D. Herumurti; I. Kuswardayan; A. Yuniarti; W. N. Khotimah; N. B. Fauzan","Institut Teknologi Sepuluh Nopember, Surabaya, Jawa Timur, ID; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2017 11th International Conference on Information & Communication Technology and System (ICTS)","22 Jan 2018","2017","","","307","310","The Augmented Reality (AR) is a technology that integrates a digital information with the user's environment in the real-time or the view of the physical real-world environment whose elements are augmented by computer-generated sensory input e.g. image/graphics, GPS data, sound or video. The AR technology uses the existing real environment and overlays a new digital information on top of it. There are many AR application developed in many aspects of life e.g. health, education, military, industry, entertainment, etc. This research explores the location-based AR technology to develop a game named Monster Buster. This game is an Android platform. This game uses the information of latitude and longitude used to generate the position of the monster. This research is expected to develop an innovative game application that can give another user's experience by using the location-based AR technology. The Unity 3D is the game engine that is used in this research, and the Kudan SDK is used to provide the AR technology.","2338-185X","978-1-5386-2827-0","10.1109/ICTS.2017.8265689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8265689","Location Based Augmented Reality;Kudan SDK;Unity 3D","Games;Information and communication technology;Augmented reality;Global Positioning System;Education;Military computing","augmented reality;computer games;Global Positioning System;mobile computing","Kudan SDK;location based augmented reality game;digital information;image/graphics;GPS data;Monster Buster;innovative game application;game engine;real-world environment augmentation;computer-generated sensory input;location-based AR technology;user experience;Unity 3D","","5","","7","IEEE","22 Jan 2018","","","IEEE","IEEE Conferences"
"Voice interaction using Gaussian Mixture Models for Augmented Reality applications","M. Hamidia; N. Zenati; H. Belghit; K. Guetiteni; N. Achour","Centre de Developpement des Technologies Avancees, Algiers, DZ; Centre de Developpement des Technologies Avancees, Algiers, DZ; Centre de Developpement des Technologies Avancees, Algiers, DZ; Faculty of Electronics and Computer Science, Bab-Ezzouar, Algeria; Faculty of Electronics and Computer Science, Bab-Ezzouar, Algeria","2015 4th International Conference on Electrical Engineering (ICEE)","25 Feb 2016","2015","","","1","4","This paper addresses the human computer interaction techniques for Augmented Reality (AR) applications. In fact, AR aims at inserting 2D or 3D virtual object generated by the computer in a real video filmed by a camera. On the other hand, the interaction in AR allows the user to take an action and control the virtual objects. In this work, Automatic Speech Recognition (ASR) system based on Gaussian Mixture Models (GMM) is investigated for voice interaction in AR. Experimental results show that good performance of the developed system. Also, the voice interaction provides an intuitive and a natural workspace for interacting with the augmented environment.","","978-1-4673-6673-1","10.1109/INTEE.2015.7416773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416773","Augmented Reality (AR);voice interaction;Automatique Speech Recognition (ASR);ARToolKit;Gaussian Mixture Models (GMM)","Feature extraction;Hidden Markov models;Speech;Augmented reality;Computers;Automatic speech recognition","augmented reality;Gaussian processes;human computer interaction;mixture models;speech recognition","voice interaction;Gaussian mixture models;augmented reality applications;human computer interaction;AR applications;2D virtual object;3D virtual object;virtual object control;automatic speech recognition system;ASR system;GMM system","","4","","12","IEEE","25 Feb 2016","","","IEEE","IEEE Conferences"
"Augmented Reality for Education; AR Children's Book","M. F. Hossain; S. Barman; A. K. M. B. Haque","Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh","TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)","12 Dec 2019","2019","","","2568","2571","By augmenting the real world with virtual information, Augmented Reality provides new possibilities for education. Education process should be all about creativity & interaction. A child learns the most when the lesson is interactive. So, it's necessary to provide them with a platform where they can interact with the subject, for their mental growth. This app is an approach to fulfill that goal.","2159-3450","978-1-7281-1895-6","10.1109/TENCON.2019.8929565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8929565","Alphabet;Bangla;English;Fruits;Education;Augmented Reality;Unity;Blender","Three-dimensional displays;Solid modeling;Augmented reality;Education;Cameras;Visualization;Object oriented modeling","augmented reality;computer aided instruction","virtual information;education process;augmented reality;AR childrens book;mental growth","","4","","12","IEEE","12 Dec 2019","","","IEEE","IEEE Conferences"
"Augmented reality approach for paper map visualization","C. Adithya; K. Kowsik; D. Namrata; V. S. Nageli; S. Shrivastava; S. Rakshit","Department of Information Science, B. M. Sreenivasaiah College of Engineering, Bangalore, India; Department of Information Science, B. M. Sreenivasaiah College of Engineering, Bangalore, India; Department of Information Science, B. M. Sreenivasaiah College of Engineering, Bangalore, India; Computer Vision Group, Center for Artificial Intelligence and Robotics, Bangalore, India; Computer Vision Group, Center for Artificial Intelligence and Robotics, Bangalore, India; Computer Vision Group, Center for Artificial Intelligence and Robotics, Bangalore, India","2010 International Conference on Communication and Computational Intelligence (INCOCCI)","24 Mar 2011","2010","","","352","356","Paper map visualization is good value proposition, even in the `everything is digital' world, because of the huge information density and ease of use at any remote or mobile location, especially in the military context. Completely doing away with the paper map brings in a discomfort factor for the military user. In this paper, we present a paper map data visualization solution that augments the information from the digital world onto a spread of a paper map. Augmented Reality techniques are used to enhance paper maps digitally resulting in a 3D visualization space with some interactions. The dynamic information of the terrain, placing virtual objects and interaction are features of the digital world that are superimposed onto a paper map. We have used ARToolkit marker tracking based approach and a see through Head Mounted Device for implementation. The digital elevation data in VRML format is split into smaller bits before rendering. The rendering is done after culling the relevant part of the terrain data and the same is popped up in stereo for enhanced visualization. The user can place virtual objects using markers. The distance between markers (user and reference) is calculated and is used for interactive features. The interaction options are load/select, slice/split and latch/freeze. We have achieved better performance by loading only the region of interest and not the complete terrain. The paper also illustrates the basic hardware set-up required for implementation.","","978-81-8371-369-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738756","Augmented Reality;Paper Map;3D Terrain;ARToolkit;Human Machine Interface","Augmented reality;Data visualization;Cameras;Three dimensional displays;Rendering (computer graphics);Solid modeling;Training","augmented reality;data visualisation;interactive systems;rendering (computer graphics);terrain mapping","augmented reality approach;paper map visualization;digital paper map enhancement;3D visualization space;dynamic information;ARToolkit marker tracking;head mounted device;digital elevation data;VRML format;rendering;terrain data;interactive feature","","2","","12","","24 Mar 2011","","","IEEE","IEEE Conferences"
"Automatic Data Generation for Deep Learning Model Training of Image Classification used for Augmented Reality on Pre-school Books","H. Le; M. Nguyen; Q. Nguyen; H. Nguyen; W. Q. Yan","School of Engineering, Computer & Mathematical Sciences, Auckland University of Technology; School of Engineering, Computer & Mathematical Sciences, Auckland University of Technology; School of Engineering, Computer & Mathematical Sciences, Auckland University of Technology; School of Engineering, Computer & Mathematical Sciences, Auckland University of Technology; School of Engineering, Computer & Mathematical Sciences, Auckland University of Technology","2020 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)","2 Nov 2020","2020","","","1","5","Nowadays, Augmented Reality (AR) has rightfully been taking as one of the leading position. Still, there are many different AR markers with different encryption and decryption methods which provide the users with an excellent capability to augment computer graphics generated virtual information onto real-world objects (e.g. text-book pictures or diagrams). However, the users need to choose which marker provider that matches their needs and create suitable markers based on the chosen provider's requirements. “Is it worth to re-print the entire existing books in-order to add AR functions?”. In this paper, we describe a new architecture to set up and present AR experiences by applying the benefit of deep learning (DL), the power of smart devices, and the flexibility of the Client-Server Architecture of the Internet. To set up, photos of pages in a textbook (but not limited to all pages) are uploaded to our server. For each page, the server will automatically generate different 3D views (thousands with different light conditions and perspectives) of the pages to form a sufficiently large enough dataset. They are then trained with a chosen convolutional neural network such as Alexnet, GoogleNet, VGG, GoogLeNet, or ResNet. The obtained model is then stored and can be loaded back to the client to serve as a classification process on a web browser using TensorFlow.JS, to recognise pages of the book. TensorFlow.JS is capable of running on smart devices with their built-in cameras; the recognised page will be used to specify which 3D graphics is displaying on top the page. This novel AR marker generating method is not only capable of keeping the original images of the books but also believed to achieve a higher detection accuracy. Thus, it is a promising, low-cost AR approach to be used in many areas, including education and training.","","978-1-7281-6555-4","10.1109/MAPR49794.2020.9237760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237760","Augmented Reality;Education;Convolutional Neural Network;Deep Learning;Machine Learning","Training;Deep learning;Three-dimensional displays;Computer architecture;Servers;Smart devices;Augmented reality","augmented reality;client-server systems;computer graphics;convolutional neural nets;cryptography;electronic publishing;image classification;Internet;learning (artificial intelligence)","automatic data generation;deep learning model training;image classification;augmented reality;AR markers;encryption;decryption;computer graphics;text-book pictures;smart devices;client server architecture;convolutional neural network;classification process;TensorFlow.JS;page recognition;preschool books;Internet;deep learning;Web browser;3D graphics","","1","","22","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"A New Approach to Remote Health Monitoring using Augmented Reality with WebRTC and WebXR","A. Sheik Abdullah; A. Manoj; G. T. Tarun Kishore; S. Selvakumar","Department of Information Technology, Thiagarajar College of Engineering, Madurai, Tamil Nadu, India; Department of Information Technology, Thiagarajar College of Engineering, Madurai, Tamil Nadu, India; Department of Information Technology, Thiagarajar College of Engineering, Madurai, Tamil Nadu, India; Department of Information Technology, Thiagarajar College of Engineering, Madurai, Tamil Nadu, India","2021 22nd International Arab Conference on Information Technology (ACIT)","17 Jan 2022","2021","","","1","5","The domain of Augmented Reality (AR) focus with the realm of conveying interactive experience of the objects in the real-world environment with the enhancement towards system generated information. It also conveys different forms of modality, visual perception, auditory and haptic information about the object which is considered for analysis. The system is used to formulate significant collaborative experiences with superimposed experiences among the users. This research work focus on the remote assistance for diagnosis and collaboration among the people who are involved as workers in product confirmation and analysis. The mechanism also decreases the communication issues with the intention of making the users to have a good enough environment to have a complete set of interaction. Therefore, to give a remote diagnostic of the work and guidance for the site workers from an expert we propose WebRTC (AppRTC) for Real-Time Video Communication and Google ARCore/ WebAR/ WebXR for augmenting the Video call, will be used and integrated to enhance the proposed system. Thereby the assembly process in improved for service quality with timely communication among the workers of a specified group..","","978-1-6654-1995-6","10.1109/ACIT53391.2021.9677324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9677324","Augmented Reality;Real Time Collaboration;WebRTC;Google ARCore;Remote Diagnostics","Three-dimensional displays;Annotations;Collaboration;Streaming media;Internet;Augmented reality;Monitoring","augmented reality;groupware;haptic interfaces;health care;Internet;video communication","remote health monitoring;WebRTC;augmented reality;interactive experience;system generated information;haptic information;collaborative experiences;superimposed experiences;remote assistance;product confirmation;real-time video communication;WebXR;Google ARCore","","1","","14","IEEE","17 Jan 2022","","","IEEE","IEEE Conferences"
"Application and evaluation of augmented reality user interface to a card game “Scopa”","H. Okada; T. Matsuse","Graduate School of Engineering, Kyoto Sangyo University, Kyoto, Japan; Graduate School of Engineering, Kyoto Sangyo University, Kyoto, Japan","SICE Annual Conference 2011","27 Oct 2011","2011","","","2127","2130","We propose an augmented reality application system for playing Scopa. The idea of this application is that visual augmentation by means of the AR method will help a Scopa beginner play games, learn rules from his/her game experiences under the support of the system, and thus become an experienced player who can play without any support. The system captures cards in the player's view via a camera, recognizes the current state, and visually augments cards to guide the user perform appropriate actions (e.g., discard an unwanted card). Our implementation and evaluation of the system are reported in this paper.","","978-4-907764-39-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060323","Augmented reality;beginners;user interaction navigation;entertainment computing;user interface","Games;Navigation;Augmented reality;User interfaces;Visualization;Cameras;Educational institutions","augmented reality;computer games;user interfaces","augmented reality user interface;card game;Scopa;visual augmentation;AR method","","","","9","","27 Oct 2011","","","IEEE","IEEE Conferences"
"The development of an ubiquitous learning system based on audio augmented reality","Hyon Lim; Ji-Hyuk Yang; Young-Sam Lee","Inha University, Incheon, Incheon, KR; NA; School of Electrical Engineering, Inha University, Incheon, South Korea","2007 International Conference on Control, Automation and Systems","26 Dec 2007","2007","","","1072","1077","This paper introduces the Street Poet project which features digitally augmented and location-aware contents. Client program in this project is capable of obtaining user's geographic position by GPS in order to playback relevant education contents. Audio augmented reality (AR) is one of the key feature of this project. We propose an audio AR in order to make immersive environments to enhance the effectiveness of ubiquitous learning (u-learning). The binaural processing module utilizes the information on the user's location and direction and generates the spatial sound dependent on the information. For non-experts, we provide authoring tools which is based on off-the-shelf geographic software for comprehensive usability. We also introduce our contents-providing method which uses inference engine to determine proper contents for individual user's profile.","","978-89-950038-6-2","10.1109/ICCAS.2007.4407058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4407058","Augmented Reality;3D Audio;Ubiquitous Learning;Context-Awareness","Learning systems;Augmented reality;Handheld computers;Application software;Ubiquitous computing;Computer vision;Computer graphics;History;Automatic control;Control systems","audio user interfaces;augmented reality;authoring systems;computer aided instruction;Global Positioning System;inference mechanisms;mobile computing","ubiquitous learning system;audio augmented reality;Street Poet project;location-aware contents;user geographic position;GPS;relevant education content playback;immersive environments;u-learning;binaural processing module;authoring tools;off-the-shelf geographic software;inference engine","","","2","9","","26 Dec 2007","","","IEEE","IEEE Conferences"
"Teleoperation of a multi-purpose robot over the internet using augmented reality","Hyeshin Park; Yo-An Lim; Aslam Pervez; Beom-Chan Lee; Sang-Goog Lee; Jeha Ryu","Department of Mechatronics, Gwangju Institute of Science and Technology, Gwangju, South Korea; Department of Mechatronics, Gwangju Institute of Science and Technology, Gwangju, South Korea; Department of Mechatronics, Gwangju Institute of Science and Technology, Gwangju, South Korea; Department of Mechatronics, Gwangju Institute of Science and Technology, Gwangju, South Korea; Department of Multimedia System Engineering, Catholic University, Seoul, South Korea; Department of Mechatronics, Gwangju Institute of Science and Technology, Gwangju, South Korea","2007 International Conference on Control, Automation and Systems","26 Dec 2007","2007","","","2456","2461","Bilateral teleoperation using augmented reality is proposed for a multi-purpose robot called SpiderBot-II that is an indoor-installed wire-driven parallel manipulator. It is intended to be used for various applications, including in-house rehabilitation training and daily life assistance such as walking assistance and health monitoring, especially for the elderly or the handicapped that spends most of time at home. Through the teleoperation over the Internet, a therapist or an attendant in a remote site can give help to the physically disabled by directly manipulating the robot. For easy recognition of the obstacle, predefined markers are attached to each obstacle in the workspace. For better teleoperation, moreover, reaction force between obstacles and the end-effector, which is calculated using force field, is given to a remote operator and this enables the operator to perform the teleoperation more effectively. Force field, which is proportional to proximity between obstacles and the end-effector, is generated to facilitate the obstacle avoidance and visually augmented on the operator's screen for better recognition of obstacles.","","978-89-950038-6-2","10.1109/ICCAS.2007.4406776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4406776","Teleoperation;Wire-driven Parallel Mechanism;Augmented Reality;Walking Assistance;Haptic Feedback","Internet;Augmented reality;Legged locomotion;Rehabilitation robotics;Senior citizens;Control systems;Robotics and automation;Parallel robots;Electronic mail;Haptic interfaces","augmented reality;collision avoidance;handicapped aids;Internet;manipulators;medical robotics;patient rehabilitation;telemedicine;telerobotics","bilateral teleoperation;augmented reality;multipurpose robot;Internet;SpiderBot-II robot;indoor-installed wire-driven parallel manipulator;in-house rehabilitation training;daily life assistance;walking assistance;health monitoring;obstacle recognition;obstacle avoidance;physically disabled people","","","","11","","26 Dec 2007","","","IEEE","IEEE Conferences"
"Analysis of Augmented Reality application based on cloud computing","M. Chen; C. Ling; W. Zhang","School of Film & TV Arts and Technology, Shanghai University, Shanghai, China; School of Film & TV Arts and Technology, Shanghai University, Shanghai, China; School of Film & TV Arts and Technology, Shanghai University, Shanghai, China","2011 4th International Congress on Image and Signal Processing","12 Dec 2011","2011","2","","569","572","Mixing of virtual and actual reality, Augmented Reality (AR) develops rapidly in recent years. AR applications based on cloud computing has a huge potential, but it also has the problems related to lack of fundamental research. This paper analyzes the AR research with cloud computing, and discusses it to solve the problem of insufficient computing power of the AR applications, focusing on the establishment of the AR cloud, resource scheduling, evaluation and other fundamental issues. The paper also introduces the implementation and transplantation of the cloud about AR real-time registration, render, collision detection and other fundamental problems.","","978-1-4244-9306-7","10.1109/CISP.2011.6100311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6100311","augmented reality;cloud computing;resource scheduling;cloud system evaluation;registration and render;collision detection","Cloud computing;Mobile communication;Real time systems;Processor scheduling;Augmented reality;Accuracy;Computers","augmented reality;cloud computing;rendering (computer graphics);resource allocation;scheduling","augmented reality application;cloud computing;resource scheduling;AR registration;AR rendering;AR collision detection","","12","","14","IEEE","12 Dec 2011","","","IEEE","IEEE Conferences"
"A Markeless Augmented Reality Tracking for Enhancing the User Interaction during Virtual Rehabilitation","A. Klein; G. A. d. Assis","Instituto de Informática, UFRGS, Porto Alegre, Brazil; NA","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","117","124","Virtual Rehabilitation provides a range of technological and clinical developments in the field of virtual reality and augmented reality applied to rehabilitation. In this context, a system for upper-limb motor rehabilitation of stroke patients based on augmented reality was developed. This system aimed providing the motor imagery using a virtual three-dimensional arm that replaces the paralyzed arm in a real-time image of the patient. During the task execution in the augmented reality environment, the physiotherapist had guided the patients while they saw themselves and surroundings, as in a mirror. Although not achieving statistical significance, the Fugl-Meyer results of these case studies suggested that the participants were able to use the technology and they had larger shoulder range of motion of the affected hand post-training using the augmented reality system. However, many faults in the detection and recognition of physical markers were occurred whenever there was partial obfuscation or imperfect capture of the marker's image. For this reason, a new version of the system was developed to provide an augmented reality system without markers, and thus, aiming to improve the usability of next clinical trials.","","978-0-7695-5001-5","10.1109/SVR.2013.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655769","Augmented reality;virtual rehabilitation;markless tracking","Electromyography;Shoulder;Augmented reality;Cameras;Face;Training","augmented reality;human computer interaction;medical computing;patient rehabilitation","markerless augmented reality tracking;user interaction;virtual rehabilitation;technological developments;clinical developments;virtual reality;upper-limb motor rehabilitation;stroke patients;motor imagery;virtual three-dimensional arm;paralyzed arm;real-time image;task execution;physiotherapist;Fugl-Meyer results;hand post-training;augmented reality system;faults detection;faults recognition;physical markers;marker image partial obfuscation;marker image imperfect capture;clinical trial usability","","11","","22","IEEE","7 Nov 2013","","","IEEE","IEEE Conferences"
"Augmented Reality Based IOT Controller","R. Khanna; V. M","School Of Information and Engineering, Vellore Institute Of Technology, Vellore, India; School Of Information and Engineering, Vellore Institute Of Technology, Vellore, India","2019 International Conference on Vision Towards Emerging Trends in Communication and Networking (ViTECoN)","14 Nov 2019","2019","","","1","5","Augmented reality enables computer generated graphics to be superimposed on real world objects. From 3D objects to animations, with the help of AR, one can create an interactive and assistance software applications. This project represents a framework for implementing an AR powered controller with interactive controlling of different devices that are connected to each other and communicate via the internet. The project aims to establish a more fundamental approach in integrating mobile AR with internet of things. The users are able to immerse themselves with a computer generated reality and use it to control vast amount of diverse objects and devices. The mobile application can be used with an AR headset for a better experience. This project produces two important contributions: 1) A mobile AR based application to control IOT enabled devices. 2) Implementation of the application using Unity 3D game engine. 3) Future scope of blending AR with IOT.","","978-1-5386-9353-7","10.1109/ViTECoN.2019.8899625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899625","augmented reality;internet of things;mobile application;game engine;smart controller","Databases;Three-dimensional displays;Games;Target tracking;Relays;Augmented reality","augmented reality;computer games;Internet of Things;mobile computing;power control","augmented reality;interactive assistance software applications;AR powered controller;interactive controlling;mobile application;Unity 3D game engine;IoT controller","","7","","15","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Application of sensors in Augmented Reality based interactive learning environments","C. V. Ramdas; N. Parimal; M. Utkarsh; S. Sumit; K. Ramya; B. P. Smitha","MARS Lab, Bangalore, India; MARS Lab, Bangalore, India; MARS Lab, Bangalore, India; MARS Lab, Bangalore, India; MARS Lab, Bangalore, India; MARS Lab, Bangalore, India","2012 Sixth International Conference on Sensing Technology (ICST)","14 Feb 2013","2012","","","173","178","Context awareness, user friendliness, and interactivity are very important and powerful concepts in building useful teaching/learning environments for the benefit of mankind. Advancements in technology are enabling us to look at new use cases in the methods of teaching, information sharing, knowledge dissemination, and self-learning. Learning environments are not only for teaching things to people., but also for providing more information to them on any subject that they may require from time to time. User friendliness can be enhanced with clever use of sensors to give hands free interactivity with the devices/gadgets. Context aware applications require sensors to get the context information. Mobile devices like smart phones and tablets today come with a hand full of sensors mounted on them which include one or two cameras, a microphone, a touch screen, an accelerometer to sense motion, and in addition have GPS and digital compass to provide location information to applications requiring these sensory inputs. The computational power packed in the processors used in these devices/gadgets including special support for graphics processing, the near general purpose computer like operating system environments, and the quality of cameras available, are all enabling application developers to map some serious computer vision based applications on today's mobile devices. This reality has encouraged us to get into development of Augmented Reality (AR) based interactive learning environments on mobile devices, leading to our development of a software framework for AR applications development and also development of an AR book and an AR board. AR has been called the eighth mass medium, after print, recordings, cinema, radio, television, Internet and mobile phones. There is ample scope for enhancing the learning/teaching experiences of the users with AR based learning environments. AR makes learning more effective and an enjoyable experience by providing more realistic information with the use of 3D graphics and animated models.","2156-8073","978-1-4673-2248-5","10.1109/ICSensT.2012.6461664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461664","Augmented Reality;AR;context awareness;AR learning","Augmented reality;Context;Context-aware services;Sensors;Mobile communication;Mobile handsets;Software","augmented reality;computer aided instruction;educational aids;interactive devices;sensors;ubiquitous computing","sensor application;augmented reality;interactive learning environments;context awareness;user friendliness;hands free interactivity;mobile device;eighth mass media;after print;Internet;mobile phones;3D graphics;animated model","","7","","11","IEEE","14 Feb 2013","","","IEEE","IEEE Conferences"
"Making a Hands-On Display with Augmented Reality Work at a Science Museum","T. B. Takahashi; S. Takahashi; F. Kusunoki; T. Terano; S. Inagaki","Gakushūin, Tokyo, Japan; Tama Art University, Tokyo, Japan; Kobe University, Hyogo, Japan; Tokyo Institute of Technology, Tokyo, Japan; Tokyo Institute of Technology, Tokyo, Japan","2013 International Conference on Signal-Image Technology & Internet-Based Systems","30 Jan 2014","2013","","","385","390","In this paper, we propose an augmented reality (AR) system with a laser projection device as a hands-on display at a science museum. The AR system provides virtual information, which learners can control for a visual explanation about an exhibited item. Learners develop their knowledge and understanding through the display without any modification to the item and/or the existing displayed explanation. We conducted an experiment using the AR system, with child visitors to Gamagori Museum of Earth, Life and the Sea. AR systems should meet the following criteria if they are to be considered effective: i) the display should make learners interested in the exhibited item, ii) learners should be able to easily handle the AR display, and iii) learners should construct their knowledge through using the display. In our experiment, we evaluated the AR display against these criteria. We conclude that the AR display system enables learners to construct their knowledge in reality, and that the system encourages learners' interest in the exhibited items.","","978-1-4799-3211-5","10.1109/SITIS.2013.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727218","augmented reality;hands-on display;museum;education","Whales;Laser applications;Interviews;Teeth;Augmented reality","augmented reality;museums","augmented reality;science museum;AR system;laser projection device;hands-on display;virtual information;visual explanation;Gamagori Museum of Earth Life and the Sea;AR display","","4","","9","IEEE","30 Jan 2014","","","IEEE","IEEE Conferences"
"Experiences using Augmented Reality Environment for training and evaluating medical students","F. Pretto; I. H. Manssour; M. H. I. Lopes; M. S. Pinho","UNIVATES, Brazil; PUCRS, Brazil; PUCRS, Brazil; PUCRS, Brazil","2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)","3 Oct 2013","2013","","","1","4","The process of medical training and evaluation in Brazil has been supported by several resources in order to graduate more qualified students. These resources include atlas, photos, movies, cadavers, animations, real patients, standarized patients(actors) and anatomical manikins, among others. For the reality of medical schools in a developing country as Brazil, high-end manikins are too expensive. This paper describes the validation of the Augmented Reality Environment for Life Support Training (ARLIST) system, built on the top of conventional manikins, used in cloth shops, during three editions of the Selection Exam for the Medical Residence Program of São Lucas Hospital, reaching a total of 450 users of this system. The use of manikins in these exams has showed that there is great potential for using this kind of technology in this process in medical schools, since the results were promising and resources as cadavers and experimental animals are increasingly scarce.","","978-1-4799-1604-7","10.1109/ICMEW.2013.6618311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618311","augmented reality;medical training","Biomedical imaging;Training;Educational institutions;Augmented reality;Lungs;Cadaver;Solid modeling","augmented reality;biomedical education;hospitals;medical computing;student experiments;training","São Lucas Hospital;medical residence program;ARLIST system;life support training;Brazil;medical training;medical students evaluation;augmented reality environment","","4","","7","IEEE","3 Oct 2013","","","IEEE","IEEE Conferences"
"Augmented reality application for cockroach phobia therapy using everyday objects as marker substitute","F. Fatharany; R. R. Hariadi; D. Herumurti; A. Yuniarti","Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2016 International Conference on Information & Communication Technology and Systems (ICTS)","27 Apr 2017","2016","","","49","52","Augmented reality (AR) technology is useful for treating several psychological problems, including phobias such as fear of flying, agoraphobia, claustrophobia, and phobia to insects and small animals. However, the currently existing applications for therapy of cockroach phobia that uses AR technology are still very dependent towards the presence of markers, which might lessen the feeling of being in an actual scenario from everyday lives. In this paper, we created a system that is able to use everyday objects as a replacement for markers. There are five main processes: getting the live streaming feed from camera, preprocessing in which adaptive threshold was used as the image processing method, extracting the center point of the objects, tracking the objects, and lastly, instantiating cockroaches randomly underneath the objects. The evaluation in this paper includes eight participants that are carefully selected based on their Fear of Spiders Questionnaire (FSQ) score that is translated into Indonesian and modified to accommodate cockroaches instead of spiders. The system is able to induce a small to medium level of anxiety on participants that are measured using Standard Unit of Discomfort scale (SUDs). Meanwhile, this application has a high score for the presence and reality judgment that are measured using Slater-Usoh-Steed Questionnaire (SUS).","2338-185X","978-1-5090-1381-4","10.1109/ICTS.2016.7910271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7910271","adaptive threshold;augmented reality;cockroach phobia","Augmented reality;Atmospheric measurements;Particle measurements;Testing;Cameras;Libraries;Medical treatment","augmented reality;image segmentation;object tracking;psychology","augmented reality application;cockroach phobia therapy;psychological problems;adaptive threshold;image processing;object tracking;fear of spiders questionnaire;FSQ score;standard unit of discomfort scale;SUDs;Slater-Usoh-Steed questionnaire;SUS","","3","","17","IEEE","27 Apr 2017","","","IEEE","IEEE Conferences"
"Interaction design in Augmented Reality on the smartphone","C. Lv; X. Yang; J. Yu","School of Information Engineering Communication, University of China Beijing, China; School of Information Engineering Communication, University of China Beijing, China; School of Information Engineering Communication, University of China Beijing, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","16 Feb 2017","2016","","","1317","1321","Augmented Reality (AR) is aimed at integrating virtual information into real world to enhance the perception ability of reality. The paper mainly presents an AR system that can complete some interactions between the user and the smartphone based on touch screen and body motion. There are three contents in this system. The first part is the building of AR scenes in Unity3D on the basis of real-time mapping access to the WebCamTexture Class. The second part is the interaction based on the touch screen with the method of Raycast. The third part is the interaction based on the body motion with the help of Gyro Sensor in the smartphone. Experimental results show that there is a good effect in the touch-screen interaction to realize some actions such as translation, rotation, scaling, or any combination of these. And it is also effective in the body-motion interaction to control the virtual objects acting according to the user's body motion.","","978-1-5090-3710-0","10.1109/CISP-BMEI.2016.7852920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852920","Augmented Reality;Interaction Design;Smartphone","Cameras;Fingers;Augmented reality;Three-dimensional displays;Streaming media;Real-time systems;Mobile handsets","augmented reality;smart phones","interaction design;augmented reality;smartphone;AR system;touch screen;body motion;AR scenes;Unity3D;real-time mapping;WebCamTexture class;raycast method;gyro sensor;touch-screen interaction;body-motion interaction;virtual object control","","2","","6","IEEE","16 Feb 2017","","","IEEE","IEEE Conferences"
"Investigating the effect of augmented reality technology on traditional culture experience motivation by using a novel Tosenkyo application","K. Mizobuchi; H. -Y. Tsai; Y. Ieiri; R. Hishiyama; S. Tengfei","Graduate School of Creative Science and Engineering, Waseda University, Shinju-ku, Tokyo, Japan; Graduate School of Creative Science and Engineering, Waseda University, Shinju-ku, Tokyo, Japan; Graduate School of Information, Production and Systems, Waseda University, Wakamatsu-ku, Kitakyushu City, Fukuoka, Japan; Graduate School of Creative Science and Engineering, Waseda University, Shinju-ku, Tokyo, Japan; Graduate School of Creative Science and Engineering, Waseda University, Shinju-ku, Tokyo, Japan","2022 61st Annual Conference of the Society of Instrument and Control Engineers (SICE)","6 Oct 2022","2022","","","1226","1231","In this study, we proved that augmented reality (AR) technology increases the motivation to experience traditional culture. We developed an AR Tosenkyo application to simulate ""Tosenkyo,"" a traditional Japanese game, and conducted experiments with 47 participants, including foreigners. Because Tosenkyo AR application components can be categorized into play equipment and backgrounds, we prepared three applications with different degrees of AR environmental conditions to investigate their effect on motivation. The results of the experiment revealed that, before the AR experience, Japanese people were less motivated to experience traditional culture compared with Chinese people; however, after the AR experience, their motivation increased considerably. This tendency was pronounced in a harmonic AR environment, which is considered a moderate fusion of reality and AR. Furthermore, the path analysis of the questionnaire results revealed that higher quality of AR application considerably improves motivation.","","978-4-9077-6478-4","10.23919/SICE56594.2022.9905814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9905814","augmented reality (AR);human computer interaction (HCI);interactive media;cognitive science","Instruments;Games;Harmonic analysis;Cultural differences;Augmented reality","augmented reality;computer games","augmented reality technology;AR Tosenkyo application;Japanese game;application components;play equipment;Japanese people;culture experience motivation","","","","13","","6 Oct 2022","","","IEEE","IEEE Conferences"
"CrowdAR Table An AR system for Real-time Interactive Crowd Simulation","N. Savenije; R. Geraerts; W. Hürst","Utrecht University, Utrecht, the Netherlands; Utrecht University, Utrecht, the Netherlands; Utrecht University, Utrecht, the Netherlands","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","57","59","Spatial augmented reality, where virtual information is projected into a user's real environment, provides tremendous opportunities for immersive analytics. In this demonstration, we focus on real-time interactive crowd simulation, that is, the illustration of how crowds move under certain circumstances. Our augmented reality system, called CrowdAR, allows users to study a crowd's motion behavior by projecting the output of our simulation software onto an augmented reality table and objects on this table. Our prototype system is currently being revised and extended to serve as a museum exhibit. Using real-time interaction, it can teach scientific principles about simulations and illustrate how these, in combination with augmented reality, can be used for crowd behavior analysis.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319072","Crowd Simulation;Augmented Reality;Interactive Tabletop","Solid modeling;Augmented reality;Real-time systems;Prototypes;Cameras;Calibration;Buildings","augmented reality;computer simulation;man-machine systems","CrowdAR table;AR system;real-time interactive crowd simulation;spatial augmented reality;virtual information;augmented reality system;simulation software;augmented reality table;prototype system;real-time interaction;crowd behavior analysis","","2","","11","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"From Virtual Reality to Augmented Reality: Devices, Bodies, Places and Relationships","M. Centorrino; J. Condemi; L. D. Paola; C. Ferrigno","Dipartimento di Civiltà Antiche e Moderne DICAM, University of Messina; Dipartimento di Civiltà Antiche e Moderne DICAM, University of Messina; Dipartimento di Civiltà Antiche e Moderne DICAM, University of Messina; Dipartimento di Civiltà Antiche e Moderne DICAM, University of Messina","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","1","7","We can consider augmented reality (AR) a true evolution of virtual reality (VR). AR is an interesting synthesis of those socially structured processes that have led, in a short time, to a maturation of the digital world. In light of all this, we intend analyse the materiality of the devices and tools (Tirino 2017) necessary to create augmented environments in order to shed light on the sociocultural processes that shape the media. We investigate how AR has led to the reaffirmation of the centrality of bodies in the experience (Damasio 1994, 1999). Plural bodies are called to interact in environments increasingly similar to hyperplaces (Bolognari, 2012). In hyperplaces the same body/mind dichotomy tends to blur, opening up to new dynamics of structural coupling with the environment (Maturana, Varela 1972). We are talking about dynamics with obvious consequences on the self and hetero perception of identity. In the light of those new expressive techniques (Montani 2020) and forms of convergent and participatory culture (Jenkins 2006, 2010), we reflect on how AR devices and applications could affect in-person sociability.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585871","Virtual reality;Augmented reality;Materiality;Identity;Hyperplace;Augmented space;Relationships;In-person sociability","Economics;Couplings;Shape;Media;Tools;Aerospace electronics;History","augmented reality;cartography;cognitive systems;history;human factors;user interfaces","digital world;augmented environments;sociocultural processes;plural bodies;structural coupling;virtual reality;augmented reality;AR devices;in-person sociability","","1","","61","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Mobile augmented reality system for personal museum tour guide applications","Chen Jing; Guo Junwei; Wang Yongtian","Key Laboratory of Photoelectronic Imaging Technology and System, Ministry of Education of China, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; Key Laboratory of Photoelectronic Imaging Technology and System, Ministry of Education of China, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; Key Laboratory of Photoelectronic Imaging Technology and System, Ministry of Education of China, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China","IET International Communication Conference on Wireless Mobile and Computing (CCWMC 2011)","7 May 2012","2011","","","262","265","In this paper, we developed a prototype of a mobile interactive museum guide system, which consists of an ultra mobile PC equipped with a webcam. This museum guidance system can automatically find and retrieve multimedia information about the objects of interest to the visitors in an intuitive way. A coarse to fine image recognition method is used to improve the recognition rate and a sub-exhibits localization method is proposed to solve the occlusion problem.","","978-1-84919-505-8","10.1049/cp.2011.0887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194844","museum guidance application;augmented reality;feature recognition","","augmented reality;image recognition;image sensors;mobile computing;museums","mobile augmented reality system;personal museum tour guide applications;mobile interactive museum;ultra mobile PC;Webcam;multimedia information;image recognition method","","","","","","7 May 2012","","","IET","IET Conferences"
"Augmented Learning: Context-Aware Mobile Augmented Reality Architecture for Learning","J. T. Doswell",The Juxtopia Group,"Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06)","24 Jul 2006","2006","","","1182","1183","Mobile augmented reality system (MARS) based e-learning environments equip a learner with a mobile wearable see-through display that interacts with training/learning software. MARS has the potential to adapt to individual learner needs and dynamically distribute tailored instruction to improve learning performance for a life time. While using MARS, learners may interact with their natural environment while MARS digitally annotates real-world objects with digital content. This digital content may combine multi-modal animation, graphics, text, and video as well as voice used to augment instruction based on empirical pedagogical models. The challenge, however, is building a MARS software architecture that fulfills this potential and is also reusable, interoperable, and adaptive to individual augmented reality (AR) ""heads-up displays"" while, at the same time, capable of delivering personalized instruction to the learner","2161-377X","0-7695-2632-2","10.1109/ICALT.2006.1652683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652683","","Augmented reality;Mars;Computer architecture;Software architecture;Eye protection;Context awareness;Graphics;Humans;Two dimensional displays;Pervasive computing","augmented reality;computer aided instruction;computer animation;helmet mounted displays;mobile computing;open systems;software architecture;software reusability","augmented learning;context-aware learning;mobile augmented reality architecture;e-learning environment;mobile wearable see-through display;training software;learning software;digital content;multimodal animation;graphics;software architecture;software reusability;interoperability;heads-up displays;personalized instruction","","14","2","6","IEEE","24 Jul 2006","","","IEEE","IEEE Conferences"
"Augmented touch without visual obtrusion","F. I. Cosco; C. Garre; F. Bruno; M. Muzzupappa; M. A. Otaduy","Università della Calabria, Italy; URJC Madrid, Spain; Università della Calabria, Italy; Università della Calabria, Italy; URJC Madrid, Spain","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","99","102","Visuo-haptic mixed reality consists of adding to a real scene the ability to see and touch virtual objects. It requires the use of see-through display technology for visually mixing real and virtual objects, and haptic devices for adding haptic interaction with the virtual objects. However, haptic devices tend to be bulky items that appear in the field of view of the user. In this work, we propose a novel mixed reality paradigm where it is possible to touch and see virtual objects in combination with a real scene, but without visual obtrusion produced by the haptic device. This mixed reality paradigm relies on the following three technical steps: tracking of the haptic device, visual deletion of the device from the real scene, and background completion using image-based models. We have developed a successful proof-of-concept implementation, where a user can touch virtual objects in the context of a real scene.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336492","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems;Artificial, Augmented, and Virtual Realities","Haptic interfaces;Virtual reality;Layout;Space technology;Actuators;Rendering (computer graphics);Optical devices;Displays;Multimedia systems;Medical services","augmented reality;data visualisation;haptic interfaces;rendering (computer graphics)","augmented touch;visuo-haptic mixed reality;virtual object;see-through display technology;haptic device;haptic interaction;real scene;image-based rendering","","29","2","17","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"[Poster] a single co-lived augmented world or many solipsistic fantasies?","N. Liberati",University of Pisa,"2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design (ISMAR-MASH'D)","27 Oct 2014","2014","","","71","72","The aim of this paper is to determine the difference, in augmented reality (AR), between the creation of one single world and the creation of multiple worlds in terms of the “reality” of the augmented world created by the device. This work analyses what kind of relation between subjects and worlds are created by these two different kinds of worlds created from a phenomenological perspective. It will be clear how the production of such an augmented world cannot be solved by mere technical elements, but it has to deal with bigger problems.","2381-8360","978-1-4799-6887-9","10.1109/ISMAR-AMH.2014.6935443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935443","H.1.2 [Information Systems]: Models and Principles—User/Machine Systems;I.2.0 [Computer Application]: Social and Behavioral Sciences—Psychology","Augmented reality;Educational institutions;Games;Communities;Media;Production;Art","augmented reality","single co-lived augmented world;solipsistic fantasies;augmented reality;AR;phenomenological perspective","","2","","8","IEEE","27 Oct 2014","","","IEEE","IEEE Conferences"
"Perceptual MR Space: Interactive Toolkit for Efficient Environment Reconstruction in Mobile Mixed Reality","C. Cao; J. Sun","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; School of New Media Art and Design, Beihang University","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","353","357","With the rapid development of relevant hardware and software, mixed reality has been widely applied in gaming, industrial production, tourism et al.. However, the environment understanding cannot fulfill the need of a mobile mixed reality application in some occasions. In this paper, we propose Perceptual MR Space, a semi-automatic environment understanding technique for complete, consistent and efficient environment understanding in mobile mixed reality applications. We use several environment reconstruction tasks to evaluate the effectiveness of the technique. A mixed reality game ""Run!Tom"" is developed to show the application and advantage of the technique.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951992","Mixed reality;HCI design;Environment reconstruction","Visualization;Mixed reality;Games;Production;Manuals;Cameras;User experience","augmented reality;computer games;interactive systems;mobile computing;virtual reality","interactive toolkit;environment reconstruction;mobile mixed reality application;gaming application;perceptual MR space;mixed reality game;environment reconstruction tasks;semiautomatic environment understanding technique","","2","","16","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"See-through window vs. magic mirror: A comparison in supporting visual-motor tasks","Zhen Bai; A. F. Blackwell",University of Cambridge; University of Cambridge,"2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","239","240","There are two alternative display metaphors for Augmented Reality (AR) screens: a see-through window or a magic mirror. Commonly used by task-support AR applications, the see-through display has not been compared with the mirror display in terms of user's task performance, even though the “mirror” hardware is more accessible to general users. We conducted a novel experiment to compare participants' performance when following object rotation cues with the two display metaphors. Results show that participants' overall performance under the mirror view was comparable to the see-through view, which indicates that the augmented mirror display may be a promising alternative to the window display for AR applications which guide moderately complex three-dimensional manipulations with physical objects.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671784","Augmented Reality;display metaphor;visual-motor","Mirrors;Cameras;Monitoring;Face;Augmented reality;Educational institutions;Three-dimensional displays","augmented reality;computer displays;mirrors","see-through window;magic mirror;visual-motor tasks;display metaphors;augmented reality screens;AR screens;task-support AR applications;see-through display;augmented mirror display;three-dimensional manipulations;physical objects","","1","","4","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"B-Handy: An Augmented Reality System for Biomechanical Measurement","J. Campbell; A. Cassinelli; D. Saakes; D. Rompapas","Brewed Engagement, Extended Reality Labs, Adelaide, Australia; School of Creative Media, Hong Kong City University, Hong Kong; Design Production Management, University of Twente, The Netherlands; Brewed Engagement, Extended Reality Labs, Adelaide, Australia","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","976","977","The study of bio-mechanics allows us to infer measurements for every day objects without needing measurement tools. A limitation of this comes from the complex mental transformations of space involved. The efficiency of this task degrades the larger these measurements become. We present B-Handy, a system that offloads this mental workload by providing visual transformations of space in the form of tracking and duplicating the user's hand in AR. It is our hope that this system will simplify the complexity of these mental transformations and increase the efficiency of bio-mechanical measurements.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757687","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality;Human-centered computing—Human computer interaction (HCI)—Interaction techniques—Pointing","Biomechanics;Visualization;Three-dimensional displays;Conferences;User interfaces;Complexity theory;Task analysis","augmented reality;biomechanics;data visualisation","augmented reality system;biomechanical measurement;measurement tools;complex mental transformations;B-Handy;mental workload","","","","5","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"MR Platform: a basic body on which mixed reality applications are built","S. Uchiyama; K. Takemoto; K. Satoh; H. Yamamoto; H. Tamura","MR Systems Laboratory, Canon, Inc., Tokyo, Japan; MR Systems Laboratory, Canon, Inc., Tokyo, Japan; MR Systems Laboratory, Canon, Inc., Tokyo, Japan; MR Systems Laboratory, Canon, Inc., Tokyo, Japan; MR Systems Laboratory, Canon, Inc., Tokyo, Japan","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","246","320","This paper describes a platform package, called ""MR Platform,"" which we have been implementing for research and development of augmented reality technology and applications. This package includes a parallax-less stereo video see-through HMD and a software development kit (SDK) for a Linux PC environment. The SDK is composed of a C++ class library for making runtime MR applications and related utilities such as a camera calibration tool. By using the SDK, the following functions are available: capturing video, handling a six degree-of-freedom (DOF) sensor, image processing such as color detection, estimating head position and orientation, displaying the real world image, and calibrating sensor placement and camera parameters of two cameras mounted on the HMD.","","0-7695-1781-1","10.1109/ISMAR.2002.1115095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115095","","Virtual reality;Application software;Cameras;Packaging;Image sensors;Research and development;Augmented reality;Software packages;Programming;Linux","augmented reality;image processing;helmet mounted displays;programming environments;Unix;C++ language;software libraries;calibration;object-oriented programming","MR Platform;mixed reality applications;platform package;research and development;augmented reality;parallax-less stereo video see-through HMD;software development kit;Linux;PC environment;C++ class library;camera calibration tool;video capture;six degree-of-freedom sensor;image processing;color detection;head position estimation","","37","7","12","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"The Effect of Tangible User Interfaces on Cognitive Load in the Creative Design Process","T. Chandrasekera; S. -Y. Yoon",Oklahoma State University; Cornell University,"2015 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design","10 Dec 2015","2015","","","6","8","The aim of the study is to investigate how Graphical User Interfaces (GUI) and Tangible User Interfaces (TUI) affect the creative design process in design education through cognitive load. A simple design problem was introduced to 30 design students in two groups. One group was provided with a TUI that was operationalized through a Desktop Augmented Reality Environment (AR) the other group was provided with a GUI that was operationalized through a Desktop Virtual Reality Environment (VR). After using the two systems the cognitive load of each interface was measure through the NASA TLX tool. Theories from cognitive psychology, information sciences, and design cognition were combined to provide an explanatory mechanism of how these media types affect the design process. The results indicate that epistemic action in TUI's such as AR interfaces reduces cognitive load thereby reducing fixation in the design process and enhancing the creative design process.","","978-1-4673-9628-8","10.1109/ISMAR-MASHD.2015.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350727","Augmented Reality;Design;Cognitive Load","Education;Graphical user interfaces;Augmented reality;Visualization;NASA;Cognition","augmented reality;cognition;graphical user interfaces;haptic interfaces;psychology","tangible user interfaces;cognitive load;creative design process;GUI;TUI;design education;cognitive load;desktop augmented reality environment;desktop virtual reality environment;desktop VR;NASA TLX tool;cognitive psychology;information sciences;design cognition;AR interfaces","","9","","11","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"Augmented illusionism. The influence of optical illusions through artworks with augmented reality","B. J. Pérez",Universidad Complutense de Madrid,"2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","158","164","The regular studies on optical illusions through artistic practice usually focus on illusionist painting, placing its conceptualization and methodology within the framework of the pictorial tradition. However, few investigations have dealt with the phenomena of ambiguity, distortion, wrong motion perception, or color in artistic pieces created through the use of augmented reality. This offers a new field of study through which to explore optical illusions, hereby considered erroneous and unconscious perceptions of the actual physical characteristics of an image or object, through the hybridization of real and virtual elements. For this, an investigation of optical illusions is carried out through the work of various artists who use augmented reality technology to generate their artistic pieces. At the same time, the results of an experiment are shown, in which 20 participants evaluate three artistic prototypes created by the author, in which digital elements are superimposed on backgrounds whose characteristics have discordant relationships, of tension and contradiction between figure and background.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288440","Augmented reality;optical illusions;art;perception","Visualization;Optical distortion;Color;Optical imaging;Adaptive optics;Augmented reality;Optical devices","art;augmented reality;visual perception","augmented illusionism;optical illusions;artistic pieces;augmented reality;artistic prototypes;illusionist painting;virtual element hybridization;real element hybridization","","","","30","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Exploring an Innovative Collaborative Design Space through Mixed Reality Boundaries","X. Wang","Faculty of Architecture, University of Sydney, Australia","2007 11th International Conference on Computer Supported Cooperative Work in Design","30 Jul 2007","2007","","","264","269","Over the past decade, various ""reality"" concepts with supporting technologies emerged in computing area to take on the task of replacing or merging physical world with virtual world. The first part of this paper presents the existing taxonomies and distinctions of these ""realities"" and their potentials in design. The second part of the paper presents the theory of Mixed Reality boundaries by Benford, which as one of those ""realities"", is envisaged to construct innovative collaborative design spaces. The final part of the paper implements mixed reality boundaries theory into creating a real-time innovative collaborative design space between architects and interior designers.","","1-4244-0962-4","10.1109/CSCWD.2007.4281445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4281445","Augmented Reality;Collaborative Design;Virtual Reality;Mixed Reality Boundaries","Collaboration;Virtual reality;Augmented reality;Physics computing;Space technology;Augmented virtuality;Merging;Displays;Collaborative work;Virtual environment","augmented reality;CAD;groupware;real-time systems","real-time innovative collaborative design space;mixed reality boundaries;virtual world;augmented reality","","5","","12","IEEE","30 Jul 2007","","","IEEE","IEEE Conferences"
"An augmented virtuality approach to 3D videoconferencing","H. Regenbrecht; C. Ott; M. Wagner; T. Lum; P. Kohler; W. Wilke; E. Mueller","DaimlerChrysler Aerospace, Germany; Igroup. org; Shared reality.com; DaimlerChrysler Aerospace, Germany; DaimlerChrysler Aerospace, Germany; DaimlerChrysler Aerospace, Germany; DaimlerChrysler Aerospace, Germany","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","290","291","This paper describes the concept, prototypical implementation, and usability evaluation of an augmented virtuality (AV) based videoconferencing (VC) system: ""cAR/PE!"". We present a first solution which allows three participants at different locations to communicate over a network in an environment simulating a traditional face-to-face meeting. Integrated into the AV environment are live video streams of the participants spatially arranged around a virtual table, a large virtual presentation screen for 2D display and application sharing, and 3D geometry (models) within the room and on top of the table.","","0-7695-2006-5","10.1109/ISMAR.2003.1240725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240725","","Augmented virtuality;Teleconferencing;Virtual prototyping;Usability;Virtual colonoscopy;Video sharing;Streaming media;Two dimensional displays;Geometry;Solid modeling","teleconferencing;groupware;virtual reality;augmented reality;multimedia systems","augmented virtuality;3D videoconferencing;prototypical implementation;usability evaluation;AV based videoconferencing;VC system;cAR/PE!;communication network;face-to-face meeting;AV environment;video streams;virtual table;virtual presentation screen;2D display;application sharing;3D geometry models;distant computer supported collaborative work;CSCW","","16","2","3","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Heuristic evaluation on Augmented Reality courseware for the deaf","N. M. M. Zainuddin; H. B. Zaman; A. Ahmad","Advanced Informatics School, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Department of Information Science, Universiti Kebangsaan Malaysia, Bangi, Malaysia; Department of Information Science, Universiti Kebangsaan Malaysia, Bangi, Malaysia","2011 International Conference on User Science and Engineering (i-USEr )","13 Feb 2012","2011","","","183","188","In this paper, we describe the heuristic evaluation of PekAR-Mikroorganisma; a courseware for the deaf in learning science by using Augmented Technology. This study employs heuristic evaluation, which is one of the inspection methods. Heuristic evaluation was chosen because it does not involve the end user. Previous studies have shown that more problems can be identified using this kind of evaluation. Several experts from different fields were involved in this evaluation. Based on the evaluation made, several disadvantages of PekAR-Mikroorganisma have been identified. In addition, experts have provided some feedbacks to further improve the courseware.","","978-1-4577-1655-3","10.1109/iUSEr.2011.6150562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6150562","augmented reality;deaf;heuristic evaluation;usability;visual informatics","Courseware;Usability;Augmented reality;Handicapped aids;Visualization","augmented reality;courseware;handicapped aids;inspection;natural sciences computing","heuristic evaluation;augmented reality courseware;deaf;PekAR-Mikroorganisma;science learning;augmented technology;inspection methods","","10","","44","IEEE","13 Feb 2012","","","IEEE","IEEE Conferences"
"Augmented reality in the smart factory: Supporting workers in an industry 4.0. environment","V. Paelke","Hochschule Ostwestfalen-Lippe, InIT-Institute for Industrial IT, Lemgo, Germany","Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)","12 Jan 2015","2014","","","1","4","We present an augmented reality system that supports human workers in a rapidly changing production environment. By providing spatially registered information on the task directly in the user's field of view the system can guide the user through unfamiliar tasks (e.g. assembly of new products) and visualize information directly in the spatial context were it is relevant. In the first version we present the user with picking and assembly instructions in an assembly application. In this paper we present the initial experience with this system, which has already been used successfully by several hundred users who had no previous experience in the assembly task.","1946-0759","978-1-4799-4845-1","10.1109/ETFA.2014.7005252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7005252","Human Centred Design;User Experience;Smart Factory;Industry 4.0;Augmented Reality;Human Machine Interaction","Augmented reality;Visualization;Assembly;User interfaces;Production facilities;Industries","assembling;augmented reality;data visualisation;factory automation;production engineering computing","augmented reality;smart factory;industry 4.0. environment;information visualization;spatial context;picking instructions;assembly instructions;human workers;production environment","","142","1","14","IEEE","12 Jan 2015","","","IEEE","IEEE Conferences"
"An innovative augmented reality educational platform using Gamification to enhance lifelong learning and cultural education","C. A. Eleftheria; P. Charikleia; C. G. Iason; T. Athanasios; T. Dimitrios","Department of Computer Engineering and Informatics, University of Patras, Patras, Greece; Department of Computer Engineering and Informatics, University of Patras, Patras, Greece; Department of Computer Engineering and Informatics, University of Patras, Patras, Greece; Department of Computer Engineering and Informatics, University of Patras, Patras, Greece; Cultural Heritage Management and New Technologies Department, University of Western Greece, Agrinio, Greece","IISA 2013","10 Oct 2013","2013","","","1","5","This paper proves that Life-long learning and Cultural Education can be supported through the use of technological advances and techniques which so far were extensively used in Games and immersive applications. In order to promote learning, this research proposal focuses on Augmented Reality (AR) and on Gamification for the creation of an educational AR book. The suggested learning subject is Science aimed at children between the ages of 10-12 years old, although the platform can be easily applied also to Culture, Arts and History. In our project, users interact with a virtual laboratory and are able to perform experiments and complete challenges through gaming so as to expand and test their knowledge. Using AR and gamification techniques, the aim is to deliver a more comprehensive understanding of the subject matter while at the same time engage learners and increase their enjoyment during the learning process. By engaging learners in cultural subjects, the cultural heritage is delivered to next generations and remains alive.","","978-1-4799-0771-7","10.1109/IISA.2013.6623724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6623724","Augmented Reality;gamification;education;culture;e-learning;AR book;engagement","Games;Augmented reality;Cultural differences;Three-dimensional displays;Electronic learning;History","art;augmented reality;computer aided instruction;computer games;continuing professional development;cultural aspects;history","cultural subjects;cultural heritage;AR techniques;gamification techniques;virtual laboratory;history;arts;science learning;learning subject;educational AR book;immersive applications;cultural education;lifelong learning;innovative augmented reality educational platform","","38","","21","IEEE","10 Oct 2013","","","IEEE","IEEE Conferences"
"Sensor Fusion for Augmented Reality","J. D. Hol; T. B. Schon; F. Gustafsson; P. J. Slycke","Division of Automatic Control, Department of Electrical Engineering, Linköping University, Linkoping, Sweden; Division of Automatic Control, Department of Electrical Engineering, Linköping University, Linkoping, Sweden; Division of Automatic Control, Department of Electrical Engineering, Linköping University, Linkoping, Sweden; Xsens Technologies B.V., Enschede, Netherlands","2006 9th International Conference on Information Fusion","12 Feb 2007","2006","","","1","6","In augmented reality (AR), the position and orientation of the camera have to be estimated with high accuracy and low latency. This nonlinear estimation problem is studied in the present paper. The proposed solution makes use of measurements from inertial sensors and computer vision. These measurements are fused using a Kalman filtering framework, incorporating a rather detailed model for the dynamics of the camera. Experiments show that the resulting filter provides good estimates of the camera motion, even during fast movements","","1-4244-0953-5","10.1109/ICIF.2006.301604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4085890","Sensor fusion;Kalman Filter;Augmented Reality;Computer Vision;Inertial Navigation","Sensor fusion;Augmented reality;Cameras;Computer vision;Magnetic sensors;Acoustic sensors;Layout;Delay;Application software;TV","augmented reality;computer vision;Kalman filters;motion estimation;sensor fusion","sensor fusion;augmented reality;AR;camera;position estimation;orientation estimation;nonlinear estimation problem;computer vision;Kalman filtering;motion estimation","","37","10","19","","12 Feb 2007","","","IEEE","IEEE Conferences"
"A Spatial Augmented Reality system for intuitive display of robotic data","F. Leutert; C. Herrmann; K. Schilling","Chair of Robotics and Telematics, Julius-Maximilians-Universität, Wurzburg, Germany; Chair of Robotics and Telematics, Julius-Maximilians-Universität, Wurzburg, Germany; Chair of Robotics and Telematics, Julius-Maximilians-Universität, Wurzburg, Germany","2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","21 Mar 2013","2013","","","179","180","In the emerging field of close human-robot-collaboration the human worker needs to be able to quickly and easily understand data of the robotic system. To achieve this even for untrained personnel, we propose the use of a Spatial Augmented Reality system to project the necessary information directly into the users' workspace. The projection system consists of a fixed as well as a mobile projector mounted directly on the manipulator, allowing for visualizing data anywhere in the surroundings of the robot. By enabling the user to simply see the necessary complex information he can better understand the data and behavior of the robotic assistant and has the opportunity to analyze and potentially optimize the working process. Together with an input device, arbitrary interfaces can be realized with the projection system.","2167-2148","978-1-4673-3101-2","10.1109/HRI.2013.6483560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483560","Augmented Reality;manipulators;robotic interfaces;human-robot-interaction","Robot kinematics;Augmented reality;Manipulators;Data visualization;Personnel;Monitoring","augmented reality;human-robot interaction;manipulators","spatial augmented reality system;intuitive display;robotic data;human-robot-collaboration;mobile projector;manipulator;data visualization;complex information;robotic assistant","","36","1","5","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Hands in Space: Gesture Interaction with Augmented-Reality Interfaces","M. Billinghurst; T. Piumsomboon; H. Bai",University of Canterbury; University of Canterbury; University of Canterbury,"IEEE Computer Graphics and Applications","5 Mar 2014","2014","34","1","77","80","Researchers at the Human Interface Technology Laboratory New Zealand (HIT Lab NZ) are investigating free-hand gestures for natural interaction with augmented-reality interfaces. They've applied the results to systems for desktop computers and mobile devices.","1558-1756","","10.1109/MCG.2014.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6756716","gesture-based interfaces;augmented reality;computer graphics;HIT Lab NZ;free-hand gestures;mobile computing","Three-dimensional displays;Augmented reality;Gesture recognition;Mobile handsets;Sensors;Mobile communication","augmented reality;gesture recognition;microcomputers;mobile computing","gesture interaction;augmented-reality interfaces;Human Interface Technology Laboratory;New Zealand;free-hand gestures;natural interaction;desktop computers;mobile devices","Animals;Computer Graphics;Computers, Handheld;Gestures;Hand;Humans;Mobile Applications;Models, Theoretical;Phobic Disorders;Spiders;User-Computer Interface","36","3","7","IEEE","5 Mar 2014","","","IEEE","IEEE Magazines"
"Computer Assisted Music Therapy: A Case Study of an Augmented Reality Musical System for Children with Cerebral Palsy Rehabilitation","A. G. D. Correa; I. K. Ficheman; M. do Nascimento; R. de Deus Lopes","Laboratório de Sistemas Integráveis da Escola Politécnica da Universidade de São Paulo, São Paulo, SP, Brasil; Laboratório de Sistemas Integráveis da Escola Politécnica da Universidade de São Paulo, São Paulo, SP, Brasil; NA; Lab. de Sist. Integraveis, Univ. de Sao Paulo, Sao Paulo, Brazil","2009 Ninth IEEE International Conference on Advanced Learning Technologies","7 Aug 2009","2009","","","218","220","This article presents an experiment conducted with an augmented reality musical system for music therapy. In this system, colored cards with graphic symbols replace the music keyboard. Unlike the keyboard, composed of unchangeable and fixed keys, in this system the therapist can print cards of different sizes and place them in various ways, according to the desired motor exercise. Each card represents a different musical note in the timbre of a given musical instrument. A colored virtual cube is attached to each card. A music therapist initially evaluated the system and later an experiment was conducted with a child with cerebral palsy. Results showed the potential of this software in the rehabilitation process.","2161-377X","978-0-7695-3711-5","10.1109/ICALT.2009.111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5194207","Augmented Reality;Musical Games;Music Therapy","Medical treatment;Augmented reality;Birth disorders;Music;Instruments;Keyboards;Application software;Muscles;Graphics;Timbre","augmented reality;brain;medical computing;medical disorders;music;musical instruments;neurophysiology;paediatrics;patient rehabilitation","computer-assisted music therapy;augmented reality musical system;children cerebral palsy rehabilitation;colored virtual cube card;graphic symbol;musical keyboard;motor exercise;musical instrument","","35","","8","IEEE","7 Aug 2009","","","IEEE","IEEE Conferences"
"Augmented Reality Interfaces","M. Singh; M. P. Singh",Independent Consultant; North Carolina State University,"IEEE Internet Computing","12 Dec 2013","2013","17","6","66","70","Technological advances, exploding amounts of information, and user receptiveness are fueling augmented reality's (AR) rapid expansion from a novelty concept to potentially the default interface paradigm in coming years. This article briefly describes AR in terms of its application in natural Web interfaces. The authors discuss key concepts involved in AR, and the technical and social challenges that remain.","1941-0131","","10.1109/MIC.2013.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682933","augmented reality;mobile applications;mobile computing;user experience;user interfaces;usability","Augmented reality;Mobile communication;User interfaces;Mobile computing;Usability","augmented reality;Internet;user interfaces","augmented reality interface;AR;default interface paradigm;natural Web interfaces","","32","5","","IEEE","12 Dec 2013","","","IEEE","IEEE Magazines"
"Application of Augmented Reality in Engineering Graphics Education","Heen Chen; Kaiping Feng; Chunliu Mo; Siyuan Cheng; Zhongning Guo; Yizhu Huang","Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China","2011 IEEE International Symposium on IT in Medicine and Education","16 Jan 2012","2011","2","","362","365","Engineering graphics (EG) is the subject of transferring information from design into manufacture. Developing ability to create and read graphical representation of engineering structure is essential for individual. Therefore, training engineers able to use the graphical language to communicate is vital in every engineering college. However, in the classroom, where lecture time is limited, it is hard for the instructors to illustrate clearly the relationship between the 3D geometry and their 2D projection using only one kind of presenting technique. This work gives a brief insight into the potential and challenges of using Augmented Reality (AR) in Engineering Graphics Education. An AR-based system specifically designed for EG instruction were studied and developed. The system aims at improving the spatial awareness and interest of learning. Our own interest is to apply the AR system to Engineering Graphics instruction and provide the students with their own unique discovery path. The AR application enables faster comprehension of complex spatial problems and relationships which will benefit the students greatly during their learning processes. The AR-based method is proved to be effective teaching aids for engineering graphics courses and applying AR technology to support learning activities may become a trend in the future.","","978-1-61284-704-7","10.1109/ITiME.2011.6132125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6132125","Engineering Graphics Education;Augmented reality;Computer vision;Teaching reform","Three dimensional displays;Education;Solid modeling;Cameras;Computational modeling;Augmented reality","augmented reality;computational geometry;computer science education;engineering education;engineering graphics;solid modelling;teaching","augmented reality;engineering graphics education;information transfer;graphical representation;engineering structure;graphical language;engineering college;3D geometry;2D projection;AR-based system;engineering graphics instruction;teaching aids","","29","","9","IEEE","16 Jan 2012","","","IEEE","IEEE Conferences"
"Augmented Reality: No Longer a Novelty?","S. J. Vaughan-Nichols","Freelance technology, Mills River, North Carolina","Computer","15 Dec 2009","2009","42","12","19","22","For years, augmented reality has been touted as an important technology of the future but has been used primarily in high-end and novelty settings. Now, though, that appears to be changing.","1558-0814","","10.1109/MC.2009.380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5353455","Keywords: Augmented reality;Location-based services;Games;Mobile technology;API specification","Augmented reality","augmented reality","augmented reality","","29","2","","IEEE","15 Dec 2009","","","IEEE","IEEE Magazines"
"View management of annotations for wearable augmented reality","K. Makita; M. Kanbara; N. Yokoya","Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan","2009 IEEE International Conference on Multimedia and Expo","18 Aug 2009","2009","","","982","985","In annotation overlay applications using augmented reality (AR), view management is widely used for improving readability and intelligibility of the annotations. In order to recognize the visible portions of objects in the user's view, the positions, orientations, and shapes of the objects should be known in the case of conventional view management methods. However, it is difficult for a wearable AR system to obtain the positions, orientations and shapes of objects because the target object is usually moving or non-rigid. In this paper, we propose a view management method to overlay annotations of moving or non-rigid objects for networked wearable AR. The proposed method obtains positions and shapes of target objects via a network in order to estimate the visible portions of the target objects in the user's view. Annotations are located by minimizing penalties related to the overlap of an annotation, occlusion of target objects, length of a line between the annotation and the target object, and distance of the annotation in sequential frames. Through experiments, we have proven that the prototype system can correctly provide each user with annotations on multiple users of wearable AR systems.","1945-788X","978-1-4244-4290-4","10.1109/ICME.2009.5202661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5202661","Augmented reality;Wearable computer;Annotation;View management","Augmented reality;Shape;Wearable computers;Technology management;System testing;Prototypes;Application software;Object oriented databases;Layout;Indoor environments","augmented reality;computer vision;wearable computers","wearable augmented reality;view management;target object;overlay annotation;occlusion;sequential frames","","25","","8","IEEE","18 Aug 2009","","","IEEE","IEEE Conferences"
"Augmented Reality and Holograms for the Visualization of Mechanical Engineering Parts","M. J. G. Figueiredo; P. J. S. Cardoso; C. D. F. Gonçalves; J. M. F. Rodrigues","ISE, CIMA, CIAC, University of Algarve, Faro, Portugal; ISE, LARSyS, University of Algarve, Faro, Portugal; ISE, University of Algarve, Faro, Portugal; ISE, LARSyS, University of Algarve, Faro, Portugal","2014 18th International Conference on Information Visualisation","22 Sep 2014","2014","","","368","373","There is an increasing number of students using tablets in schools. Mobile devices gained popularity as an educational tool and there are many schools that use them frequently in educational activities to improve learning. We found that first year students of mechanical engineering in general have difficulties in understanding 3D shapes from 2D views. There are many Augmented Reality (AR) applications available that can be used to create educational contents for these mobile devices. On the other hand, there is an increasing interest in making holograms. In this paper we studied the most popular AR systems and show examples of using an AR system for the visualization of 3D models. We also present the creation of a low cost prototype, the EducHolo, that enables the visualization of holograms supported by tablets. With this prototype students can visualize the hologram of mechanical parts, providing a better perception of the model 3D shape and improving the ability of making the 2D orthographic views and perspectives that they study in the first year of mechanical engineer.","2375-0138","978-1-4799-4103-2","10.1109/IV.2014.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6902933","Visualization;Augmented Reality;Holograms;3D models;m-learning","Three-dimensional displays;Augmented reality;Solid modeling;Visualization;Mobile handsets;Shape;Biological system modeling","augmented reality;computer aided instruction;data visualisation;engineering education;holography;mechanical engineering computing;mobile computing","augmented reality;holograms;mechanical engineering part visualization;tablets;schools;mobile devices;educational tool;educational activities;learning improvement;3D shapes;2D views;educational contents;3D model visualization;EducHolo;hologram visualization;model 3D shape;2D orthographic views","","25","","9","IEEE","22 Sep 2014","","","IEEE","IEEE Conferences"
"Augmented reality to improve STEM motivation","T. Restivo; F. Chouzal; J. Rodrigues; P. Menezes; J. B. Lopes","Universidade do Porto, Porto, Porto, PT; IDMEC-FEUP, Universidade do Porto Porto, Portugal; IDMEC-FEUP, Universidade do Porto Porto, Portugal; Instituto de Sistemas e Robótica Universidade de Coimbra Coimbra, Portugal; CIDTFF — Research Centre “Didactics and Technology in Education of Trainers”, de Trás-os-Montes e Alto-Douro Vila Real, Portugal","2014 IEEE Global Engineering Education Conference (EDUCON)","5 Jun 2014","2014","","","803","806","This paper presents an exploratory study about educational potentialities of an augmented reality (AR) application developed for DC circuit fundamentals. Particularly the study aims to characterize student involvement using the application as well as its use as an additional experimental tool and to characterize how students perceive their experience and their learning through the use of this AR application. It is also briefly described how this application was developed and how the exploratory study was implemented involving STEM students. The AR application confirmed to be manageable and students have explored its configurations intuitively. Additionally, the AR tool usability according to our preliminary results showed to be effective for the AR developed application purposes, has induced student satisfaction and revealed very good student perceptions about learning perspectives. So, this study showed this AR application for DC circuits has a great educational potential.","2165-9567","978-1-4799-3191-0","10.1109/EDUCON.2014.6826187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6826187","augmented reality;STEM learning;electrical circuit","Augmented reality;Cultural differences;Engineering education;Conferences;Electric potential;Training","augmented reality;computer aided instruction;electrical engineering computing","augmented reality;STEM motivation;DC circuit fundamentals;student involvement characterization;STEM students;AR tool usability;student satisfaction;student perceptions;learning perspectives","","23","","9","IEEE","5 Jun 2014","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality edutainment applications for cultural institutions","T. Chatzidimitris; E. Kavakli; M. Economou; D. Gavalas","Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece; Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece; Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece; Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece","IISA 2013","10 Oct 2013","2013","","","1","4","The paper focuses on current practice regarding the application of mobile Augmented Reality (AR) technologies for enabling learning in the context of cultural heritage. It also presents ARmuseum, an application developed for the Museum of Industrial Olive Oil Production in Lesvos (MBEL). Finally, it discusses a number of issues related to the evaluation of mobile AR applications for cultural institutions.","","978-1-4799-0771-7","10.1109/IISA.2013.6623726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6623726","mobile Augmented Reality;edutainment;cultural heritage","Mobile communication;Cultural differences;Games;Augmented reality;Mobile handsets;Production;Cameras","augmented reality;computer aided instruction;computer games;entertainment;history;mobile computing;museums;vegetable oils","mobile augmented reality edutainment applications;cultural institutions;cultural heritage;ARmuseum;Museum of Industrial Olive Oil Production;Lesvos;MBEL;mobile AR game applications","","23","","16","IEEE","10 Oct 2013","","","IEEE","IEEE Conferences"
"Learning Words Using Augmented Reality","C. M. Juan; E. Llop; F. Abad; J. Lluch","Instituto Universitario de Automática e Informática Industrial, Universidad Politécnica de Valencia, Valencia; Instituto Universitario de Automática e Informática Industrial, Universidad Politécnica de Valencia, Valencia; Instituto Universitario de Automática e Informática Industrial, Universidad Politécnica de Valencia, Valencia; Instituto Universitario de Automática e Informática Industrial, Universidad Politécnica de Valencia, Valencia","2010 10th IEEE International Conference on Advanced Learning Technologies","16 Sep 2010","2010","","","422","426","This paper presents an Augmented Reality (AR) game for learning words. Thirty-two children played the AR game and the equivalent real game. We have compared the results of the two games. The results indicate that children did not found significant differences between the two games except for one question, but 81% of the children liked most the AR game.","2161-377X","978-1-4244-7145-4","10.1109/ICALT.2010.123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572407","Augmented Reality;learning words;edutainment","Games;Pediatrics;Positron emission tomography;Augmented reality;Robots;Conferences;Cameras","augmented reality;computer aided instruction","learning word;augmented reality game;AR game","","20","","8","IEEE","16 Sep 2010","","","IEEE","IEEE Conferences"
"Tangible Cubes Used as the User Interface in an Augmented Reality Game for Edutainment","C. M. Juan; G. Toffetti; F. Abad; J. Cano","Instituto Universitario de Automática e Informática Industrial, Universidad Politécnica de Valencia, Valencia; Instituto Universitario de Automática e Informática Industrial, Universidad Politécnica de Valencia, Valencia; Instituto Universitario de Automática e Informática Industrial, Universidad Politécnica de Valencia, Valencia; Escola d'Estiu, Universidad Politécnica de Valencia, Valencia, Spain","2010 10th IEEE International Conference on Advanced Learning Technologies","16 Sep 2010","2010","","","599","603","In this paper, we present an Augmented Reality (AR) game for finding and learning about endangered animals in a fun way. It uses tangible cubes as the user interface. This game was included in the activity program of the Summer School of the Universidad Politecnica de Valencia. Forty-six children played the AR game and the equivalent real game. We have compared the results of the two games. The results indicate that children enjoyed playing the AR game more than playing the real game and that they perceived the AR game to be more fun than the real game. They also preferred the AR game to the real one. The children perceived the real game as being easier to play than the AR game. The children also seemed to learn about the subject of endangered animals.","2161-377X","978-1-4244-7145-4","10.1109/ICALT.2010.170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572569","Augmented Reality;tangible interface;edutainment","Games;Pediatrics;Animals;Videos;Augmented reality;Educational institutions;XML","augmented reality;computer aided instruction;computer games;entertainment;user interfaces","tangible cubes;user interface;augmented reality game;edutainment;endangered animals;Universidad Politecnica de Valencia","","19","","8","IEEE","16 Sep 2010","","","IEEE","IEEE Conferences"
"Making Augmented Reality Practical on Mobile Phones, Part 2","D. Wagner; D. Schmalstieg","Graz University of Technology, Austria; Graz University of Technology, Austria","IEEE Computer Graphics and Applications","21 Jul 2009","2009","29","4","6","9","In part 1, we introduced a software environment for augmented reality (AR) on mobile phones, discussed development and debugging strategies, and showed how to execute several tasks of a common AR system in parallel on a mobile device. Here, we discuss how to overcome the most severe limitations, such as memory, rendering speed, and computational power. We analyze in detail where an optimized mobile phone AR application spends most of its processing time and give an outlook on what to expect in the next few years.","1558-1756","","10.1109/MCG.2009.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5167481","augmented reality;mobile phones;software development;embedded systems;computer graphics;fixed-point operations;floating-point operations;rendering","Augmented reality;Mobile handsets;Rendering (computer graphics);Bandwidth;Pipelines;Cameras;Application software;Image coding;Computer vision;Image converters","augmented reality;mobile computing;rendering (computer graphics);storage management","augmented reality;mobile phones;mobile device;memory limitation;rendering speed;computational power","Cell Phone;Computer Graphics;Computer Simulation;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Theoretical;User-Computer Interface","16","1","1","IEEE","21 Jul 2009","","","IEEE","IEEE Magazines"
"Design of an assistant system for industrial maintenance tasks and implementation of a prototype using augmented reality","R. Schlagowski; L. Merkel; C. Meitinger","Faculty of Electrical Engineering, University of Applied Sciences, Augsburg, Germany; Faculty of Electrical Engineering, University of Applied Sciences, Augsburg, Germany; Faculty of Electrical Engineering, University of Applied Sciences, Augsburg, Germany","2017 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)","12 Feb 2018","2017","","","294","298","As the complexity of work tasks rises for maintenance workers in modern production facilities, new technologies will be required to support and integrate the service worker of tomorrow. This paper gives an insight into an ongoing research project examining the potential of smart glasses used as a component of assistant systems for workers performing maintenance tasks in an industry 4.0 context. A human centered design process is used to identify the needs of workers and to specify requirements for the assistant system being developed. Thereby, the maintenance of a CNC lathe is used as an example and assistant functions were developed for one specific maintenance task. The architecture of the assistant system proposed in this paper is based on an analysis of the work system including the tasks of the maintenance worker. Finally, the implementation of a first prototype, using state-of-the-art augmented reality smart glasses, is described.","2157-362X","978-1-5386-0948-4","10.1109/IEEM.2017.8289899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8289899","Assistant System;Maintenance;Augmented Reality;Smart Glasses","Maintenance engineering;Task analysis;Prototypes;Augmented reality;Production facilities;Smart glasses;Standards","augmented reality;computerised numerical control;graphical user interfaces;lathes;maintenance engineering;production engineering computing;production facilities;prototypes","industrial maintenance tasks;modern production facilities;human centered design process;augmented reality;assistant systems;CNC lathe;prototype;smart glasses;state-of-the-art;graphical user interfaces","","15","","8","IEEE","12 Feb 2018","","","IEEE","IEEE Conferences"
"The Design of Cloud-Based 4G/LTE for Mobile Augmented Reality with Smart Mobile Devices","B. -S. P. Lin; W. -H. Tsai; C. C. Wu; P. H. Hsu; J. Y. Huang; T. -H. Liu","Department of Computer Science, Intelligent Information & Communications Research Center, National Chiao Tung University, Taiwan; Department of Computer Science, Intelligent Information & Communications Research Center, National Chiao Tung University, Taiwan; Department of Computer Science, Intelligent Information & Communications Research Center, National Chiao Tung University, Taiwan; Department of Computer Science, Intelligent Information & Communications Research Center, National Chiao Tung University, Taiwan; Department of Computer Science, Intelligent Information & Communications Research Center, National Chiao Tung University, Taiwan; Department of Computer Science, Intelligent Information & Communications Research Center, National Chiao Tung University, Taiwan","2013 IEEE Seventh International Symposium on Service-Oriented System Engineering","10 Jun 2013","2013","","","561","566","The system characteristics of 4G and beyond 4G broadband mobile system (BMS) are high data rate (throughput), low latency (delay), high mobility (speed), and high capacity. The current recognized 4G BMS needs to meet the requirements specified by IMT-Advanced of ITU-T. Those BMSs include 3GPP-LTE/LTE-Advanced and IEEE 802.16e/m (WiMAX 1/WiMAX 2). In the meantime, the smart device (smart phone and tablet) with powerful CPU/GPU, HD digital camera, digital compass, GPS, and various sensors are becoming rapidly popular. In addition, the architecture and capability of cloud computing are getting adopted in various applications and services, a cloud-based 4G/LTE is one example of telecommunications services. With the combination of more deployments of cloud-based BMSs and increasing usages of smart mobile devices, there are many potential appealing applications and services with real-time and/or interactive features can be created. In this article, we explore the technology and applications of mobile augmented reality (MAR) on the cloud-based 4G BMS (TD-LTE) and smart devices environment. The developed smart device-based MAR system (SD-MAR) with the 4G/TD-LTE experimental network test bed is located at MIRC/BML in the campus of National Chiao Tung University. This test bed consists of several brandy dongles/tablets/smartphones (as UE), two NSN TD-LTE base stations (as eNodeB), one core network (as EPC), and cloud-based servers and data center. To study the technology and applications on SD-MAR system, we have integrated research teams/people specialized in the areas of cloud computing, smart device technology, 4G broadband mobile system, computer vision and image processing, gesture recognition, computer graphics and rendering, and system integration. The applications discussed in the article include real-time accurate navigation/tourism for indoor and outdoor, collaborative urban design, and multiuser interactive motion learning system in the mobile environment.","","978-0-7695-4944-6","10.1109/SOSE.2013.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525575","Cloud Computing;Smart Mobile Device;4G/LTE;Mobile Augmented Reality","Mobile communication;Computer architecture;Navigation;Mobile computing;Collaboration;Augmented reality;Mobile handsets","4G mobile communication;augmented reality;broadband networks;cloud computing;computer centres;Long Term Evolution;mobile computing;smart phones;WiMax","cloud-based 4G-LTE design;smart mobile devices;4G broadband mobile system;IMT-Advanced;ITU-T;3GPP-LTE-LTE-Advanced;IEEE 802.16;WiMAX-1;cloud computing;telecommunications services;interactive features;mobile augmented reality;cloud-based 4G BMS;TD-LTE;smart device-based MAR system;SD-MAR;4G-TD-LTE experimental network testbed;MIRC-BML;National Chiao Tung University. campus;brandy dongles;UE;NSN TD-LTE base stations;eNodeB;core network;EPC;cloud-based servers;data center;computer vision;image processing;gesture recognition;computer graphics;rendering;system integration;indoor tourism;outdoor tourism;collaborative urban design;multiuser interactive motion learning system;WiMAX-2;tablets;smart phones;indoor navigation;outdoor navigation","","15","1","17","IEEE","10 Jun 2013","","","IEEE","IEEE Conferences"
"Augmented Reality in Education 4.0","J. Martin; J. Bohuslava; H. Igor","Faculty of Materials Science and Technology in Trnava, Slovak University of Technology in Bratislava, Trnava, Slovakia; Faculty of Materials Science and Technology in Trnava, Slovak University of Technology in Bratislava, Trnava, Slovakia; Faculty of Materials Science and Technology in Trnava, Slovak University of Technology in Bratislava, Trnava, Slovakia","2018 IEEE 13th International Scientific and Technical Conference on Computer Sciences and Information Technologies (CSIT)","8 Nov 2018","2018","1","","231","236","Global progress in the industrial field, which has led to the definition of the Industry 4.0 concept, also affects other spheres of life. One of them is the education. The subject of the article is to summarize the emerging trends in education in relation to the requirements of Industry 4.0 and present possibilities of their use. One option is using augmented reality as part of a modular learning system. The main idea is to combine the elements of the CPS technology concept with modern IT features, with emphasis on simplicity of solution and hardware ease. The synthesis of these principles can combine in a single image on a conventional device a realistic view at the technological equipment, complemented with interactive virtual model of the equipment, the technical data and real-time process information.","","978-1-5386-6464-3","10.1109/STC-CSIT.2018.8526676","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8526676","augmented reality;Industry 4.0;learning system;Education 4.0","Education;Learning systems;Servers;Industries;Automation;Augmented reality;Production facilities","augmented reality;computer aided instruction;cyber-physical systems;production engineering computing","augmented reality;modular learning system;education 4.0;Industry 4.0;CPS technology","","14","","16","IEEE","8 Nov 2018","","","IEEE","IEEE Conferences"
"Augmented reality in e-commerce with markerless tracking","X. Li; D. Chen","School of Automation Engineering, University of Electronic Science and Technology, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology, Chengdu, China","2010 2nd IEEE International Conference on Information Management and Engineering","3 Jun 2010","2010","","","609","613","Current E-commerce technologies cannot provide enough individual information to buyers. Augmented Reality (AR) technology might improve the performance of E-commerce by overlaying virtual information of products on the real world. But usual tracking technology based on markers is impeding the application of AR technology in business. This paper proposes an approach to feature point correspondence of image sequence based on transient chaotic neural networks. Through this approach a new markerless visual tracking technology with image feature can be used in AR E-commerce applications. Feature point based neural network image matching method has attracted considerable attention in recent years. Rotation and scale invariant features are extracted from images firstly, and then transient chaotic neural network is used to perform global feature matching and perform the initialization phase of the tracking. Experimental results demonstrate the efficiency and the effectiveness of the proposed method.","","978-1-4244-5263-7","10.1109/ICIME.2010.5478308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5478308","augmented reality;E-commerce;neural network;feature matching","Augmented reality;Neural networks;Chaos;Automation;Feature extraction;Layout;Consumer electronics;Internet;Industrial training;Electronic commerce","augmented reality;electronic commerce;feature extraction;image matching;image sequences;neural nets;tracking","augmented reality;e-commerce;markerless tracking;virtual information;feature point correspondence;image sequence;transient chaotic neural networks;image feature;neural network image matching;scale invariant features;global feature matching","","13","","11","IEEE","3 Jun 2010","","","IEEE","IEEE Conferences"
"Square AR: Using Augmented Reality for Urban Planning","K. Anagnostou; P. Vlamos","Department of Informatics, Ionian University, Corfu, Greece; Department of Informatics, Ionian University, Corfu, Greece","2011 Third International Conference on Games and Virtual Worlds for Serious Applications","28 Jul 2011","2011","","","128","131","In this paper we describe the design and implementation of SquareAR, an Augmented Reality authoring application which enables virtual restoration of public, unexploited, spaces in cities. The aim of this application is to involve the local residents into the decision making process that affects their everyday life in an intuitive and user friendly manner. We also evaluate the application and discuss potential extensions and applications in different contexts.","","978-1-4577-0316-4","10.1109/VS-GAMES.2011.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5962095","augmented reality;urban planning;authoring tool","Cameras;Augmented reality;Solid modeling;Materials;Three dimensional displays;Robustness;Visualization","augmented reality;decision making;town and country planning","augmented reality;urban planning;SquareAR;public virtual restoration;decision making process","","13","","14","IEEE","28 Jul 2011","","","IEEE","IEEE Conferences"
"Indoor localization and navigation using smartphones augmented reality and inertial tracking","B. A. Delail; L. Weruaga; M. J. Zemerly; J. W. P. Ng","Electrical and Computer Engineering Department, Khalifa University of Science, Technology and Research, United Arab Emirates; Electrical and Computer Engineering Department, Khalifa University of Science, Technology and Research, United Arab Emirates; Electrical and Computer Engineering Department, Khalifa University of Science, Technology and Research, United Arab Emirates; BT Innovate & Design, Etisalat BT Innovation Center, Abu Dhabi, UAE","2013 IEEE 20th International Conference on Electronics, Circuits, and Systems (ICECS)","15 May 2014","2013","","","929","932","Over the last years, indoor localization and navigation is becoming a hot topic. With the increasing number of buildings, indoor positioning and navigation has turned out to be more important than outdoors. In the literature, many papers discuss wireless based indoor positioning systems. Essentially based on Wireless Fidelity (Wi-Fi), Bluetooth, Radio Frequency Identification (RFID) or existing solutions that imply the measurement of radio signals. In this paper, we evaluate an indoor image-based positioning system that takes advantage of smartphones augmented reality (AR) and inertial tracking. The excellent computing capabilities in todays highend phones or smartphones in combination with its resources of sensors, such as Global Positioning System (GPS), inertial sensors, camera, wireless receivers, are powering the mobile application sector to the extent of becoming the fastest growing one in data communication technologies. AR as an emerging technology has the potential of creating new types of indoor location based services for the near future. Here, we show some of the AR capabilities combined with inertial tracking for localization and navigation.","","978-1-4799-2452-3","10.1109/ICECS.2013.6815564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815564","Indoor Localization;Augmented Reality;Iner-tial Tracking;Indoor Navigation","Augmented reality;Smart phones;Mobile communication;Visualization;Navigation;Sensors;Three-dimensional displays","augmented reality;data communication;indoor radio;inertial navigation;object tracking;smart phones","wireless based indoor positioning systems;radio signal measurement;data communication technology;mobile application;indoor navigation;sensors resources;AR;indoor image-based positioning system;RFID;radio frequency identification;Bluetooth;Wi-Fi;wireless fidelity;inertial tracking;smartphones augmented reality","","13","","22","IEEE","15 May 2014","","","IEEE","IEEE Conferences"
"Implementation of Augmented Reality into the Training and Educational Process in Order to Support Spatial Perception in Technical Documentation","J. Kaščak; M. Telišková; J. Török; P. Baron; J. Zajac; J. Husár","Faculty of manufacturing technologies with a seat in Prešov, Technical University of Košice, Slovakia; Faculty of manufacturing technologies with a seat in Prešov, Technical University of Košice, Slovakia; Faculty of manufacturing technologies with a seat in Prešov, Technical University of Košice, Slovakia; Faculty of manufacturing technologies with a seat in Prešov, Technical University of Košice, Slovakia; Faculty of manufacturing technologies with a seat in Prešov, Technical University of Košice, Slovakia; Faculty of manufacturing technologies with a seat in Prešov, Technical University of Košice, Slovakia","2019 IEEE 6th International Conference on Industrial Engineering and Applications (ICIEA)","16 May 2019","2019","","","583","587","At present, while the development of technology used to display, create, and manipulate 3D models is already very advanced, we are still confronted with situations where it is necessary to use technical documentation. Whatever the production or educational process, this part of the documentation will still be necessary. With this fact, we are increasingly forced to think about how it would facilitate the process of reading and learning with this kind of media. Due to the often inadequate technical level of the interested persons, we come in this article with a way of possible implementation of the augmented reality into the technical documentation, to facilitate its reading and to improve the spatial perception of the included objects.","","978-1-7281-0851-3","10.1109/IEA.2019.8715120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715120","augmented reality;technical documentation;learning process;vuforia studio;spatial perception","Augmented reality;Documentation;Training;Manufacturing;Three-dimensional displays;Standards","augmented reality;computer aided instruction","spatial perception;technical documentation;educational process;augmented reality","","13","","9","IEEE","16 May 2019","","","IEEE","IEEE Conferences"
"Exploring the Use of Augmented Reality to Support Science Education in Secondary Schools","M. Davidsson; D. Johansson; K. Lindwall","School of Computer Science, Physics and Mathematics, Linnaeus University, Vaxjo, Sweden; School of Computer Science, Physics and Mathematics, Linnaeus University, Vaxjo, Sweden; School of Computer Science, Physics and Mathematics, Linnaeus University, Vaxjo, Sweden","2012 IEEE Seventh International Conference on Wireless, Mobile and Ubiquitous Technology in Education","19 Apr 2012","2012","","","218","220","During the last 2 years we have conducted several trials exploring how augmented reality and mobile technologies can be used to support learning and teaching in science education. In particular, we present the on-going efforts that are part of the EU funded project Science Center To Go. We provide an overview of the different activities, the lessons learned and what we propose as ways to forward making the technology, mobile, affordable and in the long term -- ubiquitous available.","","978-1-4673-0884-7","10.1109/WMUTE.2012.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185032","Augmented Reality;mobile learning;inquiry-based learning","Educational institutions;Augmented reality;Mobile communication;Data visualization;Collaboration;Conferences","augmented reality;computer aided instruction;mobile computing;natural sciences computing","augmented reality;science education;secondary schools;mobile technologies;Science Center To Go project;ubiquitous computing","","12","","14","IEEE","19 Apr 2012","","","IEEE","IEEE Conferences"
"Development of image processing based methods using augmented reality in higher education","O. Yaman; M. Karakose","Computer Engineering Department Firat University, Elazig, Turkey; Computer Engineering Department Firat University, Elazig, Turkey","2016 15th International Conference on Information Technology Based Higher Education and Training (ITHET)","1 Dec 2016","2016","","","1","5","Today, computer-based training is developing rapidly. The visual education is also quite commonly used in higher education as well as in primary and secondary education. The tablets, smart boards and computers constitute the basis of visual education. Visual education has many advantages, such as learning faster, memorability and in terms of paper expenses. The visual animations and presentations have become a very important material in higher education in recent years along with the development of computer technologies. The image processing has been proposed to improve instructiveness in higher education courses in the fields of Medicine, Engineering and Science. In the field of medicine, the image processing methods can be used to show the diseased regions in an easier way in many images such as CT and MR images [5]. In the fields of engineering, image processing can be used to improve images in visual courses in the fields such as Geology, Civil Mining engineering. In addition, it can be easily preferred and applied in the departments such as Chemistry, Biology and Geography in the field of Science. The unclarity of images used in courses leads to ambiguity. In this study, image processing based approaches have been developed to ensure more effective learning of the courses in higher education. Image processing is a technology which is used in many places in daily life. The image processing methods have become widespread along with the acceleration of computer technologies. Today, image processing is used in many environments such as education, health, defense industry and industrial areas. Successful results are obtained application areas such as fault diagnosis and condition monitoring using image processing methods. Today, the augmented reality which is commonly used in the field of education can further increase its contribution to the field of education by associating with image processing methods.","","978-1-5090-0778-3","10.1109/ITHET.2016.7760723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7760723","augmented reality;image processing;higher education","Augmented reality;Education;Image edge detection;Image segmentation;Visualization;Classification algorithms","augmented reality;computer based training;further education;image processing;mobile computing;smart phones","image processing;augmented reality;higher education;computer-based training;visual education;tablet;smart board","","12","","20","IEEE","1 Dec 2016","","","IEEE","IEEE Conferences"
"Augmented reality for people with disabilities","V. Hrytsyk; A. Grondzal; A. Bilenkyj","Ternopil's I. Pul'j National Technical University, Ternopil, UKRAINE; Ternopil's I. Pul'j National Technical University, Ternopil, UKRAINE; Ternopil's I. Pul'j National Technical University, Ternopil, UKRAINE","2015 Xth International Scientific and Technical Conference "Computer Sciences and Information Technologies" (CSIT)","12 Nov 2015","2015","","","188","191","Development of intellectual information technology augmented reality for persons with disabilities, including converting visual images into sound and vice versa by generating a single concept. Use of the unified knowledge base for operating mechanism, that stores images concepts.","","978-6-1760-7815-9","10.1109/STC-CSIT.2015.7325462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325462","augmented reality;a common knowledge base for concepts generated by the video and audio images;neural network;artificial intelligence;digital processing","Computational modeling;Biological neural networks;Entropy;Augmented reality;Visualization;Computers;Robots","audio signal processing;augmented reality;handicapped aids;video signal processing","augmented reality;disabled people;intellectual information technology development;visual images;unified knowledge base;operating mechanism;image concepts;audio images","","12","","19","","12 Nov 2015","","","IEEE","IEEE Conferences"
"A location-based Augmented Reality system for the spatial interaction with historical datasets","D. Pacheco; S. Wierenga; P. Omedas; L. S. Oliva; S. Wilbricht; S. Billib; H. Knoch; P. F. M. J. Verschure","Laboratory of Synthetic, Universitat Pompeu Fabra, Barcelona, Spain; Laboratory of Synthetic, Universitat Pompeu Fabra, Barcelona, Spain; Laboratory of Synthetic, Universitat Pompeu Fabra, Barcelona, Spain; Laboratory of Synthetic, Universitat Pompeu Fabra, Barcelona, Spain; Bergen-Belsen Memorial, Lower Saxony Memorial Foundation; Bergen-Belsen Memorial, Lower Saxony Memorial Foundation; Bergen-Belsen Memorial, Lower Saxony Memorial Foundation; Historical Institute, University of Cologne","2015 Digital Heritage","25 Feb 2016","2015","1","","393","396","The key role that space and spatial organization of content play in memory has been taken very little into account in the design of human-data interaction systems. Here, we present a location based Augmented Reality application for the exploration and visualization of historical files, which is based on the argument that the embodied interaction with content by moving in the real, physical space will enhance its recollection from memory and comprehension. Our software architecture integrates a historical 3D reconstruction with geo referenced historical documents, as well as specific guidance components for narrative generation. All content of the application database is spatialized and can be navigated in a completely free/exploratory mode or in a passive/guided mode. We present the results of an experiment comparing spatial memory performance in the two modes. Our data confirms previous findings in the spatial navigation literature, suggesting that active exploration of an environment leads to a better spatial understanding of it.","","978-1-5090-0048-7","10.1109/DigitalHeritage.2015.7413911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7413911","Augmented Reality;Spatial Navigation;Memory","Navigation;Trajectory;Image reconstruction;Augmented reality;Three-dimensional displays;Spatial databases","augmented reality;data visualisation;history;image reconstruction;software architecture","location-based augmented reality system;historical datasets spatial interaction;human-data interaction systems;historical files visualization;historical files exploration;software architecture;historical 3D reconstruction;geo referenced historical documents;guidance components;narrative generation;spatial memory performance","","12","","16","IEEE","25 Feb 2016","","","IEEE","IEEE Conferences"
"Low-Cost Augmented Reality Systems via 3D Point Cloud Sensors","A. P. Placitelli; L. Gallo","Institute of High Performance Computing and Networking, ICAR, National Research Council of Italy (CNR), Napoli, Italy; Institute of High Performance Computing and Networking, ICAR, National Research Council of Italy (CNR), Napoli, Italy","2011 Seventh International Conference on Signal Image Technology & Internet-Based Systems","2 Jan 2012","2011","","","188","192","In this paper, we explore the use of widely available and low-priced 3D point cloud sensors, such as the Microsoft XBox Kinect and Asus Xtion PRO LIVE, in the application of computer-generated imagery in live-video streams in Augmented Reality (AR) systems. Specifically, we examine the typical pipeline of AR applications and explore the potential simplifications derived from the use of such devices during the calibration and registration steps, which are the most computationally expensive and time consuming. Moreover, we describe how to approach the problem of face alignment, that is the aligning of a previously captured model of a face to newly captured data, by using 3D point cloud data and open-source libraries.","","978-1-4673-0431-3","10.1109/SITIS.2011.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120648","augmented reality;kinect;markerless 3D registration","Sensors;Three dimensional displays;Face;Augmented reality;Pipelines;Libraries;Cameras","augmented reality;calibration;image registration;public domain software;solid modelling;video streaming","augmented reality;3D point cloud sensors;computer-generated imagery;live video streams;face alignment;calibration;image registration;open source libraries","","11","1","19","IEEE","2 Jan 2012","","","IEEE","IEEE Conferences"
"Multimodal interaction in augmented reality","Z. Chen; J. Li; Y. Hua; R. Shen; A. Basu","Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; VIPS hop US, San Jose, CA, USA; Department of Computing Science, University of Alberta, Edmonton, Canada","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","30 Nov 2017","2017","","","206","209","With the boost of computing power in mobile devices and availability of cloud APIs in recent years, mobile augmented reality (AR) applications have become increasingly embedded in people's everyday life. However, effective and intuitive interaction between virtual and real worlds in these AR applications is still an open question. In this paper, we make one step towards an answer by exploring the possibility of incorporating two input modalities, gesture and speech, for enhancing user experience in AR applications.","","978-1-5386-1645-1","10.1109/SMC.2017.8122603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8122603","Augmented Reality;Human-Computer Interaction","Speech;Dogs;Mars;Speech recognition;Cameras;Augmented reality","application program interfaces;augmented reality;mobile computing","cloud API;mobile augmented reality applications;mobile devices;multimodal interaction;open question;AR applications;real worlds;virtual worlds;intuitive interaction","","11","","6","IEEE","30 Nov 2017","","","IEEE","IEEE Conferences"
"Development of an Online Home Appliance Control System Using Augmented Reality and an SSVEP-Based Brain-Computer Interface","S. Park; H. -S. Cha; J. Kwon; H. Kim; C. -H. Im","Department of Biomedical Engineering, Hanyang University, Seoul, Republic of Korea; Department of Biomedical Engineering, Hanyang University, Seoul, Republic of Korea; Department of Biomedical Engineering, Hanyang University, Seoul, Republic of Korea; Department of Biomedical Engineering, Hanyang University, Seoul, Republic of Korea; Department of Biomedical Engineering, Hanyang University, Seoul, Republic of Korea","2020 8th International Winter Conference on Brain-Computer Interface (BCI)","9 Apr 2020","2020","","","1","2","In this study, we implemented a new home appliance control system by combining a steady-state visual evoked potential (SSVEP)-based brain-computer interface (BCI), augmented reality (AR), and internet of things (IoT) technologies. The visual stimuli were presented on a see-through head-mounted display (HMD), while the recorded brain activity was analyzed to classify the control command, and the home appliances were controlled through IoT. The average classification accuracy of the SSVEP-BCI-based control system was 92.8%, with an information transfer rate (ITR) of 37.4 bits/min. The proposed system exhibited an excellent performance, surpassing the best results reported in previous studies regarding external device control based on BCI using an HMD as rendering device.","2572-7672","978-1-7281-4707-9","10.1109/BCI48061.2020.9061633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9061633","augmented reality;brain-computer interface;electroencephalography;internet of things;steady-state visual evoked potential","Home appliances;Visualization;Internet of Things;Augmented reality;Brain-computer interfaces;Switches","augmented reality;brain-computer interfaces;electroencephalography;helmet mounted displays;medical signal processing;visual evoked potentials","home appliances;IoT technologies;SSVEP-BCI-based control system;external device control;online home appliance control system;augmented reality;SSVEP-based brain-computer interface;internet of things technologies;visual stimuli;brain activity;steady-state visual evoked potential;head-mounted display;information transfer rate","","11","","5","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Mobile indoor navigation system in iOS platform using augmented reality","I. A. Cankaya; A. Koyun; T. Yigit; A. S. Yuksel","Department of Computer Engineering Suleyman, Demirel University, Isparta, Turkey; Department of Computer Engineering Suleyman, Demirel University, Isparta, Turkey; Department of Computer Engineering Suleyman, Demirel University, Isparta, Turkey; Department of Computer Engineering Suleyman, Demirel University, Isparta, Turkey","2015 9th International Conference on Application of Information and Communication Technologies (AICT)","30 Nov 2015","2015","","","281","284","Usage areas of mobile phones have increased in the last 10 years. Although there have been improvements in many areas, most of the developments are in the field of positioning systems. Although the people's lives continue in indoor environments, location-based information system receives data from the satellites, which can detect a person's location in outdoor areas. In indoor areas, satellite signals can cause false information or can be interrupted by the objects in the area. In this study, an indoor navigation system has been designed and developed that only uses the accelerometer, the camera and the compass components on the phone and does not require satellite signals for positioning. To provide independence from the map in this application, augmented reality is applied during the routing process by utilizing built-in camera of the phone and no map is used.","","978-1-4673-6856-8","10.1109/ICAICT.2015.7338563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7338563","Indoor navigation;augmented reality;step detection","Augmented reality;Accelerometers;Routing;Cameras;Indoor navigation;Mobile handsets","accelerometers;augmented reality;cameras;indoor environment;indoor navigation;iOS (operating system);mobile computing;smart phones","mobile indoor navigation system;iOS platform;augmented reality;mobile phones;positioning system;indoor environment;location-based information system;person location;indoor area;accelerometer;compass component;routing process;phone built-in camera","","11","","12","IEEE","30 Nov 2015","","","IEEE","IEEE Conferences"
"Mobile tourism application using augmented reality","R. Safitri; D. S. Yusra; D. Hermawan; E. Ripmiatin; W. Pradani","Department of Informatics Engineering, University of Al Azhar Indonesia, Jakarta, Indonesia; Department of Informatics Engineering, University of Al Azhar Indonesia, Jakarta, Indonesia; Department of Informatics Engineering, University of Al Azhar Indonesia, Jakarta, Indonesia; Department of Informatics Engineering, University of Al Azhar Indonesia, Jakarta, Indonesia; Department of Informatics Engineering, University of Al Azhar Indonesia, Jakarta, Indonesia","2017 5th International Conference on Cyber and IT Service Management (CITSM)","30 Oct 2017","2017","","","1","6","Indonesia as an archipelagic country that has diverse cultures and beautiful natures. This is some factor towing the arrival of tourists to visit Indonesia. Today many tourists from abroad and even from within their own country do not know the beauty of natures and cultures in Indonesia. Therefore, this research have been done to build an android application called “Exploresia” to provide information about tourism in Indonesia using Augmented Reality technology. This research begins with collecting data of tourism and cultures in 34 provinces in Indonesia. These data was processed into text, 2D image, 3D objects and video and displayed virtually through a mobile application. Users can interact with this mobile application by selecting province, sights and explore the object with 360 virtual tours. As a trigger for displaying virtual data, made a map of Indonesia as a marker and also coordinates to display the virtual data. Exploresia has been tested to 50 respondents from different segmentation to see how much influence of this app to attract tourist come to Indonesia. 93.6% of respondents agree that Exploresia provides a new way to get information on tourism in Indonesia and 96% of respondents agree that this mobile app help to promote tourism destinations in Indonesia so that tourists be interested in coming to Indonesia. The use of AR in mobile apps is expected to provide added value so that user can receive the message delivered and keen to visit Indonesia.","","978-1-5386-2739-6","10.1109/CITSM.2017.8089305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8089305","tourism;mobile application;Augmented Reality;promotion media;360 virtual tours","Three-dimensional displays;Augmented reality;Mobile applications;Media;Androids;Humanoid robots;Smart phones","augmented reality;mobile computing;travel industry","mobile tourism application;Indonesia;archipelagic country;augmented reality;Android application;Exploresia;2D image;3D objects;AR;virtual data","","10","","7","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Augmented Reality and Storytelling in heritage application in public gardens: Caloust Gulbenkian Foundation Garden","F. Guimarães; M. Figueiredo; J. Rodrigues","ISE, Universidade-do Algarve, Portugal; ISE, Universidade-do Algarve, Portugal; ISE, Universidade do Algarve, Portugal","2015 Digital Heritage","25 Feb 2016","2015","1","","317","320","Gardens, given its location, history, fauna, flora and environmental scenography, are places that are part of a natural heritage with its own cultural identity. These places are object of preservation, study and dissemination, such as cultural heritage, but in this case with a collection of natural artifacts exhibition alive and dynamic that allows user's natural immersion in the exhibition space. To create a personal user interaction with this natural heritage space is important to capture the story and aesthetics, and find other ways to immerse the user in the space. To that end, this article combines Augmented Reality technologies and concepts of Transmedia Storytelling applied to Gardens as a framework of media-art digital artifact applied to Caloust Gulbenkian Foundation Garden in Lisbon / Portugal.","","978-1-5090-0048-7","10.1109/DigitalHeritage.2015.7413891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7413891","Cultural Heritage;Natural Heritage;Augmented Reality;Transmedia Storytelling;Digital Media-Art;Museology;Socio-Museology;Garden Design;Landscape","Cultural differences;Three-dimensional displays;Augmented reality;Context;History;Solid modeling;Streaming media","art;augmented reality;history","augmented reality;heritage application;public gardens;Caloust Gulbenkian Foundation Garden;history;fauna;flora;environmental scenography;cultural identity;preservation;cultural heritage;natural artifacts exhibition;user natural immersion;exhibition space;personal user interaction;natural heritage space;transmedia storytelling;media-art digital artifact","","10","","23","IEEE","25 Feb 2016","","","IEEE","IEEE Conferences"
"Accuracy analysis of an augmented reality system","A. Belhaoua; A. Kornmann; J. -P. Radoux","ALTRAN Research Medic@(Medical Image Computerized @nalysis), Strasbourg, France; ALTRAN Research Medic@(Medical Image Computerized @nalysis), Strasbourg, France; ALTRAN Research Medic@(Medical Image Computerized @nalysis), Strasbourg, France","2014 12th International Conference on Signal Processing (ICSP)","22 Jan 2015","2014","","","1169","1174","Work described in this contribution focuses on error analysis in augmented reality (AR) systems. The tracking, the process of locating an object (e.g. fiducial marker) in an environment, is critical to the accuracy of AR applications as more realistic results can be obtained in the presence of accurate AR registration. This deals with 2D error estimations of the edge detection process, the starting step of the whole tracking procedure enabling to determine the outline of the imaged marker. Using fitting techniques to describe the geometric features composing the outline, errors bounds are determined and, as a result of this step, edge detection errors are estimated. These 2D errors are then propagated up to the final tracking step.","2164-523X","978-1-4799-2186-7","10.1109/ICOSP.2014.7015184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7015184","augmented reality;marker tracking;error propagation;edge detection;fitting techniques","Cameras;Image edge detection;Augmented reality;Fitting;Three-dimensional displays;Estimation;Error analysis","augmented reality;computational geometry;edge detection;image registration;object tracking","accuracy analysis;error analysis;augmented reality systems;AR applications;2D error estimations;edge detection process;AR registration;tracking procedure;fitting techniques;imaged marker;geometric features;edge detection errors","","9","","17","IEEE","22 Jan 2015","","","IEEE","IEEE Conferences"
"Augmented Reality, Virtual Learning Environment and Mobile Learning in education: A comparison","L. B. Kiat; M. B. Ali; N. D. Abd Halim; H. B. Ibrahim","Department of Educational Sciences, Mathematics and Creative Multimedia, Faculty of Education, Universiti Teknologi Malaysia, Johor, Malaysia; Department of Educational Sciences, Mathematics and Creative Multimedia, Faculty of Education, Universiti Teknologi Malaysia, Johor, Malaysia; Department of Educational Sciences, Mathematics and Creative Multimedia, Faculty of Education, Universiti Teknologi Malaysia, Skudai, Johor, MY; Department of Educational Sciences Mathematics and Creative Multimedia, Faculty of Education, Universiti Teknologi Malaysia, Johor, Malaysia","2016 IEEE Conference on e-Learning, e-Management and e-Services (IC3e)","14 Aug 2017","2016","","","23","28","This paper discusses the trends of technology in education and comparison between three types of technology: Augmented Reality (AR), Virtual Learning Environment (VLE) and Mobile Learning (ML). This paper aims to encourage educators and learners to incorporate the technologies in the teaching and learning process. The integration of these technologies in the teaching and learning process is able to provide new learning environment and improve the teaching and learning quality. The learning process becomes enjoyable and interesting with technologies. Although technology has a lot of benefit to the education field, educators must be creative and innovative to implement technology in the teaching and learning process. Therefore, educators and learners need to select the appropriate technology according to the lesson taught.","","978-1-4673-9060-6","10.1109/IC3e.2016.8009034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8009034","augmented reality;virtual learning environment;mobile learning;education","Education;Mobile communication;Augmented reality;Mobile handsets;Three-dimensional displays;Multimedia communication;Collaboration","augmented reality;education;mobile learning;teaching","augmented reality;virtual learning environment;mobile learning;education;learning process;teaching process","","9","","49","IEEE","14 Aug 2017","","","IEEE","IEEE Conferences"
"Co Design of Augmented Reality Game-Based Learning Games with Teachers Using Co-CreaARGBL Method","H. Tobar-Muñoz; S. Baldiris; R. Fabregat","BCDS, Universitat de Girona, Girona, Catalonia, Spain; BCDS, Universitat de Girona, Girona, Catalonia, Spain; BCDS, Universitat de Girona, Girona, Catalonia, Spain","2016 IEEE 16th International Conference on Advanced Learning Technologies (ICALT)","1 Dec 2016","2016","","","120","122","Recent studies argue that Augmented Reality Game-Based Learning (ARGBL) benefit learning and teaching processes. However, creating and leveraging ARGBL experiences is not easy for teachers, since they lack the expertise and time to design and construct them. Using Co Design strategies that combine the expertise of different actors in the creation can solve this. In this paper, we introduce Co-CreARGBL method as a strategy for co designing ARGBL learning experiences involving teachers and designers as well. The method proposes a set of stages, activities and considerations. We also describe an ongoing field experience held with teachers implementing the proposed method with promising results.","2161-377X","978-1-4673-9041-5","10.1109/ICALT.2016.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7756938","Game-Based Learning;Augmented Reality;Co-Design;Participatory Design;Design-Based Research","Games;Augmented reality;Training;Prototypes;Technological innovation;Guidelines","augmented reality;computer aided instruction;computer games;teaching","augmented reality game-based learning games;ARGBL learning experiences;Co-CreaARGBL method;teaching;codesign strategies","","9","","17","IEEE","1 Dec 2016","","","IEEE","IEEE Conferences"
"Augmented reality applied in tourism mobile applications","C. de la Nube Aguirre Brito","Faculty of Technology, University of Portsmouth, Portsmouth, United Kingdom","2015 Second International Conference on eDemocracy & eGovernment (ICEDEG)","1 Jun 2015","2015","","","120","125","Augmented reality (AR) has been used in the last years as a tool for enhancing collaboration between the real world and virtual environments. One of these fields where AR has been used is the touristic sector. The aim of this project is to identify the benefits of the use of AR in tourism mobile application through the development and evaluation of an AR tourist mobile application. The results of the implementation of this project show AR enhance tourist on-site experience in an innovative way in the real life. Moreover, AR could be applied in different industries as a method of improving the quality of service.","","978-3-9075-8913-7","10.1109/ICEDEG.2015.7114484","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7114484","Augmented Reality;mobile applications;cloud computing;cultural tourism","Mobile communication;Augmented reality;Cities and towns;Cultural differences;Androids;Humanoid robots;Usability","augmented reality;mobile computing;quality of service;travel industry","augmented reality;tourism mobile applications;virtual environments;touristic sector;AR tourist mobile application;quality of service","","9","","9","","1 Jun 2015","","","IEEE","IEEE Conferences"
"Virtual Tactical Map with Tangible Augmented Reality Interface","K. Jung; S. Lee; S. Jeong; B. -U. Choi","Department of Electronics and Computer Engineering, Hanyang University, Seoul, South Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, South Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, South Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, South Korea","2008 International Conference on Computer Science and Software Engineering","22 Dec 2008","2008","2","","1170","1173","We propose a new augmented reality (AR)-based approach for training using virtual sand table representations of military battlefields. A virtual tactical map (VTM) can archive simple actions such as moving a marker by hand, to provide more organic realizations in virtual military training. The new tangible AR interface provides a content-authoring tool that is natural, intuitive, and user-friendly. AR-interfaced VTMs exhibit multiple possibilities for military learning and training applications.","","978-0-7695-3336-0","10.1109/CSSE.2008.1305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4722261","Tangible Augmented Reality;Tangible Interface;Militery Training","Augmented reality;Military computing;Application software;Decision making;Computer science;Software engineering;Computer interfaces;Layout;Game theory;Aircraft","augmented reality;authoring systems;computer based training;human computer interaction;military computing;user interfaces","virtual tactical map;tangible augmented reality interface;virtual sand table representation;military battlefield training;content-authoring tool;user-friendliness;military learning","","9","1","7","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"Designing usability evaluation methodology framework of Augmented Reality basic reading courseware (AR BACA SindD) for Down Syndrome learner","R. Ramli; H. B. Zaman","Fakulti Sains dan Teknologi Maklumat, Kolej Universiti Islam Antarabangsa Selangor Persiaranl, Kajang, Selangor, Malaysia; Fakulti Sains dan Teknologi Maklumat, Kolej Universiti Islam Antarabangsa Selangor Persiaranl, Kajang, Selangor, Malaysia","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","19 Sep 2011","2011","","","1","5","Previous studies have found out that educational applications using the Augmented Reality (AR) technology have provided immersion, motivation, fun and high level of engagement. However, designing and developing of the AR courseware with these characteristics while ensuring the effectiveness in teaching and learning process can be quite challenging. The increasingly use of AR has called for the creation of more usable products of high quality, which in turn, makes the Usability Evaluation testing an essential process. Previous researchers stressed that until very recently, where the Usability Evaluation of AR interfaces had not been systematically examined. Furthermore, nowadays usability is a fundamental factor to consider when developing educational courseware. Therefore, a good design for the usability evaluation methodology is needed which is best suited for Down Syndrome (DS) learners in early reading. This paper describes the review of usability evaluation in learning courseware and presenting the usability evaluation that has been successfully applied to previous AR applications. Next, we will present several existing usability evaluation methods as a guideline in conducting the usability evaluation for AR BACA SindD. Lastly, this paper proposed a Design of Usability Evaluation Methodology Framework for AR BACA SindD, especially for the DS children in this case study. Hopefully, the methods that were used for the evaluation as well as the suitable usability evaluation methodology proposed, can be deployed to evaluate the effectiveness of the courseware to disabled children as general and primarily to the DS children.","2155-6830","978-1-4577-0752-0","10.1109/ICEEI.2011.6021807","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021807","Augmented Reality;Usability Evaluation;Basic Reading;Down Syndrome","Usability;Courseware;Testing;Augmented reality;Inspection;Interviews","augmented reality;courseware;handicapped aids","designing usability evaluation methodology framework;augmented reality basic reading courseware AR BACA SindD for down syndrome learner;usability evaluation testing;educational courseware;AR courseware;learning process;teaching process","","9","","26","IEEE","19 Sep 2011","","","IEEE","IEEE Conferences"
"Intelli-mirror: An augmented reality based IoT system for clothing and accessory display","N. Lobo","Department of Electronics Engineering, Vivekanand Education Society's Institute of Technology, Mumbai, India","2016 International Conference on Internet of Things and Applications (IOTA)","8 Sep 2016","2016","","","95","100","The paper presents an Augmented Reality (AR) based implementation of an interactive system termed “Intelli-Mirror”. The Intelli-Mirror uses Image Processing techniques to detect a user and then displays a garment image on the person. The Intelli-Mirror provides the user with the ability to switch between the selections available in an entire inventory of clothing. This negates the need of continuously having to physically change clothing every time a customer wishes to try on a new garment. This effectively reduces the time to shop to just the decision-making time. The implementation thus provides relief from many of the problems associated with physically changing clothing. The Intelli-Mirror is also an Internet of Things (IoT) device implemented on a Raspberry Pi capable of updating itself to the newest inventory. It can also provide data for user analytics to aid in clothing design and marketing.","","978-1-5090-0044-9","10.1109/IOTA.2016.7562702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562702","Augmented Reality;Internet of Things;Computer Vision;Image Processing;Raspberry Pi;User Analytics","Clothing;Servers;Cameras;Internet of things;Image color analysis;Switches;Augmented reality","augmented reality;clothing;image processing;interactive systems;Internet of Things;retail data processing","IoT system;clothing display;accessory display;augmented reality;interactive system;intelli-mirror;image processing techniques;user detection;garment image;clothing inventory;time-to-shop;decision-making time;Internet of Things;IoT device;Raspberry Pi;user analytics;clothing design;marketing","","9","1","11","IEEE","8 Sep 2016","","","IEEE","IEEE Conferences"
"A medical training system using augmented reality","R. Umeda; M. A. Seif; H. Higa; Y. Kuniyoshi","Faculy of Engineering, University of the Ryukyus, Okinawa, Japan; Faculy of Engineering, University of the Ryukyus, Okinawa, Japan; Faculy of Engineering, University of the Ryukyus, Okinawa, Japan; Graduate School of Medicine, University of the Ryukyus, Okinawa, Japan","2017 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)","5 Feb 2018","2017","","","146","149","This paper presents a medical training system using augmented reality, AR. Recognizing an AR marker through a Web camera, computer generated images appear on a real space. We prepared 3D (three-dimensional) anatomical objects to show, and evaluated our system using AR platform. From the experimental result, we found that our system could overlay the digital information on the operator's surrounding real world appropriately.","2189-8723","978-1-5090-6664-3","10.1109/ICIIBMS.2017.8279706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279706","AR (Augmented Reality);medical training system;Unity;Leap Motion controller","Three-dimensional displays;Training;Medical diagnostic imaging;Biological systems;Augmented reality;Bars","augmented reality;cameras;medical image processing","AR marker;3D anatomical objects;three-dimensional anatomical objects;digital information;computer generated images;Web camera;augmented reality;medical training system","","8","","11","IEEE","5 Feb 2018","","","IEEE","IEEE Conferences"
"Poster: 3D referencing for remote task assistance in augmented reality","O. Oda; M. Sukan; S. Feiner; B. Tversky","Columbia University, USA; Columbia University, USA; Columbia University, USA; Columbia University, USA","2013 IEEE Symposium on 3D User Interfaces (3DUI)","5 Sep 2013","2013","","","179","180","We present a 3D referencing technique tailored for remote maintenance tasks in augmented reality. The goal is to improve the accuracy and efficiency with which a remote expert can point out a real physical object at a local site to a technician at that site. In a typical referencing task, the remote expert instructs the local technician to navigate to a location from which a target object can be viewed, and then to attend to that object. The expert and technician both wear head-tracked, stereo, see-through, head-worn displays, and the expert's hands are tracked by a set of depth cameras. The remote expert first selects one of a set of prerecorded viewpoints of the local site, and a representation of that viewpoint is presented to the technician to help them navigate to the correct position and orientation. The expert then uses hand gestures to indicate the target.","","978-1-4673-6098-2","10.1109/3DUI.2013.6550237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6550237","Collaborative mixed/augmented reality;referencing technique;remote task assistance;maintenance and repair","Three-dimensional displays;Cameras;Augmented reality;Indexes;Thumb;Maintenance engineering","augmented reality;gesture recognition;helmet mounted displays","3D referencing technique;remote task assistance;augmented reality;remote maintenance task;head-tracked display;stereo display;see-through display;head-worn display;depth camera;viewpoint representation;hand gesture","","8","1","12","IEEE","5 Sep 2013","","","IEEE","IEEE Conferences"
"Design of virtual platoon control system using augmented reality to assist welfare vehicle users","R. Kimura; N. Matsunaga; H. Okajima; G. Kotaki","Graduate School of Science and Technology, Kumamoto University, Kumamoto, Japan; Graduate School of Science and Technology, Kumamoto University, Kumamoto, Japan; Graduate School of Science and Technology, Kumamoto University, Kumamoto, Japan; Graduate School of Science and Technology, Kumamoto University, Kumamoto, Japan","2017 17th International Conference on Control, Automation and Systems (ICCAS)","14 Dec 2017","2017","","","330","335","Recently, welfare vehicles are widely used among the elderly and the aged. However, it is not easy for inexperienced aged to control the welfare vehicle in narrow places such as elevators and narrow corridors. In this paper, driving assistance system for the welfare vehicle which is maneuverable by Augmented Reality (AR) is proposed. In addition, the proposed control system is assessed by trial runs. In the system, the cognitive ability from the objective view point is enhanced by AR. First, the virtual platoon control is outlined with a virtual preceding vehicle and a real following vehicle. The driver rides on the following vehicle and controls using the virtual preceding vehicle on Head Mounted Display(HMD). The virtual preceding vehicle projected on a HMD steered virtually with an objective viewpoint, and the real vehicle is robust controlled so as to follow the virtual preceding vehicle. Finally, the experimental driving in narrow space using proposed assistance system with AR is evaluated by beginners and a expert user.","","978-89-93215-14-4","10.23919/ICCAS.2017.8204460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8204460","Augmented reality;Virtual platoon control;Welfare vehicle;Objective viewpoint;Head mounted display","Resists;Vehicles;Control systems;Aging;Robustness;Augmented reality;Three-dimensional displays","augmented reality;control engineering computing;driver information systems;geriatrics;handicapped aids;helmet mounted displays;road vehicles;robust control","virtual preceding vehicle;virtual platoon control system;augmented reality;welfare vehicle users;driving assistance system;cognitive ability;real following vehicle;head mounted display;HMD","","8","","8","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Using augment reality to increase capacity in QR code","D. Bunma; S. Vongpradhip","Department of Computer Engineering, Chulalongkorn University, Bangkok, Thailand; Department of Computer Engineering, Chulalongkorn University, Bangkok, Thailand","2014 Fourth International Conference on Digital Information and Communication Technology and its Applications (DICTAP)","29 May 2014","2014","","","440","443","A new innovation on augment reality and 2D barcode is proposed throughout the paper regarding implementing a QR Code with the capability in storing more data or information That is to say QR Code will be developed to have higher level of storage capacity. QR Code is used to replace the traditional AR Marker, so we propose a back propagation method to keep detecting the QRAR, and show the result of bit rates of object. We have developed this QR Code based on AR System and its performance is encouraging. Clearly, the increase of data storage in QR Code is achieved by using ARQR method.","","978-1-4799-3724-0","10.1109/DICTAP.2014.6821727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821727","QR Code;Augment Reality;Capacity","Memory;Media;Computers;Image restoration;Augmented reality;Error correction codes;Mobile handsets","augmented reality;backpropagation;bar codes;information storage","quick responded code;QR code;2D barcode;storage capacity;augment reality;AR marker;back propagation method;QRAR;bit rates;AR system;data storage;ARQR method","","8","2","8","IEEE","29 May 2014","","","IEEE","IEEE Conferences"
"The Usability of the Microsoft HoloLens for an Augmented Reality Game to Teach Elementary School Children","B. Munsinger; G. White; J. Quarles","Department of Computer Science, University of Texas at San Antonio, San Antonio, Texas, USA; Department of Computer Science, University of Texas at San Antonio, San Antonio, Texas, USA; Department of Computer Science, University of Texas at San Antonio, San Antonio, Texas, USA","2019 11th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)","14 Oct 2019","2019","","","1","4","Our objective in this research is to compare the usability of three distinct head gaze-based selection methods in an Augmented Reality (AR) hidden object game for children: voice recognition, gesture, and physical button (clicker). Prior work on AR applications in STEM education has focused on how it compares with non-AR methods rather than how children respond to different interaction modalities. We investigated the differences between voice, gesture, and clicker based interaction methods based on the metrics of input errors produced and elapsed time to complete the tutorial and game. We found significant differences in input errors between the voice and gesture conditions, and in elapsed tutorial time between the voice and clicker conditions. We hope to apply the results of our study to improve the interface for AR educational games aimed at children, which could pave the way for greater adoption of AR games in schools.","2474-0489","978-1-7281-4540-2","10.1109/VS-Games.2019.8864548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864548","Augmented reality;computer security;gesture recognition;speech recognition;computer science education","Games;Tutorials;Speech recognition;Computer security;Augmented reality;Usability","augmented reality;computer aided instruction;computer games;gaze tracking;gesture recognition;speech recognition;STEM;teaching","voice recognition;physical button;STEM education;nonAR methods;interaction modalities;clicker based interaction methods;tutorial game;gesture conditions;AR educational games;Microsoft HoloLens;elementary school children;augmented reality hidden object game;head gaze-based selection methods","","8","","9","IEEE","14 Oct 2019","","","IEEE","IEEE Conferences"
"Application of Augmented Reality technology to promote interactive learning","R. -C. Chang; Z. -S. Yu","Taiwan Police College, Taipei, Taiwan, R.O.C.; Department of Digital Media Design, Asia University, Taichung, Taiwan, R.O.C.","2017 International Conference on Applied System Innovation (ICASI)","24 Jul 2017","2017","","","1673","1674","In recent years, the learning tools based on AR (Augmented Reality) technology have been highly recommended to be applied in educational sites. Teachers display abstract scientific changes in specific images by applying AR technology. By way of applying AR inter-operation to enhance students' interests in learning as well as reduce their cognitive load. This study has applied AR technology to establish a virtual biological laboratory App to be provided for college freshmen to carry out biological experiments as a curriculum preview and experiencing. The content of Virtual biology laboratory App includes units such as virtual microscope, biological anatomy concept, cell division process, and frog's bones. Through the introduction of digital technology into the general biology curriculums are then emerged with AR technology so as to confer how AR technology affects students study effects and biological experimental knowledge recognition. The study has implemented an experiment in object to college freshmen and the experiment results indicate that the integration of AR technology with teaching has made students' attitude towards learning more positive. Through interactive operation and learning, students are better able to master knowledge of fundamental biological experiments. Through the process of the study, the researcher has found the importance that students study scientific knowledge with interactive technology. Consequently, the Institute has designed a virtual biology laboratory App to achieve the benefits of action learning, situational simulation and interactive experiencing.","","978-1-5090-4897-7","10.1109/ICASI.2017.7988257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988257","Augmented Reality;Biology Experimental Curriculum;Interactive learning","Biology;Microscopy;Education;Media;Augmented reality;Tools;Mobile handsets","augmented reality;biology computing;computer aided instruction;digital simulation","augmented reality technology;interactive learning;AR technology;educational sites;abstract scientific changes;AR interoperation;student interests;cognitive load reduction;virtual biological laboratory app;college freshmen;biological experiments;curriculum preview;digital technology;general biology curriculums;biological experimental knowledge recognition;student attitude;interactive operation;fundamental biological experiments;interactive technology;action learning;situational simulation;interactive experiencing","","8","","5","IEEE","24 Jul 2017","","","IEEE","IEEE Conferences"
"Healthcare System Focusing on Emotional Aspects Using Augmented Reality - Implementation of Breathing Control Application in Relaxation Service","S. Tivatansakul; M. Ohkura","Graduate School of Engineering, Shibaura Institute of Technology, Tokyo, Japan; Shibaura Institute of Technology, College of Engineering, Tokyo, Japan","2013 International Conference on Biometrics and Kansei Engineering","19 Sep 2013","2013","","","218","222","In recent years, several systems have been proposed to emphasize the support of physical aspects at the expense of emotional aspects. However, emotional health is as important as physical health and negative emotional health can lead to social or mental health problems. To cope with negative emotional health, we propose a new healthcare system that focuses on emotional aspects. Our healthcare system integrates augmented reality to display virtual objects in real environments and Kinect, which allows users to freely interact with them. We also employ biological sensors to measure and detect user emotions, and provide three services based on their expected emotions: relaxation, amusement and excitement services. This paper focuses on the implementation of a breathing control application in the relaxation service that applied deep breathing techniques of stress management to supports users when they experience stress and other negative emotions. This application displays a virtual music box to assist them perform deep breathing. Virtual objects and music can increase user relaxation and decrease stress.","","978-0-7695-5019-0","10.1109/ICBAKE.2013.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603505","emotion;healthcare;relaxation;augmented reality","Electrocardiography;Medical services;Stress;Augmented reality;Biosensors;Three-dimensional displays","augmented reality;emotion recognition;health care;music","healthcare system;emotional aspects;augmented reality;breathing control application;physical health;negative emotional health;Kinect;user emotion measurement;user emotion detection;amusement service;excitement service;relaxation service;deep breathing techniques;stress management;virtual music box;social health problem;mental health problem","","8","","12","IEEE","19 Sep 2013","","","IEEE","IEEE Conferences"
"Towards an efficient methodology for evaluation of quality of experience in Augmented Reality","J. Puig; A. Perkis; F. Lindseth; T. Ebrahimi","Centre for Quantifiable Quality of Service in Communication Systems (Q2S), Norwegian University of Science and Technology, Trondheim, Norway; Centre for Quantifiable Quality of Service in Communication Systems (Q2S), Norwegian University of Science and Technology, Trondheim, Norway; Centre for Quantifiable Quality of Service in Communication Systems (Q2S), Norwegian University of Science and Technology, Trondheim, Norway; EPFL, Trondheim, Norway","2012 Fourth International Workshop on Quality of Multimedia Experience","9 Aug 2012","2012","","","188","193","The goal of this paper is to survey existing quality assessment methodologies for Augmented Reality (AR) visualization and to introduce a methodology for subjective quality assessment. Methodologies to assess the quality of AR systems have existed since these technologies appeared. The existing methodologies typically take an approach from the fields they are used in, such as ergonomics, usability, psychophysics or ethnography. Each field utilizes different methods, looking at different aspects of AR quality such as physical limitations, tracking loss or jitter, perceptual issues or feedback issues, just to name a few. AR systems are complex experiences, involving a mix of user interaction, visual perception, audio, haptic or other types of multimodal interactions as well. This paper focuses on the quality assessment of AR visualization, with a special interest on applications for neuronavigation.","","978-1-4673-0726-0","10.1109/QoMEX.2012.6263864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6263864","Quality of Experience;Augmented Reality;Subjective Quality Assessment;Objective Measurement","Visualization;Quality assessment;Augmented reality;Ergonomics;Usability;Surgery;Human computer interaction","augmented reality;data visualisation;graphical user interfaces;neurophysiology","quality-of-experience;augmented reality visualization;quality assessment methodologies;AR systems;user interaction;visual perception;multimodal interactions;neuronavigation","","8","","18","IEEE","9 Aug 2012","","","IEEE","IEEE Conferences"
"Vison-based auxiliary navigation method using augmented reality for unmanned aerial vehicles","H. Wu; Z. Cai; Y. Wang","School of automation science and electrical engineering, Beihang University, Beijing, China; Institute of unmArmed aerial vehicles, Beihang University, Beijing, China; School of automation science and electrical engineering, Beihang University, Beijing, China","IEEE 10th International Conference on Industrial Informatics","13 Sep 2012","2012","","","520","525","A visual-based auxiliary navigation method using augmented reality is an immersive navigation interface with virtual navigation and decision-making information superimposed on the video of real environment. It can provide the operator with more information to behave proactively in order to forestall future problems, with less stress or effort, and to increase the successful rate of UAV missions. The components of the auxiliary navigation method using AR on UAVs are described in this paper. And a method of real-time displaying targets' position with virtual information based on computer vision registration is researched. The real-time information is obtained by the transformation between three coordinate systems. An experimental verification bases on ARToolkit platform that is able to identify multiple markers and display real-time virtual information of targets' distance and direction while generating auxiliary curves is also described.","2378-363X","978-1-4673-0311-8","10.1109/INDIN.2012.6300922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6300922","augmented reality;navigation;UAVs;computer vision-based registration;ARToolkit","Cameras;Navigation;Augmented reality;Real time systems;Streaming media;Computers;Educational institutions","augmented reality;autonomous aerial vehicles;control engineering computing;decision making;image registration;object detection;path planning;position control;robot vision;video signal processing","vison-based auxiliary navigation method;augmented reality;unmanned aerial vehicle;immersive navigation interface;virtual navigation;decision-making information;video;real environment;UAV mission;target position;computer vision registration;coordinate system;ARToolkit platform;real-time virtual information;target distance;auxiliary curve","","8","7","13","IEEE","13 Sep 2012","","","IEEE","IEEE Conferences"
"A Novel Individual Location Recommendation System Based on Mobile Augmented Reality","Z. Shi; H. Wang; W. Wei; X. Zheng; M. Zhao; J. Zhao","School of Computer Science and Engineering, Xi'an University of Technology, Xi'an, China; School of Computer Science and Engineering, Xi'an University of Technology, Xi'an, China; School of Computer Science and Engineering, Xi'an University of Technology, Xi'an, China; Department of Culture Heritage and Museology, Zhejiang University, Hangzhou, China; School of Computer Science and Engineering, Xi'an University of Technology, Xi'an, China; School of Computer Science and Engineering, Xi'an University of Technology, Xi'an, China","2015 International Conference on Identification, Information, and Knowledge in the Internet of Things (IIKI)","10 Mar 2016","2015","","","215","218","In this paper, a mobile augmented reality (AR) based system for individual location recommendation is proposed. The system consists of the modules of user location, marker detection, 3D display and location guide by combing AR with navigation technology. Experimental results demonstrate that the proposed system is both efficient and effective in helping people location their position, it also enhance users' senses experience by providing users with a more intuitive, three-dimensional, dynamic information display and sharing capabilities.","","978-1-4673-8637-1","10.1109/IIKI.2015.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7428357","Augmented reality;mobile location;individual recommendation","Global Positioning System;Mobile communication;Three-dimensional displays;Cameras;Augmented reality;User interfaces","augmented reality;feature extraction;mobile computing;recommender systems","individual location recommendation system;mobile augmented reality;AR;user location;marker detection;3D display;location guide;navigation technology","","7","","6","IEEE","10 Mar 2016","","","IEEE","IEEE Conferences"
"Performance Characterization on Mobile Phones for Collaborative Augmented Reality (CAR) Applications","V. F. Bauset; J. M. Orduna; P. Morillo","Dept. Informática, Universidad de Valencia, SPAIN; Dept. Informática, Universidad de Valencia, SPAIN; Dept. Informática, Universidad de Valencia, SPAIN","2011 IEEE/ACM 15th International Symposium on Distributed Simulation and Real Time Applications","20 Oct 2011","2011","","","52","53","Collaborative Augmented Reality (CAR) systems allow multiple users to share a real world environment including computer generated images in real time. Currently, the hardware features of most mobile phones not only provide excellent multimedia services, but it also includes wireless network capabilities that provides a natural platform for CAR systems. However, the wide variety of these hardware features can have important effects on the performance of the mobile CAR applications. This paper presents the experimental characterization of CAR applications for mobile phones in regard to well-known performance metrics in distributed systems. Characterization results show that the most time consuming stage in a CAR application is the marker detection stage. Moreover, the rendering stage is decoupled on some devices. This decoupling process allows avoiding low refresh rate, facilitating the collaborative work. These results can be used as the basis for an efficient design of CAR systems and applications.","1550-6525","978-1-4577-1643-0","10.1109/DS-RT.2011.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051803","Collaborative Augmented Reality;Mobile Phones;Performance Evaluation","Smart phones;Augmented reality;Rendering (computer graphics);Throughput;Operating systems;Cameras","augmented reality;groupware;mobile computing;mobile handsets;multimedia computing;object detection;performance evaluation;radio networks","mobile phone performance characterization;collaborative augmented reality system;computer-generated image sharing;multimedia services;wireless network capabilities;distributed systems;marker detection stage;rendering stage;collaborative work","","7","","10","IEEE","20 Oct 2011","","","IEEE","IEEE Conferences"
"Application and scope analysis of Augmented Reality in marketing using image processing technique","S. Rajappa; G. Raj","Amity University, Utter Pradesh, India; Amity University, Utter Pradesh, India","2016 6th International Conference - Cloud System and Big Data Engineering (Confluence)","9 Jul 2016","2016","","","435","440","The main aim of the research paper is to understand the concept and applications of Augmented Reality (AR). It involves understanding the process of creation of an AR image, the hardware and software requirements for the process of making such an image. The paper also focuses on the ways in which the technology is used by firms and advertisers to give customers a better user experience. AR is a growing field with a lot of scope in the future, the paper also gives an insight on what is in store for AR in the near future.","","978-1-4673-8203-8","10.1109/CONFLUENCE.2016.7508159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7508159","Augmented Reality;QR Code;Adaptive Thresholding;Internet of Things;Digital Image Processing","Augmented reality;Cameras;Sensors;Tracking;Computers;Engines;Hardware","augmented reality;image processing;marketing data processing","augmented reality;marketing;image processing technique;AR image","","7","","15","IEEE","9 Jul 2016","","","IEEE","IEEE Conferences"
"Design and implementation of augmented reality system collaborating with QR code","J. -t. Wang; C. -N. Shyi; T. . -W. Hou; C. P. Fong","Department of Engineering Science, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, Southern Taiwan University, Tainan, Taiwan; Department of Engineering Science, National Cheng Kung University, Tainan, Taiwan; Department of Engineering Science, National Cheng Kung University, Tainan, Taiwan","2010 International Computer Symposium (ICS2010)","10 Jan 2011","2010","","","414","418","This work replaces conventional marker of augmented reality (AR) with Quick Response (QR) code, in which we take the advantages of QR code, i.e. the capability of error correction and the capability of carrying an abundant of information, to reinforce the occlusion immunity of AR and broaden the scale of AR applications. Basically, we combined QR code and the idea of AR together, designed and implemented a prototype system named QRAR. Meanwhile, we adopted Kalman filter to solve complete and temporary marker occlusion which the error correction can not cope with, in QRAR to gain the robustness.","","978-1-4244-7640-4","10.1109/COMPSYM.2010.5685477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685477","augmented reality;QR code;occlusion immunity;Kalman filter;passport security;credit card security;AR SDK","Augmented reality;Kalman filters;Cameras;Prototypes;Decoding;Biomedical imaging;Noise","augmented reality;error correction codes;Kalman filters","augmented reality system;Quick Response code;error correction;occlusion immunity;Kalman filter;marker occlusion","","7","1","16","IEEE","10 Jan 2011","","","IEEE","IEEE Conferences"
"A Geographic Surface Browsing Tool Using Map-Based Augmented Reality","K. Asai; T. Kondo; H. Kobayashi; A. Mizuki","Graduate University of Advanced Studies (SOKENDAI), Japan; Graduate University of Advanced Studies (SOKENDAI), Japan; Graduate University of Advanced Studies (SOKENDAI), Japan; Transfer Orbit Corporation","2008 International Conference Visualisation","18 Jul 2008","2008","","","93","98","We have developed a browsing tool for visualizing information about geographic surfaces using map-based augmented reality (AR). Map-based AR technology enables virtual objects to be overlaid on an actual map, creating a tangible user interface. In map-based AR applications, a virtual lens pointer is often used for object selection. However, this type of interaction is difficult when there are many points of possible interest on the map. Moreover, although a printed map is good for a 2D overview, it does not give a 3D local view. Our browsing tool overcomes these problems by using three interaction techniques: 1) a pointer for reliable object selection, 2) a slider for variable position selection, and 3) a local view simulated from an egocentric viewpoint. It provides a map-based learning environment that contains geographically embedded information. We applied the browsing tool to learning on exploration in the Apollo 17 mission.","","978-0-7695-3271-4","10.1109/VIS.2008.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568678","Map-based Augmented Reality;Browsing Tool;Geographic Surface;Interaction Technique;Tangible User Interface","Augmented reality;Moon;User interfaces;Navigation;Geographic Information Systems;Displays;Data visualization;NASA;Lenses;Computer graphics","augmented reality;data visualisation;geographic information systems;information retrieval;user interfaces","geographic surface;browsing tool;map-based augmented reality;information visualization;virtual object;tangible user interface;virtual lens pointer;object selection;slider;position selection;map-based learning environment;interaction technique","","6","","22","IEEE","18 Jul 2008","","","IEEE","IEEE Conferences"
"Current limitations and opportunities in mobile augmented reality applications","N. I. A. M. Nazri; D. R. A. Rambli","Computer & Information Sciences, Univesiti Teknologi PETRONAS, Tronoh, Perak, Malaysia; Computer & Information Sciences, Univesiti Teknologi Petronas, Tronoh, Perak, Malaysia","2014 International Conference on Computer and Information Sciences (ICCOINS)","31 Jul 2014","2014","","","1","4","Mobile AR has evolved from the bulkiness of head-mounted device and backpack device to smart device (smartphone, tablet etc.). To date, the current implementation has made what AR is today. However, the advancement of AR technology has met with limitation and challenges on its own, which resulted in not able to reach mass-market. This paper in turn presents current limitations and challenges that need to overcome. We have done a review based on past research papers on limitation in technical (hardware, algorithms and interaction technique) and non-technical (social acceptance, privacy and usefulness) aspects of developing and implementing mobile augmented reality applications. We also presented some future opportunities in mobile AR applications.","","978-1-4799-4390-6","10.1109/ICCOINS.2014.6868425","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6868425","Mobile augmented reality;multimodal interaction;mobile interaction","Mobile communication;Augmented reality;Mobile handsets;Google;Hardware;Privacy;Industries","augmented reality;mobile computing","mobile augmented reality applications;head mounted device;backpack device;smart device;smartphone;tablet;mass market;mobile AR applications","","6","","23","IEEE","31 Jul 2014","","","IEEE","IEEE Conferences"
"Geo-location Based Augmented Reality Application For Cultural Heritage Using Drones","M. Unal; E. Bostanci; E. Sertalp; M. S. Guzel; N. Kanwal","Computer Engineering Department, Ankara University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey; Faculty of Communication, Hacettepe University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey; Lahore College for Women University, Lahore, Pakistan","2018 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)","9 Dec 2018","2018","","","1","4","Augmented Reality (AR) already is very interesting topic for cultural heritage since it can be very easy to reconstruct the ancient building on the site without any physical intervention. With the AR technology, 3D models of ancient buildings can be overimposed to remains of the site. In this way historical sites become more interesting and appealing places. In this study, we developed a geo-location based AR application for Roman Baths of Ankara which is placed in Turkey. Novel part of this study is using drones for video source which model of the bath will be overlaid to it.","","978-1-5386-4184-2","10.1109/ISMSIT.2018.8567073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567073","augmented reality;cultural heritage;drone","Drones;Global Positioning System;Augmented reality;Cultural differences;Three-dimensional displays;Cameras;Mobile handsets","augmented reality;history;location based services","geo-location based augmented reality application;cultural heritage;drones;ancient building;physical intervention;geo-location based AR application;historical sites;Turkey;video source;Roman Baths","","6","","10","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
"From 2D to 3D: Teaching terrain representation in engineering studies through Augmented reality: Comparative versus 3D pdf","A. Álvarez; F. Javier; B. Parra; E. Beatriz; M. Tubio; F. de Paula","Depto. Edificación y Obra Civil, I.E.S. Politécnico Jesús Marín, Málaga, Spain; Depto. Edificación y Obra Civil, I.E.S. Politécnico Jesús Marín, Málaga, Spain; Depto. de Expresión Gráfica, Universidad de Málaga, Málaga, Spain; Depto. de Expresión Gráfica, Universidad de Málaga, Málaga, Spain; Dept. de Ingeniería Gráfica y Geomática, Universidad de Córdoba, Córdoba, Spain; Dept. de Ingeniería Gráfica y Geomática, Universidad de Córdoba, Córdoba, Spain","2014 IEEE Frontiers in Education Conference (FIE) Proceedings","19 Feb 2015","2014","","","1","4","Engineering students have got great skills in the use of new technologies, but large deficiencies in terms of the ability to visualize three-dimensional models shown in two dimensions. Also, the spatial capabilities are critical to them, to achieve the further development and understanding of associated complex, linked contents and competencies. However, it is difficult to illustrate the relationship between the 3D geometry and 2D projection using only drawings on blackboard. A new way to show these concepts is needed. Since Augmented reality (AR) and 3D pdf are the low-cost technologies that could easily display the relationship between two-dimensional displayed representations and the object shown. This paper presents early results conducted through the education innovation project Pol+AR. This project aims to determine the 3D-2D connection, using models, based on AR and 3D pdf, improving the spatial visualisation ability in students, specifically in the study of surveying and its applications, knowledge of the contour lines, earthworks and profiles. Studies have been developed in VET, at CFGS Proyectos de Edificación, (Building projects), at IES Politécnico Jesús Marín of Málaga. Finally, the implementation of this research will be carried out at Universidad de Málaga, Escuela Politécnica Superior.","2377-634X","978-1-4799-3922-0","10.1109/FIE.2014.7044193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7044193","Surveying;augmented reality;spatial vision;graphic expression;ICT;contour lines;earthworks;profiles","Three-dimensional displays;Solid modeling;Augmented reality;Education;Computational modeling;Portable document format;Geometry","augmented reality;computer aided instruction;data structures;data visualisation;engineering education","terrain representation teaching;engineering studies;augmented reality;3D pdf;3D model visualization;3D geometry;2D projection;2D displayed representations;Pol+AR education innovation project;VET;CFGS Proyectos de Edificacion;building projects;IES Politécnico Jesus Marin of Malaga;Universidad de Malaga;Escuela Politecnica Superior","","6","","19","IEEE","19 Feb 2015","","","IEEE","IEEE Conferences"
"Anthropological Conversations: Augmented Reality Enhanced Artifacts to Foster Education in Cultural Anthropology","L. Simeone; S. Iaconesi","FakePress, University of Roma La Sapienza, Rome, Italy; FakePress, University of Roma La Sapienza, Rome, Italy","2011 IEEE 11th International Conference on Advanced Learning Technologies","18 Aug 2011","2011","","","126","128","This paper presents a prototype for an application based on a CMS (Content Management System) connected to an augmented-reality engine that allows final users to publish, read and experience multimedia content tied to specific components of physical artifacts. When the physical artifacts are placed under a webcam, a pre-trained 3D feature recognition system scans the entire figure trying to identify some specific components. If any of these elements are recognized, the system retrieves and shows educational content from selected sources (texts, videos, pictures). We created a first instance of this framework and applied it to the Minkisi, artifacts from Congo that are claimed to possess spiritual qualities. Studies on Minkisi play a crucial role in the history of cultural anthropology and in the current ethnographic agenda. The aim of this research project is then to create a learning tool that empowers anthropological scholars and students allowing them to publish their own content on the Minkisi and to access some of the stories that make these ethnographic artifacts alive and powerful.","2161-377X","978-1-61284-209-7","10.1109/ICALT.2011.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5992282","augmented reality;enhanced learning;constructionism;mathetics","Augmented reality;Education;Three dimensional displays;Cultural differences;Pattern recognition;Prototypes;History","anthropology;augmented reality;computer aided instruction;content management;content-based retrieval;cultural aspects;feature extraction;multimedia computing;video retrieval","cultural anthropology;content management system;augmented reality engine;multimedia content;physical artifacts;Webcam;pretrained 3D feature recognition system;educational content retrieval;Minkisi;Congo;spiritual qualities;ethnographic artifacts;video retrieval;photo retrieval;text retrieval","","6","","23","IEEE","18 Aug 2011","","","IEEE","IEEE Conferences"
"Augmented reality in e-learning review of prototype designs for usability evaluation","T. Satpute; S. Pingale; V. Chavan","Department of ComputerScience and Engineering, SKN Sinhgad College of Engineering, Pandharpur, India; Department of ComputerScience and Engineering, SKN Sinhgad College of Engineering, Pandharpur, India; Department of ComputerScience and Engineering, SKN Sinhgad College of Engineering, Pandharpur, India","2015 International Conference on Communication, Information & Computing Technology (ICCICT)","23 Feb 2015","2015","","","1","4","The concept of e-learning has reached beyond use of presentations, videos. Augmented reality (AR) based systems are preferred to support teaching and learning activities along with these e-learning systems. In this paper we present a systematic review of such prototypes developed for educational purposes and compare their usability for finding benefits of AR. It also focuses on use of web 2.0 tools in e- learning and combined use of both technologies.","","978-1-4799-5522-0","10.1109/ICCICT.2015.7045712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045712","Augmented Reality;e-learning;usability;web 2.0","Augmented reality;Prototypes;Web 2.0;Electronic learning;Collaboration;Usability","augmented reality;computer aided instruction;Internet;prototypes;teaching","prototype designs;usability evaluation;augmented reality based systems;AR based systems;teaching activities;learning activities;e-learning systems;educational purposes;WEB 2.0 tools","","6","","18","IEEE","23 Feb 2015","","","IEEE","IEEE Conferences"
"Augmented Reality Tools for Enhanced Robotics Teleoperation Systems","H. Portilla; L. Basanez","University of Pamplona, Colombia; Technical University of Catalonia, Spain","2007 3DTV Conference","12 Nov 2007","2007","","","1","4","This paper describes a set of visualization aids to be used in a robotic teleoperation system. The goal is to have a set of virtual tools that can be applied in a teleoperation environment to improving the visual capabilities and knowledge of the operator about the remote workcell from the use of 3D vision, robot state feedback and augmented reality. In order to show the increase in the quality and capacity of a operator in the execution of a teleoperated tasks a set of experiments are exposed.","2161-203X","978-1-4244-0721-7","10.1109/3DTV.2007.4379424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379424","Telerobotics;Image Communication;3D-dimensional displays;Augmented Reality","Augmented reality;Protocols;Service robots;Robot sensing systems;Visualization;Internet;Mobile robots;MPEG 4 Standard;Medical control systems;Communication system control","augmented reality;telerobotics","augmented reality tools;enhanced robotics teleoperation systems;remote workcell;robot state feedback","","6","","14","IEEE","12 Nov 2007","","","IEEE","IEEE Conferences"
"Overhead Power Line Sag Monitoring through Augmented Reality","M. Y. Sermet; I. Demir; S. Kucuksari","Department of Electrical and Computer Engineering, University of Iowa, Iowa City, IA 52246, USA; Civil and Environmental Engineering, and Electrical and Computer Engineering Departments, University of Iowa, Iowa City, IA 52246, USA; Department of Technology, University of Northern Iowa, Cedar Falls, IA 50614, USA","2018 North American Power Symposium (NAPS)","3 Jan 2019","2018","","","1","5","Monitoring overhead power line sag amount plays an important role in increasing the line delivered power capacity. The sag amount has to be within certain limits and the clearance has to be maintained at all time to avoid possible failures and power outages. Literature presents various calculation methods using the temperature and line current information. This paper presents a mobile application to support distribution and transmission line monitoring for ground clearance and other obstacles via augmented reality and image recognition. The application aims to increase the line capacity safely and to reduce the maintenance costs of the lines due to unnecessary crew trips. The application is an inexpensive and provides accurate solution for the utility companies. It can also be used for citizen science to collect data through local residents.","","978-1-5386-7138-2","10.1109/NAPS.2018.8600565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8600565","Overhead line sag monitoring;augmented reality;image recognition","Monitoring;Augmented reality;Temperature measurement;Power transmission lines;Companies;Temperature sensors;Maintenance engineering","augmented reality;computerised monitoring;condition monitoring;cost reduction;failure analysis;image recognition;power engineering computing;power overhead lines;power supply quality","line delivered power capacity;power outages;line current information;mobile application;transmission line monitoring;ground clearance;line capacity;image recognition;maintenance cost reduction;crew trips;data collection;augmented reality;overhead power line sag monitoring","","6","","21","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"Mapping and re-localization for mobile augmented reality","P. Martin; E. Marchand; P. Houlier; I. Marchal","IRISA Université de Rennes 1, Rennes, France; IRISA Université de Rennes 1, Rennes, France; Orange Labs, Cesson Sevigné, France; Orange Labs, Cesson Sevigné, France","2014 IEEE International Conference on Image Processing (ICIP)","29 Jan 2015","2014","","","3352","3356","Using Simultaneous Localization And Mapping (SLAM) methods become more and more common in Augmented Reality (AR). To achieve real-time requirement and to cope with scale factor and the lack of absolute positioning issue, we propose to decouple the localization and the mapping step. We explain the benefits of this approach and how a SLAM strategy can still be used in a way that is meaningful for the end user. The method we proposed has been fully implemented on various smartphone in order to show its efficiency.","2381-8549","978-1-4799-5751-4","10.1109/ICIP.2014.7025678","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7025678","Augmented reality;simultaneous location and mapping;mobile phone","Three-dimensional displays;Cameras;Augmented reality;Simultaneous localization and mapping;Real-time systems;Mobile handsets;Image reconstruction","augmented reality;mobile computing;SLAM (robots);smart phones","relocalization;mobile augmented reality;simultaneous localization and mapping methods;SLAM methods;AR;real-time requirement;scale factor;smartphone","","6","1","15","IEEE","29 Jan 2015","","","IEEE","IEEE Conferences"
"Improving Accessibility for Dyslexic Impairments using Augmented Reality","T. Gupta; M. Sisodia; S. Fazulbhoy; M. Raju; S. Agrawal","Department of Computer Engineering, Mukesh Patel School of Technology, Management and Engineering, Mumbai, India; Department of Computer Engineering, Mukesh Patel School of Technology, Management and Engineering, Mumbai, India; Department of Computer Engineering, Mukesh Patel School of Technology, Management and Engineering, Mumbai, India; Department of Computer Engineering, Mukesh Patel School of Technology, Management and Engineering, Mumbai, India; Department of Computer Engineering, Mukesh Patel School of Technology, Management and Engineering, Mumbai, India","2019 International Conference on Computer Communication and Informatics (ICCCI)","2 Sep 2019","2019","","","1","4","Dyslexia is a specific learning disability which affects a person's ability to read, spell and understand language while reading or writing. There is a need to improve accessibility for problems faced by the dyslexic. Our system employs Augmented Reality using a smartphone camera in order to overcome these obstacles by enabling user-adjustment of background-text contrast ratio and text customization in real life. After testing the application, we received positive results with a 21.03% decrease in their overall reading time for the text passages. Therefore our application proves to be a great aid in the lives of people suffering from dyslexia.","2329-7190","978-1-5386-8260-9","10.1109/ICCCI.2019.8822152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822152","Accessibility;Augmented Reality;Dyslexia;Optical Character Recognition (OCR)","Augmented reality;Optical character recognition software;Testing;Informatics;Real-time systems;Cameras;Integrated optics","augmented reality;handicapped aids;smart phones;text analysis","background-text contrast ratio;text customization;text passages;dyslexic impairments;smartphone camera;user-adjustment;augmented reality;learning disability","","6","","5","IEEE","2 Sep 2019","","","IEEE","IEEE Conferences"
"An Augmented-Reality night vision enhancement application for see-through glasses","Chunjia Hu; Guangtao Zhai; Duo Li","Institute of Image Communication and Information Processing, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Communication and Information Processing, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Communication and Information Processing, Shanghai Jiao Tong University, Shanghai, China","2015 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","30 Jul 2015","2015","","","1","6","Nyctalopia, millions of people all over the world suffering from which, brings much trouble to the patients. The available night vision systems are poor in user experience but cost much. In this paper we design and implement an Augmented-Reality night vision enhancement application for see-through glasses. According to our model proposed for the night blindness, fast and efficient algorithms are used for both night vision enhancement and display calibration. The processed images are much brighter and aligned to the real world. The results in different daily life scenes are presented, indicating huge convenience the application will bring to the nyctalopia patients.","","978-1-4799-7079-7","10.1109/ICMEW.2015.7169860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7169860","Augmented-Reality;nyctalopia;seethrough glasses;night vision enhancement","Night vision;Cameras;Glass;Calibration;Distortion;Blindness;Augmented reality","augmented reality;handicapped aids;image processing;night vision;vision defects","Augmented-Reality night vision enhancement application;see-through glasses;night vision system;user experience;night blindness;display calibration;image processing;daily life scene;nyctalopia patient","","6","","25","IEEE","30 Jul 2015","","","IEEE","IEEE Conferences"
"Design and implementation of a framework based on augmented reality for phobia treatment applications","S. R. K. Tabbakh; R. Habibi; S. Vafadar","Department of Software Engineering, Mashhad branch, Islamic Azad University, Mashhad, Iran; Department of Software Engineering, Mashhad branch, Islamic Azad University, Mashhad, Iran; Department of Computer Engineering, Islamic Azad University, Neyshabur, Iran","2015 International Congress on Technology, Communication and Knowledge (ICTCK)","6 Oct 2016","2015","","","366","370","Augmented Reality (AR) is one of the todays' technologies that has variety of applications from education purposes to medical and military applications. It enables adding virtual objects to the real life environment that can be viewed from AR-glasses or computer displays. In this paper we propose a framework including hardware and software to apply AR technology in phobia treatment. Phobia is a psychological disorder which is an extreme fear towards an object, creature or situation. In the previous works, head-mounted and in-front displays were used; however, both have major negative effects on treatment. In contrast to the previous works, the main element of the proposed framework is an AR-desk developed to be used as patient's front desk which eliminates the use of head-mounted systems. Step by step details of the design and implementation are described and the proposed framework is evaluated through feedbacks from psychologists, IT professionals and ordinary people. Finally, it is discussed and concluded that the proposed framework has many advantages compared to similar previous works.","","978-1-4673-9762-9","10.1109/ICTCK.2015.7582697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582697","Augmented Reality;Phobia;Treatment;AR-desk;Psychological disorder;AR Applications","Psychology;Augmented reality;Computers;Software;Videos;Monitoring;Hardware","augmented reality;medical computing;medical disorders;patient treatment;psychology","augmented reality;phobia treatment applications;psychological disorder;AR-desk","","6","","19","IEEE","6 Oct 2016","","","IEEE","IEEE Conferences"
"Doctoral Colloquium—Towards a Better User Interface of Augmented Reality Based Indoor Navigation Application","B. Liu; L. Meng","Chair of Cartography Technical, University of Munich, Munich, Germany; Chair of Cartography Technical, University of Munich, Munich, Germany","2020 6th International Conference of the Immersive Learning Research Network (iLRN)","4 Aug 2020","2020","","","392","394","Navigation service is a widespread geoinformation service and can be embedded in an augmented reality (AR). In this work-in-progress, we aim at a user interface of AR-based indoor navigation system, which could not only guide users to destinations quickly and safely, but also improve users' spatial learning. We designed an interface for indoor navigation on HoloLens, gathered feedback from users, and found that arrows are an intuitive aid of orientation. Semantic meanings embedded in icons are not self-explaining, but icons with text can serve as virtual landmarks and help with spatial learning.","","978-1-7348995-0-4","10.23919/iLRN47897.2020.9155198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155198","augmented reality;indoor navigation;user interface;spatial learning","Augmented reality;Indoor navigation;User interfaces;Buildings;Semantics;Indoor environments","augmented reality;navigation;user interfaces","navigation service;widespread geoinformation service;augmented reality;AR-based indoor navigation system;users;spatial learning;doctoral colloquium;better user interface;navigation application","","6","","13","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Learning to create 3D models via an augmented reality smartphone interface","J. K. T. Tang; T. -Y. A. Duong; Y. -W. Ng; H. -K. Luk","School of Computing and Information Sciences, Caritas Institute of Higher Education, Hong Kong; School of Science and Technology, The Open University of Hong Kong, Hong Kong; School of Science and Technology, The Open University of Hong Kong, Hong Kong; School of Science and Technology, The Open University of Hong Kong, Hong Kong","2015 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)","21 Jan 2016","2015","","","236","241","The ordinary way of creating 3D models (a.k.a. 3D modeling) requires people to sit in front of the computer for a long time working with professional software. The license fees of these software are expensive, and it is very time consuming and not easy to learn. Teachers sometimes find difficult to teach students the concept of 3D modeling because the newbies need to spend a lot of time to familiarize with the tool interface beforehand. In this paper, we introduce a mobile application that assists students to learn 3D modeling skills and concepts. We provide a natural modeling style with the aid of Augmented Reality (AR). Through a smartphone user interface, the user builds a model with primitive blocks in a ""bottom-up"" manner like ""LEGO"" bricks. These blocks are visualized on the printed marker cards that allow users to manipulate (rotate, translate, etc.) them in the same way of manipulating real building blocks. User studies have been conducted and we have identified some aspects that help people to model 3D objects.","","978-1-4673-9226-6","10.1109/TALE.2015.7386050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7386050","Augmented Reality;3D Modeling;Mobile Learning;Interactive Learning;Smart Education","Three-dimensional displays;Solid modeling;Shape;Computational modeling;Augmented reality;Education;Mobile applications","augmented reality;computer aided instruction;smart phones;user interfaces","create 3D models;augmented reality smartphone interface;professional software;license fees;tool interface;mobile application;3D modeling skills;3D modeling concepts;AR;smartphone user interface;printed marker cards","","6","","19","IEEE","21 Jan 2016","","","IEEE","IEEE Conferences"
"Training System for Hybrid Vehicles Through Augmented Reality","E. F. Rivera; M. V. Pilco; P. S. Espinoza; E. E. Morales; J. S. Ortiz","Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Servicios Automotrices Jitalia, Madrid, España; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador","2020 15th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2020","2020","","","1","6","This article presents the development of a training system in augmented reality; oriented to the teaching and learning process in the area of Automotive Mechanics for hybrid vehicles. The application developed will allow the user to be more immersed in the operation of the hybrid vehicle, therefore, it will simulate the movements made by its transmission which involves the power dividing device (PSD), MG1, MG2 and internal combustion engine (IC), in addition, it performs the virtualization of the assembly and disassembly of the device in order to optimize time and economic resources, among other benefits of educational and technological impact. The system is developed in Unity 3D's graphic environment by means of large-scale 3D object recognition; by means of previously established patterns which, once the application has been developed, will allow the user to visualize the transmission together with its main components and will serve as an aid for the methodological process of teaching and learning in Automotive Mechanics.","2166-0727","978-989-54659-0-3","10.23919/CISTI49556.2020.9141020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141020","Augmented Reality;Toyota;Hybrid;Unity;Vuforia","Three-dimensional displays;Augmented reality;Solid modeling;Internal combustion engines;Training;Automotive engineering","augmented reality;automotive engineering;computer based training;hybrid electric vehicles;internal combustion engines;mechanical engineering computing;object recognition;solid modelling;teaching","training system;hybrid vehicle;augmented reality;teaching process;learning process;power dividing device;MG1;MG2;internal combustion engine;Unity 3D graphic environment;automotive mechanics;3D object recognition","","6","","16","","15 Jul 2020","","","IEEE","IEEE Conferences"
"User preference in collaborative science learning through the use of Augmented Reality","W. Matcha; D. R. Awang Rambli","Computer & Information Science department, Universiti Teknologi PETRONAS, Tronoh, Perak, Malaysia; Computer & Information Science department, Universiti Teknologi PETRONAS, Tronoh, Perak, Malaysia","2012 4th International Congress on Engineering Education","27 Mar 2014","2012","","","64","68","This paper is aimed to report the study result based on an experimental study investigating user preference toward science learning, focusing on electricity topic and the use of Augmented Reality (AR) technology to support group learning. AR technology enhances real world interaction by adding the virtual information which could not be seen in the real world with real time interaction. Survey and experimental study were used to collect the data. The result of the study showed that students are still facing problem in learning about electricity. They identified electricity as complex topic to understand and visualize. The survey results also revealed that most student prefer group to individual learning when performing experiment. User feedbacks from participant suggested the potential of AR technology to support learning due to its ability to grabs students' attention and create joyful learning.","","978-1-4673-4868-3","10.1109/ICEED.2012.6779271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6779271","Augmented Reality;Science Learning;Collaborative Learning;Electricity learning","Electricity;Augmented reality;Computers;Resistors;Visualization;Engineering education","augmented reality;computer aided instruction;groupware","user preference;collaborative science learning;augmented reality technology;group learning;technology;virtual information;joyful learning","","6","","16","IEEE","27 Mar 2014","","","IEEE","IEEE Conferences"
"GyroWand: An Approach to IMU-Based Raycasting for Augmented Reality","J. D. Hincapié-Ramos; K. Özacar; P. P. Irani; Y. Kitamura",University of Manitoba; Tohoku University; University of Manitoba; Tohoku University,"IEEE Computer Graphics and Applications","4 Mar 2016","2016","36","2","90","96","Optical see-through head-mounted displays enable augmented reality (AR) applications that display virtual objects overlaid on the real world. At the core of this new generation of devices are low-cost tracking technologies that allow us to interpret users' motion in the real world in relation to the virtual content for the purposes of navigation and interaction. The advantages of pervasive tracking come at the cost of limiting interaction possibilities, however. To address these challenges the authors introduce GyroWand, a raycasting technique for AR HMDs using inertial measurement unit (IMU) rotational data from a handheld controller.","1558-1756","","10.1109/MCG.2016.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426273","computer graphics;spatial interfaces;GyroWand;raycasting;inertial measurement units (IMUs);rotational data;handheld controller;augmented reality","Optical communication;Apertures;Interference (signal);Aerospace electronics;Noise level;Augmented reality","augmented reality;helmet mounted displays;inertial systems;motion estimation;object tracking","GyroWand;IMU-based raycasting technique;optical see-through head-mounted displays;augmented reality applications;AR applications;virtual objects;low-cost tracking technologies;user motion;virtual content;pervasive tracking;AR HMD;inertial measurement unit;IMU rotational data;handheld controller","","6","","12","IEEE","4 Mar 2016","","","IEEE","IEEE Magazines"
"ATHYNOS: Helping Children with Dyspraxia Through an Augmented Reality Serious Game","D. Avila-Pesantez; L. Vaca-Cardenas; L. A. Rivera; L. Zuniga; L. Miriam Avila","Computer Science Faculty, San Marcos National University, Lima, Peru; Informatics and Electronic Faculty, Polytechnic School of Chimborazo, Riobamba, Ecuador; Mathematical Sciences Laboratory, State University of North Fluminense, Rio de Janeiro, Brasil; Informatics and Electronic Faculty, Polytechnic School of Chimborazo, Riobamba, Ecuador; Business & Management Faculty, Polytechnic School of Chimborazo, Riobamba, Ecuador","2018 International Conference on eDemocracy & eGovernment (ICEDEG)","7 Jun 2018","2018","","","286","290","Emerging technologies and ICT have changed the lifestyle of society, all scientific areas are taking advantage of technology to get a real development. Therapists realize the benefits of using serious games as an assistive tool in psychotherapy. Thus, this research examines relevant issues regarding Dyspraxia disorders in children and presents a comparative study between two therapies methods, one using a manual puzzle and other using ATHYNOS, an Augmented Reality Serious Game developed to help children with the Dyspraxia to improve their motor skills and hand-eye coordination through technology. The analysis of data results showed that exist a significant difference between both methods, proving that children playing with ATHYNOS got less time in the activity execution and also better performance.","2573-1998","978-1-5386-2521-7","10.1109/ICEDEG.2018.8372351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8372351","serious games;augmented reality;dyspraxia;ATHYNOS","Games;Medical treatment;Augmented reality;Tools;Manuals;Software;Shape","augmented reality;medical computing;medical disorders;patient treatment;psychology;serious games (computing)","ATHYNOS;serious games;Dyspraxia disorders;motor skills;hand-eye coordination;augmented reality;serious game;ICT;assistive tool;psychotherapy;therapies methods;manual puzzle","","6","","32","IEEE","7 Jun 2018","","","IEEE","IEEE Conferences"
"Scaffolding models for remedial students in using augmented reality storybook","H. Abas; H. B. Zaman","Advanced Informatics School (AIS) Universiti Teknologi Malaysia, Kuala Lumpur, MALAYSIA; Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, MALAYSIA","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","19 Sep 2011","2011","","","1","5","Scaffolding model for augmented reality (AR) storybook is a structured method of supporting student in learning how to read. Reading is one of the fundamental skills needed by the remedial students to be successful in their academic endeavors. Remedial students are students who have problems with their cognition, motivation, and emotion. This research focuses on developing a Malay language storybook with the support of the AR technology. It contributes six scaffolding models that are based on theories, guidelines, and the previous research of scaffolding. They are i) scaffolding model for AR story books (thematic stories); ii) scaffolding model for AR story books (short stories); iii) scaffolding model for AR story books (comprehension); iv) scaffolding model for AR story books (dictionary); v) scaffolding model for AR story books (coloring activity) and vi) scaffolding model for AR story books (marker). The next step is the development phases, which are the composition of AR story book and AR markers. This will then be the lead for future works, and research on the acceptance test with experts and usability testing with the remedial students.","2155-6830","978-1-4577-0752-0","10.1109/ICEEI.2011.6021687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021687","Scaffolding;augmented reality;remedial students;reading;Bahasa Melayu","Augmented reality;Solid modeling;Educational institutions;Dictionaries;Materials","augmented reality;computer aided instruction;natural language processing","scaffolding models;remedial students;augmented reality storybook;academic endeavors;Malay language storybook;AR markers;usability testing;acceptance test","","5","","32","IEEE","19 Sep 2011","","","IEEE","IEEE Conferences"
"Collision Avatar (CA): Adding collision objects for human body in augmented reality using Kinect","K. Aitpayev; J. Gaber","Center for Energy Research, University of Technology of Belfort-Montbeliard, Astana, Kazakhstan; Computer Science Department, University of Technology of Belfort-Montbeliard, Belford, France","2012 6th International Conference on Application of Information and Communication Technologies (AICT)","31 Dec 2012","2012","","","1","4","The purpose of this study is the improvement of real and virtual world interaction in real-time by uses of Kinect. We propose adding geometric shapes as a collision object for human body parts in augmented reality with real-time animations. In this work the concept of collision Avatar (CA) is presented. We will describe different methods which creates geometric shapes, scale them according to body part sizes. Also we compare several types of real-time animations using different methods.","","978-1-4673-1740-5","10.1109/ICAICT.2012.6398480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6398480","Augmented Reality;Motion Capture;Virtual Character;Ubiquitous Computing","Bones;Joints;Augmented reality;Shape;Head;Real-time systems;Animation","augmented reality;avatars;computer animation;real-time systems","collision avatar;collision objects;augmented reality;Kinect;virtual world interaction;real-time interaction;geometric shapes;real-time animations;human body part size","","5","","5","IEEE","31 Dec 2012","","","IEEE","IEEE Conferences"
"Leihoa: A window to augmented reality in early childhood education","A. Aguirregoitia Martínez; I. Allende López; J. R. López Benito; E. Artetxe González","Dpto. de Leng. y Sists, Informáticos Universidad del PaísVasco, Bilbao, España; Informáticos Universidad del PaísVasco, Bilbao, España; CreativiTIC Innova SL, Logroño, España; CreativiTIC Innova SL, Logroño, España","2016 International Symposium on Computers in Education (SIIE)","24 Nov 2016","2016","","","1","6","Recent advances in technologies are being effectively applied to educational contexts. The current study presents an educational application using augmented reality technology which aims to initiate reading, introduce numbers and motivate exploration of rich vocabulary (structured in different interest centers) in English as a second language and Basque. The project promotes autonomous learning through exploration and inquiry. The application encourages interaction and allows content adaptability, self-evaluation and multisensory stimulus and can be successfully adopted for learning and development in Preschool education.","","978-1-5090-4596-9","10.1109/SIIE.2016.7751836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7751836","Augmented reality;Early childhood education;educational technology","Education;Vocabulary;Augmented reality;Androids;Humanoid robots;Real-time systems;Image recognition","augmented reality;computer aided instruction;natural language processing","Leihoa;augmented reality;AR;early childhood education;educational technology;English as a second language;autonomous learning;content adaptability;self-evaluation;multisensory stimulus;preschool education","","5","","17","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"Design and Development of Augmented Reality (AR) Mobile Application for Malolos' Kameztizuhan (Malolos Heritage Town, Philippines)","D. R. dela Cruz; J. S. A. Sevilla; J. W. D. San Gabriel; A. J. P. Dela Cruz; E. J. S. Caselis","Electronics Engineering Department, Bulacan State University, Malolos City, Bulacan, Philippines; Electronics Engineering Department, Bulacan State University, Malolos City, Bulacan, Philippines; Electronics Engineering Department, Bulacan State University, Malolos City, Bulacan, Philippines; Electronics Engineering Department, Bulacan State University, Malolos City, Bulacan, Philippines; Electronics Engineering Department, Bulacan State University, Malolos City, Bulacan, Philippines","2018 IEEE Games, Entertainment, Media Conference (GEM)","1 Nov 2018","2018","","","1","9","United Nations (UN) Sustainable Development Goals (SDGs) 11 advocates the preservation of world and individual nation's cultural and natural heritage. In line with this vision, the Philippines under the Republic Act No. 10066 or the National Cultural Heritage Act of 2009 has obliged the government to provide funding to implement projects supporting this cause but still a lot more sites are still left in the brink of oblivion like the Kameztizuhan in Malolos. With lack of knowledge in heritage preservation, some property owners that practice adaptive reuse seem to be of no proper restoration guidelines. Thus, many structures were altered away from its original design, losing its historical feature and value. In addition, other owners simply demolish old structures, probably finding maintenance more expensive or new structures more profitable. Currently, many of these old structures have no markers, so tourists can't identify their historicity or cultural significance. This led to the proposal of creating augmented reality (AR) mobile application where physical structures can be virtually simulated, viewed and controlled to promote the historical and cultural value of Malolos' Kameztizuhan. The graphics of the application was developed using SketchUp and imported into the Unity editor in order for them to be used for augmentation. The augmentation process was handled by Vuforia's web-based Target Manager in order to convert these images into targets. The application has been tested and evaluated by visitors of Malolos' Kameztizuhan and employees of the Malolos City Tourism office. Criteria for the evaluation of the application to prove the application's effectiveness includes the following: user-friendliness, information accuracy, and user acceptance. A pre-test and post-test was also conducted to determine the level of learning of the user about the site upon using the application. It was accepted with enthusiasm and positive feedbacks due to its personalization features, navigation, and realism it offers to the users.","","978-1-5386-6304-2","10.1109/GEM.2018.8516272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516272","Augmented Reality;Cultural Heritage;Mobile Application;Virtual Heritage;3D Reconstruction","Three-dimensional displays;Urban areas;Cultural differences;Augmented reality;Buildings;Solid modeling;Target tracking","augmented reality;government policies;history;Internet;maintenance engineering;mobile computing;solid modelling;sustainable development;travel industry","augmented reality mobile application;Malolos Heritage town;Philippines;United Nations;heritage preservation;property owners;historical feature;physical structures;historical value;augmentation process;sustainable development goals;Malolos Kameztizuhan;National cultural heritage act;Malolos city tourism office;Vuforia Web-based target manager;SDG","","5","","16","IEEE","1 Nov 2018","","","IEEE","IEEE Conferences"
"Collaborative Augmented Reality Application for Information Visualization Support","E. K. K. Yasojima; B. S. Meiguins; A. S. Meiguins","Universidade Federal do Para-UFPA, Belem, Parana, Brazil; Universidade Federal do Para-UFPA, Belem, Parana, Brazil; Centro Universitário do Pará-CESUPA, Belem, Parana, Brazil","2011 15th International Conference on Information Visualisation","25 Aug 2011","2011","","","170","175","In today's information systems, strategies for decision making and accurate results in a short time are crucial in many knowledge areas of industry, economic, medical etc.. To support this demand to store and interpret relevant information, the area of information visualization coupled with several others, such as intelligent systems and data mining, is increasingly taking place in academic research and market. Aiming to increase to level of interaction and accurate results, this article presents a collaborative augmented reality application for information visualization support.","2375-0138","978-1-4577-0868-8","10.1109/IV.2011.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6004038","Information Visualization;Collaborative Environments;Augmented Reality","Augmented reality;Data visualization;Collaboration;Image color analysis;Context;Three dimensional displays;Usability","augmented reality;data mining;data visualisation;decision making;groupware;information systems","collaborative augmented reality;information visualization support;information systems;decision making;intelligent systems;data mining","","5","","19","IEEE","25 Aug 2011","","","IEEE","IEEE Conferences"
"Work-in-Progress–The ARI2VE Model for Augmented Reality Books","J. Buchner; A. Jeghiazaryan","Learning Lab, University of Duisburg-Essen, Essen, Germany; Areeka, Amlogy GmbH, Vienna, Austriay","2020 6th International Conference of the Immersive Learning Research Network (iLRN)","4 Aug 2020","2020","","","287","290","In this work-in-progress paper, the first attempt of the ARI2VE model for Augmented Reality books is presented. The components of the model are based on research on instructional design and multimedia learning as well as previous implementations of AR in books. The components interaction, interplay, visualization and engagement are described in detail and illustrated with an example. Due to the early stage of the model no empirical findings can be reported yet, but first investigations are in progress. A call for international cooperation and joint research is made.","","978-1-7348995-0-4","10.23919/iLRN47897.2020.9155110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155110","augmented reality;AR books;instructional design;multimedia learning;AR learning environment","Task analysis;Visualization;Augmented reality;Education;Computational modeling;Solid modeling;Three-dimensional displays","augmented reality;computer aided instruction;data visualisation;human computer interaction;multimedia computing","augmented reality books;instructional design;multimedia learning;component interaction;ARI2VE model;international cooperation","","5","","38","","4 Aug 2020","","","IEEE","IEEE Conferences"
"An integration of augmented reality technology for orthodontic education: Case of bracket positioning","G. K. L. Rao; N. B. Mokhtar; Y. H. P. Iskandar","Craniofacial and Biomaterial Science Cluster, Universiti Sains Malaysia, Penang, Malaysia; Craniofacial and Biomaterial Science Cluster, Universiti Sains Malaysia, Penang, Malaysia; Graduate School of Business, Universiti Sains Malaysia, Penang, Malaysia","2017 IEEE Conference on e-Learning, e-Management and e-Services (IC3e)","12 Jul 2018","2017","","","7","11","The e-learning and augmented reality (AR) platforms independently and in tandem have a varying presence in the orthodontic curriculum. AR with its newer applications has seen a drastic growth with the development of newer technology. The AR simulation technology needs integration into the field of e-learning pedagogy. AR visual and haptic cues can be embedded for learning a significant skill of bracket positioning on teeth enhancing the psychomotor and cognitive skill development of students. The proposed tool will help learn bracket positioning on front teeth by visual colour cues and haptic senses for handling the brackets. The system will provide feedback and error identification to aid immediate learning. The technique aims to help the student build confidence to perform the required task on a real patient by training in an AR environment in the absence of a patient.","","978-1-5386-3145-4","10.1109/IC3e.2017.8409230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409230","E-learning;Augmented reality;Orthodontic education;Orthodontic bracket positioning","Teeth;Electronic learning;Visualization;Haptic interfaces;Augmented reality;Training","augmented reality;cognition;computer aided instruction;haptic interfaces","orthodontic curriculum;AR simulation technology;e-learning pedagogy;haptic cues;psychomotor;cognitive skill development;bracket positioning;visual colour cues;haptic senses;immediate learning;augmented reality technology;orthodontic education","","5","","21","IEEE","12 Jul 2018","","","IEEE","IEEE Conferences"
"Enabling Human-Robot-Interaction for Remote Robotic Operation via Augmented Reality","C. Xue; Y. Qiao; N. Murray","Athlone Institute of Technology, Ireland; Software Research Institute, Athlone Institute of Technology, Faculty of Engineering & Informatics, Athlone, Ireland; Computer & Software Engineering, Faculty of Engineering & Informatics, Athlone Institute of Technology, Athlone, Ireland","2020 IEEE 21st International Symposium on "A World of Wireless, Mobile and Multimedia Networks" (WoWMoM)","9 Oct 2020","2020","","","194","196","Human-Robot Interaction (HRI) will be a crucial component of smart factories of the future (FoF). This demo presents a reliable and cost-effective HRI system based on Augmented Reality (AR). In this demonstration, we offer concepts and methods currently being developed to enable high-level human-robot collaboration and interaction. The user interaction and instructions are captured via AR and communicated to a Robot Operating System (ROS) powered robotic arm.","","978-1-7281-7374-0","10.1109/WoWMoM49955.2020.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9217702","Augmented Reality;Unity3D;Robot Operating System;Human-Robot Interaction","Manipulators;Three-dimensional displays;Augmented reality;Human-robot interaction;Task analysis;Trajectory","augmented reality;control engineering computing;factory automation;human-robot interaction;industrial robots;mobile robots;operating systems (computers);production engineering computing;robot programming;telerobotics","human-robot-interaction;remote robotic operation;augmented reality;Human-Robot Interaction;high-level human-robot collaboration;user interaction;Robot Operating System;robotic arm;cost-effective HRI system;smart factories of the future;smart FoF","","5","","17","IEEE","9 Oct 2020","","","IEEE","IEEE Conferences"
"Providing augmented reality based education for students with attention deficit hyperactive disorder via cloud computing: Its advantages","N. A. A. Aziz; K. A. Aziz; A. Paul; A. M. Yusof; N. S. Mohamed Noor","Faculty of Engineering and Technology, Multimedia University, Malaysia; Faculty of Management, Multimedia University, Malaysia; Faculty of Creative Multimedia, Multimedia University, Malaysia; Faculty of Creative Technology and Heritage, University Malaysia Kelantan, Malaysia; School of Public Policy and Management, Korea Development Institute, South Korea","2012 14th International Conference on Advanced Communication Technology (ICACT)","3 Apr 2012","2012","","","577","581","Providing education for students with attention deficit hyperactive disorder (ADHD) is a challenge. These students need a special approach compared to normal students. They are known to have limited attention span and easily distracted. One way information sharing where an instructor is the source of information is not suitable for them. A learning module that can simulate their interest and catch their attention is needed to ensure an effective learning session. Research shows that usage of augmented reality (AR) in education receives positive feedback from students and teachers. Students are excited on the interactive aspect of AR and the freedom for them to explore the subject of study within a safe environment. On the other hand positive responses are received from educators on the effectiveness of AR based module in supporting learning sessions. AR allows the virtual object and real world to coexist, allowing the object of study such as atomic structure to be brought to life, thus, breaking the boundary of space and time. This enhances the students understanding and memory. Cloud computing technology enables a location independent computing where the computing resources, software, and data are stored in the cloud. This provides more efficient information sharing among global internet users. Our project aims to provide AR based courseware for ADHD students so that a better education can be provided for them. We would also like to explore the possibility of providing this courseware via cloud computing, thus allowing it to be reach by wider target group and solving the issue of storage capacity. Hence this paper is looking into this issue.","1738-9445","978-89-5519-163-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6174735","ADHD;augmented reality;cloud","Cloud computing;Educational institutions;Augmented reality;Multimedia communication;Courseware;Convergence","augmented reality;cloud computing;computer aided instruction","augmented reality;education;students;attention deficit hyperactive disorder;cloud computing;ADHD;information sharing;virtual object","","5","2","28","","3 Apr 2012","","","IEEE","IEEE Conferences"
"Using the Augmented Reality Technique to Develop Visualization Mindtools for Chemical Inquiry-Based Activities","K. -J. Yang; H. -C. Chu; K. -H. Yang","Department of Computer Science and Information Management, Soochow University, Taipei, Taiwan; Department of Computer Science and Information Management, Soochow University, Taipei, Taiwan; Department of Mathematics and Information Education, National Taipei University of Education, Taipei, Taiwan","2015 IIAI 4th International Congress on Advanced Applied Informatics","7 Jan 2016","2015","","","354","357","Visualization Mind tools enable students to obtain experience of observing commonly invisible phenomena. Although we often approach gases in daily life, they are not observable with the naked eye. Thus, students may have numerous misperceptions when learning the properties and phenomena of gases. In this study, an augmented reality technique will be used to establish an interactive visualization Mind tools learning model that enables students to adjust the parameters of pressure and temperature, then they can observe the diversification inside the gases accordingly, thereby improving their learning performance. The experiment will be conducted in association with the teaching unit progress of gases in the 11th grade chemistry course. Two classes of students will be randomly assigned to the experimental and the control group. After conducting the experiment, an in-depth exploration of whether the learning model can effectively improve students' problem solving abilities and learning achievement will be measured.","","978-1-4799-9958-3","10.1109/IIAI-AAI.2015.222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373930","Visualization Mindtools;augmented reality;problem solving;inquiry-based activity;chemical course","Visualization;Augmented reality;Education;Learning systems;Chemicals;Gases;Databases","augmented reality;chemistry;computer aided instruction;educational courses;interactive systems;problem solving","augmented reality technique;Mindtools;chemical inquiry-based activities;learning;interactive visualization;chemistry course;problem solving","","5","","11","IEEE","7 Jan 2016","","","IEEE","IEEE Conferences"
"Fancy Fruits - An Augmented Reality Application for Special Needs Education","S. C. Steinhaeusser; A. Riedmann; M. Haller; S. Oberdörfer; K. Bucher; M. E. Latoschik",University of Würzburg; University of Würzburg; University of Applied Sciences Würzburg-Schweinfurt; University of Würzburg; University of Würzburg; University of Würzburg,"2019 11th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)","14 Oct 2019","2019","","","1","4","Augmented Reality (AR) allows for a connection between real and virtual worlds, thus providing a high potential for Special Needs Education (SNE). We developed an educational application called Fancy Fruits to teach disabled children the components of regional fruits and vegetables. The app includes marker-based AR elements connecting the real situation with virtual information. To evaluate the application, a field study was conducted. Eleven children with mental disabilities took part in the study. The results show a high enjoyment of the participants. The study also validated the app's child-friendly design.","2474-0489","978-1-7281-4540-2","10.1109/VS-Games.2019.8864547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864547","augmented reality;special needs education;field study;children","Pediatrics;Cameras;Interviews;Tutorials;Visualization;Augmented reality","augmented reality;computer aided instruction;handicapped aids;user interfaces","Fancy Fruits;augmented reality application;Special Needs Education;virtual worlds;educational application;disabled children;regional fruits;vegetables;marker-based AR elements;virtual information;mental disabilities","","4","","17","IEEE","14 Oct 2019","","","IEEE","IEEE Conferences"
"Augmented Reality Application to Emergency Systems with Usage of SLAM","A. Sochenkova; N. Podzharaya; K. Samouylov","Applied Probability and Informatics, RUDN University, Moscow, Russian Federation; Applied Probability and Informatics, RUDN University, Moscow, Russian Federation; Applied Probability and Informatics, RUDN University, Moscow, Russian Federation","2019 8th Mediterranean Conference on Embedded Computing (MECO)","15 Jul 2019","2019","","","1","4","Nowadays modern devices and new technologies are applied in a wide sphere of human activities. The purpose of this paper is to consider the possibilities of smart phone usage when some emergency situation occurs to help people to escape the building. Therefore, it is suggested to use such technology as augmented reality. In current study analysis of the available technologies is presented, sample application for providing experiments was developed.","2637-9511","978-1-7281-1740-9","10.1109/MECO.2019.8760019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760019","augmented reality;emergency systems;indoor navigation;security","Buildings;Simultaneous localization and mapping;Augmented reality;Task analysis;Navigation;Wireless LAN;Real-time systems","augmented reality;emergency management;mobile computing;SLAM (robots);smart phones","emergency situation;augmented reality application;emergency systems;SLAM;smart phone usage","","4","","16","IEEE","15 Jul 2019","","","IEEE","IEEE Conferences"
"Augmented reality in laboratory-based education: Could it change the way students decide about their future studies?","I. -E. Lasica; K. Katzis; M. Meletiou-Mavrotheris; C. Dimopoulos",European University of Cyprus; European University of Cyprus; European University of Cyprus; European University of Cyprus,"2017 IEEE Global Engineering Education Conference (EDUCON)","8 Jun 2017","2017","","","1473","1476","Several studies have focused on the different types of laboratories arising with the evolution of technology and their influence within all educational levels concerning Science, Technology, Engineering and Mathematics (STEM) Education. Augmented Reality (AR) is receiving increased attention and interest in recent years, within not only the commercial and the entertainment sectors, but also the educational field. In this paper, some current trends are identified after a brief overview of the state-of-the-art concerning Laboratory-based education. Moreover, challenges are discussed and potential future areas of research are identified. Finally, an outline of a methodology is suggested aiming to identify how the use of different types of labs may affect students' enrollment in STEM-related studies.","2165-9567","978-1-5090-5467-1","10.1109/EDUCON.2017.7943042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7943042","Augmented Reality;Laboratory-based Education;STEM Education;Distance Learning","Laboratories;Augmented reality;STEM;Market research;Computer aided instruction;Context","augmented reality;computer aided instruction;laboratories;STEM","AR;science technology engineering and mathematics education;STEM education;laboratory-based education;augmented reality","","4","","30","IEEE","8 Jun 2017","","","IEEE","IEEE Conferences"
"VECAR: Virtual English Classroom with Markerless Augmented Reality and Intuitive Gesture Interaction","M. -T. Yang; W. -C. Liao; Y. -C. Shih","NDHU, Hualien, Taiwan; NDHU, Hualien, Taiwan; NDHU, Hualien, Taiwan","2013 IEEE 13th International Conference on Advanced Learning Technologies","19 Sep 2013","2013","","","439","440","Augmented Reality (AR) is a technology that merges virtual objects with real-world images seamlessly. The power of real-time interaction and complete immersion makes AR ideal for language learning in that the exposure and motivation are two important factors. Therefore, we propose a Virtual English Classroom empowered with marker less AR technologies and 3D gesture interactions, called VECAR. The proposed vision-based interface is intuitive and convenient for users to play around with free hands, without the need of keyboard and mouse. The objective of VECAR is to make English teaching more interesting to increase learners' motivations.","2161-377X","978-0-7695-5009-1","10.1109/ICALT.2013.134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601976","English Teaching;Markerless Augmented Reality;3D Gesture Interaction","Three-dimensional displays;Augmented reality;Education;Thumb;Cameras;Keyboards","augmented reality;computer aided instruction;gesture recognition;teaching","VECAR;virtual english classroom;markerless augmented reality;intuitive gesture interaction;AR;language learning;exposure factor;motivation factor;3D gesture interaction;vision-based interface;English teaching;learner motivation","","4","","6","IEEE","19 Sep 2013","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality Mashup for Furture IoT Environment","C. Shin; B. -H. Park; G. -M. Jung; S. -H. Hong","Realistic Media Research Platform Center, Korea Electronics Technologies Institute, Seoul, Republic of Korea; Realistic Media Research Platform Center, Korea Electronics Technologies Institute, Seoul, Republic of Korea; Realistic Media Research Platform Center, Korea Electronics Technologies Institute, Seoul, Republic of Korea; Realistic Media Research Platform Center, Korea Electronics Technologies Institute, Seoul, Republic of Korea","2014 IEEE 11th Intl Conf on Ubiquitous Intelligence and Computing and 2014 IEEE 11th Intl Conf on Autonomic and Trusted Computing and 2014 IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops","26 Oct 2015","2014","","","888","891","This paper proposes a mobile augmented reality content mash up tool for generating new contents over the real world that utilizes cyber contents corresponding to real objects. The proposed mash up tool gathers relevant contents through web services by utilizing mobile sensing and context-awareness. It then combines them with real objects aided by automatic mash up and user participation. During mash up, users are allowed to generate new contents based on web contents and real objects for their purpose, while the mash up tool automatically combines contents and real objects. Furthermore, the contents are shared among other users and used to easily and efficiently generate new mash up services. We expect that the proposed mash up tool enables users to generate and share mash up services and this continuous usage of mash up can contribute to supporting a future IoT environment.","","978-1-4799-7646-1","10.1109/UIC-ATC-ScalCom.2014.131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307059","mobile augmented reality;context-awareness;mobile mashup","Mashups;Mobile communication;Mobile handsets;Augmented reality;Visualization;Context;Three-dimensional displays","augmented reality;Internet of Things;mobile computing","furture IoT environment;mobile augmented reality content mashup tool;cyber contents;mashup tool;mobile sensing;context-awareness;automatic mashup;user participation;Web contents","","4","","12","IEEE","26 Oct 2015","","","IEEE","IEEE Conferences"
"The Application of Augmented Reality in English Phonics Learning Performance of ESL Young Learners","I. -C. Chen","Graduate School of Education Communications & Technology, National Taipei Uviversity of Education, Taipei, Taiwan","2018 1st International Cognitive Cities Conference (IC3)","9 Dec 2018","2018","","","255","259","Phonics is an essential foundation needed to build up reading and writing abilities for English learning. However, most students who learned English as a second language have not learned phonics systematically and appropriately, resulting in failed pronunciation in reading and writing English words. For eliminating struggles and barriers in the process of English learning, the new technology and interactive apps are a dynamic avenue assisting with understanding and retention for ESL elementary students. The study was conducted with augmented reality (AR) technology to integrate virtual objects and video clips into the interactive learning environment for second language learning. The effects of students' phonics learning performance were assessed. The results indicated that AR technology had validated the possibility of carrying out digital immersive language learning and embodied cognition, regardless of the drills of rote memorization. The concerns of the curriculum design based on the incorporation of the AR technology and learning materials are discussed further to improve phonics efficiency and competency for English as second language learners.","","978-1-5386-5059-2","10.1109/IC3.2018.000-7","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567219","augmented reality, phonics learning, ESL","Games;Education;Augmented reality;Vocabulary;Writing;Bridges;Visualization","augmented reality;computer aided instruction","ESL young learners;writing abilities;English learning;ESL elementary students;augmented reality;interactive learning environment;AR technology;digital immersive language learning;learning materials;phonics efficiency;language learners;English phonics learning performance","","4","","12","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
"Integrating Assessment into Augmented Reality-Based Learning Environments","M. -B. Ibáñez; D. Villarán; C. Delgado-Kloos","Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Madrid, Spain; Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Madrid, Spain; Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Madrid, Spain","2015 IEEE 15th International Conference on Advanced Learning Technologies","17 Sep 2015","2015","","","218","222","This paper presents how to take advantage of the interactive capabilities of augmented reality (AR) technology to deploy assessment activities into AR-based learning environments. It shows how to combine physical and digital spaces to design authentic, meaningful tasks where students can put into practice their skills for solving problems. The use of the framework in real scenarios illustrates its suitability for the deployment of assessment activities into AR-based learning environments.","2161-377X","978-1-4673-7334-0","10.1109/ICALT.2015.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7265309","augmented reality learning systems;computer assisted assessment;next generation learning spaces;technology-enhanced assessment","Augmented reality;Context;Conductors;Computers;Aerospace electronics;Integrated circuit modeling;Shape","augmented reality;computer aided instruction","augmented reality-based learning environments;interactive capabilities;AR technology;physical spaces;digital spaces;student skills;assessment activities deployment;AR-based learning environments","","4","","13","IEEE","17 Sep 2015","","","IEEE","IEEE Conferences"
"Object Visualization Using Maps Marker Based On Augmented Reality","D. E. Kurniawan; A. Dzikri; M. Suriya; Y. Rokhayati; A. Najmurrokhman","Departement of Informatics Engineering, Politeknik Negeri Batam, Batam, Indonesia; Departement of Informatics Engineering, Politeknik Negeri Batam, Batam, Indonesia; Departement of Informatics Engineering, Politeknik Negeri Batam, Batam, Indonesia; Departement of Informatics Engineering, Politeknik Negeri Batam, Batam, Indonesia; Department of Electrical Engineering, Universitas Jenderal Ahmad Yani, Bandung, Indonesia","2018 International Conference on Applied Engineering (ICAE)","20 Dec 2018","2018","","","1","5","Augmented Reality (AR) is a technology that combines the real world with a virtual object be it a two dimension object (2D) or three dimensions (3D) in real time. The development of AR technology has contributed a lot in various fields, one of the areas of tourism. AR in tourism can help guide tourists to explore objects in real terms. This research applies AR technology as a tour guide on Batam Island using 3D objects are applied into the building of the tour by using the method marker based tracking. The application is built using software Unity and Vuforia. The main function of this application is to display 3D tourist object that exists in a map and show the location to the tourist attraction. Result testing is done with pixel marker test, running object test, and angular position test.","","978-1-5386-8066-7","10.1109/INCAE.2018.8579411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579411","3D Object;Augmented Reality;Map Marker;Tourism","Three-dimensional displays;Augmented reality;Testing;Software;Real-time systems;Cameras;Games","augmented reality;travel industry","object visualization;maps marker;augmented Reality;virtual object;AR technology;tourism;tour guide;Batam Island;3D tourist object;tourist attraction;pixel marker test;marker based tracking","","4","","19","IEEE","20 Dec 2018","","","IEEE","IEEE Conferences"
"Influence of the Camera Viewpoint on Augmented Reality Interaction","G. M. N. Taira; A. C. Sementille; S. R. R. Sanches","Universidade Tecnologica Federal do Parana, Curitiba, PR, BR; Universidade Estadual Paulista Julio de Mesquita Filho, Sao Paulo, SP, BR; Universidade Tecnologica Federal do Parana, Curitiba, PR, BR","IEEE Latin America Transactions","14 Feb 2018","2018","16","1","260","264","Many Augmented Reality (AR) applications run on conventional platforms such as desktops or laptops. Desktop applications usually display the 3D environment through a 2D screen while an external webcam attached to the computer performs the capture of the scene. In these applications, the camera viewpoint is an important factor since it can facilitate or hinder accuracy in tasks performed. The objective of this research is to find the optimal camera viewpoint for a desktop AR environment.","1548-0992","","10.1109/TLA.2018.8291482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291482","Augmented Reality;Camera Viewpoint;User Perception","Cameras;Portable computers;Visualization;Augmented reality;IEEE transactions;Three-dimensional displays;Two dimensional displays","augmented reality;cameras","laptops;desktop applications;external webcam;optimal camera viewpoint;desktop AR environment;augmented reality interaction;3D environment;2D screen","","4","","","IEEE","14 Feb 2018","","","IEEE","IEEE Journals"
"3D-Camera for Scene Capturing and Augmented Reality Applications","T. Bothe; A. Gesierich; W. Li; C. v. Kopylow; N. Kopp; W. Juptner","Bremer Institut für Angewandte Strahltechnik GmbH, Germany; VEW-Vereinigte Elektronikwerkstätten Bremen, Germany; VEW-Vereinigte Elektronikwerkstätten Bremen, Germany; VEW-Vereinigte Elektronikwerkstätten Bremen, Germany; VEW-Vereinigte Elektronikwerkstätten Bremen, Germany; Bremer Institut für Angewandte Strahltechnik GmbH, Germany","2007 3DTV Conference","12 Nov 2007","2007","","","1","4","Coordinate based 3D multimedia applications benefit from cost effective, compact and easy-to-use profilers like the miniaturized 3D-Camera that works on basis of the fringe projection technique. The system uses a compact housing and is usable like a video camera with minimum stabilization like a tripod. Camera and projector are assembled with parallel optical axes having coplanar projection and imaging planes. Their axes distance is comparable to the human eyes' distance, giving a compact system of shoebox-size and allow measuring high gradient objects like the interior of tubes and delivering captured scenes with minimum loss by shadowing. Additionally, the 3D-Camera can be used for the Inverse Projection technique, allowing single-frame video rate capture and to virtually place information like virtual labels or defect maps onto the surface of objects, thus, allowing augmented reality applications. In this paper, the concept and realization of the 3D-Camera is described and an overview of possible applications is given.","2161-203X","978-1-4244-0721-7","10.1109/3DTV.2007.4379467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379467","Fringe projection;3-D shape measurement;3D coordinates;scene capture;inverse projection;augmented reality","Layout;Augmented reality;Cameras;Assembly;Optical imaging;Humans;Eyes;Loss measurement;Optical losses;Shadow mapping","augmented reality;cameras","3D-camera;scene capturing;augmented reality;3D multimedia applications;fringe projection;video camera;parallel optical axes;coplanar projection;imaging planes;inverse projection;single-frame video rate capture","","4","","8","IEEE","12 Nov 2007","","","IEEE","IEEE Conferences"
"Enhancing hand interaction patterns for virtual objects in mobile augmented reality using marker-less tracking","Vidya K.; Deryl R.; Dinesh K.; Rajabommannan S.; Sujitha G.","Department of information science and technology, Anna University, Chennai, India; Department of information science and technology, Anna University, Chennai, India; Department of information science and technology, Anna University, Chennai, India; Department of information science and technology, Anna University, Chennai, India; Department of information science and technology, Anna University, Chennai, India","2014 International Conference on Computing for Sustainable Global Development (INDIACom)","12 Jun 2014","2014","","","705","709","Augmented Reality (AR) has really become popular in the past few years with the emergence of smartphones which provide processing power to AR based applications. Most smart phone based AR applications are limited in user interaction they provide with most employing touch based interaction. The goal of the research is to provide support for gesture based interaction to virtual content generated in user phones. The hand detection algorithm has been designed in such a way to leverage the low processing capability of smart phones.","","978-93-80544-12-0","10.1109/IndiaCom.2014.6828052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6828052","Augmented Reality;Android;Finger Tracking;Gesture Recognition;Hand-based Interaction;Marker-less Tracking","Handheld computers;Decision support systems;Augmented reality;Conferences;Mobile handsets;Mobile communication;Human factors","augmented reality;gesture recognition;smart phones","hand interaction patterns;virtual objects;mobile augmented reality;markerless tracking;AR;smart phones;user interaction;touch based interaction;gesture based interaction;virtual content;hand detection algorithm","","4","","16","","12 Jun 2014","","","IEEE","IEEE Conferences"
"Virtual Shoe Fitting System that Uses Augmented Reality to Measure Feet and Try on Shoes","H. Bizen; M. Yoshida; M. Jimbu; Y. Kawai","Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan","2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech)","8 Apr 2021","2021","","","217","219","It is difficult to buy a pair of shoes that fit your feet because you can't try them on at the online shopping site. In this study, we proposed a system that uses augmented reality to measure the size of a foot and introduce a shoe that fits the user's foot. This system makes it possible to confirm the comfort of the shoes by visualizing the pressure points on the feet when trying them on.","","978-1-6654-1875-1","10.1109/LifeTech52111.2021.9391966","JSPS KAKENHI(grant numbers:JP 19K12665); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391966","shoe;foot;fitting;augmented reality;e-commerce","Solid modeling;Visualization;Fitting;Footwear;Size measurement;Augmented reality;Foot","augmented reality;footwear;footwear industry;retail data processing","online shopping site;uses augmented reality;virtual shoe fitting system;measure feet","","4","","7","IEEE","8 Apr 2021","","","IEEE","IEEE Conferences"
"Research on the augmented reality system without identification markers for home exhibition","L. Chen; X. Peng; J. Yao; H. Qiguan; C. Chen; Y. Ma","Software school of Xiamen University, Xiamen, China; Software school of Xiamen University, Xiamen, China; Software school of Xiamen University, Xiamen, China; Software school of Xiamen University, Xiamen, China; Software school of Xiamen University, Xiamen, China; Software school of Xiamen University, Xiamen, China","2016 11th International Conference on Computer Science & Education (ICCSE)","6 Oct 2016","2016","","","524","528","This paper discusses a system based on Augmented Reality for Home Exhibition, which supports real-time tracking without Identification Markers, the system uses FAST corner detection and local window matching algorithm to establish the initial 3D maps. It then uses OpenGL ES Graphics Rendering Tools to make the virtual furniture models which established by MAYA on the mobile phone based on the real-time camera pose.","","978-1-5090-2218-2","10.1109/ICCSE.2016.7581635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581635","augmented reality;feature detection;virtual home exhibition","Three-dimensional displays;Feature extraction;Cameras;Solid modeling;Data models;Real-time systems;Augmented reality","augmented reality;edge detection;exhibitions;feature extraction;furniture;home computing;image matching;rendering (computer graphics)","augmented reality system;home exhibition;real-time tracking;FAST corner detection;features from accelerated segment test;local window matching algorithm;3D map establishment;OpenGL ES graphics rendering tool;virtual furniture model","","4","","10","IEEE","6 Oct 2016","","","IEEE","IEEE Conferences"
"Development of a myoelectric prosthesis simulator using augmented reality","W. Nishino; Y. Yamanoi; Y. Sakuma; R. Kato","Yokohama National University, Yokohama, Japan; Yokohama National University, Yokohama, Japan; Yokohama National University, Yokohama, Japan; Yokohama National University, Yokohama, Japan","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","30 Nov 2017","2017","","","1046","1051","A myoelectric prosthesis, which can be used as a replacement for a person's upper limb, is able to control many hand motions optionally via surface electromyography (sEMG). Although many researchers have developed myoelectric prostheses that realize various motions, evaluation of their practicality has only been carried out on small numbers of patients. To solve this problem, a myoelectric prosthesis simulator that is able to move like a real prosthesis is needed. In this study, such a simulator that enables persons to grasp virtual objects with virtual prostheses was developed using Augmented Reality (AR). The results of comparative experiments conducted to evaluate the developed system using a pick and place task show that although it is not at present as effective as real prostheses, a virtual prosthesis is able to grasp virtual objects in the proposed simulator.","","978-1-5386-1645-1","10.1109/SMC.2017.8122749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8122749","virtual and augmented reality systems;image processing/pattern recognition;myoelectric prosthesis","Prosthetics;Cameras;Mathematical model;Force;Artificial neural networks;Torque;Augmented reality","augmented reality;electromyography;medical control systems;medical signal processing;prosthetics","myoelectric prosthesis simulator;augmented reality;hand motions;surface electromyography;virtual objects;virtual prostheses;pick-and-place-task","","4","","9","IEEE","30 Nov 2017","","","IEEE","IEEE Conferences"
"The Impact of a Mobile Augmented Reality Game: Changing Students' Perceptions of the Complexity of Socioscientific Reasoning","H. -Y. Chang; Y. -T. Yu; H. -K. Wu; Y. -S. Hsu","Graduate Institute of Digital Learning and Education, National Taiwan University of Science and Technology, NTUST, Taipei, Taiwan; Graduate Institute of Science Education, National Taiwan Normal University, NTNU, Taipei, Taiwan; Department of Software Engineering and Management, National Kaohsiung Normal University, NKNU, Kaohsiung, Taiwan; Graduate Institute of Science Education, National Taiwan Normal University, NTNU, Taipei, Taiwan","2016 IEEE 16th International Conference on Advanced Learning Technologies (ICALT)","1 Dec 2016","2016","","","312","313","In this paper we introduce our newly developed mobile augmented reality game that engages students in investigating a socioscientific issue (SSI) to decide on remedies for a campus site on which part of the soil was hypothetically polluted by a nuclear accident. The game allows students to collect virtual radiation data and interview virtual characters on the campus. The results indicate that the students gained knowledge and perceived the SSI as not that complex after learning with the AR game.","2161-377X","978-1-4673-9041-5","10.1109/ICALT.2016.131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7756985","mobile game;augmented reality;socioscientific issue;perception","Games;Proposals;Mobile communication;Decision making;Augmented reality;Cognition;Education","augmented reality;computer aided instruction;computer games;mobile learning;social sciences computing","AR game;virtual characters;virtual radiation data;nuclear accident;campus site;SSI;socioscientific reasoning complexity;student perceptions;mobile augmented reality game","","4","","7","IEEE","1 Dec 2016","","","IEEE","IEEE Conferences"
"Augmented Reality for maintenance operator training using SURF points and homography","A. Paz; M. L. Guenaga; A. Eguíluz","Deusto Foundation, DeustoTech Learning, Bilbao, Spain; Deusto Foundation, DeustoTech Learning, Bilbao, Spain; Deusto Foundation, DeustoTech Learning, Bilbao, Spain","2012 9th International Conference on Remote Engineering and Virtual Instrumentation (REV)","3 Sep 2012","2012","","","1","4","We present a system, PortableAR, that aims to provide Augmented Reality (AR) to diverse environments, like guided tourism visits or industrial maintenance tasks. The first version relied on AR tags and had low accuracy while the last version provides a successful AR experience using SURF and homography.","","978-1-4673-2542-4","10.1109/REV.2012.6293130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6293130","Augmented Reality;Homography;SURF","Maintenance engineering;Cameras;Augmented reality;Calibration;Training;Prototypes;Accuracy","augmented reality;computer based training;industrial training;maintenance engineering;production engineering computing","augmented reality;maintenance operator training;SURF points;homography;PortableAR;diverse environments;guided tourism visits;industrial maintenance tasks","","4","","8","IEEE","3 Sep 2012","","","IEEE","IEEE Conferences"
"Design and Development of an Augmented Reality Mobile Application for Medical Training","K. -H. Leung; K. Hung; C. -P. Ko; S. -F. Lo","School of Science and Technology, The Open University of Hong Kong, Hong Kong, China; School of Science and Technology, The Open University of Hong Kong, Hong Kong, China; Department of Anaesthesia and Intensive Care, The Chinese University of Hong Kong, Hong Kong, China; Department of Anaesthesia and Intensive Care, The Chinese University of Hong Kong, Hong Kong, China","2019 IEEE 6th International Conference on Engineering Technologies and Applied Sciences (ICETAS)","16 Jun 2020","2019","","","1","4","The ageing population has led to increasing demand for additional medical staff and training resources. However, the cost of medical training equipment is costly. Considering that augmented reality (AR) technology has been shown to enhance training experience and trainer-trainee interactions in various sectors, the aim of this project is to develop a low-cost AR mobile application framework, which is expandable for use in various medical training modules. On the displays of the trainers' and trainees' mobile devices, the application overlays AR effects that simulate physiological symptoms onto a training manikin. Under the control of the trainer, the effects can be changed for evaluating the trainee's timely responses. Initial trials focused on anesthetic injection-induced rash effects. The application was tested on three mobile platforms under different environmental settings, and was found to function satisfactorily.","","978-1-7281-4082-7","10.1109/ICETAS48360.2019.9117464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9117464","medical training;augmented reality;mobile application;Android;Unity;Vuforia","Training;Sociology;Mobile handsets;Physiology;Mobile applications;Statistics;Augmented reality","augmented reality;biomedical education;biomedical equipment;computer based training;mobile computing","training resources;medical training equipment;training experience;trainer-trainee interactions;medical training modules;trainees;training manikin;mobile platforms;augmented reality mobile application;ageing population;additional medical staff;AR mobile application framework","","4","","16","IEEE","16 Jun 2020","","","IEEE","IEEE Conferences"
"Very High Brightness, High Resolution CMOS Driving Circuit for Microdisplay in Augmented Reality","M. VIGIER; T. PILLOIX; B. DUPONT; G. MORITZ","CEA LETI, Univ. Grenoble Alpes, Grenoble, France; CEA LETI, Univ. Grenoble Alpes, Grenoble, France; CEA LETI, Univ. Grenoble Alpes, Grenoble, France; CEA LETI, Univ. Grenoble Alpes, Grenoble, France","2020 IEEE 63rd International Midwest Symposium on Circuits and Systems (MWSCAS)","2 Sep 2020","2020","","","876","879","In augmented reality applications, high brightness at high resolution is crucial to guarantee a good user experience. Explorations on efficient light sources have already been undertaken, and GaN μLEDs tend to be a good candidate. Nevertheless, micro-display driving circuits usually do not provide sufficient luminance level to offer good contrast against ambient light. We report the design and fabrication of a GaN LED microdisplay driving circuit, designed in a 0.18μm CMOS process with a 1640×1033 resolution. Each LED is controlled individually by a CMOS pixel with a 9.5μm pitch. The monochrome green microdisplay enables more than the WSXGA resolution and can reach 3.8MCd/m2 for a fully ON micro-LED array. This driving circuit enables, to our knowledge, the highest brightness for such a pixel pitch and resolution.","1558-3899","978-1-7281-8058-8","10.1109/MWSCAS48704.2020.9184480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184480","microdisplay driving circuit;GaN micro-LED;high brightness;augmented reality;pulse width modulation;HUD;near-to-eye","Light emitting diodes;Microdisplays;Gallium nitride;Brightness;Image color analysis;Color;Augmented reality","augmented reality;brightness;CMOS integrated circuits;driver circuits;gallium compounds;III-V semiconductors;microdisplays;microfabrication;wide band gap semiconductors","monochrome green microdisplay driving circuits;highest brightness;microLED array;WSXGA resolution;CMOS process;microdisplay driving circuit;luminance level;μLED;light sources;augmented reality applications;high resolution CMOS driving circuit;size 0.18 mum;GaN","","4","","11","IEEE","2 Sep 2020","","","IEEE","IEEE Conferences"
"Engaging computer engineering students with an augmented reality software for laboratory exercises","J. R. L. Benito; E. A. González; M. Anastassova; F. Souvestre","CreativiTIC Innova S.L. La Rioja, Spain; CreativiTIC Innova S.L., La Rioja, Spain; CEA LIST, Sensory and Ambient Interfaces Laboratory, Gif-sur-Yvette Cedex, France; CEA LIST, Sensory and Ambient Interfaces Laboratory, Gif-sur-Yvette Cedex, France","2014 IEEE Frontiers in Education Conference (FIE) Proceedings","19 Feb 2015","2014","","","1","4","Work in Progress: Augmented reality (AR) is an emerging technology of high potential. It has already been applied in educational fields, although its usefulness and usability have not always being empirically tested and validated. This paper proposes the development of an AR software helping Computer Engineering students understand concepts and processes in embedded systems during laboratory exercises. The design of the software's field of action has been realized taking into account a task taxonomy, based on research in cognitive and educational psychology, and students' needs established using questionnaires and interviews. The AR software has been developed under the premises of reliability, robustness and handiness. Its effectiveness and usability will be initially evaluated within the consortium of the project. Afterwards, using this feedback, the software will be further improved and introduced in real laboratory practices at universities.","2377-634X","978-1-4799-3922-0","10.1109/FIE.2014.7044094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7044094","augmented reality;education;embedded systems;laboratory exercises;computer engineering","Augmented reality;Computers;Visualization;Usability;Prototypes;Laboratories","augmented reality;cognition;computer aided instruction;computer science education;embedded systems;laboratories;psychology","computer engineering student engagement;augmented reality software;laboratory exercises;AR software;educational fields;computer engineering students;embedded systems;task taxonomy;cognitive psychology;educational psychology;student needs;reliability analysis;robustness analysis;handiness analysis;project consortium;software improvement;real laboratory practices","","4","","18","IEEE","19 Feb 2015","","","IEEE","IEEE Conferences"
"Augmented Reality Game System Design for Stroke Rehabilitation Application","R. -G. Lee; S. -C. Tien","Graduate Institute of Computer and Communication Engineering, National Taipei University of Technology, Taipei, Taiwan; Graduate Institute of Computer and Communication Engineering, National Taipei University of Technology, Taipei, Taiwan","2012 Fourth International Conference on Computational Intelligence, Communication Systems and Networks","23 Aug 2012","2012","","","339","342","By integrating the entertainment of games and the needs of rehabilitation, and utilizing Motor Assessment Scale (MAS) as the building blocks, we propose a game system developed for assessment of stroke rehabilitation by using augmented reality (AR) technology. By means of application of AR Markers and based on related parameters of Wii remotes, various assessment games have been implemented, and vivid pictures can be presented to users via a head-mounted display by seamless combination of real environment and virtual objects. This game system takes various assessment scales into consideration, and each scale is specifically designed and individually integrated to enable the relevant capacity for assessment of motor functions. According to the experimental results, the accuracy rate for users to successfully follow the game steps is 91.2%, and the accuracy rate of the system to assess the MAS categories is as high as 94.6%, which confirms the feasibility of our proposed and implemented rehabilitation game system.","","978-1-4673-2640-7","10.1109/CICSyN.2012.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6274365","cerebral vascular accident (CVA) / Stroke rehabilitation;Motor Function Assessment Scale;Augmented reality;Head-mounted displays;Wii Remote","Games;Accuracy;Augmented reality;Joints;Computers;Extremities","augmented reality;computer games;medical computing;patient rehabilitation","augmented reality game system design;stroke rehabilitation application;motor assessment scale;AR markers;Wii remotes;head-mounted display","","4","","12","IEEE","23 Aug 2012","","","IEEE","IEEE Conferences"
"A 3D interaction technique for selection and manipulation distant objects in augmented reality","A. Bellarbi; N. Zenati; S. Otmane; H. Belghit; S. Benbelkacem; A. Messaci; M. Hamidia","CDTA, Algiers, Algeria; CDTA, Algiers, Algeria; CDTA, Algiers, Algeria; CDTA, Algiers, Algeria; CDTA, Algiers, Algeria; CDTA, Algiers, Algeria; IBISC Lab, Evry University","2017 5th International Conference on Electrical Engineering - Boumerdes (ICEE-B)","14 Dec 2017","2017","","","1","5","3D object selection and manipulation is one of the essential features for any augmented reality (AR) system. However, distant object selection and manipulation still suffer from lack of accuracy and precision. This paper introduces an alternate 3D interaction technique for selection and manipulation distant 3D object in in immersive video see-through AR. The proposed interaction technique offers a high precision when selecting and manipulation distant objects thanks to the zooming-based idea. This later, allows bringing closer both real and virtual objects during maintaining the spatio-temporal registration between the virtual and the real scenes. The evaluation of our proposed approach and the comparison with other well-known techniques are given at the end of this paper.","","978-1-5386-0686-5","10.1109/ICEE-B.2017.8192012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8192012","Augmented reality;3D interaction techniques;Pose Estimation;Computer vision","Three-dimensional displays;Cameras;Augmented reality;Games;Mathematical model;Pose estimation","augmented reality;interactive systems","augmented reality system;distant object selection;interaction technique;virtual objects;3D interaction;distant object manipulation;3D object selection;immersive video see-through AR;zooming-based idea;spatio-temporal registration","","4","","28","IEEE","14 Dec 2017","","","IEEE","IEEE Conferences"
"Development of sea route display system by using augmented reality","T. Okazaki; R. Takaseki; R. Shoji; K. Matsubara","Department of Maritime System Engineering, Tokyo University of Marine Science and Technology, Tokyo, Japan; Department of Maritime System Engineering, Tokyo University of Marine Science and Technology, Tokyo, Japan; Department of Maritime System Engineering, Tokyo University of Marine Science and Technology, Tokyo, Japan; Department of Maritime System Engineering, Tokyo University of Marine Science and Technology, Tokyo, Japan","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","30 Nov 2017","2017","","","3403","3408","A navigator draws a route on a chart to navigate a ship from an origin port to a destination port. Then, the navigator sails the ship based on the route. In other word, the navigator misidentifies the route there is a possibility of running aground. In order to prevent navigator's misidentifies, this study proposed a sea route display system which displays the sea route on the surface of the sea by using augmented reality so that navigator may grasp the ship's position from the sea route easily. Effectiveness of the developed system was carried out with actual ship experiment.","","978-1-5386-1645-1","10.1109/SMC.2017.8123156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8123156","navigation support system;augmented reality;sea route","Navigation;Marine vehicles;Visual systems;Sea measurements;Cameras;Three-dimensional displays;Augmented reality","augmented reality;marine communication;ships","ship;augmented reality;sea route display system","","3","","7","IEEE","30 Nov 2017","","","IEEE","IEEE Conferences"
"Projection-Based Augmented Reality Robot Prototype with Human-Awareness","H. Ro; J. -H. Byun; I. Kim; Y. J. Park; K. Kim; T. -D. Han","Media System Lab, Yonsei University, Seoul, Republic of Korea; Media System Lab, Yonsei University, Seoul, Republic of Korea; Media System Lab, Yonsei University, Seoul, Republic of Korea; Media System Lab, Yonsei University, Seoul, Republic of Korea; Media System Lab, Yonsei University, Seoul, Republic of Korea; Media System Lab, Yonsei University, Seoul, Republic of Korea","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","25 Mar 2019","2019","","","598","599","Since projection augmented reality (AR) robot can provide a lot of information through projector, it can be useful in museums and art galleries that need to provide information to the crowd. Therefore, it is necessary to continue to interact with people, and human-aware path planning is also needed. We prototyped projection AR mobile robot implemented human-aware path planning and wrote about future research direction.","2167-2148","978-1-5386-8555-6","10.1109/HRI.2019.8673173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673173","Projection Augmented Reality;Human-aware Path Planning;Service Robot;Mobile Robot;Human-robot Interaction","Path planning;Mobile robots;Service robots;Software;Augmented reality;Hardware","art;augmented reality;control engineering computing;mobile robots;museums;path planning","projection-based augmented reality robot prototype;art galleries;human-aware path planning;projection AR mobile robot;museums","","3","","4","IEEE","25 Mar 2019","","","IEEE","IEEE Conferences"
"Energy Consumption Minimization Control for Augmented Reality Applications based on Multi-core Smart Devices","S. Song; J. Kim; J. -M. Chung","School of Electrical & Electronic Engineering, Yonsei University, Seoul, Republic of Korea; School of Electrical & Electronic Engineering, Yonsei University, Seoul, Republic of Korea; School of Electrical & Electronic Engineering, Yonsei University, Seoul, Republic of Korea","2019 IEEE International Conference on Consumer Electronics (ICCE)","7 Mar 2019","2019","","","1","4","Augmented Reality (AR) applications are becoming more and more popular, and smart devices are the most common platform for running AR applications, such as online games, travel guides, and personal assistants. However, these types of AR applications are usually interactive applications that require fast response time and an extremely high power consumption. AR applications need to be supported by highly adaptable multi-core processors equipped smart devices where the optimal low-power control technique, should be used. In this paper, the power consumption model of AR application workloads are mathematically modeled, taking into account the dynamic voltage and frequency scaling (DVFS) of the multi-core central processing unit (CPU) and the parallel execution of multi-core CPUs. Based on the proposed model, the optimal core operation frequency and minimized power consumption are derived. Experimental results show that the proposed scheme satisfies the interaction time limit with the lowest energy consumption.","2158-4001","978-1-5386-7910-4","10.1109/ICCE.2019.8661917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8661917","Energy;smartphone;augmented reality;parallel process","Energy consumption;Time factors;Power demand;Parallel processing;Time-frequency analysis;Mathematical model;Augmented reality","augmented reality;control engineering computing;low-power electronics;microprocessor chips;minimisation;multiprocessing systems;optimal control;power aware computing;power consumption;power control","energy consumption minimization control;augmented reality applications;multicore smart devices;online games;highly adaptable multicore processors;power consumption model;AR application workloads;multicore central processing unit;multicore CPUs;optimal core operation frequency;optimal low-power control technique;dynamic voltage and frequency scaling;DVFS","","3","","10","IEEE","7 Mar 2019","","","IEEE","IEEE Conferences"
"Design and Development of an Augmented Reality Tracing Application for Kindergarten Students","A. Nigam; K. K. Bhagat; M. Chandrakar; P. Goswami","Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, India; Indian Institute of Technology, Kharagpur, Kharagpur, India; Indian Institute of Technology, Kharagpur, Kharagpur, India; University College of Engineering and Technology, Hazaribagh, India","2019 IEEE Tenth International Conference on Technology for Education (T4E)","6 Feb 2020","2019","","","240","241","Children at the age of 3 to 5 years, start to learn language writing by tracing over alphabets. They start by joining the dots marked on books to create an alphabet. However, this learning process is not very effective in engaging children for active and creative learning. In this paper, we present an Augmented Reality Tracing (ART) application that creates an interactive learning environment for kids. Although the basic idea of tracing remains the same, ART allows children to recognize the mistracing or deviation and encourages them to trace better in the next trial. Therefore, the application would enhance children's language writing experience and motivate them for self-learning.","","978-1-7281-4227-2","10.1109/T4E.2019.00-14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8983762","Augmented Reality;Kindergarten;Language Learning;Tracing;Psychology","Augmented reality;Education;Subspace constraints;Visualization;Writing;Cameras","age issues;augmented reality;computer aided instruction;human factors;interactive systems;linguistics;user experience","learning process;active learning;creative learning;interactive learning environment;kindergarten students;augmented reality tracing;children language writing experience;self-learning motivation;language writing learning;alphabet tracing","","3","","7","IEEE","6 Feb 2020","","","IEEE","IEEE Conferences"
"Gesture Interaction and Augmented Reality based Hand Rehabilitation Supplementary System","Y. Xue; L. Zhao; M. Xue; J. Fu","Faculty of Printing, Packaging Engineering and Digital Media Technology, Xi'an University of Technology; Faculty of Printing, Packaging Engineering and Digital Media Technology, Xi'an University of Technology; School of Economics and Administration, Xi'an University of Technology, Xi'an, China; Faculty of Printing, Packaging Engineering and Digital Media Technology, Xi'an University of Technology","2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","16 Dec 2018","2018","","","2572","2576","The existing systems of hand rehabilitation always design different rehabilitation medical apparatus and systems according to the patients' needs. This kind of system always contain problems such as complexity, using only single training programs, inconvenient to wear and high cost. For these reasons, this paper uses gesture recognition technology and augmented reality technology to design a simple and interactive hand rehabilitation supplementary system. The system uses a low-cost, non-contact device named Leap Motion as the input device, and Unity3D as the development engine, realizing three functional modules: conventional training, AR game training and auxiliary functions. This rehabilitation training project with different levels of difficulty increases the fun and challenge of the rehabilitation process. Users can use the system to assist the treatment activity of hand rehabilitation anytime and anywhere. The system, which has good application value, can also be used in other physical rehabilitation fields.","2381-0947","978-1-5386-4509-3","10.1109/IAEAC.2018.8577476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8577476","gesture recognition;augmented reality;leap motion;interaction;unity3D","Training;Games;Thumb;Augmented reality;Gesture recognition;Three-dimensional displays","augmented reality;gesture recognition;human computer interaction;medical computing;patient rehabilitation;patient treatment","gesture recognition technology;interactive hand rehabilitation supplementary system;AR game training;rehabilitation training project;rehabilitation medical apparatus;gesture interaction;augmented reality technology;Leap Motion;Unity3D","","3","","6","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Glove-Based Sensor Support for Dynamic Tangible Buttons in Spatial Augmented Reality Design Environments","B. H. Thomas; M. Smith; T. Simon; J. Park; J. Park; G. S. Von Itzstein; R. T. Smith","University of South Australia, Wearable Computer Laboratory, Adelaide, Australia; Department of Communications Systems, Swedish Royal Institute of Technology, Stockholm, Sweden; University of South Australia, Wearable Computer Laboratory, Adelaide, Australia; Department of Computer Science, Hongik University, Seoul, Korea; Department of Computer Science, Hongik University, Seoul, Korea; University of South Australia, Wearable Computer Laboratory, Adelaide, Australia; University of South Australia, Wearable Computer Laboratory, Adelaide, Australia","2011 15th Annual International Symposium on Wearable Computers","21 Jul 2011","2011","","","109","110","Spatial Augmented Reality has shown promising results to support the industrial design process, this paper explores improvements by incorporating tangible buttons to allow dynamically positioned controls with a wearable glove sensor system for simulating prototype design functionality. We present a system to support the low cost development of an active user interface that is not restricted to the two-dimensional surface of a traditional computer display.","2376-8541","978-1-4577-0774-2","10.1109/ISWC.2011.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5959577","Spatial Augmented Reality;RFID;Industrial Design","Radiofrequency identification;User interfaces;Augmented reality;Antennas;Prototypes;Calculators;Haptic interfaces","augmented reality;data gloves;interactive devices;wearable computers","glove based sensor support;dynamic tangible button;spatial augmented reality design environment;industrial design process;tangible buttons;wearable glove sensor system;prototype design functionality simulation;active user interface;two dimensional surface;computer display","","3","1","4","IEEE","21 Jul 2011","","","IEEE","IEEE Conferences"
"Hardware adaptation for multimedia application case study: Augmented reality","T. Frikha; N. Ben Amor; K. Lahbib; J. P. Diguet; M. Abid","Sfax University, National Engineering School of Sfax; Sfax University, National Engineering School of Sfax; Sfax University, National Engineering School of Sfax; Sfax University, National Engineering School of Sfax; Sfax University, National Engineering School of Sfax","2014 6th International Conference of Soft Computing and Pattern Recognition (SoCPaR)","15 Jan 2015","2014","","","411","417","Embedded electronic multimedia systems to a wide emerged in recent years. These systems are more complex and diversified. The SoC (System on Chip) must respect many important constraints. It must operate in extreme conditions (network problems, limited energy consumption…). In this paper, we present an adaptation technique based on the dynamic reconfiguration features of Xilinx FPGA. The purpose of this technique is to reduce the computing time of a complex multimedia application by adding a variable number of hardware computing units. A case study is presented on a real system using the Xilinx design environment to develop a 3D application. This used application is the augmented reality (AR).","","978-1-4799-5934-1","10.1109/SOCPAR.2014.7008042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7008042","embedded system;3D application;Partially Dynamic Reconfiguration (PDR);augmented reality (AR) profiling;Xilinx ML 507","Three-dimensional displays;Computer architecture;Field programmable gate arrays;Hardware;Augmented reality;Multimedia communication;Software","augmented reality;field programmable gate arrays;multimedia computing;system-on-chip","embedded electronic multimedia systems;augmented reality;SoC;system on chip;adaptation technique;Xilinx FPGA;3D application;partially dynamic reconfiguration feature","","3","","20","IEEE","15 Jan 2015","","","IEEE","IEEE Conferences"
"Implementation of a Preventive Maintenance System Based on Augmented Reality","R. Hamidane; L. H. MOUSS; A. Bellarbi; R. MAHDAOUI","Laboratoire Automatique et Productique (LAP) Université de Hadj Lakhdar, Batna, Algeria; Laboratoire Automatique et Productique (LAP) Université de Hadj Lakhdar, Batna, Algeria; Centre de Développement des Technologies Avancées (CDTA), Algiers, Algeria; Laboratoire Automatique et Productique (LAP) Université de Hadj Lakhdar, Batna, Algeria","2018 3rd International Conference on Pattern Analysis and Intelligent Systems (PAIS)","3 Jan 2019","2018","","","1","6","In this article, we present ARPM (Augmented Reality-based Preventive Maintenance) system, which aims at offering to the technician of a Cement Factory a virtual assistance in real time using various forms of 3D models, images or even texts, in order to help him to maintain and inspect his equipment. This system not only offers the possibility of reducing costs of the preventive maintenance, but also allows monitoring and even anticipating failures. In order to ensure a reliable maintenance operation, we adapted our system to be compatible with the CMMS system (Computerized Maintenance Management System) already exists in the Cement factory.","","978-1-5386-4238-2","10.1109/PAIS.2018.8598510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598510","Augmented Reality;CMMS;Preventive maintenance;Smartphone;AR glasses","Preventive maintenance;Augmented reality;Tools;Task analysis;Production facilities;Reliability","augmented reality;cement industry;cost reduction;failure analysis;inspection;preventive maintenance;production equipment;real-time systems","virtual assistance;cement factory;computerized maintenance management system;augmented reality-based preventive maintenance;real time systems;3D model;cost reduction;failure monitoring;equipment inspection;smartphone;AR glasses","","3","","16","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"Exploring the Opportunities and Challenges of Adopting Augmented Reality in Education in a Developing Country","A. Sharif; F. Anzum; A. Zavin; S. A. Suha; A. Ibnat; M. N. Islam","Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh","2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT)","13 Aug 2018","2018","","","364","366","Augmented Reality (AR) is one of the emerging advanced technologies which bridges the gap between the real and the virtual worlds, that gives students prodigious possibilities to learn the information in a completely unique way. With the rising use of personal smart devices in this modern era, the vast potentials of AR have begun to be explored as the smart devices are capable of producing AR environments. In this paper, we have conducted a survey with the purpose of exploring threats and possible opportunities of adopting AR in education in a developing country like Bangladesh. Data analysis and outcomes of the survey demonstrate that lack of expertise, adoption of AR in rural area are the main challenges while increased focus and satisfaction in learning, increased accessibility of AR applications in our smart devices with 4G evolution are the opportunities of adopting AR in education sector of a developing country.","2161-377X","978-1-5386-6049-2","10.1109/ICALT.2018.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8433539","augmented reality;adoption in education;developing countires;smart devices;challenges and opportunities","Education;Augmented reality;Smart devices;Data analysis;Tools;Collaboration","4G mobile communication;augmented reality;computer aided instruction","education sector;developing country;augmented reality;students prodigious possibilities;personal smart devices;AR;Bangladesh;4G evolution","","3","","15","IEEE","13 Aug 2018","","","IEEE","IEEE Conferences"
"Design of an Augmented Reality System for Immersive Learning of Digital Electronic","S. Martin; G. Parra; J. Cubillo; B. Quintana; R. Gil; C. Perez; M. Castro","Dep. Ing. Eléctrica, Electrónica, Control, Telemática y Química aplicada a la lngeniería, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Dep. Ing. Eléctrica, Electrónica, Control, Telemática y Química aplicada a la lngeniería, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Dep. Ing. Eléctrica, Electrónica, Control, Telemática y Química aplicada a la lngeniería, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Dep. Ing. Eléctrica, Electrónica, Control, Telemática y Química aplicada a la lngeniería, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Dep. Ing. Eléctrica, Electrónica, Control, Telemática y Química aplicada a la lngeniería, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Dep. Ing. Eléctrica, Electrónica, Control, Telemática y Química aplicada a la lngeniería, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Dep. Ing. Eléctrica, Electrónica, Control, Telemática y Química aplicada a la lngeniería, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain","2020 XIV Technologies Applied to Electronics Teaching Conference (TAEE)","11 Aug 2020","2020","","","1","6","This article describes the development of two mobile applications for learning Digital Electronics. The first application is an interactive app for iOS where you can study the different digital circuits, and which will serve as the basis for the second: a game of questions in augmented reality.","","978-1-7281-6732-9","10.1109/TAEE46915.2020.9163704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9163704","Digital Electronics;Augmented Reality;Mobile Application;Immersive Learning","Augmented reality;Education;Logic gates;Mobile applications;Tools;Cameras;Libraries","augmented reality;computer aided instruction;electronic engineering computing;electronic engineering education;interactive systems;mobile computing;mobile learning;multimedia systems","augmented reality system;immersive learning;mobile applications;digital electronics;interactive app;iOS;digital circuits","","3","","10","IEEE","11 Aug 2020","","","IEEE","IEEE Conferences"
"Support of power plant telemaintenance with robots by Augmented Reality methods","F. Leutert; K. Schilling","Lehrstuhl für Robotik und Telematik, Julius-Maximilians-Universität Würzburg, Germany; Lehrstuhl für Robotik und Telematik, Julius-Maximilians-Universität Würzburg, Germany","2012 2nd International Conference on Applied Robotics for the Power Industry (CARPI)","7 Mar 2013","2012","","","45","49","In power plants, in many cases direct human access to crucial sites for inspection or maintenance is impossible. Here, remotely operated robots offer good potential to handle these tasks. This relates to technology challenges for remote operations. In this contribution we propose the use of an Augmented Reality interface as a means to directly and intuitively visualize complex information to overcome some of the challenges and support the teleoperator in his duties. Support functions that could be employed for several tasks in the context of inspection or maintenance are introduced.","","978-1-4673-4587-3","10.1109/CARPI.2012.6473362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6473362","Augmented Reality;Manipulators;Tele-inspection;Telemaintenance;Teleoperation","Augmented reality;Service robots;Inspection;Robot sensing systems;Power generation;Manipulators","augmented reality;control engineering computing;data visualisation;industrial manipulators;inspection;maintenance engineering;mobile robots;nuclear power stations;power engineering computing;service robots;telerobotics","remote operations;remotely operated robots;power plant inspection;teleinspection;manipulators;teleoperator;augmented reality interface;power plant telemaintenance","","3","","19","IEEE","7 Mar 2013","","","IEEE","IEEE Conferences"
"Augmented reality with high frame rate for low computational power devices","H. -S. Jang; J. -Y. Jeong; Y. -H. Kim; Y. -J. Yoon; S. -J. Ko","Department of Electrical Engineering, Korea University, Seoul, Korea; Department of Electrical Engineering, Korea University, Seoul, Korea; Department of Electrical Engineering, Korea University, Seoul, Korea; Department of Electrical Engineering, Korea University, Seoul, Korea; Department of Electrical Engineering, Korea University, Seoul, Korea","2011 IEEE International Conference on Consumer Electronics -Berlin (ICCE-Berlin)","29 Sep 2011","2011","","","274","275","In the conventional Augmented Reality (AR) systems, three main tasks are sequentially performed: image acquisition, camera pose tracking and rendering. Among these tasks, the camera pose tracking occupies the largest proportion of total processing time. Thus, frame rate can be reduced in small mobile devices when the tracking processing time exceeds the image acquisition time interval needed for desired frame rate. Moreover, the temporal jitter can be introduced due to the irregular tracking processing time. In this paper, we present a new framework for AR that can achieve the high frame rate and reduce the temporal jitter. In the proposed method, the three main tasks of AR are performed in parallel. This enables the image acquisition and rendering thread to work independently with the tracking thread so to prevent frame loss and temporal jitter. The tracking thread calculates the camera pose of the coarsely selected frames. For the unselected frames, the parabolic motion model is applied. Experimental results indicate that the proposed system outperforms conventional methods in terms of frame rate and temporal jitter.","2166-6822","978-1-4577-0234-1","10.1109/ICCE-Berlin.2011.6031808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6031808","augmented reality;temporal jitter;mobile devices;frame rate up conversion;smartphone;parabolic motion model","Cameras;Jitter;Rendering (computer graphics);Tracking;Mobile handsets;Estimation;Augmented reality","augmented reality;cameras;image motion analysis;jitter;object tracking;pose estimation;rendering (computer graphics)","augmented reality;low computational power devices;AR systems;image acquisition;camera pose tracking;rendering;mobile devices;temporal jitter;irregular tracking processing time;frame loss;parabolic motion model","","3","","4","IEEE","29 Sep 2011","","","IEEE","IEEE Conferences"
"Implementation and Design Issues for Augmented Reality Applications on Mobile Platforms","S. Gadre; V. Rawalgaonkar; M. Warde; D. Balasubramanian; G. Gore; J. Joshi","Eduvance, Mumbai, India; Eduvance, Mumbai, India; Eduvance, Mumbai, India; Eduvance, Mumbai, India; Eduvance, Mumbai, India; Eduvance, Mumbai, India","2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","2 Dec 2018","2018","","","1341","1344","This paper presents the factors that an Augmented Reality (AR) application designer must look at whilst implementing AR applications on mobile platforms. There are certain implementation and design issues that are critical to the success of an AR application. The trigger response time (TRT) and mobile platform battery consumption are the two main parameters that are looked at in the research preseted. The test application was designed using a combination of Vuforia, Unity and Blender platforms, and the mobile platform used was an Android based One Plus 3T phone. The results discuss the impact of trigger image complexity, 3d object complexity and ambient light on the response time and battery life.","","978-1-5386-5314-2","10.1109/ICACCI.2018.8554456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554456","Augmented Reality;response time;mobile phone;Android application;trigger image;3d Object;battery life","Three-dimensional displays;Augmented reality;Batteries;Complexity theory;Mobile handsets;Time factors;Visualization","augmented reality;mobile computing","augmented reality application designer;TRT;Blender platforms;Android based One Plus 3T phone;test application;trigger response time;design issues;AR application;mobile platform","","3","","15","IEEE","2 Dec 2018","","","IEEE","IEEE Conferences"
"Augmented Reality Based Recommendations Based on Perceptual Shape Style Compatibility with Objects in the Viewpoint and Color Compatibility with the Background","K. Tanmay; K. Ayush","Department of Electrical Engineering, IIT Kharagpur; Department of Computer Science, Stanford University","2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)","5 Mar 2020","2019","","","3361","3367","Augmented Reality (AR) has been heralded as the next frontier in retail, but so far, has been mostly used to advertise or market products in a gimmicky way and its true potential in digital marketing remains unexploited. In this work, we leverage richer data coming from AR usage to make re-targeting much more persuasive via viewpoint image augmentation. Based on the user's purchase viewpoint visual, we identify relevant objects/products present in the viewpoint along with their style such that products with more style compatibility with those surrounding real-world objects can be recommended. We also use color compatibility with the background of the user's purchase viewpoint to select suitable product textures. We embed the recommended products in the viewpoint at the location of the initially browsed product with similar pose and scale. This makes the recommendations much more personalized and relevant which can increase conversions. Evaluation with user studies show that our system is able to make recommendations better than tag-based recommendations, and targeting using the viewpoint is better than that of usual product catalogs.","2473-9944","978-1-7281-5023-9","10.1109/ICCVW.2019.00418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022075","Augmented Reality;Recommendations;Virtual Commerce;Targeting;Personalization","Image color analysis;Visualization;Three-dimensional displays;Solid modeling;Cameras;Data models;Augmented reality","augmented reality;data visualisation;recommender systems","product textures;viewpoint image augmentation;digital marketing;augmented reality;color compatibility;perceptual shape style compatibility;product catalogs;tag-based recommendations;recommended products","","3","","21","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"Augmented reality for children with Autism Spectrum Disorder - A systematic review","R. Mónica; H. Ivana; D. Javier; R. Jorge","LINTI Research Laboratory of New Computer Technologies, National University of La Plata Buenos Aires, Argentina; LINTI Research Laboratory of New Computer Technologies, National University of La Plata Buenos Aires, Argentina; LINTI Research Laboratory of New Computer Technologies, National University of La Plata Buenos Aires, Argentina; Yellopaper Master in Information Technology Quito, Ecuador","2020 International Conference on Intelligent Systems and Computer Vision (ISCV)","23 Sep 2020","2020","","","1","7","This article collects and analyzes information from various authors dedicated to the investigation of Information and Communication Technologies (ICTs) and in particular Augmented Reality (AR) in the treatment of children with Autism Spectrum Disorder (ASD). RA has ventured into the generation of different cognitive and emotional skills in children diagnosed with this disorder. Descriptive research was used for this study, through bibliographic review.","","978-1-7281-8041-0","10.1109/ISCV49265.2020.9204125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204125","Autism;Learning;Teaching Augmented Reality;TIC;Disorder;Treatment;TORCH.","Augmented reality;Autism;Systematics;Medical treatment;Education;Variable speed drives;Information and communication technology","augmented reality;computer aided instruction;handicapped aids;medical disorders;paediatrics;patient treatment","children;autism spectrum disorder;augmented reality;cognitive skills;emotional skills;bibliographic review;information and communication technologies;neurological development;innovative teaching mechanisms","","3","","36","IEEE","23 Sep 2020","","","IEEE","IEEE Conferences"
"Speaky Notes Learn languages with augmented reality","F. Sorrentino; L. D. Spano; R. Scateni","Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy; Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy; Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy","2015 International Conference on Interactive Mobile Communication Technologies and Learning (IMCL)","17 Dec 2015","2015","","","146","150","In recent years, mobile devices have become very popular within young people. Thanks to developments in mobile technologies, these devices can now do much more than just voice calls and texts. We envision mobile devices as tools for improving the young users' lifestyle, especially for learning. In this work we present a web authoring system that makes it possible to create a mobile application that supports children in learning a new language in a more pleasant and entertaining way by using Augmented Reality. This application allows pupils to improve their speaking skills turning the language acquisition into a game under the supervision of both teachers and parents. Our contribution is focused on understanding how digital technology can facilitate learning while keeping in mind that it is a wide and interdisciplinary issue.","","978-1-4673-8243-4","10.1109/IMCTL.2015.7359574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359574","Learning;Child;Augmented Reality;Voice;Language","Augmented reality;Education;Games;Smart phones;Mobile communication;Vocabulary","augmented reality;mobile computing;mobile handsets","augmented reality;mobile devices;mobile technologies;Web authoring system;speaking skills;language acquisition","","3","","11","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Markerless augmented reality system based on planar object tracking","Ahyun Lee; Jae-Young Lee; S. -H. Lee; J. -S. Choi","Graduated School of Advanced Imaging Science, Multimedia, and Film, Chung-Ang University, Seoul, South Korea; Graduated School of Advanced Imaging Science, Multimedia, and Film, Chung-Ang University, Seoul, South Korea; Graduated School of Advanced Imaging Science, Multimedia, and Film, Chung-Ang University, Seoul, South Korea; Graduated School of Advanced Imaging Science, Multimedia, and Film, Chung-Ang University, Seoul, South Korea","2011 17th Korea-Japan Joint Workshop on Frontiers of Computer Vision (FCV)","28 Mar 2011","2011","","","1","4","Typically, vision-based AR systems operate on the basis of prior knowledge of the environment such as a square marker. One problem of traditional marker-based AR system has a limitation that the marker has to be located in the sensing range. Therefore, there have been considerable research efforts for the techniques known as real-time camera tracking, in which the system attempts to add unknown 3D features to its feature map, and these then provide registration even when the reference map is out of the sensing range. In this paper, we describe a real-time camera tracking framework specifically designed to track a monocular camera in a desktop workspace. Basic idea of the proposed scheme is that a real-time camera tracking is achieved on the basis of a plane tracking algorithm. Also we suggest a method for re-detecting features to maintain registration of virtual objects. The proposed method can cope with the problem that the features cannot be tracked, when they go out of the sensing range. It can be applicable to an augmented reality system for mobile computing environment.","","978-1-61284-678-1","10.1109/FCV.2011.5739718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5739718","augmented reality;object tracking;markerless;corner detection","Cameras;Feature extraction;Three dimensional displays;Sensors;Real time systems;Tracking;Augmented reality","augmented reality;image registration;target tracking","markerless augmented reality system;planar object tracking;vision-based AR systems;real-time camera tracking;monocular camera tracking;desktop workspace;virtual object registration;mobile computing environment;reference map","","3","1","11","IEEE","28 Mar 2011","","","IEEE","IEEE Conferences"
"Augmented Reality Rendered for IoT applications","M. A. Ankireddy; A. Rajath; M. Ruthwik Ganesh; M. Anuradha","Electronics & Communication Engineering, PES University, Bangalore, India; Electronics & Communication Engineering, PES University, Bangalore, India; Computer Science and Engineering, PES University, Bangalore, India; Faculty of Engineering & Technology Electronics & Communication Engineering, PES University, Bangalore, India","2019 IEEE 16th India Council International Conference (INDICON)","12 Mar 2020","2019","","","1","4","With the growing number of Internet of Things (IoT) devices, there's an increase in the number of applications required to interact with them. To overcome the challenge of handling many applications and to enhance the user experience, the authors have demonstrated a unique approach using Augmented Reality (AR) and Image processing to control devices. The work is carried out in two phases. In the first phase, AR application for mobile devices has been implemented, where the user can interact with the augmentation and thus the changes made in AR environment are reflected in the physical world. In the second phase, low cost, portable smart glass has been designed with features to control a device by just having its context. It is a custom hardware and can be used as a plug and play device.","2325-9418","978-1-7281-2327-1","10.1109/INDICON47234.2019.9029045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9029045","Augmented Reality (AR);Image Processing;Internet of Things;Vuforia;Smart Glasses;Raspberry Pi Zero;AR-IoT","Feature extraction;Servers;Augmented reality;Internet of Things;Hardware;Smart glasses","augmented reality;Internet of Things;rendering (computer graphics)","user experience;augmented reality;Image processing;AR application;mobile devices;IoT applications;Internet of Things devices;IoT devices","","3","","16","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"An Augmented Reality App for Therapeutic Education and Suitable for Mobile Devices with Different Features","A. -M. Calle-Bustos; M. . -C. Juan; F. Abad; R. Mollá","Instituto Universitario de Autom??tica e Inform??tica Industrial Universitat Polit??cnica de Valencia, Valencia, Spain; Instituto Universitario de Autom??tica e Inform??tica Industrial Universitat Polit??cnica de Valencia, Valencia, Spain; Instituto Universitario de Autom??tica e Inform??tica Industrial Universitat Polit??cnica de Valencia, Valencia, Spain; Instituto Universitario de Autom??tica e Inform??tica Industrial Universitat Polit??cnica de Valencia, Valencia, Spain","2019 IEEE 19th International Conference on Advanced Learning Technologies (ICALT)","2 Sep 2019","2019","2161-377X","","337","339","Patients with chronic diseases can improve their quality of life with therapeutic education. Augmented Reality (AR) can be used to develop therapeutic tools. This paper presents a study in which an AR app to support therapeutic education in diabetes was used. The app supports the learning about carbohydrate portions contained in different foods. The virtual food is shown on a real dish. Sixty-six children with diabetes participated in our study. The children were divided into three groups that used three different mobile devices. The main differences between the three devices were camera resolution and display size. We used two tablets with similar display size and different camera resolution (2-megapixel and 8-megapixel), and a smartphone with about half of the diagonal display size of the tablets and with an 8-megapixel camera. The results indicated that the children learned about carbohydrate estimation by using our app. There were no statistically significant differences for the knowledge acquired, or for the perceived usability and satisfaction among the three groups. This result points out that our AR app is effective as a therapeutic education tool independently of the features of the device used.","2161-377X","978-1-7281-3485-7","10.1109/ICALT.2019.00106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820825","Diabetes, therapeutic education, augmented reality, app, mobile devices, m-learning","Diabetes;Education;Augmented reality;Mobile handsets;Usability","augmented reality;biomedical education;cameras;computer aided instruction;diseases;image resolution;medical image processing;mobile computing;patient monitoring;patient treatment;smart phones","augmented reality app;therapeutic tools;AR app;diabetes;virtual food;children;statistically significant differences;therapeutic education tool;mobile devices;camera resolution;quality of life","","3","","9","IEEE","2 Sep 2019","","","IEEE","IEEE Conferences"
"A tracking and registration method based on ORB and KLT for augmented reality system","Y. Xia; W. Zhou","Research Center of Spatial Information System, Chongqing University of Posts & Telecommunications, Chongqing, China; Research Center of Spatial Information System, Chongqing University of Posts & Telecommunications, Chongqing, China","2013 22nd Wireless and Optical Communication Conference","2 Dec 2013","2013","","","344","348","Registration is one of the key technologies of augmented reality system. In order to realize accurate and realtime registration and keep the right position and orientation of a virtual object in real world scenarios, a new registration method based on ORB and KLT algorithms is proposed. It detects the target from the video frame first and calculates the homographic matrix of initial camera poses, then continues to track camera pose for further registration. Error correction method and verification strategy are presented to improve the reliability and accuracy of the registration during the tracking process. Experiments show that the proposed method gains better registration accuracy and efficiency, it achieves real time combination of the virtual information with the moving targets.","2379-1276","978-1-4673-5699-2","10.1109/WOCC.2013.6676390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676390","augmented reality;KLT;ORB;tracking;registration","Cameras;Target tracking;Feature extraction;Augmented reality;Real-time systems;Transmission line matrix methods;Accuracy","augmented reality;image registration;image sensors;object tracking;pose estimation","registration method;tracking method;KLT;ORB;augmented reality system;realtime registration;virtual object;video frame;homographic matrix;initial camera;error correction method;verification strategy","","3","","10","IEEE","2 Dec 2013","","","IEEE","IEEE Conferences"
"Quantification of postural balance using augmented reality based environment: A pilot study","S. Roy; O. Mazumder; D. Chatterjee; K. Chakravarty; A. Sinha","Innovation Lab, Tata Consultancy Services, Kolkata, India; Innovation Lab, Tata Consultancy Services, Kolkata, India; Innovation Lab, Tata Consultancy Services, Kolkata, India; Innovation Lab, Tata Consultancy Services, Kolkata, India; Innovation Lab, Tata Consultancy Services, Kolkata, India","2017 IEEE SENSORS","25 Dec 2017","2017","","","1","3","Here, we present an affordable Augmented Reality (AR) based system to quantify postural stability of an individual which can be used in tele-rehabilitation and personalized health care applications. Postural instability is a prominent symptom of many physiological disorders and is a major precursor of fall risk. Conventional stability scoring techniques require presence of physiotherapist and are time consuming as well as expensive. Proposed system overcomes these difficulties by integrating a low cost Microsoft Kinect and an AR-based environment with a fuzzy stability scorer algorithm. The system gives a real time stability score by quantifying the Single Limb Stance task with variable step height. Results obtained are compared with Berg Balance stability scale to show the efficiency of the proposed system.","","978-1-5090-1012-7","10.1109/ICSENS.2017.8234398","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8234398","Kinect;Fuzzy;Posturography;Single Limb Stance;Tele rehabilitation;Augmented Reality","Stability criteria;Numerical stability;Vibrations;Augmented reality;Legged locomotion","augmented reality;fuzzy set theory;health care;image motion analysis;medical disorders;patient rehabilitation;pose estimation;telemedicine","postural instability;physiological disorders;fall risk;fuzzy stability scorer algorithm;time stability score;Berg Balance stability scale;postural stability;tele-rehabilitation;personalized health care applications;Microsoft Kinect;augmented reality;conventional stability scoring;postural balance quantification;Single Limb Stance task","","3","","10","IEEE","25 Dec 2017","","","IEEE","IEEE Conferences"
"Development of an english words learning system utilizes 3D markers with augmented reality technology","B. Zhenming; U. Mayu; E. Mamoru; Y. Tatami","Department of Systems and Social Informatics, Nagoya University, Nagoya City, Japan; Department of Systems and Social Informatics, Nagoya University, Nagoya City, Japan; Department of Systems and Social Informatics, Nagoya University, Nagoya City, Japan; Department of Systems and Social Informatics, Nagoya University, Nagoya City, Japan","2017 IEEE 6th Global Conference on Consumer Electronics (GCCE)","21 Dec 2017","2017","","","1","2","Augmented Reality (AR) has been developed rapidly through recent years due to the increasing mobility and computing power of PC. And there are more and more AR applications have been developed for learning experiences. However, a great number of such AR applications work as merely textbook expansion by overlaying additional information on papers. In this research, we take advantage of the potential of AR to create a model that allows more dynamic interaction to reinforce the English word learning experience. A system can be interacted with intuitively through toy-like 3D objects by utilizing the affordances that AR provides.","","978-1-5090-4045-2","10.1109/GCCE.2017.8229353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8229353","Augmented Reality;Affordance;HCI;ESL;Edutainment;Gamification","Three-dimensional displays;Augmented reality;Education;Prototypes;Vocabulary;Conferences;Consumer electronics","augmented reality;computer aided instruction","learning experiences;AR applications;English word learning experience;toy-like 3D objects;english words learning system;augmented reality technology","","3","","10","IEEE","21 Dec 2017","","","IEEE","IEEE Conferences"
"A patient position guidance system in radiation therapy using augmented reality","J. Talbot; J. Meyer; R. Watts; R. Grasset","Physics and Astronomy Department, University of Canterbury, New Zealand; Physics and Astronomy Department, University of Canterbury, New Zealand; Physics and Astronomy Department, University of Canterbury, New Zealand; Human Interface Technology Laboratory, New Zealand","2008 23rd International Conference Image and Vision Computing New Zealand","23 Jan 2009","2008","","","1","5","With the increased precision in dose delivery provided by highly conformal radiotherapy techniques such as intensity modulated radiotherapy (IMRT), the requirement for accuracy in patient positioning for treatment is emphasised. This system uses augmented reality (AR) to allow the radiation therapist to visually guide the patient during positioning for treatment. It superimposes three-dimensional scan data acquired from the planning CT over a real-time view of the patient, which is obtained from a conventional webcam. The 3D data is positioned relative to AR tracking markers visible to the camera. Throughout development, the system was tested on a 30 cm wooden phantom in place of the patient. A CT scan was performed on the phantom to obtain 3D data, and a small scale test couch was set up to perform registration tests. Modifications to the position of the phantom on the test couch on the order of a millimetre have been visible.","2151-2205","978-1-4244-3780-1","10.1109/IVCNZ.2008.4762111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4762111","Augmented reality;intensity-modulated radiotherapy","Biomedical applications of radiation;Augmented reality;Tumors;Medical treatment;Intensity modulation;Computed tomography;Imaging phantoms;Testing;Shape;Physics","augmented reality;computerised tomography;image registration;medical image processing;phantoms;radiation therapy","patient position guidance system;radiation therapy;augmented reality;dose delivery;conformal radiotherapy;intensity modulated radiotherapy;planning CT;phantom;image registration","","3","","14","IEEE","23 Jan 2009","","","IEEE","IEEE Conferences"
"Pedagogy Play: Virtual Instructors for Wearable Augmented Reality during Hands-On Learning and Play","J. T. Doswell","The Juxtopia Group, Inc.","2008 Second IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning","8 Dec 2008","2008","","","215","216","This workshop will expose participants to how autonomous virtual instructors (VI) can be delivered through wearable augmented reality (AR) to provide a personalized and just-in-time instructional intervention during psychomotor learning and play. Distributing VIs for teaching or improving psychomotor skills through wearable AR, provides individual learners with a continually available personal tutor while, at the same time, keeping their hands free to practice a range of skills.These psychomotor skills may range from children learning basic electronics through robot assembly to learning the proper steps as a master plumber by following a VIs instructions. This workshop will address various pedagogical rules that a VI must follow in order to deliver the best instruction and how the multi-modal instructional intervention of a VI enabled wearable AR system can improve task learning and proficiency during learning and play.","","978-0-7695-3409-1","10.1109/DIGITEL.2008.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4700765","Virtual Instructors;Wearable augmented reality","Augmented reality;Psychology;Taxonomy;Conferences;Education;Learning systems;Humans;Robotic assembly;Robots;Displays","augmented reality;intelligent tutoring systems;psychology;wearable computers","pedagogy play;wearable augmented reality;hands-on learning;autonomous virtual instructors;just-in-time instructional intervention;psychomotor learning;psychomotor skills;robot assembly;master plumber;pedagogical rules;multimodal instructional intervention;task learning","","3","","2","IEEE","8 Dec 2008","","","IEEE","IEEE Conferences"
"Towards augmented reality in power engineering","I. Opriş; S. Costinaş; C. S. Ionescu; D. E. G. Nistoran","University POLITEHNICA of Bucharest; University POLITEHNICA of Bucharest; University POLITEHNICA of Bucharest; Universitatea din Bucuresti, Bucuresti, RO","2017 10th International Symposium on Advanced Topics in Electrical Engineering (ATEE)","24 Apr 2017","2017","","","39","44","The paper explores the main directions in which the augmented reality and the Web can change the approach in power engineering and significantly improving it. These innovations facilitate, in a user-friendly way, the availability of real-time data, fast processed information, assistance and guidance at any time and in any place along the entire energy chain. A step-by-step implementation of AR applications is recommended to allow the human adaptation time to the new technology, the evaluation of results and the choosing of best future development. For the beginning, simple AR application should be introduced in student laboratories, on smartphones.","","978-1-5090-5160-1","10.1109/ATEE.2017.7905160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7905160","augmented reality;emerging technologies;internet;power engineering;education","Augmented reality;Power engineering;Laboratories;Data visualization;Real-time systems;Training","augmented reality;Internet;power engineering;power engineering computing;power engineering education;real-time systems;smart phones","power engineering;augmented reality;real-time data availability;fast processed information;energy chain;AR applications;human adaptation time;smartphones;Web applications","","3","","26","IEEE","24 Apr 2017","","","IEEE","IEEE Conferences"
"Hybrid Localization System for Mobile Outdoor Augmented Reality Applications","I. M. Zendjebil; F. Ababsa; J. -Y. Didier; M. Mallem","IBISC Laboratory, CNRS FRE 3190, University of Evry Val d'Essonne (UEVE), France; IBISC Laboratory, CNRS FRE 3190, University of Evry Val d'Essonne (UEVE), France; IBISC Laboratory, CNRS FRE 3190, University of Evry Val d'Essonne (UEVE), France; IBISC Laboratory, CNRS FRE 3190, University of Evry Val d'Essonne (UEVE), France","2008 First Workshops on Image Processing Theory, Tools and Applications","9 Jan 2009","2008","","","1","6","Outdoor Augmented Reality applications often combine heterogeneous sensors to recover 3D localization (position and orientation) in large environments. Indeed, accurate localization is critical to register virtual augmentations over a real scene. This paper describes a localization system composed of two parts: an Aid-localization subsystem and a Vision subsystem. The Aidlocalization subsystem, composed of GPS and inertial sensor, has two functionalities: to initialize the visual tracking and to estimate the user's position and orientation when visual tracking fails. The Vision subsystem which represents the main block, allows continuously estimating the user's position and orientation using point-based visual tracking.","2154-512X","978-1-4244-3321-6","10.1109/IPTA.2008.4743733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4743733","Outdoor Augmented Reality;3D Localization;Hybrid sensor","Augmented reality;Global Positioning System;Cameras;Motion estimation;Layout;Relays;Gyroscopes;Predictive models;Rendering (computer graphics);Image processing","augmented reality;Global Positioning System;sensors","hybrid localization system;mobile outdoor augmented reality applications;heterogeneous sensors;Aid-localization subsystem;Vision subsystem;GPS;inertial sensor","","3","","16","IEEE","9 Jan 2009","","","IEEE","IEEE Conferences"
"Improving visual perception of augmented reality on mobile devices with 3D red-cyan glasses","C. Güngör; M. Kurt","Uluslararası Bilgisayar Enstitüsü Ege Üniversitesi, İzmir, Türkiye; Uluslararası Bilgisayar Enstitüsü Ege Üniversitesi, İzmir, Türkiye","2014 22nd Signal Processing and Communications Applications Conference (SIU)","12 Jun 2014","2014","","","1706","1709","In this work, we study the understanding of 3D visual objects which are generated by augmented reality techniques. 3D glasses are typically highly priced, and so they are not purchasable for most consumers. Instead, we consider low-priced red-cyan (anaglyph) glasses. We generate the left and right views so that they are comfortable for human eyes.","2165-0608","978-1-4799-4874-1","10.1109/SIU.2014.6830577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830577","augmented reality;visual perception;three dimensional visualization","Augmented reality;Three-dimensional displays;Conferences;Glass;Signal processing;Visual perception;Visualization","augmented reality;mobile computing","visual perception;mobile devices;3D red-cyan glasses;3D visual objects;augmented reality techniques;red cyan anaglyph glasses;human eyes","","3","","15","IEEE","12 Jun 2014","","","IEEE","IEEE Conferences"
"Game-based Learning using Augmented Reality","O. L. Ying; I. Hipiny; H. Ujir; S. F. Samson Juan","Faculty of Computer Science and Information Technology, Universiti Malaysia Sarawak, Kota Samarahan, Malaysia; Faculty of Computer Science and Information Technology, Universiti Malaysia Sarawak, Kota Samarahan, Malaysia; Faculty of Computer Science and Information Technology, Universiti Malaysia Sarawak, Kota Samarahan, Malaysia; Makerspace Lab, Universiti Malaysia Sarawak, Kota Samarahan, Malaysia","2021 8th International Conference on Computer and Communication Engineering (ICCCE)","1 Jul 2021","2021","","","344","348","Game-based learning with Augmented Reality (AR) is fast gaining popularity as an educational tool for primary school students due to its proven effectiveness, particularly for lower age groups. The present ubiquity of smart devices also contributes to the rapid adoption of such technology in classrooms. The gamification element and instantaneous feedback are vital to gain and maintain younger students' focus and interest. This study investigates the effects of using such tool on students' learning of the Solar system; a topic that is part of the Malaysian upper primary school's Science syllabus. The study was conducted remotely involving 20 respondents from various public primary schools in Malaysia. Pre-test and post-test results are presented in this paper. The result validates the effectiveness of the developed game-based learning app, i.e., SoLAR Kid, in improving students' understanding of the topic. From our experiment, we observed a clear mean difference between pre-test and post-test scores.","","978-1-7281-1065-3","10.1109/ICCCE50029.2021.9467187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9467187","Game-based learning;augmented reality","Auditory system;Tools;Solar system;Task analysis;Smart devices;Augmented reality","augmented reality;computer aided instruction;computer games;human computer interaction","post-test scores;developed game-based;post-test results;pre-test;public primary schools;Malaysian upper primary school;Solar system;younger students;instantaneous feedback;gamification element;rapid adoption;smart devices;lower age groups;proven effectiveness;primary school students;educational tool;Augmented Reality","","3","","26","IEEE","1 Jul 2021","","","IEEE","IEEE Conferences"
"Behavioral Patterns and Learning Performance of Collaborative Knowledge Construction on an Augmented Reality System","T. -J. Lin; H. -Y. Wang; H. B. -L. Duh; C. -C. Tsai; J. -C. Liang","Graduate Institute of Applied Science and Technology, National Taiwan University of Science and Technology, Taipei, Taiwan; Graduate Institute of Applied Science and Technology, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Graduate Institute of Applied Science and Technology, National Taiwan University of Science and Technology, Taipei, Taiwan; Graduate Institute of Applied Science and Technology, National Taiwan University of Science and Technology, Taipei, Taiwan","2012 IEEE 12th International Conference on Advanced Learning Technologies","16 Aug 2012","2012","","","113","115","The purpose of this study was to investigate how a mobile collaborative augmented reality (AR) system affects learners¡¦ knowledge construction behaviors and learning performances. In this study, 20 undergraduate students were recruited and divided into dyads to discuss given questions with the assistance of mobile collaborative AR system named AR Physics. The participants¡¦ knowledge regarding elastic collision was evaluated through a pretest and a posttest that occurred right after the treatment. Learners¡¦ knowledge construction behaviors were qualitatively identified according to a selected coding scheme and then were analyzed by adopting sequential analysis. The results indicated that learners significantly gained their knowledge on the topic of elastic collision after completing the given task by manipulating AR Physics system. Furthermore, sequential patterns of learners¡¦ behaviors during knowledge construction activities were identified.","2161-377X","978-1-4673-1642-2","10.1109/ICALT.2012.131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268051","Augmented reality;knowledge construction;behavioral mobile learning","Physics;Collaboration;Collaborative work;Educational institutions;Sequential analysis;Augmented reality;Mobile communication","augmented reality;computer aided instruction;groupware;mobile computing;physics computing;physics education","behavioral patterns;learning performance;collaborative knowledge construction;mobile collaborative augmented reality system;learning performances;undergraduate students;AR Physics;elastic collision;coding scheme;sequential analysis","","3","","8","IEEE","16 Aug 2012","","","IEEE","IEEE Conferences"
"Acceleration of Dynamic Spatial Augmented Reality System with a Depth Camera","R. Koizumi; D. Kobayashi; N. Hashimoto","Department of Informatics, The University of Electro-Communications, Tokyo, Japan; Department of Informatics, The University of Electro-Communications, Tokyo, Japan; Department of Informatics, The University of Electro-Communications, Tokyo, Japan","2015 International Conference on Cyberworlds (CW)","4 Feb 2016","2015","","","50","53","Recently, spatial augmented reality (SAR) has been used as a method of editing appearance of real objects by using a projector. In addition to SAR with stationary objects, SAR with moving objects is paid attention to in case of entertainments, work supports, design study, and so on. Although such dynamic SAR requires pose estimation and tracking, it cannot accomplish enough accuracy and processing speed by using non-contact measurement by cameras. Therefore, in this research, we propose optimization of point cloud data used for the tracking at off-line and on-line processes, and accomplish acceleration of the SAR system which we have achieved with a depth camera.","","978-1-4673-9403-1","10.1109/CW.2015.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398391","Spatial Augmented Reality;Tracking;3D Point Cloud;Point Cloud Reduction","Three-dimensional displays;Target tracking;Cameras;Solid modeling;Acceleration;Augmented reality","augmented reality;computer graphics","dynamic spatial augmented reality system;depth camera;point cloud data optimization","","2","","3","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"BARRACUDA: An augmented reality display for increased motorcyclist en route hazard awareness","M. P. Jenkins; D. Young","Charles River Analytics, Cambridge, MA, USA; Charles River Analytics, Cambridge, MA, USA","2016 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)","23 Jun 2016","2016","","","68","72","Motorcyclists face a unique set of challenges when operating on public streets and highways. In addition to hazards relevant to automobiles, motorcycle riders must remain vigilant for hazards that pose significant danger uniquely to motorcycles (e.g., uneven terrain, sand/gravel, potholes); however, there is currently no motorcycle-specific hazard tracking or alerting system available for riders. To address this need, Charles River Analytics is designing a system for Bayesian Assessments and Real-Time Rider Alerting and Cueing for Upcoming Danger Avoidance (BARRACUDA). BARRACUDA will capture and integrate relevant information from an array of public databases and on-motorcycle and environmental sensors. It will fuse this information and apply advanced probabilistic models and reasoning techniques to generate route-based real-time hazard alerts (presented with a trip planning application prior to departure and an augmented reality (AR) heads-up display (HUD) while en route), even when operating on uncertain or incomplete information, to increase rider situation awareness. This effort was funded under a US Dept. of Transportation SBIR Phase I contract (DTRT5715C10063).","2379-1675","978-1-5090-0632-8","10.1109/COGSIMA.2016.7497788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7497788","Augmented Reality;Safety;Ecological Interface Design;Hazard Awareness;Situation Awareness;Motorcycles","Hazards;Motorcycles;Real-time systems;Probabilistic logic;Accidents;Augmented reality","augmented reality;motorcycles;traffic engineering computing","BARRACUDA system;augmented reality display;motorcyclist route hazard awareness;Charles River Analytics;Bayesian assessments and realtime rider alerting and cueing for upcoming danger avoidance;trip planning application;rider situation awareness","","2","","13","IEEE","23 Jun 2016","","","IEEE","IEEE Conferences"
"Augmented Reality with Maps for Off-Screen POI Awareness","M. B. Carmo; A. P. Afonso; M. Melo; B. Rocha; V. Botan","BioISI- Biosystems & Integrative Sciences Institute, Faculty of Sciences, University of Lisboa, Lisboa, Portugal; LASIGE Faculty of Sciences, University of Lisboa; LASIGE Faculty of Sciences, University of Lisboa; LASIGE Faculty of Sciences, University of Lisboa; LASIGE Faculty of Sciences, University of Lisboa","2020 24th International Conference Information Visualisation (IV)","11 Mar 2021","2020","","","454","459","Augmented Reality (AR) applications for mobile devices are common nowadays, however the information superimposed over the image captured by the device's camera is limited to its field of view. To address this problem in the visualization of points of interest (POI), we have combined the AR view with the display of the POI's location in a map to increase user awareness about nearby POI. It gives insight about the orientation and distance between the POI and the user. We developed 3 solutions: (1) including cues to off-screen POI in a frame at the border of the AR view and providing an alternative map view; (2) combining the AR view with a mini-map superimposed on its top left corner; and (3) combining the AR view with a circular radar view on its top left corner. A usability study performed to compare these approaches revealed that, although all the approaches were positively appreciated, the solution with a mini-map was the preferred one.","2375-0138","978-1-7281-9134-8","10.1109/IV51561.2020.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373097","Augmented Reality;off-screen objects;relevance","Visualization;Two dimensional displays;Radar;Search problems;Mobile handsets;Usability;Augmented reality","augmented reality;data visualisation;mobile computing;user interfaces","mini-map;off-screen POI;augmented reality applications;mobile devices;AR view;POI location;user awareness;alternative map view;top left corner;circular radar view","","2","","17","IEEE","11 Mar 2021","","","IEEE","IEEE Conferences"
"Personalized Training in Fast-Food Restaurants Using Augmented Reality Glasses","M. S. Albayrak; A. Öner; I. M. Atakli; H. K. Ekenel","Innovation and Transformation Department, ATA Technology Platforms, Istanbul, Turkey; Innovation and Transformation Department, ATA Technology Platforms, Istanbul, Turkey; Innovation and Transformation Department, ATA Technology Platforms, Istanbul, Turkey; Department of Computer Engineering, Istanbul Technical University, Istanbul, Turkey","2019 International Symposium on Educational Technology (ISET)","1 Aug 2019","2019","","","129","133","Employee training in fast-food restaurants is a long, practice-based process, which is mainly done on the job. Employee performance during training directly affects service quality and customer satisfaction. In this study, we optimize the training process in fast-food restaurants with the use of augmented reality glasses. We increase the quality of the training by gamifying and personalizing the process. We also aim to help businesses lower the labor costs by shortening or possibly fully eliminating one-on-one training sessions instructed by senior employees. We implemented a new training system on a game engine with the aid of various sensors such as gyroscope, accelerometer and audial & visual inputs. We also intend to eliminate the culture of high employee turnover rates of the fast-food sector by increasing the quality of the training. The outcome of this study will be used to fully train and supervise employees in the future.","","978-1-7281-3388-1","10.1109/ISET.2019.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782209","Personalized employee training, augmented reality, gamification, marker based object detection, fast-food restaurant","Training;Glass;Augmented reality;Videos;Games;Random access memory;Business","accelerometers;augmented reality;catering industry;computer based training;customer satisfaction;gyroscopes;personnel;serious games (computing)","fast-food restaurants;augmented reality glasses;employee training;practice-based process;employee performance;training process;training sessions;senior employees;training system;fast-food sector;personalized training;visual inputs;audial inputs;accelerometer;gyroscope;game engine;labor costs;customer satisfaction;service quality;employee turnover rates","","2","","19","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"Development of Mobile Learning Application Based on Augmented Reality with Index Card Match Method","W. Nur Hidayat; M. Akhsan Hakiki; M. Fajar Nashrullah; H. Elmunsyah; T. Atmadji Sutikno","Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia","2020 4th International Conference on Vocational Education and Training (ICOVET)","21 Oct 2020","2020","","","304","309","Botany is one of the biology learning materials in junior high schools which is still widely taught theoretically and monotonously, so boring. In this material students still have to imagine how the anatomical forms of plants are, because the media used are still based on textbooks and explanations from the teacher alone. With this research, there is in the form of a learning media for botanical material using the index card match method by using an android application that can read markers which will later bring up 3D objects or commonly called augmented reality which will later facilitate students in visualizing material that delivered by the teacher so that students increasingly understand and can increase enthusiasm for learning. Based on the results of the study showed that based on the assessment of expert judgment obtained 84.4 percent media value included in the valid category. The notes from the application include navigation revisions and material display. Future development is carried out for teaching sources other than AR that can be used by students such as text and video in the hope that students have more choices of learning resources.","","978-1-7281-8131-8","10.1109/ICOVET50258.2020.9229914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229914","Mobile Learning;Augmented Reality;Index Card Match;Method;Botanical","Media;Augmented reality;Visualization;Indexes;Electrical engineering;Three-dimensional displays;Web and internet services","Android (operating system);augmented reality;botany;computer aided instruction;mobile computing;teaching","augmented reality;media value;material display;learning resources;mobile learning application;index card match method;biology learning;junior high schools;material students;textbooks;learning media;botanical material;android application;AR","","2","","14","IEEE","21 Oct 2020","","","IEEE","IEEE Conferences"
"Location finder using Augmented Reality for railways assistance","S. Djanali; M. Huda; A. M. Shiddiqi","Teknik Informatika, Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia; Teknik Informatika, Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia; Teknik Informatika, Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia","2014 2nd International Conference on Information and Communication Technology (ICoICT)","2 Oct 2014","2014","","","487","492","Currently, railways have been an influential transportation system in every country, including Indonesia. This transportation system moves people from one place to another in a large number of passengers. The railways have an advantage of traffic-free and relatively low cost. However, there are many train accidents occurred caused by several reasons. In Indonesia, a critical issue that causes the accidents is the absence of real time monitoring system. The monitoring system relies on radio communication among the operating railways and stations. This paper proposes a real-time railways monitoring system. This monitoring system includes real time data tracking of the current position of a train. The data will be displayed on a web site that can be monitored by train station officials. In addition, the system will notify candidate passengers should their train is approaching or having delays. To reach train station, if someone having difficulties in finding the station, this system has the feature of Augmented Reality (AR) that assists the passengers to find the stations he is about to take on the train. The navigation to search the station uses the current position of the passenger and the longitude and latitude of the station. To improve the accuracy of location decision on AR, we combine GLONASS and GPS that increases the accuracy of location acquiring by 919,8 %. Experiment results show that the AR technology successfully implemented using inclination angle and azimuth.","","978-1-4799-3581-9","10.1109/ICoICT.2014.6914110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6914110","Augmented reality;CBIR;GPS;GLONASS;Railway","Global Positioning System;Smart phones;Rail transportation;Accuracy;Databases;Augmented reality","augmented reality;computerised monitoring;content-based retrieval;Global Positioning System;image retrieval;object tracking;railway accidents;traffic engineering computing","location finder;augmented reality;railways assistance;transportation system;train accidents;radio communication;real-time railways monitoring system;real time data tracking;train station;GLONASS;GPS;CBIR;content-based image retrieval;Indonesia","","2","","11","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"Dual Face Interaction in Handheld Augmented Reality Environments","S. Asai; M. Hirakawa","Interdisciplinary Graduate School of Science and Engineering, Shimane University, Matsue, Japan; Interdisciplinary Faculty of Science and Engineering, Shimane University, Matsue, Japan","2009 11th IEEE International Symposium on Multimedia","28 Dec 2009","2009","","","187","193","Sophisticated multimodal interfaces are the key to success in future computer development and many ideas have been proposed so far. Augmented reality (AR) is such an idea. Computer-generated digital objects are mixed with objects in the real world, and they are perceptually assimilated. People don't need to be aware of the computer. What to do for them is just behave as usual in the real world. However, interaction with the objects is limited in existing AR systems. In fact, many of the systems allow the user just to change his/her viewpoint to real world objects. There are some other systems which accept manipulation of virtual objects, but they assume users wear or hold special devices. In this paper we propose a handheld AR interface supporting two interaction techniques based on the understanding that both real and virtual objects are compatible in manipulation. One of the techniques is for the user to directly manipulate virtual objects by his/her finger. One more technique concerns indirect manipulation of virtual objects. Motion of a handheld device serves as a trigger to make a certain change to target virtual objects.","","978-1-4244-5231-6","10.1109/ISM.2009.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364505","augmented reality;dual face interaction;handheld computer;gestures","Augmented reality;Handheld computers;Cameras;Fingers;Application software;Software libraries;Tracking;Displays;Computer interfaces;Physics computing","augmented reality;human computer interaction;notebook computers","dual face interaction;handheld augmented reality environments;sophisticated multimodal interfaces;computer-generated digital objects;virtual object manipulation","","2","2","32","IEEE","28 Dec 2009","","","IEEE","IEEE Conferences"
"Markerless tracking using interest window for augmented reality applications","M. Hamidia; N. Zenati-Henda; H. Belghit; M. Belhocine","Faculty of Electronics and Computer Science, Bab-Ezzouar, Algiers, Algeria; Centre de Developpement des Technologies Avancees, Algiers, DZ; Centre de Développement des Technologies Avancées, Baba-Hassen, Algiers, Algeria; Centre de Développement des Technologies Avancées, Baba-Hassen, Algiers, Algeria","2014 International Conference on Multimedia Computing and Systems (ICMCS)","29 Sep 2014","2014","","","20","25","This paper deals with the problem of object tracking in Augmented Reality (AR) applications. In the recent years AR has been of increasing interest. It consists of inserting a virtual object into a real scene. The temporal coherence between real and virtual objects is one of the hardest challenges of the AR system realization. A markerless tracking based on the interest points matching using SURF (Speed Up Robust Features) is mostly used, but it suffers from high computational complexity. For this reason, we propose a method using an interest window around of the object to be tracked. Moreover, a relationship between the object size and the metric threshold of SURF is investigated. The experimental results show an improvement of the proposed object tracking method performance compared to a standard method based on SURF interest points matching.","","978-1-4799-3824-7","10.1109/ICMCS.2014.6911133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911133","Augmented reality;object tracking;interest points detection;SURF;matching;interest window","Feature extraction;Object tracking;Real-time systems;Augmented reality;Robustness;Estimation;Computational complexity","augmented reality;computational complexity;object tracking","markerless tracking;interest window;augmented reality;object tracking;AR system realization;SURF;speed up robust features;computational complexity","","2","","24","IEEE","29 Sep 2014","","","IEEE","IEEE Conferences"
"Augmented Reality Application to Assist in On-Field Activities on the Electrical Sector","D. V. João; P. Z. Lodetti; A. B. dos Santos; M. A. Izumida Martins; S. de Francisci; J. F. Brandão Almeida","Sustainable Energy Center, CERTI Foundation, Florianópolis, SC, Brazil; Sustainable Energy Center, CERTI Foundation, Florianópolis, SC, Brazil; Technical Consulting, Indra Company, São Paulo, Brazil; Sustainable Energy Center, CERTI Foundation, Florianópolis, SC, Brazil; NT&I - Smart Grid Brasil, Enel Distribuição São Paulo, São Paulo, Brazil; NT&I - Smart Grid Brasil, Enel Distribuição São Paulo, São Paulo, Brazil","2021 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)","16 Mar 2021","2021","","","1","5","Workforces in electrical power sector is highly qualified. It is due to the continuous improvement effort of these professionals and many rules they have to follow daily. Their activity presents risks, and it needs to be done carefully to safeguard their life. The electrical power sector has a short history and it has been considered a conservative sector, meaning, that the assets and the way they are operated have not been following all technological trends in industry. Those analysis lead to a major concern regarding the aging of workforces and how to transfer knowledge and experiences to a new workforce. In that sense, this paper proposes a smartphone application aiming to simplify the access to information during the execution of the on-field activities. The aforementioned app can automatically recognize some assets and show relevant information about them in Augmented Reality. Some benefits brought by this application include reducing time for asset identification, faster information finding, improving and agile problem solving avoiding the use of paper documents, etc. This application is implemented within the scope of Urban Futurability Project, an innovation project that ENEL Distribuiç ão Sao Paulo is carrying out in Brazil in the framework of the Brazilian regulator's R&D) program.","2472-8152","978-1-7281-8897-3","10.1109/ISGT49243.2021.9372201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372201","Augmented Reality;Utilities Workforce;Human Interface;Network Digital Twin®","Industries;Technological innovation;Aging;Market research;Smart grids;Problem-solving;Augmented reality","augmented reality;continuous improvement;information retrieval;mobile computing;power engineering computing;power system management;smart phones","augmented reality application;electrical sector;electrical power sector;conservative sector;smartphone application;agile problem;Urban Futurability Project","","2","","15","IEEE","16 Mar 2021","","","IEEE","IEEE Conferences"
"Input system interface for image-guided surgery based on augmented reality","S. Martins; M. Vairinhos; S. Eliseu; J. Borgerson","Digimedia, University of Aveiro, Portugal; Digimedia, University of Aveiro, Portugal; ID+, University of Aveiro, Portugal; EC Medica Limited, United Kingdom","2016 1st International Conference on Technology and Innovation in Sports, Health and Wellbeing (TISHW)","9 Feb 2017","2016","","","1","6","Augmented reality allows users to enhance their perception of the real world by using technology to overlap digital information onto their field of view. This raises challenges of a technical and conceptual nature, the latter particularly from an interaction design standpoint. The implementation of such technology has advantages in many areas of human activity, including its use in clinical interventions. The main objective of this research is to develop a navigation system for Image Guided Surgery (IGS), capable of combining the real world elements of the surgeon's visual field with virtual representations of internal organs, tissues, meta-information and clinical instruments allowing clinicians to approach surgical procedures much more fluently. This proposed method would be supported by electromagnetic tracking, allowing surgeons to view captures from the ultrasonic probe directly in their field of view. This would make it possible to support needle insertion in a more naturalistic environment. As the first of a series of evaluations, the input system interface will be presented and discussed in this paper.","","978-1-5090-5727-6","10.1109/TISHW.2016.7847779","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847779","augmented reality;image-guided surgery;human-computer interaction","Surgery;Acoustics;Probes;Augmented reality;Needles;Optical imaging","augmented reality;human computer interaction;image representation;medical image processing;surgery;user interfaces","input system interface;image-guided surgery;augmented reality;human activity;clinical interventions;virtual representations;electromagnetic tracking;ultrasonic probe","","2","","14","IEEE","9 Feb 2017","","","IEEE","IEEE Conferences"
"GeoSolvAR: Augmented Reality Based Solution for Visualizing 3D Solids","N. Kaur; R. Pathan; U. Khwaja; S. Murthy","IDP-Educational Technology, IIT, Bombay; IDP-Educational Technology, IIT, Bombay; IDP-Educational Technology, IIT, Bombay; IDP-Educational Technology, IIT, Bombay","2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT)","13 Aug 2018","2018","","","372","376","Visualization is an important skill required to understand 3-Dimensional (3D) geometry concepts involving solids. However, 3D visualization is fairly difficult as it involves complex tasks like mental rotation and spatial transformations. Traditional methods of teaching 3D solids concepts such as static 2D images and physical models are not adequate to build these abilities in students. Also, existing geometry software packages restricts the user to interact and manipulate objects on the computer screens and not in real 3D space. In this paper, we have designed and developed an Augmented Reality (AR) based application-GeoSolvAR, that targets middle school students for improving their visualization skills. Learning activities in GeoSolvAR build on theoretical foundations of Predict-Observe-Explain (POE) strategy to teach the concepts of 3D views like the top, the side and the front view. This paper also reports results and observations obtained from a qualitative pilot study conducted on four 7th grade students. Purpose of the study was to know students' perception of GeoSolvAR's role in helping them visualize 3D solids and to encounter challenges faced by them while interacting with GeoSolvAR.","2161-377X","978-1-5386-6049-2","10.1109/ICALT.2018.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8433541","3D Geometry;Augmented Reality;Visualisation","Three-dimensional displays;Visualization;Solid modeling;Geometry;Solids;Two dimensional displays;Augmented reality","augmented reality;computer aided instruction;data visualisation;geometry;software packages;solid modelling;teaching","static 2D images;geometry software packages;middle school students;visualization skills;Predict-Observe-Explain strategy;3-Dimensional geometry concepts;GeoSolvAR;Augmented Reality;3D solid visualization;3D solids concepts teaching","","2","","19","IEEE","13 Aug 2018","","","IEEE","IEEE Conferences"
"Kullback-Leibler Divergence based Marker Detection in Augmented Reality","S. Susan; S. Tandon; S. Seth; M. T. Mudassir; R. Chaudhary; N. Baisoya","Department of Information Technology, Delhi Technological University, Delhi, Bawana Road, India; Department of Information Technology, Delhi Technological University, Delhi, Bawana Road, India; Department of Information Technology, Delhi Technological University, Delhi, Bawana Road, India; Department of Information Technology, Delhi Technological University, Delhi, Bawana Road, India; Department of Information Technology, Delhi Technological University, Delhi, Bawana Road, India; Department of Information Technology, Delhi Technological University, Delhi, Bawana Road, India","2018 4th International Conference on Computing Communication and Automation (ICCCA)","29 Jul 2019","2018","","","1","5","A marker is a pre-defined pattern that is scanned for in augmented reality videos. Its presence when detected would provide the exact location for the placement of the 3D object in the video. The accurate detection of markers is based on efficient matching strategies, correlation being the most common measure. In this experimental study, we investigate the utility of the Kullback-Leibler (KL) divergence for marker matching and detection. This requires the marker intensities to be normalized to a probability distribution since the KL divergence measures the distance between two probability distributions.","2642-7354","978-1-5386-6947-1","10.1109/CCAA.2018.8777570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777570","Kullback-Leibler divergence;Marker Detection;Augmented Reality","Pattern matching;Videos;Correlation;Probability distribution;Entropy;Augmented reality;Feeds","augmented reality;image matching;object detection;probability","probability distribution;KL divergence;Kullback-Leibler divergence;marker detection;augmented reality videos;marker matching strategies","","2","","18","IEEE","29 Jul 2019","","","IEEE","IEEE Conferences"
"Public facilities location search with augmented reality technology in Android","G. S. Budhi; R. Adipranata","Informatics Department, Petra Christian University, Surabaya, Indonesia; Informatics Department, Petra Christian University, Surabaya, Indonesia","Proceedings of International Conference on Information, Communication Technology and System (ICTS) 2014","15 Jan 2015","2014","","","195","198","In this research we developed an application for public facilities search with augmented reality technology so that search becomes easier and has an attractive interface. This application takes advantages of hardware that resides on the mobile device such as data connection, GPS, geomagnetic / digital compass and accelerometer. To perform a search, user directs the mobile device in the direction he wants and the application will display an icon of public facilities that are found and combined with real images coming from camera. Data residing on server and locally on mobile device so that applications can be run whether there is no internet connection. In order for local data on mobile devices are always up to date, application will synchronize with data contained on server.","","978-1-4799-6858-9","10.1109/ICTS.2014.7010582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7010582","augmented reality;public facilities search;android","Augmented reality;Servers;Mobile handsets;Synchronization;Hardware;Androids;Humanoid robots","augmented reality;facility location;mobile computing;public administration","public facility location search;augmented reality technology;mobile device;server;Android;camera","","2","","12","IEEE","15 Jan 2015","","","IEEE","IEEE Conferences"
"Motivating Pre-service Teachers with Augmented Reality to Developing Instructional Materials through Project-Based Learning Approach","S. Chookaew; S. Howimanporn; W. Sootkaneung; C. Wongwatkit","Department of Teacher Training in Mechanical Engineering, King Mongkut's University of Technology North Bangkok, Bangkok, Thailand; Department of Teacher Training in Mechanical Engineering, King Mongkut's University of Technology North Bangkok, Bangkok, Thailand; Department of Computer Engineering, Rajamangala University of Technology Phra Nakhon, Bangkok, Thailand; Department of Computer and Information Technology, King Mongkut's University of Technology Thonburi, Bangkok, Thailand","2017 6th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","16 Nov 2017","2017","","","780","784","Pre-service teachers play a crucial role in educational system as they are required to be well-prepared for their future teaching to students. Hence, they should be able to construct their own teaching materials effectively. Presently, Augmented Reality has widely been adopted to make learning and teaching environments more engaging and interesting. Therefore, this study employs the advantages of AR technology to motivate the pre-service teachers in constructing the teaching materials. Project-based learning approach has been used in this proposal by requiring the pre-service teachers developing their materials in a structural manner with higher-order thinking process. By analyzing the motivation questionnaires, it has found that the proposed approach has motivated them both males and females to construct their teaching materials. This novel approach could help enhance the preparation of educational system.","","978-1-5386-0621-6","10.1109/IIAI-AAI.2017.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113349","pre-service teacher;augmented reality;learning motivation;project-based learning;instructional material","Augmented reality;Mobile handsets;Planning;Robots;Training","augmented reality;computer aided instruction;human factors;teaching","augmented reality;instructional materials;educational system;future teaching;teaching materials;pre-service teacher motivation","","2","","25","IEEE","16 Nov 2017","","","IEEE","IEEE Conferences"
"Comparative Analysis of Marker and Marker-less Augmented Reality in Education","P. J; V. M; V. G. Pai; A. M","Electronics and Communication Engineering Department, PES University, Bangalore, Karnataka, India; Electronics and Communication Engineering Department, PES University, Bangalore, Karnataka, India; Electronics and Communication Engineering Department, PES University, Bangalore, Karnataka, India; Electronics and Communication Engineering Department, PES University, Bangalore, Karnataka, India","2020 IEEE International Conference for Innovation in Technology (INOCON)","1 Jan 2021","2020","","","1","4","Augmented Reality (AR) is the rendering of elements such as text, images, videos, 3D objects, etc into our real-world environment. In this paper, we have used this technology to bring a change in the vision of education (online mostly while staying remotely) to help students understand the concepts for example Engineering Mathematics, Electromagnetism, etc. by bringing 3D models of the concepts superimposed into the real world. The paper has been divided into two parts: The first part consists of the marker-based AR approach where an image target is brought in front of the camera to superimpose it with 3D model here. It consists of feature extraction, feature description and feature matching, homography, projection and bringing 3D object to scene. The second part is the development of an Android application using Marker less AR approach explaining an engineering concept. We have used 3D models and necessary UI elements. A comparison of both the parts of the work has been made.","","978-1-7281-9744-9","10.1109/INOCON50539.2020.9298303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298303","Augmented Reality(AR);Homography;ORB-Oriented FAST and Rotated BRIEF;RANSAC- Random Sample Consensus;SLAM- Simultaneous Location and Mapping;Unity 3D;Vuforia SDK","Three-dimensional displays;Augmented reality;Solid modeling;Education;Feature extraction;Visualization;Operating systems","augmented reality;computer aided instruction;feature extraction","marker-based AR approach;image target;feature extraction;feature description;feature matching;UI elements;comparative analysis;augmented reality","","2","","7","IEEE","1 Jan 2021","","","IEEE","IEEE Conferences"
"Proposition of a 3D pattern for e-learning augmented reality applications based on ARToolkit library","B. Mohamed; B. Mohamed","Lire laboratory, University of Mentouri, Constantine, Algeria; Lire laboratory, University of Mentouri, Constantine, Algeria","International Conference on Education and e-Learning Innovations","24 Nov 2012","2012","","","1","4","The augmented Reality aims to enhance the view of the user by adding objects that were not perceptible a priori. One of its fields of application is e-learning, it can be used to create applications for educational purposes, instructive and illustrative in the field of education and in particular to enable a distant teacher to do real time synchronous illustrations. In this paper, we propose a 3D pattern that is a dodecahedron whose faces are markers of the ARToolkit library that are black square with a motif on the inside. This pattern has the advantage of being more robust to the orientation change and allows a distant teacher in e-learning to enhance it with 3D virtual objects.","","978-1-4673-2225-6","10.1109/ICEELI.2012.6360672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360672","augmented reality;patterns;ARToolkit;markers","Augmented reality;Cameras;Educational institutions;Electronic learning;Real-time systems;Robustness","augmented reality;computer aided instruction;distance learning","3D pattern;e-learning augmented reality;ARToolkit library;distant teacher;real time synchronous illustrations;3D virtual objects","","2","","10","IEEE","24 Nov 2012","","","IEEE","IEEE Conferences"
"Augmented reality Virtual Class Box for digital learning services","E. Cahyadi; H. A. Santoso; Y. Bandung; A. Z. R. Langi","Digital Signal Processing Research and Technology Group, School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia; Digital Signal Processing Research and Technology Group, School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia; Digital Signal Processing Research and Technology Group, School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia; Digital Signal Processing Research and Technology Group, School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia","2012 International Conference on Cloud Computing and Social Networking (ICCCSN)","14 Jun 2012","2012","","","1","4","Our previous research has successfully developed Virtual Class Box prototype that uses multimedia conference technology to provide digital learning service. This technology however faces a limitation in coverage and distance because the system needs a dedicated wireless infrastructure. Our recent research is to break this limitation by proposing augmented reality concept and design to provide digital learning service. This new concept is expected to be able provide the service using existing commercial communication network with low bandwidth.","","978-1-4673-1816-7","10.1109/ICCCSN.2012.6215754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6215754","virtual class;augmented reality;digital learning","GSM;Hardware;Materials;Augmented reality;Multimedia communication;Bandwidth;Software","augmented reality;computer aided instruction;multimedia computing","augmented reality virtual class box;digital learning services;multimedia conference technology;dedicated wireless infrastructure;commercial communication network","","2","","4","IEEE","14 Jun 2012","","","IEEE","IEEE Conferences"
"Fraud Detection by Facial Expression Analysis Using Intel RealSense and Augmented Reality","N. Prasad; K. Unnikrishnan; R. Jayakrishnan","Dept. of CSE, Rajiv Gandhi Institute of Tech., Kottayam, India; Dept. of CSE, Rajiv Gandhi Institute of Tech., Kottayam, India; Innovation Labs Ernst and Young, Trivandrum","2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)","10 Mar 2019","2018","","","919","923","Fraud detection embodies all the processes that help in the identification of actual or fraud that is expected to take place within an organization. Every organization must equip themselves to combat this possibility of fraud. Global Fraud Study done by The Association of Certified Fraud Examiners' (ACFE) identified that on an average, an organization loses approximately 5% of revenues to fraud annually. This accounts to approximately $3.7 trillion losses of revenue, on a global scale. As a solution, the proposed system aims at providing an augmented reality aided approach to detect fraud from the facial expressions of the prospective customers. The micro expressions that a person involuntary exhibits while experiencing an emotion is used to determine the intention of the suspected person. These micro expressions shed light on the probability that the/she is indeed lying. The result of which can be used to screen the customer's intention and behaviour. This has been achieved with the help of Intel's 3D camera namely RealSense.","","978-1-5386-2842-3","10.1109/ICCONS.2018.8663219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663219","Augmented Reality;Intel RealSense;Micro expressions;Unity","Cameras;Face;Face recognition;Conferences;Augmented reality;Lips;Control systems","augmented reality;cameras;face recognition;fraud","facial expression analysis;augmented reality;facial expressions;microexpressions;fraud detection;Intel RealSense;customer intention;customer behaviour","","2","","12","IEEE","10 Mar 2019","","","IEEE","IEEE Conferences"
"Teaching High School Computer Science with Videos of Historical Figures -- An Augmented Reality Approach","C. -Y. Hsu; M. -W. Chen; C. -C. Wu","Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan; Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan; Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan","2015 International Conference on Learning and Teaching in Computing and Engineering","18 Jun 2015","2015","","","22","25","This study investigated the effects of teaching history of computing with videos of historical figures. Augmented reality (AR) techniques were applied to assist student accessing the videos of historical figures while reading a printed textbook. Whenever a student was interested in a historical figure, one could use a tablet PC to scan the figure's picture, and the corresponding video about the person would then be played on the screen. We adapted thirteen videos of historical figures in computer network field and adopted a quasi-experimental method to evaluate the effectiveness of the AR-based learning approach. Two classes of high school students, with a total of 84 students, participated in the experiment. One class of the students used Tablet PCs to access the videos of historical figures, and the other class using traditional didactic instruction served as the control group. The data collected for analysis are students' achievement test scores and answers to a questionnaire, which consists of questions on attitudes toward learning, perspectives of nature of science, and perceptions on the AR activities. Our findings showed that the AR-based historical figure videos helped students comprehend learning contents and promoted their attitudes toward learning. Students appreciated the convenience of using AR tools to access the history videos. Future research should investigate other approaches to integrate AR with the videos of historical figure, and in general, to integrate AR with other media format of computing history.","","978-1-4799-9967-5","10.1109/LaTiCE.2015.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7126226","history of computing;videos;historical figures;augmented reality","Videos;History;Education;Computers;Augmented reality;Context;Computer networks","augmented reality;computer aided instruction;computer science education;notebook computers","high school computer science teaching;videos;historical figures;augmented reality approach;computing history;AR-based learning approach;printed textbook;tablet PC computer network field;quasiexperimental method;didactic instruction;AR activities;media format;learning contents","","2","","8","IEEE","18 Jun 2015","","","IEEE","IEEE Conferences"
"Learners' motivation in an augmented reality E-learning system","Y. -c. Chen","Chinese Culture University, Taipei, Taiwan, ROC","2013 International Conference on Engineering, Technology and Innovation (ICE) & IEEE International Technology Management Conference","17 Dec 2015","2013","","","1","6","Learning math may not sound interesting to most students. However, motivation is an essential factor to promote academic performance and learning satisfaction. Augmented reality technology combines virtual and real worlds and gives users interesting visual experiences. Since related research is still limited, the purpose of this study is to investigate whether AR helps improve math learning motivation. In this study, Keller's ARCS model was applied to evaluate learning motivation. The results showed that the participants in the AR group were more motivated in learning math especially in the attention and satisfaction subscales. The results will be valuable when instructors want to adopt AR technology in developing math instructional materials and math class.","","978-1-4673-7383-8","10.1109/ITMC.2013.7352609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352609","Augmented reality;motivation;ARCS model","Augmented reality;Education;Solid modeling;Multimedia communication;Computational modeling;Instruments;Reliability","augmented reality;human factors;learning management systems;mathematics computing","e-learning system;learning satisfaction;augmented reality technology;math learning motivation;ARCS model;AR technology;math instructional material","","2","","24","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Seamless Annotation Display for Augmented Reality","S. Yonemoto","Graduate School of Information Science, Kyushu Sangyo University, Fukuoka, Japan","2013 International Conference on Cyberworlds","12 Dec 2013","2013","","","387","387","This paper proposes seamless display connection between two display styles, AR display and table-top display. The former is used in most augmented reality applications, and the latter is used in table-top display. Our framework supports three types of annotations, inner annotation, outer annotation and adaptive annotation. We developed the prototype system that can seamlessly switch the two display styles.","","978-1-4799-2246-8","10.1109/CW.2013.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680161","augmented reality;marker-less tracking;homography transformation","Monitoring;Augmented reality;Educational institutions;Prototypes;Painting;Information science;Electronic mail","augmented reality;computer displays","seamless annotation display connection;display styles;AR display;table-top display;augmented reality applications;inner annotation;outer annotation;adaptive annotation","","2","","1","IEEE","12 Dec 2013","","","IEEE","IEEE Conferences"
"Efficient mobile museum guidance system using augmented reality","Jihyun Oh; Moon-Hyun Lee; H. Park; J. -I. Park; Jong-Sung Kim; Wookho Son","Department of Electronics and Computer Engineering, Hanyang University, Seoul, Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, Korea; Electronics and Telecommnications Research Institute, Daejeon, South Korea; Electronics and Telecommnications Research Institute, Daejeon, South Korea","2008 IEEE International Symposium on Consumer Electronics","9 Jul 2008","2008","","","1","4","We propose a mobile augmented reality (AR) system for helpful and efficient museum guidance. The system can provide not only useful information of exhibitions such as their inside view, origination, and how-to-use, but also a variety of interactions with the exhibitions. The system prototype is implemented on ultra mobile personal computer (UMPC) which is equipped with a camera, an ultrasound receiver, and a gyro sensor. The system function consists of two parts: tracking part, and event handling and visualization part. The tracking part consists of two parts again: global pose tracking part using ultrasound sensors and a gyro sensor, and local pose tracking part using a vision sensor which computes effectively the camera pose under less-controlled environments by combining edge information with feature point information of the camera images. The usefulness of the proposed system and user satisfaction are evaluated through the experimental results in various scenarios.","2159-1423","978-1-4244-2422-1","10.1109/ISCE.2008.4559482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4559482","Mobile augmented reality;position and pose tracking;museum guidance","Augmented reality;Cameras;Image sensors;Ultrasonic imaging;Prototypes;Mobile computing;Microcomputers;Sensor systems;Visualization;Computer vision","augmented reality;data visualisation;edge detection;feature extraction;humanities;image sensors;mobile computing;pose estimation;tracking;video cameras","mobile museum guidance system;mobile augmented reality system;ultra mobile personal computer;video camera;ultrasound receiver;gyro sensor;global pose tracking;event handling;data visualization;ultrasound sensor;local pose tracking;vision sensor;image edge information;image feature point information;user satisfaction evaluation","","2","1","5","IEEE","9 Jul 2008","","","IEEE","IEEE Conferences"
"ARCoins. An Augmented Reality App for Learning about Numismatics","M. . -C. Juan; M. Loachamín-Valencia; I. Garcia-Garcia; J. M. Melchor; J. Benedito","Instituto Universitario de Automática e Informática Industrial, Universitat Politècnica de València, València, Spain; Instituto Universitario de Automática e Informática Industrial, Universitat Politècnica de València, València, Spain; DSIC Universitat Politècnica de València, Valencia, Spain; Josep Benedito Universitat Jaume I; Universitat Jaume I, Castello de la Plana, Comunitat Valenciana, ES","2017 IEEE 17th International Conference on Advanced Learning Technologies (ICALT)","7 Aug 2017","2017","","","466","468","Museum visitors need support tools to facilitate their informal learning. In this paper, we present ARCoins, an augmented reality app to support informal learning about numismatics. Our app helps museum visitors to read the deteriorated text of coins and also shows additional information that offers a clear idea of the general meaning of the coinage of the coins. The app recognizes the real coins. We carried out a study to determine the potential of the app. A total of twenty-eight subjects between 19 and 65 years old participated in the study. The participants observed the real coins using ARCoins and a magnifying glass. From the results, ARCoins allows the participants to read the deteriorated text and even observe the most imperceptible details of the coins. There were statistically significant differences for reading the text when the participants used ARCoins and the magnifying glass in favour of ARCoins. The participants preferred ARCoins for a more enriching museum experience. ARCoins could be a valuable AR app for informal learning about numismatics in museums.","2161-377X","978-1-5386-3870-5","10.1109/ICALT.2017.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8001834","ARCoins;Augmented Reality;informal learning;museums;numismatics;cultural heritage","Glass;Augmented reality;Androids;Humanoid robots;Mobile handsets;Cameras;Cultural differences","augmented reality;computer aided instruction;museums","ARCoins;augmented reality app;numismatics;museum visitors;informal learning;coinage;coins;museum experience;valuable AR app","","2","","6","IEEE","7 Aug 2017","","","IEEE","IEEE Conferences"
"Using Augmented Reality Technology for the Development of Historic Building Teaching Application: A Mackay Culture Course","K. -Y. Chin; C. -X. Hou; C. -S. Wang; K. -F. Lee","Department of Digital Humanities, Aletheia University, New Taipei City, Taiwan; Department of Digital Humanities, Aletheia University, New Taipei City, Taiwan; Department of Computer Science and Information Engineering, Aletheia University, New Taipei City, Taiwan; Department of Computer, National Taipei University of Technology, Taipei City, Taiwan","2017 IEEE 17th International Conference on Advanced Learning Technologies (ICALT)","7 Aug 2017","2017","","","87","88","This study proposes a mobile augmented-reality teaching system focused on historic buildings that enables users to build a deeper understanding of the building structure, features, historical references and era influence while simultaneously exploring the historic site through the interaction effect that combines the virtual and the real. This increases overall interest in architecture and history. In this study, five students will operate the AR system to study how Mackay Culture influenced Tamsui and a satisfaction survey with both the questionnaire survey and an interview will be utilized to determine if participants are receptive to our proposed system and provide feedback on how to make subsequent improvements on our model.","2161-377X","978-1-5386-3870-5","10.1109/ICALT.2017.7","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8001726","Augmented reality;Historic building;Mobile teaching system;Digital guide system","Augmented reality;Buildings;Education;Mobile communication;Legged locomotion;Urban areas;Cultural differences","architecture;augmented reality;buildings (structures);computer aided instruction;educational courses;history;mobile learning;teaching","historic building teaching application;Mackay culture course;mobile augmented-reality teaching system;architecture;Tamsui","","2","","9","IEEE","7 Aug 2017","","","IEEE","IEEE Conferences"
"Augmented Reality for Tissue Converting Maintenance","S. Coscetti; D. Moroni; G. Pieri; M. Tampucci","Institute of Information Science and Technologies, National Research Council of Italy, Pisa, Italy; Institute of Information Science and Technologies, National Research Council of Italy, Pisa, Italy; Institute of Information Science and Technologies, National Research Council of Italy, Pisa, Italy; Institute of Information Science and Technologies, National Research Council of Italy, Pisa, Italy","2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","16 Apr 2020","2019","","","585","590","Tissue converting lines represent one of the key plants in the paper production field: thanks to them, paper tissue is converted into its final form for domestic and sanitary usage. One of the critical points of the tissue converting lines is the productivity and the possibility to follow the conversion process at a relatively low cost. Although the actual lines have high productivity yet, the study of state of the art has shown that choke-points still exist, caused by inadequate automation. In this paper, we present the preliminary results of a project which aims at removing such obstacles towards complete automation, by introducing a set of innovations based on ICT solutions applied to advanced automation. In detail, advanced computer vision and video analytics methods will be applied to monitor converting lines pervasively and to extract automatically process information to self-regulate either specific machine and global parameters. Augmented reality interfaces are being designed and developed to support converting line monitoring and maintenance, both ordinary and extraordinary. An Artificial Intelligence module provides suggestions and instructions to the operators in order to guarantee the production level even in the case of unskilled staff. The automation of such processes will improve factory safety, decrease manual interventions, and, thus, will increase production line up-time and efficiency.","","978-1-7281-5686-6","10.1109/SITIS.2019.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9067909","tissue converting;augmented reality;artificial intelligence;factory of the future","Augmented reality;Prototypes;Three-dimensional displays;Production;Monitoring;Image recognition;Cameras","artificial intelligence;augmented reality;computer vision;computerised monitoring;paper industry;paper products;production engineering computing;production facilities;production management;productivity;safety","converting line monitoring;production level;production line up-time;tissue converting maintenance;tissue converting lines;paper production field;paper tissue;domestic usage;sanitary usage;critical points;actual lines;advanced automation;advanced computer vision;video analytics methods;augmented reality interfaces","","2","","18","IEEE","16 Apr 2020","","","IEEE","IEEE Conferences"
"Collabrative Education UI in Augmented Reality from Remote to Local","Y. Yao; D. Wu; Y. Liu","Rapid Manufacture Engineering Center, Shanghai University, Shanghai, China; Rapid Manufacture Engineering Center, Shanghai University, Shanghai, China; College of Software, Dalian University of Technology, Dalian, China","2009 First International Workshop on Education Technology and Computer Science","26 May 2009","2009","2","","670","673","The goal of this paper is to provide a easy way for manipulating 3D graphical object in remote education system. We describe a remote collaborative framework running in an augmented reality environment. It provides a nature operation interface for manipulating graphics object in the Web browser or applications from different locations. A Jabber like protocol is designed to translate geometry information and transformation status which reduce the total amount of data transmission. We will discuss the structure of this method, and demonstrate its usability with practical applications.","","978-1-4244-3581-4","10.1109/ETCS.2009.409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959124","remote collaboration;augmented reality;ARSGF","Augmented reality;Collaborative work;Layout;Application software;Computer science education;Systems engineering education;Protocols;Buildings;Educational technology;Collaboration","augmented reality;computational geometry;computer aided instruction;graphical user interfaces;groupware;Internet;protocols","collaborative education;augmented reality;3D graphical object;remote education system;Web browser;geometry information;transformation status;data transmission;Jabber protocol","","2","","11","IEEE","26 May 2009","","","IEEE","IEEE Conferences"
"A Card-Based Interaction to Design Visualizations in Augmented Reality Environments","I. Victor Costa; V. Favacho Queiroz; B. Pinto Miranda; A. Abreu de Freitas; C. Gustavo Resque dos Santos; B. Serique Meiguins","Laboratory of Visualization, Interaction and Intelligent Systems (LABVIS), Federal University of Para, Brazilt; Laboratory of Visualization, Interaction and Intelligent Systems (LABVIS), Federal University of Para, Brazilt; Laboratory of Visualization, Interaction and Intelligent Systems (LABVIS), Federal University of Para, Brazilt; Laboratory of Visualization, Interaction and Intelligent Systems (LABVIS), Federal University of Para, Brazilt; Laboratory of Visualization, Interaction and Intelligent Systems (LABVIS), Federal University of Para, Brazilt; Laboratory of Visualization, Interaction and Intelligent Systems (LABVIS), Federal University of Para, Brazilt","2019 23rd International Conference in Information Visualization ??? Part II","26 Aug 2019","2019","","","52","55","The use of objects for generating virtual content is increasingly present in the daily life of computer user. This form of interaction, called tangible interfaces, generates ways of visualizing data in different ways, such as Augmented Reality, which with the help of a given marker can present the user with a specific content. Thus, this work aims to demonstrate a prototype, which through cards as tangible objects, create, manipulate and interact with visualization techniques. Presenting the architecture developed for the development of the prototype, as well as the interaction approach according to the tasks of InfoVis. The prototype also seeks to offer collaboration among users, diversifying and facilitating learning about concepts and InfoVis.","","978-1-7281-2850-4","10.1109/IV-2.2019.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811944","Tangible Objects, Information Visualization, Augmented Reality, Collaborative Environments","Data visualization;Visualization;Prototypes;Augmented reality;Task analysis;Games;Tools","augmented reality;human computer interaction","tangible objects;visualization techniques;card-based interaction;augmented reality environments;virtual content;computer user;tangible interfaces;InfoVis","","2","","22","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"A Cloud-Based Framework to Enhance Augmented Reality","C. -T. Kao; K. -Y. Jan; R. C. S. Chen","Cloud System Software Institute, Institute for Information Industry, Taipei, Taiwan; Cloud System Software Institute, Institute for Information Industry, Taipei, Taiwan; Cloud System Software Institute, Institute for Information Industry, Taipei, Taiwan","2013 Seventh International Conference on Complex, Intelligent, and Software Intensive Systems","19 Sep 2013","2013","","","78","82","We propose a cloud-based framework for AR applications. The framework is combined of state-of-the-art Virtualization Desktop Infrastructure (VDI) of Personal Cloud Computer (PC2) and parallel computing technique of MapReduce. We design a sophisticated client-server architecture to enhance performance of multi-user Augmented Reality (AR) application. Computing load balance is the design concern between client devices and application servers. A multi-user AR game is used as case study running on parallel Virtual Machines (Vs.). We also explore the concurrent AR mechanism on cooperation VMs. Finally, we conclude our proposed work and point future work.","","978-0-7695-4992-7","10.1109/CISIS.2013.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603870","cloud;virtual desktop;augmented reality;client-server;rendering","Servers;Games;Augmented reality;Rendering (computer graphics);Cameras;Decoding;Computer architecture","augmented reality;client-server systems;cloud computing;game theory;parallel programming;software architecture;virtual machines","cloud-based framework;augmented reality;AR applications;virtualization desktop infrastructure;VDI;personal cloud computer;PC2;parallel computing;MapReduce;client-server architecture;multiuser AR game;parallel virtual machines","","2","","17","IEEE","19 Sep 2013","","","IEEE","IEEE Conferences"
"Development of Augmented Reality-Based Application to Search for Electric Appliances and Furniture","K. Sato; T. Soejima; M. Saito; R. Sasage; N. Kamioka; N. Goto; Y. Kawai","Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan; Department of Information Systems, Bunkyo University, Chigasaki, Japan","2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech)","8 Apr 2021","2021","","","214","216","This study developed an application to promote purchases through functions that are not available in existing shopping applications, based on the expansion and growth of e-commerce sites and the increase in the conversion of physical stores to e-commerce. The developed application uses augmented reality (AR) to place virtual objects in real space and allow the user to set the desired size of the item. The application can also search for products based on the size of the retrieved object data and present the actual product.","","978-1-6654-1875-1","10.1109/LifeTech52111.2021.9391825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391825","augmented reality;home electric appliances;furniture;electronic commerce;Smartphone application","Image color analysis;Conferences;Search problems;Life sciences;Surface texture;Task analysis;Augmented reality","augmented reality;domestic appliances;electronic commerce;purchasing","e-commerce sites;physical stores;augmented reality-based application;electric appliances;furniture;purchases;shopping applications;AR;virtual objects","","2","","7","IEEE","8 Apr 2021","","","IEEE","IEEE Conferences"
"Augmented Reality Experiences in Informal Education","M. Petrovich; M. Shah; A. Foster","Drexel University, Philadelphia, PA, US; Drexel University, Philadelphia, PA, US; Drexel University, Philadelphia, PA, US","2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)","17 Jan 2019","2018","","","815","819","The development of several digital technologies has enabled educators and researchers to approach learning and education from a personalized perspective. At the forefront of this technological-pedagogical development is augmented reality (AR). Though research has demonstrated AR's implementations within formal learning environments, there is a distinct lack of research evaluating AR applications within informal learning environments. In order to address this gap in literature, this study provides a systematic review of empirical investigations involving AR applications in informal learning settings. In total, eighteen (18) articles were examined between the time period of 2010 to 2017. Preliminary analysis has revealed several similarities between experiments within formal and informal learning environments such as expected learning outcomes, research design, and data collection methods. This review looks to expand on these overarching trends to answer questions regarding how AR implementations vary across formal and informal contexts.","2470-6698","978-1-5386-6522-0","10.1109/TALE.2018.8615396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615396","augmented reality;informal learning;systematic review","Education;Augmented reality;Bibliographies;Databases;Data collection;Keyword search;Australia","augmented reality;computer aided instruction","augmented reality experiences;informal education;digital technologies;technological-pedagogical development;formal learning environments;AR applications;informal learning environments;research design;learning outcomes;preliminary analysis;data collection methods;systematic review","","2","","31","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Interactive learning methods: Leveraging persoalized learning and augmented reality","T. M. Brown; J. L. Gabbard","Industrial and Systems Engineering, Virginia Polytechnic Institute and State University, Blacksburg, Virginia; Industrial and Systems Engineering, Virginia Polytechnic Institute and State University, Blacksburg, Virginia","2015 International Conference on Interactive Collaborative Learning (ICL)","5 Nov 2015","2015","","","38","38","Personalized learning is tailoring learning to meet the skill level, strengths, challenges and personal needs of individual students. Augmented reality technologies project virtual objects onto real world objects. These technologies create new levels of engagement for students while simultaneously increasing students' test performance. In this poster we describe how combining these two areas of research will result in knowledge needed to inform the design of hands-on, rich experiences to learning.","","978-1-4799-8707-8","10.1109/ICL.2015.7318217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318217","Augmented Reality;Personalize Leanring;interactive learning methods;geometry","Geometry;Augmented reality;Learning systems;Systems engineering and theory;Collaborative work;Collaboration","augmented reality;computer aided instruction;human computer interaction","interactive learning methods;personalized learning;augmented reality technologies;student engagement level","","2","","","IEEE","5 Nov 2015","","","IEEE","IEEE Conferences"
"Technological Acceptance Model (TAM) using Augmented Reality in University Learning Scenarios","W. L. Gavilanes López; B. Rocio Cuji; M. J. Abásolo; G. L. Aguirre Sailema","Facultad de Ciencias Humanas y de la Educación, Universidad Tecnica de Ambato, Ambato, Tungurahua, EC; Facultad de Ciencias Humanas y de la Educación, Universidad Tecnica de Ambato, Ambato, Tungurahua, EC; Instituto de Investigación en Informática, Facultad de Informática, Universidad Nacional de La Plata; Escuela Superior Politécnica de Chimborazo","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","6","The present work analyzes the degree of technological acceptance of educational contents enriched with Augmented Reality (AR) by university students, mainly if these contents have been designed by some students to others. The research was carried out with students of the Information Technology Teaching Career of the Faculty of Human Sciences and Education of the Technical University of Ambato, who designed and created contents on a specific subject for a group of students of the careers of Educational Psychology and Basic Education. The process carried out to design the contents is described and the analysis of the experience is detailed through the TAM Technological Acceptance Model, the evaluation of the designed educational resource, as well as a pre-test and a post-test to evaluate the learning. In this particular experience of university education the results show that the use of AR has awakened a high degree of acceptance and motivation, and the contents enriched with RA have been easy and useful and have allowed an improvement in learning.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760784","Augmented Reality;TAM Model;mobile devices content;learning","Instruments;Education;Augmented reality;Information systems;Videos;Engineering profession;Biological system modeling","augmented reality;computer aided instruction;educational institutions;psychology;teaching;technology acceptance model","educational contents;university students;university education;augmented reality;educational psychology;TAM;educational resource;technological acceptance model;university learning scenarios;information technology teaching career;Faculty of Human Sciences and Education;Technical University of Ambato;basic education","","2","","","","15 Jul 2019","","","IEEE","IEEE Conferences"
"A design of XML schema for information presentation system using augmented reality in new generation network management","K. Wada; Y. Kawahara; T. Asami","University of Tokyo, Japan; University of Tokyo, Japan; University of Tokyo, Japan","2009 ITU-T Kaleidoscope: Innovations for Digital Inclusions","20 Nov 2009","2009","","","1","7","In coming ubiquitous network society, a user who has no knowledge about network technology might have to manage his/her network including information appliances and sensor networks. Current network is, however, too difficult to manage because protocols to access ubiquitous network devices are not same and it is not easy to identify the cause of problems if a network failure occurs. Toward uniting protocols to access devices, we have designed Tambourine framework, which uses REST API to hide SNMP, NET-CONF and proprietary protocols for sensor networks and enables users to manage network devices using HTTP and XML under resource-oriented architecture. However, original Tambourine framework does not have an information presentation system which provides users with information without understanding of the network configuration. To bind real devices with the logical network configuration, we focus on Augmented Reality (AR) technology and designed an information presentation system using AR technology. AR technology enables users to monitor the device information which is displayed on that device. The object overlaid on AR is configured by an XML file, which describes main Computer Graphics (CG) object, size, font, color, degree of transparency, position and decoration. By using XML, developers can utilize XML processing technologies as represented by Web service technologies. In addition, XML has broad utilities, and our system provides users with an information presentation which meets their requirements. Furthermore, our system has user identification system and flexible information presentation system which is able to change CG objects according to the user's request.","","978-92-61-12891-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5338924","Augmented Reality;Network Management;New Generation Network;Information Presentation","XML;Augmented reality;Access protocols;Character generation;Knowledge management;Technology management;Home appliances;Resource management;Computerized monitoring;Computer graphics","augmented reality;computer graphics;computer network management;distributed sensors;protocols;ubiquitous computing;XML","XML schema;information presentation system;augmented reality;new generation network management;ubiquitous network;sensor networks;proprietary protocols;Tambourine framework;REST API;SNMP;NET-CONF;HTTP;resource-oriented architecture;computer graphics","","2","","12","","20 Nov 2009","","","IEEE","IEEE Conferences"
"Time Machine: A Mobile Augmented Reality System for Tourism Based on Coded-Aperture Camera","D. Feng; D. Meng; Y. Zhang; D. Weng","School of Optoelectronics, Beijing Institute of Technology, Beijing, China; School of Optoelectronics, Beijing Institute of Technology, Beijing, China; School of Optoelectronics, Beijing Institute of Technology, Beijing, China; School of Optoelectronics, Beijing Institute of Technology, Beijing, China","2013 IEEE 10th International Conference on Ubiquitous Intelligence and Computing and 2013 IEEE 10th International Conference on Autonomic and Trusted Computing","30 Jan 2014","2013","","","502","506","Time Machine is an Augmented Reality (AR) system for enhancing tourists' traveling experience. Based on optimized panoramic images, we proposed a novel spatiotemporal interactive approach which imbues users the ability to interact with both the spatial world and its history. Time machine utilizes panorama of a specific place at different time for achieving interactions with temporal dimension. It also adopts interior panorama of landmark building which can be used by the user to interact with the physical world. Additionally, the panoramas optimized by aperture-coded camera can alleviate the noisy foreground information such as crowds and address defocus blurring to improve the quality of panorama.","","978-1-4799-2482-0","10.1109/UIC-ATC.2013.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726250","panorama;aperture-coded camera;spatiotemporal interaction;mobile augmented reality","Cameras;Mobile communication;Mobile handsets;Apertures;Kernel;Augmented reality;Spatiotemporal phenomena","augmented reality;cameras;mobile computing;travel industry","time machine;mobile augmented reality system;coded-aperture camera;tourist traveling experience;spatiotemporal interactive approach;noisy foreground information;panorama quality","","2","","19","IEEE","30 Jan 2014","","","IEEE","IEEE Conferences"
"Touring System using Augmented Reality - A Case Study of Yilan Cultural Industries","J. -H. Lo; G. -Z. Gong","Department of Applied Informatics, Fo-Guang University, Yilan, Taiwan; Department of Applied Informatics, Fo-Guang University, Yilan, Taiwan","2020 3rd IEEE International Conference on Knowledge Innovation and Invention (ICKII)","18 Jan 2021","2020","","","204","207","As Taiwan is developing tourism industry in recent years, it has become an indispensable part of people's daily lives. However, current tourist guide system lacks an integrated solution and travelers have difficulties to obtain the information on attractions due to outdated data. Moreover, available on-line tourist guide apps with google map navigation lack technical breakthrough and innovation. In this research, augmented reality (AR) tourist guide system is developed to construct a backstage database system for automatically updating attractions data. A new framework from Android called “Actionbar Scrollable Tabs” for UI design is used with mobile web technology. The main purpose is to let users gain overall knowledge and the latest information with tour guide system, furthermore, to get rid of tourist guide problems.","","978-1-7281-9333-5","10.1109/ICKII50300.2020.9318893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318893","augmented reality;jquery mobile;location-based system;mobile guidance","Smart phones;Internet;Augmented reality;Technological innovation;Radar;Fingers;Springs","Android (operating system);augmented reality;cultural aspects;graphical user interfaces;Internet;mobile computing;travel industry;user interface management systems","touring system;Taiwan;tourism industry;integrated solution;augmented reality tourist guide system;backstage database system;attractions data;tour guide system;tourist guide problems;Yilan cultural industries;online tourist guide apps;AR tourist guide system;Actionbar Scrollable Tabs;UI design;Android framework;mobile Web technology","","2","","8","IEEE","18 Jan 2021","","","IEEE","IEEE Conferences"
"Haptic and audio displays for augmented reality tourism applications","Side Wei; Gang Ren; E. O'Neill","Department of Computer Science, University of Bath, Bath, UK; Department of Computer Science, University of Bath, Bath, UK; Department of Computer Science, University of Bath, Bath, UK","2014 IEEE Haptics Symposium (HAPTICS)","20 Mar 2014","2014","","","485","488","Augmented Reality (AR) technology has potential for supporting applications such as tourism. However, non-visual interaction modalities are undervalued and underused in AR tourism applications. Visual displays are ineffective or inappropriate in some situations such as in strong sunlight or when walking or driving. Meanwhile, non-visual modalities are becoming increasingly important in mobile user experiences. In this paper, two non-visual interaction modalities, haptic display and audio display, and their combination are evaluated in representing tourism information to users with a mobile phone. An experimental evaluation was conducted with different tourism information presented by haptic display, audio display and both, with 3 different rhythms and 3 levels of amplitude. The results show a main effect of interaction modality, with identification rate highest for information represented in the combined Haptic-Audio display at 86.7%, while no significant effect was found for rhythm or amplitude alone. Qualitative data from the participants indicated that, across all interaction modalities, different levels of amplitude were more difficult to distinguish than different rhythms or different combinations of rhythm and amplitude.","2324-7355","978-1-4799-3131-6","10.1109/HAPTICS.2014.6775503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6775503","Haptic;audio;augmented reality","Haptic interfaces;Mobile communication;Rhythm;Visualization;Smart phones;Augmented reality","augmented reality;haptic interfaces;travel industry","audio displays;augmented reality tourism applications;AR tourism applications;nonvisual interaction modalities;tourism information;haptic-audio display","","2","","16","IEEE","20 Mar 2014","","","IEEE","IEEE Conferences"
"Augmented Reality Shopping Framework","P. Souza-Herod; A. Hamam","Computer Engineering Florida Polytechnic University, Lakeland FL, USA; Computer Science Florida Polytechnic University, Lakeland FL, USA","SoutheastCon 2021","21 Apr 2021","2021","","","1","6","Augmented Reality (AR) is becoming an important computing platform with the potential of enhancing the experiences of everyday users. One of those experiences is shopping. When customers buy any product, it is very discouraging to locate vital information such as the expiration date. This paper discusses an AR solution for shoppers that want to elevate their shopping experience in general by an enhanced information search. The solution can be also expanded in the future to assist shoppers who are suffering from a reduced visual sense. A proof of concept application is developed to test the solution, where we simulate a medicine shopping scenario. The application we developed on the HoloLens uses the Vuforia SDK to tag products and display information about these products. In addition, it contains elements that can alter the text size thus providing assistive support option for the visually impaired in the future. We predict that the convenience of having information displayed next to products as well as the ability to control the text size will make shopping more pleasant. Our architecture shows promise for a full assistive technology for the visually impaired that could be vital for the community, and there are future plans to port it to a different platform such as Android or iOS. Moreover, the architecture harnesses the ability to customize the information that the user can select to view, such as instructions, ingredients, and/or users' review. We conclude the paper with our look into the future.","1558-058X","978-1-6654-0379-5","10.1109/SoutheastCon45413.2021.9401926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9401926","Augmented Reality;Shopping;Assistive;HoloLens;Vuforia","Visualization;Assistive technology;Computer architecture;Augmented reality","augmented reality;electronic commerce;handicapped aids;mobile computing;retail data processing;retailing","important computing platform;everyday users;vital information;expiration date;AR solution;shoppers;shopping experience;enhanced information search;reduced visual sense;concept application;medicine shopping scenario;Vuforia SDK;display information;text size;assistive support option;assistive technology;future plans;different platform;augmented Reality shopping framework","","2","","23","IEEE","21 Apr 2021","","","IEEE","IEEE Conferences"
"Computer Supported Collaborative Design Using Augmented Reality","T. Gjosaeter","Department of Information and media science, University of Bergen, Bergen, Norway","2009 International Workshop on Social Informatics","4 Sep 2009","2009","","","35","40","While doing a usability evaluation of an augmented reality application (FurnitAR), interesting aspects of the application in regards to collaborative design were uncovered. FurnitAR can perhaps make one step in the furniture design process – the creation of a mock-up model in for instance cardboard – more efficient. FurnitAR was proposed as a solution to make the creation of mock-ups more in line with the CAD process. An evaluation of FurnitAR revealed that it could enhance the prototyping process of furniture design and provides new ways to support collaboration during the design process.","","978-0-7695-3706-1","10.1109/SocInfo.2009.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230716","augmented reality;CSCW;CSCD;furniture design","Augmented reality;Prototypes;Collaborative work;Process design;Design automation;Software prototyping;International collaboration;Application software;Visualization;Informatics","augmented reality;CAD;furniture;furniture industry;groupware;production engineering computing;user interfaces","computer supported collaborative design;augmented reality;usability evaluation;FurnitAR;furniture design process;CAD process;prototyping process","","2","","10","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"Augmented Reality to Support Multi-Criteria Decision Making in Building Retrofitting","V. Sangiorgio; M. Silvia; F. Fatiguso","DICATECH, Politecnico di Bari, Bari, Italy; DICATECH, Politecnico di Bari, Bari, Italy; DICATECH, Politecnico di Bari, Bari, Italy","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","760","765","In the decision-making process, many complex problems may be difficult to deal with traditional approaches. In particular, in the construction sector, the large volume of information and the involvement of non-expert users can make time consuming and inconsistent the choice. In this paper, a new method supported by the Augmented Reality (AR) is proposed to simplify and improve the decision-making process. Such novel approach starts from the theoretical basis of the Analytic Hierarchy Process (AHP) and Simos-Roy-Figueira method (SRF) and develops a virtual environment to support the decision-making. In particular the AR provide a large amount of visual information transforming a complex decision method in a user-friendly tool. The proposed approach is applied in the field of building energy retrofitting in order to demonstrate its effectiveness. In particular, the goal of the analysis is the selection of the best panel, chosen from a set of experimental Precast Construction Panels, to improve the envelope performances of existing buildings. The decision involved both quantitative data (such as costs and thermal behavior) and qualitative data (such as the aesthetic impact).","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9283420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283420","Augmented Reality;Multi-criteria decision methods;Building retrofitting;Precast Concrete Panels","Visualization;Buildings;Virtual environments;Tools;Concrete;Augmented reality;Testing","analytic hierarchy process;augmented reality;building management systems;buildings (structures);decision making;maintenance engineering;structural engineering computing","augmented reality;multicriteria decision making;building retrofitting;decision-making process;complex problems;construction sector;nonexpert users;analytic hierarchy process;complex decision method;user-friendly tool;experimental precast construction panels;AHP;Simos-Roy-Figueira method;SRF;AR;aesthetic impact","","2","","20","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Web 2.0 Meets Wearable Augmented Reality","T. N. Hoang; S. R. Porter; B. Close; B. H. Thomas","Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia","2009 International Symposium on Wearable Computers","22 Sep 2009","2009","","","151","152","This paper explores how a wearable computer with an augmented reality interface can provide real time contextual interactions, based on location aware Web 2.0 social network information.","2376-8541","978-0-7695-3779-5","10.1109/ISWC.2009.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254665","Web 2.0;Wearable Computing;Augmented Reality","Augmented reality;Visualization;Global Positioning System;Wearable computers;Social network services;Twitter;Context awareness;Computer displays;Libraries;Information resources","augmented reality;graphical user interfaces;mobile computing;wearable computers;Web services","location aware Web 2.0 social network;wearable computer;augmented reality interface;real time contextual interaction","","2","","4","IEEE","22 Sep 2009","","","IEEE","IEEE Conferences"
"Knowledge Acquisition and Representation in Facility Management: Facility Management with Semantic Technologies and Augmented Reality","C. -A. Schumann; E. Forkel; F. Otto; E. Müller; M. Clauß; A. Lanka","Inst. for Manage. & Inf., West Saxon Univ. of Appl. Sci. Zwickau, Zwickau, Germany; Institute for Management and Information, West Saxon University of Applied Sciences Zwickau, Zwickau, Germany; Institute for Management and Information, West Saxon University of Applied Sciences Zwickau, Zwickau, Germany; Technische Universitat Chemnitz, Chemnitz, Sachsen, DE; Institute for Management and Information, West Saxon University of Applied Sciences Zwickau, Zwickau, Germany; Department of Factory Planning and Factory Management, Chemnitz University of Technology, Chemnitz, Germany","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20 Mar 2017","2016","","","1005","1009","One more and more upcoming challenge for IT systems used in the Facility Management domain is the automated acquisition and processing of distributed heterogeneous data. Especially for approval or maintenance processes the mobile access to necessary data constantly gains significance. But because of their limited size particularly mobile devices require new ways for representing the needed amount of information. This conceptual paper discusses new approaches of knowledge acquisition and representation, which enable the efficient support of facility managers in their daily tasks. The underlying research project develops concepts and solutions for the semantic modelling and linking of distributed data as well as its context-based representation on a mobile device via Augmented Reality.","","978-1-5090-5510-4","10.1109/CSCI.2016.0192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881485","Semantic Technologies;Augmented reality;Knowledge Acquisition;Knowlwdge Representation;Facility management","Semantics;Prototypes;Context;Ontologies;Unified modeling language;Facilities management;Augmented reality","augmented reality;knowledge acquisition;mobile computing","knowledge acquisition;facility management;augmented reality;automated acquisition;distributed heterogeneous data;mobile devices","","2","","5","IEEE","20 Mar 2017","","","IEEE","IEEE Conferences"
"Virtual studio system for augmented reality & Chroma key processing","S. Kim","Department of Multimedia, Hannam University, Daejeon, South Korea","13th International Conference on Advanced Communication Technology (ICACT2011)","7 Apr 2011","2011","","","762","765","Chroma key image synthesis, out of Images A and B, makes transparent a specific scope of Image B and reflects Image A on it, and the chroma key which can synthesize an object with a desired background realizes an effect that the object seems to exist in that background. By combining real information with virtual information in this process and applying AR(Augmented Reality) technology to increase information delivery, an inexpensive and convenient HD virtual studio can be applied. That is, even though upcoming HD digital broadcasting service requires a shift from existing SD to HD resolution is required for HD digital broadcasting service, most of the HD equipments are expensive. Therefore, there are needed a low-priced HD virtual studio system which is being used only in public broadcasting network and a HD virtual studio system with chroma key applied.","1738-9445","978-89-5519-155-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5745923","Augmented Reality;Chroma Key;Image Processing;Visual Studio;Virtual Studio","High definition video;Education;Broadcasting;Augmented reality;Media;Real time systems;Servers","augmented reality;digital multimedia broadcasting;image processing;telecommunication computing","augmented reality;chroma key processing;chroma key image synthesis;HD digital broadcasting service;HD virtual studio system;high-definition","","2","","10","","7 Apr 2011","","","IEEE","IEEE Conferences"
"The effects of augmented-reality head-up display system on the perception of precautionary situation","Y. Hwang; B. -J. Park; K. -H. Kim","IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; IT Convergence Technology Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea","2015 International Conference on Information and Communication Technology Convergence (ICTC)","17 Dec 2015","2015","","","1146","1148","This study is to ensure the effects of an augmented-reality head-up display (AR-HUD) system on the perception of precautionary traffic situation. We performed the experiment in order to collect the drivers' response time as the perception on the objective precautionary situation. And the Driving Behavior Determinants questionnaire was used to collect the driver's psychological characteristics. As a result, the difference of response time on the precautionary situation was not statistically significant between two groups: AR-HUD system usage condition and control condition. However, five factors of DBD were differently correlated with the perception on the precautionary situation in each two groups.","","978-1-4673-7116-2","10.1109/ICTC.2015.7354760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7354760","Augmented-Reality Head-Up Display;driving safety;response time;usability","Vehicles;Time factors;Psychology;Safety;Augmented reality;Vehicle crash testing;Engineering profession","augmented reality;head-up displays;traffic engineering computing","augmented reality head-up display system;AR-HUD system;objective precautionary situation perception;behavior determinant questionnaire;driver psychological characteristics","","2","","10","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Context Awareness Aims at Novel Fruition Models: Augmented Reality May be the Killer Application for Context Awareness","C. Venezia; M. Marengo","Strategy and Innovation, Telecom Italia, Milano, Lombardia, IT; Strategy and Innovation, Telecom Italia, Turin, Italy","2010 IEEE/IFIP International Conference on Embedded and Ubiquitous Computing","28 Jan 2011","2010","","","392","396","In this paper we describe the achievement of a Context Aware platform capable of collecting contextual user data and also information about users' surrounding context such as relevant Point of Interests. We also analyze the complexity of exploiting a large amount of collected data through a proper interactive system without affecting applications' usability and avoiding information overload. We finally detail the achievement of an Augmented reality user interface which serves as pedestrian navigator towards context aware Point of Interests.","","978-1-4244-9719-5","10.1109/EUC.2010.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5703550","Context Awareness;Augmented reality;Context APIs;Recommendation techniques","Context;Navigation;Augmented reality;Context-aware services;Mobile communication;Cameras;Mobile handsets","augmented reality;graphical user interfaces;ubiquitous computing","context awareness;augmented reality;contextual user data;user interface;context aware point-of-interest","","2","1","13","IEEE","28 Jan 2011","","","IEEE","IEEE Conferences"
"AR Digestive System: 3D Visualization of the Digestive System with Augmented Reality","K. C. Trinidad; D. L. P. Villa; I. H. R. Portillo; F. E. Saldaña","Departament of Electrical and Computer Engineering, Universidad Autónoma de Ciudad Juárez, Juarez City, Mexico; NA; NA; Departament of Electrical and Computer Engineering, Universidad Autónoma de Ciudad Juárez, Juarez City, Mexico","2013 International Conference on Mechatronics, Electronics and Automotive Engineering","16 Jan 2014","2013","","","90","95","The following document presents the development process of a new, educational tool that utilizes 3D modeling techniques, and augmented reality to enable third and fourth-graders to better visualize the digestive system. Moreover, results obtained from a questionnaire applied to two groups in a private school in Ciudad Juarez, Chihuahua, are presented. The questionnaire was composed of diagnose questions about the presented topic, as well as the use of it.","","978-1-4799-2253-6","10.1109/ICMEAE.2013.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6713961","augmented reality;digestive system;3D modeling;educational tools;immersive learning;Head Mounted Display","Digestive system;Augmented reality;Three-dimensional displays;Animation;Visualization;Educational institutions","augmented reality;biomedical education;data visualisation;educational aids;educational technology","AR digestive system;3D visualization;augmented reality;educational tool;3D modeling techniques","","2","","5","IEEE","16 Jan 2014","","","IEEE","IEEE Conferences"
"SIMNET: Simulation-Based Exercises for Computer Network Curriculum Through Gamification and Augmented Reality","M. G. Gramajo; F. Trejo Lezcano; S. G. Lobo; G. Juarez; A. L. Fraga","CIDISI, Centro de Investigación y Desarrollo de Ingeniería en Sistemas de Información, UTN - FRSF, Santa Fe, Argentina; Departamento de Sistemas, UTN-FRT, San Miguel de Tucumán, Argentina; Departamento de Sistemas, UTN-FRT, San Miguel de Tucumán, Argentina; Departamento de Sistemas, UTN-FRT, San Miguel de Tucumán, Argentina; UTN - FRSF, CONICET, INGAR - Instituto de Desarrollo y Diseño, Santa Fe, Argentina","2018 IEEE World Engineering Education Conference (EDUNINE)","30 Aug 2018","2018","","","1","5","Gamification and Augmented Reality techniques, in recent years, have tackled many subjects and environments. Its implementation can, in particular, strengthen teaching and learning processes in schools and universities. Therefore, new forms of knowledge, based on interactions with objects, contributing game, experimentation and collaborative work. Through the technologies mentioned above, we intend to develop an application that serves as a didactic tool, giving support in the area of Computer Networks. This tool aims to stand out in simulated controlled environments to create computer networks, taking into account the necessary physical devices and the different physical and logical topologies. The main goal is to enrich the students' learning experiences and contribute to teacher-student interaction, through collaborative learning provided by the tool, minimizing the need for expensive equipment in learning environments.","","978-1-5386-4889-6","10.1109/EDUNINE.2018.8450974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8450974","Gamijication;Augmented Reality;Simulation-based exercises","Tools;Computer networks;Games;Education;Androids;Humanoid robots;Augmented reality","augmented reality;computer aided instruction;computer games;computer networks;computer science education;educational institutions;groupware;teaching","computer network curriculum;gamification;Augmented Reality techniques;teaching;learning processes;schools;universities;collaborative work;didactic tool;computer networks;teacher-student interaction;collaborative learning;learning environments;SIMNET;simulation-based exercises","","2","","16","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Augmented Reality for Accessible Digital Mental Healthcare","V. Lush; C. Buckingham; S. Wileman; S. Edwards; U. Bernardet","Computer Science, Aston University, Birmingham, UK; Computer Science, Aston University, Birmingham, UK; Enlighten, Tamworth, UK; Enlighten, Tamworth, UK; Computer Science, Aston University, Birmingham, UK","2019 5th Experiment International Conference (exp.at'19)","21 Oct 2019","2019","","","274","275","It is estimated that one person dies every 40 seconds due to suicide and there are indications that for each fatal suicide attempt conducted by an adult, there may be more than 20 other suicide attempts. Public healthcare resources to support individuals who are at risk of mental ill health are increasingly thinly stretched. This calls for new ways of disseminating mental health knowledge and support to those who need, but lack it. In this demonstration, we present an interactive Augmented Reality (AR) system for mental health information dissemination and self-assessment. The advantage of the system is that it provides direct pathway to relevant mental health resources and offers a positive incentive and interventions for at-risk users.","","978-1-7281-3637-0","10.1109/EXPAT.2019.8876554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876554","Augmented Reality;Mental Health;Mental Health Disorders;Self-Assessment Tools.","Tools;Augmented reality;Mobile handsets;Psychiatry","age issues;augmented reality;health care;information dissemination;medical computing;medical information systems","mental ill health;mental health knowledge;interactive Augmented Reality system;mental health information dissemination;mental health resources;digital mental healthcare","","2","","7","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality in Nursing Educational Environments","E. Quqandi; M. Joy; M. Rushton; I. Drumm","Computer Science Department, Warwick University, Coventry, UK; Computer Science Department, Warwick University, Coventry, UK; School of Health and Society, The University of Salford, Manchester, UK; Computer, Science and Engineer, The University of Salford, Manchester, UK","2018 10th Computer Science and Electronic Engineering (CEEC)","28 Mar 2019","2018","","","266","269","The possibility of using Augmented Reality (AR) in learning and training has become more straightforward than before, as a result of the extensive use of Information and Communication Technologies (ICT) in the computer and mobile industries. Even though AR is used in education, and it is generally acknowledged that it has a positive impact on learning outcomes, the value of integrating AR applications into learning environments has not yet been fully investigated [1]. This in progress work considers the integration of AR technology into nursing clinical lab training, introduces new ways of interacting with manikins, and allows students to view patient scenarios instead of relying on teacher explanations. AR allows students to visualize hidden objects such as internal organs, which makes simulations more realistic and immersive. The study investigates the potential of this technology in terms of enhancing nursing students' self-regulation skills.","","978-1-5386-7275-4","10.1109/CEEC.2018.8674182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674182","Augmented Reality;Mobile Learning;Nursing;Higher Education;Self-learning;Self-Regulation;Clinical skills","Medical services;Education;Augmented reality;Three-dimensional displays;Solid modeling;Videos;Task analysis","augmented reality;biomedical education;computer aided instruction;medical computing;mobile computing;patient care","learning environments;AR technology;clinical lab training;patient scenarios;nursing educational environments;ICT;mobile augmented reality;information and communication technologies;hidden objects visualization;nursing students self-regulation skills;manikins","","1","","17","IEEE","28 Mar 2019","","","IEEE","IEEE Conferences"
"Safety view management for augmented reality based on MapReduce strategy on multi-core processors","Hsiao-Chien Tsai","Division for Telematics and Vehicular Control System, Industrial Technology Research Institute, HsinChu, Taiwan, R.O.C","2013 13th International Conference on ITS Telecommunications (ITST)","19 Dec 2013","2013","","","151","156","Augmented reality (AR) can enrich intelligent transportation systems by overlaying virtual traffic information on user's view. Pedestrians and drivers using AR applications can read traffic information and keep their eye on roads at the same time without distracting attentions. However, any information displayed on device screens may overlay on moving objects on roads and obstruct user's view which causes traffic safety problems. This paper proposes a mechanism called safety view management to display information on AR applications in a safer way. When display labels or annotations on a device screen, the safety view management mechanism provides a safety region which does not overlap moving objects on the screen to increase driving safety. To efficiently detect safety region on a screen, the view management mechanism adopts MapReduce to analyze moving objects in parallel way on multi-core processors. Performance evaluations show that the proposed mechanism can efficiently calculate a safety region on screens and keeps drivers and passengers' remain safety view in smart cars.","","978-1-4799-0846-2","10.1109/ITST.2013.6685537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6685537","augmented reality;object detection;MapReduce;parallel computing;view management","Safety;Cameras;Vehicles;Prototypes;Roads;Telecommunications;Augmented reality","augmented reality;intelligent transportation systems;mobile handsets;multiprocessing systems;road safety","traffic safety problems;virtual traffic information;intelligent transportation systems;multicore processors;MapReduce strategy;augmented reality;safety view management","","1","","10","IEEE","19 Dec 2013","","","IEEE","IEEE Conferences"
"Autonomous electromagnetic mapping system in augmented reality","J. Rioult; S. Delgrande; N. Bremard; G. Copin; V. Deniau","IFSTTAR, Villeneuve d’Ascq, France; IRCICA/CRIStAL, Villeneuve d’Ascq, France; IRCICA/CRIStAL, Villeneuve d’Ascq, France; Luxondes, Armentières, France; IFSTTAR, Villeneuve d’Ascq, France","2019 International Symposium on Electromagnetic Compatibility - EMC EUROPE","17 Oct 2019","2019","","","138","143","Mapping or scanning the electromagnetic emissions of electronic cards or any environment requires the use of relatively complex mechanical or electronic devices. These systems may be difficult to transport and not well suited to perform measurements in confined environments. Moreover, they can require long acquisition times. Being autonomous, compact and fast, the scanning system proposed in this article aims to overcome these constraints. It makes it possible to map the electromagnetic environment directly on site or in locations difficult to access, such as inside a vehicle for example. This scanner is composed of a smartphone coupled to removable EM field sensors to allow covering different configurations. Using augmented reality technology, it has an interface that allows communication via an USB port between the smartphone and the various sensors. In this paper, the device is described and measurement results illustrating its potential are presented.","2325-0364","978-1-7281-0594-9","10.1109/EMCEurope.2019.8872055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8872055","measurements;mapping;augmented reality","Electromagnetic compatibility;Augmented reality;Universal Serial Bus;Mechanical sensors;Software;Electromagnetics","augmented reality;electronic engineering computing","autonomous electromagnetic mapping system;electromagnetic emissions;electronic cards;electronic devices;electromagnetic environment;augmented reality technology;EM field sensors","","1","","10","IEEE","17 Oct 2019","","","IEEE","IEEE Conferences"
"Implementation of the 3d Digitalized Brochure using Marker-based Augmented Reality for Real Estates","T. P. Ambre; P. P. Khalane; S. D. Kanjiya; J. Kenny","Dept. Of Computer Engineering, Universal College of Engineering, Vasai, India; Dept. Of Computer Engineering, Universal College of Engineering, Vasai, India; Dept. Of Computer Engineering, Universal College of Engineering, Vasai, India; Dept. Of Computer Engineering, Universal College of Engineering, Vasai, India","2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Sep 2020","2020","","","483","487","Nowadays, due to increasing growth in all sectors, be it in healthcare, infrastructure, finance, education, and logistics, etc. the world has come closer to foster their needs. Even though in the era of smart technology constructors, builders are using the traditional method, i.e., usage of brochures by generating 2D sketches of project layout. Builders use these catalogs to sell their construction sites like flats, buildings, or any property to customers by just showing them various floor plans, multiple views, etc. This procedure aims to be unproductive and inefficient because it does not give a clear idea regarding how exactly the property will look. Augmented Reality, shifting to new emerging technology, gives an entirely new perspective for development. This paper discusses the AR implementation that provides many advantages for construction planning, which will help customers to draw a clear view regarding the properties before making deals without actually visiting the sample flats. The paper's focus is to develop an AR-based brochure as a planning tool that will serve as an application to intelligently increase the customers by minimizing their efforts and easing their decision-making process and maximizing the overall productivity.","","978-1-7281-5374-2","10.1109/ICIRCA48905.2020.9183196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183196","Brochure;3D Live models;2D models;Augmented Reality (AR);visual representations","Three-dimensional displays;Solid modeling;Augmented reality;Two dimensional displays;Visualization;Buildings;Computational modeling","augmented reality;decision making;property market;solid modelling","logistics;smart technology constructors;builders;project layout;catalogs;construction sites;buildings;floor plans;entirely new perspective;AR implementation;construction planning;clear view;sample flats;planning tool;3d digitalized brochure;marker-based augmented Reality;real estates;increasing growth;education","","1","","13","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"CooperAR: promoting educational inclusion through augmented reality","J. Quintero; S. Baldiris; J. Cerón; J. Garzón; D. Burgos; G. Vélez",Pontifical Bolivarian University; International University of La Rioja; Pontifical Bolivarian University; Catholic University of the East; International University of La Rioja; Pontifical Bolivarian University,"2021 International Conference on Advanced Learning Technologies (ICALT)","2 Aug 2021","2021","","","311","313","Augmented reality (AR) is an emerging technology that has been successfully integrated into education. However, the use of AR as a tool to achieve educational inclusion has not been deeply explored. This study introduces CooperAR, a methodology aimed at attending educational inclusion, understanding inclusion as a process where the needs of all students are taken into consideration. CooperAR focuses on the creation of AR-based learning scenarios, in which teachers and students become co-creators of content. The methodology is based on the principles of Universal Design for learning and the Cooperative Learning approach. The effectiveness of CooperAR was validated in the context of a case study that involved 66 students. The results showed promising results, suggesting that CooperAR is an efficient methodology to promote educational inclusion through cooperation.","2161-377X","978-1-6654-4106-3","10.1109/ICALT52272.2021.00100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499926","augmented reality;co-creation;cooperative learning;educational inclusion;universal design for learning","Education;Tools;Task analysis;Augmented reality","augmented reality;computer aided instruction;educational institutions","educational inclusion;augmented reality;AR-based learning scenarios;cooperative learning approach;CooperAR methodology","","1","","10","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"Quimo: A deformable material to support freeform modeling in spatial augmented reality environments","E. T. A. Maas; M. R. Marner; R. T. Smith; B. H. Thomas","Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia","2011 IEEE Symposium on 3D User Interfaces (3DUI)","29 Apr 2011","2011","","","111","112","This poster discusses a new free-form modeling material called Quimo (Quick Mock-up), designed for use in spatial augmented reality environments. Quimo is a white malleable material that can be sculpted and deformed with bare hands into an approximate model. The material is white in color, retains its shape once sculpted, and allows for later modification. Projecting imagery onto the surface of the low-fidelity mock-up allows for detailed prototype visualizations to be presented.","","978-1-4577-0064-4","10.1109/3DUI.2011.5759230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759230","Spatial Augmented Reality;Industrial Design;Deformable Surface;Quimo","Materials;Solid modeling;Surface treatment;Shape;Augmented reality;Three dimensional displays;Prototypes","augmented reality","Quimo;deformable material;freeform modeling;spatial augmented reality environments;free-form modeling material;quick mock-up","","1","","9","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"Realization of Robot Fish with 3D Hologram Fish using Augmented Reality","J. Y. Lee; J. -W. Lee; T. Talluri; A. Angani; J. B. Lee","Dept of ICT Creative Design, Busan University of Foreign Studies, Busan 46234, Republic of Korea; Dept of ICT Creative Design, Busan University of Foreign Studies, Busan 46234, Republic of Korea; Dept of ICT Creative Design, Busan University of Foreign Studies, Busan 46234, Republic of Korea; Dept of ICT Creative Design, Busan University of Foreign Studies, Busan 46234, Republic of Korea; Dept of ICT Creative Design, Busan University of Foreign Studies, Busan 46234, Republic of Korea","2020 IEEE 2nd International Conference on Architecture, Construction, Environment and Hydraulics (ICACEH)","3 Mar 2021","2020","","","102","104","The present research designed a tracking system of fish with 3D holographic augmented reality (AR). To track the fish, OpenCv through a camera with an algorithm was used. 3D holographic fish followed color marks that were used to track the fish. If the marks disappeared, 3D holographic fish stopped swimming. This process was repeated until the algorithm stopped. This experiment showed that 3D holographic fish followed the real fish.","","978-1-7281-7722-9","10.1109/ICACEH51803.2020.9366226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9366226","Robot fish;3D holographic fish;Augmented reality;Color mark","Three-dimensional displays;Tracking;Robot kinematics;Color;Fish;Augmented reality;Sports","augmented reality;autonomous underwater vehicles;cameras;holography;image colour analysis;mobile robots;robot vision","3D holographic fish;robot fish;3D hologram fish;tracking system;3D holographic augmented reality;AR;OpenCv;color marks","","1","","16","IEEE","3 Mar 2021","","","IEEE","IEEE Conferences"
"Augmented Reality Lightfield Display for a Smart Window Using an Active Pinhole Array","M. Park; H. Lee; H. -J. Choi","Department of Physics and Astronomy, Sejong University, Seoul, South Korea; Department of Physics and Astronomy, Sejong University, Seoul, South Korea; Department of Physics and Astronomy, Sejong University, Seoul, South Korea","IEEE Access","9 Dec 2019","2019","7","","171974","171979","An augmented reality (AR) lightfield display can provide three-dimensional (3D) images at the locations of real objects. However, a conventional AR lightfield display has a few disadvantages in that its 3D resolution is poor and it is bulky in form owing to the use of an optical combiner or relay optics. In this paper, we propose a novel method to realize an AR lightfield display using a transparent display and an active pinhole array (APA) to enhance both the 3D resolution and visibility of real objects. An experimental demonstration verifies that the proposed method is appropriate for smart window applications.","2169-3536","","10.1109/ACCESS.2019.2956605","National Research Foundation of Korea; Ministry of Education(grant numbers:2018R1D1A1B07049563); Technology Innovation Industrial Program; Ministry of Trade, Industry and Energy(grant numbers:10052667); Research and Business Development Program through the Korea Institute for Advancement of Technology (KIAT); Ministry of Trade, Industry and Energy(grant numbers:P0004078); Information Technology Research Center (ITRC) support Program supervised by the Institute for Information and Communications Technology Promotion (IITP)(grant numbers:IITP-2017-2015-0-00448); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917551","Augmented reality;lightfield reconstruction;active pinhole array","Three-dimensional displays;Image resolution;Optical imaging;Holography;Holographic optical components;Liquid crystal displays;Augmented reality","augmented reality;display instrumentation;image resolution;stereo image processing","augmented reality lightfield display;active pinhole array;three-dimensional imaging;optical combiner;AR lightfield display;transparent display;smart window applications;3D imaging;3D resolution;relay optics;APA","","1","","16","CCBY","28 Nov 2019","","","IEEE","IEEE Journals"
"3D Natural Interaction for an Augmented Reality System","K. Mouna; A. M. Mohamed","Telecom Department, Centre de Développement des Technologies Avancées, Algiers, Algeria; Informatics Department, USTHB Université des Sciences et de la Technologie, Algiers, Algeria","2019 International Conference on Advanced Electrical Engineering (ICAEE)","2 Mar 2020","2019","","","1","6","3D natural interaction is one of the topics actively investigated, by both researchers and developers, in order to provide more systems allowing users to interact with the 3D contents in an easy and an intuitive manner by using natural body inputs. In this work, we present an augmented reality system in which the user can interact naturally using the voice to select and manipulate 3D objects. Two ways are used to integrate vocal commands in the system (i) using the Speech Recognition API (Windows) as an offline solution (ii) using Speech Services (IBM Watson) as on the cloud solution. Furthermore, we show our application meant to teach the DNA molecule's 3D form, this application is capable of visualizing the whole molecule as well as its different components, it provides the user by multiple annotations to enhance their information and knowledge, also several voice commands can be used by pronouncing either simple words or longer phrases in a natural way.","","978-1-7281-2220-5","10.1109/ICAEE47123.2019.9015075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9015075","3D natural interaction;voice interaction;augmented reality;Natural User Interface (NUI);vocal commands;speech recognition;education;biomedical teaching;DNA molecule","Three-dimensional displays;Augmented reality;Speech recognition;DNA;Cloud computing;Visualization;User interfaces","application program interfaces;augmented reality;DNA;speech recognition","3D natural interaction;augmented reality system;natural body inputs;DNA molecule;3D contents;speech recognition API;Windows;speech services;IBM Watson;cloud solution;molecule visualization;vocal commands","","1","","40","IEEE","2 Mar 2020","","","IEEE","IEEE Conferences"
"Augmented Reality life-size flight panel for checklist training","S. K. Füchter; G. Salazar; S. Mario Sergio","Estácio de Santa Catarina University, Florianópolis, Brazil; NASA, Johnson Space Center, Houston, Texas; Estácio de Santa Catarina University, Florianópolis, Brazil","2020 23rd International Symposium on Measurement and Control in Robotics (ISMCR)","23 Nov 2020","2020","","","1","5","A pre-flight checklist requires in-depth technical knowledge of the aircraft and its dashboard, avionics, instruments, functions, and cabin layout. The student in training to be a pilot or advanced pilot, to obtain an updated certification, must know very thoroughly each instrument and its position on the flight panel. Every second spent searching for the location of an instrument, switch or indicator can waste time completing the checklist, resulting in a poor start-up procedure and possibly a safety hazard. This paper reports preliminary findings of using augmented reality (AR) technology in a training setting. The objective of this research was to obtain preliminary data to determine if the use of AR as a human interface for training can help pilots improve their skills and help them learn new flight panel layouts of different aircraft more efficiently and effectively than traditional training methods. For this research, the methodology used was Human-Centered Design (HCD) which is a multidisciplinary process that involves many actors who collaborate on design skills, including people who belong to this process such as flight instructors, students, and pilots. A mobile / tablet application prototype was created for the user to have in their pocket, a rich experience with enough detail of a flight panel of a Cessna150, an aircraft used in training flights at the Santa Catarina Aero club. The tests were applied in Brazil and the results showed a good response and acceptance from the users from the users from the users.","","978-1-6654-0479-2","10.1109/ISMCR51255.2020.9263717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9263717","Augmented Reality;Virtual Training;Flight Panel","Training;Industries;Instruments;Layout;Aerospace electronics;Aircraft;Augmented reality","aerospace computing;augmented reality;avionics;computer based training;design engineering;user centred design;user interfaces","flight instructors;flight training;checklist training;pre-flight checklist;cabin layout;safety hazard;human interface;flight panel layouts;aircraft layout;human-centered design;augmented reality life-size flight panel;HCD","","1","","11","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Technology in Digital Advertising","C. -C. Kiu; K. -W. N. Andrew; W. -L. Lee; C. -W. Chan","School of Computing and IT, Taylor’s University, Subang Jaya, Malaysia; School of Computing and IT, Taylor’s University, Subang Jaya, Malaysia; School of Computing and IT, Taylor’s University, Subang Jaya, Malaysia; School of Computing and IT, Taylor’s University, Subang Jaya, Malaysia","2018 Fourth International Conference on Advances in Computing, Communication & Automation (ICACCA)","29 Jul 2019","2018","","","1","6","Advertisers today have a vast array of mediums to use and the Internet alone gives many advertising opportunities. However new technologies are needed to help achieve various advertising goals and to increase brand awareness. In today's digital edge, mobile applications are widely used in our society. With that, comes the opportunity to introduce a new mode of advertising which is through Augmented Reality (AR) technology. This paper presents architecture framework to implement AR technology in digital advertising. This paper also discusses how customer behavior and big data in improving digital advertising to enhance performance of digital advertising.","2642-7354","978-1-5386-7167-2","10.1109/ICACCAF.2018.8776686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8776686","Augmented Reality;Digital Advertising;Big Data Analytics","Advertising;Augmented reality;Big Data;Industries;Mobile handsets;Cameras","advertising data processing;augmented reality;Big Data;consumer behaviour;Internet;mobile computing","brand awareness;mobile applications;customer behavior;Big Data;Augmented Reality technology;digital edge;advertising goals;advertising opportunities;digital advertising","","1","","18","IEEE","29 Jul 2019","","","IEEE","IEEE Conferences"
"Training Assistant for LACT Process Through Augmented Reality","Y. Y. Montoya; C. G. Pillajo; J. S. Ortiz","Universidad Politécnica Salesiana, Quito, Ecuador; Universidad Politécnica Salesiana, Quito, Ecuador; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador","2020 15th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2020","2020","","","1","6","This article proposes the development of a 3D augmented reality app for mobile devices focused on staff training (training of operators) in the oil industry on the operation of Lease Automatic Custody Transfer Units (LACT Units). First, existing information about LACT Units was collected to define the basic and specific parameters for the virtual creation of a 3D model of the LACT Units (CAD files) which allows the visualization of the equipment and instruments commonly used in the LACT Units, also through the Unity 3D graphic engine a specific sequence of operation is defined attached to a real system. The application focuses on the recognition of P&ID through a smartphone allowing users to make changes in the variables involved in the process, e.g., pressure, temperature and flow, such that, if the user makes any changes to the variables, the system responds according to these changes based on mathematical models of the plant, achieving a more realistic experience between the user and the process.","2166-0727","978-989-54659-0-3","10.23919/CISTI49556.2020.9141081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141081","Augmented Reality;LACT Unit;P & ID;Unity 3D","Three-dimensional displays;Oils;Training;Animation;Solid modeling;Augmented reality;Hydrocarbons","augmented reality;computer based training;continuing professional development;data visualisation;industrial training;mobile computing;personnel;petroleum industry;production engineering computing;production equipment;smart phones;solid modelling","Unity 3D graphic engine;training assistant;LACT process;staff training;lease automatic custody transfer units;LACT units;3D augmented reality app;mobile devices;oil industry;3D model;CAD files;equipment visualization;smartphone","","1","","16","","15 Jul 2020","","","IEEE","IEEE Conferences"
"A study on development scenarios with augmented reality for cultural exploration of beipu historical region in Taiwan","Y. -C. Chen; G. -Z. Liao","Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan; Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan","2011 International Conference on Electrical and Control Engineering","24 Oct 2011","2011","","","6281","6285","The study aims at based on the concept of story scenario, and develops the scenario with augmented reality for cultural exploration of Beipu historical region in Taiwan. The research combines the integration of the people, the matters, the circumstances, and the things in the learning process, then as the references of interaction design. For understanding the Beipu historical region, spatial environment, and the cultural characteristics, the research procedure conducts to investigate in the region and depth interview the experts for surveying residents in order to plan the moving routes in the guided activity. The results of study define the themes and moving routes of guided activity, and hope that the methods of scenario developments consult as others historical region.","","978-1-4244-8165-1","10.1109/ICECENG.2011.6056937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6056937","augmented reality;Beipu historical region;scenario design","Augmented reality;Cultural differences;Educational institutions;Computers;Electronic learning;Media","augmented reality;history","augmented reality;cultural exploration;Beipu historical region;learning process","","1","","","IEEE","24 Oct 2011","","","IEEE","IEEE Conferences"
"A Document Browser Based on a Book-Style Interface with Augmented Reality","M. Nishimura; T. Kagawa; H. Nishino; K. Utsumiya","Department of Computer Science and Intelligent Systems, Oita University, Oita, Japan; Department of Computer Science and Intelligent Systems, Oita University, Oita, Japan; Department of Computer Science and Intelligent Systems, Oita University, Oita, Japan; Oita Daigaku, Oita, JP","2013 Seventh International Conference on Complex, Intelligent, and Software Intensive Systems","19 Sep 2013","2013","","","741","746","We propose a document browsing method based on a book-style interface usable in a normal office environment. Augmented reality (AR) technology is applied to realize an easy-to-use interface. In the proposed method, documents and multi-media contents are projected on a real booklet including an AR marker printed on each page. Users can feel that they are reading a book consisting of document files, presentation files, movies, and images. Furthermore, we utilize the motion sensor Kinect to recognize the users' gestures. The detected gestures can be used to activate some functions such as picking a page up and placing it in a real work space. In this paper, we describe the proposed book-style interface, its implementation method, and evaluate and discuss the effectiveness of the proposed method.","","978-0-7695-4992-7","10.1109/CISIS.2013.133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603983","Augmented Reality;book-style interface;gesture interaction;graphical user interface","Three-dimensional displays;Prototypes;Tracking;Multimedia communication;Augmented reality;Motion pictures","augmented reality;document handling;gesture recognition;human computer interaction;multimedia systems","document browser;document browsing method;book-style interface;office environment;augmented reality;AR technology;easyto-use interface;multimedia contents;booklet;AR marker;motion sensor Kinect;users gesture recognition","","1","","9","IEEE","19 Sep 2013","","","IEEE","IEEE Conferences"
"SculptAR: An augmented reality interaction system","V. A. Sangalli; T. V. de Oliveira; L. P. Soares; M. S. Pinho","PUCRS, Computer Science School, Brazil; PUCRS, Computer Science School, Brazil; PUCRS, Computer Science School, Brazil; PUCRS, Computer Science School, Brazil","2017 IEEE Symposium on 3D User Interfaces (3DUI)","6 Apr 2017","2017","","","260","261","In this work, a 3D mobile interface to create sculptures in an augmented reality environment tracked by AR markers is presented. A raycasting technique was used to interact with the objects in the scene, as well as 2D and 3D interfaces to manipulate and modify the objects. The users can move, delete, paint and duplicate virtual objects using 6 DOFs techniques.","","978-1-5090-6716-9","10.1109/3DUI.2017.7893371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893371","3D Interaction;Augmented Reality;Mobile","Color;Augmented reality;Three-dimensional displays;Painting;Paints;Mobile communication;Two dimensional displays","augmented reality;computer graphics;mobile computing;ray tracing;user interfaces","SculptAR;augmented reality interaction system;3D mobile interface;sculpture creation;AR markers;raycasting technique;2D interfaces;3D interfaces;virtual object duplication","","1","1","4","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Utilizing Apple’s ARKit 2.0 for Augmented Reality Application Development","I. Permozer; T. Orehovački","Faculty of Economics and Tourism „Dr. Mijo Mirkovic“, Juraj Dobrila University of Pula, Pula, Croatia; Faculty of Informatics, Juraj Dobrila University of Pula, Pula, Croatia","2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","11 Jul 2019","2019","","","1629","1634","When it comes to practical augmented reality applications, mobile platform tools are the most deserving. Thanks to the nature of mobile devices and their everyday usage, the ideal basis for this kind of content has inadvertently formed itself. Consequently, within the iOS development environment, Apple's Xcode program enables application development using the ARKit library which delivers a host of benefits. Amongst the plethora of advantages, this paper focuses on utilizing features such as the ability to measure distances between two points in space, horizontal and vertical plane detection, the ability to detect three-dimensional objects and utilize them as triggers, and the consolidated implementation of ARKit and MapKit libraries in conjunction with the Google Places API intended for displaying superimposed computer-generated content on iOS 11 and later iterations of Apple's mobile operating system.","2623-8764","978-953-233-098-4","10.23919/MIPRO.2019.8756928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756928","Apple;AR;ARKit;Augmented Reality;Computer Vision;Core ML;Custom Vision;Google Places;iOS;iPhone;Machine Learning;Map Kit;Microsoft Cognitive;POI;Points of interest;SceneKit;Swift;Xcode","Libraries;Google;Machine learning;Augmented reality;Training;Operating systems;Cameras","application program interfaces;augmented reality;mobile computing","augmented reality application development;mobile platform tools;mobile devices;iOS development environment;horizontal plane detection;vertical plane detection;MapKit libraries;Apple ARKit;Apple mobile operating system;Apple Xcode program;Google Places API","","1","","7","","11 Jul 2019","","","IEEE","IEEE Conferences"
"Tracking chessboard corners using projective transformation for augmented reality","S. Malek; N. Zenati-Henda; S. Benbelkacem; M. Belhocine","Division Robotique & Productique, Centre de Développement des Technologies Avancées Baba Hassen, Algeria; Division Robotique & Productique, Centre de Développement des Technologies Avancées Baba Hassen, Algeria; Division Robotique & Productique, Centre de Développement des Technologies Avancées Baba Hassen, Algeria; Division Robotique & Productique, Centre de Développement des Technologies Avancées Baba Hassen, Algeria","2011 International Conference on Communications, Computing and Control Applications (CCCA)","29 Sep 2011","2011","","","1","6","Augmented reality has been a topic of intense research for several years for many applications. It consists of inserting a virtual object into a real scene. The virtual object must be accurately positioned in a desired place. Some measurements (calibration) are thus required and a set of correspondences between points on the calibration target and the camera images must be found. In this paper, we present a tracking technique based on both detection of Chessboard corners and a least squares method; the objective is to estimate the perspective transformation matrix for the current view of the camera. This technique does not require any information or computation of the camera parameters; it can used in real time without any initialization and the user can change the camera focal without any fear of losing alignment between real and virtual object.","","978-1-4244-9796-6","10.1109/CCCA.2011.6031196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6031196","pinhole model;tracking;augmented reality;Chessboard corners detection","Cameras;Three dimensional displays;Feature extraction;Mathematical model;Computational modeling;Lighting;Augmented reality","augmented reality;calibration;least squares approximations;object detection","projective transformation;augmented reality;virtual object;calibration target;camera images;chessboard corners detection;least squares method","","1","","19","IEEE","29 Sep 2011","","","IEEE","IEEE Conferences"
"Designing to Enhance Student Participation in Campus Heritage Using Augmented Reality","G. Gao; Y. Zhang; C. Cheng; Y. Bu; P. C. Shih","School of Informatics, Computing, and Engineering, Indiana University Bloomington, Bloomington, USA; School of Informatics, Computing, and Engineering, Indiana University Bloomington, Bloomington, USA; School of Informatics, Computing, and Engineering, Indiana University Bloomington, Bloomington, USA; School of Informatics, Computing, and Engineering, Indiana University Bloomington, Bloomington, USA; School of Informatics, Computing, and Engineering, Indiana University Bloomington, Bloomington, USA","2018 3rd Digital Heritage International Congress (DigitalHERITAGE) held jointly with 2018 24th International Conference on Virtual Systems & Multimedia (VSMM 2018)","26 Aug 2019","2018","","","1","4","This paper presents Capsule, a design prototype using augmented reality to encourage students to learn the cultural heritage on campus. Based on a pilot study with prospective and current students, Capsule not only provides students the cultural histories of campus but strengthens the connection between students and heritage by adding features of improving the interaction between students and the heritage. The performance of the prototype was evaluated in a user study with 10 students, which provides design implications for future cultural heritage.","","978-1-7281-0292-4","10.1109/DigitalHeritage.2018.8810077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8810077","Cultural heritage;augmented reality;AR;digital heritage;heritage;mobile;campus heritage","Prototypes;Cultural differences;Mobile handsets;Interviews;Global Positioning System;Augmented reality;History","augmented reality;computer aided instruction;history;human factors","campus heritage;augmented reality;Capsule;design prototype;prospective students;cultural histories;design implications;cultural heritage;student participation","","1","","3","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"Illuminant Condition Matching in Augmented Reality: A Multi-Vision, Interest Point Based Approach","M. Bingham; D. Taylor; Z. Xu; D. Gledhill","University of Huddersfield, Huddersfield, UK; University of Huddersfield, Huddersfield, UK; University of Huddersfield, Huddersfield, UK; University of Huddersfield, Huddersfield, UK","2009 Sixth International Conference on Computer Graphics, Imaging and Visualization","30 Oct 2009","2009","","","57","61","For the output of an augmented reality application to appear realistic a number of issues need to be taken into consideration. The illumination correspondence between the real and virtual components should be taken into account as well as the scene level of detail and the accuracy of alignment between the two worlds. This paper focuses on matching world illumination and photometric registration methods. It introduces a new technique that aims to utilize shadow/object interest point correspondences in order to locate and virtually reproduce real-life illuminants. The technique is attractive as it makes use of natural calibration objects in the form of natural scene geometry and associated shadows. Computational complexity is kept relatively low by using an interest point based approach. Further work to be undertaken is discussed.","","978-0-7695-3789-4","10.1109/CGIV.2009.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5298362","augmented reality;realism;interest points;shadow","Augmented reality;Layout;Photometry;Lighting;Calibration;Application software;Geometry;Military computing;Computational complexity;Computer aided manufacturing","augmented reality;calibration;computational complexity;computational geometry;computer vision;image matching;image registration;natural scenes;photometry;realistic images","real-life illuminant condition matching;augmented reality;multivision approach;shadow/object interest point-based approach;realistic image;virtual component;real component;photometric registration method;natural calibration object;natural scene geometry;computational complexity","","1","1","18","IEEE","30 Oct 2009","","","IEEE","IEEE Conferences"
"Poster: Markerless fingertip-based 3D interaction for handheld augmented reality in a small workspace","Huidong Bai; Lei Gao; M. Billinghurst","The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand","2013 IEEE Symposium on 3D User Interfaces (3DUI)","5 Sep 2013","2013","","","129","130","Compared with traditional screen-touch input, natural gesture-based interaction approaches could offer a more intuitive user experience in handheld Augmented Reality (AR) applications. However, most gesture interaction techniques for handheld AR only use two degrees of freedom without the third depth dimension, while AR virtual objects are overlaid on a view of a three dimensional space. In this paper, we investigate a markerless fingertip-based 3D interaction method within a client-server framework in a small workspace. Our solution includes seven major components: (1) fingertip detection (2) fingertip depth acquisition (3) marker tracking (4) coordinate transformation (5) data communication (6) gesture interaction (7) graphic rendering. We describe the process of each step in details and present performance results of our prototype.","","978-1-4673-6098-2","10.1109/3DUI.2013.6550212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6550212","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities","Three-dimensional displays;Mobile communication;Servers;Mobile handsets;Cameras;Augmented reality;Target tracking","augmented reality;client-server systems;gesture recognition;graphical user interfaces;human computer interaction;object tracking;rendering (computer graphics);smart phones","mobile phone;smart phone technology;graphic rendering;data communication;coordinate transformation;marker tracking;fingertip depth acquisition;fingertip detection;client-server framework;3D space;handheld AR;gesture interaction techniques;small workspace;handheld augmented reality;markerless fingertip-based 3D interaction method","","1","","5","IEEE","5 Sep 2013","","","IEEE","IEEE Conferences"
"Design of a Prototype for Augmented Reality Defective Bone Repair Simulation System","Y. Yao; X. -x. Pang; T. Liu; Q. -x. Hu","Rapid Manufacturing Engineering Center, Shanghai University, Shanghai, China; Rapid Manufacturing Engineering Center, Shanghai University, Shanghai, China; Rapid Manufacturing Engineering Center, Shanghai University, Shanghai, China; Rapid Manufacturing Engineering Center, Shanghai University, Shanghai, China","2009 First International Workshop on Education Technology and Computer Science","26 May 2009","2009","1","","66","70","Combining the exiting bone scaffold design system and augmented reality interactive technology, this paper presents an aided planning and test interactive system frame for defective bone repair surgery, and develops the prototype system based on it. The system allows the clinician to carry out the surgical planning and simulation directly using the virtual model, after designing the CAD model of defective bone scaffold. The results, which can be used to validate and modify the bone scaffold model.","","978-1-4244-3581-4","10.1109/ETCS.2009.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4958727","augmented reality;bone scaffold design;defective bone repair;visualization technology;human-machine interaction","Virtual prototyping;Augmented reality;Bones;Layout;Surgery;Rendering (computer graphics);Computer displays;Design engineering;Computer aided manufacturing;Pulp manufacturing","augmented reality;CAD;digital simulation;interactive systems;medical computing","augmented reality defective bone repair simulation system;interactive system frame;defective bone repair surgery;surgical planning;virtual model;CAD model;bone scaffold model","","1","","13","IEEE","26 May 2009","","","IEEE","IEEE Conferences"
"The use of augmented reality in the maintenance of mechanical objects","O. A. Orlando; S. Markon","Kobe Institute of computing, Kobe, Hyogo Prefecture, Japan; Kobe Institute of computing, Kobe, Hyogo Prefecture, Japan","2017 International Conference on Applied System Innovation (ICASI)","24 Jul 2017","2017","","","842","845","In Kenya, like in most of Africa, many of the existing industries are aged. Due to insufficient resources, maintaining these Industries becomes a challenge. It is important to note that most, if not all, of these industries are key drivers of the economies of these countries. Maintenance of these industries thus becomes a key activity to ensure economic growth. Training of engineers to completely support the industries is also a challenge because of limited resources. Currently engineers have to refer to paper manuals inside the industries as they work and this manuals are getting damaged and hence risk losing the maintenance data. This paper proposes the use of augmented reality technology to be able to provide guidance to engineers as they carry out maintenance activities on equipment. This should be able to improve the quality and accuracy of maintenance activities as per the original equipment manufacturer's (OEM) instructions. This small investment in technology can have an effect of increasing machine life, reduce machine downtimes as maintenance is performed faster and make economic sense in the long term.","","978-1-5090-4897-7","10.1109/ICASI.2017.7988565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988565","Augmented Reality;Maintenance;Low cost","Maintenance engineering;Manuals;Augmented reality;Industries;Power generation;Prototypes;Conferences","augmented reality;maintenance engineering;mechanical engineering computing","mechanical object maintenance;augmented reality technology;original equipment manufacturer;OEM instructions;machine life;machine downtime reduction","","1","","7","IEEE","24 Jul 2017","","","IEEE","IEEE Conferences"
"Ionic and Metallic Bonding Visualization Using Augmented Reality","S. Rostianingsih; A. Setiawan; C. I. Halim","Informatics Department, Petra Christian University, Surabaya, Indonesia; Informatics Department, Petra Christian University, Surabaya, Indonesia; Informatics Department, Petra Christian University, Surabaya, Indonesia","2018 3rd Technology Innovation Management and Engineering Science International Conference (TIMES-iCON)","24 Jan 2019","2018","","","1","4","Augmented Reality (AR) is one of the smartphone technologies that can be used to experience three-dimensional object visualization with integrated information. It can also be used as a support tool for learning different topics. One of these is chemical bonding. Thus, this study aimed to visualize ionic and metallic bonding via the use of AR in order to improve the cognitive skills of students. A marker and three-dimensional model for each chemical element were created. Each marker exhibited a unique pattern that was tracked by the application to obtain visualization. The AR engine and game engine utilized by the application include Vuforia and Unity. This research study created a framework that can be redeveloped to facilitate other types of chemical bonding. However, additional rules, images, and illustrations for the application must be included in the framework.","","978-1-5386-7573-1","10.1109/TIMES-iCON.2018.8621665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621665","augmented reality;ionic bonding;metallic bonding","Bonding;Visualization;Engines;Chemicals;Augmented reality;Iron;Solid modeling","augmented reality;bonds (chemical);data visualisation;solid modelling","smartphone technologies;three-dimensional object visualization;integrated information;support tool;chemical bonding;ionic bonding;metallic bonding;three-dimensional model;chemical element;game engine;augmented reality","","1","","9","IEEE","24 Jan 2019","","","IEEE","IEEE Conferences"
"Implementation of Android-based augmented reality as learning and teaching media of dicotyledonous plants learning materials in biology subject","C. N. Qamari; M. R. Ridwan","Department of Biology Education, Syiah Kuala University, Banda Aceh, Indonesia; Department of Interior Design, Bandung Institute of Technology, Bandung, Indonesia","2017 3rd International Conference on Science in Information Technology (ICSITech)","15 Jan 2018","2017","","","441","446","The field of education so far often make use of technology such as presentation slides and also interactive programs as a learning and teaching media. This study attempted to apply the Android-based augmented reality (AR) technology to display the learning materials in the digital format so the students can observe the overall learning object with the help of Android application. The main aim of this study was to understand the level of interest and inputs from the students related to the provided learning object, so it can be developed better in the next chance. This study was done using the qualitative approach method with the results sourced from the observation and simulation research method, using questionnaire form given to 24 students where the questions were based from the direct simulation using Android smartphone. The results show that 85,4% of the overall students are very interested in using AR media, 95,8% stated strongly agree that the biology learning material becomes more easily understood using AR media, 86,5% stated that AR media is very easy and practical to use, 76% stated strongly agree that their Android smartphone can function well to use AR media, and 65,6% stated that the AR cards used in this study can be scanned easily with using the application. Overall, the average percentage of all students' opinions was 81,9%, which was interpreted as a strongly agreed option that AR media is interesting to be applied as a media for studying dicotyledonous plants in the biology subject.","","978-1-5090-5866-2","10.1109/ICSITech.2017.8257153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8257153","android;augmented reality;interest;learning and teaching media","Media;Three-dimensional displays;Education;Biology;Augmented reality;Androids;Humanoid robots","augmented reality;computer aided instruction;smart phones;teaching","augmented reality;dicotyledonous plants;biology subject;learning materials;Android application;qualitative approach method;simulation research method;Android smartphone;AR media;biology learning material;learning object","","1","","12","IEEE","15 Jan 2018","","","IEEE","IEEE Conferences"
"The AlKesFar App, A Mobile Augmented Reality on Learning Media Tools for Indonesian Pharmacy School","M. Firdaus; Mastuki; J. F. Allan","Department of Informatics Universitas, Surabaya Surabaya, Indonesia; Department of Mechanical, Engineering Universitas, Surabaya Surabaya, Indonesia; Department of Informatics Universitas, Surabaya Surabaya, Indonesia","2018 Third International Conference on Informatics and Computing (ICIC)","1 Aug 2019","2018","","","1","5","In understanding the knowledge of pharmaceuticals, an understanding of medical equipment is essential. In fact, the medical equipment is not all can be seen in the learning process due to limited space and procurement for the tool due to the high price of medical equipment. To resolve this, effective and efficient learning media is required without the need for space and equipment procurement. In this research, we developed an application of AlkesFar based on andorid devices using Augmented Reality (AR) technology to introduce and give understanding about medical equipment. AlKesFar combines AR technology directly on images of medical equipment. AlkesFar was tested on students of class XI SMK Pharmacy Kapasari Surabaya, Indonesia. From the testing results, respondents who answered strongly agree obtained 69%. From this result, AlKeFar application is ready to be applied as a learning media tools for Indonesian Pharmacy School.","","978-1-5386-6921-1","10.1109/IAC.2018.8780491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780491","medical equipment;Augmented Reality;learning media","Biomedical equipment;Augmented reality;Media;Three-dimensional displays;Tools;Presses;Testing","augmented reality;biomedical education;computer aided instruction;medical computing;mobile computing","effective learning media;efficient learning media;equipment procurement;medical equipment;learning media tools;mobile augmented reality;Indonesian pharmacy school;AR;XI SMK Pharmacy Kapasari Surabaya;AlKeFar application","","1","","7","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"Augmented reality registration method based on natural feature points","Q. Li; Y. Li; J. Tian; D. Ren","Chengdu University of Information Technology, Cehngdu, China; Chengdu University of Information Technology, Cehngdu, China; Chengdu University of Information Technology, Cehngdu, China; Chengdu University of Information Technology, Cehngdu, China","2017 IEEE 17th International Conference on Communication Technology (ICCT)","17 May 2018","2017","","","1937","1941","A three-dimensional registration method based on natural feature points is presented, which is applied to the augmented reality system. Firstly, several common feature extraction algorithms have been compared in this paper, and the SIFT algorithm is applied to improve the matching accuracy as a descriptor matching method. And then the data of ten key image frames is used to reconstruct the 3D structure of the scene. When the real-time image data is input, the key frame which mostly matches the current image is selected, and the image matching method based on key frame is used to obtain the camera pose. Finally, improved Lucas-Kanade method for real-time tracking is adopted, not only maintaining the accuracy of registration but reducing the system computing time. The experimental results shown that the method achieves a effect of real-time tracking and accurate registration, and can keep a better registration precision.","2576-7828","978-1-5090-3944-9","10.1109/ICCT.2017.8359967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359967","three-dimensional registration;natural feature points;SIFT algorithm;augmented reality","Cameras;Feature extraction;Image reconstruction;Mathematical model;Augmented reality;Three-dimensional displays;Matrix decomposition","augmented reality;feature extraction;image matching;image registration;transforms","augmented reality registration method;natural feature points;three-dimensional registration method;common feature extraction algorithms;SIFT algorithm;key image frames;real-time image data;key frame;image matching method;improved Lucas-Kanade method;real-time tracking;registration precision","","1","","11","IEEE","17 May 2018","","","IEEE","IEEE Conferences"
"Case study of the development app of infographics design with mobile augmented reality","C. -C. Chiu; C. -T. Lee","National Taipei University of Technology, Taiwan, R.O.C.; National Taipei University of Technology, Taiwan, R.O.C.","2016 International Conference on Advanced Materials for Science and Engineering (ICAMSE)","6 Feb 2017","2016","","","181","184","Today, cultural and creative centers exist in all of the cities and counties in Taiwan and hold numerous events to attract crowds. In response to the arrival of the digital humanities era, this study aimed to develop a novel app that posts information on cultural events. With the assistance of the app and a geographic information system (GIS), the general public or students in senior high school or above can receive the latest information on arts and culture events around them and then actively participate in them as well as gather companions. With numerous apps coming out or being eliminated every day, research has found that smartphone users rarely read information in text form carefully but prefer information presented in a simple and visualized form. The inclusion of augmented reality (AR) interactions makes users more willing to use an app. We first conducted a questionnaire survey to understand user preferences with regard to layout and interface operations. Based on the results, we developed prototypes for the IOS/Android OS environments and incorporated open data for synchronized updates on cultural events. In addition to providing information on cultural events, the app also offers instant access to desired information via AR and infographics. Furthermore, the app can serve as a future source of big data for the analysis of information such as user preferences with regard to cultural events and travel route planning. It is hoped that this achievement can help more people understand more about cultural events throughout Taiwan and be extended to private cultural events and exhibitions.","","978-1-5090-3869-5","10.1109/ICAMSE.2016.7840274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840274","geographic information system;digital humanities;mobile augmented reality;infographics","Cultural differences;Geographic information systems;Mobile communication;Art;Augmented reality;Mobile handsets","Android (operating system);augmented reality;educational institutions;geographic information systems;graphical user interfaces;humanities;iOS (operating system);mobile computing;smart phones","infographics design development app;mobile augmented reality;digital humanities;cultural events;geographic information system;GIS;senior high school;smartphone users;iOS environment;Android OS environment","","1","","5","IEEE","6 Feb 2017","","","IEEE","IEEE Conferences"
"Data compression for photo-based augmented reality on a tablet","F. Ishigami; K. Nagata; M. Ohta; K. Yamashita","Graduate School of Humanities and Sustainable System Sciences, Osaka Prefecture University, Sakai, Osaka, Japan; Graduate School of Engineering, Osaka Prefecture University; Graduate School of Humanities and Sustainable System Sciences, Osaka Prefecture University, Sakai, Osaka, Japan; Graduate School of Engineering, Osaka Prefecture University","2016 IEEE 5th Global Conference on Consumer Electronics","29 Dec 2016","2016","","","1","2","Photo-based Augmented Reality (Photo AR) is an AR system implemented by rendering multi-viewpoint photo images. While having an advantage that this system doesn't require 3D models, this system consumes a large volume of disk space. To resolve this problem, we have proposed the data compression method that handles photo images as video format. However, this method is impractical due to security restriction on a tablet device. Therefore, the purpose of this study is to consider a practical data compression method for Photo AR on a tablet.","","978-1-5090-2333-2","10.1109/GCCE.2016.7800480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7800480","Augmented reality;Data compression;Tablet;HTML5/Javascript;Video processing","Rendering (computer graphics);Data compression;Augmented reality;Interpolation;Solid modeling;Image coding;Browsers","augmented reality;data compression;notebook computers;rendering (computer graphics);video coding","data compression;photo-based augmented reality;multiviewpoint photo image rendering;video format;tablet device;photo AR","","1","","3","IEEE","29 Dec 2016","","","IEEE","IEEE Conferences"
"Simulating consequences of smoking with Augmented Reality","B. R. Mohan; K. Bijlani; R. Jayakrishnan","Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Amritapuri, Kollam, Kerala, India; Amrita Vishwa Vidyapeetham, Coimbatore, Tamil Nadu, IN; Amrita Vishwa Vidyapeetham, Coimbatore, Tamil Nadu, IN","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","28 Sep 2015","2015","","","919","924","Visualization in an educational context provides the learner with visual means of information. Conceptualizing certain circumstances such as consequences of smoking can be done more effectively with the help of the technology, Augmented Reality (AR). It is a new methodology for effective learning. This paper proposes an approach on how AR based on Marker Technology simulates the harmful effects of smoking and its consequences using Unity 3D game engine. The study also illustrates the impact of AR technology on students for better learning.","","978-1-4799-8792-4","10.1109/ICACCI.2015.7275728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275728","Augmented Reality;Marker Technology","Three-dimensional displays;Augmented reality;Databases;Games;Lungs;Education","augmented reality;biomedical education;computer aided instruction;data visualisation;medical computing","smoking consequence simulation;augmented reality;visualization;educational context;effective learning;Marker Technology;smoking harmful effects;Unity 3D game engine","","1","","18","IEEE","28 Sep 2015","","","IEEE","IEEE Conferences"
"Visualization Of Furniture Model Using Augmented Reality","G. M. Vaidya; Y. Loya; P. Dudhe; R. Sawarkar; S. Chanekar","Computer Technology Department, Yeshwantrao Chavan College of Engineering, Nagpur, India; Department of Computer Technology, Yeshwantrao Chavan College of Engineering, Nagpur, India; Department of Computer Technology, Yeshwantrao Chavan College of Engineering, Nagpur, India; Department of Computer Technology, Yeshwantrao Chavan College of Engineering, Nagpur, India; Department of Computer Technology, Yeshwantrao Chavan College of Engineering, Nagpur, India","2022 Fifth International Conference on Computational Intelligence and Communication Technologies (CCICT)","12 Oct 2022","2022","","","488","493","AR furniture aims at providing a platform to visualize a furniture model using augmented reality (AR) so that it will be easy to choose the furniture according to color combinations and combinations of furniture. This application provides a real representation of furniture as a 3D model interpreting in a real world. This Application let user choose the choice of furniture from a range of furniture and let them place 3D object of the same furniture on empty area so that they can look at the way it will feel at that area. You can view multiple objects at the same time. It will help in decorating empty room. By looking at multiple object user will be able to choose object that he/she desires. The project is developed on Unity Software and Visual Studio","","978-1-6654-7224-1","10.1109/CCiCT56684.2022.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9913515","Furniture Visualization;Augmented Reality;Object Placing.","Visualization;Solid modeling;Three-dimensional displays;Color;Software;Communications technology;Augmented reality","augmented reality;furniture;furniture industry","furniture model;augmented reality;AR furniture","","1","","7","IEEE","12 Oct 2022","","","IEEE","IEEE Conferences"
"Interactive Touch Screen using Augmented Reality","P. Chakraborty; A. Shah","Information Technology, Ramrao Adik Institute of Technology, Navi Mumbai, India; Computer Engineering, L. D. College of Engineering, Ahmedabad, India","2018 4th International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)","20 Feb 2020","2018","","","294","298","Interactive Touch Screen using Augmented Reality is a set-up where Microsoft Kinect's depth-sensing ability is used to create an interactive touch environment on any plane surface. Touch screens are becoming quite popular, which is owing to the fact that they can accurately detect the user's touch points on the surface of the screen. Our setup proposes an approach to achieve a touch-sensitive surface which is made possible using a Microsoft Kinect placed on top of a horizontal surface along with a projector to project the screen on which the actions would be performed. The possible actions on the interactive surface are Touch, Hover, and Idle. There are notable advantages of using this setup to detect touch. Firstly, it is cost-effective since it is a one-time investment. Secondly, you can vary the screen-size as per requirement. Thirdly, there is no fear of causing physical damage since it is not instrumented. Lastly, it is portable. This attempt manages to reduce the false positives when compared to other previous touch screen techniques.","","978-1-5386-7706-3","10.1109/iCATccT44854.2018.9001956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001956","Kinect;Touch;Hover;Depth-sensor;Augmented Reality","Touch sensitive screens;Calibration;Hardware;Tracking;Augmented reality;Mice;Skeleton","augmented reality;touch sensitive screens;user interfaces","touch-sensitive surface;interactive surface;interactive touch screen;augmented reality;interactive touch environment;Microsoft Kinect depth-sensing ability","","1","","10","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"Cooperative Learning by Location-Based Augmented Reality for an Inquiry Learning Course","T. H. C. Chiang; S. J. H. Yang; C. J. H. Huang; A. Y. S. Su","Department of Computer Science and Information Engineering, National Central University, Chung-li, Tao-yuan, Taiwan; Department of Computer Science and Information Engineering, National Central University, Chung-li, Tao-yuan, Taiwan; Department of Computer Science and Information Engineering, National Central University, Chung-li, Tao-yuan, Taiwan; Department of Computer Science and Information Engineering, National Central University, Chung-li, Tao-yuan, Taiwan","2014 International Conference of Educational Innovation through Technology","15 Dec 2014","2014","","","75","78","Inquiry learning has been developed for years and many countries have incorporated inquiry learning into the scope of K-12 education. The knowledge-sharing process of inquiry learning tends to be complex. Therefore, we propose using location-based augmented reality (AR) to immerse students in the inquiry learning process. Mobile devices were used to immediately record and observe objects and enable learners to communicate with each other and engage in discussions, which raises their level of knowledge. The process of inquiry learning entails five steps: asking a question, attempting to answer the question, stimulating creative concepts, multiple people discussing the topic, and lastly, reaching a conclusion based on discourse and discovering an in-depth question from the conclusion, resulting in a new inquiry cycle. Therefore, to better understand learner behaviours in online knowledge-sharing discussions using location-based AR, we used an interaction analysis model to explore knowledge discussion behaviours among multiple participants to understand whether location-based AR helps students achieve higher phases of knowledge construction.","","978-1-4799-4230-5","10.1109/EITT.2014.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982566","Cooperative learning;augmented reality;inquiry learning","Augmented reality;Learning systems;Educational institutions;Cognition;Roads","augmented reality;computer aided instruction;educational courses;groupware;mobile computing","cooperative learning;location-based augmented reality;inquiry learning course;K-12 education;knowledge-sharing process;mobile device;interaction analysis model","","1","","14","IEEE","15 Dec 2014","","","IEEE","IEEE Conferences"
"Capture and posture assessment for patients with orthotic or prosthetic in lower limbs using augmented reality","J. R. Clímaco; C. F. Alfaro",NA; NA,"2014 IEEE Central America and Panama Convention (CONCAPAN XXXIV)","5 Jan 2015","2014","","","1","4","The advancements in the interaction that one has with a computer through augmented reality (AR) and its applications are each time more noticeable. Applying AR elements and using motion capture devices, a system that captures and stores people's corporal postures has been developed, allowing the quantification of the capture through virtual tools in order to stablish adequate procedures during rehabilitation, primarily in users that use orthotic or prosthetic in lower limbs. The result of this research seeks to verify the viability of applying this tool in the area of physical rehabilitation and therefore, contribute to the improvement of disabled people quality of live, through additional services to which they already are used to, at low cost.","","978-1-4799-7584-6","10.1109/CONCAPAN.2014.7000416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000416","Augmented reality;corporal posture","Software;Manuals;Orthotics;Prosthetics;Augmented reality;Abstracts;Computers","augmented reality;biomechanics;handicapped aids;orthotics;patient rehabilitation;prosthetics","capture assessment;posture assessment;orthotics;prosthetics;lower limbs;augmented reality;AR elements;motion capture devices;people corporal postures;virtual tools;physical rehabilitation;disabled people quality","","1","","5","IEEE","5 Jan 2015","","","IEEE","IEEE Conferences"
"Research on 3D Visualization of Crystal Molecular Structure Based on Augmented Reality","Y. Chang; Z. -s. Wang","Research Center for Sustainable Development of Shandong Province, Shandong Normal University, Jinan, China; School of Management Engineering, Shandong Jianzhu University, Jinan, China","2008 International Conference on Computer Science and Software Engineering","22 Dec 2008","2008","2","","1146","1149","Augmented Reality (AR) is a technology that allows overlaying the computer-generated virtual information into the userpsilas view of the real world, and with changes of his position and line of sight, the virtual objects will change accordingly. AR has many potential applications in industrial operations and academic research. First, this paper discusses the development of 3D visualization of crystal molecular structure. Next, the paper addresses the design of 3D macromolecule visualization based on AR. Then, the paper discusses 3D modeling of macromolecule. 3D model of crystal molecular is built with grid modeling in OpenGL. Finally, the paper makes a verifying research on it. The data of molecular was downloaded from internet database. The AR visualization system is established in ARToolKit. The result is stable, immersive and interactive.","","978-0-7695-3336-0","10.1109/CSSE.2008.503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4722255","Augmented Reality;3D Visualization;ARToolkit;Crystal molecular","Augmented reality;Data visualization;Computational modeling;Internet;Analytical models;Atomic measurements;Mathematical model;Computer vision;Visual databases;Predictive models","augmented reality;biology computing;data visualisation;macromolecules;molecular configurations","crystal molecular structure;augmented reality;computer-generated virtual information;AR;3D macromolecule visualization;grid modeling;OpenGL;Internet database;ARToolKit","","1","","5","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"AUGGO: Augmented Reality and Marker-based Application for Learning Geometry in Elementary Schools","U. L. Yuhana; R. R. Hariadi; M. Mukramin; H. Fabroyir; S. Arifiani","Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)","24 Dec 2020","2020","","","116","120","Suitable learning media can be used to achieve learning goals. The more interactive the learning media, the learning process will be more interactive. This paper proposes a learning media named Auggo. Auggo is an Augmented Reality (AR) and marker-based application as an interactive media to learn geometry in Elementary School. To show the impact of Auggo, this research conducts a test to 14 students in elementary school as participants. The test was carried out using the Two-Group Paired Sample T-Test method with those 14 elementary school students. Participants were divided into 2 groups: 7 participants as Group A (experimental class) and 7 participants as Group B (control class). Assessment of participants showed the results of the pretest to posttest in Group A increased by 26%, while Group B only increased by 10.29%. These results indicate that the AR-based AUGGO application can help students in improving the understanding of space concept.","","978-1-7281-8283-4","10.1109/CENIM51130.2020.9298003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298003","learning media;Augmented Reality;Geometry;Elementary School","Media;Geometry;Three-dimensional displays;Games;Informatics;Augmented reality;Shape","augmented reality;computer aided instruction;geometry;interactive systems;mathematics computing","augmented reality;marker-based application;interactive media;AUGGO application;elementary schools;suitable learning media;learning process;geometry;two-group paired sample T-test method","","1","","19","IEEE","24 Dec 2020","","","IEEE","IEEE Conferences"
"Geomath: An Augmented Reality Based Geometry Introductory Android-Based Application with Cuboid Tracking","J. Y. Mambu; B. G. Wullur; A. K. Wahyudi; J. Ambana; J. Moejahedy; R. Kumendong","Computer Science Faculty, Universitas Klabat, Airmadidi, Indonesia; School of Education, Curtin University, Perth, Australia; Computer Science Faculty, Universitas Klabat, Airmadidi, Indonesia; Computer Science Faculty, Universitas Klabat, Airmadidi, Indonesia; Computer Science Faculty, Universitas Klabat, Airmadidi, Indonesia; Computer Science Faculty, Universitas Klabat, Airmadidi, Indonesia","2020 2nd International Conference on Cybernetics and Intelligent System (ICORIS)","18 Jan 2021","2020","","","1","5","Geometry is the lesson we have learned from the elementary school level, which is divided into two categories: plane geometry and solid geometry. The shapes of geometrical objects can be around us in our everyday life, such as dice with cuboid shape, door with rectangular shape, plates with circular shapes, etc. Even so, the apparatus used for introducing these shapes are many still in the form of books or static media or objects. In this research, innovation is made by creating an application that will show geometry planes and objects using Augmented Reality technology and the 3D Cuboid Tracking method. This method uses a cuboid-shaped marker that has six sides and can be tracked all at once. By using this method, the geometry objects can be seen in 3D, where users can see every object at a different angle and gives better haptic feedback as the cube can be held. In this research, we use ten geometry objects that consist of six solid geometry objects (cube, rectangular prism, triangular prism, sphere, cylinder, cone) and four plane geometry objects (triangle, rectangle, square, circle). This application shows geometry objects with its description and the calculation of surface area, volume, and perimeter and a quite accurate projection with less than 0.5 cm margin error. A test of the application also has been done on Android smartphones and successfully installed on Android 5.1 and higher versions.","","978-1-7281-7257-6","10.1109/ICORIS50180.2020.9320815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320815","Geometry;3D Cuboid Tracking;Augmented Reality;pedagogy;smartphone","Geometry;Smart phones;Cameras;Testing;Augmented reality;Shape;Three-dimensional displays","augmented reality;computational geometry;computer aided instruction;haptic interfaces;mathematics computing;mobile computing;smart phones;solid modelling","geometrical objects;cuboid shape;rectangular shape;circular shapes;static media;geometry planes;augmented reality;cuboid-shaped marker;solid geometry objects;plane geometry objects;geometry introductory;Geomath;Android-based application;elementary school level;3D cuboid tracking;haptic feedback;triangular prism;rectangular prism;surface area;Android smartphones;Android 5.1","","1","","20","IEEE","18 Jan 2021","","","IEEE","IEEE Conferences"
"RF-ISee: Identify and Distinguish Multiple RFID Tagged Objects in Augmented Reality Systems","J. Sun; L. Xie; Q. Cai; C. Wang; J. Wu; S. Lu","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; Department of Computer Information and Sciences, Temple University, USA; State Key Laboratory for Novel Software Technology, Nanjing University, China","2016 IEEE 36th International Conference on Distributed Computing Systems (ICDCS)","11 Aug 2016","2016","","","723","724","In this paper, we leverage RFID technology to label different objects with RFID tags, so as to realize the vision of ""show me what I see from the augmented reality system"". We deploy additional RFID antennas to the COTS depth camera and propose a continuous scanning-based scheme to scan the objects, i.e., the system continuously rotates and samples the depth of field and RF-signals from these tagged objects. In this way, we can accurately identify and distinguish multiple tagged objects, by pairing the tags with the objects according to the correlations between the depth of field and RF-signals. Our solution achieves an average match ratio of 91% in distinguishing up to dozens of tagged objects with a high deployment density.","1063-6927","978-1-5090-1483-5","10.1109/ICDCS.2016.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536571","RFID;Augmented Reality System","Cameras;RFID tags;Antennas;Feature extraction;Object recognition;Augmented reality","augmented reality;cameras;object detection;radiofrequency identification","RF-ISee;RFID tagged objects;radiofrequency identification;object identification;augmented reality systems;RFID tags;RFID antennas;COTS depth camera;continuous scanning-based scheme;depth of field","","1","","","IEEE","11 Aug 2016","","","IEEE","IEEE Conferences"
"Augmented reality in groundwater flow","J. C. Marques; J. Rodrigues; M. T. Restivo","IDMEC-FEUP, Universidade do Porto; IDMEC-FEUP, Universidade do Porto; IDMEC-FEUP, Universidade do Porto","2014 11th International Conference on Remote Engineering and Virtual Instrumentation (REV)","10 Apr 2014","2014","","","399","400","Augmented reality technology can be used in training and learning environments to increase the level of users' immersion. Taking advantage of this technology a tool has been developed for helping students to re-observe experimental results of groundwater flow in small scale models of embankment dams. It is available to be used any time after experimental sessions at students' request and without requiring any special human support.","","978-1-4799-2024-2","10.1109/REV.2014.6784201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784201","Augmented Reality;experimental setup;user interfaces","Filling;Reservoirs;Augmented reality;Training;Earth;Finite element analysis;Three-dimensional displays","augmented reality;civil engineering computing;computer aided instruction;dams;engineering education;geophysics computing;geotechnical engineering;groundwater;soil","groundwater flow;augmented reality technology;training environment;learning environment;user immersion;embankment dam small scale model","","1","","3","IEEE","10 Apr 2014","","","IEEE","IEEE Conferences"
"Mobile application with augmented reality as a tool to reinforce learning in pre-Inca cultures","M. Cabanillas-Carbonell; A. Canchaya-Ramos; R. Gómez-Osorio","Department of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Department of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú; Department of Engineering and Architecture, Universidad Autónoma del Perú, Lima, Perú","2020 IEEE Engineering International Research Conference (EIRCON)","17 Nov 2020","2020","","","1","4","Peru is one of the countries with the most rich and varied culture in the world, which can be made known by making use of augmented reality for better understanding and learning at school. This document shows the development of an application following the mobile d methodology, for the creation of 3D models regarding pre-Inca cultures and determines the influence it would have on the learning of students at the primary level. Using the quasi-experimental design, the sample consists of 84 students from the third grade divided into 2 classrooms (control group and experimental group). The results show an increase of 33.07% in grades, 49.51% in satisfaction, 42.85% in motivation and a reduction of 34.05% in evaluation time with respect to the post-test, applied to the experimental group.","","978-1-7281-8367-1","10.1109/EIRCON51178.2020.9254018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9254018","augmented reality;mobile application;cultural learning;mobile-d methodology","Solid modeling;Three-dimensional displays;Conferences;Tools;Mobile applications;Cultural differences;Augmented reality","augmented reality;computer aided instruction;human factors;learning (artificial intelligence);mobile computing","classrooms;quasiexperimental design;mobile d methodology;varied culture;rich culture;pre-Inca cultures;augmented reality;mobile application","","1","","15","IEEE","17 Nov 2020","","","IEEE","IEEE Conferences"
"The Hotspots and Trends on Augmented Reality Studies in Education: Based on CiteSpace","E. Liu; C. Liu; S. Cai","School of Educational Technology, Faculty of Education Beijing Normal University, Beijing, China; School of Educational Technology, Faculty of Education Beijing Normal University, Beijing, China; School of Educational Technology, Beijing Normal University, Beijing, China","2018 International Joint Conference on Information, Media and Engineering (ICIME)","13 Jan 2019","2018","","","282","287","With the rapid development of Augmented Reality (AR) technology these years, a system review based on the visualization way could help researchers finding the hotspots and future trends in this field. In this study, 604 publications from 2016 to 2018 on Web of Science (WOS) database were selected into analysis. The distribution of different categories and regions of these studies was analyzed. The ""Education & Educational Research"" was the biggest category of all the studies. USA was the most productive region in the 2016 to 2018. The most influential author based on these studies was Ronald T Azuma. Three main hotspots and possible future trends were discussed in detail based on the visualization result.","","978-1-5386-7616-5","10.1109/ICIME.2018.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8609544","Augmented Reality, knowledge network map, visualization, research hotspots, research trends","Education;Augmented reality;Market research;Visualization;Knowledge engineering;Databases","augmented reality;computer aided instruction;data visualisation","CiteSpace;Education & Educational Research;visualization result;augmented reality technology;Web of Science","","1","","34","IEEE","13 Jan 2019","","","IEEE","IEEE Conferences"
"Basic 3D interaction techniques in Augmented Reality","Y. Ariyana; A. I. Wuryandari","School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia","2012 International Conference on System Engineering and Technology (ICSET)","25 Oct 2012","2012","","","1","6","Information technology currently supports the development of human interaction with virtual environment, this development will continue in developing in the form of Human Computer Interaction (HCI). In this study, how the environment 3D virtual computer should be able to recognize human hand as part as virtual object, so it can interact with virtual environment. HCI is a study in which the relationship between humans and computing technology and how computers are designed for easy to use by human, more practical and more intuitive. HCI emphasizes how human interaction with computer technology. This research is using use 3D transformation to digital objects used in computer graphics, transformation of the basis for the movement of digital objects in interaction technique in virtual environment to interact between human hand and virtual object. Tracker is needed in virtual interaction by using Augmented Reality (AR), the problem that arise in AR is how to read marker, so it can display a virtual object that has been computed before, basically is how to read the geometry model of human hand, then the result from the processing of the human hand model geometry is used as a marker, so it can interact with a virtual environment on AR as one of the HCI model implementation. This process is intended for the movement of human hands that have been read as a virtual object can communicate virtually using image processing.","","978-1-4673-2376-5","10.1109/ICSEngT.2012.6339281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6339281","Human Computer Interaction;Augmented Reality;Virtual Interaction;3D Transformation Natural hand gesture","Humans;Virtual environments;Educational institutions;Human computer interaction;Computers;Augmented reality;Belief propagation","augmented reality;gesture recognition;human computer interaction;image motion analysis;solid modelling;stereo image processing","3D interaction technique;augmented reality;information technology;human interaction;virtual environment;human computer interaction;3D virtual computer;human hand recognition;virtual object;computer technology;3D transformation;computer graphics;digital object movement;virtual interaction;marker reading;human hand model geometry processing;HCI model;human hand movement;image processing","","1","","29","IEEE","25 Oct 2012","","","IEEE","IEEE Conferences"
"Design and implementation of a Chinese character teaching system based on augmented reality interaction technology","Q. -m. Li; Y. -m. Chen; D. -y. Ma; C. Huang; S. Xu; R. -m. Lu; Y. Liu; X. -c. Wang","Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, China; Department of Computer Science and Technology School of Computer Engineering and Science, Shanghai University, Shanghai, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, China; Department of Computer Science and Technology, School of Computer Engineering and Science, Shanghai University, China","2011 IEEE International Conference on Computer Science and Automation Engineering","14 Jul 2011","2011","2","","322","326","In this paper, we design and realize an augmented reality interaction framework. A linear interpolation algorithm in an adaptive spatial grid is proposed to calibrate the magnetic tracker, and the calibrated data is used for registration of the user's viewpoint and the virtual objects. An optimized collision detection algorithm based on Vclip is adopted. Additionally, grasp gesture recognition algorithm based on rough sets theory is presented to capture and recognize the user's hand operation. In order to make it easier to learn the new Chinese characters, a Chinese character teaching system based on the framework is developed. The experimental results show that, in the teaching system, the user's immersion feeling is enhanced to a great extent by the accurate and natural human-computer interaction, which promotes the efficiency of learning new Chinese characters.","","978-1-4244-8728-8","10.1109/CSAE.2011.5952479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5952479","augmented reality;human computer interaction;chinese character teaching system","Real time systems;Education;Augmented reality;Human computer interaction;Data gloves;Gesture recognition;Computers","augmented reality;character recognition;computer aided instruction;gesture recognition;human computer interaction;interpolation;object detection;rough set theory;teaching","Chinese character teaching system;augmented reality interaction technology;linear interpolation algorithm;adaptive spatial grid;magnetic tracker;virtual objects;optimized collision detection algorithm;Vclip;grasp gesture recognition algorithm;rough sets theory;users hand operation;natural human-computer interaction","","1","","10","IEEE","14 Jul 2011","","","IEEE","IEEE Conferences"
"Ubiquitous anotation and a collaborative open mobile augmented reality","S. Martín; E. J. Lorenzo; M. Rodriguez-Artacho; S. Ros; R. Hernández; M. Castro","Electrical & Computer Engineering Dep., UNED, Control and Communications Systems Dep., UNED; Electrical & Computer Engineering Dep., UNED, Control and Communications Systems Dep., UNED; Electrical & Computer Engineering Dep., UNED, Control and Communications Systems Dep., UNED; Electrical & Computer Engineering Dep., UNED, Control and Communications Systems Dep., UNED; Electrical & Computer Engineering Dep., UNED, Control and Communications Systems Dep., UNED; Electrical & Computer Engineering Dep., UNED, Control and Communications Systems Dep., UNED","Proceedings of the 2012 IEEE Global Engineering Education Conference (EDUCON)","17 May 2012","2012","","","1","5","Mobile learning is impacting education using different technologies and methodologies. This article introduces two relevant learning experiences at UNED where new mobile technologies and pedagogical methodologies were applied. The first experience was based on a ubiquitous annotation system, while the second one used augmented reality to create an engaging mobile collaborative and open environment where students were learners and teachers at the same time, publishing content and learning from the content published by other peers.","2165-9567","978-1-4673-1456-5","10.1109/EDUCON.2012.6201201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6201201","mobile learning;augmented reality;collaborative learning;engineering education;ubiquitous anotation","Mobile communication;Augmented reality;Mobile handsets;Computers;Collaboration;Context;Education","augmented reality;computer aided instruction;mobile computing","ubiquitous anotation;collaborative open mobile augmented reality;mobile learning;education;learning experiences;mobile technologies;pedagogical methodologies;ubiquitous annotation system","","1","","9","IEEE","17 May 2012","","","IEEE","IEEE Conferences"
"Application with Augmented Reality to improve the Teaching and Learning of Medical Students","K. M. Canchanya; N. C. Vasquez","Facultad de Ingenieria, Universidad Privada del Norte, Lima, Perú; Facultad de Ingenieria, Universidad Privada del Norte, Lima, Perú","2021 IEEE 1st International Conference on Advanced Learning Technologies on Education & Research (ICALTER)","19 Jan 2022","2021","","","1","4","For several years the problem of teaching higher education students has been analyzed. There is little application of emerging technologies despite the fact that this technology is currently being adapted to different areas of knowledge. In the case of medical students, they need to carry out practices for learning the human body, which are carried out in a short time in specialized laboratories. What was done is the application of a system with augmented reality that shows 3D models of the different parts of the human body, with a didactic design, easy to use for the comfort of the student. With this application, students improve their learning through the visualization and interaction of the human anatomy at any time of the day just by having a mobile device. With which a better learning experience was obtained and awakening the greatest interest in the career.","","978-1-6654-0705-2","10.1109/ICALTER54105.2021.9675119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9675119","Augmented Reality;Teaching;learning objects;Asset Store","Visualization;Three-dimensional displays;Software;Solid modeling;Education;Augmented reality;Biological system modeling","augmented reality;biomedical education;computer aided instruction;further education;medical computing;solid modelling;teaching","augmented reality;medical students;teaching higher education students;human body;specialized laboratories;human anatomy;learning experience","","1","","","IEEE","19 Jan 2022","","","IEEE","IEEE Conferences"
"Pre-processing of gender-based comparative usability performance data in Mobile Augmented Reality English language teaching","K. C. Lim; A. Selamat; N. A. M. Ghani; M. H. M. Zabil; R. A. Alias; F. Puteh","Department of Software Engineering, Universiti Tenaga Nasional, Selangor, Malaysia; Center for Information and Communication Technology, Universiti Teknologi Malaysia, Johor, Malaysia; Faculty of Computer and Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Selangor, MALAYSIA; Department of Software Engineering, Universiti Tenaga Nasional, Selangor, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia; Language Academy, Universiti Teknologi Malaysia, Johor Bahru, Malaysia","2017 IEEE Conference on e-Learning, e-Management and e-Services (IC3e)","12 Jul 2018","2017","","","102","107","This article is part of this research group's work on a larger scale project prioritization of usability data in Mobile Augmented Reality learning (MAR-learning) environment. The work specifically focuses on pre-processing analysis on the early stages of experiment involving an MAR-learning application build to improve students interview skills in English language. The article will first highlight the related works leading to this project and problems encountered while scrutinizing current works on MAR-learning usability basing on gender biases. A methodology is then proposed with 3 important phases where this paper will only highlight the pre-processing stage of the third phase before presentation and discussion on the results. This paper will end with future works related to this project in the nearest future research undertakings.","","978-1-5386-3145-4","10.1109/IC3e.2017.8409246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409246","Usability;Gender-based;Mobile Augmented Reality;English Language Teaching","Usability;Augmented reality;Object tracking;Task analysis;Education;Standards","augmented reality;computer aided instruction;mobile computing;teaching","gender-based comparative usability performance data;larger scale project prioritization;usability data;MAR-learning application;nearest future research undertakings;mobile augmented reality English language teaching;MAR-learning environment;student interview skills;MAR-learning usability","","1","","35","IEEE","12 Jul 2018","","","IEEE","IEEE Conferences"
"Augmented reality: Fusing the real and synthetic worlds","M. D. Mura; M. Zanin; C. Andreatta; P. Chippendale","Technologies of Vision, Fondazione Bruno Kessler (FBK), Trento, Italy; Technologies of Vision, Fondazione Bruno Kessler (FBK), Trento, Italy; Technologies of Vision, Fondazione Bruno Kessler (FBK), Trento, Italy; Technologies of Vision, Fondazione Bruno Kessler (FBK), Trento, Italy","2012 IEEE International Geoscience and Remote Sensing Symposium","10 Nov 2012","2012","","","170","173","Augmented Reality (AR) offers a means to inject virtual information into real scenes. In the past few years, AR has been receiving greater attention thanks to considerable advancements in the hardware of consumer-level portable devices. In this paper, we illustrate how mobile AR can be exploited to intuitively visualize, and moreover generate new, geo-data. We explore these two concepts through i) the visualization and interaction modality of geo-data as AR layers and ii) the exploitation of mobile devices as opportunistic sensors for generating information relating to a user's immediate surroundings.","2153-7003","978-1-4673-1159-5","10.1109/IGARSS.2012.6351610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6351610","Augmented reality;image registration;visualization;opportunistic sensors;data collection","Augmented reality;Remote sensing;Sensors;Data visualization;Hardware;Mobile communication;Cameras","augmented reality;data visualisation;geophysical image processing;image registration;mobile computing;natural scenes;portable computers;sensors","augmented reality;real worlds;synthetic worlds;virtual information;real scenes;consumer-level portable devices;mobile AR;geo-data visualization;interaction modality;mobile devices;opportunistic sensors;information generation;image registration","","1","","8","IEEE","10 Nov 2012","","","IEEE","IEEE Conferences"
"An augmented reality platform targeted to promote learning about planetary systems","M. C. Costa; A. Manso; J. M. Patrício; A. Carvalho; B. Alegria; V. Zinatulins","UIED* - Unit of Research Education and Development, Universidade NOVA de Lisboa, PORTUGAL; Ci2 - Smart Cities Research Center, Instituto Politécnico de Tomar, PORTUGAL; Ci2 - Smart Cities Research Center, Instituto Politécnico de Tomar, PORTUGAL; Instituto Politécnico de Tomar, PORTUGAL; Instituto Politécnico de Tomar, PORTUGAL; Instituto Politécnico de Tomar, PORTUGAL","2019 International Symposium on Computers in Education (SIIE)","28 Jan 2020","2019","","","1","5","We present a mobile augmented reality platform targeted to promote learning about planetary systems. The architecture of this platform includes a mobile application and a back-office that allows teachers to choose the planetary system they intend to present to their students. Furthermore, they can introduce information about celestial bodies, such as stars or planets and develop a set of multiple-choice questions to assess student's learning about the subject matters they teach. Also, after playing the game, the data collected by the application is sent to the information system that processes it and makes it available to teachers. With these functionalities, this paper intends to propose this platform as a resource to be implemented in any level of school syllabus.","","978-1-7281-3182-5","10.1109/SIIE48397.2019.8970136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970136","Mobile learning;augmented reality;collaborative learning environments;learning object repositories;astronomy","Computers;Planets;Education;Games;Computer architecture;Mobile applications;Augmented reality","astronomy computing;augmented reality;computer aided instruction;information systems;mobile computing;physics education;teaching","planetary system;mobile augmented reality platform;mobile application;information system;back-office;celestial bodies;stars;data collection;student learning assessment","","1","","11","IEEE","28 Jan 2020","","","IEEE","IEEE Conferences"
"Accelerating Data Loading for Photo-Based Augmented Reality on Web Browser","R. Naka; N. Hagiwara; M. Ohta","Graduate School of Humanities and Sustainable System Sciences, Osaka Prefecture University, 1-1 Gakuen-cho Nakaku Sakai Osaka, Japan; Graduate School of Humanities and Sustainable System Sciences, Osaka Prefecture University, 1-1 Gakuen-cho Nakaku Sakai Osaka, Japan; Graduate School of Humanities and Sustainable System Sciences, Osaka Prefecture University, 1-1 Gakuen-cho Nakaku Sakai Osaka, Japan","2018 IEEE 7th Global Conference on Consumer Electronics (GCCE)","13 Dec 2018","2018","","","698","699","A photo-based augmented reality (Photo AR) system is an AR system that uses photographic images instead of computer graphics of three-dimensional models. Photo AR can display realistic AR views to users, but it requires large disk space due to its many images. Although all images can be significantly compressed into one video format file, the decoding and memory storage process are time-consuming. In this study, we propose a method to accelerate data loading for Photo AR operating on a web browser in a mobile device. The experimental results demonstrate the effectiveness of our method.","2378-8143","978-1-5386-6309-7","10.1109/GCCE.2018.8574862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8574862","Augmented Reality;Photo AR;Data compression;Web browser","Loading;Streaming media;Mobile handsets;Acceleration;Augmented reality;Browsers;Computational modeling","augmented reality;computer graphics;mobile computing;online front-ends","computer graphics;Photo AR;data loading;web browser;photo-based augmented reality system;AR system;photographic images;mobile device","","1","","6","IEEE","13 Dec 2018","","","IEEE","IEEE Conferences"
"Study on an augmented reality based 3-Dimensional see-through wall","Y. Lu; T. Yang; Y. Liu; Y. Wang","School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; School of Optics and Electronics, Beijing Institute of Technology, Beijing, China","2010 3rd International Congress on Image and Signal Processing","29 Nov 2010","2010","4","","1680","1683","This paper describes an augmented reality application system which can achieve 3-Dimensional perspective effect based on computer vision. In such a system a display screen is installed on a wall beside a window, its user can see the outside scene at any viewpoint with the help of the display screen. In addition, the scene displayed on the screen is matched with the scene through the neighbor window, as if the display screen is a real window. The system uses 3-Dimensional see-through rendering, marker tracking, image mosaic and vertex stretching methods to support single naked eye perspective directly. Experimental results show its potentials to be used in a wider application domain.","","978-1-4244-6516-3","10.1109/CISP.2010.5647749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5647749","3D see-throug;augmented reality;image processing;computer vision;vertex stretch","Cameras;Three dimensional displays;Head;Augmented reality;Two dimensional displays;Tracking;Computer vision","augmented reality;computer vision;image segmentation;rendering (computer graphics)","3-dimensional see-through wall;augmented reality application system;computer vision;display screen;3-dimensional see-through rendering;marker tracking;image mosaic;vertex stretching methods","","1","2","4","IEEE","29 Nov 2010","","","IEEE","IEEE Conferences"
"An interactive educational tool based on augmented reality, mobile applications and comic strips to teach children the Cañari and Inca cultures in the Ecuadorian context","A. Medina-Carrión; P. Arias-Espinoza; V. Robles-Bykbaev; Y. Robles-Bykbaev; F. Pesántez-Avilés; J. Ortega","GI-IATa, UNESCO Chair on Support Technologies for Educational Inclusion, Universidad Politécnica Salesiana, Cuenca, Ecuador; GI-IATa, UNESCO Chair on Support Technologies for Educational Inclusion, Universidad Politécnica Salesiana, Cuenca, Ecuador; GI-IATa, UNESCO Chair on Support Technologies for Educational Inclusion, Universidad Politécnica Salesiana, Cuenca, Ecuador; GI-IATa, UNESCO Chair on Support Technologies for Educational Inclusion, Universidad Politécnica Salesiana, Cuenca, Ecuador; GI-IATa, UNESCO Chair on Support Technologies for Educational Inclusion, Universidad Politécnica Salesiana, Cuenca, Ecuador; Museo Pumapungo, Ministerio de Cultura del Ecuador, Cuenca, Ecuador","2018 Congreso Argentino de Ciencias de la Informática y Desarrollos de Investigación (CACIDI)","20 Dec 2018","2018","","","1","5","According to the United Nations Educational, Scientific and Cultural Organization (UNESCO), due of the rapidity of cultural change, safeguarding the world's tangible and intangible cultural heritage has become an increasingly complex and multidimensional undertaking. Therefore, it is fundamental for the children and youth of today to learn the culture, values, and traditions that define their identity as well as the identity of their nation. For these reasons in this paper, we present an interactive app aimed at supporting both teaching and rescuing the heritage of Cañari and Inca indigenous cultures. Our mobile app can be used at children's home or during the guided visits of one of the most important museums in Ecuador: the Pumapungo Museum. Likewise, the app can identify QR codes to show multimedia material to children, contains several 3D objects that are presented using Augmented Reality (AR), and incorporates a Natural Language Processing (NLP) module to determine the children's learning progress. In this line, it is important mentioning that children use the app to create small ""stories"" about the learned concepts. The app was tested in real guided visits in the museum with 30 children from three different schools (low and middle -income), and the results show high levels of interest in the contents and the app.","","978-1-5386-5447-7","10.1109/CACIDI.2018.8584190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8584190","Natural language processing (NLP);Augmented reality (AR);Interactive Application;Expert System;Mobile applications","Cultural differences;Augmented reality;Three-dimensional displays;Natural language processing;Tools;Mobile applications;Multimedia systems","augmented reality;computer aided instruction;educational institutions;history;mobile computing;museums;natural language processing;teaching","mobile app;augmented reality;mobile applications;interactive app;teach children;cultural heritage;Pumapungo museum;QR codes;natural language processing;NLP;UNESCO;United Nations Educational-Scientific and Cultural Organization","","1","","8","IEEE","20 Dec 2018","","","IEEE","IEEE Conferences"
"Developing Interactive Quizzes Using LAYAR(TM) Augmented Reality: Lessons Learned","A. S. Al-Khalifa; H. S. Al-Khalifa","Electronic and Computer Research Institute, King Abdulaziz City for Science and Technology, Riyadh, Saudi Arabia; Information Technology Department, King Saud University, Riyadh, Saudi Arabia","2012 Sixth International Conference on Next Generation Mobile Applications, Services and Technologies","11 Oct 2012","2012","","","31","35","Augmented Reality (AR) as a vastly growing technology in the mobile computing domain is becoming mature enough to engender a variety of applications for the end user, especially in the educational domain. In this paper, we explore the possibility of developing interactive quizzes mediated by Layar™ AR technology. These quizzes are created with no advanced programming skills. Evaluating the usage of the created quizzes showed that they were useful, fun and represented a low cost solution for introducing AR in the classroom.","2161-2897","978-1-4673-2598-1","10.1109/NGMAST.2012.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327927","Augmented Reality;Mobile learning;Interactive Quizzes;LayarTM","Mobile communication;Augmented reality;Browsers;Computers;Education;Games;Servers","augmented reality;computer aided instruction;interactive systems;mobile computing","interactive quiz development;LAYAR augmented reality;mobile computing domain;educational domain;Layar AR technology","","1","","13","IEEE","11 Oct 2012","","","IEEE","IEEE Conferences"
"Volumetric Medical Intervention Aiding Augmented Reality Device","D. Balazs; E. Attila","Department of Control Engirneerirng and Information Technology, BUTE, Budapest, Hungary; Department of Control Engirneerirng and Information Technology, BUTE, Budapest, Hungary","2006 2nd International Conference on Information & Communication Technologies","16 Oct 2006","2006","1","","1091","1096","Nowadays medical imaging can be used to generate highly accurate 3D images of the interior of patients' bodies. 3D medical data must be presented in a compact way in order not to overwhelm or distract doctors who often work under strict time constraints. Augmented Reality (AR) lets doctors to optimize actual procedures. Surgical decisions usually depend on the extent of the disease. The accurate volume measurement is complicated in most cases. For instance, surgeons can use AR technology to analyze the disease and determine its extent in three dimensional space so diagnosis can be faster and more precise.","","0-7803-9521-2","10.1109/ICTTA.2006.1684526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1684526","augmented reality;computer vision-based tracking;direct manipulation;gesture recognition;perceptual user intenface;computer aided medical diagnosis","Augmented reality;Biomedical imaging;Space technology;Data visualization;Medical diagnostic imaging;Hardware;Information technology;Surgery;Diseases;Computed tomography","augmented reality;medical image processing;patient diagnosis;surgery","augmented reality;computer vision-based tracking;direct manipulation;gesture recognition;perceptual user intenface;computer aided medical diagnosis","","1","","10","IEEE","16 Oct 2006","","","IEEE","IEEE Conferences"
"A Review and Implementation Framework of Industrial Augmented Reality","K. Mühlan; K. A. Przybysz; F. Lindner; D. Akrmanová; D. Winkler; S. Keil","Faculty of Business Administration and Engineering Zittau/Görlitz University of Applied Sciences, Zittau, Germany; Faculty of Business Administration and Engineering Zittau/Görlitz University of Applied Sciences, Zittau, Germany; Faculty of Business Administration and Engineering Zittau/Görlitz University of Applied Sciences, Zittau, Germany; Faculty of Business Administration and Engineering Zittau/Görlitz University of Applied Sciences, Zittau, Germany; Faculty of Business Administration and Engineering Zittau/Görlitz University of Applied Sciences, Zittau, Germany; Faculty of Business Administration and Engineering Zittau/Görlitz University of Applied Sciences, Zittau, Germany","2021 26th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA )","30 Nov 2021","2021","","","01","04","The implementation of digital technologies, especially Augmented Reality (AR), in industrial environments is a great challenge for companies due to individual requirements and specifications of each system. After a brief introduction to the topic of AR and the associated digitalization in industrial companies, this paper describes the methodological approach of the applied systematic literature review (SLR) and the results on which the implementation concept is based. 13 AR-related frameworks wholly or partially related to the introduction and integration of this technology in value-adding (manufacturing and assembly) and/or non-value-adding (logistics and maintenance) processes have been assessed. The main part of the paper comprises a concept derived from the literature that is enhanced towards stepwise managerial implementation of AR in the industrial environment. This concept includes a total of four dimensions, two of which are technical (technological and process dimension) and two of which are non-technical (social and organizational dimension). In addition, six process steps have been identified. This matrix is completed by the temporal classification into before, during and after implementation. Based on this organizational concept, industrial companies should be able to introduce AR processes and procedures faster, more efficiently and in a more targeted manner and thus support the deployment of the technology as such. Processes should be optimised in the long term through the introduction of AR. Some processes are suitable for the implementation, while others are not (yet) suitable for AR due to various factors.","","978-1-7281-2989-1","10.1109/ETFA45728.2021.9613426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613426","industrial augmented reality;industry 4.0;digitalization;systematic literature review;implementation framework","Systematics;Conferences;Bibliographies;Companies;Maintenance engineering;Manufacturing;Augmented reality","assembling;augmented reality;logistics data processing;organisational aspects;production engineering computing","associated digitalization;industrial companies;assembly;logistics;maintenance;stepwise managerial implementation;industrial environment;technological process dimension;social dimension;organizational dimension;organizational concept;industrial Augmented Reality;digital technologies","","1","","25","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Revealing the “spirit of the place”: Genius Loci, a spatial augmented reality performance based on 3D data and historical hypotheses","A. Favre-Brun; C. Jacquemin; V. Caye","National School of Architecture, Marseille, France; National School of Architecture, Marseille, France; LIMSI-CNRS / Univ. Paris-Sud, Orsay, France","2012 18th International Conference on Virtual Systems and Multimedia","3 Dec 2012","2012","","","103","108","In the cultural heritage field, since twenty years, tools for 3D acquisition and diffusion devices of historical architecture are progressively developed. The association with traditional techniques of survey allows historians achieving a high level of knowledge of the monument. Several kinds of systems are developed to operate data and to share results of archaeological studies such as digital surveys, 3D reconstruction, photorealistic texturing, GIS, documentary database or 3D visit real-time. This paper presents especially the example of a cultural valorisation device called Genius Loci presented in 2011 in the charterhouse of Villeneuve-lès-Avignon (Gard, France). From the 3D digitization of the current church and the restitution proposal of its XVIIIth century state, three scientific and artistic teams have produced a spatial augmented reality performance based on the 3D digital model. Over the dialogue between virtual and real actors, the spirit of the place is progressively revealed. This project illustrates a new kind of heritage valorisation through an efficient collaboration between science, heritage and art.","","978-1-4673-2563-9","10.1109/VSMM.2012.6365913","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365913","Heritage digitization;spatial augmented reality;3D digital model;historical hypotheses;immersive performance;public space","Solid modeling;Augmented reality;Buildings;Real-time systems;Visualization;Painting;Cultural differences","archaeology;art;augmented reality;history","Genius Loci;spatial augmented reality performance;3D data;historical hypotheses;cultural heritage;3D acquisition;historical architecture diffusion device;historical survey;monument knowledge;archaeological studies;digital surveys;cultural valorisation device;restitution proposal;3D church digitization;artistic teams;scientific teams;3D digital model;virtual actors;real actors;heritage valorisation;science-heritage-art collaboration","","1","","11","IEEE","3 Dec 2012","","","IEEE","IEEE Conferences"
"Robot devastation: Using DIY low-cost platforms for multiplayer interaction in an augmented reality game","D. Estevez; J. G. Victores; S. Morante; C. Balaguer",Robotics Lab research Group Universidad Carlos III de Madrid; Robotics Lab research Group Universidad Carlos III de Madrid; Robotics Lab research Group Universidad Carlos III de Madrid; Robotics Lab research Group Universidad Carlos III de Madrid,"2015 7th International Conference on Intelligent Technologies for Interactive Entertainment (INTETAIN)","12 Nov 2015","2015","","","32","36","We present Robot Devastation, a multiplayer augmented reality game using low-cost robots. Players can assemble their low-cost robotic platforms and connect them to the central server, commanding them through their home PCs. Several low-cost platforms were developed and tested inside the game.","","978-1-6319-0061-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325482","augmented reality;diy;low-cost;multiplayer interaction;robots;game","Games;Servers;Augmented reality;Streaming media;Cameras;Robot vision systems","augmented reality;computer games;graphical user interfaces;humanoid robots;mobile robots","robot devastation;DIY low-cost platforms;multiplayer interaction;multiplayer augmented reality game;low-cost robotic platforms;central server;home PC;do-it-yourself robots","","","","14","","12 Nov 2015","","","IEEE","IEEE Conferences"
"A Human-Robot Interaction Applicution Based on Augmented Reality (AR) for Industrial Robot Grasping Process","L. Zhao; Z. Hu; H. Ding; S. Ji; J. Yan","School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China","2022 7th International Conference on Robotics and Automation Engineering (ICRAE)","8 Mar 2023","2022","","","312","316","The application of Augmented Reality (AR) technology in human-robot interaction is one of the research hotspots in recent years. This paper introduces an AR application that can realize the interaction between humans and industrial robots. Unlike traditional interaction methods, the application in this paper can capture the operator's hand joint points and posture in real-time to recognize the gesture of the operator, and then issue the corresponding instructions to the industrial robot. In addition, it can display model information and track the model in real-time to assist the operator. The application is tested in a case study, and its practical effect is shown.","","978-1-6654-8918-8","10.1109/ICRAE56463.2022.10056198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10056198","Augmented Reality;human-robot interaction;gesture recognition","Automation;Service robots;Human-robot interaction;Grasping;Real-time systems;Augmented reality","augmented reality;gesture recognition;grippers;human-robot interaction;image capture;industrial robots;pose estimation;robot vision","AR application;augmented reality technology;gesture recognition;hand joint point capture;human-robot interaction applicution;industrial robot grasping process;real-time posture capture","","","","11","IEEE","8 Mar 2023","","","IEEE","IEEE Conferences"
"Learning Tools of KVK Module using Augmented Reality Mobile Application for Remedial Education Program (REP)","A. A. Ayub; M. B. Othman; N. M. Sahar; M. S. M. N. Azni; M. A. Ilyas; M. B. Jaafar","Faculty of Electrical and Electronic Engineering (FKEE), Universiti Tun Hussein Onn Malaysia (UTHM), Batu Pahat, Johor; Faculty of Electrical and Electronic Engineering (FKEE), Universiti Tun Hussein Onn Malaysia (UTHM), Batu Pahat, Johor; Faculty of Electrical and Electronic Engineering (FKEE), Universiti Tun Hussein Onn Malaysia (UTHM), Batu Pahat, Johor; Faculty of Electrical and Electronic Engineering (FKEE), Universiti Tun Hussein Onn Malaysia (UTHM), Batu Pahat, Johor; Faculty of Electrical and Electronic Engineering (FKEE), Universiti Tun Hussein Onn Malaysia (UTHM), Batu Pahat, Johor; Faculty of Electrical and Electronic Engineering (FKEE), Universiti Tun Hussein Onn Malaysia (UTHM), Batu Pahat, Johor","2020 IEEE Student Conference on Research and Development (SCOReD)","12 Nov 2020","2020","","","433","437","Augmented Reality (AR) is one of the technologies that has increased popularity in industry revolution 4.0 (IR 4.0). This technology is widely used in the education sector that can help the students easily acquire, process, and remember the information. However, due to the lack of introduction to new technology in some education fields, primary students tend to only use conventional learning methods such as books or card games. By looking at this loophole, this project is focusing on the primary students that being called remedial students in Remedial Education Program (RP). We choose the consonant vowel consonant (KVK) module after a deep discussion with the remedial teacher and regional education officer in Batu Pahat. The record shows that remedial students are facing hardship to spell, read, and pronounce the KVK. We have successfully developed the AR application education platform apps by using the Unity Real-Time Development platform (Unity 3D) and Vuforia. Inside this application, there are two menus for learning purposes which are KVK and Suku Kata and one menu for evaluation which is Kuiz. This module has been tested to 25 remedial students and the results show that the evaluation time taken to answer the Kuiz from the apps has been reduced around 10% to 50% compared to the conventional method. We hope that this application can be applied widely for remedial students in elementary school in year one that has a problem in mastering the KVK for REP.","2643-2447","978-1-7281-9317-5","10.1109/SCOReD50371.2020.9250934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250934","augmented reality;learning disabilities;remedial education program;unity;vuforia;android","Three-dimensional displays;Education;Tools;Real-time systems;Mobile applications;Augmented reality;Research and development","augmented reality;computer aided instruction;educational institutions;mobile computing;user interfaces","augmented reality mobile application;education sector;education fields;primary students;conventional learning methods;consonant vowel consonant module;remedial teacher;regional education officer;AR application education platform apps;KVK module;remedial students;remedial education program","","","","12","IEEE","12 Nov 2020","","","IEEE","IEEE Conferences"
"Implementation of Augmented Reality, TTS, and Midpoint Algorithm in Supporting People with Color Vision Deficiency","Irawati; A. Muawwal; H. Darwis; H. Lahuddin; Sugiarti; L. N. Hayati","Faculty of Computer Science, Universitas Muslim Indonesia, Makassar, Indonesia; Department of Information System, STMIK Kharisma, Makassar, Indonesia; Faculty of Computer Science, Universitas Muslim Indonesia, Makassar, Indonesia; Faculty of Computer Science, Universitas Muslim Indonesia, Makassar, Indonesia; Faculty of Computer Science, Universitas Muslim Indonesia, Makassar, Indonesia; Faculty of Computer Science, Universitas Muslim Indonesia, Makassar, Indonesia","2018 2nd East Indonesia Conference on Computer and Information Technology (EIConCIT)","24 Oct 2019","2018","","","86","90","Color blindness or color vision deficiency (CVD) is a physical disorder causing patients hardly to recognize or to distinguish certain colors. It might make some tasks on daily basis more challenging particularly in dealing with certain jobs requiring high visual acuity. In this research, augmented reality (AR), text-to-speech (TTS) system, and midpoint algorithm as color pixel detector were implemented in developing an application to support people with CVD. The application provides a convenient way to recognize colors using an Android smartphone camera. Four experiments were designed to measure how the application works; a drinking bottle was used as the first experiment object, the second and third experiments were designed to perceive the result of the same object but different contrasts, the fourth is a testing on printed colors. This research has figured out that the algorithm works well to recognize the color pixel and so does the TTS system because the average result of the detection rate was 85% with normal lighting level and 80% of response time of TTS system.","","978-1-5386-8050-6","10.1109/EIConCIT.2018.8878518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878518","color blindness;augmented reality;TTS;midpoint algorithm;color detection;android smartphone","Image color analysis;Color;Augmented reality;Cameras;Java;Information technology","augmented reality;cameras;colour vision;handicapped aids;smart phones;speech synthesis;vision defects","augmented reality;midpoint algorithm;color vision deficiency;color blindness;CVD;physical disorder;visual acuity;text-to-speech system;color pixel detector;printed colors;TTS system;Android smartphone camera","","","","16","IEEE","24 Oct 2019","","","IEEE","IEEE Conferences"
"The Effect of Role Assignment on Students’ Collaborative Inquiry-based Learning in Augmented Reality Environment","X. Jiao; Z. Liu; H. Zhou; S. Cai","Faculty of Education, Beijing Normal University, Beijing, China; Faculty of Education, Beijing Normal University, Beijing, China; Faculty of Education, Beijing Normal University, Beijing, China; Faculty of Education, Beijing Normal University, Beijing, China","2022 International Conference on Advanced Learning Technologies (ICALT)","17 Aug 2022","2022","","","349","351","Augmented Reality (AR) has great potential in science education, and Collaborative Inquiry-based Learning (CIBL) in the AR environment is of great significance. However, there is a problem of low collaborative performance in technology-based CIBL. This study applied the strategy of role assignment to AR-based CIBL, aiming to explore the effect of role assignment on students’ collaboration. Forty-seven sixth-grade students in elementary school were randomly divided into Group A (without role assignment) and Group B (with role assignment) to participate in AR-based collaborative scientific inquiry activities. Data on students’ scientific knowledge achievement, attitudes toward science learning, cognitive load, and flow experience were collected. In addition, interviews were conducted to investigate students’ opinions on role assignments. It is found that the strategy of role assignment could significantly improve students’ science knowledge achievement. The interview results revealed how role assignments facilitate students’ collaboration from three aspects.","2161-377X","978-1-6654-9519-6","10.1109/ICALT55010.2022.00109","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853793","augmented reality;role assignment;collaborative inquiry-based learning;science education","Education;Collaboration;Interviews;Augmented reality","augmented reality;computer aided instruction;groupware","role assignment;students;technology-based CIBL;AR-based collaborative scientific inquiry activities;students collaborative inquiry-based learning;augmented reality environment;role assignments;students science knowledge achievement;students collaboration","","","","10","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"The impact of augmented reality in society. Rehabilitation processes","C. C. Morales","Docente Escuela de Computación, Universidad Don Bosco","2015 IEEE Thirty Fifth Central American and Panama Convention (CONCAPAN XXXV)","10 Mar 2016","2015","","","1","6","Technology should be at the service of individuals and society. Improve the quality of life of the people must be the goal of any development. Augmented Reality is a clear example. Being today one of the most widely used emerging technologies and greater range of possibilities it offers, it is important to think about what impact it has on society, in the areas where it currently is being used and how it can be applied. In this paper the basic elements required for this are mentioned, the areas where it is used with particular emphasis on rehabilitation, it approached from a development project, divided into two modules: SAPR+ and EMAR+. The operation of these modules is explained and how they interact with the patient.","","978-1-4673-7872-7","10.1109/CONCAPAN.2015.7428457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7428457","Augmented Reality;Computer Graphics;Rehabilitation;Society","Biomedical imaging;Software;Three-dimensional displays;Visualization;Augmented reality;Silicon compounds;Hardware","augmented reality;computer graphics;medical computing;patient rehabilitation","augmented reality;patient rehabilitation processes;SAPR+ module;EMAR+ module;computer graphics","","","","","IEEE","10 Mar 2016","","","IEEE","IEEE Conferences"
"Supplementary Physical Device for In-Depth Augmented Reality Touring of Architectural Heritage Sites","N. -C. Tai; J. -L. Wu; C. -Y. Yeh","Department of Interaction Design, National Taipei University of Technology, Taipei, Taiwan; Department of Interaction Design, National Taipei University of Technology, Taipei, Taiwan; Department of Interaction Design, National Taipei University of Technology, Taipei, Taiwan","2022 IEEE International Conference on Consumer Electronics - Taiwan","1 Sep 2022","2022","","","53","54","Augmented reality (AR) that can overlay the interactive digital contents on real scenes has advanced the breadth and depth of the guided tour for architectural heritages. However, it increases the demand for precision in identifying real scenes without physical AR target installation for flexible and natural exploration. In this study, a customized physical convertible stand for a tablet computer that captures an extendable physical target object was developed to calibrate captured scenes and on-site viewing. The developed stand ensures an improved AR touring experience in receiving complex knowledge regarding visited cultural heritage sites.","2575-8284","978-1-6654-7050-6","10.1109/ICCE-Taiwan55306.2022.9869009","Ministry of Science and Technology of Taiwan(grant numbers:MOST 109-2221-E-027-024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869009","tourism experience;architectural heritage;Chinese scholar garden;augmented reality;mobile touring system","Tablet computers;Object recognition;Cultural differences;Augmented reality;Consumer electronics","augmented reality;history;interactive systems","supplementary physical device;architectural heritage sites;interactive digital contents;architectural heritages;physical AR target installation;natural exploration;customized physical convertible stand;tablet computer;extendable physical target object;captured scenes;on-site viewing;cultural heritage sites;AR touring experience;in-depth augmented reality touring","","","","9","IEEE","1 Sep 2022","","","IEEE","IEEE Conferences"
"Powerful learning using augmented reality - ATOMIC project experience","F. Urem; M. L. Hinić; A. Laska-Leśniewicz","Polytechnic of Šibenik, Šibenik, Croatia; Polytechnic of Šibenik, Šibenik, Croatia; Lodz University of Technology, Łódź, Poland","2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)","27 Jun 2022","2022","","","745","748","Quality higher education recognizes the usefulness of linking research and the application of modern technologies with teaching because in such an environment, students can acquire powerful knowledge with a more interesting learning experience. Such teaching focuses on the researcher student who is actively taking responsibility for his learning. Linking such an approach to learning with modern technologies such as augmented reality can improve the educational process as students can learn about real business problems. This paper describes some results of implementing the Erasmus KA2 project ATOMIC, whose primary goal is to create an AR-based teaching environment that will enable students to meet the challenges of a natural business environment.","2623-8764","978-953-233-103-5","10.23919/MIPRO55190.2022.9803518","Erasmus; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9803518","enquiry based learning;powerful learning;augmented reality;ATOMIC","Knowledge acquisition;Education;Augmented reality;Business","augmented reality;computer aided instruction;further education;teaching","researcher student;educational process;Erasmus KA2 project ATOMIC;teaching environment;natural business environment;powerful learning;augmented reality - ATOMIC project experience;quality higher education;powerful knowledge;interesting learning experience","","","","16","","27 Jun 2022","","","IEEE","IEEE Conferences"
"AR-Ghost Hunter: An augmented reality gun application","D. Weng; X. Liu; Y. Wang; Y. Liu","Beijing Institute of Technology, China; Beijing Institute of Technology, China; Beijing Institute of Technology, China; Beijing Institute of Technology, China","2011 IEEE International Symposium on VR Innovation","29 Apr 2011","2011","","","137","143","This paper presents an augmented reality gun application named AR-Ghost Hunter. AR-Ghost Hunter is an extension of the traditional first person game which adopts an innovative infrared marker system and portable computer to form a complete mobile AR system. In this system, players are able to fight with virtual ghost through special gun like devices in real environment. The basic issue of the system such as infrared marker indentify, pose estimation, and user's devices are discussed.","","978-1-4577-0054-5","10.1109/ISVRI.2011.5759617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759617","Augmented reality;infrared tracking;PNP","Cameras;Pixel;Games;Radio frequency;Augmented reality;Portable computers;Smoothing methods","augmented reality;computer games;mobile computing;portable computers;pose estimation;weapons","augmented reality gun application;AR-Ghost Hunter;innovative infrared marker system;portable computer;mobile AR system;virtual ghost;pose estimation;first person game","","","","6","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"Mobile Remote Assistance with Augmented Reality Applied in a Power Distribution Utility: A Qualitative Study","P. Z. Lodetti; A. B. Dos Santos; L. T. Hattori; E. G. Carvalho; M. A. I. Martins","Sustainable Energy Center, CERTI Foundation, Florianopolis, SC, Brazil; Energy & Utilities Indra Company, São Paulo, Brazil; Energy & Utilities Indra Company, São Paulo, Brazil; NT&I Smart Grid Brazil Enel São Paulo, São Paulo, Brazil; Sustainable Energy Center, CERTI Foundation, Florianópolis, Brazil","2022 Intermountain Engineering, Technology and Computing (IETC)","20 Jun 2022","2022","","","1","6","In Industry 4.0 scenario, new technologies have emerged to improve daily industrial activities. Among these technologies, Remote Assistance (RA) techniques adoption is growing in several sectors, in order to improve cooperation between staffs. This approach combined with Augmented Reality (AR) can be even more effective and assertive during the interactions. In the specific context of Power Distribution Utilities (PDU), an efficient communication between the electricians is usually required. With this in mind, this paper presents a qualitative analysis of the testing, deployment and operation of a RA with AR system applied in a PDU from São Paulo Metropolitan Region. This evaluation was performed through a survey with a group of 98 electricians over four months using the technology. The survey included questions about adequacy, usability, communication, applicability and acceptance of the system. The results showed more than 80% of positive and neutral rates of the technology in all evaluated qualitative features.","","978-1-6654-8653-8","10.1109/IETC54973.2022.9796952","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796952","Remote Assistance;Augmented Reality;Electric Power Sector;Power Distribution Utility.","Training;Scalability;Power distribution;Fourth Industrial Revolution;Usability;Augmented reality;Smart phones","augmented reality;mobile computing;power distribution","power distribution utilities;PDU;qualitative analysis;São Paulo Metropolitan Region;augmented reality;mobile remote assistance;Industry 4.0","","","","22","IEEE","20 Jun 2022","","","IEEE","IEEE Conferences"
"Integrating geographical information and mobile augmented reality technique for tracking tree species composition","I. S. Ramli; H. Arshad; A. Y. K. Kahbi; S. Ramly; S. M. Shariff; M. I. Rahim","Department of Computer Sciences, Universiti Teknologi MARA (Negeri Sembilan), Kuala Pilah, Negeri Sembilan; Faculty of Information Science & Technology, Universiti Kebangsaan Malaysia Bangi, Selangor; Department of Computer Sciences, Universiti Teknologi MARA (Negeri Sembilan), Kuala Pilah, Negeri Sembilan; Department of Computer Sciences, Universiti Teknologi MARA (Negeri Sembilan), Kuala Pilah, Negeri Sembilan; Department of Biology, Universiti Teknologi MARA (Negeri Sembilan), Kuala Pilah, Negeri Sembilan; Academy of Language Studies, Universiti Teknologi MARA (Negeri Sembilan), Kuala Pilah, Negeri Sembilan","2013 IEEE Conference on e-Learning, e-Management and e-Services","10 Feb 2014","2013","","","125","129","Studies based on tracking tree species composition are very important for researchers to conserve the ecosystem. The information about tree species composition can be obtained through physical tagging with markers. However, this method is tedious and may harm the structure of trees. Besides, it is time consuming for researchers to track the information for future research. Thus, this paper will propose a mobile tracking application (ARTSC) which integrates the geographical information and mobile augmented reality technique for tracking the tree species composition. By using camera on the smart phone, the information about the species composition will be overlaid on top of the real image. Thus, this application can be one of the alternative methods for researchers to track information about the tree species.","","978-1-4799-1574-3","10.1109/IC3e.2013.6735978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6735978","Mobile Augmented Reality;Geographical Information;Tracking Method;Tree Species Composition","Vegetation;Mobile communication;Augmented reality;Google;Computers;Tagging;Navigation","augmented reality;cameras;geographic information systems;mobile computing;smart phones;vegetation","geographical information system;mobile augmented reality technique;tree species composition tracking;mobile tracking application;ARTSC;smart phone;camera","","","","18","IEEE","10 Feb 2014","","","IEEE","IEEE Conferences"
"GIT and Augmented Reality as tools for promotion and development of spatial thinking","L. Azevedo; A. Osório; V. Ribeiro","Universidade do Minho, Braga, Braga, PT; Universidade do Minho, Braga, Braga, PT; Universidade do Minho, Braga, Braga, PT","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","5","This research project, carried out within the PhD in Educational Sciences, specializing in Educational Technology, is intended to deepen knowledge regarding the contributions and potential of Geographic Information Technologies (GIT) and Augmented Reality (AR) as digital tools that improve the teaching/learning process and promote the spatial thinking development of students of basic education (BE) in different learning contexts. Supported by the qualitative method, the project is based on case studies to assess the respective perceptions, usability, relevance and attractiveness of GIT and AR, both by students and teachers. With this research project, it is hoped to recognize the motivational and pedagogical value of GIT and AR as research and analysis tools that develop more complex levels of spatial thinking, as well as it is speculated that teacher training is fundamental for the recognition of the potentialities of these technologies by teachers, and for increase frequency of their integration in educational practices.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760995","Augmented Reality (AR);Geographic Information Technology (GIT);teaching/learning process;spatial thinking;geograpfic education","Augmented reality;Tools;Information systems;Google;Information technology;Education;Earth","augmented reality;computer aided instruction;geographic information systems;teacher training;teaching","GIT;digital tools;basic education;qualitative method;educational practices;educational sciences;educational technology;learning contexts;augmented reality;geographic information technologies;teaching process;learning process;spatial thinking development","","","","","","15 Jul 2019","","","IEEE","IEEE Conferences"
"A Novel Surgery Navigation System Combined with Augmented Reality Based on Image Target Positioning System","S. -Y. Chiou; H. -L. Liu; C. -W. Lee; M. -Y. Lee; C. -Y. Tsai; C. -L. Fu; P. -Y. Chen; K. -C. Wei","Department of Electrical Engineering, Department of Nuclear Medicine, Chang Gung University, Linkou Chang Gung Memorial Hospital, Tao-Yuan, Taiwan; Department of Electrical Engineering, Department of Nuclear Medicine, Chang Gung University, Linkou Chang Gung Memorial Hospital, Tao-Yuan, Taiwan; Department of Electrical Engineering, College of Engineering, Chang Gung University, Tao-Yuan, Taiwan; Department of Electrical Engineering, College of Engineering, Chang Gung University, Tao-Yuan, Taiwan; Department of Electrical Engineering, College of Engineering, Chang Gung University, Tao-Yuan, Taiwan; Department of Electrical Engineering, College of Engineering, Chang Gung University, Tao-Yuan, Taiwan; Departmenl of Neurosurgery, Linkou Chang Gung Memorial Hospital, Tao-Yuan, Taiwan; Departmenl of Neurosurgery, Linkou Chang Gung Memorial Hospital, Tao-Yuan, Taiwan","2019 International Conference on Computing, Electronics & Communications Engineering (iCCECE)","27 Dec 2019","2019","","","173","176","Current medical surgical navigation allows surgeons to use the surgeon as a more accurate aid. However, most Dicom images are projected onto another screen, and it is quite inconvenient for the doctor to perform surgery on the patient while watching another screen. This paper takes brain surgery as an example, using augmented reality technology based on image target positioning system, combined with smart phone, can instantly display the image of Dicom superimposed on the patient's head to provide surgical assistance for doctors. The surgical vision is more intuitive and focused. This paper is also implemented on Android smart phones to prove the feasibility of this technology.","","978-1-7281-2138-3","10.1109/iCCECE46942.2019.8941839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941839","Neuronavigation;augmented reality;mobile device;head-mounted display","Surgery;Head;Augmented reality;Smart phones;Navigation;Electrical engineering","augmented reality;brain;medical image processing;medical robotics;navigation;smart phones;surgery","accurate aid;surgeon;current medical surgical navigation;novel surgery navigation system combined;surgical assistance;image target positioning system;augmented reality technology;brain surgery;doctor;Dicom images","","","","8","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"A 360 degree trackable marker for augmented reality applications","E. Özüağ; S. Ertürk","Kocaeli Universitesi, Kocaeli, TR; Kocaeli Universitesi, Kocaeli, TR","2016 24th Signal Processing and Communication Application Conference (SIU)","23 Jun 2016","2016","","","2197","2200","In this paper, a new shaped marker is designed for augmented reality applications that has 360 degree viewing angle about its shaft axis. The main advantage of the designed marker is that it is very simple to extract marker area from images with basic image processing methods. And decoding of the marker codes is very simple with basic mathematical functions. Experimental results showed that, the designed marker provides robust results with noisy data under perspective distortions and partial occlusions.","","978-1-5090-1679-2","10.1109/SIU.2016.7496210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496210","augmented reality;marker design;image processing","Augmented reality;Conferences;Image processing;Decoding;Computer vision;Shafts;Robustness","augmented reality;decoding;feature extraction;image coding","360 degree trackable marker;augmented reality applications;360 degree viewing angle;marker area extraction;basic image processing methods;marker codes decoding;basic mathematical functions;partial occlusions;perspective distortions","","","","","IEEE","23 Jun 2016","","","IEEE","IEEE Conferences"
"Didactic tool with augmented reality for teaching limits: a development proposal","H. A. Solis Bautista; R. Guadalupe Cruz Flores; M. M. Reyes","Centro Universitario Valle de Chalco, Universidad Autónoma del Estado de México, Estado de México; Centro Universitario Valle de Chalco, Universidad Autónoma del Estado de México, Estado de México; Centro Universitario Valle de Chalco, Universidad Autónoma del Estado de México, Estado de México","2021 Mexican International Conference on Computer Science (ENC)","13 Sep 2021","2021","","","1","5","The issue of limits in differential and integral calculus represents an important challenge in understanding and applying the concepts, among students of engineering careers, in many cases generating dropouts from universities. This research paper proposes the development of a didactic tool with augmented reality technology, which allows students, with the teacher's guidance, to generate vivid learning experiences of the essential concepts of limits, as well as attract their interest in the theme using new technologies.","2332-5712","978-1-6654-2612-1","10.1109/ENC53357.2021.9534802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534802","Limits;Differential and integral calculus;Augmented Reality;Educational Technology;Education","Computer science;Engineering profession;Education;Tools;Calculus;Proposals;Augmented reality","augmented reality;computer aided instruction;educational institutions;software engineering;teaching","vivid learning experiences;essential concepts;didactic tool;teaching limits;development proposal;differential calculus;integral calculus;engineering careers;augmented reality technology","","","","0","IEEE","13 Sep 2021","","","IEEE","IEEE Conferences"
"Framework for Smart Online 3D Bin Packing Using Augmented Reality","A. Jaoua; E. Negri; S. B. Layeb; Z. Ayed","LR-OASIS, National Engineering School of Tunis University of Tunis El Manar, Tunis, Tunisia; Management, Economics and Industrial Engineering, Politecnico di Milano, Milano, Italy; LR-OASIS, National Engineering School of Tunis University of Tunis El Manar, Tunis, Tunisia; LR-OASIS, National Engineering School of Tunis University of Tunis El Manar, Tunis, Tunisia","2023 IEEE International Conference on Advanced Systems and Emergent Technologies (IC_ASET)","20 Jun 2023","2023","","","01","06","Given the growth of the e-commerce market and the increasing demands, it is crucial to come up with an efficient and optimized way to pack products. Furthermore, the advent of new technologies and the fourth industrial revolution opened up a range of research areas and opportunities to expand the scope of classic packing applications. In this context, this work presents a framework to assist operators with an immersive application to assure smart packing. For that purpose, several heuristics that take into consideration multiple conditions imposed by the nature of the product are embedded to solve the online 3D Bin Packing Problem. Then the best packing solution is sent to the Augmented Reality developed application to immerse the operator in the packing process. This framework is designed for industries that rely on manual packing and aims to automate the process and/or provide intelligent decision-aid tools to ensure a smart packing process.","","979-8-3503-2102-9","10.1109/IC_ASET58101.2023.10150767","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150767","3Dimentional Bin Packing Problem;Augmented Reality;Industry 4.0;Smart Logistics;Heuristics","Industries;Three-dimensional displays;Manuals;Fourth Industrial Revolution;Electronic commerce;Augmented reality","augmented reality;bin packing;electronic commerce;production engineering computing","Augmented Reality;classic packing applications;consideration multiple conditions;e-commerce market;fourth industrial revolution;immersive application;manual packing;online 3D Bin Packing Problem;packing solution;smart online 3D Bin Packing;smart packing process","","","","18","IEEE","20 Jun 2023","","","IEEE","IEEE Conferences"
"Analyzing the impact of Augmented Reality based Digital Environment on Students' Learning","S. Gargrish; Harun; L. Sharma; B. Sharma; N. Tuli; M. Pathania","Chandigarh University, Punjab, India; Chandigarh University, Punjab, India; Chandigarh University, Punjab, India; Chandigarh University, Punjab, India; Chandigarh University, Punjab, India; Chandigarh University, Punjab, India","2022 International Conference on Emerging Smart Computing and Informatics (ESCI)","22 Apr 2022","2022","","","1","4","Augmented Reality (AR) is an immersive technology that provides a realistic and authentic teaching learning experience. It is clear that the today's generation favors technology-assisted learning over traditional learning. Although past research on AR has offered some light on how it can improve learning outcomes in different fields, studies on science experiment methods are still sparse. Experimental knowledge is essential for students to have a deeper grasp of the phenomena. The process of creating and developing a Smartphone app for a physics experiment employing AR technology is discussed in this article. This is an additional learning tool for upper secondary school. The ultimate goal of this mobile based AR app for Physics Experiment is to deliver meticulous knowledge in addition to traditional procedures and learning resources. A number of experiments have been chosen for inclusion in ElectroAR. To gauge feedback, an expert review is done. The user evaluation of ElectroAR in real classroom settings is something that will be done in the future.","","978-1-6654-0073-2","10.1109/ESCI53509.2022.9758186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758186","Augmented Reality;ElectroAR;Experimental Knowledge","Education;Informatics;Physics;Augmented reality","augmented reality;computer aided instruction;educational courses;educational institutions;mobile learning;physics computing;physics education;smart phones;student experiments","technology-assisted learning;traditional learning;learning outcomes;science experiment methods;experimental knowledge;smartphone app;physics experiment;learning tool;upper secondary school;mobile based AR app;learning resources;augmented reality;digital environment;student learning;immersive technology;teaching learning experience;ElectroAR;user evaluation","","","","19","IEEE","22 Apr 2022","","","IEEE","IEEE Conferences"
"Augmented reality service using real-time device recognition","I. Shin; B. Lim; J. Kim","Digital Media & Communications Research and Development Center, Samsung Electronics Company Limited; Digital Media & Communications Research and Development Center, Samsung Electronics Company Limited; Digital Media & Communications Research and Development Center, Samsung Electronics Company Limited","2011 18th International Conference on Telecommunications","20 Jun 2011","2011","","","113","117","AR (Augmented Reality) on mobile device is beyond providing simple additional information. Moreover, it has extended its range to variety domains. The latest AR service for device recognition uses POI (Point of Interest), GPS (Global Positioning System) or digital compass. These technologies could not be applied well in home and office environments, because it is difficult to recognize small and uniform shaped devices like industrial products. Nowadays, other methods of device recognition have been widely studied. One is tracking device features. This makes feature model and then compares feature model with trained model. The other is that using bar code or RFID. Such methods are hard to get into user-space because dynamic device status, device sensing or recognition could not be made into trained model. Therefore, in inner space like home or office, AR has not been used widely compared to outer space. In this paper, we propose new concept of technology about device recognition using network profile information though a mobile camera interface. In addition, we provide preview method about device's service, contents, and real-time status information so that users can use faster, more intuitive user-interface in mobile devices. We implement the system of media server and renderer to share digital contents. This provides intuitive interaction for contents sharing just using camera preview.","","978-1-4577-0024-8","10.1109/CTS.2011.5898901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5898901","AR;Augmented Reality;UPnP;DLNA;Media-Sharing;Recognition","Mobile handsets;Augmented reality;Cameras;Mobile communication;Media;Real time systems;Visualization","augmented reality;bar codes;cameras;feature extraction;Global Positioning System;mobile handsets;multimedia servers;peer-to-peer computing;radiofrequency identification","augmented reality service;real time device recognition;mobile device;AR service;POI;global positioning system;digital compass;office environment;home environment;industrial product;tracking device feature;bar code;RFID;dynamic device status;device sensing;network profile information;mobile camera interface;real time status information;user interface;media server;digital content sharing","","","3","15","IEEE","20 Jun 2011","","","IEEE","IEEE Conferences"
"AR-ChUM: Augmented Reality Chart Update Mashup","T. Kokoszka; H. Pham; B. Sullivan; T. Butkiewicz","Center for Coastal and Ocean Mapping, University of New Hampshire, Durham, New Hampshire, USA; Center for Coastal and Ocean Mapping, University of New Hampshire, Durham, New Hampshire, USA; Center for Coastal and Ocean Mapping, University of New Hampshire, Durham, New Hampshire, USA; Center for Coastal and Ocean Mapping, University of New Hampshire, Durham, New Hampshire, USA","OCEANS 2018 MTS/IEEE Charleston","10 Jan 2019","2018","","","1","6","Many mariners, especially recreational boaters, still utilize paper nautical charts for navigation. Unlike electronic charts, regularly updating these paper charts with new information can be a tedious task. Changes to paper charts are published in a textual format, which mariners must then use to manually locate on their physical chart by using a compass, pencil, and ruler to carefully place the update in the proper position on the chart. This project investigates the potential for using augmented reality (AR) to simplify and expedite the updating process. AR is a technology that superimposes digital information directly on top of a user's real world view. This project uses off-the-shelf, self-contained AR glasses (Microsoft HoloLens) to allow mariners to look at their paper nautical charts and see all modifications that need to be rectified and their respective locations on the paper chart. Advances in both AR and smart-phone technologies imply that this application could be implemented as a mobile app in the near future, which would make it easily accessible to average mariners.","0197-7385","978-1-5386-4814-8","10.1109/OCEANS.2018.8604659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8604659","augmented reality;charting;navigation","Three-dimensional displays;Image recognition;Navigation;US Government agencies;Cameras;Augmented reality;Tools","augmented reality;charts;mobile computing","paper chart;augmented reality chart update mashup;mariners;electronic charts;physical chart;nautical charts;AR-ChUM;Microsoft HoloLens;mobile app","","","","8","IEEE","10 Jan 2019","","","IEEE","IEEE Conferences"
"Poster: Preventing Spatial and Privacy Attacks in Mobile Augmented Reality Technologies","L. M. Claramunt; L. P. Epse; C. E. Rubio-Medrano; J. Baek; G. -J. Ahn","Arizona State University, Tempe, Arizona, USA; Arizona State University, Tempe, Arizona, USA; Texas A&M University - Corpus Christi, Corpus Christi, Texas, USA; Arizona State University, Tempe, Arizona, USA; Arizona State University, Tempe, Arizona, USA","2021 IEEE European Symposium on Security and Privacy (EuroS&P)","4 Nov 2021","2021","","","713","715","The growing popularity of applications featuring Mobile Augmented Reality (MAR) raises serious concerns regarding the use of such a game-changing technology inside sensitive physical spaces, e.g., memorials, hospitals, museums, etc., such that the safety and privacy of users is preserved. To address such concerns, we present our ongoing work for mediating the way MAR Content, e.g., digital objects rendered on top of a video stream, is generated, distributed, and consumed by applications. We introduce a theoretical model, a supporting framework, as well as SpaceMediator, a proof-of-concept application implementing our approach.","","978-1-6654-1491-3","10.1109/EuroSP51992.2021.00056","National Science Foundation(grant numbers:NSF-SFS-1129561); Arizona State University; Texas A&M University – Corpus Christi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9581271","Mobile Augmented Reality;Space;Invasion;Affectation;Mediation;Privacy;Authorization","Privacy;Hospitals;Streaming media;Safety;Augmented reality","augmented reality;data privacy;mobile computing","proof-of-concept application;spatial attack;privacy attacks;mobile augmented reality technologies;game-changing technology;user safety;digital objects;sensitive physical spaces;MAR content;SpaceMediator","","","","5","IEEE","4 Nov 2021","","","IEEE","IEEE Conferences"
"Augmented Reality for Assisting Students in the Learning Riau Malay Culture Local Subject during COVID-19 Pandemic","M. H. Adiya; D. Nasien; D. Andrio; S. Suroyo; D. M. Sari; N. Apriani","Department of Informatic Engineering, Faculty of Computer Science, Institut Bisnis dan Teknologi Pelita Pekanbaru, Pekanbaru, Indonesia; Department of Informatic Engineering, Faculty of Computer Science, Institut Bisnis dan Teknologi Pelita Pekanbaru, Pekanbaru, Indonesia; Department of Chemical Engineering, Faculty of Engineering, Universitas Riau, Pekanbaru, Indonesia; Department of History Education, Faculty of Education, Universitas Riau, Pekanbaru, Indonesia; Program Studi Magister, Faculty of Industrial Technology, Universitas Trisakti, Jakarta, Indonesia; Department of History Education, Faculty of Education, Universitas Riau, Pekanbaru, Indonesia","2021 Universitas Riau International Conference on Education Technology (URICET)","26 Aug 2022","2021","","","471","475","Corona Virus Disease 2019 or known as COVID-19 disseminated Indonesia in March 2020. The presence of this virus leads to fear and worry, all work activities are carried out from home. This is also perceived by the Public Elementary School number 189 Pekanbaru (SDN 189), particularly in the subject Budaya Melayu Riau (BMR) or Riau Malay Culture. BMR is a subject on heritage that characterizes Riau Malay culture; it has material evidence objects which are the results of human cultural history, nature and the environment are notable to be preserved. The problem faced by SDN 189 is that the level of students' comprehension towards BMR subject is diminished during COVID-19. The solution offered in solving this problem is to create fun learning technology through online learning using Android-based Augmented Reality (AR). AR is a type of interactive technology combines actual and virtual objects to produce 3D objects that are real in life. Therefore, the ultimate goal of this research is to intensify the knowledge and teacher’s skills in teaching and enhance students' understanding of BMR subjects.","","978-1-6654-2096-9","10.1109/URICET53378.2021.9865881","KT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9865881","Augmented reality;Riau Malay Culture (BMR);online learning","COVID-19;Three-dimensional displays;Pandemics;Education;Media;Internet;Augmented reality","augmented reality;computer aided instruction;diseases;history;management education;teaching","online learning;Android-based Augmented Reality;BMR subject;learning Riau Malay Culture local subject;COVID-19 pandemic;Corona Virus Disease 2019;COVID-19 disseminated Indonesia;March 2020;Public Elementary School number 189 Pekanbaru;SDN 189;characterizes Riau Malay culture;material evidence objects;human cultural history;students","","","","15","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"A Review: Augmented Reality Technology-Based Interactive Learning Media","A. W. Astuti; M. Y. Rezaldi; S. Riyanto; R. Richardo","Mathematics Education, Alma Ata University, Yogyakarta, Indonesia; Research Center for Data and Information Science, National Research and Innovation Agency, Bandung, Indonesia; Research Center for Data and Information Science, National Research and Innovation Agency, Cibinong, Indonesia; Mathematics Education, Alma Ata University, Yogyakarta, Indonesia","2022 5th International Conference on Networking, Information Systems and Security: Envisage Intelligent Systems in 5g//6G-based Interconnected Digital Worlds (NISS)","3 Apr 2023","2022","","","1","5","Some research improves that students find it difficult to learn mathematics and are considered scary. This is influenced by conventional and less interactive learning methods so that students cannot understand mathematics. To overcome this, interactive learning based on Augmented Reality (AR) technology is needed. The technology has been widely used to overcome various problems in the world of education. This research purpose to review the results of research related to AR in mathematics learning published in the last 5 years. Based on the results analysis, it can be seen that AR is very effective in learning mathematics so that students can digest and understand mathematics optimally. The research results can be used as recommendations in the learning system through the use of AR technology.","","978-1-6654-5363-9","10.1109/NISS55057.2022.10085418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10085418","augmented reality;mathematics;interactive;learning media","Learning systems;Education;Media;Mathematics;Security;Intelligent systems;Augmented reality","augmented reality;computer aided instruction","AR technology;augmented reality technology-based interactive learning media;mathematics learning","","","","40","IEEE","3 Apr 2023","","","IEEE","IEEE Conferences"
"Effective educational augmented reality applications: Points to consider","S. Kucuk; R. M. Yilmaz; Y. Goktas","Deparment of Conputer Education and Instructional Technology, Istanbul University, Istanbul, Turkey; Department of Computer Education and Instructional Technology, Ataturk University, Erzurum, Turkey; Department of Computer Education and Instructional Technology, Ataturk University, Erzurum, Turkey","2014 IEEE 8th International Conference on Application of Information and Communication Technologies (AICT)","9 Feb 2015","2014","","","1","4","A new paradigm, that it is possible to access information in any place at any time, led education researchers to seek methods to permit interactions between the real environment and digital information. Augmented Reality (AR), which provides such an environment of interaction, was consequently developed as a technology that allows interaction between people and information. This technology promises significant potential if integrated into education. The purpose of this study is to present important factors to consider while developing an effective educational AR applications. The analysis, design, development, and implementation of educational AR applications are examined. This is a case study. The sample consisted of 42 senior undergraduate students, who had experience with educational AR technology. Structured interview form was used as the data collection tool. According to the findings, the participants focused especially on software selection in the analysis phase. They reported that easy interfacing of the program, multimedia support, the environment where the application is to be implemented, and the related devices to be used should be carefully considered. In the design and development phases, it is important to determine whether the application is appropriate to the target population, the content, and the purpose. In the implementation phase, it is important to provide the necessary technical sub-structure and the physical environment; to inform the students about the program, materials, purpose, and potential outcomes; and to provide them with equal opportunities in the application. The results obtained in this study can be used to guide future educational implementations and research studies on AR technology.","","978-1-4799-4119-3","10.1109/ICAICT.2014.7035994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7035994","Augmented reality;educational technology;instructional design","Software;Education;Augmented reality;Materials;Sociology;Statistics;Multimedia communication","augmented reality;educational technology","educational augmented reality;educational AR applications;educational AR technology;data collection tool;software selection;multimedia support","","","","13","IEEE","9 Feb 2015","","","IEEE","IEEE Conferences"
"Media Interactive Learning and biology subjects implementation with augmented reality application","S. Moedjiono; A. Kusdaryono; Nurcahyadi","Universitas Budi Luhur, Jakarta, Jakarta, ID; Budi Luhur University, Jakarta, Indonesia; Universitas Budi Luhur, Jakarta, Jakarta, ID","2017 Second International Conference on Informatics and Computing (ICIC)","5 Feb 2018","2017","","","1","6","Media Interactive Learning will be very beautiful if applied in the world of education, especially high school students that on average have Smartphones. Therefore, can be designed a media learning application that will use the biology subjects with the material in human organs, which will use the materials of the high school grade XI. Android is a container that can be used to apply media applications learning, using Augmented Reality (AR) technology which is often called AR Media learning would be more interesting to use. The result is media learning and biology subjects with AR technology using a marker Natural Feature Tracking reading techniques.","","978-1-5386-2985-7","10.1109/IAC.2017.8280626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8280626","Augmented Reality (AR);smartphone;marker;Natural Feature Tracking;Android","Media;Biology;Smart phones;Androids;Humanoid robots;Augmented reality;Education","augmented reality;biology computing;computer aided instruction;mobile learning","biology subjects;augmented reality application;media applications learning;media interactive learning;Android;AR media learning;natural feature tracking reading techniques","","","","8","IEEE","5 Feb 2018","","","IEEE","IEEE Conferences"
"A Study of Augmented Reality in Learning, Memory and Learning Motivation: A Case Study of Practical Writing in Middle School Life","F. -C. Ou Yang; W. -T. Huang; C. -J. Liao","Dept. of Information Management, Chien Hsin University of Science and Technology, Chung-Li, Taiwan; Dept. of Information Management, Chien Hsin University of Science and Technology, Chung-Li, Taiwan; Dept. of Information Management, Chung Yuan Christian University, Chung-Li, Taiwan","2018 7th International Congress on Advanced Applied Informatics (IIAI-AAI)","18 Apr 2019","2018","","","958","959","With the development of Augmented Reality (AR) technology, more and more research studies have explored the educational impact of AR technology applications. However, in the field of practical writing, few studies discussed the effectiveness of AR technology in Chinese idiom (inscription) learning. In this study we developed a Chinese idiom learning system, named Chinese Idioms Learning Card (CILC), which combined AR technology and game-based learning design. In the current state of the study, the proposed system has been developed and continues to address usability based on the advice of linguistic experts and students. Two classes of junior high school students in Taiwan will participate in continuous experiments. In the future, a mixed study will be conducted to explore effectiveness of students' self-learning in practical writing with the help of using this AR learning system.","","978-1-5386-7447-5","10.1109/IIAI-AAI.2018.00200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693400","Augmented Reality;practical writing;learning card","Writing;Games;Education;Learning systems;Augmented reality;Information management;Animation","augmented reality;computer aided instruction;serious games (computing)","practical writing;Chinese idiom learning system;junior high school students;mixed study;AR learning system;middle school life;educational impact;AR technology applications;augmented reality technology;game-based learning design;Taiwan","","","","4","IEEE","18 Apr 2019","","","IEEE","IEEE Conferences"
"Augmented Reality English Education Based iOS with MobileNetV2 Image Recognition Model","D. P. Alamsyah; Y. Ramdhani; A. T. Syam; A. Setiadi","Entrepreneurship Department, BINUS Business School Undergraduate Program, Bina Nusantara University, Jakarta, Indonesia; Informatic Engineering, Universitas Adhirajasa Reswara Sanjaya, Bandung, Indonesia; Informatic Engineering, Universitas Adhirajasa Reswara Sanjaya, Bandung, Indonesia; Informatic Engineering, Universitas Adhirajasa Reswara Sanjaya, Bandung, Indonesia","2022 Seventh International Conference on Informatics and Computing (ICIC)","13 Jan 2023","2022","","","1","5","The ability to speak English is a must-have currently. Along with the development of the times, the ability to speak English is very important for everyone. Learning English is very important, especially in terms of education and work. Therefore, with the urgent need for English in the national and international arena, English must be introduced from an early age. By taking advantage of technological advances, especially iOS, education can be done using educational applications. This English-language object recognition educational application is designed by utilizing Augmented Reality (AR) technology by utilizing ARKit, and CoreML for object recognition models, and AVKit for text-to-speech. To find out the name of an object in English, the user is required to point his cellphone at the object he wants to know the name, then click on the cellphone screen to bring up the text of the object name in English above the object and a sound will sound the pronunciation of the text. This educational application is done using XCode software and the Swift programming language. Its development uses the waterfall method. This object recognition educational application in English can run well according to the design, starting from identifying objects and displaying text on objects with test results using the Black Box method, which is valid as a whole.","","979-8-3503-4571-1","10.1109/ICIC56845.2022.10007000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10007000","Education Game;Augmented Reality;English;iOS;MobileNetV2;ARKit;CoreML","Computer languages;Image recognition;Education;Closed box;Object recognition;Informatics;Augmented reality","augmented reality;image recognition;iOS (operating system);mobile computing;object recognition;programming languages","AR;augmented reality English education based iOS;black box method;English-language object recognition educational application;MobileNetV2 image recognition model;swift programming language;waterfall method;XCode software","","","","20","IEEE","13 Jan 2023","","","IEEE","IEEE Conferences"
"User Behaviour Analysis of Volumetric Video in Augmented Reality","E. Zerman; R. Kulkarni; A. Smolic","V-SENSE, School of Computer Science and Statistics, Trinity College Dublin, Dublin, Ireland; V-SENSE, School of Computer Science and Statistics, Trinity College Dublin, Dublin, Ireland; V-SENSE, School of Computer Science and Statistics, Trinity College Dublin, Dublin, Ireland","2021 13th International Conference on Quality of Multimedia Experience (QoMEX)","30 Jun 2021","2021","","","129","132","Augmented reality (AR) is getting popular, and among other content creation techniques, volumetric video allows to bring dynamic real world content as captured by cameras into such applications. To develop efficient algorithms for compression and transmission of the volumetric media, it is important to understand how users will consume this new form of dynamic 3D content. In this paper, we analyse the user behaviour for the volumetric video consumption in AR. In particular, we study the distribution of users' viewpoints, relative locations, and average distances from the content. For this purpose, we built an Android AR application using the volumetric video and conducted a user study remotely. The results show that users spent most of their time looking at the frontal part of the volumetric video, and this indicates the importance of the face in visual attention. The collected user behaviour data are made public to support further research.","2472-7814","978-1-6654-3589-5","10.1109/QoMEX51781.2021.9465456","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465456","user behaviour;user movement;augmented reality;volumetric video;user experience","Visualization;Three-dimensional displays;Heuristic algorithms;Streaming media;Media;Cameras;Augmented reality","Android (operating system);augmented reality;data compression;face recognition;human computer interaction;human factors;image coding;stereo image processing;video signal processing","Android augmented reality;content creation;user behaviour analysis;volumetric video;dynamic 3D content;volumetric media transmission;volumetric media compression;Android AR;visual attention;face importance","","","","28","IEEE","30 Jun 2021","","","IEEE","IEEE Conferences"
"Mobile learning and augmented reality","F. Pais; S. Vasconcelos; S. Capitão; V. Carlos; M. Almeida","Departamento de Educação e Departamento de Comunicação e Arte, Universidade de Aveiro, Aveiro, Portugal; Departamento de Educação e Departamento de Comunicação e Arte, Universidade de Aveiro, Aveiro, Portugal; Departamento de Educação e Departamento de Comunicação e Arte, Universidade de Aveiro, Aveiro, Portugal; Departamento de Educação e Departamento de Comunicação e Arte, Universidade de Aveiro, Aveiro, Portugal; Departamento de Educação e Departamento de Comunicação e Arte, Universidade de Aveiro, Aveiro, Portugal","6th Iberian Conference on Information Systems and Technologies (CISTI 2011)","4 Aug 2011","2011","","","1","4","This article presents a protype for a mobile learning solution using augmented reality. Aimed at promoting the digital inclusion of elementary school deaf students the project is entitled: “A minha rua”/ My street.","2166-0735","978-989-96247-5-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974309","Augmented reality;Mobile Learning;Digital Inclusion;Geographic Information Technologies;Special Needs","Augmented reality;Global Positioning System;Internet;Mobile communication;Surges;Markup languages;Software","augmented reality;computer aided instruction;handicapped aids;mobile computing","mobile learning;augmented reality;mobile learning solution;digital inclusion;elementary school deaf students;minha rua","","","","14","","4 Aug 2011","","","IEEE","IEEE Conferences"
"Adaptive Visualization of Gas Distribution Using Augmented Reality Glasses","L. Duan; H. Matsukura; P. Punpongsanon; T. Hiraki; D. Iwai; K. Sato","Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan","2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)","21 Dec 2020","2020","","","658","659","Monitoring gas distribution is a method to supervise and validate the stabilization and safety of landfill sites. Recent technologies that use sophisticated sensors confuse workers' understanding of estimated gas distribution due to mismatch between the gas position in a scene and the one in a monitor. In this paper, we propose a method for spatially visualizing gas distribution using augmented reality glasses. Furthermore, we discuss the initial step toward the adaptive visualization of gas distribution based on workers' knowledge and monitoring purposes using real-time AR.","2378-8143","978-1-7281-9802-6","10.1109/GCCE50665.2020.9291811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291811","Gas distribution mapping;Gas visualization;Augmented reality;Head-Mounted display","Visualization;Glass;Real-time systems;Sensors;Safety;Monitoring;Augmented reality","augmented reality;data visualisation;environmental science computing;natural gas technology;real-time systems;refuse disposal","adaptive gas distribution visualization;augmented reality glasses;gas distribution monitoring;landfill site stabilization;landfill site safety;sensors;gas position;gas distribution estimation;real-time AR","","","","5","IEEE","21 Dec 2020","","","IEEE","IEEE Conferences"
"Vision-based markerless tracking in an augmented reality application for a signboard aided-design system","H. -y. Pai","Department of Multimedia Design, National Formosa University No. 64, Wunhua Rd., Huwei Township, Taiwan, ROC, Yunlin","2018 1st IEEE International Conference on Knowledge Innovation and Invention (ICKII)","9 Dec 2018","2018","","","74","77","In most cities in Taiwan, electronic signboards can be seen everywhere. Advertising signboards for stores are becoming more common, larger, and more noticeable in order to attract more attention. The harmony between outdoor signboards and the surrounding environment has long been ignored by local residents. Because of the urban aesthetics of absence, outdoor signboards have come to be treated as visual pollution. In this paper, we focus on vision-based markerless tracking [7] in an augmented reality (AR) [4] [5] [6] application as part of a signboard aided-design system. We present an AR framework that uses simultaneous localization and mapping (SLAM) [8] to approach an AR scene as realistically as a photographic image. Two AR systems are developed as demonstration examples: a signboard design photo-image storage system and a signboard display system. The project is developed using 3D computer graphics technologies, including a visual SLAM [9] algorithm, tessellation shader technology, and editable 3D textures with an embedded image approach. With the features of 3D relief signboard displays and a measurable landscape, the system helps signboard designers to improve their signboards by recognizing the influence of environmental factors. Consequently, the aided design system offers a path toward environmental harmony for designers by facilitating the pre-production process using mobile AR.","","978-1-5386-5267-1","10.1109/ICKII.2018.8569120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8569120","Augmented Reality;Simultaneous Localization and Mapping(SLAM);Signboard Design","Technological innovation;Conferences;Augmented reality;Computer vision;Internet","augmented reality;computer graphics;computer vision;image recognition;image texture","vision-based markerless tracking;augmented reality application;signboard aided-design system;electronic signboards;advertising signboards;mobile AR systems;simultaneous localization and mapping;photo-image storage system;SLAM algorithm;visual pollution;photographic image;3D computer graphics technologies;tessellation shader technology;embedded image;pre-production process","","","","10","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
"The Model of Marker Based Tracking on the Augmented Reality of Hijaiyah Alphabet and Tajweed Al-Qur'an for Children Education","Al-Khowarizmi; Akrim; N. Ginting","Department of Information Technology, Universitas Muhammadiyah Sumatera Utara, Medan, Indonesia; Department of Islamic Religion Education, Universitas Muhammadiyah Sumatera Utara, Medan, Indonesia; Department of Islamic Religion Education, Universitas Muhammadiyah Sumatera Utara, Medan, Indonesia","2021 International Conference on Computer Science and Engineering (IC2SE)","13 Jun 2022","2021","1","","1","4","Al-Qur'an is a holy book of Muslims. The recitation of the Al-Qur'an is controlled by many laws which are contained in the Hijaiyah alphabets and Tajweed which refer to the correct pronunciation of the Al-Qur'an. If it is misstated, it will be wrong in meaning and meaning in the delivery of the Al- Qur'an. However, a Muslim is obliged to be good at reading the Al-Qur'an from an early age. So that with the development of technology specifically in smartphone media, children become addicted to the use of smartphone technology. It is undeniable that children are very fond of using smartphones, so with the development of this technology, a learning media was designed that could be implemented in a smartphone in order to overcome children's addiction in playing smartphone games replaced by special learning in the introduction of Hijaiyah Alphabet and Tajweed Al- The Qur'an. The technology used is the development of multimedia technology such as Augmented Reality (AR) which expands our physical world by adding a layer of digital information to it. AR was also developed on the basis of several marker techniques so that in this paper a children's learning media was developed with responsive results in the Marker Based Tracking Technique on AR for the introduction of the Hijaiyah alphabet and the Tajweed Al- Qur'an as a substitute for children's addiction in using smart phones.","","978-1-6654-0046-6","10.1109/IC2SE52832.2021.9792135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792135","Augmented Reality;Marker Based Tracking Technique;Learning Media;Children's Education","Computer science;Computational modeling;Education;Games;Media;Augmented reality;Smart phones","augmented reality;computer aided instruction;humanities;mobile computing;natural language processing;serious games (computing);smart phones","smartphone technology;augmented reality;Hijaiyah alphabet;children education;smartphone media;Tajweed Al-Qur'an;AR;multimedia technology;marker based tracking technique;childrens addiction;holy book;Muslims","","","","25","IEEE","13 Jun 2022","","","IEEE","IEEE Conferences"
"An optimization calculation method: the positioning of passenger's mobility based on augmented reality","H. Kabaou; P. Lorenz; S. Tabbane","University of Haute Alsace, France; University of Haute Alsace, France; University of Carthage - Sup'COM, Tunisia","2014 22nd International Conference on Software, Telecommunications and Computer Networks (SoftCOM)","12 Feb 2015","2014","","","77","83","There is extensive research on passengers mobility estimated position. Among these approaches, Simultaneous Localization And Mapping (SLAM) is one of the most frequent methods that exponentially increase the computational complexity. To overcome this problem, we propose a method based on augmented reality that reduces the computational complexity by using less computing power. With this method, each target image is characterized by three dimensions: position, content and size. The passenger is equipped with a smartphone that captures images, processes and compares them with a database to overlay the virtual 3D elements with the real world.","","978-9-5329-0052-1","10.1109/SOFTCOM.2014.7039073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7039073","positioning;mobility;augmented reality;image processing tracking","Three-dimensional displays;Cameras;Augmented reality;Simultaneous localization and mapping;Feature extraction;Databases;Accuracy","augmented reality;SLAM (robots);smart phones;traffic engineering computing","optimization calculation method;augmented reality;simultaneous localization and mapping;SLAM;computational complexity;image position dimension;image content dimension;image size dimension;smart phone;virtual 3D elements;passengers mobility position estimation","","","","9","","12 Feb 2015","","","IEEE","IEEE Conferences"
"Augmented Reality Game Creator for on-site Job Training","A. -r. Asadi; R. Hemadi","Antidisciplinary Research and Development Association, Tehran, Iran; Antidisciplinary Research and Development Association, Tehran, Iran","2018 2nd National and 1st International Digital Games Research Conference: Trends, Technologies, and Applications (DGRC)","13 May 2019","2018","","","128","133","Various serious games for education and especially training have emerged in recent years. Applying augmented reality to serious games makes it possible to develop games that are played in real environments of corporations instead of virtual worlds and using cell phones as the platform makes developing and training with such games easier and more accessible. This paper explains a prototype of a system which consists of a serious game authoring application and a playable client that can be implemented by companies and organizations without requiring programming or 3D modeling skills.","","978-1-7281-1114-8","10.1109/DGRC.2018.8712020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8712020","Serious Games;Augmented Reality;Corporate Training","Games;Training;Augmented reality;Companies;Hardware","augmented reality;computer based training;on-the-job training;serious games (computing)","augmented reality game creator;on-site job training;serious games;virtual worlds;serious game authoring application;cell phones","","","","17","IEEE","13 May 2019","","","IEEE","IEEE Conferences"
"Augmentative and Alternative Communication with Eye-gaze Technology and Augmented Reality: Reflections from Engineers, People with Cerebral Palsy and Caregivers","H. Zhao; P. Karlsson; O. Kavehei; A. McEwan","School of Biomedical Engineering, The University of Sydney, Sydney, Australia; Research Institute, Cerebral Palsy Alliance & Brain and Mind Centre, The University of Sydney, Sydney, Australia; School of Biomedical Engineering, The University of Sydney, Sydney, Australia; School of Biomedical Engineering, The University of Sydney, Sydney, Australia","2021 IEEE Sensors","17 Dec 2021","2021","","","1","4","This paper reports on the outcome of a survey in which the perceived satisfaction and workload of a novel augmented reality (AR) device for Augmentative and Alternative Communication (AAC) was explored among engineers, people with Cerebral Palsy (CP) and/or their caregivers. The current design of a novel device using AR glasses, Microsoft HoloLens, and an eye-tracking system from Pupil Labs HoloLens Binocular Add-on was explored. The survey was based on QUEST 2.0 and NASA-TLX. The average result for the QUEST 2.0 was 3.52, 3.65, and 3.04 out of 5 for all participants, engineers, and people with cerebral palsy and/or their guardians, respectively. Findings from the NASA-TLX showed that people with cerebral palsy and/or their caregivers perceived a lower workload than the engineers. Therefore, it is believed that, although the current design still has some challenges, it holds the potential as a novel AAC solution for people with cerebral palsy, with complex communication needs.","2168-9229","978-1-7281-9501-8","10.1109/SENSORS47087.2021.9639819","Cerebra; University of Sydney; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9639819","Augmentative and Alternative Communication (AAC);Augmented Reality (AR);Eye-gaze Technology(EGT);Cerebral Palsy (CP)","Glass;Reflection;Sensors;Pupils;Augmented reality","augmented reality;handicapped aids;human computer interaction;patient care","caregivers;eye-tracking system;Pupil Labs HoloLens Binocular;QUEST 2;NASA-TLX;cerebral palsy;Augmentative Communication;Alternative Communication;eye-gaze technology;perceived satisfaction;novel augmented reality device","","","","32","IEEE","17 Dec 2021","","","IEEE","IEEE Conferences"
"Augmented Reality Application as a Food Purchasing Assistant","K. V. Sysoev; A. A. Frolov","National Research Nuclear University MEPhI (Moscow Engineering Physics Institute), Moscow, Russian Federation; National Research Nuclear University MEPhI (Moscow Engineering Physics Institute), Moscow, Russian Federation","2021 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus)","9 Apr 2021","2021","","","703","706","Possibility of application of apps with the function of augmented reality for daily use is considered by the example of development and subsequent use of food search app for pensioners in food stores. The experimental part of the work describes the process of selecting important functions of the application which must help pensioners to buy food in stores. Describes the architecture and process of creating a cross-platform application using Unity 3D, the interaction of the application with a web server through the processing of requests received from the mobile application. The results show examples of mobile application work, possibilities of this application, as well as the results of surveys of potential users about the usefulness of such applications. In summary, there are conclusions of the work, the advantages and disadvantages of the finished product.","2376-6565","978-1-6654-0476-1","10.1109/ElConRus51938.2021.9396358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396358","augmented reality;AR;Android;Unity 3D","Three-dimensional displays;Production;Mobile handsets;Web servers;Mobile applications;Service-oriented architecture;Augmented reality","augmented reality;Internet;mobile computing;purchasing;retail data processing","pensioners;cross-platform application;Unity 3D;mobile application work;augmented reality application;food purchasing assistant;food search app;food stores;work describes;web server","","","","11","IEEE","9 Apr 2021","","","IEEE","IEEE Conferences"
"Advanced Military Helmet aided with Wireless Live Video Transmission, Sensor Integration and Augmented Reality Headset","S. Jalui; T. Hait; T. Hathi; S. Ghosh","Bachelor of Engineering in Electronics and Telecommunication, Mumbai University., MCT's Rajiv Gandhi Institute of Technology, Mumbai, India; Bachelor of Engineering in Electronics and Telecommunication, Mumbai University., MCT's Rajiv Gandhi Institute of Technology, Mumbai, India; Bachelor of Engineering in Electronics and Telecommunication, Mumbai University., MCT's Rajiv Gandhi Institute of Technology, Mumbai, India; Bachelor of Engineering in Instrumentation, Mumbai University., MCT's Rajiv Gandhi Institute of Technology, Mumbai, India","2019 International Conference on Communication and Electronics Systems (ICCES)","20 Feb 2020","2019","","","123","127","Military and Army need weapons for military activities or operations to safeguard our country and its citizens. Due to their extensive cost and hefty architecture bottlenecks, Military people face many problems especially in the warfare. Therefore, we came up with an idea of integrating different wireless technologies and Augmented Reality [AR] models in helmet to display all the information related to battlefield in a single screen. This advanced technology can provide innovative strategies in war times to deliver more insights about the ongoing military operations.","","978-1-7281-1261-9","10.1109/ICCES45898.2019.9002600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9002600","Augmented Reality;Wireless Video Transmission;Radar Motion Detection;GPS tracking;Strategic War Improvement","Augmented reality;Global Positioning System;Temperature sensors;Temperature measurement;Radar;Cameras;Humidity","augmented reality;helmet mounted displays;military communication;military computing;video communication;weapons","AR models;military operations;wireless live video transmission;sensor integration;augmented reality headset;weapons;military activities;advanced military helmet","","","","12","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Sandpit Simulating Ant Colonies","L. Smith; J. McCormack; Z. Xiong","Dept of ECSE, Monash University, Australia; Faculty of Information Technology, Monash University, Australia; Dept of ECSE, Monash University, Australia","2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","29 Nov 2018","2018","","","1","6","The way ants navigate their environment and forage for food is an intricate process. A common way ant species navigate is by using pheromone chemical trails leading to and from food sources. This paper summarizes an augmented reality sandpit project that aims to show the creation and evolution of these pheromone trails within a colony in an interactive way. A complex yet accessible simulation was built to allow users to move sand in a real sandpit while seeing virtually projected images on top of the sandpit change accordingly to showcase emergent ant colony behavior. A demo video of the project is available at https://www.youtube.com/watch?v=63Kx_xVEZkk.","","978-1-5386-4195-8","10.1109/ICMEW.2018.8551581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8551581","Augmented reality (AR);sandpit;ant colony simulation;pheromone;pheromone navigation model","Navigation;Mathematical model;Two dimensional displays;Software;Augmented reality;Biological system modeling;Chemicals","ant colony optimisation;augmented reality","https://www.youtube.com/watch?v=63Kx_xVEZkk;virtually projected images;ant species;ant colony behavior;augmented reality sandpit project;food sources;pheromone chemical trails;intricate process;sandpit change","","","","8","IEEE","29 Nov 2018","","","IEEE","IEEE Conferences"
"Otonona: a prototype for experiencing absolute pitch using multimodal augmented reality","A. Oka; K. Kurihara","Dept. of Computer Science, Tsuda University, Tokyo, Japan; Dept. of Computer Science, Tsuda University, Tokyo, Japan","2022 IEEE 11th Global Conference on Consumer Electronics (GCCE)","18 Jan 2023","2022","","","453","456","The sense of sound, so called absolute and relative pitch, influences our perception and understanding of music. This research aims to extend the human sense of pitch in a multimodal approach using computers. In this paper, we focus on absolute pitch. Absolute pitch is an ability that some people are said to acquire by the age of six. Although degrees of this ability vary, people who have this ability are generally said to be able to recognize the note names even without being given a reference note. This is a potentially useful ability for understanding music, although it is difficult to acquire this ability through training as an adult. In this paper, we present the results of a subjective survey regarding with sound perception conducted on absolute pitch holders, the design and implementation of Otonona, a system for accessing the usefulness of absolute pitch using multimodal augmented reality, and future work.","2378-8143","978-1-6654-9232-4","10.1109/GCCE56475.2022.10014312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10014312","mixed / augmented reality;auditory feedback;multimodal;wearable device;bone-conduction headphone","Training;Headphones;Computers;Prototypes;Music;Augmented reality;Consumer electronics","augmented reality;hearing;music;musical acoustics","absolute pitch holders;multimodal augmented reality;music;Otonona;relative pitch;sound perception","","","","9","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"Attempt to Extract Lacking Information on University Campus by Augmented Reality Content Production Activities","T. Ozeki; Y. Okamura; T. Mouri","Department of Media Infomatics, Aichi University of Technology, Gamagori, Japan; Digital Promotion Division, AR Marketing Division, Startialab, Inc, Tokyo, Japan; Facirity of Enginnering, Gifu University, Gifu, Japan","2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)","8 Mar 2021","2020","","","925","926","Augmented Reality (AR) makes it easy to link certain information to contents on the Internet and present it to others. This study conducts workshop as specific course that asked first-year university students who were not familiar with the campus to link them with information using the items in the college as AR markers. Participants proposed a campus map contents as a marker for the trees and objects. Participants showed us the information that freshly students wanted. In further works, we would indicate to find out what problems to be promote student's learning activities. This work-in-progress paper describes a workshop.","2470-6698","978-1-7281-6942-2","10.1109/TALE48869.2020.9368390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9368390","augmented reality (AR);media information;exploring learning resources;workshop","Conferences;Education;Production;Internet;Data mining;IEEE activities;Augmented reality","augmented reality;computer aided instruction;educational courses;educational institutions;Internet;mobile computing","extract lacking information;university campus;augmented Reality content production activities;specific course;asked first-year university students;AR markers;campus map contents;freshly students;promote student","","","","7","IEEE","8 Mar 2021","","","IEEE","IEEE Conferences"
"An Analysis for Motivating Sketching Practice with Augmented Reality in Da Vinci Eye","S. -C. Liao; M. -J. Kuo","dept. Multimedia and Entertainment Science, Southern Taiwan University of Science and Technology, Tainan, Taiwan; dept. Multimedia and Entertainment Science, Southern Taiwan University of Science and Technology, Tainan, Taiwan","2020 International Symposium on Computer, Consumer and Control (IS3C)","8 Apr 2021","2020","","","95","97","Aside from sketching with naked eyes, Augmented Reality (AR) allows users to sketch a wide variety of items in an innovative approach. And this research aims to explore how this technology helps users learn better with higher intrinsic motivation. In order to investigate how this type of apps help users learn and practice sketching, we chose Da Vinci Eye as our tool in this research. We recruited 16 participants whose ages are between 20 and 25 as our participants. 8 of them never had the intensive training on sketching; and the others had majored in art-related professions. Results showed that tracing the virtual silhouette increased the motivation of beginners to practice sketching; on the other hand, this assistance didn't help too much for those who had several years of sketching experience. Our findings provided initial confirmation that AR application has the potential to improve novices' motivation and performance in sketching.","","978-1-7281-9362-5","10.1109/IS3C50286.2020.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394037","Augmented Reality;Sketching;Da Vinci Eye;Learning Motivation;Learning Performance","Training;Art;Three-dimensional displays;Shape;Tools;Market research;Augmented reality","art;augmented reality;computer aided instruction;human factors","sketching practice;augmented reality;Da Vinci Eye;naked eyes;intrinsic motivation;sketching experience;art-related professions;virtual silhouette tracing;AR application;learning motivation;learning performance","","","","10","IEEE","8 Apr 2021","","","IEEE","IEEE Conferences"
"Implementation of Rehabilitation Platform based on Augmented Reality Technology","N. T. Thinh; N. A. Quoc; N. V. Tam Toan; T. T. Luc","Department of Mechatronics, Ho Chi Minh City University of Technology and Education, Vietnam; Department of Mechatronics, Ho Chi Minh City University of Technology and Education, Vietnam; Department of Mechatronics, Ho Chi Minh City University of Technology and Education, Vietnam; Department of Mechatronics, Ho Chi Minh City University of Technology and Education, Vietnam","2021 21st International Conference on Control, Automation and Systems (ICCAS)","28 Dec 2021","2021","","","1926","1931","Stroke is now one of the leading causes of death and disability in both motor and cognitive functions. In addition, rehabilitation for stroke survivors also faces many physical and human difficulties. To address this issue, we studied the use of Augmented Reality (AR) in rehabilitation using a system called RARS. This system creates limbs rehabilitation exercises in the form of games using an AR interface. The goal of the RARS is to increase patient's positive emotions, which motivates them to enjoy rehabilitation exercises. As a result, recovery efficiency will be improved, and the burden on physiotherapists will be reduced. The RARS is evaluated through a research about the effectiveness of this system on rehabilitation for patients after stroke (n=10). Reported results showed that the RARS produced significant improvement in the patient's indicators of functional status. From that, this system shows that it not only creates great benefits for personnel and economic but also bring about huge potential for future growth.","2642-3901","978-89-93215-21-2","10.23919/ICCAS52745.2021.9650059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650059","stroke;rehabilitation;Augmented Reality","Training;Hospitals;Games;Stroke (medical condition);Real-time systems;Personnel;Augmented reality","augmented reality;cognition;handicapped aids;medical robotics;patient rehabilitation;patient treatment","human difficulties;RARS;limbs rehabilitation exercises;patient;rehabilitation platform;Augmented Reality technology;motor;cognitive functions;stroke survivors;physical difficulties","","","","14","","28 Dec 2021","","","IEEE","IEEE Conferences"
"Augmented Reality as a Crucial Element in Modern Electric Distribution Company","P. Sylwestrzak; J. Szkutnik","Life Sciences and Technical Institute, Angelus Silesius State College of Applied Sciences, Walbrzych, Poland; Life Sciences and Technical Institute, Angelus Silesius State College of Applied Sciences, Walbrzych, Poland","2019 20th International Scientific Conference on Electric Power Engineering (EPE)","29 Jul 2019","2019","","","1","5","The predominant goal of this article is to touch upon the usefulness of the so-called Augmented Reality (AR) technology with regard to its utilization in companies distributing electric power. AR is understood to be a real-time combination of real world imagery, typically in the form of images recorded by a camera, with digitally generated one. Additional elements have to be added to the camera-captured image in real time and the whole experience should be interactive in nature, as well as allow the user to move freely. After analyzing the current applications of the discussed technology, the authors propose its utilization within the scope of companies operating in the electric power-related branch of industry, with the major focus being put on enterprises specializing in electric power distribution, both in terms of network infrastructure management and organization of training sessions pertaining to key procedures and machine handling.","2376-5631","978-1-7281-1334-0","10.1109/EPE.2019.8778022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778022","augmented reality;AR;service visualization;virtual training sessions","Augmented reality;Production;Training;Companies;Real-time systems;Industries","augmented reality;cameras;electricity supply industry;image capture;power distribution","camera-captured image;electric power distribution;augmented reality;electric distribution company;network infrastructure management","","","","17","IEEE","29 Jul 2019","","","IEEE","IEEE Conferences"
"A Chinese Drama Rehearsal System Based on Phonetic Matching and Augmented Reality","Y. Zhang; R. Huang","University of Science and Technology of China, Hefei, Anhui, CN; Department of Communication of Science and Technology, University of Science and Technology of China Hefei, Anhui, China","2017 International Conference on Culture and Computing (Culture and Computing)","21 Dec 2017","2017","","","108","111","Antiphonal singing is a common and important form of expression in Chinese drama. Antiphonal singing requires two actors performs in turns, and their action, expression, gesture need to correspond to the other one. In this paper the authors present a Chinese drama rehearsal system based on phonetic matching and augmented reality to help Chinese traditional drama actor and enthusiasts to rehearse and experience drama in a more immersive and realistic way.","","978-1-5386-1135-7","10.1109/Culture.and.Computing.2017.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8227353","Chinese drama;Antiphonal singing;rehearsal system;phonetic matching;augmented reality","Cameras;Microphones;Art;Audio databases;Heuristic algorithms;Augmented reality","augmented reality;entertainment;humanities;speech processing","Chinese drama rehearsal system;phonetic matching;augmented reality;antiphonal singing","","","","8","IEEE","21 Dec 2017","","","IEEE","IEEE Conferences"
"Three-Dimensional Registration Method of KLT Inter-Frame Tracking and Improved ORB Feature Detection in Augmented Reality","G. Xu; W. He; W. Zhang; G. Gu; Q. Chen","School of Electronic Engineering and Optoelectronic Technology, Nanjing University of Science and Technology, Nanjing, China; School of Electronic Engineering and Optoelectronic Technology, Nanjing University of Science and Technology, Nanjing, China; School of Electronic Engineering and Optoelectronic Technology, Nanjing University of Science and Technology, Nanjing, China; School of Electronic Engineering and Optoelectronic Technology, Nanjing University of Science and Technology, Nanjing, China; School of Electronic Engineering and Optoelectronic Technology, Nanjing University of Science and Technology, Nanjing, China","2020 IEEE 3rd International Conference on Information Systems and Computer Aided Education (ICISCAE)","2 Nov 2020","2020","","","509","513","Due to the problems of poor real-time performance and unstable registration of visual-based augmented reality 3D registration technology, a 3D registration method based on KLT inter-frame tracking and improved ORB feature detection and matching is proposed in this paper. The registration process in our system is directly divided into offline stage and online stage. In the offline stage, the template image is trained with the improved ORB algorithm to generate a subset of feature description. In the online stage, I match firstly the global video frame with the template features, and then optimize the matching results through the RANSAC algorithm, ultimately through the feature matching threshold to determine whether there is a target in the video frames. If there is a target in the scence, the KLT tracking algorithm is used to track the target. By solving the homography matrix between the video frames, the homography matrix relative to the template is obtained at any time. The homography matrix obtained by solving uses the projection imaging theory and the PNP method to complete the calculation of the three-dimensional registration matrix. In addition, for KLT, it is easy to track the drift, and it is analyzed by establishing a threshold, and if the tracking fails, the target is detected again. Experiments show that the three-dimensional registration method proposed in this paper can work normally under the condition of target rotation and partial occlusion. The real-time FPS reaches more than 15fps, and the registration stability is higher than the KCF + ORB three-dimensional registration method.","","978-1-7281-8304-6","10.1109/ICISCAE51034.2020.9236814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9236814","Augmented Reality;3D registration;KLT;ORB;PNP","Target tracking;Three-dimensional displays;Feature detection;Two dimensional displays;Real-time systems;Stability analysis;Augmented reality","augmented reality;feature extraction;image matching;image registration;video signal processing","KLT inter-frame tracking;improved ORB feature detection;real-time performance;unstable registration;visual-based augmented reality 3D registration technology;3D registration method;registration process;offline stage;online stage;template image;improved ORB algorithm;feature description;global video frame;template features;matching results;RANSAC algorithm;video frames;KLT tracking algorithm;homography matrix;PNP method;three-dimensional registration matrix;three-dimensional registration method;registration stability;ORB feature matching","","","","16","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Cinema Station Application (CSA): An augmented reality application for accessing film information and online cinema booking","S. M. Alkhuraiji","Computer Science Department, King Abdulaziz University, Jeddah, Saudi Arabia","2020 8th International Symposium on Digital Forensics and Security (ISDFS)","15 Jun 2020","2020","","","1","6","Cinema is an effective medium for education and recreation, as it plays a crucial social, political, educational, and moral role in life. Reopening cinemas in Saudi Arabia has garnered much attention from cinema operators, moviemakers, and Saudi citizens who are eager to watch movies in cinemas. The main problem that cinemas will face when they reopen will be the overwhelming demand for tickets, as it will be difficult to reserve a ticket on a regular day and almost impossible for movie premieres. This paper describes a Cinema Station Application (CSA), which is a mobile application for cinemas that allows users to search for movies and cinema operators quickly and easily. Users have the opportunity to book a ticket anywhere and anytime. Furthermore, the application uses augmented reality technology to display a movie trailer directly on the poster and view reviews, the overall rating, and the cast.","","978-1-7281-6939-2","10.1109/ISDFS49300.2020.9116419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116419","Augmented reality;cinema;mobile application;ticket reservation","Ethics;Education;Digital forensics;Motion pictures;Mobile applications;Security;Augmented reality","augmented reality;entertainment;mobile computing","augmented reality;online cinema booking;cinema station application;film information;Saudi Arabia;mobile application","","","","14","IEEE","15 Jun 2020","","","IEEE","IEEE Conferences"
"An interactive application based on augmented reality and rules-based reasoning to support educational activities of high school students","A. Pérez-Muñóz; D. Castro-Idrovo; Y. Robles-Bykbaev; V. Robles-Bykbaev; F. Pesántez-Avilés","GI-IATa, Cátedra UNESCO Tecnologías de apoyo para la Inclusión Educativa, Universidad Politécnica Salesiana, Cuenca, Ecuador; GI-IATa, Cátedra UNESCO Tecnologías de apoyo para la Inclusión Educativa, Universidad Politécnica Salesiana, Cuenca, Ecuador; GI-IATa, Cátedra UNESCO Tecnologías de apoyo para la Inclusión Educativa, Universidad Politécnica Salesiana, Cuenca, Ecuador; GI-IATa, Cátedra UNESCO Tecnologías de apoyo para la Inclusión Educativa, Universidad Politécnica Salesiana, Cuenca, Ecuador; GI-IATa, Cátedra UNESCO Tecnologías de apoyo para la Inclusión Educativa, Universidad Politécnica Salesiana, Cuenca, Ecuador","2020 IEEE World Conference on Engineering Education (EDUNINE)","27 Jul 2020","2020","","","1","5","According to the latest estimates of the United Nations Educational, Scientific and Cultural Organization (UNESCO), in 2017, more than 617 million children and adolescents were not achieving minimum proficiency levels regarding reading and mathematics. In this line, it is essential for children and youth developing mainstays for solving problems and adequately understanding the information around them. These mainstays are strongly related to logical and mathematical skills. Therefore, in this paper, we present an educational tool that uses augmented reality to provide interactive exercises for the following areas: functions, areas, volumes, angles, and the Pythagorean theorem. Similarly, our proposal incorporates a decision support system that suggests to a given student what activities and exercises must solve. The validation process of the tools was carried out with the support of 179 volunteers.","","978-1-7281-6638-4","10.1109/EDUNINE48860.2020.9149526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9149526","Augmented reality;Mathematics;Support Decision System;Children and youth","Augmented reality;Mathematics;Tools;Expert systems;Three-dimensional displays;Training","augmented reality;computer aided instruction;decision support systems;mathematics computing","logical skills;mathematical skills;educational tool;interactive exercises;Pythagorean theorem;decision support system;mathematics;minimum proficiency levels;UNESCO;United Nations Educational, Scientific and Cultural Organization;high school students;support educational activities;rules-based reasoning;augmented reality;interactive application","","","","11","IEEE","27 Jul 2020","","","IEEE","IEEE Conferences"
"Effects of Augmented Reality Assisted Learning Materials on Students’ Learning Outcomes","P. -S. Tsai; J. -C. Chen","Teacher Education Center, National Taipei University of Technology, Taipei, Taiwan; Graduate Institute of Technological and Vocational Education, National Taipei University of Technology, Taipei, Taiwan","2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)","4 Aug 2020","2020","","","325","326","This study explored the effects of augmented reality (AR) on students' learning outcomes. The participants of this study were 66 seventh-grade senior high school students from two classes in northern Taiwan. A quasi-experimental design with a control group (problem-based learning; PBL) and an experimental group (PBL with AR) was utilized. The results showed that the students who learned with the PBL and AR-assisted learning materials performed better than those who used the PBL approach in terms of answering questions that required their cognitive abilities of knowledge and comprehension, which are identified as lower cognitive ability.","2161-377X","978-1-7281-6090-0","10.1109/ICALT49669.2020.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155919","problem based learning;augmented reality;Bloom’s taxonomy","Augmented reality;Education;Taxonomy;Computers;Magnetic fields;Conferences;Communications technology","augmented reality;cognition;computer aided instruction;teaching","augmented reality assisted learning materials;seventh-grade senior high school students;quasiexperimental design;AR-assisted learning materials;PBL approach;problem-based learning;cognitive ability","","","","10","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Real-Time Blur Rendering of Moving Objects in an Augmented Reality Environment","Z. Yue; L. J. Jiao; L. Z. Ni; M. Ji","School of Information Science & Engineering, Northeastern University, Shenyang, China; Sch. of Inf. Sci. & Eng., Northeastern University, Shenyang, Liaoning, CN; Sch. of Inf. Sci. & Eng., Northeastern University, Shenyang, Liaoning, CN; School of Information Science & Engineering, Northeastern University, Shenyang, China","2014 Sixth International Conference on Intelligent Human-Machine Systems and Cybernetics","9 Oct 2014","2014","2","","138","141","When moving objects occur a large number of blurred situations, the augmented reality rendering virtual objects can't consistent with motion blur. As the above problem, we proposed a three-dimensional motion blur rendering virtual objects algorithm. First, an image structure model of motion-blurred template matching was used, which was used to track motion blurred objects. Second, we used the same image structure model to generate blur. We produced motion blur for 3D motion by mixing 2D distorted and 3D rendering. Through experimental comparison, our method generated virtual blurred objects realistically. And our rendering speed was faster than without using OpenGL approximation. Therefore, our method was better performance.","","978-1-4799-4955-7","10.1109/IHMSC.2014.136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911467","3d motion blur target;blur rendering;image structure model;augmented reality;intermediate image","Rendering (computer graphics);Augmented reality;Three-dimensional displays;Educational institutions;Target tracking;Cameras","augmented reality;image colour analysis;image matching;image motion analysis;object detection;rendering (computer graphics)","motion blur rendering virtual object algorithm;augmented reality;image structure model;template matching","","","1","8","IEEE","9 Oct 2014","","","IEEE","IEEE Conferences"
"Towards Increase Reading Habit For Preschool Children Through Interactive Augmented Reality Storybook","M. A. Khairul Anuardi; S. Mustapha; M. N. Mohammed","Faculty of Information Science & Engineering, Management and Science University, Malaysia; Faculty of Information Science & Engineering, Management and Science University, Malaysia; Mechanical Engineering Department, College of Engineering, Gulf University, Sanad, Kingdom of Bahrain","2022 IEEE 12th Symposium on Computer Applications & Industrial Electronics (ISCAIE)","13 Jun 2022","2022","","","252","257","The reading habit is crucial in children for developing their cognitive, communication and understanding. Generally, children learn to read and write as early as three years old and can read by their own at the age of eight years old. However, the reading habit in children becoming less attractive to the kids as apart from their lack of interest, the technology has replaced the reading activity in children. Instead of reading, the kids spend more time playing digital game, watch video online or view the updates in social media. In Malaysia particularly, the reading habit in children to read English storybook became an issue. Due to lack of understanding the written story, lack of engagement in reading the story and less motivation to sustain reading the story are among the main factors of it. This research aims to increase the reading habit for preschool children through interactive augmented reality storybook. With the AR technology, the story can be presented in attractive environment and children able to interact with the story. The interaction used in the AR English storybook is slightly different from a normal AR interaction that based on click, touch, drag or slide. It’s required to user to play against the main character in the storybook. The finding shows that children show positive feedback with such approach in reading the English storybook. Substantially, it instills the good reading habit in children.","","978-1-6654-8703-0","10.1109/ISCAIE54458.2022.9794543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794543","Storybook;Augmented Reality;reading habit","Industrial electronics;Social networking (online);Games;Watches;Augmented reality","augmented reality;computer aided instruction;computer games;social networking (online)","interactive augmented reality storybook;reading activity;preschool children;reading habit;social media;AR technology;AR English storybook;digital game","","","","13","IEEE","13 Jun 2022","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality applications to discover new environments","N. Ghouaiel; J. -M. Cieutat; J. -P. Jessel","ESTIA-IRIT, UMR, Bidart, France; ESTIA-IRIT, UMR, Bidart, France; ESTIA-IRIT, UMR, Bidart, France","2013 Science and Information Conference","14 Nov 2013","2013","","","423","427","Although man has become sedentary over time, his wish to travel the world remains as strong as ever. The aim of this paper is to show how techniques based on imagery and Augmented Reality (AR) can prove to be of great help when discovering a new urban environment and observing the evolution of the natural environment. The study's support is naturally the Smartphone which in just a few years has become our most familiar device, which we take with us practically everywhere we go in our daily lives.","","978-0-9893193-0-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6661773","Augmented Reality;Pervasive Computing;Object Recognition","Augmented reality;Mobile communication;Detectors;Feature extraction;Visualization;Pervasive computing;Object recognition","augmented reality;mobile computing;smart phones","mobile augmented reality applications;AR;urban environment discovery;natural environment evolution;smart phone","","","","17","","14 Nov 2013","","","IEEE","IEEE Conferences"
"Augmented Reality-Based Learning Media for Simple Distillation Practical Apparatus","S. R. Vakasari; I. Farida; F. S. Irwansyah","Chemistry Education, UIN Sunan Gunung Djati, Bandung, Indonesia; Chemistry Education, UIN Sunan Gunung Djati, Bandung, Indonesia; Chemistry Education, UIN Sunan Gunung Djati, Bandung, Indonesia","2022 IEEE 8th International Conference on Computing, Engineering and Design (ICCED)","13 Jan 2023","2022","","","1","5","In the simple distillation practicum, some of the equipment used was the equipment that was not always used during practicum. Augmented reality has become one of the technologies that could help in introducing simple distillation equipment. This study aims to describe the display of learning media, analyze the validation test results, and analyze the results of feasibility using the Multimedia Development Life Cycle (MDLC) method. The study results obtained that the display of AR media consisted of the main page, consisting of an information menu containing guide information and profile, logout, and log In. The scan AR page consisted of a camera menu to access the marker and assembling menu for assembling simple distillation equipment and a video of assembling simple distillation equipment The validation results showed an R-count value of around 0.90 and a feasibility test of 94%, which means that the learning media could be stated to be used properly.","2767-7826","978-1-6654-5389-9","10.1109/ICCED56140.2022.10010642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010642","augmented reality;laboratory equipment;learning media;simple distillation","Distance learning;Distillation equipment;Layout;Media;Cameras;Augmented reality","augmented reality;computer aided instruction;distillation;distillation equipment;multimedia computing","AR media;augmented reality;learning media;MDLC method;multimedia development life cycle method;scan AR page;simple distillation equipment;simple distillation practical apparatus;simple distillation practicum;validation test","","","","48","IEEE","13 Jan 2023","","","IEEE","IEEE Conferences"
"Employing augmented reality to create digital artworks to present interactive poem","M. -C. Hsieh; H. -C. K. Lin","Department of Information and Learning Technology, National University of Tainan, Tainan, Taiwan; Department of Information and Learning Technology, National University of Tainan, Tainan, Taiwan","2010 International Computer Symposium (ICS2010)","10 Jan 2011","2010","","","331","337","In this paper, we employ augmented reality to create digital artworks to present interactive poem. This work is established where the digital poem is generated via the interaction between a video film and a text-based poem. We use triangulation evaluation method that includes questionnaires, observation and interviews. The research result proves that the evaluation has positive usability and audiences enjoy the interaction with artworks and audiences accepted this kind of artworks. From the process of evaluation, the audience can interact with AR digital poem and therefore we can receive ideas of them. Moreover, they give the feedback to the future development of the research.","","978-1-4244-7640-4","10.1109/COMPSYM.2010.5685492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685492","Augmented reality;Digital artworks;Interactive poem","Films;Usability;Art;Computers;Image color analysis;Image texture;Augmented reality","art;augmented reality;literature","augmented reality;digital artworks;interactive poem;video film;text based poem;triangulation evaluation method;AR digital poem","","","","11","IEEE","10 Jan 2011","","","IEEE","IEEE Conferences"
"Development and Application of Parts Assembly Guidance System Based on Augmented Reality","L. Xia; J. Lu; Z. Zhang; R. Chen; S. Wang; H. Zhang","CIMS Research Center, Tongji University; CIMS Research Center, Tongji University; CIMS Research Center, Tongji University; CIMS Research Center, Tongji University; CIMS Research Center, Tongji University; CIMS Research Center, Tongji University","2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","13 Feb 2020","2019","","","1325","1330","In the traditional assembly process, it is difficult for operators to quickly understand assembly process information from the instruction manual, which results in inefficient assembly process. Therefore, an assembly guidance system based on augmented reality is about to be proposed in this paper. Also, in view of the problem that geometric models cannot fully express part assembly relationships, this paper proposes to analyze and construct the assembly semantic information model of parts based on the part object model. On the basis of the above semantic information model, the assembly relationship between parts is visually modeled, and these information models are accurately superposed on the real assembly guidance environment by using AR and virtual space modeling technology. Finally, we recursively decompose the parts assembly situation in this paper, and establish the part assembly guidance prototype system to verify the order and accuracy of the part assembly guidance process.","2381-0947","978-1-7281-1907-6","10.1109/IAEAC47372.2019.8997861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8997861","Augmented Reality;Assembly Guidance;Semantic Model;Assembly situation","Solid modeling;Semantics;Object oriented modeling;Augmented reality;Computational modeling;Three-dimensional displays;Cameras","assembly planning;augmented reality;production engineering computing;prototypes;semantic networks","assembly semantic information model;virtual space modeling technology;part assembly guidance prototype system;augmented reality;geometric models;AR modeling technology","","","","16","IEEE","13 Feb 2020","","","IEEE","IEEE Conferences"
"Steering behavior analysis and implementation to simulate crowd tawaf ritual on Augmented Reality Manasik","O. D. E. Wulansari","Computer Science, Lampung University, Bandar Lampung, Indonesia","2010 International Conference on Distributed Frameworks for Multimedia Applications","14 Jul 2011","2010","","","1","7","Steering behavior is behaviors allowed individual elements to navigate their digital environments in a “life-like” manner with strategies for seeking, fleeing, wandering, arriving, pursuing, evading, path following, obstacle avoiding, etc. This technique is widely used in various fields including the field of robotics, artificial intelligence and artificial life, games and animation. In this research technique of steering behavior used to develop macroscopic simulation crowd of tawaf ritual. Some works are done to create crowded simulation more real by modeling, designing, and implementation analysis and test. This was done in order to simulate more realistic crowd tawaf ritual, steering technique to be applied are flocking, following the path, and path-flocking. Implementation is done by performing coding using C ++ programming language, library Opensteer, and the OpenGL. The steering techniques are next evaluated on several pilgrims' general behaviors, i.e. walking to certain direction, collision avoidance, and obstacle avoidance behavior. In the evaluation, the occurrences of unusual behavior in three steering behavior techniques are recorded and then compared. An evaluation involving user has also been done to get a quick feedback. Based on the evaluation results, it can be concluded that steering behavior of the path flocking is a better model for tawaf crowd simulation than the path following or flocking method alone. That simulation implemented on Augmented Reality for Manasik (ARM).","","978-602-97479-1-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5952322","steering behavior;path following;flocking;crowd simulation;Augmented Reality","Solid modeling;Trajectory;Animation;Collision avoidance;Computational modeling;Augmented reality;Analytical models","augmented reality;C++ language;collision avoidance;open systems;software libraries;steering systems","steering behavior analysis;Tawaf ritual simulation;augmented reality;digital environment;macroscopic simulation crowd;path flocking;C++ programming language;library Opensteer;OpenGL;collision avoidance;Manasik","","","","19","","14 Jul 2011","","","IEEE","IEEE Conferences"
"Visualization of Fibroid in Laparoscopy Videos using Ultrasound Image Segmentation and Augmented Reality","D. Kupas; P. Torok; A. Hajdu; B. Harangi","Faculty of Informatics, University of Debrecen, Debrecen, Hungary; Department of Obstetrics and Gynecology, University of Debrecen, Debrecen, Hungary; Faculty of Informatics, University of Debrecen, Debrecen, Hungary; Faculty of Informatics, University of Debrecen, Debrecen, Hungary","2019 11th International Symposium on Image and Signal Processing and Analysis (ISPA)","17 Oct 2019","2019","","","60","63","Though they rarely become malignant, the surgical removal of fibroids (uterine myomas) is commonly considered to prevent any possible future risks. As the least invasive intervention, endoscopic surgery is the most popular approach for this aim. However, since these compact tumors reside in the deep (muscle/connective) tissues of the uterus, they are hardly visible using only the video stream provided by the endoscopic camera. Thus, conform to the current general trend in human surgery, in this paper we propose a multimodal approach to make these tumors more visible during endoscopic interventions, namely, the reconstruction of the whole three-dimensional model of the uterus from ultrasound images and segmentation of the fibroids using this modality. Then, we map the result of the segmentation on the surface of the uterus, hence they become visible during endoscopic surgery. Similar efforts have already been made, considering the usage of MRI for this purpose, but ultrasound image acquisition is more widely available, faster, and cheaper next to the lower image quality. Our aim is to use the output of the 3D ultrasound imaging device during the laparoscopic surgery. Our segmentation pipeline processes the ultrasound images and consists of Otsu's thresholding using a special mask derived from image averages and morphological snakes to extract uterus boundary. As the final step, we project the segmented 3D model of the uterus with its lesion on an endoscope camera flow in real time to provide an augmented reality application.","1849-2266","978-1-7281-3140-5","10.1109/ISPA.2019.8868446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868446","segmentation;uterus;augmented reality;laparoscopy","Image segmentation;Ultrasonic imaging;Augmented reality;Surgery;Signal processing algorithms;Three-dimensional displays;Videos","augmented reality;biological organs;biomedical optical imaging;biomedical ultrasonics;cancer;endoscopes;feature extraction;image reconstruction;image segmentation;medical image processing;muscle;surgery;tumours","laparoscopy videos;ultrasound image segmentation;surgical removal;fibroids;uterine myomas;endoscopic surgery;tumors;deep tissues;video stream;endoscopic camera;human surgery;ultrasound image acquisition;image quality;3D ultrasound imaging device;laparoscopic surgery;uterus boundary;endoscope camera flow;augmented reality;MRI;Otsu's thresholding","","","","12","IEEE","17 Oct 2019","","","IEEE","IEEE Conferences"
"Three-dimensional interactive pen based on Augmented Reality","Wang Jiawei; Yuan Li; Liu Tao; Yao Yuan","Engineering and Technology Training Center, Shanghai University, Shanghai, China; Rapid Manufacturing Engineering Center, Shanghai University, Shanghai, China; Rapid Manufacturing Engineering Center, Shanghai University, Shanghai, China; Rapid Manufacturing Engineering Center, Shanghai University, Shanghai, China","2010 International Conference on Image Analysis and Signal Processing","1 Jun 2010","2010","","","7","11","In order to shorten the learning curve and simplify the complex in current CAD system, one direct approach is to provide a more intuitive way of interaction. This paper proposes an interactive pen tool, which transforms the actions in real space into the virtual three-dimensional CAD system space. Augmented Reality technology is used to track the operator's action in the real world. The design and principle of the interactive tool are introduced in detail. In addition, the experimental system is provided to illustrate a simple process of curves designing and the statistics result of tracking error is also given.","2156-0129","978-1-4244-5556-0","10.1109/IASP.2010.5476172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5476172","Augmented Reality;Interactive Tool","Augmented reality;Space technology;Design automation;Shape control;Graphics;Imaging phantoms;Solid modeling;Layout;Computer aided manufacturing;Process design","augmented reality;CAD;human computer interaction;interactive devices;solid modelling","augmented reality;learning curve;interactive pen;CAD;tracking error;interactive tool","","","","11","IEEE","1 Jun 2010","","","IEEE","IEEE Conferences"
"Optometry training simulation with augmented reality and haptics","L. Wei; S. Nahavandi; H. Weisinger","Centre for Intelligent System Research, Deakin University, Geelong, Australia; Centre for Intelligent System Research, Deakin University, Geelong, Australia; School of Medicine, Deakin University, Geelong, Australia","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","10 Apr 2014","2013","","","976","977","Optometry is an essential health care profession that has existed for many centuries and is still evolving. However, the training approaches for optometrists are not yet on par with the latest technological evolution. The traditional supervisor-student training mode could not provide good immersion and repeatability, while most existing vision-based computer-assisted simulations provide even worse immersion on screens. In this paper, we propose an effective system for optometry training simulation with two major components: augmented reality and haptics. These components are integrated with the actual slit lamp and are able to greatly enhance the immersion for typical optometry training tasks such as foreign body removal. Medical doctors are also involved in suggesting configurations and validating visual and haptic rendering results. Preliminary user studies show very positive feedbacks from optometry students.","","978-1-4503-2240-9","10.1109/ASONAM.2013.6785819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785819","augmented reality;optometry simulation;haptics;foreign body removal","Training;Haptic interfaces;Rendering (computer graphics);Visualization;Computational modeling;Pipelines;Augmented reality","augmented reality;biomedical education;computer based training;computer vision;haptic interfaces;health care;rendering (computer graphics)","optometry training simulation;augmented reality;haptics;health care profession;training approaches;technological evolution;supervisor-student training mode;vision-based computer-assisted simulations;foreign body removal;medical doctors;haptic rendering;visual rendering","","","","9","","10 Apr 2014","","","IEEE","IEEE Conferences"
"Tuklas: Design, Development and Testing of an Augmented Reality Experience for a Children’s Museum","M. M. T. Rodrigo; E. C. E. Vidal; I. Y. D. Herras; J. L. Agapito; W. D. Diy; V. A. Ortega; N. A. Bugayong; A. Ong; J. M. Santos; L. R. T. Lim","Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines; Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Quezon City, Philippines","2019 IEEE International Conference on Engineering, Technology and Education (TALE)","15 Oct 2020","2019","","","1","6","We describe the design, development, and testing of Tuklas, an augmented reality experience for children visiting Museo Pambata (Children's Museum) in Manila, Philippines. Because the target audience was 7 years old and below, the game minimized the use of text. Instead, it adopted an aim-and-click interaction style coupled with a collection mechanic to increase the children's engagement with the museum exhibits. During the post-game interviews with the children's parents or guardians, feedback was highly positive. The interface was easy to use, and the game mechanic was easy to understand. The children enjoyed watching the animations after completing each scene.","2470-6698","978-1-7281-2665-4","10.1109/TALE48000.2019.9225915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225915","augmented reality;human computer interaction;electronic learning;mobile learning","Games;Urban areas;Animation;Testing;Augmented reality;Aging;Tutorials","augmented reality;computer aided instruction;computer games;interactive systems;museums;user interfaces","aim-and-click interaction style;game mechanic;post-game interviews;museum exhibits;target audience;Museo Pambata;Children's Museum;augmented reality experience;Tuklas","","","","13","IEEE","15 Oct 2020","","","IEEE","IEEE Conferences"
"Ability of Solving Augmented Reality Problems with Fuzzy Logic Algorithms","L. P. Kozlova; O. A. Kozlova","Faculty of Industrial Automation and Electrical Engineering, Saint-Petersburg Electrotechnical University “LETI”, Saint Petersburg, Russia; Faculty of Information Systems and Technologies, The Bonch-Bruevich St. Petersburg State University of Communication, Saint Petersburg, Russia","2021 XXIV International Conference on Soft Computing and Measurements (SCM)","16 Aug 2021","2021","","","147","149","Augmented reality has long been part of both the industrial sphere and ordinary life. However, there are still many difficulties associated with the correct operation of this modeling area, the problems of hardware implementation being closely related to the problems of the software part. The implementation of the pattern recognition algorithm plays a huge role here, the solution to the problems of which can be the introduction of fuzzy logic methods.","","978-1-6654-3974-9","10.1109/SCM52931.2021.9507166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507166","augmented reality;pattern recognition;reference base;fuzzy algorithm","Fuzzy logic;Software algorithms;Software;Hardware;Pattern recognition;Augmented reality","augmented reality;fuzzy logic","fuzzy logic algorithms;hardware implementation;software part;pattern recognition algorithm;augmented reality problems","","","","4","IEEE","16 Aug 2021","","","IEEE","IEEE Conferences"
"A Study on Augmented Reality-based Virtual Pets for the Elderly Living Alone","M. -G. Cho","School of Information & Communication, Semyung University, Jeachon, Korea","2021 International Conference on Information and Communication Technology Convergence (ICTC)","7 Dec 2021","2021","","","1280","1283","Due to recent industrialization and nuclear family, the population of the elderly living alone is rapidly increasing. Elderly people living alone are prone to suffering from loneliness and depression, and one way to solve this is known to have a companion animal. However, since raising a companion animal requires a sacrifice of time and money, this paper proposes a method of raising a virtual pet by introducing augmented reality technology with IoT. Additionally, the proposed method improves the quality of life of the elderly living alone by introducing the functions of rehabilitation, mental and physical stability, and living convenience.","2162-1233","978-1-6654-2383-0","10.1109/ICTC52510.2021.9620928","National Research Foundation of Korea(grant numbers:2019R1F1A1056444); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9620928","Augmented Reality;Elderly Friendly Service;AI;Smart-phone;Virtual Pet","Animals;Senior citizens;Sociology;Depression;Information and communication technology;Statistics;Augmented reality","augmented reality;geriatrics;Internet of Things;patient rehabilitation;psychology","elderly people;companion animal;living convenience;augmented reality-based virtual pets;elderly living alone;IoT;quality of life;mental stability;physical stability;rehabilitation function","","","","11","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"Case study: Methodology for the development of learning objects (OA) in 3D for applications of augmented reality (AR)","J. Betzabe Samaniego-Franco; D. I. Jara-Roa; C. P. Sarango-Lapo; M. V. Agila-Palacios; J. E. Guaman-Jaramillo; J. A. Contreras-Mendieta","Universidad Tecnica Particular de Loja, Loja, Loja, EC; Universidad Tecnica Particular de Loja, Loja, Loja, EC; Universidad Tecnica Particular de Loja, Loja, Loja, EC; Universidad Tecnica Particular de Loja, Loja, Loja, EC; Universidad Tecnica Particular de Loja, Loja, Loja, EC; Universidad Tecnica Particular de Loja, Loja, Loja, EC","2018 13th Iberian Conference on Information Systems and Technologies (CISTI)","28 Jun 2018","2018","","","1","7","The present work aims to describe the methodology used for the development of learning objects (LO) in 3D for Augmented Reality (AR) apps, based on a combination of several methodologies used in the design of LO. The methodology consists of three components: 1) app scope, 2) content, and 3) technology. For the development of 3D LO, the prototype software development approach was used, where phases 2 and 3 are executed in each new version accompanied by the respective quality assurance. As a result of the implementation. The “Biologia AR” was gotten. To validate the resulting app from the methodology, a questionnaire, with 14 items, applied to 223 students was used. The results are that 89.30 percent, consider that the app content is in line with the bibliographic material used in the subject and 75.94 percent indicates that the contents of 3D LO used has allowed them to reinforce their learning. The 77.01 percent mention that the interaction with 3D LO is more didactic than with a plain text. Regarding the inconveniences to access the app, 52.47 percent mentioned that it had some type of inconvenience, mainly in download, installation and use, therefore, it is important to know the types of mobile devices in which the applications of AR is going to be used. Hence, it is guaranteed that the methodology allows AR consistent resources to be generated with the learning outcomes, without losing sight of the digital competences that professors and the students must have.","","978-989-98434-8-6","10.23919/CISTI.2018.8399145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8399145","augmented reality;methodology;AR apps","Three-dimensional displays;Software;Augmented reality;Biology;Instruments;Multimedia communication;Prototypes","augmented reality;computer aided instruction;educational aids;mobile computing;solid modelling","learning objects;Augmented Reality apps;prototype software development approach;respective quality assurance;resulting app;app content;learning outcomes;OA;3D LO;Biologia AR;mobile devices;digital competences","","","","","","28 Jun 2018","","","IEEE","IEEE Conferences"
"Real-Time Hand Palm Detection and Tracking Augmented Reality Game Using Lucas Kanade Optical Flow Combined with Color Blob Detection","P. N. Crisnapati; M. Setiawan; I. G. N. Wikranta Arsa; P. Devi Novayanti; M. S. Wibawa; K. G. Oka Ciptahadi","Computer System, STIKOM Bali, Denpasar, Bali; Information System, STIKOM Bali, Denpasar, Bali; Computer System, STIKOM Bali, Denpasar, Bali; Computer System, STIKOM Bali, Denpasar, Bali; Information System, STIKOM Bali, Denpasar, Bali; Information System, STIKOM Bali, Denpasar, Bali","2019 1st International Conference on Cybernetics and Intelligent System (ICORIS)","21 Oct 2019","2019","1","","263","268","Games have become an increasingly widespread part of society because of the spread and use of mobile devices. But playing games for a long time can simulate a negative impact on health such as hemorrhoids caused by sitting within a long period. The body's metabolism will decrease due to lack of activity when playing games. Many games on the market today are usually played in a sitting position and only move a finger. But with the development of technology, games can now be played by moving other limbs. One example is to combine the Augmented Reality, Hand Tracking, and Hand Gesturing technology so that players are required to move their limbs, such as hands, head, and body to play the game. The Hand Tracking algorithm used is the Lucas Kanade Optical Flow algorithm combined with Color Blob Detection, while the Convex Hull algorithm is used to recognize Hand Gesture. The results of this study indicate that by applying the above three algorithms for Hand Tracking and Hand Gesturing in Android games, it has a profound effect on lighting and background color, using background colors that contrast with skin color and adequate lighting, Hand Tracking and hand movements can work well.","","978-1-7281-1474-3","10.1109/ICORIS.2019.8874892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8874892","augmented reality;game;hand tracking;hand gesturing;opencv;lucas kanade;color blob detection","Games;Three-dimensional displays;Optical flow;Color;Weapons;Augmented reality;Blob detection","augmented reality;computer games;gesture recognition;human computer interaction;image colour analysis;image motion analysis;image sequences;mobile computing;object tracking","augmented reality game;playing games;hand tracking algorithm;Lucas Kanade optical flow algorithm;hand gesture;Android games;hand movements;hand gesturing technology;color blob detection;convex hull algorithm","","","","14","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality (MAR) in Distance Learning: Present and Future","R. A. Azawi; M. Al-Obaidy; K. Qaddoum","Higher Colleges of Techonlogy, UAE; Higher Colleges of Techonlogy, UAE; Higher Colleges of Techonlogy, UAE","2020 Seventh International Conference on Information Technology Trends (ITT)","19 Jan 2021","2020","","","140","145","Covid-19 pandemic affects our life suddenly and dramatically. The most affected area was our teaching methods. Students and teachers move to distance learning without good experience and background especially for non-IT teachers.In this paper, we will discuss the opportunity to enhance distance learning and how to make it more effective, easier, and more enjoyable by activating Augmented Reality (AR) in the education field.Recently, AR has been used in various contexts to enhance our experience in mobile and wearable devices. This paper discusses the use of AR in the field of education where it has been observed that learning results have been improved. This type of application required specialized teams of software to create and maintain it and we will explain the benefits and limitations of using AR in distance learning. Using AR in education will provide powerful paradigms for the next generation advanced learning system.","","978-1-7281-8379-4","10.1109/ITT51279.2020.9320889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320889","Teaching strategies;interactive learning environment;e-learning;augmented reality;Virtual Learning Environment and Mobile Learning","Education;Augmented reality;Three-dimensional displays;Software;Computer aided instruction;Hardware;Tools","augmented reality;distance learning;mobile computing;social aspects of automation;teaching","distance learning;covid-19 pandemic;affected area;teaching methods;good experience;mobile augmented reality;education field;learning results;nonIT teachers;AR;next generation advanced learning system","","","","35","IEEE","19 Jan 2021","","","IEEE","IEEE Conferences"
"Work-in-Progress-The Use of Plane-Detection Augmented Reality in Learning Geometry","H. Na","Department of Educational Psychology and Learning Systems, Florida State University, Tallahassee, USA","2021 7th International Conference of the Immersive Learning Research Network (iLRN)","28 Jun 2021","2021","","","1","3","During the last decade, Augmented Reality (AR) has become popular technology in education. From a pedagogical perspective of mathematics education, AR is embodied by virtual manipulatives and matches well with constructivism. To support geometry learning based on constructivist learning theory, this work-in-progress paper aims to shed light on the pedagogical potentials and design principles of using plane-detection AR. Plane-detection AR, the marker-less AR technique, can significantly increase the degree and the scope of learners' interaction. Plane-detection AR can also bring physical objects into geometry learning in a meaningful way. This paper also provides the developed plane-detection AR mobile application as an example. The practical hurdles of using plane-detection AR, and proposed study design for future research to investigate the effects of using plane-detection AR are further discussed.","","978-1-7348995-2-8","10.23919/iLRN52045.2021.9459312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459312","augmented reality;learning geometry;mathematics education;K-12 education","Geometry;Education;Mobile applications;Augmented reality","augmented reality;computer aided instruction;geometry","design principles;geometry learning;plane-detection Augmented Reality;constructivist learning theory;pedagogical potentials;plane-detection AR mobile application","","","","17","","28 Jun 2021","","","IEEE","IEEE Conferences"
"Efficient Estimation of Multiple Illuminant Directions Using C-means Clustering and Self-correction for Augmented Reality","J. Ma; Y. Zhou; Q. Hao; Y. Zhang","School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information Science and Technology, Beijing Institute of Technology, Beijing, China","2009 Eighth IEEE/ACIS International Conference on Computer and Information Science","25 Aug 2009","2009","","","1106","1110","This paper presents a novel method to estimate multiple illuminant directions from a single image in augmented reality system. A square marker is used for 2D-3D registration, and a mirror sphere with known size is employed to detect light sources. Highlight pixels in captured sphere image are analyzed by using c-means clustering algorithm and its initialization with max-min distance method. The initialization estimates number of light sources and initial highlight areas centroids. C-means algorithm optimizes each position of the centroids. With the help of registration, multiple illuminant directions are calculated from the centroids and userpsilas viewpoint. Moreover, a self correction course reduces estimation errors. Experimental results show that our approach is computationally efficient and multiple illuminant directions can be accurately obtained by it.","","978-0-7695-3641-5","10.1109/ICIS.2009.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5223304","c-means clustering;multiple illuminant directions;augmented reality","Augmented reality;Light sources;Layout;Mirrors;Clustering algorithms;Information science;Paper technology;Shape;Lighting;Geometry","augmented reality;minimax techniques;pattern clustering","augmented reality system;c-means clustering algorithm;multiple illuminant direction estimation;square marker;mirror sphere;light sources centroid;initial highlight areas centroid;max-min distance method","","","","13","IEEE","25 Aug 2009","","","IEEE","IEEE Conferences"
"Work-in-Progress—Measuring Learners’ Subjective Experience in Augmented Reality: First Evaluation of the ARcis Questionnaire","J. M. Krüger; D. Bodemer","Media-based Knowledge Construction, University of Duisburg-Essen, Duisburg, Germany; Media-based Knowledge Construction, University of Duisburg-Essen, Duisburg, Germany","2022 8th International Conference of the Immersive Learning Research Network (iLRN)","11 Jul 2022","2022","","","1","3","In order to effectively use augmented reality (AR) for learning support, it is important to take into account learners’ subjective AR-specific learning experience. In this work-in-progress paper, a first version of the ARcis questionnaire intended to measure learners’ perception of contextuality, interactivity, and spatiality in AR-based learning environments is presented. Results of a first implementation of this questionnaire in four studies (total N = 456) with different AR-based learning materials are described. Analyses of reliability and factor structure of the questionnaire show promising first outcomes on which suggestions for adaptations and future validation strategies are made.","","978-1-7348995-3-5","10.23919/iLRN55037.2022.9815900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815900","augmented reality;experience;questionnaire;evaluation","Reliability;Augmented reality","augmented reality;computer aided instruction","factor structure;reliability analysis;learner subjective AR-specific learning experience;learner subjective experience measurement;AR-based learning materials;ARcis questionnaire;augmented reality;work-in-progress","","","","14","","11 Jul 2022","","","IEEE","IEEE Conferences"
"Using Thematic English Learning and Augmented Reality to Enhance Vocabulary Learning Motivation and Enjoyment of Elementary School Students","H. -C. Chuang; V. Gunawan; W. -C. Wu; K. -L. Chuang","Department of Foreign Languages and Literature, Asia University, Taichung City, Taiwan; Department of Foreign Languages and Literature, Asia University, Taichung City, Taiwan; Department of Foreign Languages and Literature, Asia University, Taichung City, Taiwan; Department of Foreign Languages and Literature, Asia University, Taichung City, Taiwan","2022 International Conference on Advanced Learning Technologies (ICALT)","17 Aug 2022","2022","","","256","258","Nowadays, vocabulary learning for second-grade students can be enhanced with appropriate teaching techniques, which can also improve their learning motivation and enjoyment at the same time. The use of Augmented Reality- Assisted Language Learning (ARALL) has been proven to be an innovative way to enhance the learning achievements of lower graders. Therefore, this study aimed to find out whether applying ARALL can improve the ability of lower-grade students in English vocabulary learning while also enhancing their learning motivation and enjoyment. Twenty-three lower-grade students participated in this study, and a mixed research method was adopted for data analysis. The results showed that the students did improve their vocabulary, and they enjoyed this ARALL instruction. Furthermore, through AR thematic English teaching methods, the students could remember the vocabulary rapidly and enhance their own confidence and enjoyment in learning English.","2161-377X","978-1-6654-9519-6","10.1109/ICALT55010.2022.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853844","Augmented Reality-assisted;thematic English learning;lower-grade pupil;learning motivation;learning enjoyment","Vocabulary;Data analysis;Education;Augmented reality","augmented reality;computer aided instruction;data analysis;linguistics;teaching;vocabulary","elementary school students;second-grade students;ARALL;lower-grade students;English vocabulary;English teaching methods;thematic English learning;vocabulary learning motivation;augmented reality-assisted language learning;data analysis","","","","12","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"Monitoring and Controlling Industrial Cyber-Physical Systems with Digital Twin and Augmented Reality","D. da Silva Ribeiro Castro; A. M. A. de Sales; N. J. da Silva Farias; R. L. P. de Medeiros; V. J. da Silva; V. F. de Lucena Junior","Federal University of Amazonas, Manaus, Brazil; Federal University of Amazonas, Manaus, Brazil; Federal University of Amazonas PPGI, PPGEE, CETELI, Manaus, Brazil; Federal University of Amazonas PPGEE CETELI, Manaus, Brazil; Federal University of Amazonas ICET, Itacoatiara, Brazil; Federal University of Amazonas PPGI, PPGEE, CETELI, Manaus, Brazil","2023 IEEE International Conference on Consumer Electronics (ICCE)","17 Feb 2023","2023","","","01","04","This article aims to present the experimental implementation of the integration of digital twin (DT) and augmented reality (AR) technologies, aiming to develop a human-machine interface for remote monitoring of industrial cyber-physical systems. The advantages of integrating these technologies are explored to enhance the monitoring capabilities of an operator through 3D resources in a graphical interface, seeking to achieve more immersion and interactivity. For this, the game development engine Unity 3D was used to develop the interface, and the software Blender 3D was used for modeling and animating the virtual models of the industrial process. Finally, the results and possible advances achieved with the implementation using AR and DT for supervision were analyzed.","2158-4001","978-1-6654-9130-3","10.1109/ICCE56470.2023.10043445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10043445","Digital Twin;Augmented Reality;Industrial Process;Smartphones","Solid modeling;Three-dimensional displays;Process control;Games;Software;Digital twins;Augmented reality","augmented reality;computer animation;control engineering computing;cyber-physical systems;digital twins;graphical user interfaces;process monitoring;production engineering computing","3D resources;AR technology;augmented reality;Blender 3D software;digital twin;graphical interface;human-machine interface;industrial cyber-physical systems;industrial process;interactivity;remote monitoring;Unity 3D game development engine;virtual model animation","","","","15","IEEE","17 Feb 2023","","","IEEE","IEEE Conferences"
"Designing Augmented Reality Book for Improving Practical Skill in Scout Education Course","P. Selfi Cholifah; N. L. Sakinah Nuraini; A. Ferdiansyah","Dept. of Primary Education and Preschool, Universitas Negeri Malang, Malang, Indonesia; Dept. of Primary Education and Preschool, Universitas Negeri Malang, Malang, Indonesia; Dept. of Primary Education and Preschool, Universitas Negeri Malang, Malang, Indonesia","2022 2nd International Conference on Information Technology and Education (ICIT&E)","27 Apr 2022","2022","","","403","407","It is important to look at the element of skill in scout learning. This research aims to produce scout teaching books with the help of augmented reality that can improve students' practical skills in scouting education subjects. This research used ADDIE model development research. This research is aimed at elementary school teacher education students in general who take scouting education courses. Based on the results of the analysis obtained the results of expert validation tests of 90.31 % which belong to the category is very valid. Therefore, related to these results, this book can be used for scouting education learning by improving the practical skills of elementary school teacher education students","","978-1-6654-9433-5","10.1109/ICITE54466.2022.9759857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9759857","augmented reality;textbook;scout education","Analytical models;Technological innovation;Educational courses;Product development;Augmented reality","augmented reality;computer aided instruction;educational courses;teaching","designing augmented reality book;practical skill;scout education course;scout learning;scout teaching books;education subjects;ADDIE model development research;elementary school teacher education students;education courses;expert validation tests;education learning","","","","22","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Identifying patients and visualize their vitality data through augmented reality","T. Kiebel; A. Dietrich; M. Schulze; S. Zug; J. Kaiser","Department for Distributed Systems, Otto von Guericke University Magdeburg, Magdeburg, Germany; Department for Distributed Systems, Otto von Guericke University Magdeburg, Magdeburg, Germany; Department for Distributed Systems, Otto von Guericke University Magdeburg, Magdeburg, Germany; Department for Distributed Systems, Otto von Guericke University Magdeburg, Magdeburg, Germany; Department for Distributed Systems, Otto von Guericke University Magdeburg, Magdeburg, Germany","The 7th IEEE International Conference on Mobile Ad-hoc and Sensor Systems (IEEE MASS 2010)","10 Dec 2010","2010","","","757","758","Hospitals aim at an extensive continuous monitoring of patients. This enables the personal to check the conditions of a patient anywhere at any given time and allows them to immediately react to anomalies and emergencies. The same technology can be used to instantaneously visualize available patient data using augmented reality techniques.","2155-6814","978-1-4244-7490-5","10.1109/MASS.2010.5663824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663824","augmented reality;patient monitoring;sensor networks;situation awareness;visualization","Wireless sensor networks;Data visualization;Monitoring;Medical services;Augmented reality;Temperature sensors;Biomedical monitoring","augmented reality;data visualisation;hospitals;medical administrative data processing;patient monitoring;telemedicine","patient identification;vitality data visualization;augmented reality;hospital;continuous patient monitoring","","","","7","IEEE","10 Dec 2010","","","IEEE","IEEE Conferences"
"OpenSURF Algorithm Improvement for Augmented Reality Based on the Natural Features","J. Yang; F. -W. Zhu; Z. -P. Yuan; S. -H. Zhang; X. -D. He","School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China","2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics","20 Sep 2012","2012","1","","62","65","In the field of computer vision, image matching is very important in many applications, such as the object recognition, 3D reconstruction, stereo vision, motion tracking and augmented reality. A method of improving the Opensurf algorithm used in AR for decreasing matching points and mismatch and increasing the calculation speed is proposed.","","978-1-4673-1902-7","10.1109/IHMSC.2012.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6305625","Augmented Reality;Opensurf;RANSAC;k-d trees","Feature extraction;Augmented reality;Computer vision;Kernel;Vectors;Cameras;Educational institutions","augmented reality;computer vision;image matching","OpenSURF algorithm improvement;augmented reality;natural features;computer vision;image matching;object recognition;3D reconstruction;stereo vision;motion tracking;AR;calculation speed","","","","10","IEEE","20 Sep 2012","","","IEEE","IEEE Conferences"
"Pedagogy of mobile augmented reality in health education","",,"2014 International Conference on Interactive Mobile Communication Technologies and Learning (IMCL2014)","19 Jan 2015","2014","","","209","212","Augmented reality has the potential to provide powerful, contextual, and situated learning experiences for medical students. There are need learning theories to guide the design of AR in health education to bring out the potentials. The objectives of this paper is to present the learning theories which could be supported AR in health education. We propose use situation learning, experiential learning; transformative learning as the learning theory basis of mobile AR. We also suggested the possible learning activities on different environment to guide design mobile AR.","","978-1-4799-4742-3","10.1109/IMCTL.2014.7011133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7011133","mobile augmented reality;health education;situation learning;experiential learning;transformative learning","Education;Mobile communication;Augmented reality;Context;Medical services;Internet;Conferences","augmented reality;biomedical education;medical computing;mobile learning","mobile augmented reality pedagogy;health education;medical students;learning theories;situation learning;experiential learning;transformative learning;mobile AR","","","","24","IEEE","19 Jan 2015","","","IEEE","IEEE Conferences"
"The use of Augmented Reality to promote learning in Science Laboratories","F. F. Moro; M. Paula Corrêa Angeloni; L. M. Rockenbach Tarouco; J. Bosco da Mota Alves","Programa de Pós-Graduação em Informática na Educação, Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Programa de Pós-Graduação em Informática na Educação, Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Programa de Pós-Graduação em Informática na Educação, Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Programa de Pós-Graduação em Tecnologias da Informação e Comunicação, Federal University of Santa Catarina, Araranguá, Brazil","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","1021","1025","This paper presents a research on the use of Augmented Reality (AR) in Science teaching laboratories, aiming to verify features and functionalities that promote the interaction and participation of students in line with learning theories while supporting experiential learning. From this research, a prototype of a virtual laboratory involving the use of AR was developed, and a strategy was built for applying it in learning activities about the planet Earth in elementary school.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9798929","science laboratory;augmented reality;experiential learning","Earth;Scientific computing;Laboratories;Education;Prototypes;Augmented reality;Computational intelligence","augmented reality;computer aided instruction;teaching","virtual laboratory;Augmented Reality;Science laboratories;Science teaching laboratories;learning theories;experiential learning","","","","17","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"Augmented reality via temporal psycho-visual modulation","Xiaoyong Lu; Bin You; P. -Y. Lin","School of Software Engineering, Nanchang University, Nanchang, Jiangxi, China; School of Software Engineering, Nanchang University, Nanchang, Jiangxi, China; Department of Information Communication, Yuan Ze University, Chung-Li, Taiwan","2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","26 Sep 2016","2016","","","1","4","Nowadays, augmented reality (AR) has entered our lives. An AR tag is usually used and stacked on the products for sake of being detected and recognized easily. With the recognized pattern, AR system thereby can superimpose the corresponding virtual object on the AR tag. The AR tag, however, distort the perception of products. In this study, we proposed a method that the AR tag could be embedded on a digital screen by applying the technique of temporal psycho visual modulation (TPVM). The new method utilizes the differences between the human-eye perception and digital camera image-forming to stack an invisible AR tag on digital screen and projector. The AR tag can be detected by digital devices but not yet by human eyes. Based on this concept of AR and TPVM, the related applications would be achieved, such as the immersive virtual scene created in entertainment, commercial and entertainment.","","978-1-5090-1552-8","10.1109/ICMEW.2016.7574703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574703","Augmented reality;temporal psycho visual modulation;perception;mobile device","Augmented reality;Modulation;Digital cameras;Mobile handsets;Three-dimensional displays;Media","augmented reality;image processing;screens (display);visual perception","augmented reality;temporal psycho-visual modulation;pattern recognition;virtual object;AR tag;digital screen;human eye perception;digital camera image forming method;immersive virtual scene","","","","14","IEEE","26 Sep 2016","","","IEEE","IEEE Conferences"
"Guido: Augmented Reality for Indoor Navigation Using Commodity Hardware","Z. T. Çankırı; E. E. Maraşlı; S. Aktürk; S. Sonlu; U. Güdükbay","Department of Computer Engineering, Bilkent University, Ankara, Turkey; Department of Computer Engineering, Bilkent University, Ankara, Turkey; Department of Computer Engineering, Bilkent University, Ankara, Turkey; Department of Computer Engineering, Bilkent University, Ankara, Turkey; Department of Computer Engineering, Bilkent University, Ankara, Turkey","2020 24th International Conference Information Visualisation (IV)","11 Mar 2021","2020","","","708","713","Indoor positioning is one of the difficult problems in current navigation systems. There is an increasing demand for detecting the locations of objects and humans inside closed environments in various fields including surveillance, robotics, and entertainment. Recent works focus on indoor navigation systems using different technologies including Wireless Local Area Network (WLAN), Radio Frequency Identification (RFID), Inertial Measurement Unit (IMU), and Simultaneous Localization and Mapping (SLAM). Research reveals using these technologies alone is inefficient in terms of accuracy and cost. To address this issue, we propose a marker-based Augmented Reality (AR) indoor navigation system with integrated SLAM and IMU. We use Unity's AR Foundation Framework for highly accurate results with minimum hardware requirements.","2375-0138","978-1-7281-9134-8","10.1109/IV51561.2020.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373121","Augmented Reality;Simultaneous Localization and Mapping;Inertial Measurement Unit;Indoor Navigation","Wireless LAN;Simultaneous localization and mapping;Measurement units;Indoor navigation;Hardware;Augmented reality;Radiofrequency identification","augmented reality;indoor navigation;mobile robots;navigation;radiofrequency identification;SLAM (robots);wireless LAN","commodity hardware;indoor positioning;current navigation systems;closed environments;fields including surveillance;indoor navigation systems;Wireless Local Area Network;IMU;marker-based Augmented Reality indoor navigation system;minimum hardware requirements;guido","","","","24","IEEE","11 Mar 2021","","","IEEE","IEEE Conferences"
"Augmented Reality as a Didactic Tool for Development Spatial Intelligence","L. Haz; E. Vargas; Y. Molineros; J. I. Aviles","Universidad de Guayaquil, Guayaquil, Guayas, EC; Universidad de Guayaquil, Guayaquil, Guayas, EC; Universidad de Guayaquil, Guayaquil, Guayas, EC; Universidad de Guayaquil, Guayaquil, Guayas, EC","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","5","Augmented Reality (AR)complements perception and interaction with a semi-real world and allows the user to observe a virtual environment enhanced with additional information assisted by a computer. The use of this technology has been introduced in multiple areas especially in education for spatial intelligence development and students' learning improvement. This paper describes the development of a single didactic material representing Ecuador's historical content through an application of AR in order to improve teaching and learning processes. It shows historical facts on virtual models by superimposing 2D and 3D dynamic graphics which were generated in real time; and description of recognition marks design were utilized to create AR. Thus, it also presents level of acceptance and perception on students using this technology. Students' academic performance was analyzed before and after the didactic material was utilized in the classroom and results were recorded.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760688","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760688","Augmented Reality;Didactic material;Space Intelligence;Teaching - Learning","Education;Visualization;Three-dimensional displays;Image color analysis;Social sciences;Augmented reality;Tools","augmented reality;computer aided instruction;history;teaching","didactic tool;virtual environment;teaching;historical facts;virtual models;3D dynamic graphics;augmented reality;spatial intelligence;Ecuador historical content;2D dynamic graphics","","","","25","","15 Jul 2019","","","IEEE","IEEE Conferences"
"Enhancing Traditional Games with Augmented Reality Technologies","H. Sakuma; T. Yamabe; T. Nakajima","Department of Computer Science and Engineering, Waseda University, Japan; Department of Computer Science and Engineering, Waseda University, Japan; Department of Computer Science and Engineering, Waseda University, Japan","2012 9th International Conference on Ubiquitous Intelligence and Computing and 9th International Conference on Autonomic and Trusted Computing","18 Oct 2012","2012","","","822","825","Digital technologies are useful to enhance existing traditional games to increase their pleasure. In many games, digital technologies can add special effects to excite a player emotionally. However, the technologies are also useful to help a player to learn complex rules in the games. Especially, traditional games like a poker are not easy to learn for beginners so many recent young people lose interests to play the games. In this paper, we present AR-Hold'em that is an enhanced Texas Hold'em poker game with augmented reality technologies. We also present some user studies showing the effectiveness of our approach.","","978-1-4673-3084-8","10.1109/UIC-ATC.2012.95","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6332090","Augmented Reality;Card Games","Games;Footwear;Augmented reality;Interviews;Materials;RFID tags","augmented reality;computer games","augmented reality;digital technology;AR-Hold'em;Texas Hold'em poker game","","","","7","IEEE","18 Oct 2012","","","IEEE","IEEE Conferences"
"Influence of Augmented Reality for the learning of Geometric Solids in Primary School students","J. Buitrón-Luna; M. Cabanillas-Carbonell","Facultad de Ingeniería y Arquitectura, Universidad Autónoma del Perú, Lima, Perú; Facultad de Ingeniería, Universidad Privada del Norte, Lima, Perú","2021 IEEE Engineering International Research Conference (EIRCON)","30 Nov 2021","2021","","","1","4","Currently, technological advances have had relevance in different factors of daily life, however, in many educational centers it has not been used for the benefit of education. The objective of this research was to influence the learning process of Geometric Solids through the use of a mobile application. The development of the application was proposed under the Mobile-D methodology and the name “ARmetry” was proposed. The experimental design of the quasi-experimental type was also chosen, where the population to be studied was 140 students and the sample was two sections of the morning shift, 70 students for the sample in total. Finally, it is concluded that using a mobile application with Augmented Reality positively influences the learning process in Geometric Solids.","","978-1-6654-4445-3","10.1109/EIRCON52903.2021.9613353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613353","Augmented Reality;education;Mobile Application;Mobile-D Methodology;Geometric Solids","Conferences;Sociology;Education;Solids;Mobile applications;Statistics;Augmented reality","augmented reality;computer aided instruction;educational institutions;mobile computing","Augmented Reality;Geometric Solids;primary school students;technological advances;educational centers;learning process;mobile application;Mobile-D methodology;experimental design;quasiexperimental type","","","","10","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Examination of Book Reading Experience Supported by Augmented Reality Technology with EEG","Y. Daşdemır; M. Bayat; A. Kartal; B. Coşkun","Bilgisayar Mühendisliği, Erzurum Teknik Üniversitesi, Erzurum, Türkiye; Bilgisayar Mühendisliği, Erzurum Teknik Üniversitesi, Erzurum, Türkiye; Bilgisayar Mühendisliği, Erzurum Teknik Üniversitesi, Erzurum, Türkiye; Bilgisayar Mühendisliği, Erzurum Teknik Üniversitesi, Erzurum, Türkiye","2021 Innovations in Intelligent Systems and Applications Conference (ASYU)","18 Nov 2021","2021","","","1","5","Augmented Reality (AR) has the potential to enrich traditional books with virtual objects. However, little is known about how the unique possibilities of this immersive technology can affect reading habits and cognitive reading awareness. This study investigates the possibilities of AR, which is one of the immersive environments of students' reading habits, with the support of Electroencephalography (EEG). 14 university students read 10 different texts from a physical book and virtual objects placed in an immersive environment, and examined the object on the screen using affine transformations. The results show that AR-assisted reading significantly engages the participant and demonstrates higher classification performance than reading from a physical book. It has been observed that the designed AR application also meets the usability characteristics.","","978-1-6654-3405-8","10.1109/ASYU52992.2021.9599082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599082","Reading;augmented reality;electroencephalography;EEG;Vuforia","Electroencephalography;Augmented reality;Support vector machines;Usability;Reactive power;Radio frequency;Wavelet transforms","augmented reality;cognition;computer aided instruction;educational institutions;electroencephalography;electronic publishing;human computer interaction;medical signal processing","book reading experience;augmented reality technology;virtual objects;reading habits;cognitive reading awareness;immersive environment;university students;physical book;AR-assisted reading;EEG;AR application","","","","","IEEE","18 Nov 2021","","","IEEE","IEEE Conferences"
"Animal metamorphosis learning media using android Based augmented reality technology","A. Purwanto; M. P. Kurniawan; A. Z. Rahman","Information Technology, Amikom University of Yogyakarta, Yogyakarta, Indonesia; Information System, Amikom University of Yogyakarta, Yogyakarta, Indonesia; Informatics, Amikom University of Yogyakarta, Yogyakarta, Indonesia","2019 4th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE)","2 Apr 2020","2019","","","79","84","Making learning method applying IT technology of choice for the learning process more interesting that combines augmented reality technology based on Android with educational book that discusses the process of metamorphosis. Aiming to create an atmosphere of teaching and learning to be more interactive, interesting, and the delivery of content clearer. Due to the 3D feature (three-dimensional) objects relating to the material, sound narration to clarify the material presented, and videos that explain more clearly of a process that is raised from the material and can be viewed live significantly through this technology. Learning media is running with a purpose, namely to Indonesia a better education. Maximize new learning method that is more effective than the application of learning methods previously applied. Creating a bond in the learning process between teachers and students and also between parent and child is more harmonious.","","978-1-7281-5118-2","10.1109/ICITISEE48480.2019.9003765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003765","Augmented reality;metamorphosis;3D feature","Three-dimensional displays;Augmented reality;Media;Animation;Animals;Education;Testing","augmented reality;computer aided instruction;computer animation;teaching","animal metamorphosis learning media;learning process;educational book;teaching;Android based augmented reality technology","","","","8","IEEE","2 Apr 2020","","","IEEE","IEEE Conferences"
"Projector-Screen Matching Image Generation Technology for Spatial Augmented Reality","C. Huang; D. Weng; Y. Li; H. Zhou","Department of Optoelectronic Engineering, Beijing Institute of Technology, Beijing, China; Department of Optoelectronic Engineering, Beijing Institute of Technology, Beijing, China; Department of Optoelectronic Engineering, Beijing Institute of Technology, Beijing, China; Department of Optoelectronic Engineering, Beijing Institute of Technology, Beijing, China","2013 International Conference on Computer-Aided Design and Computer Graphics","15 May 2014","2013","","","435","436","The technology used to distort any projected image to fit the uneven-shaped physical screens perfectly is a key issue to the application of Spatial Augmented Reality. We proposed an image generation technique based on Structured Light, which can generate the image of physical screen at the projector angle. Through the image, we thus get the accurate matching information between the projected image and the physical screen. It can be used as the initial image for people to debug remotely and conveniently on the worksite. This paper also confirmed the high stability and accuracy of the technology on different physical screens with different materials.","","978-1-4799-2576-6","10.1109/CADGraphics.2013.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815048","Spatial Augmented Reality;matching image;manual adjustment;projected image","Solid modeling;Augmented reality;Three-dimensional displays;Manuals;Cameras;Image generation;Materials","augmented reality;image matching","projector-screen matching image;matching image generation technology;spatial augmented reality;projected image distortion;structured light;uneven-shaped physical screens;projector angle;matching information","","","","5","IEEE","15 May 2014","","","IEEE","IEEE Conferences"
"Work-In-Progress—A Mobile Augmented Reality Application for Learning about Trademark Registration in Intellectual Property Education","J. Bacca-Acosta; J. -P. Lis-Gutierrez; C. Avila-Garzon; M. Sandoval-Escobar; J. Cardenas-Criollo","Dept. of Mathematics and Engineering, Fundación Universitaria Konrad Lorenz, Bogotá, Colombia; Business School, Fundación Universitaria Konrad Lorenz, Bogotá, Colombia; Dept. of Mathematics and Engineering, Fundación Universitaria Konrad Lorenz, Bogotá, Colombia; Dept.of Psychology, Fundación Universitaria Konrad Lorenz, Bogotá, Colombia; Dept. of Mathematics and Engineering, Fundación Universitaria Konrad Lorenz, Bogotá, Colombia","2022 8th International Conference of the Immersive Learning Research Network (iLRN)","11 Jul 2022","2022","","","1","4","Intellectual Property (IP) education plays a key role for support and creativity in society. However, research on IP education has not paid attention to the potential that AR could bring to this field. This work-in-progress paper presents an augmented reality mobile application developed in Unity for learning trademark registration as part of the first phase of a research project studying the uses of AR in intellectual property education. This paper describes the design of the application and some screenshots of the final developed version, the research method, instruments to evaluate the application, and preliminary findings. The main contribution of this paper is a use case of AR in the field of intellectual property education, an example of designing an app for this topic and some insights into the benefits of AR in the field of intellectual property education.","","978-1-7348995-3-5","10.23919/iLRN55037.2022.9815982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815982","Intellectual property;trademark registration;augmented reality;mobile learning;educational affordances","Instruments;Affordances;Education;Intellectual property;Trademarks;Mobile applications;Augmented reality","augmented reality;computer aided instruction;mobile computing;trademarks","mobile augmented reality application;trademark registration;intellectual property education;IP education","","","","25","","11 Jul 2022","","","IEEE","IEEE Conferences"
"Cloud-Based Augmented Reality As a Disruptive Technology for Higher Education","A. M. Mohamad; S. Kamaruddin; Z. Hamin; W. R. Wan Rosli; M. Faizal Omar; N. N. Mohd Saufi","School of Law and Centre for Testing, Measurement and Appraisal (CeTMA), Universiti Utara Malaysia, Kedah, Malaysia; Faculty of Management & Economics, Universiti Pendidikan Sultan Idris, Perak, Malaysia; Faculty of Law, University Teknologi MARA, Selangor, Malaysia; Faculty of Management, Law & Social Science, University of Bradford, United Kingdom; School of Quantitative Sciences and Centre for Testing, Measurement and Appraisal (CeTMA), Universiti Utara Malaysia, Kedah, Malaysia; Faculty of Business Management & Professional Studies, Management & Science University, Selangor, Malaysia","2023 International Conference on Disruptive Technologies (ICDT)","19 Jun 2023","2023","","","269","273","Augmented reality (AR) within the context of higher education is an approach to engage students with experiential learning by utilising AR technology. This paper discusses the process undertaken by a teacher in higher education in designing and implementing cloud-based AR lesson for the students. The methodology engaged was case study at one institution of higher learning in Malaysia. The AR teaching process involves six stages, beginning with the selection of the course, followed by selection of the topic, designing of the AR teaching plan and the implementation of the AR lesson. Upon completion of the implementation of the AR lesson, the teacher and students would provide reflection of their experiences. The process concludes by the improvement of the AR teaching plan by the teacher. The study found that cloud based has indeed disrupted higher education in terms of providing richer learning experiences to the students, as well as enhanced teaching practices for the teachers. Hopefully, this paper would provide insights into the practices of AR teaching and learning approach for teachers in general, and within the context of higher education in particular. It is also intended that the six-steps process outlined in this paper becomes a reference and be duplicated by teachers at large who might be interested to design and implement AR lessons for their own courses.","","979-8-3503-2388-7","10.1109/ICDT57929.2023.10150499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150499","Augmented Reality;Cloud Computing;Disruptive Technology;Emerging Technology;Higher Education","Education;Reflection;Disruptive technologies;Augmented reality","augmented reality;cloud computing;computer aided instruction;educational courses;educational institutions;further education;teaching","AR teaching plan;AR teaching process;cloud-based AR lesson;cloud-based augmented reality;course selection;disruptive technology;higher education;higher learning institution","","","","26","IEEE","19 Jun 2023","","","IEEE","IEEE Conferences"
"Using Augmented Reality Technology in Learning Archeological Places","R. Porncharoen; S. Ratchataruj; S. Wichiranon","Department of Electronics and Communication Engineering, Rajamagala University of Technology Phra Nakhon, Bangkok, Thailand; Department of Technical Education, Rajamagala University of Technology Phra Nakhon, Bangkok, Thailand; Department of General Education, Rajamagala University of Technology Phra Nakhon, Bangkok, Thailand","2021 6th International STEM Education Conference (iSTEM-Ed)","8 Dec 2021","2021","","","1","4","The purpose of this research is to use augmented reality (AR) technology in learning archeological places of 9 places including Wat Thewarat Kunchorn, Wat Sukhantharam, Wat Benchamabophit Dusitwanaram, Wat Mai Thong Sen, Wat Ratchaphatikaram, Morphon House Palace, Suan Sunandha Palace, Parusakawan Palace, and Wat Bot Samsen. Each place can see the history of the content through VDO and 3-D models that can be viewed 360 degrees. They presented it through the learn archeological places guidebook. The sample groups of the research were 30 students of bachelor's degree in industrial education program, Rajamangala University of Technology Phra Nakhon. The research results showed that the learn archeological places guidebook was at a high level (the mean equaled to 4.36) and the students' satisfaction with the learn archeological places guidebook was at a high level (the mean equaled to 4.13).","","978-1-6654-3600-7","10.1109/iSTEM-Ed52129.2021.9625107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9625107","Augmented Reality;Archeological Places;AR Based;Vuforia Unity","Solid modeling;Three-dimensional displays;Public relations;Education;Mobile handsets;History;Augmented reality","augmented reality;computer aided instruction;data loggers;educational courses;educational institutions;further education;solid modelling","Wat Mai Thong Sen;Wat Ratchaphatikaram;Morphon House Palace;Suan Sunandha Palace;Parusakawan Palace;Wat Bot Samsen;augmented reality;Wat Thewarat Kunchorn;Wat Sukhantharam;Wat Benchamabophit Dusitwanaram;University of Technology Phra Nakhon;archeological places guidebook learning;VDO;3D models","","","","11","IEEE","8 Dec 2021","","","IEEE","IEEE Conferences"
"Implementation of The Introduction of Skin Diseases Based on Augmented Reality","M. A. Iqbal; A. Saleh; H. A. Darwito","Department of Telecommunication Engineering, Politeknik Elektronika Negeri Surabaya, Surabaya, Indonesia; Department of Telecommunication Engineering, Politeknik Elektronika Negeri Surabaya, Surabaya, Indonesia; Department of Telecommunication Engineering, Politeknik Elektronika Negeri Surabaya, Surabaya, Indonesia","2020 International Electronics Symposium (IES)","20 Oct 2020","2020","","","406","410","Indonesia is a tropical country that has high rainfall. Environmental conditions greatly affect health conditions in humans such as skin health examples. Many people are still confused to identify the skin disease they are suffering from. This has a negative impact on people's lives. In this research, an application is made that is useful for introducing and informing various types of skin diseases with the Convolutional Neural Network (CNN) algorithm and implementation for information in introducing this skin disease using augmented reality (AR). This application is created using the Java programming language and is implemented on smartphones with the Android operating system.From the test results obtained, the classification results obtained when detecting skin diseases get conditions in accordance with or the same as the trained data. At a light intensity of 355 lux, the highest accuracy was obtained for measles skin disease. For the detection of skin diseases using different distances, the optimal distance to get a high accuracy value is the distance of 8 cm.","","978-1-7281-9530-8","10.1109/IES50839.2020.9231615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231615","Convolutional Neural Network;Classification;Augmented Reality;ARCore;Sceneform","Skin;Diseases;Three-dimensional displays;Testing;Solid modeling;Smart phones;Augmented reality","augmented reality;convolutional neural nets;diseases;image classification;Java;medical image processing;skin;smart phones","augmented reality;skin health examples;detecting skin diseases;measles skin disease;environmental conditions;health conditions;convolutional neural network;CNN;Java programming language;smartphones;Android operating system","","","","4","IEEE","20 Oct 2020","","","IEEE","IEEE Conferences"
"Decomposition of contact force using contact pressure for haptic augmented reality","H. Kim; S. Choi; W. K. Chung","Department of Mechanical Engineering, POSTECH, Pohang, Korea; Department of Computer Science and Engineering, POSTECH, Pohang, Korea; Department of Mechanical Engineering, POSTECH, Pohang, Korea","2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","17 Dec 2015","2015","","","194","196","In this paper, we present a decomposition method of contact force between a haptic interface and an object for haptic augmented reality. The proposed method uses contact pressure distribution as well as force measurement. Thanks to the contact pressure distribution, the proposed method can find the right normal direction regardless of large shear deformation. The simulation result validated the performance of the proposed method.","","978-1-4673-7971-7","10.1109/URAI.2015.7358866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358866","Haptic;augmented reality;tactile sensing","Force;Haptic interfaces;Friction;Augmented reality;Force measurement;Geometry;Robot sensing systems","augmented reality;haptic interfaces","contact force decomposition;haptic augmented reality;haptic interface;contact pressure distribution;force measurement;shear deformation","","","","5","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Prototype UX Design: Mobile Augmented Reality Application based on Gamification for Cultural Heritage Tourism","S. E. Hiererra; Meyliana; A. Ramadhan; F. Purnomo","Computer Science Department, BINUS Graduate Program - Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program - Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program - Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program - Computer Science, Bina Nusantara University, Jakarta, Indonesia","2022 8th International HCI and UX Conference in Indonesia (CHIuXiD)","13 Jan 2023","2022","1","","30","35","This study aims to identify the processes of UX designing a mobile application, Augmented Reality based on Gamification for Cultural Heritage Tourism, and to provide the prototype design and the testing result; this research employs the Design Thinking Method to design the prototype and uses the System Usability Scale (SUS) to identify and validate the testing result; the author establishes two research questions for this study, then explains the answers through a clear description of the stages of making a prototype which consists of the empathize, define, ideate, prototype, and testing stages, then to find out the testing results, the author uses the SUS method, scoring 88.5 in the excellent and acceptable categories; the originality of the research, this study provides the Design Thinking method to investigate the process of UX designing and the SUS Score method to calculate the resting result, helps build a complete understanding of developing the prototype and validation through testing comprehensively.","","978-1-6654-7664-5","10.1109/CHIuXiD57244.2022.10009802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009802","UX design;augmented reality;gamification;cultural heritage;tourism","Human computer interaction;Prototypes;Mobile applications;Cultural differences;Usability;Interviews;Augmented reality","augmented reality;history;mobile computing;travel industry","Cultural Heritage Tourism;Design Thinking Method;Design Thinking method;Gamification;mobile application;mobile Augmented Reality application;prototype design;prototype UX Design;resting result;SUS method;SUS Score method;System Usability Scale;testing result;testing stages;UX designing","","","","34","IEEE","13 Jan 2023","","","IEEE","IEEE Conferences"
"eTourism applying geolocation technology, virtual tours and augmented reality mobile","C. I. Rodríguez","Escuela de Ingeniería en Computación ITCA-FEPADE, La Libertad, El Salvador","2015 IEEE Thirty Fifth Central American and Panama Convention (CONCAPAN XXXV)","10 Mar 2016","2015","","","1","6","This paper focuses on the knowledge of the different tools to develop software based on mobile technologies that incorporate the use of geographic information systems capable of generating interactive maps that allow for the location of tourist sites, virtual tours places located on maps and incorporating augmented reality technology to enhance the information provided to visitors who attend these places, and also highlight the importance of these tools for the tourism industry and development in the region.","","978-1-4673-7872-7","10.1109/CONCAPAN.2015.7428453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7428453","Phones;geolocation;interactive maps;virtual tours;augmented reality;geographic information;virtual tour;virtual museums;mobile technologies;types of tourism;tourism and computer technology applied to tourism;APP for tourism","Geology;Videos;Augmented reality;Mobile communication;Visualization;Global Positioning System;Cultural differences","augmented reality;geographic information systems;mobile computing;travel industry","etourism;geolocation technology;virtual tours;geographic information systems;mobile technologies;augmented reality technology;tourism industry","","","","","IEEE","10 Mar 2016","","","IEEE","IEEE Conferences"
"Real-time color correction for a photo-based augmented reality system","M. Ohta; T. Sato; M. Motokurumada; K. Yamashita","Graduate School of Engineering, Osaka Prefecture University; Graduate School of Engineering, Osaka Prefecture University; Graduate School of Engineering, Osaka Prefecture University; Graduate School of Engineering, Osaka Prefecture University","2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE)","14 Nov 2013","2013","","","102","103","This report proposes methods for correcting the color tone of photographic images in a photo-based augmented reality (AR) system in real time to suit the user's environment. Photo-based AR systems achieve AR by selecting a specific photographic image, which was shot in advance, to suit user's camera position and “pasting” it onto the camera view. Unlike conventional systems, this system does not require a 3D model, so no model rendering, which reduces the rendering load, is necessary. The approach should be effective in terminals with small battery capacities such as smartphones. However, this system becomes problematic if the photograph of the object selected does not fit well with the background lighting conditions when the photograph was shot, because the AR may vary. Thus, the proposed method facilitates more natural AR by correcting the color tone of the photographic image.","2378-8143","978-1-4799-0892-9","10.1109/GCCE.2013.6664761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6664761","augmented reality;photo-based AR;color correction;multiple regression analysis","Image color analysis;Cameras;Rendering (computer graphics);Real-time systems;Augmented reality;Three-dimensional displays;Load modeling","augmented reality;cameras;image colour analysis;photography","background lighting conditions;battery capacities;camera view pasting;user camera position;photographic image;photo-based AR systems;user environment;color tone;photo-based augmented reality system;real-time color correction","","","","3","IEEE","14 Nov 2013","","","IEEE","IEEE Conferences"
"Creating Virtual Reality and Augmented Reality Development in Classroom: Is it a Hype?","V. T. Nguyen; K. Jung; T. Dang","Dept. of Computer Science, Texas Tech University, Texas, United States; Dept. of Edu. Psychology & Leadership, Texas Tech University, Texas, United States; Dept. of Computer Science, Texas Tech University, Texas, United States","2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","212","2125","The fast-growing number of high-performance computer processor and hand-held devices have paved the way for the development of Virtual Reality and Augmented Reality in terms of hardware and software in the education sector. The question of whether students can adopt these new technologies is not fully addressed. Answering this question thus plays an essential role for instructors and course designers. The objectives of this study are: (1) to investigate the feasibility of the Virtual Reality/Augmented Reality development for undergraduate students, and (2) to highlight some practical challenges when creating and sharing Virtual Reality and Augmented Reality applications from student's perspective. Study design for the coursework was given with detail. During a 16-week long, 63 Virtual Reality/Augmented Reality applications were created from a variety of topics and various development tools. 43 survey questions are prepared and administered to students for each phase of the projects to address technical difficulties. The exploration method was used for data analysis.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942272","virtual reality, augmented reality, user study, technology adoption","Water pollution;Tools;Education;Augmented reality;Hardware;Software","augmented reality;computer aided instruction;educational courses;further education","high-performance computer processor;hand-held devices;virtual reality;augmented reality;education sector;undergraduate students;coursework","","5","","15","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"Using Olfactory Stimuli in Virtual Reality Applications","J. Mendes Miranda Martins; M. de Paiva Guimarães","Departamento de Ciência da Computação, Centro Universitário Campo Limpo Paulista (Unifaccamp), Campo Limpo Paulista, SP, Brasil; Universidade Federal de São Paulo (Unifesp-UAB)/Programa de Pós-Graduação do Centro Universitário Campo Limpo Paulista(Unifaccamp), São Paulo, Brasil","2018 20th Symposium on Virtual and Augmented Reality (SVR)","19 Aug 2019","2018","","","57","64","Sight and hearing senses are commonly used in virtual reality applications to provide users immersion. However, it is possible to enhance immersion exploring the other human senses. This paper aims to present a hardware and software solution to build virtual reality applications using olfactory stimulus. We build a display olfactory device and a library to develop the applications. It is also presented a case study.","","978-1-7281-0604-5","10.1109/SVR.2018.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802380","Olfactory;Virtual Reality;Augmented Reality;display olfactive","Visualization;Hardware;Software;Olfactory;Surface acoustic waves;Augmented reality","chemioception;virtual reality","virtual reality applications;human senses;olfactory stimuli;hearing sense;hardware solution;software solution;olfactory device;sight sense","","3","","0","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"Collaborative augmented sketching","H. Seichter","Department of Architecture, University of Hong Kong, Hong Kong, China","2003 IEEE International Augmented Reality Toolkit Workshop","9 Aug 2004","2003","","","42","43","The aim of this paper is to demonstrate a software prototype using AR Toolkit (Billinghurst and Kato, 1999) for collaborative augmented reality sketching in architectural design. The author introduces a non-intrusive interaction technique developed for this prototype. Additionally, sketching and distribution mechanisms are discussed and illustrated. The prototype uses non-photo-realistic rendering and an adaptive tessellation mechanism in the geometry kernel to provide a visual cue for the conceptual stage of an architectural design.","0953-5683","0-7803-8240-4","10.1109/ART.2003.1320425","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320425","","Collaboration;Proposals;Spline;Surface topography;Surface reconstruction;Geometry;Kernel;Augmented reality;Shape;Software tools","groupware;computational geometry;augmented reality;rendering (computer graphics);architectural CAD","collaborative work;collaborative augmented sketching;software prototype;augmented reality toolkit;architectural design;rendering;adaptive tessellation;geometry kernel","","","","4","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"A mixed reality system with visual and tangible interaction capability: application to evaluating automobile interior design","T. Ohshima; T. Kuroki; H. Yamamoto; H. Tamura","MR Systems Laboratory, Canon, Inc., Tokyo, Japan; MR Systems Laboratory, Canon, Inc., Tokyo, Japan; MR Systems Laboratory, Canon, Inc., Tokyo, Japan; MR Systems Laboratory, Canon, Inc., Tokyo, Japan","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","284","285","This paper presents a mixed reality (MR) system with tangible interface as well as visual fusion in an MR space. The sense of touch is given by physical objects on which computer generated imagery is accurately registered and superimposed. The proposed approach is especially useful in industrial design where digital mockups and physical mockups are thoroughly utilized.","","0-7695-2006-5","10.1109/ISMAR.2003.1240722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240722","","Virtual reality;Automobiles;Image generation;Augmented reality;Haptic interfaces;Character generation;Shape;Feedback;Laboratories;Physics computing","augmented reality;haptic interfaces;image registration;automobile industry;computer graphics","mixed reality;visual interaction;tangible interaction;automobile interior design;interior design evaluation;MR system;tangible interface;visual fusion;MR space;computer generated imagery;industrial design;digital mockups;physical mockups;user interface;haptic interface;object registration","","9","5","1","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"Cooperatively Resolving Occlusion between Real and Virtual in Multiple Video Sequences","X. Jin; X. Chen; B. Zhou; H. Lin","The State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; The State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; The State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; The State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China","2011 Sixth Annual Chinagrid Conference","20 Oct 2011","2011","","","234","240","The occlusion between real and virtual objects influences not only seamless merging of virtual and real environments but also users' visual perception of orientations & locations and spatial interactions in augmented reality. If there exist a large amount of video sequences for representing the real environment, and each video sequence utilizes computer vision algorithms to deal with all of occlusions between real and virtual, this often drops down the real-time performance of augmented reality system. This article proposed an approach of cooperatively resolving the occlusion between real and virtual based on multiple video sequences in augmented reality scene. Firstly it analyzes the occlusion relations between virtual and real objects in initial video sequences with their intrinsic parameters and poses, and obtains the spatial relations among video sequences through 3D registration information. Secondly, for each video sequence, it divides and codes the perception regions of relative augmented reality scene. Lastly, according to the spatial relations of video sequences, the known occlusion relations in initial video sequences and the code data of perception regions, three types of occlusion relations including real occluding virtual, virtual occluding real and non-occlusion are detected out and represented in augmented reality scene. Some experimental results show that this approach can reduce redundant calculations on the way of resolving the occlusion between real and virtual objects, and improve the performance of generating augmented reality scene, especially which includes plenty of video sequences and occlusion relations of virtual occluding real or non-occlusion.","1949-1328","978-1-4577-0885-5","10.1109/ChinaGrid.2011.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051758","component;Virtual Reality;Augmented Reality;Video Sequence;Occlusion;Region Code","Video sequences;Augmented reality;Cameras;Three dimensional displays;Estimation;Encoding","augmented reality;computer graphics;image registration;image sequences;video signal processing","occlusion;multiple video sequences;visual perception;augmented reality system;computer vision algorithms;3D registration information","","","","13","IEEE","20 Oct 2011","","","IEEE","IEEE Conferences"
"The Duran Duran project: the augmented reality toolkit in live performance","J. Pair; J. Wilson; J. Chastine; M. Gandy","Institute for Creative Technologies, University of Southern California, USA; Eioniedical Interactive Technology Center, Georgia Institute of Technology, USA; Clayton State University, USA; Interactive Media Technology Center, Georgia Institute of Technology, USA","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","2 pp.","","A variety of real time visual effects were developed for the band Duran Duran's December 2000 ""Pop Trash"", live concert tour. The ARtoolkit was utilized extensively to prototype and demonstrate many of these effect sequences.","","0-7803-7680-3","10.1109/ART.2002.1107010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1107010","","Augmented reality;Animation;Lighting control;Graphics;Visual effects;Prototypes;Real time systems;Cameras;Multimedia communication;Broadcasting","augmented reality;music","Duran Duran project;augmented reality toolkit;live performance;ARtoolkit;augmented reality","","4","","4","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality in Mechanical Engineering Education","G. Ivanova; A. Ivanov; L. Zdravkov","Department of Computing, University of Ruse, Ruse, Bulgaria; Department of Machine tools and manufacturing, University of Ruse, Ruse, Bulgaria; Department of Computing, University of Ruse, Ruse, Bulgaria","2023 46th MIPRO ICT and Electronics Convention (MIPRO)","29 Jun 2023","2023","","","1612","1617","Nowadays innovative technologies are entering the educational process with the aim of learners easily understanding and learning the material provided. The technologies used and/or based on virtual and augmented reality in the educational process affects today’s digital generation and motivation of learners, giving them the opportunity to use their smartphones in the learning process. The aim of the paper is to show the main positive aspects of 3D Virtual Reality environments and 3D Augmented Reality Learning environments in mechanical engineering education. An interactive Mobile Apps for 3D Augmented Reality Learning environment and 3D Virtual Reality Learning environment for setting up and operating a variety of Grinding Devices for Cutting tool sharpening are presented. The Mobile Apps are using Mobile Virtual Glasses suitable for smartphones. The use of 3D Virtual learning and 3D Augmented learning reality in the training of Cutting Tools has been tested with students from the Faculty of Mechanical and Manufacturing Engineering of the University of Ruse. With the Mechanical engineering students, comparative research was conducted to determine the effectiveness of the learning and students’ experience level in a 3D Augmented and Virtual Reality Learning environment versus that of a real learning laboratory.","2623-8764","978-953-233-104-2","10.23919/MIPRO57284.2023.10159965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10159965","virtual reality;augmented reality;3D educational process;3D laboratory;3D virtual reality;3D augmented reality","Training;Cutting tools;Visualization;Solid modeling;Three-dimensional displays;Operating systems;Virtual reality","augmented reality;computer aided instruction;cutting tools;educational institutions;engineering education;grinding;mechanical engineering;mobile computing;smart phones;virtual reality","3D Augmented learning reality;3D Virtual learning;3D Virtual Reality environments;3D Virtual Reality Learning environment;augmented reality;digital generation;educational process;interactive Mobile Apps;learning laboratory;learning process;mechanical engineering education;Mechanical engineering students;Mobile Virtual Glasses suitable;nowadays innovative technologies","","","","9","","29 Jun 2023","","","IEEE","IEEE Conferences"
"Design and Evaluation of an Augmented Reality App for Learning Spatial Transformations and their Mathematical Representations","Z. Shaghaghian; H. Burte; D. Song; W. Yan","Texas A&M University, College Station, United States; Texas A&M University, College Station, United States; Texas A&M University, College Station, United States; Texas A&M University, College Station, United States","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","608","609","There is a close relation between spatial thinking and mathematical problem-solving. This paper presents a newly developed educational Augmented Reality (AR) mobile application, BRICKxAR/T, to help students intuitively learn spatial transformations and the related mathematics through play. A pilot study with 7 undergraduate students evaluates students learning gain through a mental rotation and a math test on transformation matrices. The results show most students performed better with a higher score after learning with the app. Students found the app interesting to play and useful for learning geometric transformations and matrices.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00155","National Science Foundation(grant numbers:2119549); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757688","Applied computing;Education;Interactive learning Environments","Three-dimensional displays;Conferences;User interfaces;Mathematics;Mobile applications;Problem-solving;Augmented reality","augmented reality;computer aided instruction;computer science education;educational courses;learning (artificial intelligence);mathematics computing","7 undergraduate students;transformation matrices;geometric transformations;Augmented Reality app;spatial transformations;mathematical representations;spatial thinking;mathematical problem-solving;newly developed educational Augmented Reality mobile application;related mathematics","","1","","7","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"A Participatory Design in Developing Prototype an Augmented Reality Book for Deaf Students","N. M. M. Zainuddin; H. B. Zaman; A. Ahmad","Department of Information Science, Universiti Kebangsaan Malaysia, Bangi, Selangor Darul Ehsan, Malaysia; Department of Information Science, Universiti Kebangsaan Malaysia, Bangi, Selangor Darul Ehsan, Malaysia; Department of Information Science, Universiti Kebangsaan Malaysia, Bangi, Selangor Darul Ehsan, Malaysia","2010 Second International Conference on Computer Research and Development","21 Jun 2010","2010","","","400","404","One of Augmented Reality applications is known as Augmented Reality Book. Due to this, particular AR-Book is based on visually oriented technique and deaf students are generally classified as visual learners. The aim of this paper is to identify the criteria in developing an AR-Book for the deaf students. The AR-Book for deaf students is not the same as normal students because it has to include the sign language. In this ongoing study, qualitative approaches such as participatory design philosophy were used in designing and developing an AR-Book for deaf students. Three deaf students and three teachers who taught the deaf students were involved in this study. Two main findings showed that the sign language marker should be avoided and meanwhile, for the 3D model marker, it can work with the 2D picture or text. Therefore, it is more suitable to use sign language symbols in the AR-Book.","","978-0-7695-4043-6","10.1109/ICCRD.2010.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5489589","Augemted reality;deaf;special education","Prototypes;Augmented reality;Books;Deafness;Virtual reality;Information science;Handicapped aids;Augmented virtuality;Job design;Research and development","augmented reality;computer aided instruction;handicapped aids;human computer interaction","augmented reality book;deaf students;visually oriented technique;visual learners;3D model marker;sign language symbols","","16","","33","IEEE","21 Jun 2010","","","IEEE","IEEE Conferences"
"Image-Based Modelling for Augmenting Reality","A. van den Hengel","The University of Adelaide, Adelaide, SA, AU","2010 International Symposium on Ubiquitous Virtual Reality","26 Aug 2010","2010","","","1","4","The interaction between real and synthetic geometry is fundamental to Augmented Reality. Portraying such interactions in a manner that is convincing to the user requires 3D models of the shape of the real objects involved. The large-scale application of Augmented Reality technologies will thus require practical methods for generating 3D models of real objects. These methods will need to be fast, flexible, and capable of operating in-situ in order to generate models in unforeseen environments. Image-based modelling offers a means of creating such models by direct analysis of an image set. This paper describes two approaches to image-based modelling for Augmented Reality, and argues that technologies of this type are critical to the future of the domain.","","978-1-4244-7702-9","10.1109/ISUVR.2010.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557945","component;formatting;style;styling","Solid modeling;Cameras;Three dimensional displays;Shape;Simultaneous localization and mapping;Augmented reality;Visualization","augmented reality;image processing;solid modelling","image-based modelling;synthetic geometry;augmented reality;3D model generation","","1","1","12","IEEE","26 Aug 2010","","","IEEE","IEEE Conferences"
"Magnifying Augmented Mirrors for Accurate Alignment Tasks","V. Kern; C. Kleinbeck; K. Yu; A. Martin-Gomez; A. Winkler; N. Navab; D. Roth",Friedrich-Alexander-Universitat Erlangen-Nürnberg; Friedrich-Alexander-Universitat Erlangen-Nürnberg; TU Munich; Johns Hopkins University; LM U Hospital TU Munich; TU Munich Johns Hopkins University; Friedrich-Alexander-Universitat Erlangen-Nürnberg,"2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","685","686","Limited mobility in augmented reality applications restricts spatial understanding along with augmentation placement and visibility. Systems can counteract by providing perspectives by tracking and augmenting mirrors without requiring user movement. However, the decreased visual size of mirrored objects reduces accuracy for precision tasks. We propose Magnifying Augmented Mirrors: digitally zoomed mirror images mapped back onto their surface, producing magnified reflections. In a user study $(N=14)$ conducted in virtual reality, we evaluated our method on a precision alignment task. Al-though participants needed time for acclimatization, they achieved the most accurate results using a magnified mirror.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108734","Human-centered computing;Human computer in-teraction (HCI);Interaction paradigms Mixed / augmented reality;Visualization;Augmented reality;Virtual reality","Visualization;Three-dimensional displays;Tracking;Conferences;User interfaces;Reflection;Mirrors","augmented reality;mirrors;virtual reality","accurate alignment tasks;augmentation placement;augmented reality applications;augmenting mirrors;magnified mirror;magnified reflections;Magnifying Augmented Mirrors;mirror images;mirrored objects;precision alignment task;precision tasks;visibility","","","","4","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"[POSTER] Affording Visual Feedback for Natural Hand Interaction in AR to Assess Upper Extremity Motor Dysfunction","M. A. Cidota; R. M. S. Clifford; P. Dezentje; S. G. Lukosch; P. J. M. Bank","Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Leiden University Medical Center, The Netherlands","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","92","95","For the clinical community, there is great need for objective, quantitative and valid measures of the factors contributing to motor dysfunction. Currently, there are no standard protocols to assess motor dysfunction in various patient groups, where each medical discipline uses subjectively scored clinical tests, qualitative video analysis, or marker-based motion capturing. We investigate the potential of Augmented Reality (AR) combined with serious gaming and marker-less tracking of the hand to facilitate efficient, cost-effective and patient-friendly methods for evaluation of upper extremity motor dysfunction in different patient groups. First, the design process of the game and the system architecture of the AR framework are described. To provide unhindered assessment of motor dysfunction, patients should operate with the system in a natural way and be able to understand their actions in the virtual AR world. To test this in our system, we conducted a usability study with five healthy people (aged between 57-63) on three different modalities of visual feedback for natural hand interaction with AR objects. These modalities are: no augmented hand, partial augmented hand (tip of index finger and tip of thumb) and a full augmented hand model. The results of the study show that a virtual representation of the fingertips or hand improves the usability of natural hand interaction.","","978-1-4673-7660-0","10.1109/ISMAR.2015.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328069","Augmented Reality;Optical See-Through HMD;Natural Hand Interaction;Serious Gaming;Upper Extremity Motor Dysfunction;Assessment","Games;Thumb;Tracking;Cameras;Augmented reality;Usability","augmented reality;diseases;human computer interaction;serious games (computing)","visual feedback;natural hand interaction;motor dysfunction;qualitative video analysis;marker-based motion capturing;augmented reality;serious gaming;marker-less tracking;patient-friendly method;cost-effective method;system architecture;virtual AR world;virtual representation","","4","","16","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"KinardCar: Auxiliary Game in Formation of Young Drivers, Utilizing Kinect and Arduino Integration","F. A. Vaz; J. L. de Souza Silva; R. Sol Dos Santos","Centro de Informática-CIn, Universidade Federal de Pernambuco, Recife, Brasil; Dept. de Eng. Eletr., Inst. Fed. da Bahia, Brazil; Dept. de Eng. Eletr., Inst. Fed. da Bahia, Brazil","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","139","142","Applications of Virtual and Augmented Reality with a focus in the welfare of society are becoming recurrent and there are many advantages on doing this. An important concern is the good formation of citizens for life in society, especially when such improvement can help mitigate accidents, and consequently save lives. Therefore, the aim of this article is to describe the development of a system to support training of young drivers to make the learning of the traffic rules more friendly and exciting. To achieve this, we developed a game called Kinard Car, where we use the Microsoft Kinect sensor integrated with an Arduino micro controller. The environment consists of a small remotely operated vehicle by the user's movements, which are tracked by the sensor. In the vehicle, there is a marker attached which identifies the position and orientation of the car in the virtual test track, and thus there is an interaction between multiple virtual vehicles and the real one. Considering these results, we can conclude that the game goes beyond its educational nature, as this also provides a new perspective on life in society.","","978-1-4799-4261-9","10.1109/SVR.2014.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913086","Augmented Reality;Game;Traffic;Kinect;Arduino","Vehicles;Games;Tracking;Augmented reality;Training;Educational institutions;Microcontrollers","augmented reality;automobiles;computer based training;computer games;image sensors;microcontrollers;remotely operated vehicles;traffic engineering computing","auxiliary game;young driver formation;Arduino integration;virtual reality;augmented reality;societal welfare;traffic rules;KinardCar;Microsoft Kinect sensor;Arduino microcontroller;remotely operated vehicle;user movements;car position;car orientation;virtual test track;multiple virtual vehicles;educational nature","","1","","20","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"Encountered haptic Augmented Reality interface for remote examination","E. Ruffaldi; A. Filippeschi; F. Brizzi; J. M. Jacinto; C. A. Avizzano","Scuola Superiore Sant'Anna, Pisa, Italy; Scuola Superiore Sant'Anna, Pisa, Italy; Scuola Superiore Sant'Anna, Pisa, Italy; Scuola Superiore Sant'Anna, Pisa, Italy; Scuola Superiore Sant'Anna, Pisa, Italy","2015 IEEE Symposium on 3D User Interfaces (3DUI)","25 Jun 2015","2015","","","179","180","This paper presents an interaction system for haptic based remote palpation and in general remote examination. In particular the proposed approach combines 3D representation of the remote environment with encountered haptic feedback aiming at high transparency and natureleness of interaction. The paradigm is described as interaction design and system implementation.","","978-1-4673-6886-5","10.1109/3DUI.2015.7131759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131759","","Haptic interfaces;Medical services;Three-dimensional displays;Robots;Solid modeling;Augmented reality;Visualization","augmented reality;feedback;haptic interfaces;telemedicine","haptic augmented reality interface;interaction system;haptic based remote palpation examination;3D representation;haptic feedback;interaction natureleness;interaction transparency","","7","1","10","IEEE","25 Jun 2015","","","IEEE","IEEE Conferences"
"Resolving multiple occluded layers in augmented reality","M. A. Livingston; J. E. Swan; J. L. Gabbard; T. H. Hollerer; D. Hix; S. J. Julier; Y. Baillot; D. Brown","Virtual Reality Laboratory, Naval Research Laboratory, Inc., Washington D.C., DC, USA; Virtual Reality Laboratory, Naval Research Laboratory, Inc., Washington D.C., DC, USA; Naval Research Laboratory, Inc., USA; Department of Computer Science, University of California, Santa Barbara, USA; Naval Research Laboratory, Inc., Washington D.C., DC, USA; ITT Advanced Engineering and Sciences, Naval Research Laboratory, Inc., Washington D.C., DC, USA; ITT Advanced Engineering and Sciences, Naval Research Laboratory, Inc., Washington D.C., DC, USA; Virtual Reality Laboratory, Naval Research Laboratory, Inc., USA","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","56","65","A useful function of augmented reality (AR) systems is their ability to visualize occluded infrastructure directly in a user's view of the environment. This is especially important for our application context, which utilizes mobile AR for navigation and other operations in an urban environment. A key problem in the AR field is how to best depict occluded objects in such a way that the viewer can correctly infer the depth relationships between different physical and virtual objects. Showing a single occluded object with no depth context presents an ambiguous picture to the user. But showing all occluded objects in the environments leads to the ""Superman's X-ray vision"" problem, in which the user sees too much information to make sense of the depth relationships of objects. Our efforts differ qualitatively from previous work in AR occlusion, because our application domain involves far-field occluded objects, which are tens of meters distant from the user. Previous work has focused on near-field occluded objects, which are within or just beyond arm's reach, and which use different perceptual cues. We designed and evaluated a number of sets of display attributes. We then conducted a user study to determine which representations best express occlusion relationships among far-field objects. We identify a drawing style and opacity settings that enable the user to accurately interpret three layers of occluded objects, even in the absence of perspective constraints.","","0-7695-2006-5","10.1109/ISMAR.2003.1240688","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240688","","Augmented reality;Visualization;Laboratories;Displays;Navigation;Context awareness;Human factors;Switches;Virtual reality;Computer science","hidden feature removal;augmented reality;data visualisation;computer displays;object detection","multiple occluded layers;augmented reality;AR systems;occluded infrastructure;mobile AR;navigation;occluded objects;virtual objects;AR occlusion;drawing style;opacity settings;perspective constraints;visualization","","68","3","26","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"3D referencing techniques for physical objects in shared augmented reality","O. Oda; S. Feiner","Department of Computer Science, Columbia University; Department of Computer Science, Columbia University","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","207","215","We introduce an augmented reality referencing technique for shared environments that is designed to improve the accuracy with which one user can point out a real physical object to another user. Our technique, GARDEN (Gesturing in an Augmented Reality Depth-mapped ENvironment), is intended for use in otherwise unmodeled environments in which objects in the environment, and the hand of the user performing a selection, are interactively observed by a depth camera, and users wear tracked see-through displays. We present the results of a user study that compares GARDEN against existing augmented reality referencing techniques, as well as the use of a physical laser pointer. GARDEN performed significantly more accurately than all the comparison techniques when the participating users have sufficiently different views of the scene, and significantly more accurately than one of these techniques when the participating users have similar perspectives.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402558","Collaborative mixed/augmented reality;referencing technique","Cameras;Laser theory;Streaming media;Augmented reality;Accuracy;Animation","augmented reality;display devices","3D referencing techniques;physical objects;shared augmented reality;augmented reality referencing technique;shared environments;GARDEN;gesturing in an augmented reality depth-mapped environment;unmodeled environments;depth camera;wear tracked see-through displays;physical laser pointer","","20","1","30","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Body Weight Perception of Females using Photorealistic Avatars in Virtual and Augmented Reality","E. Wolf; N. Döllinger; D. Mal; C. Wienrich; M. Botsch; M. E. Latoschik","HCI Group, University of Würzburg; HTS Group, University of Würzburg; HCI Group, University of Würzburg; HTS Group, University of Würzburg; Computer Graphics Group, TU Dortmund University; HCI Group, University of Würzburg","2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","462","473","The appearance of avatars can potentially alter changes in their users’ perception and behavior. Based on this finding, approaches to support the therapy of body perception disturbances in eating or body weight disorders by mixed reality (MR) systems gain in importance. However, the methodological heterogeneity of previous research has made it difficult to assess the suitability of different MR systems for therapeutic use in these areas. The effects of MR system properties and related psychometric factors on body-related perceptions have so far remained unclear. We developed an interactive virtual mirror embodiment application to investigate the differences between an augmented reality see-through head-mounted-display (HMD) and a virtual reality HMD on the before-mentioned factors. Additionally, we considered the influence of the participant’s body-mass-index (BMI) and the BMI difference between participants and their avatars on the estimations. The 54 normal-weight female participants significantly underestimated the weight of their photorealistic, generic avatar in both conditions. Body weight estimations were significantly predicted by the participants’ BMI and the BMI difference. We also observed partially significant differences in presence and tendencies for differences in virtual body ownership between the systems. Our results offer new insights into the relationships of body weight perception in different MR environments and provide new perspectives for the development of therapeutic applications.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00071","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284711","Mixed reality;immersion;presence;embodiment;virtual body ownership;agency;body image;eating disorders;Human-centered computing;Human computer interaction (HCI);Empirical studies in HCI;Human-centered computing;Human computer interaction (HCI);Mixed / augmented reality;Human-centered computing;Human computer interaction (HCI);Virtual reality","Avatars;Medical treatment;Estimation;Resists;Mirrors;Indexes;Augmented reality","augmented reality;avatars;biomechanics;human computer interaction;medical computing;psychometric testing","mixed reality systems;augmented reality;body weight perception;photorealistic avatars;body perception disturbances;eating disorders;MR system properties;body-related perceptions;interactive virtual mirror embodiment application;virtual reality HMD;BMI difference;generic avatar;body weight estimations;virtual body ownership;normal-weight female participants;human-centered computing;human computer interaction","","14","","72","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Light Detecting 3D User Interface-Equipped System for Mixed and Augmented Reality Games","J. Park; S. An; W. Woo","KAIST UVR Lab., S. Korea; Graduate School of Culture Technology, KAIST, S. Korea; KAIST UVR Lab., S. Korea","2015 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design","10 Dec 2015","2015","","","55","56","This paper suggests a novel and interactive system for three dimensional games in mixed and augmented reality (MAR). The proposed system allows a user to interact with 3D virtual objects with accuracy by locating a source of light using simple light detecting algorithms. From our pilot study, our tangible system proved to be highly usable and beneficial for 3D MAR gameplay with inexpensive accompanying equipment. Here, we provide implementation details, present results from a pilot study, and outline future directions.","","978-1-4673-9628-8","10.1109/ISMAR-MASHD.2015.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350738","","Games;Augmented reality;User interfaces;Three-dimensional displays;Cameras;Light sources;Usability","computer games;human computer interaction;light sources;virtual reality","light detecting 3D user interface-equipped system;interactive system;three dimensional games;mixed and augmented reality games;3D virtual objects;light source;light detecting algorithms;tangible system;3D MAR gameplay","","","","5","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"NUX Characters - interaction with voice assistants in Virtual Reality","K. Buchta; P. Wójcik; K. Nakonieczny; J. Janicka; M. Igras-Cybulska","1000 realities studio Krakow, Poland; 1000 realities studio Krakow, Poland; 1000 realities studio Krakow, Poland; 1000 realities studio Krakow, Poland; 1000 realities studio, AGH University of Science and Technology, Institute of Electronics, Krakow, Poland","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","917","918","NUX Characters is a Virtual Reality environment designed for testing different voice assistants. We prepared five environments covering various styles and personas of the assistants: a virtual human, a virtual animal, a cartoon-like character, a non-humanoid robot and a humanoid robot. The common feature of the environments is the mechanics of the user's task - to collect the items hidden in the location while the assistant helps in this quest by giving verbal hints. The environment can be used for the investigation of user experience, impressions and preferences towards virtual assistants as well as the traits attributed to them, which can be applied to optimize design decisions for the VR environments supporting voice user interface.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974522","Human-centered computing-Visualization-Visualization techniques-Voice interaction;Human-centered computing-Visualization-Voice assistant","Animals;Virtual assistants;Humanoid robots;User interfaces;Task analysis;Augmented reality;Testing","humanoid robots;user interfaces;virtual reality","assistant;cartoon-like character;design decisions;different voice assistants;humanoid robot;nonhumanoid robot;NUX Characters - interaction;personas;user experience;virtual animal;virtual assistants;virtual human;Virtual Reality environment;voice user interface;VR environments","","","","11","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Sensitivity of image based Augmented Reality fitting simulation","S. Hah; J. Park; J. -d. Kim","Department Visual Communication design, Hong-ik University, Seoul, South Korea; Department Computer Science, Hong-ik University, Seoul, South Korea; Department Film & Communication design, Hong-ik University, Seoul, South Korea","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","107","108","Augmented Reality services, by providing virtual images, create specific reality that is different from reality. In spite of technological innovation, AR based fitting services are not getting popularity because of this specific reality created by unnatural and awkward virtual garment images. AR based fitting services do not satisfy customers' needs. This paper introduced new design techniques that may satisfy users' perception and enhance shopping experience. Our techniques were focused on the emotional and sensitive perception of the users rather than enhancing quality of the virtual images.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093667","AR Fitting;Simulation;Sensitivity Image;Experience;Reality","Fitting;Sensitivity;Clothing;Painting;Shape;Visualization;Solid modeling","augmented reality;clothing;customer satisfaction;digital simulation","image sensitivity;augmented reality fitting simulation;AR based fitting services;virtual garment images;user perception satisfaction;shopping experience enhancement","","3","","3","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"The effect of out-of-focus blur on visual discomfort when using stereo displays","T. Blum; M. Wieczorek; A. Aichert; R. Tibrewal; N. Navab","Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany; Computer Aided Medical Procedures & Augmented Reality (CAMP), Technische Universität München, Munich, Germany","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","13","17","Visual discomfort is a major problem for head-mounted displays and other stereo displays. One effect that is known to reduce visual comfort is double vision, which can occur due to high disparities. Previous studies suggest that adding artificial out-of-focus blur increases the fusional limits, where the left and right image can be fused without double vision. We investigate the effect of adding artificial out-of-focus blur on visual discomfort using two different setups. One uses a stereo monitor and an eye tracker to change the depth of focus based on the gaze of the user. The other one uses a video-see through head mounted display. A study involving 18 subjects showed that the viewing comfort when using blur is significantly higher in both setups for virtual scenes. However we can not confirm without doubt that the higher viewing comfort is only related to an increase of the fusional limits, as many subjects reported that double vision did not occur during the experiment. Results for additional photographed images that have been shown to the subjects were less significant. A first prototype of an AR system extracting a depth map from stereo images and adding artificial out-of-focus blur is presented.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643544","","Cameras;Visualization;Monitoring;Stereo vision;Pixel;Augmented reality;Three dimensional displays","helmet mounted displays;stereo image processing;virtual reality","out-of-focus blur;visual discomfort;stereo displays;head mounted displays;double vision;stereo monitor;eye tracker;virtual scenes;depth map","","20","11","21","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Toward Methods To Develop Experience Measurements For Mixed Reality","T. Q. Tran",University of Otago,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","266","269","In recent years, Mixed Reality (MR) has become more popular with more affordable devices and the introduction of new applications. These applications and devices create MR experiences which can be completely different from the experience in the real world. Different approaches have been developed to measure those expe-riences. Besides behaviour observations or incorporating devices to measure physiological signals, using questionnaires is the most popular practice. However, the usage of questionnaires which were developed not based on any rational theory or well-defined model can lead to potential issues. In this paper, we present methods to design measurement models which can be used to develop instru-ments to measure experiences in MR. In addition, an illustration of developing a model for the sense of presence in MR is introduced.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974211","General and reference-Measurement;Human-centered computing-Virtual reality;Human-centered computing-Mixed / augmented reality;Human-centered computing-User mod-els;Human-centered computing-e-HCI theory;concepts and models","Computational modeling;Design methodology;Mixed reality;Physiology;Augmented reality","behavioural sciences computing;physiology;virtual reality","affordable devices;behaviour observations;design measurement models;expe-riences;experience measurements;incorporating devices;measurement models;mixed reality;MR experiences;physiological signals;popular practice;rational theory","","","","24","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Investigating User Embodiment of Inverse-Kinematic Avatars in Smartphone Augmented Reality","E. Makled; F. Weidner; W. Broll",Ilmenau University of Technology; Ilmenau University of Technology; Ilmenau University of Technology,"2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","27 Dec 2022","2022","","","666","675","Smartphone Augmented Reality (AR) has already provided us with a plethora of social applications such as Pokemon Go or Harry Potter Wizards Unite. However, to enable smartphone AR for social applications similar to VRChat or AltspaceVR, proper user tracking is necessary to accurately animate the avatars. In Virtual Reality (VR), avatar tracking is rather easy due to the availability of hand-tracking, controllers, and HMD whereas smartphone AR has only the back-(and front) camera and IMUs available for this task. In this paper we propose ARIKA, a tracking solution for avatars in smartphone AR. ARIKA uses tracking information from ARCore to track the users hand position and to calculate a pose using Inverse Kinematics (IK). We compare the accuracy of our system against a commercial motion tracking system and compare both systems with respect to sense of agency, self-location, and body-ownership. For this, 20 participants observed their avatars in an augmented virtual mirror and executed a navigation and a pointing task. Our results show that participants felt a higher sense of agency and self location when using the full body tracked avatar as opposed to IK avatars. Interestingly and in favor of ARIKA, there were no significant differences in body-ownership between our solution and the full-body tracked avatars. Thus, ARIKA and it’s single-camera approach is valid solution for smartphone AR applications where body-ownership is essential.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995369","Augmented reality;inverse kinematics;embodiment;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;augmented;and virtual realities; I.4. S [Image Processing and Computer Vision]: Scene Analysis-Tracking","Tracking;Navigation;Avatars;Multimedia systems;Collaboration;Resists;Cameras","augmented reality;avatars;cameras;helmet mounted displays;mobile computing;object tracking;smart phones;virtual reality","ARIKA;augmented virtual mirror;avatar tracking;body-ownership;commercial motion tracking system;full-body tracked avatars;hand-tracking;Harry Potter Wizards Unite;IK avatars;IMUs available;Inverse Kinematics;Inverse-kinematic avatars;proper user tracking;smartphone AR applications;smartphone Augmented Reality;Smartphone Augmented Reality;social applications;tracking solution;user embodiment;users hand position","","","","62","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"“Soul Hunter”: A novel augmented reality application in theme parks","D. Weng; W. Xu; D. Li; Y. Wang; Y. Liu","Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China","2011 10th IEEE International Symposium on Mixed and Augmented Reality","5 Apr 2012","2011","","","279","280","This paper introduces a novel augmented reality shooting game named “Soul Hunter”, which has been successfully operating in a theme park in China. Soul Hunter adopts an innovative infrared marker scheme to build a mobile augmented reality application in a wide area. It is an extension of the traditional first person game, in which a player is able to fight with virtual ghost through a gunlike device in real environment. This paper describes the challenges of applying augmented reality in theme parks and shares some experiences in solving the problems encountered in practical applications.","","978-1-4577-2185-4","10.1109/ISMAR.2011.6143901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162916","Augment reality;Infrared markers;Shooting game","Games;Augmented reality;Rendering (computer graphics);Painting;Lighting;Cameras;Radiofrequency identification","","","","1","","6","IEEE","5 Apr 2012","","","IEEE","IEEE Conferences"
"CAMAR 2.0: Future Direction of Context-Aware Mobile Augmented Reality","C. Shin; W. Lee; Y. Suh; H. Yoon; Y. Lee; W. Woo","GIST U-VR Laboratory, Woontack Woo, South Korea; GIST U-VR Laboratory, Woontack Woo, South Korea; GIST U-VR Laboratory, Woontack Woo, South Korea; GIST U-VR Laboratory, Woontack Woo, South Korea; GIST U-VR Laboratory, Woontack Woo, South Korea; GIST U-VR Laboratory, Woontack Woo, South Korea","2009 International Symposium on Ubiquitous Virtual Reality","4 Sep 2009","2009","","","21","24","With the rapid spreading of ubiComp and mobile augmented reality, the interaction of mobile users in U-VR environments has been evolving. However, current interaction is limited in individualspsila experience with given contents and services. In this paper, we propose CAMAR 2.0 as a future direction of CAMAR aiming at improving perception and interaction of users in U-VR environments. We thus introduce three principles for future interaction and experience in U-VR environments. We also discuss technical challenges and promising scenarios for realizing the vision of CAMAR 2.0 in U-VR environments.","","978-1-4244-4437-3","10.1109/ISUVR.2009.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232247","U-VR;Context-aware Mobile AR;Ubiquitous computing","Augmented reality;Virtual reality;Convergence;Mobile computing;Humans;Space technology;Pervasive computing;Portable computers;Personal digital assistants;Microcomputers","augmented reality;mobile computing","CAMAR 2.0;context-aware mobile augmented reality;ubiComp","","5","","14","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"Realistic occlusion effects in mirror-based co-located augmented reality systems","J. D. Mulder","Center for Mathematics and Computer Science, CWI, Amsterdam, Netherlands","IEEE Proceedings. VR 2005. Virtual Reality, 2005.","15 Aug 2005","2005","","","203","208","This paper describes the incorporation of realistic occlusion effects into mirror-based, stereoscopic co-location augmented reality display systems. By adding a light-blocking device in the form of an LCD panel underneath the semi-transparent mirror, the view on the physical world can be selectively blocked out such that virtual objects can fully occlude physical objects. Furthermore, by removing areas of the virtual objects rendered on the reflected display, physical objects seen through the semi-transparent mirror and the transmissive LCD panel appear to occlude these virtual objects. We describe the governing principles of the approach, and present an efficient algorithm for the generation of the occlusion masks with the use of vision-based scene reconstruction. Finally, a first prototype implementation of the system is presented.","2375-5334","0-7803-8929-8","10.1109/VR.2005.1492775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1492775","","Augmented reality;Virtual reality;Mirrors;Computer displays;Liquid crystal displays;Layout;Three dimensional displays;Prototypes;Computer graphics;Costs","augmented reality;hidden feature removal;rendering (computer graphics);computer displays;three-dimensional displays;liquid crystal displays;mirrors;realistic images;image reconstruction","realistic occlusion effects;mirror-based colocated augmented reality systems;stereoscopic display systems;light-blocking device;semitransparent mirror;virtual objects;rendering;transmissive LCD panel;occlusion masks;vision-based scene reconstruction;object occlusion","","4","3","31","IEEE","15 Aug 2005","","","IEEE","IEEE Conferences"
"Augmented Reality for Advanced Home Applications","Pronika; D. Mudgal; G. Yati","Faculty of Engineering and Technology, Manav Rachna International Institute of Research and Studies, Faridabad, Haryana; Faculty of Engineering and Technology, Manav Rachna International Institute of Research and Studies, Faridabad, Haryana; Faculty of Engineering and Technology, Manav Rachna International Institute of Research and Studies, Faridabad, Haryana","2023 5th International Conference on Smart Systems and Inventive Technology (ICSSIT)","14 Mar 2023","2023","","","118","123","Augmented Reality is a revolutionary technology that is already being used in various technologies like Video Games, Simulations and Internet of Things (IoT). The use of Augmented Reality can also be done to take control of devices and appliances, specifically Smart Devices or ones equipped with Internet of Things Technologies and Tools. This paper explores the possibility of using Augmented Reality in conjunction to Internet of Things and presents an implementation of it on a Prototype with a Light Bulb using various AR tools, Cloud and IOT technologies like Arduino Uno Board. AR technology will bring various benefits including increased security via the required security target image for the light bulb to work and they are explored in this paper along with the limitations of using Augmented Reality (AR) with further improvements and suggestions. The possibility of combining Augmented Reality (AR) or Mixed Reality (MR) with Internet of Things (IoT) to create better solutions for control devices, where home automation is explored and also further improvements and limitations are suggested.","2832-3017","978-1-6654-7467-2","10.1109/ICSSIT55814.2023.10060904","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10060904","Augmented Reality;Internet of Things (IoT);Home Automation;Home Applications;Mixed Reality","Home appliances;Video games;Solid modeling;Home automation;Mixed reality;Switches;Internet of Things","augmented reality;home automation;Internet of Things;microcontrollers","advanced home applications;AR tools;augmented reality;cloud technologies;Internet of Things technologies;IoT technologies;mixed reality;MR;revolutionary technology","","","","15","IEEE","14 Mar 2023","","","IEEE","IEEE Conferences"
"Viewpoint Planning of Projector Placement for Spatial Augmented Reality using Star-Kernel Decomposition","T. Hiraki; T. Hayase; Y. Ike; T. Tsuboi; M. Yoshiwaki",University of Tsukuba; Fujitsu Laboratories Ltd; Fujitsu Laboratories Ltd; Musashino University; Osaka City University,"2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","583","584","To obtain the targeted projection appearance in a spatial augmented reality system, we need to solve the projector placement problem. However, there are only heuristic solutions for viewpoint planning, which is the fundamental problem of projector placement. In this paper, we propose the star-kernel decomposition algorithm that can solve the viewpoint planning problem of an object composed of known polygons. The star-kernel decomposition algorithm decomposes a polygon into subpolygons that have non-empty star kernels. We implemented a program to obtain the placement of multiple projectors and evaluated the applicability of the obtained placement.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00174","Osaka City University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419279","Computing methodologies;Computer graphics","Solid modeling;Three-dimensional displays;Conferences;Spatial augmented reality;Virtual reality;User interfaces;Search problems","augmented reality;computational geometry;optical projectors","heuristic solutions;fundamental problem;star-kernel decomposition algorithm;viewpoint planning problem;nonempty star kernels;multiple projectors;targeted projection appearance;spatial augmented reality system;projector placement problem","","","","4","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Creating Meaningful Environment Models for Augmented Reality","E. E. Veas; D. Schmalstieg","Technische Universität Graz, Austria; Technische Universität Graz, Austria","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","295","296","This article introduces a framework to generate three-dimensional models for augmented reality (AR) including semantics. The semantics of 3D models have been studied previously in the field of intelligent virtual environments, but the process of creating real- world models containing such information have received little attention. We introduce a method for the creation of semantic, 3D models of the environment using an AR application named InventAry. Assisted by an ontology, InventAry enforces the creation of combined geometric and semantic environment model.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480808","","Augmented reality;Ontologies;Virtual environment;Virtual reality;Relational databases;Solid modeling;Intelligent agent;Layout;Geometry;Shape","augmented reality;ontologies (artificial intelligence);programming language semantics","augmented reality;three dimensional models;semantics;intelligent virtual environments;InventAry;ontology;geometric environment model","","","9","6","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"Enhancing Culinary Training with Spatial Augmented Reality: A User Study Comparing sAR Kitchen and Video Tutorials","Y. Ghasemi; A. Bayro; J. MacDonald; H. Jeong; J. Reynolds; C. S. Nam",University of Illinois at Chicago; Arizona State University; University of Illinois at Chicago; Arizona State University; DePaul University; North Carolina State University,"2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","390","392","This paper presents sAR Kitchen, a cooking assistant that aims to enhance culinary training through the use of spatial augmented reality (sAR). We conducted a user study with twenty-two participants to investigate the effects of instructions given by our proposed sAR system and a monitor display with video tutorials in a playdough-making task representing the cooking task. Our study measured participants' perceived workload, usability, and performance regarding task completion time, product quality, and cooking station messiness. The results showed that sAR significantly decreased the perceived workload and increased the system's usability compared to traditional video-based tutorials. Additionally, our open-ended questions revealed that participants found the sAR instructions more engaging and interactive. Overall, this study demonstrates the potential of sAR to provide more user-friendly learning methods in culinary training.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108768","Human-centered computing-Human computer interaction (HCI)-Interactive systems and tools-User interface programming;Human-centered computing-Interaction design-Interaction design process and methods-Activity centered design","Tutorials;Virtual reality;Augmented reality;Training;Videos;Food products","augmented reality;computer aided instruction;product quality;video signal processing","cooking assistant;cooking task;culinary training;monitor display;participants;perceived workload;performance regarding task completion time;playdough-making task;sAR instructions;sAR system;spatial augmented reality;traditional video-based tutorials;user study comparing sAR Kitchen;user-friendly learning methods;video tutorials","","","","15","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"ComposAR: An intuitive tool for authoring AR applications","H. Seichter; J. Looser; M. Billinghurst","Human Interface Technology Laboratory, New Zealand; Human Interface Technology Laboratory, New Zealand; Human Interface Technology Laboratory, New Zealand","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","177","178","This paper introduces ComposAR, a tool to allow a wide audience to author AR and MR applications. It is unique in that it supports both visual programming and interpretive scripting, and an immediate mode for runtime testing. ComposAR is written in Python which means the user interface and runtime behavior can be easily customized and third-party modules can be incorporated into the authoring environment. We describe the design philosophy and the resulting user interface, lessons learned and directions for future research.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637354","H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities;H.5.2 [User Interfaces]: Graphical user interfaces (GUI)","Augmented reality;Three dimensional displays;Virtual reality;Graphical user interfaces;Programming;Visualization;User interfaces","augmented reality;authoring systems;graphical user interfaces;program testing;visual programming","augmented reality;mixed reality;authoring tool;visual programming;interpretive scripting;runtime testing;Python;ComposAR;user interface","","48","4","13","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"In situ image-based modeling","A. van den Hengel; R. Hill; B. Ward; A. Dick","School of Computer Science, University of Adelaide, Australia; School of Computer Science, University of Adelaide, Australia; School of Computer Science, University of Adelaide, Australia; School of Computer Science, University of Adelaide, Australia","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","107","110","We present an interactive image-based modelling method for generating 3D models within an augmented reality system. Applying real time camera tracking, and high-level automated image analysis, enables more powerful modelling interactions than have previously been possible. The result is an immersive modelling process which generates accurate three dimensional models of real objects efficiently and effectively. In demonstrating the modelling process on a range of indoor and outdoor scenes, we show the flexibility it offers in enabling augmented reality applications in previously unseen environments.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336482","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems;Artificial, augmented, and virtual realities I.4.8 [IMAGE PROCESSING AND COMPUTER VISION]: Scene Analysis;Shape","Layout;Power system modeling;Cameras;Augmented reality;Geometry;Shape;Image analysis;Information analysis;Solid modeling;Parameter estimation","augmented reality;computer vision","in situ image-based modeling;interactive image-based modelling method;augmented reality system;real time camera tracking;high-level automated image analysis;immersive modelling process","","21","5","18","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"A Method for Predicting Marker Tracking Error","R. M. Freeman; S. J. Julier; A. J. Steed","University College London, UK; University College London, UK; University College London, UK","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","157","160","Many augmented reality (AR) applications use marker-based vision tracking systems to recover camera pose by detecting one or more planar landmarks. However, most of these systems do not interactively quantify the accuracy of the pose they calculate. Instead, the accuracy of these systems is either ignored, assumed to be a fixed value, or determined using error tables (constructed in an off-line ground-truthed process) along with a run-time interpolation scheme. The validity of these approaches are questionable as errors are strongly dependent on the intrinsic and extrinsic camera parameters and scene geometry. In this paper we present an algorithm for predicting the statistics of marker tracker error in real-time. Based on the scaled spherical simplex unscented transform (SSSUT), the algorithm is applied to the augmented reality toolkit plus (ARToolKitPlus). The results are validated using precision off-line photogrammetric techniques.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538841","augmented reality;tracking;ARToolKit;unscented transforms","Augmented reality;Cameras;Machine vision;Accuracy;Runtime;Interpolation;Layout;Geometry;Prediction algorithms;Error analysis","augmented reality;computer vision","marker tracking error prediction;vision tracking systems;run-time interpolation scheme;scaled spherical simplex unscented transform;augmented reality toolkit plus","","10","1","18","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"Acceptability of an A2R Application: Analysis of Correlations between Factors in a TAM","M. Tenemaza; J. Ramírez; A. de Antonio","Escuela Politécnica Nacional; Universidad Politécnica, de Madrid; Universidad Politécnica, de Madrid","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","178","183","Adaptive Augmented Reality (A2R) presents the environment and useful information for the user decision making, this is in real time. Nowadays, there is a gap in A2R acceptance research, although A2R is an emergent technology, specific studies of A2R acceptance has not been conducted yet. In contrast, Augmented Reality (AR) acceptance and recommendation acceptance has actually been addressed in several works. Thus, to analyze A2R acceptance, an A2R prototype was developed relying on hybrid and mobile technology. This application guides visitants to locate remarkable places at the historic center of Quito. The guide proposes places according to the user's preferences or interests gathered from a social network. Based on this prototype, an experiment with a sample of young people between 18 and 25 years old was carried out in order to determine the acceptance of A2R technology. An adaptation of Davis, Leues and Vecandesh's Technology acceptance models was applied. This study analyzed the correlations among different variables such as perceived adaptability, perceived enjoyment, perceived easy of use, perceived usefulness and attitude towards using. The results show that the perceived adaptability, perceived ease of use, perceived usefulness and perceived enjoyment are crucial in the success of A2R application.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836492","H [Human-centered computing H.1 HCI design and evaluation methods H.2 Interaction paradigmsUser studies Computing methodologies Mixed/augmented reality]: —","Augmented reality;Prototypes;Correlation;Adaptation models;Facebook;Analytical models;Decision making","augmented reality;decision making;history;human computer interaction;human factors;information filtering;mobile computing;recommender systems;social networking (online);technology management","user attitude;perceived usefulness;perceived easy of use;perceived enjoyment;perceived adaptability;technology acceptance models;social network;user preferences;Quito;hybrid technology;mobile technology;recommendation acceptance;A2R acceptance;decision making;adaptive augmented reality;correlation analysis;TAM","","4","","17","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"lifeClipper3 — An augmented walking experience field evaluation of an experience design approach for immersive outdoor augmented reality","J. Torpus; B. Tobler","Institute for Research in Art and Design, HGK, University of Applied Sciences, North-Western Switzerland, Switzerland; Museum of Communication, Bern, Switzerland","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","73","82","lifeClipper3 is a media art project in which a walk is audiovisually expanded into a game-like experience by means of “augmented reality” technologies. For visitors this creates an immersive experience which is unique in each case, and which challenges and calls into question habitual modes of perception. In this paper the “experience design” strategies used in lifeClipper3 are introduced, and examined by means of qualitative ethnographic methods in a visitor evaluation. The resulting insights are intended to be beneficial for similarly designed future AR art projects.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093660","Augmented reality;mixed reality;reactive environment;locative media;location-based;ubiquitous computing;pervasive game;computer vision;mobile computing;experience design;design research;field evaluation","Games;Media;Art;Streaming media;Augmented reality;Three dimensional displays;Meteorology","augmented reality;solid modelling;user interfaces","lifeClipper3 media art project;experience design approach;immersive outdoor augmented reality;game-like experience;visitor evaluation;ethnographic method","","3","","31","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Virtual Reality, Augmented Reality, and Mixed Reality Applications: Present Scenario","T. Mirza; N. Tuli; A. Mantri","Institute of Engineering and technology, Chitkara University, Punjab; Institute of Engineering and technology, Chitkara University, Punjab; Institute of Engineering and technology, Chitkara University, Punjab","2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)","18 Jul 2022","2022","","","1405","1412","With tremendous research, innovation in human computer interaction, infographics and greater accessibility of visualization technologies i.e., augmented reality; virtual reality and mixed reality is to find new possibilities for its applications. The ability to transform the user's perception and interaction with his environment has increased his popularity of use in all spheres of life. This study analyses the literature on augmented reality, virtual reality and mixed reality applications in order to find the research gaps in these fields. This review study has taken 103 papers of 2010-2021 into account from SCOPUS, SCI and IEEE databases. The results of the analysis can provide some useful insights regarding potential and use of augmented reality, virtual reality and mixed reality in the different areas of application.","","978-1-6654-3789-9","10.1109/ICACITE53722.2022.9823482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9823482","Augmented reality;virtual reality;mixed reality;education","Wireless communication;Human computer interaction;Visualization;Technological innovation;Education;Mixed reality;Transforms","augmented reality;data visualisation;database management systems;human computer interaction;virtual reality","virtual reality;augmented reality;mixed reality applications","","2","","121","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Next Generation Augmented Reality Displays","M. K. Hedili; E. Ulusoy; S. Kazempour; S. Soomro; H. Urey","Electrical Engineering Dept., Koç University, Istanbul, Turkey; Electrical Engineering Dept., Koç University, Istanbul, Turkey; Electrical Engineering Dept., Koç University, Istanbul, Turkey; Electrical Engineering Dept., Koç University, Istanbul, Turkey; Electrical Engineering Dept., Koç University, Istanbul, Turkey","2018 IEEE SENSORS","27 Dec 2018","2018","","","1","3","Wearable AR/VR displays have a long history and earlier efforts failed due to various limitations. Advances in various sensors, optical technologies, and computing technologies renewed the interest in this area. AR glasses can be the new computing platform and potentially replace smart phones but there are some challenges ahead. We have been working on various wearable display architectures and here we summarize our efforts on laser MEMS scanning displays, head-mounted projectors, and holographic near-eye displays.","2168-9229","978-1-5386-4707-3","10.1109/ICSENS.2018.8589942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8589942","Augmented reality;Virtual reality;Head-mounted displays","Augmented reality;Lenses;Computer architecture;Micromechanical devices;Optical sensors;Optical imaging","augmented reality;helmet mounted displays;holographic displays;micromechanical devices;smart phones","optical technologies;computing technologies;AR glasses;computing platform;smart phones;wearable display architectures;laser MEMS scanning displays;augmented reality displays;wearable AR-VR displays;head-mounted projectors;holographic near-eye displays","","2","","10","IEEE","27 Dec 2018","","","IEEE","IEEE Conferences"
"Augmented Dimension Portal Types","A. K. Ouyang; G. A. L. Morteo; R. C. Flores","Instituto de Ingeniería Universidad Autónoma de Baja California, México; Instituto de Ingeniería Universidad Autónoma de Baja California, México; Centro Universitario Valle de Chalco Universidad Autónoma del Estado de México, México","2022 IEEE Mexican International Conference on Computer Science (ENC)","16 Sep 2022","2022","","","1","4","This article classifies one kind of portal that can be used in the Augmented Dimension. Firstly, it defines the origins of Augmented Dimension, which comes from the Augmented Reality. Then define what the Augmented Dimension is. Afterwards, defining what a portal is and how it can be classified. The classification is based on a previous study about categorization scheme for Augmented Reality. Lastly, discussing the classification of the Augmented Dimension portals and their possible future work in the educational field.","2332-5712","978-1-6654-7347-7","10.1109/ENC56672.2022.9882937","National Council of Science and Technology (Conacyt)(grant numbers:CVU: 1126029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882937","Portal;Augmented Reality;Augmented Dimension","Computer science;Technological innovation;Logic gates;Mobile applications;Portals;Augmented reality;Smart phones","augmented reality;computer aided instruction;portals","Augmented Dimension portal types;Augmented Reality;Augmented Dimension portals","","","","19","IEEE","16 Sep 2022","","","IEEE","IEEE Conferences"
"Augmented prototyping of 3D rigid curved surfaces","M. A. Oikawa; I. de Souza Almeida; T. Taketomi; G. Yamamoto; J. Miyazaki; H. Kato","Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","307","308","This paper presents an application of Augmented Reality (AR) in Rapid Prototyping (RP) of non-textured rigid curved surfaces. By enhancing the prototypes with AR, evaluation of its design and aesthetic concepts in real-time becomes easier, saving time and production costs. In our application, no fiducial markers are required and the CAD model used to build the prototype is applied in an edge-based tracking system specially designed to deal with curved shapes. Results from a pilot user study comparing the use of a 3D software and the proposed application are also presented.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402587","product design;augmented prototyping;model-based tracking;non-textured curved surfaces","Prototypes;Solid modeling;Augmented reality;Surface texture;Shape;Software;Visualization","augmented reality;computational geometry","augmented prototyping;3D rigid curved surfaces;rapid prototyping;nontextured rigid curved surface;CAD model;edge-based tracking system;curved shapes","","1","","6","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Augmented Reality-Based Cybersecurity Education on Phishing","Y. -M. Chiou; C. -C. Shen; C. Mouza; T. Rutherford","Department of Computer and Information Sciences, University of Delaware, Delaware, USA; Department of Computer and Information Sciences, University of Delaware, Delaware, USA; School of Education, University of Delaware, Delaware, USA; School of Education, University of Delaware, Delaware, USA","2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","22 Dec 2021","2021","","","228","231","With the rising of remote work and schooling, the adaption of emerging technologies to teach the concepts of cybersecurity becomes critical. In this work, we present the concept, design, and prototype of a Mixed Reality-based cybersecurity education application on phishing, so that school children could be exposed to the subject remotely and practice to differentiate malicious from genuine messages.","","978-1-6654-3225-2","10.1109/AIVR52153.2021.00052","National Science Foundation(grant numbers:NSF DRL-2048874); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644321","Mixed Reality;Cybersecurity Education;Phishing","Training;Phishing;Conferences;Prototypes;Mixed reality;Virtual reality;Transforms","augmented reality;computer aided instruction;computer crime;security of data;teaching;telecommunication security;virtual reality","augmented Reality-based cybersecurity education;rising;remote work;schooling;Mixed Reality-based cybersecurity education application;phishing;school children","","3","","19","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Stereo augmentation of simulation results on a projection wall by combining two basic ARVIKA systems","S. Noelle","Virtual Reality, Corporate Research, Volkswagen AG, Germany","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","271","322","The article describes the potential for cost-reduction by using augmented reality (AR) in the automotive industry. AR allows for the evaluation of computer-generated simulations with physically crashed cars. The augmented simulation results are displayed on a projection wall in stereo by simply combining two basic ARVIKA systems.","","0-7695-1781-1","10.1109/ISMAR.2002.1115108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115108","","Visualization;Vehicle crash testing;Computational modeling;Augmented reality;Cams;Automotive engineering;Computer simulation;Computer crashes;Animation;Virtual reality","augmented reality;digital simulation;automobiles;engineering graphics;stereo image processing;video signal processing","stereo augmentation;computer generated simulation evaluation;cost reduction;augmented reality;automotive industry;physically crashed cars;projection wall;ARVIKA systems","","7","","9","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Interactive multi-marker calibration for augmented reality applications","G. Baratoff; A. Neubeck; H. Regenbrecht","Virtual and Augmented Environments, DaimlerChrysler AG Research and Technology, Ulm, Germany; Virtual and Augmented Environments, DaimlerChrysler AG Research and Technology, Ulm, Germany; Virtual and Augmented Environments, DaimlerChrysler AG Research and Technology, Ulm, Germany","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","107","116","Industrial augmented reality (AR) applications require fast, robust, and precise tracking. In environments where conventional high-end tracking systems cannot be applied for certain reasons, marker-based tracking can be used with success as a substitute if care is taken about (1) calibration and (2) run-time tracking fidelity. In out-of-the-laboratory environments multi-marker tracking is needed because the pose estimated from a single marker is not stable enough. The overall pose estimation can be dramatically improved by fusing information from several markers fixed relative to each other compared to a single marker only. To achieve results applicable in an industrial context relative marker poses need to be properly calibrated. We propose a semiautomatic image-based calibration method requiring only minimal interaction within the workflow. Our method can be used off-line, or preferably incrementally online. When used online, our method shows reasonably good accuracy and convergence with workflow interruption of less than one second per incremental step. Thus, it can be interactively used. We illustrate our method with an industrial application scenario.","","0-7695-1781-1","10.1109/ISMAR.2002.1115079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115079","","Calibration;Augmented reality;Instruments;Computational fluid dynamics;Robustness;Airplanes;Magnetic heads;Virtual reality;Cameras;Manufacturing industries","calibration;augmented reality;computer vision;optical tracking","interactive multi-marker calibration;augmented reality;marker-based tracking;run-time tracking fidelity;pose estimation;semiautomatic image-based calibration;accuracy;convergence;workflow interruption","","20","17","20","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Live Solar System (LSS): Evaluation of an Augmented Reality book-based educational tool","A. K. Sin; H. B. Zaman","Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor Darul Ehsan, Malaysia; Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor Darul Ehsan, Malaysia","2010 International Symposium on Information Technology","2 Sep 2010","2010","1","","1","6","Live Solar System (LSS) is an Augmented Reality book-based educational tool to learn Astronomy. Augmented Reality (AR) has its own potential in the education field. In this paper, we review on Tangible Augmented Reality (TAR) which is a combination of Tangible User Interface and AR interface. By applying TAR in LSS, it was able to provide intuitive interaction which became a new learning experience for users. A user study was conducted to test on the usability of LSS based on three constructs namely: ease of use, learnability, and effectiveness. Findings of the study showed that LSS is easy to use and learn, and it also helped users in learning Astronomy.","2155-899X","978-1-4244-6718-1","10.1109/ITSIM.2010.5561320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561320","Augmented Raelity;Tangible User Interface;Tangible Augmeneted Relity;User study","Augmented reality;Solar system;Education;Motion pictures;Planets;Three dimensional displays","astronomy;augmented reality;computer aided instruction;physics education;user interfaces","live solar system;augmented reality book-based educational tool;tangible augmented reality;tangible user interface;LSS;astronomy learning","","27","","28","IEEE","2 Sep 2010","","","IEEE","IEEE Conferences"
"An on-line evaluation system for optical see-through augmented reality","N. Navab; S. Zokai; Y. Genc; E. M. Coelho","Computer Science Department, Technology Universitaet Muenchen, Munich, Germany; Siemens AG Corporate Research and Development, Princeton, NJ, USA; Siemens AG Corporate Research and Development, Princeton, NJ, USA; College of Computing, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Virtual Reality 2004","12 Jul 2004","2004","","","245","246","This work introduces a technique that allows final users to evaluate and recalibrate their AR system as frequently as needed. We developed an interactive game as a prototype for such evaluation system and explain how this technique can be implemented to be used in real life.","1087-8270","0-7803-8415-6","10.1109/VR.2004.1310091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310091","","Augmented reality;Personal digital assistants;Optical feedback;Calibration;Mice;Displays;Virtual reality;Games;Computer science;Educational institutions","augmented reality;software performance evaluation;computer games","online evaluation system;augmented reality;AR recalibration;interactive game","","15","","4","IEEE","12 Jul 2004","","","IEEE","IEEE Conferences"
"Editing real world scenes: augmented reality with image-based rendering","D. Cobzas; M. Jagersand; K. Yerex","CS, University of Alberta, Edmonton, AB, Canada; CS, University of Alberta, Edmonton, AB, Canada; CS, University of Alberta, Edmonton, AB, Canada","IEEE Virtual Reality, 2003. Proceedings.","2 Apr 2003","2003","","","291","292","We present a method that using only an uncalibrated camera allows the capture of object geometry and appearance, and then at a later stage registration and AR overlay into a new scene. Using only image information first a coarse object geometry is obtained using structure-from-motion, then a dynamic, view dependent texture is estimated to account for the differences between the reprojected coarse model and the training images. In AR rendering, the object structure is interactively aligned in one frame by the user, object and scene structure is registered, and rendered in subsequent frames by a virtual scene camera, with parameters estimated from real-time visual tracking. Using the same viewing geometry for both object acquisition, registration, and rendering ensures consistency and minimizes errors.","1087-8270","0-7695-1882-6","10.1109/VR.2003.1191169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191169","","Layout;Augmented reality;Rendering (computer graphics);Virtual reality","rendering (computer graphics);augmented reality;image registration","augmented reality;rendering;AR rendering;object geometry;registration;uncalibrated camera;object acquisition;viewing geometry;object registration","","1","9","6","IEEE","2 Apr 2003","","","IEEE","IEEE Conferences"
"The Effects of Augmented Reality Head-Up Display Graphics on Driver Situation Awareness and Takeover Performance in Driving Automation Systems","R. L. Greatbatch; H. Kim; Z. Doerzaph",Virginia Tech; Oakland University; Virginia Tech Transportation Institute,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","521","522","Implementing head-up displays to convey takeover requests allows for the opportunity to increase driver safety during takeover. This work aims to gain greater understanding in the effects of different visualization strategies on takeover performance and participant's situation awareness using two HUD visualization strategies, screen-relative and world-relative graphics. Initial results indicate an increase in takeover performance using HUD graphic visualization strategies.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757673","Driving Automation System;Takeover;Augmented Reality;HUD;H.5 [Information Interfaces and Presentation]: H.5.1: Multimedia Information Systems – Artificial, Augmented, and Virtual Realities;H.5.2: User Interfaces – Ergonomic, Evaluation / Methodology","Visualization;Automation;Three-dimensional displays;Conferences;Multimedia systems;Head-up displays;User interfaces","augmented reality;data visualisation;driver information systems;head-up displays;helmet mounted displays;road safety","takeover requests;increase driver safety;different visualization strategies;takeover performance;participant;HUD visualization strategies;world-relative graphics;HUD graphic visualization strategies;augmented reality head-up display graphics;driver situation awareness;driving automation systems;implementing head-up displays","","","","5","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"The SmartTool: a system for augmented reality of haptics","T. Nojima; D. Sekiguchi; M. Inami; S. Tachi","University of Tokyo, Japan; University of Tokyo, Japan; University of Tokyo, Japan; University of Tokyo, Japan","Proceedings IEEE Virtual Reality 2002","7 Aug 2002","2002","","","67","72","Previous research on augmented reality has been mainly focused on augmentation of visual or acoustic information. However, humans can receive information not only through vision and acoustics, but also through haptics. Haptic sensation is very intuitive, and some researchers are focusing on making use of haptics in augmented reality systems. While most previous research on haptics is based on static data, such as that generated from CAD, CT, and so on, these systems have difficulty responding to a changing real environment in real time. In this paper, we propose a new concept for the augmented reality of haptics, the SmartTool. The SmartTool responds to the real environment by using real time sensor(s) and a haptic display. The sensor(s) on the SmartTool measure the real environment then send us that information through haptic sensation. Furthermore, we will describe the prototype system we have developed.","1087-8270","0-7695-1492-8","10.1109/VR.2002.996506","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=996506","","Augmented reality;Haptic interfaces;Humans;Displays;Surgery;Navigation;Cameras;Acoustics;Real time systems;Machine vision","augmented reality;haptic interfaces","augmented reality;haptics;haptic sensation;SmartTool;real environment;time sensor;haptic display;prototype system","","29","1","10","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Perception of Health Professional about Clinical Utility of an Augmented Reality Musical System to Motor and Cognitive Rehabilitation","A. G. Dionisio Correa; G. Aparecida De Assis; I. Karaguilla Ficheman; R. De Deus Lopes; M. Do Nascimento","Fac. de Comput. e Inf. - FCI, Univ. Presbiteriana Mackenzie - UPM, Brazil; Dept. de Inf., Univ. Tecnol. Fed. do Parana - UTFPR, Brazil; Lab. de Sist. Integraveis - LSI, Escola Politec. da Univ. de Sao Paulo - EPUSP, Brazil; Lab. de Sist. Integraveis - LSI, Escola Politec. da Univ. de Sao Paulo - EPUSP, Brazil; Colmeia Med. Integrada, Brazil","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","71","79","GenVirtual is a augmented reality musical software that allows development of activities in music therapy. This study aimed to analyze the perceptions of other health professionals about the clinical utility of GenVirtual. A secondary objective was to understand the attitudes of these professionals facing the augmented reality technology. Three focus groups composed of music therapists, occupational therapists, physiotherapists, speech and language therapists and nurses who assist people with motor or cognitive disabilities were assigned. The quantitative and qualitative data were analysed using inductive thematic analysis. The outcomes showed that the view of the participants about the GenVirtual is as a tool that has great potential to be used in motor rehabilitation. The research brought new insights regarding the clinical use of GenVirtual with children, youth, adults and seniors and provided information about new features and improvements for future developments of the GenVirtual software.","","978-1-4799-4261-9","10.1109/SVR.2014.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913074","augmented reality;music therapy;cognitive and motor rehabilitation","Software;Sorting;Instruments;Conferences;Augmented reality;Materials;Timbre","augmented reality;cognition;medical computing;music;patient rehabilitation","augmented reality musical system;cognitive rehabilitation;augmented reality musical software;activities development;music therapy;health professional perception;clinical utility;professional attitudes;augmented reality technology;occupational therapists;physiotherapists;speech therapists;language therapists;nurses;motor disabilities;cognitive disabilities;inductive thematic analysis;motor rehabilitation;clinical use;GenVirtual software","","2","","24","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"SoundPacman: Audio augmented reality in location-based games","T. Chatzidimitris; D. Gavalas; D. Michael","Computer Technology Institute and Press “Diophantus”, Patras, Greece; Computer Technology Institute and Press “Diophantus”, Patras, Greece; Department of Multimedia and Graphic Arts, Cyprus University of Technology, Limassol, Cyprus","2016 18th Mediterranean Electrotechnical Conference (MELECON)","23 Jun 2016","2016","","","1","6","Sound design has received little attention in location-based games research. Typically, existing prototypes heavily rely on visual information with sound only having a marginal role in the game design and development process. This paper investigates the role of sound as primary interface for conveying game information and creating engaging gaming experiences. As a case study, we present SoundPacman, a prototype location-based game, wherein players experience the game space with the use of 3D sounds, which augment the physical environment. Preliminary tests utilizing EEG analysis provide evidence that sound augmentation may significantly contribute towards enhancing the immersion levels of players.","2158-8481","978-1-5090-0058-6","10.1109/MELCON.2016.7495414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495414","pervasive games;augmented reality;3D sound;location-based games;EEG","Games;Three-dimensional displays;Engines;Servers;Prototypes;Roads;Augmented reality","audio acoustics;augmented reality;biology computing;computer games;electroencephalography;medical computing","SoundPacman;audio augmented reality;sound design;location-based games research;visual information;game information;3D sounds;EEG analysis;immersion levels;players","","25","","15","IEEE","23 Jun 2016","","","IEEE","IEEE Conferences"
"SignAR: A Sign Language Translator Application with Augmented Reality using Text and Image Recognition","N. -U. -N. Soogund; M. H. Joseph","Faculty of Computing, Engineering & Technology, Asia Pacific University of Technology & Innovation, Kuala Lumpur, Malaysia; Faculty of Computing, Engineering & Technology, Asia Pacific University of Technology & Innovation, Kuala Lumpur, Malaysia","2019 IEEE International Conference on Intelligent Techniques in Control, Optimization and Signal Processing (INCOS)","9 Jan 2020","2019","","","1","5","Studies have shown that hearing impaired students face lots of difficulties in reading comprehension mostly because they cannot develop a fluent system of communication required to become proficient readers. This in turn can have an impact on their communication and social skills, leading to an overall depressed academic achievement, affecting their future prospects. SignAR will help hearing impaired children learn English as well as sign language and hearing people can also use it to learn sign language. So, basically, once a word has been captured by the phone camera, the corresponding sign animation will be augmented on the user’s screen. Each word will be mapped to its corresponding animation and shown on the phone’s screen. By using SignAR, the hearing impaired children will be able to learn English using Signs while hearing users will learn Signs using English. In this way, the communication barriers between the hearing and non-hearing will hopefully be greatly diminished.","","978-1-5386-9543-2","10.1109/INCOS45849.2019.8951322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951322","Augmented Reality;Deaf;Education;Text Recognition;Animation","Auditory system;Assistive technology;Augmented reality;Gesture recognition;Cameras;Databases;Animation","augmented reality;cameras;computer aided instruction;computer animation;handicapped aids;hearing;image recognition;language translation;mobile learning;sign language recognition;text analysis;text detection","text recognition;depressed academic achievement;social skills;hearing impaired students;image recognition;augmented reality;sign language translator;hearing users;sign animation;phone camera;hearing people;hearing impaired children;SignAR","","4","","9","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Living the Past: Augmented Reality and Archeology","A. Bernardini; C. Delogu; E. Pallotti; L. Costantini","Fondazione Ugo Bordoni, Rome, Italy; Fondazione Ugo Bordoni, Rome, Italy; Fondazione Ugo Bordoni, Rome, Italy; Fondazione Ugo Bordoni, Rome, Italy","2012 IEEE International Conference on Multimedia and Expo Workshops","16 Aug 2012","2012","","","354","357","Archeological remnants in urban areas tend to be included in the urban landscape or even remain hidden in subterranean locations which are not visible and, for these reasons, they are accessed with difficulty by visitors. In our previous experience, we developed a mobile application, which guided visitors in real time through various archaeological sites using texts, images, and videos. The results of an evaluation test which collected visitors' impressions and suggestions showed us that the mobile application allowed them to visit archeological remnants in a more participative way but that most visitors were unable to imagine what relation the archaeological remnants had with the ancient urban landscape. To solve this problem and improve the visitors' experience, we are now working at another application, which combines historical and archeological details with an immersive experience. The mobile application recognizes a cultural heritage element by image recognition or by positioning and it augments the interface with various layers of information. Furthermore, the application will provide not only information but it will offer to visitors an emotional experience.","","978-1-4673-2027-6","10.1109/ICMEW.2012.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6266281","archeology;annotation;augmented reality;story telling;user interface","Cultural differences;Augmented reality;Mobile communication;Mobile handsets;Real time systems;Global Positioning System;Videos","archaeology;augmented reality;history;image recognition;mobile computing","augmented reality;archeology;archeological remnants;urban areas;subterranean locations;mobile application;archaeological sites;evaluation test;visitors impressions;visitors suggestions;ancient urban landscape;visitors experience;historical details;archeological details;cultural heritage element;image recognition;emotional experience","","3","","15","IEEE","16 Aug 2012","","","IEEE","IEEE Conferences"
"Collaboration in the age of augmented reality","I. Tomek; R. Giles","Jodrey School of Computer Science, Acadia University, Wolfville, Canada; Jodrey School of Computer Science, Acadia University, Wolfville, Canada","2008 IEEE International Technology Management Conference (ICE)","28 Apr 2016","2008","","","1","8","Groupware and socialware focus on human interaction and usually provide document sharing and team management support. During the last few years, however, people and documents have been joined by Internet-connected electronic devices that produce and consume data and allow humans to observe and control real-world processes. This co-presence of humans, data, and electronic devices on Internet constitutes a virtual universe with a new dimension, one that parallels the physical world and merges with it seamlessly. Unfortunately, no applications currently support this new reality while providing sophisticated groupware and socialware features at the same time. We propose a list of properties of an ideal environment supporting human, document, and device interaction, and describe a design that would satisfy these requirements.","","978-0-85358-244-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7462005","Augmented reality;collaboration;social interaction;software framework","Collaborative software;Collaborative work;Software;Augmented reality;Games;Real-time systems","augmented reality;groupware;human computer interaction","collaboration;augmented reality;groupware;socialware;human interaction;document sharing;team management support;Internet-connected electronic devices;virtual universe;device interaction","","","","24","","28 Apr 2016","","","IEEE","IEEE Conferences"
"Virtual and augmented reality environment for remote training of wheelchairs users: Social, mobile, and wearable technologies applied to rehabilitation","E. L. M. Naves; T. F. Bastos; G. Bourhis; Y. M. L. R. Silva; V. J. Silva; V. F. Lucena","Federal University of Uberlandia (UFU), Uberlandia, Brazil; Federal University of Espirito Santo (UFES), Vitoria, Brazil; University of Lorraine, Metz, France; UFAM)Manaus, Brazil; UFAM)Manaus, Brazil; Federal University of Amazonas (UFAM), Manaus, Brazil","2016 IEEE 18th International Conference on e-Health Networking, Applications and Services (Healthcom)","21 Nov 2016","2016","","","1","4","New research reports shows that important progresses for controlling electric-powered wheelchair have been made recently aiming people with severe disabilities. In fact, a significant amount of people affected by those physical disabilities still cannot take advantage of autonomous mobility, even electronic or automated ones. For those people, the use of proper biological signals to control the assisted environment may be the only existing solution. In such scenario, the act of commanding an electric-powered wheelchair without proper training may be a serious safety risk. To avoid this kind of dangerous situation and to permit users to make use of such technology, one viable solution would be to be trained by using virtual driving simulators. Nevertheless, when using biomedical signals as commands it is not possible to ensure a continuous and reliable control of the wheelchair, it is necessary to associate the control possibilities with autonomous features such as semiautomatic obstacle detection or contour. Thus, it is interesting to offer to new wheelchair users the possibility of using simulators to allow them to learn to drive at distance, making use of telematics techniques combined with mobile and wearable devices, and publishing their progress and worries in social networks, which is the objective of this work. This project joints complementary skills from researchers from the Federal University of Amazonas, Federal University of Espirito Santo, and Federal University of Uberlandia, with the collaboration of researches from the University of Lorraine in Metz-France.","","978-1-5090-3370-6","10.1109/HealthCom.2016.7749418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7749418","Assistive Technology;Virtual and Augmented Reality;Multimodal System;Mobile Devices;Wearable Devices","Wheelchairs;Training;Electroencephalography;Muscles;Augmented reality;Social network services;Electrodes","augmented reality;computer based training;electric vehicles;handicapped aids;mobile computing;wheelchairs","augmented reality environment;virtual reality environment;remote training;wheelchairs users;wearable technologies;mobile technologies;social technologies;electric powered wheelchair;severe disabilities;physical disabilities;autonomous mobility;biological signals;safety risk;virtual driving simulators;biomedical signals;semiautomatic obstacle detection;wheelchair users;social networks;Federal University of Amazonas;Federal University of Espirito Santo","","6","","19","IEEE","21 Nov 2016","","","IEEE","IEEE Conferences"
"ARecycle NOID ARt Game: The Augmented Reality Game in Public Space","A. Mesarosova; M. F. Hernandez","Facultad de Bellas Artes, Universitat Politecnica de Valencia, Valencia, Spain; Facultad de Bellas Artes, Universitat Politecnica de Valencia, Valencia, Spain","2014 International Conference on Cyberworlds","15 Dec 2014","2014","","","421","424","The act of playing a game in the urban space is the main idea of this interactive intervention. We place an Augmented Reality game on the street, which for us is a representation of the public space. We understand a street as a free, social and cultural space, and not only a space of transit. Our aim is to return the ludic function to the street. We find ourselves in the ""digital age"" and everything ""digital"" usually happens behind the screen so we make use of the Augmented Reality technologies for Smartphones that allow us to move the action of a digital game to the street.","","978-1-4799-4677-8","10.1109/CW.2014.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980793","augmented reality game;augmented public space;art game;augmented urban space;hybrid space","","art;augmented reality;computer games","ARecycle NOID;ARtGame;augmented reality game;public space;urban space;interactive intervention;digital age;augmented reality technologies;smart phones;street digital game","","1","","5","IEEE","15 Dec 2014","","","IEEE","IEEE Conferences"
"AR Feels “Softer” than VR: Haptic Perception of Stiffness in Augmented versus Virtual Reality","Y. Gaffary; B. Le Gouis; M. Marchal; F. Argelaguet; B. Arnaldi; A. Lécuyer","Inria, IRISA; INSA Rennes, IRISA; INSA Rennes, IRISA; Inria, IRISA; INSA Rennes, IRISA; Inria, IRISA","IEEE Transactions on Visualization and Computer Graphics","29 Sep 2017","2017","23","11","2372","2377","Does it feel the same when you touch an object in Augmented Reality (AR) or in Virtual Reality (VR)? In this paper we study and compare the haptic perception of stiffness of a virtual object in two situations: (1) a purely virtual environment versus (2) a real and augmented environment. We have designed an experimental setup based on a Microsoft HoloLens and a haptic force-feedback device, enabling to press a virtual piston, and compare its stiffness successively in either Augmented Reality (the virtual piston is surrounded by several real objects all located inside a cardboard box) or in Virtual Reality (the same virtual piston is displayed in a fully virtual scene composed of the same other objects). We have conducted a psychophysical experiment with 12 participants. Our results show a surprising bias in perception between the two conditions. The virtual piston is on average perceived stiffer in the VR condition compared to the AR condition. For instance, when the piston had the same stiffness in AR and VR, participants would select the VR piston as the stiffer one in 60% of cases. This suggests a psychological effect as if objects in AR would feel ”softer” than in pure VR. Taken together, our results open new perspectives on perception in AR versus VR, and pave the way to future studies aiming at characterizing potential perceptual biases.","1941-0506","","10.1109/TVCG.2017.2735078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007246","Augmented Reality;Virtual Reality;Haptic;Perception;Stiffness;Psychophysical Study","Pistons;Haptic interfaces;Visualization;Augmented reality;Virtual reality;Virtual environments;Physiology;Psychology","augmented reality;force feedback;haptic interfaces;pistons;psychology","VR piston;pure VR;haptic perception;Virtual Reality;Augmented Reality;virtual object;purely virtual environment;real environment;augmented environment;haptic force-feedback device;virtual piston;fully virtual scene;VR condition;Microsoft HoloLens;psychological effect","Adult;Computer Graphics;Equipment Design;Female;Humans;Male;Psychophysics;Touch;Virtual Reality;Young Adult","29","","22","IEEE","10 Aug 2017","","","IEEE","IEEE Journals"
"Analyzing Pedestrian Behavior in Augmented Reality — Proof of Concept","P. Maruhn; A. Dietrich; L. Prasch; S. Schneider","Technical University of Munich, Germany; Technical University of Munich, Germany; Technical University of Munich, Germany; Technical University of Munich, Germany","2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","11 May 2020","2020","","","313","321","With recent advancements in head-mounted displaying technologies, virtual reality pedestrian simulators have become a common tool for traffic safety research. In contrast to field studies, test track studies and traffic observations, simulators enable researchers to analyze pedestrian behavior in a safe and controlled environment. However, creating the necessary virtual environments is time-consuming, especially in terms of meeting today’s expectations regarding graphical level of detail and realism. Furthermore, VR experiments often lack a body representation or require additional sensors to create an avatar. Due to the laboratory setting, VR simulators might fail to convey the feeling of standing on an actual street. In addition, simulators on the one hand and real-world testing on the other hand leave a methodological gap on the reality-virtuality continuum. This paper presents a novel approach for an augmented reality pedestrian simulator. With this simulator, the participant experiences virtual vehicles, augmented on a real scenario, allowing for safe and controlled testing in a realistic setting. In a between-subject design, 13 participants experienced a gap acceptance scenario with virtual vehicles, while 30 participants experienced the same scenario with real vehicles in the same environment. These participants were instructed to initiate a street crossing if they considered that the gap between the two experimental vehicles was safe to cross the street. Results indicate similar, but also offset behavior for both conditions. Lower acceptance rates and later crossing initiation times could be observed in the augmented reality condition. Still, it was shown that augmented reality renders a promising tool for pedestrian research but also features limitations depending on the use case.","2642-5254","978-1-7281-5608-8","10.1109/VR46266.2020.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089506","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Human-centered computing;Human computer interaction (HCI);Empirical studies in HCI;Human-centered computing;Human computer interaction (HCI);Interaction devices;Displays and imagers","Roads;Virtual environments;Cameras;Streaming media;Augmented reality;Safety","augmented reality;avatars;helmet mounted displays;rendering (computer graphics);road traffic;traffic engineering computing;virtual reality","pedestrian behavior;virtual reality pedestrian simulators;traffic safety research;traffic observations;VR experiments;VR simulators;reality-virtuality continuum;augmented reality pedestrian simulator;virtual vehicles;gap acceptance scenario;experimental vehicles;augmented reality rendering;head-mounted displaying technologies","","7","","25","IEEE","11 May 2020","","","IEEE","IEEE Conferences"
"Virtual and augmented reality 2020","L. Rosenblum","Naval Research Laboratory, Inc.","IEEE Computer Graphics and Applications","6 Aug 2002","2000","20","1","38","39","With roots going back to Ivan Sutherland's research in the 1960s, virtual reality (VR) reached a plateau in the early 1990s when the promise was demonstrable in universities and research laboratories. Although we all knew we had a long way to go, hype overtook the field, leading to impossible expectations. Fortunately, a few years later the Internet became the latest hot topic, leaving VR researchers free to go back to work. Almost a decade later, VR has gone from ""almost there"" to ""barely there"". That's a big step! Perhaps by 2020 we will be ""pretty well there""! In this article, I venture a few remarks about progress over the next two decades. However, the safest prediction is that unanticipated science and technology advances will make this forecast seem overly conservative.","1558-1756","","10.1109/38.814551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=814551","","Augmented reality;Virtual reality;Cameras;Computer displays;Magnetic sensors;Haptic interfaces;Biomedical imaging;Wearable computers;Image sensors;Acoustic sensors","virtual reality;augmented reality;technological forecasting","virtual reality;augmented reality;Year 2020;forecast;progress;prediction;unanticipated advances","","21","","","IEEE","6 Aug 2002","","","IEEE","IEEE Magazines"
"[POSTER] Visualizing In-Organ Tumors in Augmented Monocular Laparoscopy","E. Özgür; A. Lafont; A. Bartoli","EnCoV, Université Clermont Auvergne, France; EnCoV, Université Clermont Auvergne, France; EnCoV, Université Clermont Auvergne, France","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","46","51","One of the important goals of medical augmented reality is to reveal the hidden anatomy, such as a tumor in an organ. However, conveying a hidden tumor's depth to the user effortlessly and precisely is still an unsolved problem. This is especially difficult in monocular laparoscopy. First, the number of available depth cues is in practice limited to only two: occlusion and relative size. Second, exploiting these cues is not an easy task either. We propose a specific visualization consisting of auxiliary orthographic tumor silhouettes on the front and back surfaces of the organ and a semi-transparent tumor in between. This creates two depth planes forming a perceivable ratio-scaled metric space for the tumor. We conducted a user study to evaluate the proposed visualization. The results show that subsurface tumor depth perception is improved dramatically compared to the conventional transparent overlay.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088447","erol.ozgur@uca.fr;alexis.lafont@uca.fr;adrien.bartoli@gmail.com","Tumors;Laparoscopes;Visualization;Surgery;Augmented reality;Image color analysis","augmented reality;data visualisation;medical computing;tumours","auxiliary orthographic tumor silhouettes;semitransparent tumor;depth planes;subsurface tumor depth perception;In-Organ Tumors;augmented monocular laparoscopy;medical augmented reality;hidden anatomy;hidden tumor;occlusion;relative size;perceivable ratio-scaled metric space;specific visualization;depth cues","","5","","29","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Retrofitting Realities: Affordances and Limitations in Porting an Interactive Geospatial Visualization from Augmented to Virtual Reality","M. Richardson; D. Jacoby; Y. Coady",University of Victoria Computer Science; University of Victoria Computer Science; University of Victoria Computer Science,"2018 IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)","17 Jan 2019","2018","","","1081","1087","As Augmented Reality (AR) and Virtual Reality (VR) applications become more mainstream, developers now have a number of design decisions that must be carefully considered before choosing a device for an interactive visualization with big data. Unfortunately, understanding the true affordances and limitations of each device, and how these affect the resultant potential to support visual analytics, is still more of a black art than a science. In this paper, we highlight key design decisions and technical challenges in the context of a case study to port an interactive geospatial visualization from an AR device, the Microsoft Hololens, to a mobile VR device, the Google Daydream. Our results show that careful leveraging of backend cloud services can allow for interactive visualizations of big data to scale well across devices.","","978-1-5386-7266-2","10.1109/IEMCON.2018.8614978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614978","Augmented and Virtual Reality;interactive visualizations;geospatial datasets;data analytics;platform porting;cloud processing","Data visualization;Virtual reality;Speech recognition;Google;Cloud computing;Geographic information systems;Games","augmented reality;Big Data;data visualisation;geographic information systems","retrofitting realities;big data;visual analytics;mobile VR device;augmented reality applications;virtual reality applications;design decisions;geospatial visualization;black art;cloud services;Google daydream;Microsoft Hololens;AR device visualization","","","","19","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Active Visualization of Visual Cues on Hand for Better User Interface Design Generalization in Mixed Reality","M. Raza; D. Reilly; J. Malloch","Faculty of Computer Science, Dalhousie University, Halifax, Canada; Faculty of Computer Science, Dalhousie University, Halifax, Canada; Faculty of Computer Science, Dalhousie University, Halifax, Canada","2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","30 Jan 2023","2022","","","149","152","With the emergence of various unique augmented reality devices, researchers are exploring how mixed-reality applications can enhance user experience. We propose a working prototype emphasizing that mixed reality applications should consider incorporating visual cues on the user’s hand for better user experience, in our case representing selected color on the index fingertip. Such a design can assist users in being attentive regarding what color they are using. Eventually, reducing unintended errors occur when the active visual component is not visible in the field of view. Generally, we argue that representing visual cues on the user’s hand has major advantages, including defining a general platform for placing visual cues, immediate response, and preserving computational resources. Most importantly, developers can utilize the general platform to give or place visual feedback in mixed-reality applications. Moreover, we highlight the importance of interacting in mid-air compared to tactile feedback.","2771-7453","978-1-6654-5725-5","10.1109/AIVR56993.2022.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024469","augmented reality;mixed-reality;visual cues;active visualization;user interface design;color selection;hand interaction","Visualization;Mixed reality;Tactile sensors;Prototypes;Color;User interfaces;User experience","augmented reality;data visualisation;human computer interaction;user interfaces;virtual reality","active visual component;active visualization;better user interface design generalization;general platform;mixed reality applications;mixed-reality applications;unique augmented reality devices;user experience;visual cues;visual feedback","","","","18","IEEE","30 Jan 2023","","","IEEE","IEEE Conferences"
"Mixed Reality Extended TV","C. Baillard; V. Alleaume; M. Fradet; P. Jouet; A. Laurent; T. Luo; P. Robert; F. Servant","Technicolor Research & Innovation, Cesson-Sévigné Cedex, France; Technicolor Research & Innovation, Cesson-Sévigné Cedex, France; Technicolor Research & Innovation, Cesson-Sévigné Cedex, France; Technicolor Research & Innovation, Cesson-Sévigné Cedex, France; Technicolor Research & Innovation, Cesson-Sévigné Cedex, France; Technicolor Research & Innovation, Cesson-Sévigné Cedex, France; Technicolor Research & Innovation, Cesson-Sévigné Cedex, France; Technicolor Research & Innovation, Cesson-Sévigné Cedex, France","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","332","333","The Extended TV application allows to enhance an audiovisual content displayed on a TV, using Mixed Reality technology. During preprocessing, the close environment of the TV is scanned using a consumer depth camera. The captured RGB-D data are analyzed, providing models for both the 3D geometry and the lighting of the real scene. During runtime, the TV is watched through a tablet, and virtual objects can apparently come out of the screen and start populating the user's environment. Virtual objects can be occluded by real objects, and virtual shadows are consistent with the real ones.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836528","Mixed Reality;Augmented Reality;entertainment;3D scene analysis;spatial interactions;occlusions;light source analysis;immersive blending","TV;Three-dimensional displays;Virtual reality;Light sources;Solid modeling;Rendering (computer graphics);Cameras","audio-visual systems;augmented reality;computational geometry;data analysis;image capture;screens (display);television applications","mixed reality extended TV application;audiovisual content;consumer depth camera;captured RGB-D data analysis;3D geometry;lighting;tablet;virtual objects;virtual shadows;user environment","","","","","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Robust and unobtrusive marker tracking on mobile phones","D. Wagner; T. Langlotz; D. Schmalstieg","Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","121","124","Marker tracking has revolutionized augmented reality about a decade ago. However, this revolution came at the expense of visual clutter. In this paper, we propose several new marker techniques, which are less obtrusive than the usual black and white squares. Furthermore, we report methods that allow tracking beyond the visibility of these markers further improving robustness. All presented techniques are implemented in a single tracking library, are highly efficient in their memory and CPU usage and run at interactive frame rates on mobile phones.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637337","marker tracking;pixel flow;mobile phones;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;I.4.8 [Image Processing and Computer Vision]: Scene Analysis — Tracking","Pixel;Tracking;Cameras;Robustness;Mobile handsets;Augmented reality;Feature extraction","augmented reality;mobile computing;mobile handsets","mobile phone marker tracking;augmented reality;visual clutter","","68","27","12","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Kinect for interactive AR anatomy learning","Ma Meng; P. Fallavollita; T. Blum; U. Eck; C. Sandor; S. Weidert; J. Waschke; N. Navab","Technische Universität München, München, Germany; Technische Universität München, München, Germany; Technische Universität München, München, Germany; University of South Australia, Adelaide, Australia; University of South Australia, Adelaide, Australia; Chirurgischen Klinik und Poliklinik-Innenstadt, 1MU, München, Germany; Anatornlsche Anstalt der 1MU, München, Germany; Technische Universität München, München, Germany","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","277","278","Education of anatomy is a challenging but crucial element in educating medical professionals, but also for general education of pupils. Our research group has previously developed a prototype of an Augmented Reality (AR) magic mirror which allows intuitive visualization of realistic anatomical information on the user. However, the current overlay is imprecise as the magic mirror depends on the skeleton output from Kinect. These imprecisions affect the quality of education and learning. Hence, together with clinicians we have defined bone landmarks which users can touch easily on their body while standing in front of the sensor. We demonstrate that these landmarks allow the proper deformation of medical data within the magic mirror and onto the human body, resulting in a more precise augmentation.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671803","Augmented Reality;Kinect;Anatomy Learning","Mirrors;Biomedical imaging;Education;Augmented reality;Bones;Computed tomography","augmented reality;biomedical education;bone;computer aided instruction;data visualisation;medical computing","interactive AR anatomy learning;anatomy education;augmented reality;AR magic mirror;intuitive visualization;realistic anatomical information;skeleton output;Kinect;education quality;learning quality;bone landmarks;sensor;medical data deformation;human body","","43","","12","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Semi-automatic Annotations in Unknown Environments","G. Reitmayr; E. Eade; T. W. Drummond","Engineering Department, University of Cambridge, Cambridge, UK; Engineering Department, University of Cambridge, Cambridge, UK; Engineering Department, University of Cambridge, Cambridge, UK","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","67","70","Unknown environments pose a particular challenge for augmented reality applications because the 3D models required for tracking, rendering and interaction are not available ahead of time. Consequently, authoring of AR content must take place on-line. This work describes a set of techniques to simplify the online authoring of annotations in unknown environments using a simultaneous localisation and mapping (SLAM) system. The point-based SLAM system is extended to specifically track and estimate high-level features indicated by the user. The automatic estimation of these complex landmarks by the system relieves the user from the burden of manually specifying the full 3D pose of annotations while improving accuracy. These properties are especially interesting for remote collaboration applications where either user interfaces on handhelds or camera control by the remote expert are limited.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538827","H.5.1 [Information Systems]: Multimedia Information Systems-Augmented Reality;I.4.8 [Image Processing and Computer Vision]: Scene Analysis-Tracking","Simultaneous localization and mapping;Cameras;Application software;Layout;Augmented reality;Collaborative work;Geometry;Shape measurement;Humans;User interfaces","augmented reality;computer vision","semiautomatic annotations;augmented reality;tracking;rendering;simultaneous localisation and mapping system;3D pose;remote collaboration","","38","4","12","IEEE","6 Jun 2008","","","IEEE","IEEE Conferences"
"ARToolkit and Qualcomm Vuforia: An Analytical Collation","A. B. Dos Santos; J. B. Dourado; A. Bezerra","Faculdade de Tecnologia de Lins, Professor Antonio Seabra — FATEC, Lins, SP, Brasil; Faculdade de Tecnologia de Lins, Professor Antonio Seabra — FATEC, Lins, SP, Brasil; Faculdade de Tecnologia de Lins, Professor Antonio Seabra — FATEC, Lins, SP, Brasil","2016 XVIII Symposium on Virtual and Augmented Reality (SVR)","21 Jul 2016","2016","","","229","233","Given the trend toward the use of technologies that allow greater interaction and user immersion with computer systems and mobile applications, augmented reality technology is increasingly present in popular systems in various application domains. To assist in the development of these types of systems using ar technology, various graphic libraries have been developed. This work brings a discussion and an analytical collation in some perspectives of two graphics libraries with ra features: qualcomm vuforia and artoolkit.","","978-1-5090-4149-7","10.1109/SVR.2016.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7517280","Augmented Reality;Qualcomm Vuforia;ARToolkit","Software;Three-dimensional displays;Visualization;Augmented reality;Androids;Humanoid robots","augmented reality;computer graphics","ARToolkit;Qualcomm Vuforia;analytical collation;user immersion;mobile applications;augmented reality technology;graphic libraries","","12","","17","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"GeoBoids: A mobile AR application for exergaming","R. W. Lindeman; Gun Lee; L. Beattie; H. Gamper; R. Pathinarupothi; A. Akhilesh","The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; The Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","93","94","We have designed a mobile Augmented Reality (AR) game which incorporates video see-through and spatialized audio AR techniques and encourages player movement in the real world. In the game, called GeoBoids, the player is surrounded by flocks of virtual creatures that are visible and audible through mobile AR application. The goal is for the player to run to the location of a GeoBoid swarm in the real world, capture all the creatures there, then run to the next swarm and repeat, before time runs out, encouraging the player to exercise during game play. The most novel elements of the game are the use of audio input and output for interacting with the creatures. The interface design of the game includes AR visualization, spatialized audio, touch gestures and whistle interaction. Feedback from users in a preliminary user study was mostly positive on overall game play and the design of the UI, while the results also revealed improvements were needed for whistle interaction and the visual design of the GeoBoids.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483997","Augmented Reality;Exergaming;Spatialized Audio;Mobile;Gaming","Games;Mobile communication;Augmented reality;Visualization;Entertainment industry;Sensors;Cameras","augmented reality;computer games;mobile computing","GeoBoids;mobile AR application;mobile augmented reality game;exergaming;video see-through;spatialized audio AR techniques;game play;AR visualization","","10","","12","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Interaction techniques for HMD-HHD hybrid AR systems","R. Budhiraja; G. A. Lee; M. Billinghurst","The Human Interface Technology Laboratory New Zealand, University of Canterbury; The Human Interface Technology Laboratory New Zealand, University of Canterbury; University of Canterbury, Christchurch, NZ","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","243","244","Most mobile Augmented Reality (AR) systems use either a head mounted display (HMD) or a handheld display (HHD) as a hardware platform. As mobile devices become more affordable, it becomes more common that users own more than one mobile device and use them together. In this research, we investigate Hybrid AR systems that use both HMD and HHD for AR visualization and interaction. In addition to a simple approach of using HMD as a display and HHD as an input device (e.g. a touch pad or a pointer), we further explore novel interaction techniques that can take advantage of having both HMD and HHD closely integrated into one AR system, such as cross-device information sharing, situation adaptive visualization management, and multi-layered visualization.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671786","Mobile augmented reality;wearable computer;headmounted display;handheld display","Visualization;Augmented reality;Mobile communication;Three-dimensional displays;Mobile handsets;Wearable computers;Hardware","augmented reality;data visualisation;helmet mounted displays;human computer interaction;mobile computing","interaction techniques;HMD-HHD hybrid AR system;mobile augmented reality systems;head mounted display;handheld display;mobile devices;AR visualization;AR interaction;cross-device information sharing;situation adaptive visualization management;multilayered visualization","","9","","7","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"BurnAR: Feel the heat","P. Weir; C. Sandor; M. Swoboda; Thanh Nguyen; U. Eck; G. Reitmayr; A. Dey","Magic Vision Lab, University of South Australia, Adelaide, Australia; Magic Vision Lab, University of South Australia, Adelaide, Australia; Fairlight; Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Magic Vision Lab, University of South Australia, Adelaide, Australia; Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Magic Vision Lab, University of South Australia, Adelaide, Australia","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","331","332","Augmented Reality systems that run interactively and in real time, using high quality graphical displays and sensational cues, can create the illusion of virtual objects appearing to be real. This paper presents the design and implementation of BurnAR, a demonstration which enables users to experience the illusion of seeing their own hands burning, which we achieve by overlaying virtual flames and smoke on their hands. Surprisingly, some users reported an involuntary warming sensation of their hands.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402599","H.5.1. [Information Interfaces and Presentation]: Multimedia Information Systems—[Artificial;augmented and virtual realities] H.1.2. [Information Systems]: Models and Principles—[Human factors]","Image color analysis;Streaming media;Cameras;Augmented reality;Image segmentation;USA Councils","augmented reality;flames;smoke;user interfaces","BurnAR;augmented reality system;graphical display;sensational cue;virtual object illusion;user experience;virtual flame;virtual smoke;involuntary warming sensation","","9","","5","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Multitouch interaction for Tangible User Interfaces","H. Seichter; R. Grasset; J. Looser; M. Billinghurst","Human Interface Technology Laboratory, New Zealand; Human Interface Technology Laboratory, New Zealand; Human Interface Technology Laboratory, New Zealand; Human Interface Technology Laboratory, New Zealand","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","213","214","We introduce a novel touch-based interaction technique for tangible user interfaces (TUIs) in Augmented Reality (AR) applications. The technique allows for direct access and manipulation of virtual content on a registered tracking target, is robust and lightweight, and can be applied in numerous tracking and interaction scenarios.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336455","H.5.1 [Information Systems]: Information Interfaces and Presentation;Artificial, augmented, and virtual realities; I.4.6 [Computing Methodologies]: Image Processing and Computer Vision;Edge and feature detection","User interfaces;Target tracking;Fingers;Computer vision;Electronic mail;Robustness;Augmented reality;Computer interfaces;Cameras;Image sampling","augmented reality;target tracking;user interfaces","multitouch interaction;tangible user interface;augmented reality;target tracking","","9","","11","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"A Conceptual Model for Data Collection and Analysis for AR-based Remote Collaboration Evaluation","B. Marques; A. Teixeira; S. Silva; J. Alves; P. Dias; B. Sousa Santos","IEETA, DETI, University of Aveiro, Portugal; IEETA, DETI, University of Aveiro, Portugal; IEETA, DETI, University of Aveiro, Portugal; IEETA, DETI, University of Aveiro, Portugal; IEETA, DETI, University of Aveiro, Portugal; IEETA, DETI, University of Aveiro, Portugal","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","1","2","A significant effort has been devoted to the creation of the enabling technology and in the proposal of novel methods to support remote collaboration using Augmented Reality (AR), given the novelty of the field. As the field progresses to focus on the nuances of supporting collaboration and with the growing number of prototypes mediated by AR, the characterization and evaluation of the collaborative process becomes an essential, but difficult endeavor. Evaluation is particularly challenging in this multifaceted context involving many aspects that may influence the way collaboration occurs. Therefore, it is essential the existence of holistic evaluation strategies that monitor the use and performance of the proposed solutions regarding the team, its members, and the technology, allowing adequate characterization and report of collaborative processes. As a contribute, we propose a conceptual model for multi-user data collection and analysis that monitors several collaboration aspects: individual and team performance, behaviour and level of collaboration, as well as contextual data in scenarios of remote collaboration using AR-based solutions.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288412","Collaboration;Augmented Reality;Evaluation;Conceptual Model","Analytical models;Collaboration;Prototypes;Data collection;Data models;Monitoring;Augmented reality","augmented reality;data acquisition;data analysis;groupware","conceptual model;AR-based remote collaboration evaluation;augmented reality;collaborative process;multiuser data collection;contextual data;data analysis;multifaceted context;team performance","","8","","5","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"A Transitional AR Furniture Arrangement System with Automatic View Recommendation","M. Mori; J. Orlosky; K. Kiyokawa; H. Takemura",Osaka University; Osaka University; Osaka University; Osaka University,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","158","159","Augmented Reality furniture arrangement systems are useful for viewing room or building layouts without having to buy or move real furniture. However, such systems often require users to physically and frequently change their viewpoint of the physical space, which requires manual manipulation of the scene, and are often limited to 2D tablet or phone interfaces. To help address this problem, we have developed a system that automatically calculates the most suitable viewpoint to improve understanding of the room layout as a whole, and allows the user to easily transition to that viewpoint in a head mounted display (HMD) with minimal interaction. Experimental results show that users can grasp the layout more easily with our system compared to a conventional AR interface.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836488","H.5.1 [Multimedia Information Systems]: Artificial;augmented;and virtual realities","Layout;Augmented reality;Solid modeling;Cameras;Electronic mail;Grasping;Headphones","augmented reality;furniture;helmet mounted displays;recommender systems;user interfaces","transitional AR furniture arrangement system;automatic view recommendation;augmented reality furniture arrangement systems;room layouts;building layouts;2D tablet;phone interfaces;head mounted display;HMD","","8","","4","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Tangible interaction techniques to support asynchronous collaboration","A. Irlitti; S. Von Itzstein; L. Alem; B. Thomas","Wearable Computer Lab, University of South Australia, Mawson Lakes, SA, AUS; Wearable Computer Lab, University of South Australia, Mawson Lakes, SA, AUS; CSIRO ICT Centre, Marsfield, NSW, AUS; Wearable Computer Lab, University of South Australia, Mawson Lakes, SA, AUS","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","1","6","Industrial uses of Augmented Reality (AR) are growing, however their uses are consistently fashioned with an emphasis on consumption, delivering additional information to the worker to assist them in the completion of their job. A promising alternative is to allow user data creation during the actual process by the worker performing their duties. This not only allows spatially located annotations to be produced, it also allows an AR scene to be developed in-situ and in real-time. Tangible markers offer a physical interface while also creating physical containers to allow for fluent interactions. This form factor allows both attached and detached annotations, whilst allowing the creation of an AR scene during the process. This annotated scene will allow asynchronous collaboration to be conducted between multiple stakeholders, both locally and remotely. In this paper we discuss our reasoning behind such an approach, and present the current work on our prototype created to test and validate our proposition.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671840","Augmented Reality;Asynchronous Collaboration;Spatial Annotations;Tangible Interaction","Collaboration;Prototypes;Mobile communication;Context;Australia;Augmented reality;Wearable computers","augmented reality;haptic interfaces;human computer interaction","tangible interaction techniques;asynchronous collaboration;augmented reality;job completion;user data creation;AR scene;tangible markers;physical interface;physical containers;fluent interactions;attached annotations;detached annotations","","7","2","11","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"ClonAR: Rapid redesign of real-world objects","M. Csongei; L. Hoang; U. Eck; C. Sandor","Magic Vision Lab, University of South Australia; Magic Vision Lab, University of South Australia; Magic Vision Lab, University of South Australia; Magic Vision Lab, University of South Australia","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","277","278","ClonAR enables users to rapidly clone and edit real-world objects. First, real-world objects can be scanned using KinectFusion. Second, users can edit the scanned objects in our visuo-haptic Augmented Reality environment. Our whole pipeline does not use mesh representation of objects, but rather Signed Distance Fields, which are the output of KinectFusion. We directly render Signed Distance Fields haptically and visually. We do direct haptic rendering of Signed Distance Fields, which is faster and more flexible than rendering meshes. Visual rendering is performed by our custom-built raymarcher, which facilitates realistic illumination effects like ambient occlusions and soft shadows. Our prototype demonstrates the whole pipeline. We further present several results of redesigned real-world objects.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402572","H.5.1. [Information Interfaces and Presentation]: Multimedia Information Systems—[Artificial, augmented and virtual realities];H.5.2. [Information Interfaces and Presentation]: User Interfaces—[Haptic I/O ];H.1.2. [Information Systems]: Models and Principles—[Human factors]","Rendering (computer graphics);Haptic interfaces;USA Councils;Lighting;Real-time systems;Augmented reality;Cloning","augmented reality;haptic interfaces;rendering (computer graphics)","ClonAR;real-world object redesign;KinectFusion;visuo-haptic augmented reality;signed distance fields;haptic rendering;visual rendering;custom-built raymarcher;realistic illumination effect;ambient occlusion;soft shadow","","6","2","8","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"3D fiducials for scalable AR visual tracking","J. Steinbis; W. Hoff; T. L. Vincent","Center for Robotics Automation and Distributed Intelligence, Colorado Schml of Mines, USA; Center for Robotics Automation and Distributed Intelligence, Colorado Schml of Mines, USA; Center for Robotics Automation and Distributed Intelligence, Colorado Schml of Mines, USA","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","183","184","A new vision and inertial pose estimation system was implemented for real-time handheld augmented reality (AR). A sparse set of 3D cone fiducials are utilized for scalable indoor/outdoor tracking, as opposed to traditional planar patterns. The cones are easy to segment and have a large working volume which makes them more suitable for many applications. The pose estimation system receives measurements from the camera and IMU at 30 Hz and 100 Hz respectively. With a dual-core workstation, all measurements can be processed in real-time to update the pose of virtual graphics within the AR display.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637357","Augmented Reality;Pose Estimation;H.5.2 [Information Interfaces and Presentation]: User Interfaces—Graphical User Interfaces","Augmented reality;Image segmentation;Cameras;Three dimensional displays;Distance measurement;Real time systems;Image color analysis","augmented reality;pose estimation;real-time systems","3D fiducials;scalable AR visual tracking;vision pose estimation system;inertial pose estimation system;real-time handheld augmented reality;virtual graphics;frequency 30 Hz;frequency 100 Hz","","5","2","8","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Head-mounted virtual loupe with sight-based activation for surgical applications","A. Martin-Gonzalez; S. -M. Heining; N. Navab","Computer Aided Medical Procedures, TUM, Germany; Trauma Surgery Department, LMU, Germany; Computer Aided Medical Procedures, TUM, Germany","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","207","208","This work presents the development of an augmented reality magnification system, termed virtual loupe, implemented in a head-mounted display for surgical applications. The system provides a magnified view with a novel control based on tracked sight orientation. The system was evaluated by measuring the completion time of a suturing task performed by surgeons. The magnifying approach implemented proved to be useful by providing global context of the operating field. The sight-based activation was widely accepted by surgeons as a useful functionality to control viewing modalities.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336459","Augmented reality;medical visualization;user interaction","Surgery;Cameras;Target tracking;Biomedical imaging;Augmented reality;Computer displays;Visualization;Microscopy;Application software;Medical control systems","augmented reality;helmet mounted displays;medical computing;surgery","head-mounted virtual loupe;sight-based activation;surgical application;augmented reality magnification system","","5","","7","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Camera Time Warp: Compensating Latency in Video See-Through Head-Mounted-Displays for Reduced Cybersickness Effects","J. P. Freiwald; N. Katzakis; F. Steinicke",University of Hamburg; University of Hamburg; University of Hamburg,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","49","50","Camera Time Warp or “CamWarp” is an extension of current reprojection techniques for video see-through augmented reality (AR), which significantly reduces the registration error between captured real-world videos and rendered virtual images. Experiment participants were asked to report discomfort while moving their head in a Fitts' Law inspired pattern. Results suggest that CamWarp can reduce discomfort and cybersickness symptoms for all tested camera configurations. In a second experiment participants were asked to move physical objects on a projected path as quickly and precisely as possible. CamWarp had a positive effect on speed and accuracy.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699171","Human-centered computing—Human computer interaction (HCI)—Epirical studies in HCI×Cyersickness;Human-centered computing—Interaction paradigms×Mixed / augmented reality","Cameras;Head;Augmented reality;Streaming media;Resists;Analysis of variance","augmented reality;cameras;helmet mounted displays;rendering (computer graphics);video signal processing","augmented reality;registration error;CamWarp;camera time warp;cybersickness effects;video see-through head-mounted-displays;Fitts' law inspired pattern","","4","","9","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Intention to use an interactive AR app for engineering education","A. Álvarez-Marín; J. Á. Velázquez-Iturbide; M. Castillo-Vergara","Departamento de Ingeniería Industrial, Universidad de La Serena, La Serena, Chile; Departamento de Informática y Estadística, Universidad Rey Juan Carlos, Móstoles, Madrid, Spain; Facultad de Economía y Negocios, Universidad Alberto Hurtado, Santiago, Chile","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","70","73","Augmented reality (AR) has been incorporated into educational processes in various subjects to improve academic performance. One of these areas is the field of electronics since students often have difficulty understanding electricity. An interactive AR app on electrical circuits was developed. The app allows the manipulation of circuit elements, computes the voltage and amperage values using the loop method, and applies Kirchhoff's voltage law. This research aims to determine the intention of using the AR app by students. It also looks to determine if it is conditioned by how the survey is applied (online or face-to-face) or students' gender. The results show that the app is well evaluated on the intention of use by students. Regarding how the survey is applied, the attitude towards using does not present significant differences. In contrast, the students who carried out the online survey presented a higher behavioral intention to use than those who participated in the guided laboratory. Regarding gender, women showed a higher attitude toward using and behavioral intention to use this technology than men.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00033","Ministry of Economy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288398","Augmented reality;technology acceptance;engineering;education","Engineering education;Augmented reality","augmented reality;computer aided instruction;engineering education","engineering education;augmented reality;educational processes;academic performance;electricity;electrical circuits;circuit elements;amperage values;Kirchhoff voltage law;AR app;students;online survey;behavioral intention","","3","","13","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Design of an AR marker for cylindrical surface","A. Suzuki; Y. Manabe; N. Yata",Chiba University; Chiba University; Chiba University,"2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","293","294","This paper proposes an augmented reality marker that can be robustly detected even on a cylindrical surface. The marker enables the surface normal estimation of a cylindrical object to realize the presentation of appropriate virtual information on the object. Conventional markers have difficulty detecting and obtaining accurate surface normal in the presence of occlusion or distortion of the marker in the image. Furthermore, it is difficult to identify a feature on a cylindrical object on which to position a marker. These problems are resolved by relying on the characteristic that a line parallel to the central axis of the cylinder maintains linearity. In addition, surface normal is calculated by estimating the object's shape by using transformation matrices.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671811","Augmented reality;Marker;Cylindrical surface","Estimation;Augmented reality;Vectors;Multimedia communication;Cameras;Silicon","augmented reality;matrix algebra","AR marker;cylindrical surface;augmented reality marker;surface normal estimation;virtual information;transformation matrices","","3","","2","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Real-time representation of inter-reflection for cubic marker","Y. Uranishi; A. Ihara; H. Sasaki; Y. Manabe; K. Chihara","Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Kobe University, Japan; Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","217","218","This paper proposes a method for rendering an inter-reflection between a marker and a glossy floor in Augmented Reality (AR). At first, a reflectance ratio of the floor is estimated from the reflection on the floor and from the marker box directly. Then the roughness of the floor is estimated based on the sharpness of the reflected marker box image on the floor. Lastly, the marker box reflection is eliminated based on the surrounding colors of the marker box reflection. Rendered images show that natural inter-reflection can be achieved by using the proposed method.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336457","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems;Artificial, Augmented, and Virtual Realities","Optical reflection;Reflectivity;Rendering (computer graphics);Electronic mail;Cameras;Light sources;Rough surfaces;Surface roughness;Augmented reality;Mirrors","augmented reality;rendering (computer graphics)","real-time representation;cubic marker box reflection;inter-reflection image rendering;augmented reality;reflectance ratio;glossy floor estimation","","3","","9","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Moveillance: Visualizing Electric Machines","S. Mann; D. E. Garcia; P. V. Do; D. Lam; P. Scourboutakos","MannLab Canada 330 Dundas Street West, Toronto, Ontario, Canada; MannLab Canada 330 Dundas Street West, Toronto, Ontario, Canada; MannLab Canada 330 Dundas Street West, Toronto, Ontario, Canada; MannLab Canada 330 Dundas Street West, Toronto, Ontario, Canada; MannLab Canada 330 Dundas Street West, Toronto, Ontario, Canada","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","420","424","We introduce a novel method of researching, understanding, and visualizing fundamentals of electric machines through the use of augmented reality (AR). The otherwise hidden rotating electromagnetic (EM) fields inside electric motors and generators are made visible with Sequential Wave Imprinting Machines (SWIMs). By attaching one or more SWIMs to the machine's rotating frame, the system reveals the electric machine's inner workings. Changes to these waves directly reflect changes in the controller and its parameters, for example, load or timing. Finally, we discuss the useful insights provided by AR for load analysis and motor control, using the visualized Waveform patterns from a three-phase motor.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262613","Augmented reality (AR);signal visualization;design engineering;electric machines;Sequential Wave Imprinting Machine (SWIM)","Visualization;Motor drives;Generators;Timing;Magnetic fields;Augmented reality;Electric motors","augmented reality;computer aided instruction;data visualisation;electric machines;electric motors;electrical engineering education;student experiments;waveform analysis","augmented reality;hidden rotating electromagnetic fields;electric motors;SWIM;electric machine;load analysis;motor control;sequential wave imprinting machines;visualized electric machines;visualized waveform patterns","","3","","12","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"Retrospective Speech Balloons on Speech-Visible AR via Head-Mounted Display","T. Kurahashi; R. Sakuma; K. Zempo; K. Mizutani; N. Wakatsuki","Graduate School of Systems and Information Engineering, University of Tsukuba, Japan; College of Information Science, University of Tsukuba, Japan; Faculty of Engineering, Information and Systems, University of Tsukuba, Japan; Faculty of Engineering, Information and Systems, University of Tsukuba, Japan; Faculty of Engineering, Information and Systems, University of Tsukuba, Japan","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","423","424","It was confirmed speech balloon captioning shown in 3 dimensional space (such as Augmented Reality) were better than caption shown in 2 dimension screen with the aim of information insurance for people with hearing impairment in previous research. In this research, we reconfirmed that multi line captions contributes to the user's comprehension of the speech balloon contents better than the single line caption. This research has also found that the system's ability which enables the user to look back on the previous parts of the conversation leads to the improvement of the user experience. In addition, when the amount of sentences increases, the captions presented not as a log, but as multi speech balloons like comics are more natural and do not obstruct the user's view.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699323","Support for person with hearing impairment;speech recognition;scroll type caption;speech Balloon;Human-centered computing—Accessibility—Accessibility systems and tools;Human-centered computing— Interaction paradigms—Mixed / augmented reality","Resists;Speech recognition;Auditory system;Face;Head-mounted displays;Cameras;Augmented reality","augmented reality;handicapped aids;hearing;helmet mounted displays;speech processing;user experience","information insurance;hearing impairment;multiline captions;user experience;multispeech balloons;retrospective speech balloons;speech-visible AR;head-mounted display;augmented reality;speech balloon captioning","","2","","7","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Learning Object and State Models for AR Task Guidance","W. Hoff; H. Zhang","Division of Computer Science, Colorado School of Mines, Golden, CO; Division of Computer Science, Colorado School of Mines, Golden, CO","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","272","273","We present a method for automatically learning object and state models, which can be used for recognition in an augmented reality task guidance system. We assume that the task involves objects whose appearance is fairly consistent, but the background may vary. The novelty of our approach is that the system can be automatically constructed from examples of experts performing the task. As a result, the system can be easily adapted to new tasks. The approach makes use of the fact that the key features of the object are consistently present in multiple viewing instances; whereas features from the background or irrelevant objects are not consistently present. Using information theory, we automatically identify the features that can best discriminate between object states. In evaluations, our prototype successfully recognized object states in all trials.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836514","State recognition;egocentric vision;augmented reality;task guidance","Maintenance engineering;Databases;Feature extraction;Training;Augmented reality;Printers;Entropy","augmented reality;information theory;learning (artificial intelligence);object recognition","object models;state models;AR task guidance;augmented reality task guidance system;multiple viewing instances;information theory;object state recognition;learning","","2","","6","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Towards In-situ Authoring of AR Visualizations with Mobile Devices","M. Satkowski; W. Luo; R. Dachselt",Interactive Media Lab Technische Universität Dresden; Interactive Media Lab Technische Universität Dresden; Interactive Media Lab Technische Universität Dresden,"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","324","325","Augmented Reality (AR) has been shown to enhance the data visualization and analysis process by supporting users in their immersive exploration of data in a real-world context. However, authoring such visualizations still heavily relies on traditional, stationary desktop setups, which inevitably separates users from the actual working space. To better support the authoring process in immersive environments, we propose the integration of spatially-aware mobile devices. Such devices also enable precise touch interaction for data configuration while lowering the entry barriers of novel immersive technologies. We therefore contribute an initial set of concepts within a scenario for authoring AR visualizations. We implemented an early prototype for configuring visualizations in-situ on the mobile device without programming and report our first impressions.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00073","Deutsche Forschungsgemeinschaft; Technische Universität Dresden; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585802","Human-centered computing;Mixed/Augmented Reality;Visualization","Data visualization;Prototypes;Mobile handsets;Augmented reality;Space stations","augmented reality;authoring systems;data analysis;data visualisation;human computer interaction;mobile computing","AR visualizations;augmented reality;data visualization;immersive environments;spatially-aware mobile devices;touch interaction;data configuration;immersive technologies;in-situ authoring;data analysis","","1","","8","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"A Study in Virtual Navigation Cues for Forklift Operators","A. Pereira; G. A. Lee; E. Almeida; M. Billinghurst","Detel, IFCE, Fortaleza, Brazil; HIT Lab NZ, University of Canterbury, Christchurch, New Zealand; Detel, IFCE, Fortaleza, Brazil; School of ITMS, University of South Australia, Adelaide, Australia","2016 XVIII Symposium on Virtual and Augmented Reality (SVR)","21 Jul 2016","2016","","","95","99","Augmented Reality (AR) is a technology that can overlap virtual elements over the real world in real time. This research focuses on studying how different AR elements can help forklift operators locate pallets as quickly as possible in a warehouse environment. We have developed a simulated AR environment to test Egocentric or Exocentric virtual navigation cues. The virtual elements were displayed to the user in a HUD (head-up display) on the forklift windshield, fixed place in front of the user operator, or in a HMD (head-mounted display), where the virtual cues are attached to the head of the user. A user study found that the Egocentric AR view was preferred over the Exocentric condition and performed better while the HUD and HMD viewing methods produced no difference in performance.","","978-1-5090-4149-7","10.1109/SVR.2016.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7517259","Augmented Reality;logistics;forklift;navigation","Navigation;Vehicles;Solid modeling;Three-dimensional displays;Augmented reality;Automotive components;Australia","augmented reality;fork lift trucks;head-up displays;helmet mounted displays;human computer interaction;palletising;warehouse automation","forklift operators;augmented reality;virtual elements;pallet location;warehouse environment;simulated AR environment;egocentric virtual navigation cues;exocentric virtual navigation cues;HUD;head-up display;forklift windshield;HMD;head-mounted display;egocentric AR view","","1","","17","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"MiXR: A Hybrid AR Sheet Music Interface for Live Performance","S. Kohen; C. Elvezio; S. Feiner",Columbia University; Columbia University; Columbia University,"2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","76","77","Musicians face a number of issues when performing live, including organizing and annotating sheet music. This can be an unwieldy process, as musicians need to simultaneously read and manipulate sheet music and interact with the conductor and other musicians. Augmented Reality can provide a way to ease some of the more cumbersome aspects of live performance and practice. We present MiXR, a novel interactive system that combines an AR headset, a smartphone, and a tablet to allow performers to intuitively and efficiently manage and annotate virtual sheet music in their physical environment. We discuss our underlying motivation, the interaction techniques supported, and the system architecture.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00035","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288469","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Applied computing;Arts and Humanities;Sound and music computing;Human-centered computing;Ubiquitous and mobile computing;Ubiquitous and mobile devices;Smartphones;Tablet computers","Performance evaluation;Headphones;Interactive systems;Music;Systems architecture;Augmented reality;Faces","augmented reality;mobile computing;music;smart phones;user interfaces","live performance;musicians;MiXR;virtual sheet music;hybrid AR sheet music interface;augmented reality;AR headset;smartphone;tablet","","1","","14","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Psychophysical exploration of stereoscopic pseudo-transparency","M. Otsuki; P. Milgram","Ritsumeikan Daigaku, Kyoto, Kyoto, JP; Dept. Mechanical & Industrial Engineering, University of Toronto, Canada","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","283","284","We report an experiment related to perceiving (virtual) objects in the vicinity of (real) surfaces when using stereoscopic augmented reality displays. In particular, our goal was to explore the effect of various visual surface features on both perception of object location and perception of surface transparency. Surface features were manipulated using random dot patterns on a simulated real object surface, by manipulating dot size, dot density, and whether or not objects placed behind the surface were partially occluded by the surface.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671806","Human factors;stereoscopic augmented reality;pseudo-transparency;transparency perception","Augmented reality;Surface texture;Stereo image processing;Surface treatment;Visualization;Educational institutions;Three-dimensional displays","augmented reality;stereo image processing;three-dimensional displays","psychophysical exploration;stereoscopic pseudo-transparency;virtual objects;real object surface;stereoscopic augmented reality display;visual surface features;object location perception;surface transparency perception;surface features;random dot patterns;dot size manipulation;dot density manipulation","","1","","6","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Aurasma: A Tool for Education","V. R. Barbosa Holzschuh; T. N. Bogoni","Department of Information System, Mato Grosso State University, Colíder, MT, Brazil; Department of Information System, Mato Grosso State University, Colíder, Brazil","2017 19th Symposium on Virtual and Augmented Reality (SVR)","20 Nov 2017","2017","","","257","260","This paper is a preliminary result of a investigation on use the Augmented Reality Aurasma application in the teaching-learning in Geography teaching support process. A field study with qualitative data collection was carried out to identify the applicability of the system in a public school. In this methodology initially we were trainning the teacher to use the Aurasma and later the system was used in the classroom with 9 students. At the end of experiment, questionnaires were applied to the teacher and students to collect their impressions about the tool. Preliminary data indicate to an improvement of the teaching-learning process, leaving the student more focused in the classroom, however, new experiments with more students and teachers are needed to obtain more precise conclusions.","","978-1-5386-3588-9","10.1109/SVR.2017.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114446","Augmented Reality;Educational Informatics;Mobile Devices in Education","Smart phones;Bills of materials;Augmented reality;Education;Tools;Information systems;Androids","augmented reality;computer aided instruction;educational institutions;geography;teaching","qualitative data collection;public school;teaching-learning process;augmented reality Aurasma application;geography teaching support process","","1","","14","IEEE","20 Nov 2017","","","IEEE","IEEE Conferences"
"AR-Chat: an AR-based instant messaging system","P. Jouet; V. Alleaume; A. Laurent; M. Fradet; T. Luo; C. Baillard","InterDigital, Rennes, France; InterDigital, Rennes, France; InterDigital, Rennes, France; InterDigital, Rennes, France; InterDigital, Rennes, France; InterDigital, Rennes, France","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","153","157","We describe a multi-user system enabling instant messaging in Augmented Reality. A user can get in contact with another one without requiring his/her identification number and can easily localize the person initiating the contact. It is also possible to exchange various types of personal information in a private manner. This innovative type of social interaction can significantly increase consumer interest for AR experiences.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288380","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Computer systems organization;Architectures;Distributed architectures;Client-server architectures","Solid modeling;Three-dimensional displays;Protocols;Prototypes;Instant messaging;Servers;Augmented reality","augmented reality;data privacy;electronic messaging;Internet;user experience","AR-Chat;instant messaging system;multiuser system;augmented reality;identification number;personal information;social interaction;AR experiences","","1","","16","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"AR Mini-Games for Supermarkets","U. Riedlinger; L. Oppermann; Y. Uzun; C. Brosda",Fraunhofer FIT; Fraunhofer FIT; Fraunhofer FIT; Fraunhofer FIT,"2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","19","20","We present an Augmented Reality (AR) application intended for use in supermarkets, with the primary goal to bring fun and digital engagement through AR mini-games to the customers while shopping. We believe that our approach can be extended and scaled up by integrating mini-games into existing shopping apps in the future.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287827","Human-centered computing;Ubiquitous and mobile computing systems and tools;Human-centered computing;Mixed / augmented reality","Augmented reality;Mobile computing","augmented reality;computer games;human computer interaction;interactive systems;mobile computing;retail data processing","AR mini-games;supermarkets;augmented reality application;digital engagement;shopping apps","","","","12","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Compact Object Representation of a Non-Rigid Object for Real-Time Tracking in AR Systems","T. Wang; X. Qin; F. Zhong; X. Tong; B. Chen; M. C. Lin","Shandong University, Jinan, Shandong, CN; Shandong University, Jinan, Shandong, CN; Shandong University, Jinan, Shandong, CN; Shandong University, Jinan, Shandong, CN; Shandong University, Jinan, Shandong, CN; University System of Maryland, Adelphi, MD, US","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","63","68","Detecting moving objects in the real world with reliability, robustness and efficiency is an essential but difficult task in AR applications, especially for interactions between virtual agents and real pedestrians, motorcycles and more, where the spatial occupancy of non-rigid objects should be perceived. In this paper, a novel object tracking method using visual cues with pre-training is proposed to track dynamic objects in 2D online videos robustly and reliably. The object's area in images can be transformed to 3D spatial area in the physical world with some simple, well-defined constraints and priors, thus spatial collision of agents and pedestrians can be avoided in AR environments. To achieve robust tracking in a markerless AR environment, we first create a novel representation of non-rigid objects, which is actually the manifold of normalized sub-images of all the possible appearances of the target object. These sub-images, captured from multiple views and under varying lighting conditions, are free from any occlusion and can be obtained from both video sequences and synthetic image generation. Then, from the instance pool made up of these sub-images, a compact set of templates which can well represent the manifold is learned by our proposed iterative method using sparse dictionary learning. We ensure that this template set is complete by using an SVM-based sparsity detection method. This compact, complete set of templates is then used to track the target trajectory online in video and augmented reality (AR) systems. Experiments demonstrate the robustness and efficiency of our method.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699328","Computing methodologies—Mixed / augmented reality;Computing methodologies—Appearance and texture representations;Computing methodologies—Tracking;Computing methodologies—Spatial and physical reasoning","Augmented reality","augmented reality;image motion analysis;image representation;image sequences;iterative methods;learning (artificial intelligence);object detection;object tracking;support vector machines;video signal processing","nonrigid object;moving objects;robust tracking;object representation;object tracking method;AR systems;2D online videos;video sequences;synthetic image generation;iterative method;sparse dictionary learning;SVM;augmented reality","","","","","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Effective Registration for Multiple Users AR System","W. -J. Chen; C. -W. Chen; J. Wang; M. -D. Shieh","Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Himax Technologies, Inc.; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","270","271","Registration is an important task in augmented reality (AR) systems. For markerless AR, feature descriptors are generally used as a basis of registration process, which is expected to be robust for various application scenarios. This work aims at exploring effective schemes to improve the registration results, especially for applications with large viewpoint angles. Using the proposed scheme, the registration error can be reduced by only evaluating feature points near the virtual object and within the region of interest. Experimental results reveal that about 30% to 50% registration error and 10 times data size of features can be reduced by applying the proposed schemes. Thus, the bandwidth requirement for transmitting features among different users is also decreased accordingly.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836513","Multi-users augmented reality (AR) system;virtual object registration;computer vision","Augmented reality;Robustness;Computer vision;Feature extraction;Transmission line matrix methods;Signal processing algorithms;Bandwidth","augmented reality;computer vision;feature extraction","viewpoint angle;registration process;feature descriptors;markerless AR;augmented reality system;multiple users AR system","","","1","7","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"AR-based visibility evaluation for preserving landscapes of historical buildings","N. Yabuki; K. Miyashita; T. Fukuda","Division of Sustainable Energy and Environmental Engineering, Osaka University, Suita, Osaka, Japan; Hyogo, Japan; Division of Sustainable Energy and Environmental Engineering, Osaka University, Suita, Osaka, Japan","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","281","282","Building tall structures behind an aesthetic and historical building tends to destroy the good landscape. To avoid such situations, public agencies must regulate height of buildings and other structures near the landscape target. In order to check the visibility of portions of high, future structures, in this research, a new method using Augmented Reality (AR) was proposed. In this method, a number of virtual rectangular objects with a scale are located on the grid of 3D geographical model. And then, the virtual rulers are shown in an overlapping manner with the actual landscape from multiple viewpoints using the AR technology. The user measures the maximum skyline-preserving height for each rectangular object at a grid point. Using the measured data, the government or public agencies can establish appropriate height regulations for all surrounding areas of the target structures. To verify the proposed method, a system was developed deploying AR Toolkit and was applied to a scenic building. The performance of the system was checked and then, the errors of the obtained data were evaluated. In conclusion, the proposed method was evaluated feasible and effective.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643607","Augmented reality;landscape;invisible depth","Buildings;Augmented reality;Cameras;Accuracy;Three dimensional displays;Solid modeling;Prototypes","augmented reality;building;computational geometry;data visualisation;solid modelling;structural engineering computing","AR based visibility evaluation;preserving landscape;historical building;building height regulation;Augmented Reality;skyline preserving height;AR toolkit;3D geographical model;virtual rulers;scenic building","","","","4","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"A Comparative Study of Matching Algorithms for Natural Markers","C. Forte; R. Ribani; B. Silveira; M. Marengoni; J. Bolter","School of Literature, Media and Communication, Americana, Brasil; Programa de Pós-Graduação em Engenharia Elétrica, Paulo, Brasil; School of Literature, Media and Communication, Americana, Brasil; Programa de Pós-Graduação em Engenharia Elétrica, Paulo, Brasil; Universidade Presbiteriana Mackenzie, Atlanta, USA","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","96","101","Natural markers are increasingly being adopted by the Augmented Reality (AR) community. These systems require several steps of data processing to be carried out with the aim of allowing a less parameterized image be recognized by the computer system. Among the possibilities for this task there are the proposals that employ interest points (or feature points). The steps needed to process the natural markers using interest points include the matching (usually between one image representation and the video stream). Even having these options well known in the community, try to minimize the processing time or improve the results in terms of accuracy of matching is especially important to the development of AR applications. In this paper, we discuss the results of three comparative studies that demonstrate the advantages and disadvantages of the algorithms FLANN and Brute Force when employed in the matching step of natural markers using interest points. As one of the results, we show that in some cases, the algorithm with most computational complexity can be the better choice.","","978-1-4799-4261-9","10.1109/SVR.2014.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913077","Natural Markers;Computer Vision;Augmented Reality","Image resolution;Robustness;Hardware;Augmented reality;Communities;Streaming media;Force","augmented reality;computational complexity;computer vision;image matching;image representation;video signal processing","image matching algorithms;natural markers;augmented reality;less parameterized image recognition;interest points;feature points;image representation;video stream;FLANN algorithms;brute force algorithms;computational complexity","","","","12","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"AR-enabled wayfinding kiosk","A. Edwards; B. Elmer; B. S. Kim; K. Smith","Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA","2010 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","22 Nov 2010","2010","","","65","66","This paper summarizes the implementation of Augmented Reality technology in proof of concept kiosk intended to improve wayfinding in Pittsburgh, Pennsylvania's Oakland community. It addresses the appropriateness of the technology for the specific needs of the community as well as its relevance to the objectives of the client. In addition, it considers the unexpected successes and unfortunate failures discovered during early user testing.","2381-8360","978-1-4244-9342-5","10.1109/ISMAR-AMH.2010.5643292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643292","Augmented reality;wayfinding","Augmented reality;Communities;Testing;Cities and towns;Business;Navigation;Technological innovation","augmented reality","AR-enabled wayfinding kiosk;augmented reality technology;Pittsburgh wayfinding;Pennsylvania Oakland community;early user testing","","","","2","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Full-Scale Visualization of a Person on a Movable Transparent Screen","A. Oikawa; I. Kitahara; Y. Kameda; Y. Ohta","Graduate School of Systems and Information Engineering, University of Tsukuba, Japan; Center for Computational Studies, University of Tsukuba, Japan; Center for Computational Studies, University of Tsukuba, Japan; University of Tsukuba, Japan","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","51","52","We propose to visualize pre-recorded activity of a person on a movable transparent screen for in-situ reviewing of his/her activity in augmented reality fashion. Activity of the target person was taken as a video by a surveillance camera. Viewers can watch the activity in the scene as if it happened there because segmented image of the target person was projected onto a human-size transparent screen and other static objects around the target person can be visible throughout the transparent screen. Our final goal is to move the transparent screen by mounting it on a small robot and moves the robot to follow the target person in the video. On the way to the final goal, we currently assume that the viewers move the screen manually so as to pose the screen at the same location of the target person in the video. A tracking method of the transparent screen in the scene is devised by utilizing projector-camera calibration and simple infrared marker tracking.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836458","Spatial augmented reality;projector camera calibration;infrared marker;surveillance camera","Cameras;Surveillance;Calibration;Visualization;Augmented reality;Motion segmentation","augmented reality;data visualisation;image segmentation;robots;video cameras;video surveillance","full-scale visualization;movable transparent screen;augmented reality;video surveillance camera;image segmentation;human-size transparent screen;small robot;target person;tracking method;projector-camera calibration;infrared marker tracking","","","","6","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"AR-HMD Multitask Viewing System Concept with a Supporting Handheld Viewport for Multiple Spatially-Anchored Workspaces","S. Y. Oh; B. Yoon; W. Woo",KAIST UVR Lab; KAIST UVR Lab; KAIST UVR Lab,"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","812","813","We propose a system concept for Augmented Reality Head-Mounted Display users, which supports multitask viewing with multiple vir-tual workspaces anchored in the real-world space. Although people encounter multitasking necessities frequently, the native AR HMD and existing interfaces lack measures to visualize multiple sets of spatially-anchored information in parallel. The system separately vi-sualizes two different sets of spatially-anchored information, one on each AR HMD and smartphone, enabling side-by-side multitasking on AR HMD without applying heavy load on users. We implemented a proof-of-concept prototype that allows side-by-side viewing of the two different virtual workspaces. The proposed concept shows promises of multitasking on AR HMD, and future research will de-velop the system to be fully functional and verified with user studies.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974238","Human-centered computing [Mixed / augmented reality];[Human-centered computing]: User interface programming-","Visualization;Head-mounted displays;Prototypes;Resists;Multitasking;Augmented reality","augmented reality;data visualisation;helmet mounted displays","AR-HMD multitask viewing system concept;augmented reality head-mounted display users;handheld viewport;multiple spatially-anchored workspaces;multiple virtual workspaces;multitasking necessities;proof-of-concept prototype;real-world space;side-by-side multitasking;side-by-side viewing;smartphone;spatially-anchored information;virtual workspaces","","","","7","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Objective Measurements of Background Color Shifts Caused by Optical See-Through Head-Mounted Displays","D. Hirobe; Y. Uranishi; J. Orlosky; S. Shirai; P. Ratsamee; H. Takemura","Osaka University, Japan; Osaka University, Japan; Augusta University, United States Osaka University, Japan; Osaka University, Japan; Osaka Institute of Technology, Japan; Osaka University, Japan","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","389","390","Optical see-through head-mounted displays (OST-HMDs) have been increasingly used in research and industrial applications as Augmented Reality (AR) support devices. However, problems still exist that prevent their use as general-purpose devices. One of these issues is the color blending problem between content and background colors. More specifically, the light from the background overlaps with the light from the OST-HMD and shifts the color of OST-HMD's light from its intended display intensity and color. Though color compensation methods exist, in order to properly compensate for light shifts, we need to know how the background color will affect the light that eventually hits the user's eye when combined with the OST-HMD image. In this paper, we study how background colors shift as a result of passing through the OST-HMD's optics in order to better inform the development of color compensation methods. We measured the background color objectively for the Magic Leap 1, the HoloLens (first gen), and the HoloLens 2 and evaluated results. We found that all three OST-HMDs shift background color to a perceptible degree, and that the degree of shift depends on the original background color.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974531","Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Mixed/augmented reality","Head-mounted displays;Image color analysis;Optical variables measurement;Optical imaging;Augmented reality;Optical devices","augmented reality;helmet mounted displays;image colour analysis","Augmented Reality support devices;background color shifts;background colors shift;color blending problem;color compensation methods;general-purpose devices;head-mounted displays;industrial applications;intended display intensity;light shifts;objective measurements;original background color;OST-HMD image;OST-HMD's optics;OST-HMDs shift background color","","","","6","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"[Poster] Device vs. user perspective rendering in google glass AR applications","J. P. Lima; R. Roberto; J. M. Teixeira; V. Teichrieb","DEINFO/UFRPE Voxar Labs, Cln/UFPE; Voxar Labs, Cln/UFPE; DEINFO/UFRPE Voxar Labs, Cln/UFPE; Voxar Labs, Cln/UFPE","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","279","280","According to Gartner's 2013 Hype Cycle for Emerging Technologies, Augmented Reality will reach its Plateu of Productivity before Wearable User Interfaces. In this work, device and user-perspective rendering are compared regarding their applicability to AR-based solutions for Google Glass. The conducted experiment measured and evaluated the advantages and drawbacks on each method and also got positive and negative feedbacks given by users. The tests showed that users preferred the device-perspective approach.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948449","H.5.1 [Information Interfaces and Presentation];Multimedia Information Systems — Artificial, Augmented, Virtual Realities","Glass;Calibration;Google;Rendering (computer graphics);Cameras;Augmented reality;Optical sensors","augmented reality;interactive devices;rendering (computer graphics)","device rendering;user perspective rendering;Google Glass AR application;augmented reality;Hype Cycle for Emerging Technologies;wearable user interfaces;device-perspective approach","","","","6","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Designing a Multitasking Interface for Object-aware AR applications","B. Huynh; J. Orlosky; T. Höllerer","University of California, Santa Barbara; Osaka University; University of California, Santa Barbara","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","39","40","Many researchers and industry professionals believe Augmented Reality (AR) to be the next step in personal computing. However, the idea of an always-on context-aware AR device presents new and unique challenges to the way users organize multiple streams of information. What does multitasking look like and when should applications be tied to specific elements in the environment? In this exploratory study, we look at one such element: physical objects, and explore an object-centric approach to multitasking in AR. We developed 3 prototype applications that operate on a subset of objects in a simulated test environment. We performed a pilot study of our multitasking solution with a novice user, domain expert, and system expert to develop insights into the future of AR application design.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288472","Human-centered computing;Mixed / augmented reality;Human-centered computing;User interface design","Industries;Prototypes;Multitasking;Augmented reality","augmented reality","object-centric approach;AR application design;multitasking interface;augmented reality;personal computing;context-aware AR device;physical objects;object-aware AR applications","","","","4","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Hybrid Reality based Education Expansion System for Intelligent Learning","F. Khan; J. Ahamed","Higher Colleges of Technology, Dubai, United Arab Emirates; Higher Colleges of Technology, Dubai, United Arab Emirates","2020 Seventh International Conference on Information Technology Trends (ITT)","19 Jan 2021","2020","","","224","227","Most educators use traditional teaching method to conduct the teaching and learning activities in the classroom by the face-to-face method via verbal communication. However, the teaching and learning environment has grown beyond the classroom. The integration of technology in the teaching and learning process is the new trend in education, with a positive outcome. Technologies provide an environment for learning activities to occur anytime and anywhere that benefits educators and learners across the globe. One of the skills that have been showing possibilities of the appliance in educational environments is the Hybrid Reality (HR), including both Virtual Reality (VR) and Augmented Reality (AR). This work tries to build upon the current state of hybrid reality and its application in education. The first segment describes the basic structure of hybrid reality and its different parts. Following segments give a definitive structure of some innovative applications that developed for the hybrid reality. Lastly, the paper shows the benefits of those applications over the traditional teaching methods and the essential user reactions to them.","","978-1-7281-8379-4","10.1109/ITT51279.2020.9320784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320784","Virtual Reality;Augmented Reality;Hybrid Reality;Mobile Devices","Education;Augmented reality;Market research;Virtual environments;Three-dimensional displays;Information technology;Conferences","augmented reality;computer aided instruction;distance learning;teaching","classroom;educational environments;intelligent learning;teaching;learning activities;face-to-face method;learning environment;verbal communication;virtual reality;augmented reality;user reactions;hybrid reality based education expansion system","","1","","15","IEEE","19 Jan 2021","","","IEEE","IEEE Conferences"
"Words in Kitchen: An Instance of Leveraging Virtual Reality Technology to Learn Vocabulary","T. Jia; Y. Liu","Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology; Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","150","155","Vocabulary is an essential part in second language learning. The traditional way of learning vocabulary is dull and boring in class with thin context. Nevertheless, a rich context for memorizing words is necessary according to the situated learning theory. Thanks to virtual reality (VR) technology, such a rich context can be achieved by creating a virtual simulation scenario. ""Words In Kitchen"" is a VR system designed as an educational tool for second language learners to learn vocabulary. With the help of the proposed system, a user can interact with virtual objects in the virtual scene to learn the spelling and pronunciation of specific vocabularies. We aim to make full use of immersion and interaction of VR and propose a prototype of vocabulary learning in VR, so that the system can promote learners' common vocabulary learning as a supplement to class and textbooks. A pilot study was conducted to identify its usability and enjoyment and the result indicated that the system could help remember words and stimulate interests.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951900","Language learning, education, virtual reality","Vocabulary;Task analysis;Education;Games;Augmented reality;Tools","computer aided instruction;linguistics;virtual reality;vocabulary","pronunciation;spelling;educational tool;words memorization;Words in Kitchen;second language learning;virtual reality technology;vocabulary learning;virtual scene;virtual objects;language learners;VR system;virtual simulation scenario;situated learning theory","","4","","15","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Markerless Augmented Reality Application for Interior Designing","N. R R; R. M; R. B. S; S. Sultana; N. M. Nadig","Department of Computer Science, The National Institute of Engineering, Mysuru, India; Department of Computer Science, The National Institute of Engineering, Mysuru, India; Department of Computer Science, The National Institute of Engineering, Mysuru, India; The National Institute of Engineering, Mysuru, India; Department of Computer Science, The National Institute of Engineering, Mysuru, India","2022 Second International Conference on Advanced Technologies in Intelligent Control, Environment, Computing & Communication Engineering (ICATIECE)","24 Feb 2023","2022","","","1","5","Markerless Augmented Reality - by using the screen of your smartphone, tablet, or AR glasses, you may place and examine digital things in the real world without the use of a marker like a QR Code, location, image, etc. Pokémon GO was one of the games that made AR a popular topic. Since then, several AR-enabled goods have been created, including social networking app filters, virtual footwear, sunglasses, and more. Often, we need to download applications such as Instagram or Facebook to view content. The introduction of web-based augmented reality implies that downloading a data-intensive and compute-intensive app is longer needed. Today, augmented reality material may be viewed through a browser. This web-based AR methodology is a new potential, due to its low bandwidth, accessibility, and speed. The advantages of WebAR are double. First, the restriction is too lax for viewers to access and share your content. People are more likely to browse and share content when an app is absent. This guarantees greater accessibility, increased connectedness, and a greater sharing feature. Because there is no application, there is minimal expense and flexibility, which leads to the second benefit. You can link to ongoing initiatives, for instance, by pushing fresh material quicker and more affordably. With our software, users may examine a specified 3D model, which is a representation of visual furniture without markers and can be viewed and altered in real-time. This is a step toward Web-based AR. This study suggests a novel method for applying augmented reality technology to furniture. Using a versatile online interface on a variety of devices, the user can connect 3D virtual furniture data and observe visual furniture.","","978-1-6654-9396-3","10.1109/ICATIECE56365.2022.10047281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10047281","Augmented Reality;Markerless;WebAR;WebXR Device","Visualization;Solid modeling;Three-dimensional displays;Social networking (online);Multimedia Web sites;QR codes;Information filters","augmented reality;computer games;footwear;furniture;location based services;mobile computing;QR codes;smart phones;social networking (online);solid modelling;virtual reality","3D virtual furniture data;AR-enabled goods;augmented reality material;augmented reality technology;compute-intensive app;data-intensive;digital things;download applications;fresh material;greater accessibility;greater sharing feature;interior designing;low bandwidth;markerless Augmented Reality application;QR Code;social networking app;virtual footwear;web-based AR methodology;web-based augmented reality","","","","5","IEEE","24 Feb 2023","","","IEEE","IEEE Conferences"
"Walking Your Virtual Dog: Analysis of Awareness and Proxemics with Simulated Support Animals in Augmented Reality","N. Norouzi; K. Kim; M. Lee; R. Schubert; A. Erickson; J. Bailenson; G. Bruder; G. Welch",University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida; Stanford University; University of Central Florida; University of Central Florida,"2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","30 Dec 2019","2019","","","157","168","Domestic animals have a long history of enriching human lives physically and mentally by filling a variety of different roles, such as service animals, emotional support animals, companions, and pets. Despite this, technological realizations of such animals in augmented reality (AR) are largely underexplored in terms of their behavior and interactions as well as effects they might have on human users' perception or behavior. In this paper, we describe a simulated virtual companion animal, in the form of a dog, in a shared AR space. We investigated its effects on participants' perception and behavior, including locomotion related to proxemics, with respect to their AR dog and other real people in the environment. We conducted a 2 by 2 mixed factorial human-subject study, in which we varied (i) the AR dog's awareness and behavior with respect to other people in the physical environment and (ii) the awareness and behavior of those people with respect to the AR dog. Our results show that having an AR companion dog changes participants' locomotion behavior, proxemics, and social interaction with other people who can or can not see the AR dog. We also show that the AR dog's simulated awareness and behaviors have an impact on participants' perception, including co-presence, animalism, perceived physicality, and dog's perceived awareness of the participant and environment. We discuss our findings and present insights and implications for the realization of effective AR animal companions.","1554-7868","978-1-7281-0987-9","10.1109/ISMAR.2019.000-8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943625","Augmented Reality;Augmented Reality Animals;Virtual Animals;Companion Animals;Virtual Reality","Dogs;Games;Augmented reality;Legged locomotion;Visualization","augmented reality;behavioural sciences;computer animation;computer games;groupware;human factors","mixed factorial human-subject study;emotional support animals;service animals;human lives;domestic animals;simulated support animals;virtual dog;effective AR animal companions;perceived physicality;animalism;social interaction;AR companion dog changes participants;physical environment;AR dog;proxemics;shared AR space;simulated virtual companion animal;human users;augmented reality;technological realizations","","23","","77","IEEE","30 Dec 2019","","","IEEE","IEEE Conferences"
"ABOVE & BELOW: Investigating Ceiling and Floor for Augmented Reality Content Placement","M. Satkowski; R. Rzayev; E. Goebel; R. Dachselt","Interactive Media Lab, Technische Universität, Dresden, Germany; Interactive Media Lab, Technische Universität, Dresden, Germany; Interactive Media Lab, Technische Universität, Dresden, Germany; Interactive Media Lab, Technische Universität, Dresden, Germany","2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","27 Dec 2022","2022","","","518","527","Augmented Reality (AR) interfaces support users by providing access to digital content within real-world environments. However, displaying content at the users’ eye level might result in the occlusion of the real world. Therefore, it requires finding AR content placement areas that free the users’ field of vision. In this work, we systematically investigate two content placement areas beyond the users’ eye level: the ceiling and floor. To understand how potential users perceive virtual content on the ceiling and floor and how the content should be placed on these areas, we conducted two user studies. While the first exploratory study showed the general usefulness of either area, the second quantitative study allowed us to define optimal placement parameters regarding visibility and comfort. With insights from our studies, we provide design recommendations for future AR applications that support 2D content presentation on the ceiling and the floor.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00068","Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995192","User Study;Augmented Reality;Mixed Reality;Ceiling;Floor;Content Placement Human-centered computing—Mixed/Augmented Reality; Human-centered computing—Visualization","User interfaces;Floors;Augmented reality","augmented reality;user interfaces","AR applications;AR content placement areas;augmented reality content placement;optimal placement parameters;virtual content","","","","65","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"Image-driven view management for augmented reality browsers","R. Grasset; T. Langlotz; D. Kalkofen; M. Tatzgern; D. Schmalstieg","Graz University of Technology; Technische Universitat Graz, Graz, Steiermark, AT; Technische Universitat Graz, Graz, Steiermark, AT; Graz University of Technology; Technische Universitat Graz, Graz, Steiermark, AT","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","177","186","In this paper, we introduce a novel view management technique for placing labels in Augmented Reality systems. A common issue in many Augmented Reality applications is the absence of knowledge of the real environment, limiting the efficient representation and optimal layout of the digital information augmented onto the real world. To overcome this problem, we introduce an image-based approach, which combines a visual saliency algorithm with edge analysis to identify potentially important image regions and geometric constraints for placing labels. Our proposed solution also includes adaptive rendering techniques that allow a designer to control the appearance of depth cues. We describe the results obtained from a user study considering different scenarios, which we performed for validating our approach. Our technique will provide special benefits to Augmented Reality browsers that usually lack scene knowledge, but also to many other applications in the domain of Augmented Reality such as cultural heritage and maintenance applications.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402555","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented and virtual realities;H.5.2 [Information Interfaces and Presentation]: User Interface—User interface management system (UIMS)","Layout;Visualization;Image edge detection;Labeling;Image color analysis;Augmented reality;Linear programming","augmented reality;edge detection;geometry;rendering (computer graphics)","image-driven view management;augmented reality browser;view management technique;augmented reality system;digital information;image-based approach;visual saliency algorithm;edge analysis;image region;geometric constraint;labels;adaptive rendering technique;depth cue appearance;scene knowledge;cultural heritage;maintenance application","","90","16","41","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Investigating the Mobile Augmented Reality Acceptance Model with Pre-Service Teachers","T. A. Mikropoulos; M. Delimitros; G. Koutromanos","The Educational Approaches to Virtual Reality Technologies Lab, University of Ioannina, Ioannina, Greece; The Educational Approaches to Virtual Reality Technologies Lab, University of Ioannina, Ioannina, Greece; Department of Primary Education, National and Kapodistrian University of Athens, Athens, Greece","2022 8th International Conference of the Immersive Learning Research Network (iLRN)","11 Jul 2022","2022","","","1","8","The aim of this study was to investigate the factors that might affect pre-service teachers’ intention to use Mobile Augmented Reality in their future teaching. The Mobile Augmented Reality Acceptance Model (MARAM) was used as the study’s theoretical framework. In addition, this work was a validity study for MARAM. Empirical data was collected from 137 pre-service teachers who had developed their own Mobile Augmented Reality applications during an undergraduate university course. The findings of the regression analysis revealed that the MARAM’s variables can explain the variance of perceived ease of use, perceived usefulness, attitude, and intention to a satisfactory degree. Mobile self-efficacy and facilitating conditions were predictors of perceived ease of use. Both perceived enjoyment and perceived relative advantage were predictors of perceived usefulness. In addition, both perceived usefulness and perceived enjoyment were predictors of attitude. Finally, attitude and perceived usefulness were predictors of pre-service teachers’ intention to use Mobile Augmented Reality in their future teaching. However, perceived ease of use failed to be a predictor of attitude and perceived usefulness. These results have implications for pre-service teachers’ education, school leaders and researchers in the field of augmented reality acceptance models.","","978-1-7348995-3-5","10.23919/iLRN55037.2022.9815972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815972","Mobile Augmented Reality;Technology Acceptance Model;pre-service teachers;education","Education;Regression analysis;Augmented reality","augmented reality;computer aided instruction;educational courses;educational institutions;mobile computing;regression analysis;teaching","137 pre-service teachers;Mobile Augmented Reality applications;perceived usefulness;Mobile self-efficacy;perceived enjoyment;future teaching;augmented reality acceptance models;Mobile Augmented Reality Acceptance Model;MARAM;validity study","","","","46","","11 Jul 2022","","","IEEE","IEEE Conferences"
"Massively Multiplayer Online Worlds as a Platform for Augmented Reality Experiences","T. Lang; B. Maclntyre; I. J. Zugaza","Ludwig-Maximilians-Universität München, München, Germany; School of Interactive Computing, GVU Center, Georgia Institute of Technology, USA; University of Deusto","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","67","70","Massively Multiplayer Online Worlds (MMOs) are persistent virtual environments where people play, experiment and socially interact. In this paper, we demonstrate that MMOs also provide a powerful platform for Augmented Reality (AR) applications, where we blend together locations in physical space with corresponding places in the virtual world. We introduce the notion of AR stages, which are persistent, evolving spaces that encapsulate AR experiences in online three-dimensional virtual worlds. We discuss the concepts and technology necessary to use an MMO for AR, including a novel set of design concepts aimed at keeping such a system easy to learn and use. By leveraging the features of the commercial MMO Second Life, we have created a powerful AR authoring environment accessible to a large, diverse set of users.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480752","Augmented Reality;Virtual Reality;Massively Multi-player Online Worlds;User Interfaces;Second Life;I.3.7 [Three-Dimensional Graphics and Realism]: Virtual reality-;H.5.1 [Multimedia Information Systems]: Artificial;augmented;and virtual realities-","Augmented reality;Space technology;Second Life;Graphics;Collaborative work;Virtual environment;Virtual reality;User interfaces;Multimedia systems;Information systems","augmented reality;authoring systems;computer games;user interfaces","massively multiplayer online worlds;augmented reality;online three-dimensional virtual world;authoring environment;second life;user interface","","15","3","14","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"Augmented Reality and its Implementation in Health Care Sector","S. Srivastava; R. B. Agnihotri","AIIT Amity Institute of Information and Technology(AIIT), Delhi, India; AIIT Amity Institute of Information and Technology(AIIT), Delhi, India","2019 International Conference on Intelligent Computing and Control Systems (ICCS)","16 Apr 2020","2019","","","1391","1396","The monstrous mechanical headways around the world have made huge testing rivalry among organizations where every one of the organizations attempts to pull in the clients utilizing distinctive procedures. One of such ongoing technology is AR (Augmented Reality). The Augmented Reality (AR) is another innovation that is fit for introducing potential outcomes that are troublesome for different advances to be meet. These days various AR applications are being utilized in that business of various types or scattered everywhere throughout the world. Augmented Reality will surely change the manner in which people view the environment . The Augmented-Reality is till now in its underlying periods of explore and advancement at various schools and cutting edge organizations. All devices through the most recent years, AR applications wound up transportable and by and large accessible on various gadgets. In addition, Augmented-Reality initialize to possess its position in our broad medium to be used in diverse domains throughout our lifespan in substantial or energizing ways, for example, Television, games and is utilized in numerous areas throughout human's lifespan..This investigation presents AR applications in medical practices and instruction, and plans to help health experts find out about these applications, getting to be intrigued to enhance the nature of medical by means of the innovation.","","978-1-5386-8113-8","10.1109/ICCS45141.2019.9065777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9065777","Augmented-Environment;Virtual-Environment;AR equipped Software;AR in Mobile;Connecting devices.","Augmented reality;Technological innovation;Medical services;Artificial intelligence;Heart;Biomedical imaging;Motion pictures","augmented reality;health care;medical information systems","augmented reality;organizations;health care sector;AR applications;medical practices;medical instruction","","1","","19","IEEE","16 Apr 2020","","","IEEE","IEEE Conferences"
"Context-Aware Augmented Reality Authoring Tool in Digital Ecosystem","J. Park; C. Kang; S. Oh; H. Lee; W. Woo","GIST U VR Laboratory, Gwangju, South Korea; GIST U VR Laboratory, Gwangju, South Korea; GIST U VR Laboratory, Gwangju, South Korea; GIST U VR Laboratory, Gwangju, South Korea; GIST U VR Laboratory, Gwangju, South Korea","2010 International Symposium on Ubiquitous Virtual Reality","26 Aug 2010","2010","","","16","19","In this paper, we propose a context-aware authoring tool which users make virtual contents in-situ. In order to realize, three essential components are defined and some technical challenges are reviewed. We expect that the contents will be adaptive and responsible to dynamic environment. It will be applicable for many industries such as book publication, in-situ simulation and so on.","","978-1-4244-7702-9","10.1109/ISUVR.2010.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557941","augmented reality;authoring;tangible user interface","Three dimensional displays;Books;Real time systems;Computer vision;Virtual reality;Feature extraction;Robustness","augmented reality;authoring systems;environmental science computing;ubiquitous computing","context-aware augmented reality;digital ecosystem;context-aware authoring tool;virtual content;dynamic environment","","3","","15","IEEE","26 Aug 2010","","","IEEE","IEEE Conferences"
"Augmented Reality System for the Assistance of Unmanned Aerial Vehicles","E. S. Misse; S. A. Villacrés; P. M. Velasco; V. H. Andaluz","Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador","2020 15th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2020","2020","","","1","6","This article proposes the development of a virtual and augmented reality environment to assist in the assembly and maintenance of an unmanned aerial vehicle. Taking the lack of technological knowledge as the research gap, the study provides researchers and practitioners with new solutions through the familiarization and guided assistance of a UAV. The system is based on the user tracing to locate the position of the hands and validate in real-time if the actions performed are correct. In the interface can also access to virtualized environment so that the user define a route with the movement of his hands and immediately the UAV follow the path marked from the beginning to the end, the errors are displayed on the same screen to verify the stability of control.","2166-0727","978-989-54659-0-3","10.23919/CISTI49556.2020.9140958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140958","Tracking;UAV;virtualization;mixed reality;kinect","Unmanned aerial vehicles;Augmented reality;Maintenance engineering;Three-dimensional displays;Real-time systems;Solid modeling;Cameras","augmented reality;autonomous aerial vehicles;path planning;stability","augmented reality system;virtual reality environment;augmented reality environment;UAV assistance;unmanned aerial vehicle assistance;control stability;user tracing","","","","17","","15 Jul 2020","","","IEEE","IEEE Conferences"
"Understanding Physical Common Sense in Symmetrical Reality","Z. Zhang",Tencent,"2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","275","276","Physical common sense is the intuitive knowledge that can be obtained from the physical world. But the common sense will be broken in symmetrical reality because of the integration of the physical world and the virtual world. In this paper, we will introduce the specific physics in symmetrical reality from two perspectives: existence and interaction. We emphasize the bi-directional mechanical control within the symmetrical reality framework and why free wills of machines can break the common sense. Afterward, we give the experiments of discovering the new physical common sense of symmetrical reality systems. Experiment I is about learning physical common sense from symmetrical reality, which is used to show what can be learned and how to learn in a symmetrical reality environment. Experiment II is about changing the physical common sense of symmetrical reality, which is used to show why physical common sense deserves much attention. Finally, we draw an initial conclusion about the physical common sense in symmetrical reality and give some suggestions for understanding symmetrical reality-based physical common sense.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288442","Human-centered computing;Human computer interaction (HCI);HCI theory;concepts and models;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality","Computational modeling;Bidirectional control;Augmented reality;Physics","human computer interaction;learning (artificial intelligence);physics computing;virtual reality","physical world;symmetrical reality;physical common sense;existence perspective;interaction perspective;bidirectional mechanical control;machine learning;physics","","1","","7","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Encryption and Decryption of Marker Based 3-Dimensional Augmented Reality Image Using Modified Hill Cipher Technique for Secure Transfer","A. Sharma; A. Singh; A. Kumar","Department of Software Engineering, Delhi Technological University, Delhi, India; Department of Software Engineering, Delhi Technological University, Delhi, India; Department of Software Engineering, Delhi Technological University, Delhi, India","2022 IEEE 2nd International Conference on Computer Communication and Artificial Intelligence (CCAI)","30 Jun 2022","2022","","","155","159","The Mobility of digital data has increased over time, but securing them is a major task to do. Research has been conducted to help shield data from unauthorized intruders and attacks that includes disclosure of data, masquerade, content modification and repudiation, though safeguarding Augmented Reality media remains an unfulfilled issue. This research takes a step towards encrypting augmented reality content by implementing the modified Hill cipher encryption approach. This is acquired by offering marker-based mobility of immersive 3 Dimensional media, that is scanned by the user to extract it; furthermore, users first verify their identity by entering the passcode or key to the modified Hill cipher to decrypt the data. Coupling cryptography and augmented reality will lead to a safe and secured meaningful engagement of the digital media over the networks.","","978-1-6654-9663-6","10.1109/CCAI55564.2022.9807727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9807727","augmented reality;cryptography;modified hill cipher;encryption;decryption;key;markers;security","Couplings;Ciphers;Data privacy;Computer hacking;Conferences;Mixed reality;Media","augmented reality;cryptography;stereo image processing;user interfaces","modified Hill cipher technique;secure transfer;digital data;unauthorized intruders;content modification;repudiation;augmented reality media;reality content;marker-based mobility;immersive 3D media;digital media;modified Hill cipher encryption;marker based 3D augmented reality image","","","","26","IEEE","30 Jun 2022","","","IEEE","IEEE Conferences"
"A New Framework for Tracking by Maintaining Multiple Global Hypotheses for Augmented Reality","K. Hayashi; H. Kato; S. Nishida","Graduate School of Engeneering Science, Osaka University, Japan; Graduate School of Engeneering Science, Nara Institute of Science and Technology, Japan; Graduate School of Engeneering Science, Osaka University, Japan","17th International Conference on Artificial Reality and Telexistence (ICAT 2007)","2 Jan 2008","2007","","","15","22","Several tracking techniques for augmented reality have been proposed. In feature point tracking, a pose is computed by minimizing the error between the observed 2D feature points and the back-projected feature points from the 3D scene model. This minimization problem is usually solved by nonlinear optimization. The main advantage of this approach is its accuracy. However, it is difficult to compute the correct pose unless an appropriate initial value is used. In addition, when an observation contains some errors, this approach does not guarantee a correct pose even if it converges to the global minimum. Therefore, once an incorrect pose is computed in a frame, either the tracking in the next frame may fail or the result will deviate from the correct pose. In this paper, we propose a new tracking framework for augmented reality. The proposed method tracks features as multiple local hypotheses based on not just one pose but multiple poses that are computed from pose estimation in the previous frame. Since multiple poses are maintained as global hypotheses, as long as the correct pose is contained in the hypotheses, tracking can be continued even in difficult situations such as a simple iterative scene with high-speed movements.","","0-7695-3056-7","10.1109/ICAT.2007.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414611","","Augmented reality;Cameras;Robustness;Layout;Computational efficiency;Information science;Computer errors;Error correction;Tracking;Minimization methods","augmented reality;minimisation;pose estimation;tracking","multiple global hypotheses;augmented reality;tracking technique;feature point tracking;3D scene model;minimization problem;nonlinear optimization;pose estimation","","5","1","11","IEEE","2 Jan 2008","","","IEEE","IEEE Conferences"
"Augmented reality motion-based robotics off-line programming","D. Araque; R. Díaz; B. Pérez-Gutiérrez; A. J. Uribe","School of Engineering, Mechatronics Engineering, VR Center Laboratory, Universidad Militar Nueva Granada, Bogota, Colombia; School of Engineering, Mechatronics Engineering, VR Center Laboratory, Universidad Militar Nueva Granada, Bogota, Colombia; School of Engineering, Mechatronics Engineering, VR Center Laboratory, Universidad Militar Nueva Granada, Bogota, Colombia; Mechanical Project Design Department, Campinas State University, Brazil","2011 IEEE Virtual Reality Conference","29 Apr 2011","2011","","","191","192","Augmented reality allows simulating, designing, projecting and validating robotic workcells in industrial environments that are not equipped with real manipulators. In this paper a study and implementation of a gestural programmed robotic workcell through augmented reality is presented. The result was an interactive environment in which the user can program an industrial robot through gestures, accomplished from the development of a computer based framework.","2375-5334","978-1-4577-0038-5","10.1109/VR.2011.5759463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759463","","Service robots;Computers;Augmented reality;Robot sensing systems;Kinematics;Programming","augmented reality;control engineering computing;industrial manipulators","augmented reality motion based robotics;offline programming;industrial environments;manipulators;gestural programmed robotic workcell","","4","","7","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"How Field of View Affects Awareness of an Avatar During a Musical Task in Augmented Reality","S. C. Weng; T. Hopkins; R. Vanukuru; C. Tobin; A. Banic; D. Leithinger; E. Y. Do","ATLAS Institute, University of Colorado Boulder; ATLAS Institute, University of Colorado Boulder; ATLAS Institute, University of Colorado Boulder; ATLAS Institute, University of Colorado Boulder; Interactive Realities Lab, University of Wyoming; ATLAS Institute, University of Colorado Boulder; ATLAS Institute, University of Colorado Boulder","2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","633","634","To investigate how field of view (FOV) affects how players notice the communicative gestures of their partner's avatar in a musical task, we conducted an experiment that compares several AR technologies with varying FOV. We measured response time to communicative gestures, co-presence score, and task enjoyment in three different AR scenarios: holograms, AR headset, and an AR headset with notifications of the avatar's intention to gesture. Results suggest that the hologram setup had the fastest response time and highest ratings for sense of co-presence and task enjoyment. Notification tasks slowed response time, but noticeably improved co-presence with the avatar.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108798","Human-centered computing-Interaction paradigms-Mixed / augmented reality;Human-centered computing-Interaction paradigms-Collaborative Interaction;Applied computing-Sound and music computing","Headphones;Three-dimensional displays;Avatars;Conferences;Music;User interfaces;Time measurement","augmented reality;avatars;holography;human computer interaction;music","AR headset;augmented reality;avatar intention;communicative gestures;copresence score;field of view;FOV;hologram setup;musical task;notification tasks;task enjoyment","","","","7","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Point Cloud Generation Using Deep Local Features for Augmented and Mixed Reality Contents","S. Lim; M. Shin; J. Paik","Image Processing and Intelligent System Laboratory, Chung-Ang University, Seoul, Korea; Image Processing and Intelligent System Laboratory, Chung-Ang University, Seoul, Korea; Image Processing and Intelligent System Laboratory, Chung-Ang University, Seoul, Korea","2020 IEEE International Conference on Consumer Electronics (ICCE)","23 Mar 2020","2020","","","1","3","With the commercialization of 5G network and the mounted of 3D sensor such as ToF on smartphones, augmented and mixed reality (AR/MR) technology has attracted increasing attention. AR/MR contents need 3D data in various models to interact with human users. However, creating a 3D model is a complicated and expensive process involving 3D acquisition, 3D reconstruction, and rendering with computer graphics techniques. To solve that problem, we use an autoencoder to extract local information. We then train the latent space in a generative adversarial network (GAN). The GAN takes local context from the latent variable, and then generates a point cloud of various robust shapes. The proposed method can generate a novel 3D model that can significantly save computational load to render AR/MR contents.","2158-4001","978-1-7281-5186-1","10.1109/ICCE46568.2020.9043081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043081","Augmented reality (AR);mixed reality (MR);point cloud;generative adversarial network (GAN)","Point cloud compression;Solid modeling;Three-dimensional displays;Shape;Computational modeling;Mixed reality;Generative adversarial networks","augmented reality;feature extraction;image reconstruction;neural nets;rendering (computer graphics);solid modelling;stereo image processing","5G network commercialization;AR-MR contents;rendering;3D reconstruction;3D acquisition;3D sensor;augmented reality contents;latent space;local information extraction;computer graphics techniques;human users;mixed reality technology;smartphones;ToF;mixed reality contents;deep local features;point cloud generation;computational load;GAN;generative adversarial network","","4","","7","IEEE","23 Mar 2020","","","IEEE","IEEE Conferences"
"An Optical See-Through Augmented Reality System with Gesture-Based Interaction","L. Zhen; C. Jing; Z. Zixiang; T. Qiushuo; H. Ningsheng","School of Optoelectronics, Beijing Institute of Technology, Beijing, China; School of Optoelectronics, Beijing Institute of Technology, Beijing, China; School of Optoelectronics, Beijing Institute of Technology, Beijing, China; School of Optoelectronics, Beijing Institute of Technology, Beijing, China; School of Optoelectronics, Beijing Institute of Technology, Beijing, China","2016 International Conference on Virtual Reality and Visualization (ICVRV)","5 Jun 2017","2016","","","447","452","We present an optical see-through augmented reality system. The system features optical see-through calibration, object tracking, virtual scene rendering and gesture interaction. Compared with video see-through augmented reality system, the optical see-through system requires more accurate alignment between the virtual and the real scene. Our system calibration is done using natural feature based calibration method based on SPAAM algorithm. The tracking method is based on RGB-D camera and the gesture interaction is implemented with custom gestures. Finally, we design a test scene and the system achieves the mixture of virtual and real reality in the test scene and meets the accuracy and real-time requirement.","","978-1-5090-5188-5","10.1109/ICVRV.2016.82","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7938237","augmented reality;optical see-through display;gesture interaction;RGB-D Camera","Calibration;Cameras;Resists;Optical imaging;Biomedical optical imaging;Adaptive optics;Holography","augmented reality;calibration;cameras;gesture recognition;natural scenes;object tracking;rendering (computer graphics)","optical see-through augmented reality system;gesture-based interaction;optical see-through calibration;object tracking;virtual scene rendering;real scene;system calibration;natural feature based calibration;SPAAM algorithm;RGB-D camera;test scene;virtual reality;real reality","","3","1","12","IEEE","5 Jun 2017","","","IEEE","IEEE Conferences"
"Aroaro - A Tool for Distributed Immersive Mixed Reality Visualization","F. Beltrán; D. White; J. Geng",The University of Auckland; The University of Auckland; The University of Auckland,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","972","973","In this research demo we present three immersive scenarios on three XR modalities - VR, immersive AR on HoloLens and 2D AR on Android. These scenarios are a network of Harry Potter characters in VR, a map-based visualization of a soldier's history with rich attributes including images and sound on HoloLens, and a visualization of car racing on Android. These visualizations have been created with Aroaro our distributed mixed reality data visualization tool.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757464","Augmented reality;Virtual reality;Mixed reality;Data visualization;Immersive analytics;Multi-user;Networks;Human-centered computing;Visualization;Visualization application domains;Visual analytics;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Human computer interaction","Three-dimensional displays;Conferences;Data visualization;Mixed reality;History;Automobiles;X reality","Android (operating system);augmented reality;data visualisation","distributed immersive mixed reality visualization;HoloLens;Android;Harry Potter characters;map-based visualization;rich attributes;XR modalities;soldiers history;distributed mixed reality data visualization tool;Aroaro","","","","7","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Workshop on Creativity in Designing with & for Mixed Reality","J. Verlinden; D. Aschenbrenner; S. Lukosh",University of Antwerp; Delft University of Technology; Delft University of Technology,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","314","314","Although developments in devices and software are maturing towards novel Mixed Reality systems, there is too little connection to the design field. Especially if AR is combined with other “smart” technologies (internet of things), perspectives shift from merely technical characteristics and quantifiable human factors to more complex UX scenarios. Although there are other special interest groups/conferences that in part cover this theme (CHI, IUI, UIST), we would think that ISMAR is a better venue in connecting the graphics/tracking community with design researchers. We also would like to address the lack of software engineering skills with design students/professionals. How can we bridge these disciplines and silos of innovation? This workshop invites both industrial and academic participants to contribute to this debate, first of all by submitting extended abstracts that cover case studies, best practices and challenges in design for/with AR. To cater for a design debate, we strongly encourage submissions of annotated artworks/3D scenes/pictures/floorplans as well as more traditional papers. Position papers should be 2-6 pages long, submitted in PDF format and formatted using the ISMAR 2018 paper template available from https://ismar2018.org/guidelines_submission/index.html. Papers will be peer-reviewed and after acceptance be published in the adjunct proceedings or ISMAR. During the workshop papers will be presented/demonstrations as short presentations. Submissions should not be anonymized and the author names and affiliations should be displayed on the first page. At least one author of each accepted paper must attend the workshop and register for at least one day of the conference. All accepted papers workshop's papers will be published in the ISMAR 2018 Adjunct Proceedings.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699272","","Conferences;Augmented reality;Creativity;Software;Internet of Things;Human factors","augmented reality;computer graphics;human factors;Internet;Internet of Things;software engineering;user interfaces","creativity;smart technologies;design researchers;software engineering skills;mixed reality systems;human factors;tracking community;augmented reality;graphics community;Internet of things","","","","0","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"X-portal: Mixed reality for body engagement in new first person game experience","H. Sung; C. -M. Wang","Doctoral Program, Graduate School of Design, Douliu City, Yunlin County, Taiwan (R.O.C.); Doctoral Program, Graduate School of Design, Douliu City, Yunlin County, Taiwan (R.O.C.)","2018 IEEE International Conference on Applied System Invention (ICASI)","25 Jun 2018","2018","","","1073","1074","In recent years, Augmented Reality (AR) based mobile games have become popular among players. It is Important how to merge virtual content and the real space, let the players intuitively immerse the interaction. This paper presents a “X-Portal” prototype that uses the plane detection technology to create the portal between the real space and game scene. The user plays first-person shooting mo bile game, which is including physical movements (e.g. walking, squatting, jumping) through between real and virtual space. Furthermore, player can interactive with game character. In addition, we apply the system to war simulation first-person mobile game practicing, our preliminary study has shown that the proposed “X-Portal” prototype can provide players with the body experience more intuitive, enhance the sense of immersion. The principal contribution of our research is to provide a novel approach for Augmented Reality mobile game, which extends our Body Engagement and supports new immersive experience.","","978-1-5386-4342-6","10.1109/ICASI.2018.8394463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8394463","Augmented Reality;Body Engagement;Portal;Mixed Reality","Games;Land mobile radio;Augmented reality;Portals;Cameras;Prototypes","augmented reality;computer games;human factors;mobile computing","body experience;body engagement;Mixed reality;mobile games;X-Portal prototype;game scene;physical movements;war simulation first-person;first-person shooting mobile game;first-person mobile game;first person game experience;Augmented Reality","","2","","8","IEEE","25 Jun 2018","","","IEEE","IEEE Conferences"
"Using children's developmental psychology to guide augmented-reality design and usability","I. Radu; B. MacIntyre",Georgia Institute of Technology; Georgia Institute of Technology,"2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","227","236","Augmented reality (AR) designers have great potential to enrich children's lives through AR experiences in education and entertainment. A significant difficulty in designing for children is that tremendous physical and cognitive development occurs across the first 10 years of life, and the changes in children's capabilities and limitations impact how these users respond to AR designs. Currently, little is known about how developmental changes relate to AR designs, or what AR designs are effective for young children. In this work, we focus on children 6–9 years old, presenting several concepts from developmental psychology and discussing how these relate to AR designs. Specifically, we investigate children's skills in the categories of motor abilities, spatial cognition, attention, logic and memory, and we discuss the relationship of these skills to current and hypothetical AR designs. Through this work, we intend to strengthen the field's understanding of AR usability and design, resulting in the generation of effective AR experiences for young users.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402561","Augmented Reality;Children;Psychology;Interaction Design;Mixed Reality","Games;Augmented reality;Psychology;Cameras;Guidelines;Performance evaluation;Muscles","augmented reality;human factors;psychology;software reusability","children developmental psychology;augmented-reality design;augmented-reality usability;AR experiences;education;entertainment;physical development;cognitive development;AR designs;children skills;motor abilities;spatial cognition;attention;logic;memory","","31","","50","IEEE","7 Jan 2013","","","IEEE","IEEE Conferences"
"Vibro-tactile Feedback for Dial Interaction using an Everyday Object in Augmented Reality","M. Greenslade; A. Clark; Z. Chen; S. Lukosch","HIT Lab NZ University of Canterbury; School of Product Design University of Canterbury; School of Psychology, Speech and Hearing University of Canterbury; HIT Lab NZ University of Canterbury","2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","909","910","Interaction using everyday objects offer a compelling alternative to gesture and dedicated controller interaction in augmented real-ity. However, unlike dedicated controllers, everyday objects cannot provide active haptic feedback. To explore active feedback with everyday objects, a within-subjects study was conducted with n = 28 participants, using a flowerpot enhanced with vibro-tactile feedback to perform dial interactions and comparing four conditions based on the inclusion and exclusion of audio and haptic feedback. No significant differences between conditions were found for task com-pletion time or accuracy, however measurements of immersion and user preference were higher for the conditions that included haptic feedback.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108653","Human-centered computing—Human computer interaction (HCI)—Interaction devices—Haptic devices, Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality;Human-centered computing—Human computer interaction (HCI)—HCI design and evaluation methods—User studies;User studies;Augmented Reality;Haptic Feedback;Everyday Objects","Three-dimensional displays;Atmospheric measurements;Design methodology;Conferences;User interfaces;Particle measurements;Time measurement","augmented reality;cloud computing;feedback;haptic interfaces;mobile computing","active feedback;active haptic feedback;augmented real-ity;augmented reality;dedicated controller interaction;dedicated controllers;dial interaction;everyday object;gesture;vibro-tactile feedback","","","","6","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Augmented Reality for Urban Skills Training","D. G. Brown; J. T. Coyne; R. Stripling","U.S. Naval Research Laboratory, USA; U.S. Naval Research Laboratory, USA; Strategic Analysis, Inc., USA","IEEE Virtual Reality Conference (VR 2006)","7 Aug 2006","2006","","","249","252","Warfighters develop and maintain their skills through training. Since fully-manned live training in the real world is often too expensive (by many measures), scientists have developed many types of training systems ranging from classroom sessions to those using virtual reality. Recently, researchers have used augmented reality (AR) to insert virtual entities into the real world, attempting to create a low cost, repeatable, and effective substitute for fully-manned live training. However, very little evaluation of the effectiveness of AR for training has been performed. We performed a pilot study to evaluate the use of wearable AR in teaching urban skills, specifically, room clearing in teams. Eight teams of two were briefed on room clearing techniques, given hands-on instruction, and then allowed to practice those techniques with or without the AR system. After this instructional period, subjects performed several room clearing scenarios against real people using infrared-based practice weapons that logged the number of hits on the subjects and the enemy and neutral forces. During these trials, a subject matter expert evaluated how well the subjects applied the room-clearing techniques. In this paper, we describe the pilot study in more detail, including the hardware and software testbed, and then provide an analysis of the results of the pilot study.","2375-5334","1-4244-0224-7","10.1109/VR.2006.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1667652","augmented reality;training;evaluation","Augmented reality;Virtual reality;Performance evaluation;Military computing;Education;Weapons;Computer applications;Testing;Control systems;Prototypes","","augmented reality;training;evaluation","","11","","6","IEEE","7 Aug 2006","","","IEEE","IEEE Conferences"
"Distant Hand Interaction Framework in Augmented Reality","J. Ugarte; N. Norouzi; A. Erickson; G. Bruder; G. Welch",University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","962","963","Recent augmented reality (AR) head-mounted displays support shared experiences among multiple users in real physical spaces. While previous research looked at different embodied methods to enhance interpersonal communication cues, so far, less research looked at distant interaction in AR and, in particular, distant hand communication, which can open up new possibilities for scenarios, such as large-group collaboration. In this demonstration, we present a research framework for distant hand interaction in AR, including mapping techniques and visualizations. Our techniques are inspired by virtual reality (VR) distant hand interactions, but had to be adjusted due to the different context in AR and limited knowledge about the physical environment. We discuss different techniques for hand communication, including deictic pointing at a distance, distant drawing in AR, and distant communication through symbolic hand gestures.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00332","National Science Foundation(grant numbers:1564065); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757391","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Augmented reality","Visualization;Three-dimensional displays;Head-mounted displays;Conferences;Collaboration;User interfaces;Planning","augmented reality;gesture recognition;groupware;helmet mounted displays;virtual reality","distant hand communication;research framework;virtual reality;distant drawing;distant communication;symbolic hand gestures;distant hand interaction framework;recent augmented reality head-mounted displays;shared experiences;multiple users;physical spaces;different embodied methods;interpersonal communication cues;distant interaction;particular hand communication","","","","4","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Virtual Reality in Physical Mirrors","S. Woo; T. Aoki; H. Mitake; N. Hashimoto; M. Sato","Precision and Intelligence Laboratory, Tokyo Institute of Technology, Japan; Precision and Intelligence Laboratory, Tokyo Institute of Technology, Japan; Precision and Intelligence Laboratory, Tokyo Institute of Technology, Japan; Precision and Intelligence Laboratory, Tokyo Institute of Technology, Japan; Precision and Intelligence Laboratory, Tokyo Institute of Technology, Japan","2009 IEEE Virtual Reality Conference","7 Apr 2009","2009","","","239","240","Sometimes, mirrors provide illusions that distort physical laws. In these methods, the illusions become ""real"" as your visual, tactile, and auditory senses are immersed in the world inside the mirror. Our methods allows you to experience a mirror illusion through three modalities of feedback (visual, haptic, and auditory) and perceive a boundary less transition between the real world and the world inside the mirror. This approach is expected to open new possibilities for using mirrors in the fields of media art or virtual reality.","2375-5334","978-1-4244-3943-0","10.1109/VR.2009.4811034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811034","Interactive Interface with Physical Properties;Augmented Reality Perspective;H.5.2 [Information Interfaces and Presentation]: User Interface-Interaction styles;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;augmented;and virtual realities","Virtual reality;Mirrors;Feedback;Reflection;Gravity;Haptic interfaces;Art;Laboratories;Augmented reality;Multimedia systems","user interfaces;virtual reality","virtual reality;physical mirrors;mirror illusion;user interfaces","","","","2","IEEE","7 Apr 2009","","","IEEE","IEEE Conferences"
"Augmented Reality for Warehouse: Aid System for Foreign Workers","A. Albawaneh; V. Agnihothram; J. Wu; G. Singla; H. Kim","School of Engineering and Computer Science, Oakland University, USA; School of Engineering and Computer Science, Oakland University, USA; School of Engineering and Computer Science, Oakland University, USA; School of Engineering and Computer Science, Oakland University, USA; School of Engineering and Computer Science, Oakland University, USA","2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","432","433","Order picking in inventory warehouses is one of the challenging tasks, especially for foreign workers due to language barriers found in current order picking instructions. To address this challenge, we took the user-centered design approach and developed an augmented reality (AR) aid system using a head-worn display (HWD). Unlike most AR warehouse aid systems that present icons or texts on fixed locations of the displays, we directly overlaid visual symbols atop the real-world to better guide foreign workers' tasks. Our pilot user study demonstrated the potential of the proposed system in improving user performance, perceived safety, and usability as compared to one of the current practices for order picking, verbal instructions. This work highlights the importance of the user-centered design of AR solutions that bridge the gap between end-users and available technologies in warehouses. The proposed AR job aid system could be developed further to support more complex warehouse tasks.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108845","Augmented reality;Human-computer interaction;User interface application;Warehouse;H.5 [Information Interfaces and Presentation]: H.5.1: Multimedia Information Systems - Artificial;Augmented;Virtual Realities","Visualization;Three-dimensional displays;User centered design;Symbols;User interfaces;Safety;Proposals","augmented reality;ergonomics;inventory management;order picking;personnel;production engineering computing;user centred design","AR job aid system;augmented reality aid system;foreign workers;head-worn display;inventory warehouses;language barriers;order picking instructions;user performance;user-centered design;visual symbols","","","","6","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Ar in VR: Simulating Infrared Augmented Vision","F. Lahoud; S. Susstrunk","School of Computer and Communication Sciences EPFL, Switzerland; School of Computer and Communication Sciences EPFL, Switzerland","2018 25th IEEE International Conference on Image Processing (ICIP)","6 Sep 2018","2018","","","3893","3897","Developing an augmented reality (AR) system involves multiple algorithms such as image fusion, camera synchronization and calibration, and brightness control, each of them having diverse parameters. This abundance of settings, while allowing for many features, is detrimental to developers as they try to navigate between different combinations and pick the most suitable towards their application. Additionally, the temporally inconsistent nature of the real world makes it hard to build reproducible scenarios for testing and comparison. To help address these issues, we develop a virtual reality (VR) environment that allows simulating a variety of AR configurations”. We show the advantages of AR simulation in virtual reality, demonstrate an image fusion AR system and conduct an experiment to compare different fusion methods.","2381-8549","978-1-4799-7061-2","10.1109/ICIP.2018.8451811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451811","augmented reality;virtual reality;augmented vision;image fusion;simulation;infrared","Image fusion;Solid modeling;Image color analysis;Cameras;Temperature;Augmented reality;Testing","augmented reality;calibration;cameras;image fusion;infrared imaging","augmented reality system;image fusion;camera synchronization;calibration;brightness control;virtual reality environment;AR simulation;fusion methods;infrared augmented vision","","5","","21","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"LUMAR: A Hybrid Spatial Display System for 2D and 3D Handheld Augmented Reality","A. Olwal; A. Henrysson","School of Computer Science and Communication, KTH (Royal Institute of Technology), Stockholm, Sweden; ITN, Campus Norrköping, VITA, Linköping University, Norrkoping, Sweden","17th International Conference on Artificial Reality and Telexistence (ICAT 2007)","2 Jan 2008","2007","","","63","70","LUMAR is a hybrid system for spatial displays, allowing cell phones to be tracked in 2D and 3D through combined egocentric and exocentric techniques based on the LightSense and UMAR frameworks. LUMAR differs from most other spatial display systems based on mobile phones with its three-layered information space. The hybrid spatial display system consists of printed matter that is augmented with context-sensitive, dynamic 2D media when the device is on the surface, and with overlaid 3D visualizations when it is held in mid-air.","","0-7695-3056-7","10.1109/ICAT.2007.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414617","Spatially aware;portable;mobile;handheld;cell;phone;augmented reality;mixed reality;ubiquitous.","Three dimensional displays;Two dimensional displays;Augmented reality;Cameras;Cellular phones;Handheld computers;Personal digital assistants;Computer vision;Computer displays;Virtual reality","augmented reality;computer displays;mobile computing","hybrid spatial display system;3D handheld augmented reality;2D handheld augmented reality;cell phone;egocentric technique;exocentric technique;mobile phone;ubiquitous mobile augmented reality","","2","","12","IEEE","2 Jan 2008","","","IEEE","IEEE Conferences"
"Augmented Cues Facilitate Learning Transfer from Virtual to Real Environments","N. Cooper; F. Milella; I. Cant; C. Pinto; M. White; G. Meyer",University of Liverpool; Virtual Engineering Centre; Virtual Engineering Centre; Virtual Engineering Centre; University of Liverpool; University of Liverpool,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","194","198","The aim of this study was to investigate whether augmented cues that have previously been shown to enhance performance and user satisfaction in VR training translate into performance improvements in real environments. Subjects were randomly allocated into 3 groups. Group 1 were trained to perform a real tyre change, group 2 were trained in a conventional VR setting, while group 3 were trained in VR with augmented cues. After training participants were tested on a real tyre change task. Overall time to completion was recorded as objective measure; subjective ratings of presence, perceived workload and discomfort were recorded using questionnaires. The performances of the three groups were compared. Overall, participants who received VR training performed significantly faster on the real task than participants who completed the real tyre change only. The difference between the virtual reality training groups was found to be not significant. However, participants who were trained with augmented cues performed the real tyre change with fewer errors than participants in the minimal cues training group. Systematic differences in subjective ratings that reflected objective performance were also observed.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836496","virtual reality;training transfer;multisensory feedback;augmented cues;performance;presence;workload;simulation sickness","Training;Solid modeling;Virtual reality;Atmospheric measurements;Particle measurements;Computational modeling;Wheels","augmented reality;computer based training","augmented cues;learning transfer;virtual environments;real environments;VR training","","9","","31","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"JomAR: Reality Purchasing Experiences","J. R. Prasojo; P. S. JosephNg; K. Y. Phan; J. T. Lim","ICSDI, UCSI University, Malaysia; ICSDI, UCSI University, Malaysia; FICT, Universiti Tunku Abdul Rahman, Malaysia; FICT, Universiti Tunku Abdul Rahman, Malaysia","2021 IEEE 4th International Conference on Computing, Power and Communication Technologies (GUCON)","2 Nov 2021","2021","","","1","6","In the modern world, online shopping is a common activity that people do. They buy all things even large-size products such as furniture. People used to measure the product traditionally using a tape measure. However, people can take advantage of virtual reality products such as augmented reality. This study used a mixed methodology involving 105 respondents. The augmented reality will have the benefit to reduce the cost since the customer does not need to measure traditionally and to increase efficiency to buy the product. Additionally, the customer will have more trust in the seller. The augmented reality can help users to understand the product and match the product with the user's surroundings. This augmented reality will potentially grow and adapt to the user needs as the user might explore more with the image projection.","","978-1-7281-9951-1","10.1109/GUCON50781.2021.9573999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9573999","Augmented Reality;Furniture;Virtual;Online Shopping;Mobile Shopping","Costs;Conferences;Clothing;Communications technology;Mobile applications;Electronic commerce;Augmented reality","augmented reality;electronic commerce;furniture;Internet;purchasing;retail data processing;virtual reality","reality purchasing experiences;large-size products;tape measure;virtual reality products;augmented reality","","1","","50","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Projector robot for augmented children's play","J. -g. Ahn; H. Yang; G. J. Kim; N. Kim; K. Choi; H. Yeon; E. Hyun; M. Jo; J. Han","Korea University, Seongbuk-gu, Seoul, KR; Korea University, Seongbuk-gu, Seoul, KR; Korea University, Seongbuk-gu, Seoul, KR; Dept. of Game Engineering, Dongui University, Busan, Korea; Sungkyunkwan University, Jongno-gu, Seoul, KR; Sungkyunkwan University, Jongno-gu, Seoul, KR; Sungkyunkwan University, Jongno-gu, Seoul, KR; Cheongju National University of Education, Cheongju, Chungcheongbuk-do, KR; Cheongju National University of Education, Cheongju, Chungcheongbuk-do, KR","2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","27 Aug 2012","2011","","","27","27","Participating in a play is one of integral curriculum for young children at nurseries and kindergartens. At the same time, it is not very easy to successfully run and manage a play for young children due to their low age and immaturity. We are exploring the use of a robot and augmented reality (AR) technology to assist the nursery teachers in hopes to alleviate the difficult and complicated task of running the play, and also as a way to increase the learning effect by promoting the concentration and immersion (by the presence of the robot and novelty of the augmented display) [1, 2, 3]. We have devised a semi-autonomous remote-controlled projector robot with the capabilities of background projection and control, generating the synthesized augmented view, camera/movement control, producing story narration and various special effects (See Figure 1). We have recently deployed the robot assistant for a play (`Three Little Pigs') at an actual nursery to observe and investigate various aspects of human robot interaction. For instance, the robot interacts with the actors on stage, leading and guiding them by showing (with small display on the robot) the synthesized augmented view, script guidance, and putting forth and changing the backdrop projection. It also assumes the role of the “camera man” and may instigate minute interplay with the actor as it zooms in and out on actors (by remote control). Our initial observation indicated that the use of the robot and AR indeed exhibited very high potential in drawing the attention of the children and enhancing the educational effect, but required the right amount of autonomy and external control and an intuitive interface.","2167-2148","978-1-4673-4395-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6281337","Human Robot Interaction;Projector Robot;Augmented Reality;Teaching Assistant Robot","Robots;Educational institutions;Human robot interaction;Abstracts;Augmented reality;Cameras","augmented reality;control engineering computing;control engineering education;human-robot interaction;optical projectors;telerobotics","augmented children play;augmented reality technology;AR technology;augmented display;semiautonomous remote-controlled projector robot;background projection;synthesized augmented view generation;camera-movement control;story narration;Three Little Pigs;human robot interaction;script guidance;backdrop projection","","","","","","27 Aug 2012","","","IEEE","IEEE Conferences"
"Photo-shoot localization of a mobile camera based on registered frame data of virtualized reality models","K. Makita; J. Nishida; T. Ishikawa; T. Okuma; M. Kourogi; T. Vincent; L. Nigay; J. Yamashita; H. Kuzuoka; T. Kurata","AIST, Japan; ZENRIN DataCom, Japan; AIST, Japan; AIST, Japan; AIST, Japan; Université J. Fourier, France; Université J. Fourier, France; Univ. of Tsukuba, Japan; Univ. of Tsukuba, Japan; AIST, Japan","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","273","274","This paper presents a study of a method for estimating the position and orientation of a photo-shoot in indoor environments for augmented reality applications. Our proposed localization method is based on registered frame data of virtualized reality models, which are photos with known photo-shoot positions and orientations, and depth data. Because registered frame data are secondary product of modeling process, additional works are not necessary to create registered frame data especially for the localization. In the method, a photo taken by a mobile camera is compared to registered frame data for the localization. Since registered frame data are linked with photo-shoot position, orientation, and depth data, 3D coordinates of each pixel on the photo of registered frame data is available. We conducted experiments with employing five techniques of the estimation for comparative evaluations.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671801","","Cameras;Image edge detection;Data models;Feature extraction;Estimation;Mobile communication;Solid modeling","augmented reality;cameras;pose estimation","photo-shoot localization;mobile camera;registered frame data;virtualized reality models;position estimation;augmented reality;3D coordinates","","2","","11","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"Simulation of Augmented Telerobotic Operation","Y. S. Park; X. Zhao; S. Korthals","Nuclear Engineering Division, Argonne National Laboratory, IL; Nuclear Engineering Division, Argonne National Laboratory, IL; Nuclear Engineering Division, Argonne National Laboratory, IL","2014 International Symposium on Optomechatronic Technologies","11 Jun 2015","2014","","","242","246","This paper presents an augmented reality system which facilitates user interactive simulation of teleoperation of robotic systems. Leveraging the recent advances in augmented reality and 3D sensing and modeling technologies, the system facilitates various concepts of enhanced teleoperation, including virtual fixture, teleautonomy, and augmented teleoperation. A series of test operations was made using the virtual simulator, which demonstrated the potential benefits of the use of augmented reality technique for enhancement of teleoperation performance.","","978-1-4673-6752-3","10.1109/ISOT.2014.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119429","teleoperation;simulator;augmented reality;virtual fixtures;3D sensing and modeling","Fixtures;Robot sensing systems;Haptic interfaces;Augmented reality;Three-dimensional displays","augmented reality;telerobotics;user interfaces","virtual simulator;augmented teleoperation;teleautonomy;virtual fixture;3D sensing;user interactive simulation;augmented reality system;augmented telerobotic operation simulation","","3","","11","IEEE","11 Jun 2015","","","IEEE","IEEE Conferences"
"Augmented TV: An augmented reality system for TV programs beyond the TV screen","H. Kawakita; T. Nakagawa","Science and Technology Research Laboratories, NHK(Japan Broadcasting Corporation), Tokyo, Japan; Science and Technology Research Laboratories, NHK(Japan Broadcasting Corporation), Tokyo, Japan","2014 International Conference on Multimedia Computing and Systems (ICMCS)","29 Sep 2014","2014","","","955","960","TV Service using a mobile device as a second screen has been increasing. We propose a new TV system which is able to augment representation of TV programs beyond the TV screen. In the system, which we named augmented TV, since animated 3DCG content interlocked with TV programs is overlaid on live video from the mobile device camera in the mobile device screen by augmented reality techniques, the representation of having a TV character coming out of the screen can be provided. To achieve the representation giving such surprise or reality to the viewer, synchronization accuracy of the overlay display is required. A conventional synchronization method for multi-device or a visible light communication method does not meet the requirement of the accuracy. Therefore, we developed an accurate synchronization method and authoring environment of augmented TV content. We implemented augmented TV, and confirmed frame-accurate synchronization (synchronization error time is about 0.03 seconds or less). And we confirmed that the authoring environment is easy to produce augmented TV content using a video clip using a 3DCG character with TV program quality.","","978-1-4799-3824-7","10.1109/ICMCS.2014.6911158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911158","Augmented TV;Augmented Reality;Second Screen;Synchronization Method;Authoring Environment","TV;Cameras;Tin;Internet;Mobile handsets;Accuracy;Software","augmented reality;authoring systems;computer animation;mobile computing;mobile television;multimedia systems;synchronisation","augmented reality system;TV programs;TV screen;TV service;animated 3DCG content;live video;mobile device camera;mobile device screen;augmented reality technique;TV character;synchronization accuracy;overlay display;synchronization method;multidevice method;visible light communication method;authoring environment;augmented TV content;frame-accurate synchronization;synchronization error time;video clip;3DCG character;TV program quality","","11","8","15","IEEE","29 Sep 2014","","","IEEE","IEEE Conferences"
"Augmenting markerless complex 3D objects by combining geometrical and color edge information","A. Petit; E. Marchand; K. Kanani",INRIA Rennes; IRISA; Astrium,"2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","287","288","This paper presents a method to address the issue of augmenting a markerless 3D object with a complex shape. It relies on a model-based tracker which takes advantage of GPU acceleration and 3D rendering in order to handle the complete 3D model, whose sharp edges are efficiently extracted. In the pose estimation step, we propose to robustly combine geometrical and color edge-based features in the nonlinear minimization process, and to integrate multiple-hypotheses in the geometrical edge-based registration phase. Our tracking method shows promising results for augmented reality applications, with a Kinect-based reconstructed 3D model.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671808","3D visual tracking;model-based tracking","Three-dimensional displays;Solid modeling;Image edge detection;Image color analysis;Robustness;Augmented reality;Computational modeling","augmented reality;edge detection;feature extraction;graphics processing units;image colour analysis;image reconstruction;image registration;object tracking;pose estimation;rendering (computer graphics);solid modelling","markerless complex 3D object augmentation;geometrical information;color edge information;model-based tracker;GPU acceleration;3D rendering;3D model;sharp edge extraction;pose estimation step;geometrical feature;color edge-based feature;nonlinear minimization process;geometrical edge-based registration phase;tracking method;augmented reality applications;Kinect-based reconstructed 3D model","","9","","6","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"How to augment the second image? Recovery of the translation scale in image to image registration","P. Georgel; P. Schroeder; S. Benhimane; M. Appel; N. Navab","CAMP, Technical University of München, Germany; CAMP, Technical University of München, Germany; CAMP, Technical University of München, Germany; Siemens Corporate Technology, Germany; CAMP, Technical University of München, Germany","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","171","172","In this paper, we present an automatic pose estimation (6 DoF) technique to augment images using keyframes pre-registered to a CAD model. State of the art techniques recover the essential matrix (5 DoF) in an automatic manner, but include a manual step to align the image with the CAD reference system because the essential matrix does not provide the scale of the translation. We propose using planar structures to recover this scale automatically and to offer immediate augmentation. These techniques have been implemented in our augmented reality software. Qualitative tests are performed in an industrial environment.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637351","","Three dimensional displays;Solid modeling;Design automation;Computational modeling;Streaming media;Distance measurement;Augmented reality","augmented reality;CAD;image registration;pose estimation","image translation scale;image registration;automatic pose estimation technique;CAD reference system;planar structures;augmented reality software","","5","3","11","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"User-Defined Interaction Using Everyday Objects for Augmented Reality First Person Action Games","M. Greenslade; A. Clark; S. Lukosch","HIT Lab NZ, University of Canterbury; School of Product Design, University of Canterbury; HIT Lab NZ, University of Canterbury","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","842","843","In this paper, we present an elicitation study to explore how people use everyday objects for augmented reality first person games. 24 participants were asked to select items from a range of everyday objects to use as controllers for three different classes of virtual object. Participants completed tasks using their selected items and rated the experience using the Augmented Reality Immersion (ARI) questionnaire. Results indicate no strong consensus linking any specific everyday object to any virtual object across our testing population. Based on these findings, we recommend developers provide the ability for users to choose the everyday objects they prefer.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757463","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality—Human-centered computing—Human computer interaction;(HCI)—HCI design and evaluation methods—User studies—Interaction design—Interaction design process and methods—Participatory design","Three-dimensional displays;Design methodology;Conferences;Sociology;Games;User interfaces;Task analysis","augmented reality;computer games","virtual object;user-defined interaction;augmented reality immersion questionnaire;augmented reality first person action games;ARI questionnaire","","1","","7","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Voice-based Augmented Reality Interactive System for Car’s Components Assembly","D. Aouam; S. Benbelkacem; N. Zenati; S. Zakaria; Z. Meftah","Centre de développement des technologies avancées (CDTA), Baba-Hassen, Alger; Centre de développement des technologies avancées (CDTA), Baba-Hassen, Alger; Centre de développement des technologies avancées (CDTA), Baba-Hassen, Alger; Université Saad Dahlab Blida 1, Route de Soumâa, Blida; Université Saad Dahlab Blida 1, Route de Soumâa, Blida","2018 3rd International Conference on Pattern Analysis and Intelligent Systems (PAIS)","3 Jan 2019","2018","","","1","5","In this paper, we propose a voice-based interaction technique applied to an augmented reality (AR) system for automobile assembly / disassembly. We use the speech signal to perform the interaction with augmented reality environment. This latter is composed of virtual car's components inserted in the real scene. Thanks to Windows Voice Recognition, the voice commands are recognized and translated into textual commands and they are interpreted in internal order by the AR system. This allows the user to manipulate the different parts and view them by simply giving voice commands, such as the designation of objects by their name to make them appear or move them indicating the next position.","","978-1-5386-4238-2","10.1109/PAIS.2018.8598516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598516","","Speech recognition;Servers;Augmented reality;Three-dimensional displays;Automotive engineering;Task analysis;Synchronization","assembling;augmented reality;interactive systems;speech recognition","augmented reality system;automobile assembly;augmented reality environment;virtual car;voice commands;AR system;Windows voice recognition;voice-based augmented reality interactive system","","3","","12","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"Paper-Based Augmented Reality","J. J. Hull; B. Erol; J. Graham; Q. Ke; H. Kishi; J. Moraleda; D. G. Van Olst","California Research Center, Ricoh Innovations, Inc., Menlo Park, CA, USA; California Research Center, Ricoh Innovations, Inc., Menlo Park, CA, USA; California Research Center, Ricoh Innovations, Inc., Menlo Park, CA, USA; California Research Center, Ricoh Innovations, Inc., Menlo Park, CA, USA; California Research Center, Ricoh Innovations, Inc., Menlo Park, CA, USA; California Research Center, Ricoh Innovations, Inc., Menlo Park, CA, USA; California Research Center, Ricoh Innovations, Inc., Menlo Park, CA, USA","17th International Conference on Artificial Reality and Telexistence (ICAT 2007)","2 Jan 2008","2007","","","205","209","A new method for augmenting paper documents with electronic information is described that does not modify the format of the paper document in any way. Applicable to both commercially printed documents as well as documents that are output from PC's, the technique we call Paper-Based Augmented Reality substantially improves the utility of paper. We describe the recognition technology that makes this possible as well as several applications. An implementation on a camera phone is discussed that lets users retrieve data and access links from paper documents to electronic data. Recognition is performed at 4 frames per second on a Treo 700w and support is provided for several user applications, including ""clickable paper"" -- printed web pages whose appearance is unchanged but that can be navigated with a camera phone.","","0-7695-3056-7","10.1109/ICAT.2007.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414635","camera phone;paper documents;data links","Augmented reality;Cameras;Text recognition;Image recognition;Indexing;Information retrieval;Web pages;Uniform resource locators;Image databases;Technological innovation","augmented reality;document image processing","paper-based augmented reality;paper document augmentation;electronic information;commercially printed document;recognition technology;electronic data;printed Web page","","31","17","8","IEEE","2 Jan 2008","","","IEEE","IEEE Conferences"
"Physics Based Deformation Using Shape Matching in Augmented Reality Environments","H. K. Choi; H. S. Kim; W. J. Park; K. H. Lee","GIST, Gwangju Institute of Science and Technology, South Korea; GIST, Gwangju Institute of Science and Technology, South Korea; GIST, Gwangju Institute of Science and Technology, South Korea; GIST, Gwangju Institute of Science and Technology, South Korea","2008 International Symposium on Ubiquitous Virtual Reality","18 Jul 2008","2008","","","47","50","The importance of the deformation and physics based deformation methods are continuously increasing in computer graphics area. However, the user interaction and reality using them is still insufficient for the various applications such as modeling process and game industry. In this paper, we propose physics based deformation technology under AR (augmented reality) environments to improve the effectiveness of the model manipulation. In the proposed method, free form deformation and lattice shape matching method are combined first for the stable and fast deformation of the polygonal model. Then dynamics of the lattice shape matching region is applied for the physics based deformation. Finally those algorithms are implemented under AR environment. For the various physics based simulations, the adjustment of the material properties such as elasticity and damping ratio are also enable.","","978-0-7695-3259-2","10.1109/ISUVR.2008.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568644","","Physics;Shape;Augmented reality;Deformable models;Lattices;Computer graphics;Application software;Toy industry;Material properties;Elasticity","augmented reality;computer graphics;image matching;user interfaces","physics based deformation;shape matching;augmented reality environments;computer graphics;modeling process;game industry;polygonal model","","3","","14","IEEE","18 Jul 2008","","","IEEE","IEEE Conferences"
"Dynamic texturing of real objects in an augmented reality system","K. Matkovic; T. Psik; I. Wagner; D. Gracanin","VRVis Res. Center, Vienna, Austria; NA; NA; NA","IEEE Proceedings. VR 2005. Virtual Reality, 2005.","15 Aug 2005","2005","","","245","248","The ability to physically change properties of real objects used in augmented reality (AR) applications is limited. Geometrical properties (shape, size) and appearance (color, texture) of a real object remain unchanged during a single application run. However, an AR system can be used to provide a virtual texture for the real object. The texture can be changed dynamically based on user interactions. The developed AR system includes two components, the ""3D Table"" and the ""Texture Painter"". The 3D Table is a table where real objects are placed. The tabletop is used as a projection surface, making it possible to add a context to the real object. The Texture Painter makes it possible to paint on the real object, using a real brush and virtual ink (texture). ARToolkit markers are placed on the 3D Table tabletop to augment the environment with the virtual objects. Markers are either physical (printouts on the tabletop) or virtual (projections). The scene is recorded with a camera and the composed video is projected in real time. The projection shows a virtual environment, real objects painted with virtual ink, and virtual objects positioned where real or virtual ARToolkit markers are placed. The developed system is used in architectural design applications where, due to the different qualities of real architectural models and rendered architectural models, real models are still used. The system was tested at the Academy of Fine Arts in Vienna where it is used as a support tool for architecture students.","2375-5334","0-7803-8929-8","10.1109/VR.2005.1492781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1492781","","Augmented reality;Ink;Shape;Paints;Brushes;Layout;Cameras;Virtual environment;System testing;Art","architecture;image texture;rendering (computer graphics);computational geometry;computer aided instruction;augmented reality;user interfaces;real-time systems","dynamic object texturing;real objects;augmented reality system;geometrical properties;object shape;object size;object appearance;object color;virtual texture;user interactions;3D Table;Texture Painter;projection surface;virtual ink;ARToolkit markers;camera;video projection;virtual environment;virtual objects;architectural design;rendering;Academy of Fine Arts;Vienna;Austria;architecture students;user interface;image texture","","2","2","8","IEEE","15 Aug 2005","","","IEEE","IEEE Conferences"
"Dynamic Texturing of Real Objects in an Augmented Reality System","K. Matkovic; T. Psik; I. Wagner; D. Gracanin","VRVis Research Center, Vienna, Austria; Institute of Design and Assessment of Technology, University of Technology, Vienna, Vienna, Austria; Institute of Design and Assessment of Technology, University of Technology, Vienna, Vienna, Austria; Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA","IEEE Proceedings. VR 2005. Virtual Reality, 2005.","15 Aug 2005","2005","","","257","260","The ability to physically change properties of real objects used in augmented reality (AR) applications is limited. Geometrical properties (shape, size) and appearance (color, texture) of a real object remain unchanged during a single application run. However, an AR system can be used to provide a virtual texture for the real object. The texture can be changed dynamically based on user interactions. The developed AR system includes two components, the ""3D Table"" and the ""Texture Painter."" The 3D Table is a table where real objects are placed. The tabletop is used as a projection surface, making it possible to add a context to the real object. The Texture Painter makes it possible to paint on the real object, using a real brush and virtual ink (texture). ARToolkit markers are placed on the 3D Table tabletop to augment the environment with the virtual objects. Markers are either physical (printouts on the tabletop) or virtual (projections). The scene is recorded with a camera and the composed video is projected in real time. The projection shows a virtual environment, real objects painted with virtual ink, and virtual objects positioned where real or virtual ARToolkit markers are placed. The developed system is used in architectural design applications where, due to the different qualities of real architectural models and rendered architectural models, real models are still used. The system was tested at the Academy of Fine Arts in Vienna where it is used as a support tool for architecture students.","2375-5334","0-7803-8929-8","10.1109/VR.2005.1492784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1492784","","Augmented reality;Ink;Shape;Paints;Brushes;Layout;Cameras;Virtual environment;System testing;Art","augmented reality;haptic interfaces;medical robotics;surgery;laser applications in medicine;force feedback;medical computing","augmented reality;haptic feedback;visible trajectory;conceptual surgical laser system;surgical robot;visual feedback;haptic laser system;low-power laser;noncutting laser;haptic interface","","1","1","12","IEEE","15 Aug 2005","","","IEEE","IEEE Conferences"
"Augmented reality based teaching in classrooms","F. Abbasi; A. Waseem; E. Ashraf","Department of Computer Science, Bahria University, Islamabad, Pakistan; Department of Computer Science, Bahria University, Islamabad, Pakistan; Department of Computer Science, Bahria University, Islamabad, Pakistan","2017 International Conference on Communication, Computing and Digital Systems (C-CODE)","4 May 2017","2017","","","259","264","Augmented reality is a useful technique and has been of interest to researchers recently. Many real-life applications ranging from games to learning have been developed using augmented reality. The aim of this work is to improve student's understanding of realistic phenomenon of nature and enhance their capabilities towards learning. Augmented reality technique has proved itself in education as it replaces memory based learning to fun driven and conceptual schooling. In this paper, we have proposed an algorithm to support marker based augmented reality teaching methodology. A controlled experimental lecture in classroom was conducted with the usage of augmented reality technique. The delivered lecture was then compared with the traditional method of teaching. Post and pre-test were conducted to record the student's understanding which depicted that the proposed augmented reality teaching method is more proficient than the traditional one and plays significant role in improving student's grades.","","978-1-5090-4448-1","10.1109/C-CODE.2017.7918939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7918939","Augmented Reality (AR);Marker based augmented Reality (MAR);Conceptual Schooling;Augmented Reality Technique","Chemistry;Education;Compounds;Smart phones;Games;Three-dimensional displays;Engineering profession","augmented reality;computer aided instruction;teaching","classrooms;marker based augmented reality teaching methodology;controlled experimental lecture","","6","","16","IEEE","4 May 2017","","","IEEE","IEEE Conferences"
"A Conceptual Model and Taxonomy for Collaborative Augmented Reality","B. Marques; S. Silva; J. Alves; T. Araújo; P. Dias; B. S. Santos","IEETA, DETI, University of Aveiro, Aveiro, Portugal; IEETA, DETI, University of Aveiro, Aveiro, Portugal; IEETA, DETI, University of Aveiro, Aveiro, Portugal; PPGCC, Federal University of Pará, Belém, Brasil; IEETA, DETI, University of Aveiro, Aveiro, Portugal; IEETA, DETI, University of Aveiro, Aveiro, Portugal","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2022","2022","28","12","5113","5133","To support the nuances of collaborative work, many researchers have been exploring the field of Augmented Reality (AR), aiming to assist in co-located or remote scenarios. Solutions using AR allow taking advantage from seamless integration of virtual objects and real-world objects, thus providing collaborators with a shared understanding or common ground environment. However, most of the research efforts, so far, have been devoted to experiment with technology and mature methods to support its design and development. Therefore, it is now time to understand where the field stands and how well can it address collaborative work with AR, to better characterize and evaluate the collaboration process. In this article, we perform an analysis of the different dimensions that should be taken into account when analysing the contributions of AR to the collaborative work effort. Then, we bring these dimensions forward into a conceptual framework and propose an extended human-centered taxonomy for the categorization of the main features of Collaborative AR. Our goal is to foster harmonization of perspectives for the field, which may help create a common ground for systematization and discussion. We hope to influence and improve how research in this field is reported by providing a structured list of the defining characteristics. Finally, some examples of the use of the taxonomy are presented to show how it can serve to gather information for characterizing AR-supported collaborative work, and illustrate its potential as the grounds to elicit further studies.","1941-0506","","10.1109/TVCG.2021.3101545","Foundation for Science and Technology; Institute of Electronics and Informatics Engineering of Aveiro; FCT(grant numbers:UID/CEC/00127/2019); Portugal2020; Competitiveness and Internationalization Operational Program; European Regional Development Fund(grant numbers:CENTRO-01-0145-FEDER-000010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506837","Collaboration;augmented reality;conceptual model;taxonomy;human-centered;systematization","Collaboration;Taxonomy;Collaborative work;Augmented reality;Visualization;Augmented reality;Three-dimensional displays;Human computer interaction","augmented reality;groupware","AR-supported collaborative work;collaboration process;collaborative AR;Collaborative Augmented Reality;conceptual model;extended human-centered taxonomy;real-world objects;virtual objects","Humans;Augmented Reality;Computer Graphics","21","","120","IEEE","4 Aug 2021","","","IEEE","IEEE Journals"
"An intuitional interface for invocation of Chinese painting","H. B. -L. Duh; C. -H. Chen; C. C. -C. Su; R. K. C. Koh","IDMI / ECE, National University of Singapore, Singapore; Department of industrial design, National Cheng Kung University, Taiwan; Department of industrial design, National Cheng Kung University, Taiwan; IDMI / ECE, National University of Singapore, Singapore","2009 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media and Humanities","17 Nov 2009","2009","","","53","54","This study establishes a new painting experience that entails an AR-based approach that augments regular freehand 2D sketches into a Chinese painting artwork. Within the study, the realistic diffusion of ink can be interactively generated for users to create works inspired by the Chinese painting style as well as to unveil the opportunity for users to model up their own augmented information without any pre-building processes, potentially spanning the applications of AR in alternate directions.","2381-8360","978-1-4244-5508-9","10.1109/ISMAR-AMH.2009.5336722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336722","Augmented Reality;Interaction design;J.5 [ARTS AND HUMANITIES];Arts;fine and performing","Painting;Art;Augmented reality;Cameras;Ink;Application software;Algorithm design and analysis;Subspace constraints;Hardware;Software performance","art;augmented reality;interactive devices","intuitional interface;painting experience;augmented reality;freehand 2D sketch;Chinese painting artwork;realistic ink diffusion","","1","","4","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Feasible mid-air virtual reality with the immaterial projection screen technology","I. Rakkolainen","Tampere University of Technology, Tampere, Finland","2010 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video","8 Jul 2010","2010","","","1","4","The immaterial projection screen is an emerging display technology that enables high-quality projected images in mid-air. It can be extended to virtual reality (VR) and augmented reality (AR) mid-air displays. In order to make such mid-air VR and AR displays feasible, unobtrusive and low-cost user tracking solutions are needed. In this paper we present such feasible desktop VR and AR mid-air displays.","2161-203X","978-1-4244-6379-4","10.1109/3DTV.2010.5506314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5506314","3D displays;mid-air displays;FogScreen;virtual reality;augmented reality;mixed reality","Virtual reality;Computer displays;Augmented reality;Three dimensional displays;TV;User interfaces;Spatial resolution;Brightness;Mie scattering;Motion pictures","augmented reality;screens (display)","immaterial projection screen technology;feasible mid-air virtual reality;display technology;augmented reality","","10","","12","IEEE","8 Jul 2010","","","IEEE","IEEE Conferences"
"Advanced Interaction and Virtual\/Augmented Reality-Part II: A Look at Novel Applications","F. Lamberti; F. Pescador","Department of Control and Computer Engineering, Politecnico di Torino, Italy; Universidad Politécnica de Madrid, Spain","IEEE Consumer Electronics Magazine","6 Apr 2018","2018","7","3","62","63","Approaching this broad and timely topic has called for a variety of contributions pertaining to ongoing technical developments, practical applications and use cases, user studies and evaluations, standardization efforts, and next-generation technologies in the two fields of advanced interaction and virtual/augmented reality. The overall theme has been split into two parts, the first focused mostly on human-machine interaction and appeared in the March 2018 issue of IEEE Consumer Electronics Magazine. This second part deals with novel applications of virtual and augmented reality.","2162-2256","","10.1109/MCE.2018.2797623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8333004","","Virtual reality;Augmented reality;Sensors;Internet of Things;Urban areas;Data visualization;Solid modeling","augmented reality;consumer electronics;human computer interaction","advanced interaction;ongoing technical developments;practical applications;user studies;standardization efforts;next-generation technologies;human-machine interaction;virtual reality;augmented reality;IEEE Consumer Electronics Magazine","","3","","","IEEE","6 Apr 2018","","","IEEE","IEEE Magazines"
"Summary: 2017 IEEE virtual reality second workshop on K-12 embodied learning through Virtual & Augmented Reality (KELVAR)","I. Radu; E. Southgate; F. Ortega; S. Smith",Georgia Institute of Technology; University of Newcastle; Florida International University; University of Newcastle,"2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual & Augmented Reality (KELVAR)","29 Jun 2017","2017","","","1","2","Summary form only given. The complete presentation was not made available for publication as part of the conference proceedings. In this workshop we aim to bring together developers and researchers who are interested in creating educational experiences for the classroom of the future. The workshop will enable participants to discuss and be exposed to different approaches for integrating virtual-, augmented- and mixed-reality technologies, specifically focusing on the challenges and potential for embodied learning in the classroom.","","978-1-5386-1892-9","10.1109/KELVAR.2017.7961555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961555","","Augmented reality;Conferences;Education;Three-dimensional displays;Psychology;Cognition","","","","2","","","IEEE","29 Jun 2017","","","IEEE","IEEE Conferences"
"Making Augmented Reality Practical on Mobile Phones, Part 1","D. Wagner; D. Schmalstieg","University of Technology; Graz University of Technology, Austria","IEEE Computer Graphics and Applications","5 May 2009","2009","29","3","12","15","In 2003, we started an AR framework for mobile phones. We intended its first generation as primarily a proof of feasibility. The second generation was an attempt to port a fully featured PC-based AR framework, Studierstube 4, to a phone platform. You can port existing applications and make them run on mobile phones. However, as we had to painfully experience ourselves, this approach typically produces slow, bloated, and unstable software. Optimally using phones' scarce resources requires different algorithms and architectural decisions than for PCs, leading to a complete reengineering of an existing solution. So, for the third generation, Studierstube ES, we largely abandoned compatibility requirements and added new elements to the design, such as an asymmetric client-server technique, that are specific to mobile devices. In this first installment of our two-part tale of Studierstube ES and what we've learned along the way, we describe the mobile phone platform's restrictions and how our software architecture allows fast development of mobile phone AR applications.","1558-1756","","10.1109/MCG.2009.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4909113","augmented reality;mobile phones;software development;embedded systems","Augmented reality;Mobile handsets;Application software;Personal communication networks;Target tracking;Smart phones;Software architecture;Hardware;Programming;Bandwidth","augmented reality;software architecture","mobile phones;handheld augmented reality;Studierstube ES;software architecture","Algorithms;Cell Phone;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Theoretical;User-Computer Interface","36","4","3","IEEE","5 May 2009","","","IEEE","IEEE Magazines"
"Mixed Reality for Cultural Heritage","D. A. Plecher; M. Wandinger; G. Klinker",Technical University of Munich; Technical University of Munich; Technical University of Munich,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1618","1622","In this paper we present two different approaches with Mixed (Virtual and Augmented) Reality to give pupils an understanding of ancient Greek culture and history in a motivating way. We identify the possibilities of AR in a museum for ancient statues to represent virtual information and to guide the visitor. Moreover, we discuss typical issues of mobile and stationary Virtual Reality (VR) systems in the context of public usage within schools and museums. Additionally, a new VR-streaming approach called SaMaXVR is presented that combines the benefits of mobile and stationary consumer ready VR systems in terms of usability, maintenance, safety and graphics-quality by mitigating many of their individual disadvantages when used in daily business. As this streaming solution consists of cost-effective hardware, this approach can be seen as a valuable and affordable alternative for schools, museums and students. To demonstrate its potential, an application was developed that visualizes complex 3D scans of cultural heritage in their former original environment to give users the possibility to travel back in time (and place) to see how the artifacts might have looked like in the past.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797846","Mixed Reality;Virtual Reality;Augmented Reality;Cultural Heritage","Hardware;Cultural differences;Virtual reality;Three-dimensional displays;Visualization;Resists;Maintenance engineering","augmented reality;data visualisation;history;museums","cultural heritage;history;ancient statues;virtual information;public usage;museums;VR-streaming approach;mobile consumer ready VR systems;stationary consumer ready VR systems;safety;graphics-quality;mixed reality;SaMaXVR;ancient Greek culture;complex 3D scans;virtual reality;augmented reality","","17","","20","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Augmented Reality based Cockpit Module Assembly System","H. -S. Park; H. -W. Choi; J. -W. Park","School for Mechanical and Automotive Engineering, University of Ulsan, Ulsan, South Korea; School for Mechanical and Automotive Engineering, University of Ulsan, Ulsan, South Korea; School for Mechanical and Automotive Engineering, University of Ulsan, Ulsan, South Korea","2008 International Conference on Smart Manufacturing Application","2 May 2008","2008","","","130","135","Because of global competition, most of automobile manufacturer try to reduce the cost and time for the implementation of manufacturing system. The AR technology as a new man-machine interface introduces a noteworthy perspective for a new manufacturing system. Because virtual objects are superimposed to real scene, system planner can design and validate the new system without modeling the surrounding environment of production domain during short process planning time. In this paper, the architecture of AR browser is introduced and the optimal environment parameters for practical application of AR system are determined through lots of tests. Moreover, many methods such as multi-marker coordinate system, partition of virtual objects and so on, are proposed in order to solve the problems suggested from the initial practical test. Based on these tests and results, the test bed of a cockpit module assembly system is configured and operation program for cockpit module assembly is generated using the AR system.","","978-89-950038-8-6","10.1109/ICSMA.2008.4505627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4505627","Augmented Reality;AR browser architecture;Robust superimposition;Cockpit module assembly system","Augmented reality;Assembly systems;System testing;Manufacturing systems;Automobile manufacture;Costs;User interfaces;Layout;Production systems;Process planning","assembling;augmented reality;automobile manufacture;manufacturing systems;process planning;production engineering computing;user interfaces","augmented reality;cockpit module assembly system;automobile manufacturer;manufacturing system;man-machine interface;virtual objects;process planning time;multi-marker coordinate system","","10","","4","","2 May 2008","","","IEEE","IEEE Conferences"
"Poster: A wearable augmented reality system with haptic feedback and its performance in virtual assembly tasks","K. Murakami; R. Kiyama; T. Narumi; T. Tanikawa; M. Hirose","Graduate School of Information Science and Technology, University of Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Japan; Graduate School of Information Science and Technology, University of Tokyo, Japan","2013 IEEE Symposium on 3D User Interfaces (3DUI)","5 Sep 2013","2013","","","161","162","Haptic feedback is important to improve the operability of virtual objects. However, AR systems with haptic feedback are still not many. Moreover, users cannot perform tasks that need large workspaces in those systems because of physical constraints from haptic feedback devices. In this paper, we combined a wearable haptic device and a marker-less AR technology to develop an AR system in which users can perform activities that need large workspaces. Differences of the operability of virtual objects in an assembly task of large machines are examined to evaluate effects of the haptic feedback in this system. The result indicates that haptic feedback is effective and users can perform activities that need large space in this system.","","978-1-4673-6098-2","10.1109/3DUI.2013.6550228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6550228","Haptic;Wearable;Augmented Reality;3D Interaction","Haptic interfaces;Assembly;Augmented reality;Performance evaluation;Force;Gears;Three-dimensional displays","assembling;augmented reality;haptic interfaces;human computer interaction;wearable computers","wearable augmented reality system;haptic feedback devices;virtual assembly tasks;virtual object operability improvement;AR systems;wearable haptic device;marker-less AR technology","","10","1","4","IEEE","5 Sep 2013","","","IEEE","IEEE Conferences"
"Using augmented reality smart glasses to design games for cognitive training","Y. -J. Chang; H. -H. Liu; Y. -s. Kang; C. C. Kao; Y. -S. Chang","Department of Electronic Engineering, Chung Yuan Christian University, Chung-Li, Taiwan; Department of Electronic Engineering, Chung Yuan Christian University, Chung-Li, Taiwan; Department of Electronic Engineering, Chung Yuan Christian University, Chung-Li, Taiwan; Department of Electronic Engineering, Chung Yuan Christian University, Chung-Li, Taiwan; Department of Tourism and Leisure Management, Chung Chou University of Science and Technology, Chang-Hua, Taiwan","2016 13th International Conference on Remote Engineering and Virtual Instrumentation (REV)","31 Mar 2016","2016","","","252","253","To develop and test a cognitive therapy game using smart glasses (SiME; Taipei, Taiwan) in an interactive object game. Using the smart glasses as an input device, an interactive object game for cognitive rehabilitation, in which players accomplished a virtual food preparation task by making various choices, was developed. Over the course of 17 sessions, which were divided into baseline, intervention, and maintenance phases, under a multiple baseline design, three participants with different levels of cognitive impairment interacted with the game, and user performance data were collected during the gameplay. Three participants significantly increased their target responses during the intervention phase. In addition, they maintained their virtual food preparation performance after the intervention phase. The developed game can be an effective method for delivering cognitive rehabilitation for a diverse population.","","978-1-4673-8246-5","10.1109/REV.2016.7444474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444474","augmented reality;task prompting;cognitive impairments;community-based rehabilitation;smart glasses","Glass;Games;Employment;Training;Google;Augmented reality;Sociology","augmented reality;cognitive systems;virtual instrumentation","augmented reality smart glasses;cognitive training;cognitive therapy;cognitive rehabilitation","","8","","3","IEEE","31 Mar 2016","","","IEEE","IEEE Conferences"
"Poster: The NetEyes Collaborative, Augmented Reality, Digital Paper System","D. McGee; X. Huang; P. Barthelmess; P. Cohen","Adapx, Inc., Seattle, WA, USA; Adapx, Inc., Seattle, WA, USA; Adapx, Inc., Seattle, WA, USA; Adapx, Inc., Seattle, WA, USA","2008 IEEE Symposium on 3D User Interfaces","31 Mar 2008","2008","","","145","146","NetEyes is a system that allows remote and co-located partners to collaborate by annotating maps printed on digital paper. It combines natural language capabilities, in particular the interpretation of sketched symbols, with the display of three-dimensional representations of recognized objects, allowing users to jointly visualize a planned or evolving situation in detail. Visualization can take place either on a conventional monitor or through optical see-though, head-mounted displays. Seamless collaboration is promoted via the use of tangible paper maps, which makes it possible for multiple parties sitting around a table to place annotations as they would using regular paper and pen. To account for movements and rotation of the maps that are common during collaborative annotation sessions, a vision-based tracking component is used. This component recovers the location of the paper map in the real-world, and scales and rotates the digitally displayed objects so that they keep aligned with the map.","","978-1-4244-2047-6","10.1109/3DUI.2008.4476609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4476609","Tangible Interfaces;Collaborative Interfaces;3D interfaces;Digital Paper;Natural Language Interaction;Augmented reality;Vision-based tracking;H5.3 [Group and Organization Interfaces]: Collaborative Computing;Synchronous Interaction;H.5.2 [User Interfaces]: Input devices and strategies","Collaboration;Augmented reality;Three dimensional displays;Visualization;Collaborative work;Natural languages;Monitoring;User interfaces;Tracking;Computer interfaces","augmented reality;data visualisation;groupware","NetEyes;augmented reality;digital paper system;natural language capability;head-mounted display;seamless collaboration;tangible paper map;collaborative annotation;vision-based tracking component","","5","","6","IEEE","31 Mar 2008","","","IEEE","IEEE Conferences"
"Implementing Augmented Reality Using Microsoft Kinect","K. Németh; V. B. Czinder; A. Molnár","John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary; John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary; John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary","2018 IEEE 22nd International Conference on Intelligent Engineering Systems (INES)","8 Nov 2018","2018","","","000225","000230","This project was created to provide a spectacular and interactive way of teaching geography to the new generation, whose members are often visual learners. The system, consisting of a Microsoft Kinect sensor, a projector, a computer, and a box filled with sand, can visualize topography and it can show in real time, that how changing the terrain affects the map created by it. From the surface of the sand, a topographical map is created with the well know colours and contour lines of these maps, and then it is projected back to the surface, reacting to any change of the sand's structure in real time. With the help of different computer algorithms, the system is configurable to create the output by the needs of the operator.","1543-9259","978-1-5386-1122-7","10.1109/INES.2018.8523979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8523979","Microsoft Kinect;augmented reality;geography","Image color analysis;Augmented reality;Surface topography;Software;Real-time systems;Interpolation;Informatics","augmented reality;computer aided instruction;geography;surface topography;teaching","geography;visual learners;Microsoft Kinect sensor;topography;topographical map;augmented reality","","2","","9","IEEE","8 Nov 2018","","","IEEE","IEEE Conferences"
"Research on Eye-gaze Tracking Network Generated by Augmented Reality Application","M. Chen; Y. Chen; Z. Yao; W. Chen; Y. Lu","Shanghai University, Shanghai, China; Shanghai University, Shanghai, China; Shanghai University, Shanghai, China; Shanghai University, Shanghai, China; Shanghai University, Shanghai, China","2009 Second International Workshop on Knowledge Discovery and Data Mining","2 Feb 2009","2009","","","594","597","Eye gaze control is playing an important role in AR system. However, the physiology mechanism of eye gaze control canpsilat be totally understood for the limitation of biomedicine presently. The research on evolving networks has been widely studied recently and the degree distributions of these networks are of a power-law form. To enhance the calibration accuracy and improve the judgment effects of gazing objects, in this paper, the property of eye gaze tracking network is studied according to those methods used in complex network. The eye gaze tracking network model inserted position information and achievement probability was established and the degree distribution was discussed. Simulation results show that the degree distribution of eye gaze tracking network is scale-free.","","978-0-7695-3543-2","10.1109/WKDD.2009.73","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4772007","augmented reality;eye-gaze tracking;complex network;scale free","Augmented reality;Control systems;Eyes;Physiology;Calibration;Complex networks;Data mining;Internet;Displays;Video recording","augmented reality;eye;medicine;physiology","eye-gaze tracking network;augmented reality application;eye gaze control;AR system;physiology mechanism;biomedicine;gazing objects;degree distribution","","2","10","13","IEEE","2 Feb 2009","","","IEEE","IEEE Conferences"
"Development of a PC-based markerless augmented reality","T. S. Yee; H. Arshad; A. Abdullah","Center for Artificial Intelligence Technology (CAIT), Universiti Kebangsaan Malaysia (UKM), Selangor, Malaysia; Center for Artificial Intelligence Technology (CAIT), Universiti Kebangsaan Malaysia (UKM), Selangor, Malaysia; Center for Artificial Intelligence Technology (CAIT), Universiti Kebangsaan Malaysia (UKM), Selangor, Malaysia","2015 International Conference on Electrical Engineering and Informatics (ICEEI)","17 Dec 2015","2015","","","49","53","AR applications are divided into two major types; marker-based and markerless AR. Some applications of AR such as in education and training are still being implemented on PC where the use of mobile and wearable devices are not possible. This paper presents the development of a PC-based markerless AR application. Four main components in markerless AR development; detector, descriptor, matcher and pose estimation are employed. This application used FAST as the detector, FREAK as the descriptor while BruteForce Matcher is used as the matcher algorithm. The reference image used is Graffiti from Mikolajczyk's dataset. The tracking process is tested for its robustness to rotation, scale, brightness and also blur changes. The application successfully rendered a 3D object on top of the reference image during the robustness test.","2155-6830","978-1-4673-7319-7","10.1109/ICEEI.2015.7352468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352468","Augmented Reality;Graffiti;Markerless;PC-based","Three-dimensional displays;Databases;Detectors;Augmented reality;Robustness;Brightness;Real-time systems","augmented reality;brightness;image matching;image restoration;object detection;pose estimation","PC-based markerless augmented reality development;marker-based AR;markerless AR;mobile devices;detector component;descriptor component;matcher component;pose estimation;FAST;FREAK;BruteForce matcher;reference image;Graffiti;Mikolajczyk dataset;image rotation;image scale;image brightness;image blur;robustness test;3D object rendered","","2","","24","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Supporting system with hand gesture for location-based augmented reality","J. Minagawa; W. Choi; S. Tsurumi; N. Hirakoso; N. Sasaki; L. Li; K. Hachimura","Advanced Production Systems Engineering Course, National Institute of Technology, Gunma College Maebashi, Japan; Advanced Production Systems Engineering Course, National Institute of Technology, Gunma College Maebashi, Japan; Advanced Production Systems Engineering Course, National Institute of Technology, Gunma College Maebashi, Japan; Advanced Production Systems Engineering Course, National Institute of Technology, Gunma College Maebashi, Japan; Advanced Production Systems Engineering Course, National Institute of Technology, Gunma College Maebashi, Japan; College of Information Science and Engineering, Ristumeikan University, Kusatsu, Japan; College of Information Science and Engineering, Ristumeikan University, Kusatsu, Japan","2015 IEEE 4th Global Conference on Consumer Electronics (GCCE)","4 Feb 2016","2015","","","479","480","We proposed a supporting system for location-based AR that enables user to handle virtual object without AR markers and hand mounting instruments. We also carried out design and implementation of the proposed system. It makes possible to calculate global coordinates of hands and recognize hand gestures through a combination of depth sensor, motion capture system, and head mounted display. To evaluate the performance of the proposed system, we carried out the taskes of moving, generating, and eliminating of virtual object. The recognition rates for all tasks are above 90%. Furthermore, because it is possible to handle virtual object with hand gestures by adopting depth sensor, the supporting system improved the disadvantages of AR marker method for location-based AR.","","978-1-4799-8751-1","10.1109/GCCE.2015.7398533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398533","augmented reality;hand gesture;human interface;location-based AR;wearable computing","Cameras;Graphical user interfaces;Augmented reality;Rocks;Instruments;Head;Wearable computers","augmented reality;gesture recognition;helmet mounted displays;image motion analysis;mobile computing","hand gesture recognition;augmented reality;supporting system;depth sensor;motion capture system;head mounted display;location-based AR","","1","","3","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"Marker Image Variables Measurement of Augmented Reality in Mobile Application","I. P. Windasari; Y. E. Windarto; R. Septiana","Department of Computer Engineering, Diponegoro University, Semarang, Indonesia; Department of Computer Engineering, Diponegoro University, Semarang, Indonesia; Department of Computer Engineering, Diponegoro University, Semarang, Indonesia","2018 5th International Conference on Information Technology, Computer, and Electrical Engineering (ICITACEE)","16 Dec 2018","2018","","","120","124","There are two ways to measure the success value estimation of AR technology based on mobile application. The first method is through the user opinions that will analyze the effect of AR usage on user directly. The second method is measuring the accuracy of the object virtual display that has many challenges to overcome. One of the problems that must be solved is to get appropriate measurement results for the virtual object to seem as perfect as the real object. Therefore, the various variable of measurement is required to ensure that objects created by AR technology in a mobile application are correct. This research purpose a reference to the measurement of object virtual accuracy by detecting the image marker from the point appropriately. Three components of image marker measured are finding the distance of the camera to the object, camera angle position, and impact of camera lens obstacle. The results of this research indicate the right position of the mobile device camera so virtual objects will be seen perfectly. The virtual object can be displayed if the camera distances are about 5-100 cm and the angles of the camera start from 300 to 900 with a maximum value of obstacle blocking the object is about 25%.","","978-1-5386-5529-0","10.1109/ICITACEE.2018.8576897","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576897","Augmented Reality Technology;Mobile Application;Virtual Object;Accuracy Measurement","Three-dimensional displays;Cameras;Mobile applications;Augmented reality;Mobile handsets;Two dimensional displays;Education","augmented reality;cameras;image processing;mobile computing","marker image variables measurement;augmented reality;mobile application;success value estimation;AR technology;object virtual display;appropriate measurement results;virtual object;object virtual accuracy;image marker measured;camera angle position;camera lens obstacle;mobile device camera","","1","","10","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Innovative 3D augmented reality techniques for spinal surgery applications","M. -L. Wang; J. -R. Wu; K. -C. Liu; P. -Y. Lee; Y. -Y. Chiang; H. -Y. Lin","Medical Image Research Department, IRCAD-Taiwan, Asian Institute of TeleSurgery, Changhua, Taiwan; Medical Image Research Department, IRCAD-Taiwan, Asian Institute of TeleSurgery, Changhua, Taiwan; Medical Image Research Department, IRCAD-Taiwan, Asian Institute of TeleSurgery, Changhua, Taiwan; Medical Image Research Department, IRCAD-Taiwan, Asian Institute of TeleSurgery, Changhua, Taiwan; Department of Electrical Engineering, National Chung Cheng University, Chiayi, Taiwan; Department of Electrical Engineering, National Chung Cheng University, Chiayi, Taiwan","2012 International Symposium on Intelligent Signal Processing and Communications Systems","7 Mar 2013","2012","","","16","20","This paper aims to be an outlet for speeding up workflow of orthopedics surgery and be helpful for surgeons to simply coordinate transformations between several imaging displays. Based on epipolar geometry and simple feature landmarks, a 3-D superimposed imaging approach is developed via the construction of the camera-projector system. The superimposed approach is to rectify the perspective, X-ray and projected image pair using the perspective projection model. The proposed method not only simplifies the computation between surgical instruments and patient for surgeons, but also reduces the radiation exposure. Experimental results for both the synthetic spinal image on dummy and real patient testing have demonstrated the feasibility of our approach.","","978-1-4673-5082-2","10.1109/ISPACS.2012.6473445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6473445","3-D Augmented Reality;Medical AR;Camera-projector system","Surgery;Cameras;Visualization;Three-dimensional displays;Solid modeling;Biomedical imaging;Augmented reality","augmented reality;cameras;medical image processing;optical projectors;surgery;three-dimensional displays;X-ray imaging","innovative 3D augmented reality technique;spinal surgery application;orthopedics surgery;imaging displays;epipolar geometry;feature landmarks;3D superimposed imaging approach;camera-projector system;X-ray-projected image pair;surgical instruments;surgeons;radiation exposure;synthetic spinal image;patient testing","","1","","21","IEEE","7 Mar 2013","","","IEEE","IEEE Conferences"
"Augmented Reality Solution for Retail Using Visual Commerce Engine","M. A. Kodandarama; S. Chandrashekar","Preksh Innovations Pvt. Ltd, Bangalore, India; Preksh Innovations Pvt. Ltd, Bangalore, India","2016 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)","19 Jan 2017","2016","","","173","175","Currently, the e-commerce platforms or websites are designed such that users search for products and they are not ""store centric"" rather product centric. Browsing products over such websites does not add any value to the stores. The below abstract shows the method and system of a Visual Commerce Engine. In this system, stores can come online and showcase their products and improve their branding in the marketplace. This system works best for stores where visual appeal plays a vital role. We are bridging the gap of a faraway shopper with the store, where the shopper can visit the store online, view the products (as if in store) and buy them on the spot in the high quality 360° virtual tour. We have added many shopping features (built using our software toolsets) which will give the shopper an interactive real experience in the store.","","978-1-5090-4573-0","10.1109/CCEM.2016.041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819694","Visual Commerce;Augmented reality for retail;Customer Engagement;Virtual guided tour for retail shopping","Business;Visualization;Engines;Electronic commerce;Standards;Augmented reality;Art","augmented reality;electronic commerce;information retrieval;Internet;retail data processing;Web sites","augmented reality;visual commerce engine;e-commerce platforms;e-commerce Websites;product centric search;online store;software toolsets;retail","","1","","3","IEEE","19 Jan 2017","","","IEEE","IEEE Conferences"
"Human Robot Interaction and Control: Translating Diagrams into an Intuitive Augmented Reality Approach","E. Lakshantha; S. Egerton","School of Information Technology, Monash University Malaysia, Malaysia; School of Information Technology, Monash University Malaysia, Malaysia","2014 International Conference on Intelligent Environments","29 Sep 2014","2014","","","111","116","Robots will play a vital role in our future personal spaces and we need to provide ways for robots and humans to interact with each other in a way that is natural, intuitive, descriptive and unambiguous. In this paper we introduce a framework that enables a human and robot to naturally interact and communicate with each other using the idea of diagrams. The diagrams are formed by a connected set of object markers placed in the environment. These markers can either be physically present in the environment or virtually present using marker-less technology. This paper presents a marker-less method for globally persistent markers. Diagrams are formed by connecting the objects together enabling the user to easily interact and control the robot in complex ways. We report on a proof-of-concept implementation of our framework and show how the framework can be used to program a robot to carry out navigation and action tasks within an environment.","","978-1-4799-2947-4","10.1109/IE.2014.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6910435","human robot interaction;augmented reality;robotics;vision-based navigation","Navigation;Robot sensing systems;Cameras;Robot kinematics;Augmented reality;Servers","augmented reality;control engineering computing;human-robot interaction;path planning","human robot interaction;intuitive augmented reality approach;diagrams translation;object markers;marker-less technology;globally persistent markers;navigation task;action task","","1","","12","IEEE","29 Sep 2014","","","IEEE","IEEE Conferences"
"Human-centered augmented reality manual arc welding active safety design","G. Shi; Y. Wang; Y. Liu; Xiaochao Guo; Mingzhao Sun; Duanqin Xiong","Institute of Aviation Medicine, Beijing, China; School of Optoelectronic, Beijing Institute of Technology, Beijing, China; School of Optoelectronic, Beijing Institute of Technology, Beijing, China; Institute of Aviation Medicine, Beijing, China; Institute of Aviation Medicine, Beijing, China; Institute of Aviation Medicine, Beijing, China","2011 International Conference on Computer Science and Service System (CSSS)","4 Aug 2011","2011","","","3264","3267","With the modern welding equipment progressing continually and the human-centered concept being accepted widely, the technology degree and safety standards of welder are demanded to farther reinforce. These needs the design of manual arc welding shield should consider both protective capability and assistant performance. But the conventional protection shield which based on the design of machine-centered is difficult to meet two needs of modern manual welding protection. According to the ideas of active safety and human-centered, considering the deficiency of visual information and the human physiological characteristic during welding, a helmet shield design has been developed which replaces the conventional protection shield with a video see-through helmet, where additional information is provided supplying artificial assistant elements. This design which can commendably achieve two needs of modern manual welding protection is an innovative manual welding protection design.","","978-1-4244-9763-8","10.1109/CSSS.2011.5974820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974820","active safety;human-centered;augmented reality (AR);manual welding","Welding;Manuals;Augmented reality;Safety;Visualization;Robot kinematics;Sun","arc welding;augmented reality;occupational safety;physiology;production engineering computing;safety systems;welding equipment","welding equipment progressing;human-centered concept;manual arc welding;conventional protection shield;machine-centered design;active safety;visual information;human physiological characteristic;helmet shield design;artificial assistant elements;manual welding protection;augmented reality","","","","","IEEE","4 Aug 2011","","","IEEE","IEEE Conferences"
"An improved MOBIL descriptor for markerless augmented reality","A. Bellarbi; N. Zenati-Henda; H. Belghit; M. Hamidia; S. Benbelkacem; S. Otmane","CDTAAlgiers, Algeria; Centre de Developpement des Technologies Avancees, Algiers, DZ; CDTAAlgiers, Algeria; CDTAAlgiers, Algeria; CDTAAlgiers, Algeria; IBISC Lab, University of Evry, France","2015 3rd International Conference on Control, Engineering & Information Technology (CEIT)","3 Sep 2015","2015","","","1","5","In this paper, we present an improved version of MOBIL descriptor [1] (Improved MOments based BInary differences for Local description), which introduces two main contributions. The first one is the use of geometric information for the binary test instead of the classical intensity binary test, to get more precision in the description step. The second one is to attribute two bits for each test, to increase the distinctiveness level. This approach offers high distinctiveness against affine transformations and appearance changes. The experimental evaluation shows that MOBIL achieves a quite good performance in term of low computation complexity and high recognition rate compared to state-of-the-art real-time local descriptors.","","978-1-4799-8212-7","10.1109/CEIT.2015.7233052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7233052","Local binary descriptors;moments;Augmented reality;Computer vision","Robustness;Computer vision;Augmented reality;Pattern recognition;Conferences;Feature extraction;Image recognition","augmented reality;computational complexity","improved MOBIL descriptor;markerless augmented reality;improved moments based binary differences for local description;geometric information;binary test;computation complexity;recognition rate","","","","29","IEEE","3 Sep 2015","","","IEEE","IEEE Conferences"
"Virtual Stamping to Arouse Interest Using Augmented Reality","W. Shim; J. -I. Park","Department of Electronics and Computer Engineering, Hanyang University, Seoul, Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, Korea","2013 International Conference on Culture and Computing","12 Dec 2013","2013","","","181","182","Stamping is a very simple and old way of cultural behavior. Moreover, it has been used widely even though we have efficient electrical methods. Stamp can be used to show a person's strong confidence or assurance and it psychologically affects people for cultural reasons, especially in Asia. We propose a mobile application that users can get stamps virtually with this application. This application brings people to get good use of the emotional merit of the stamping and the portability of the mobile device. We had two tests to show what factors arouse people to do something, and we generalized it to extract cultural essentials. Stamping was not only a psychological factor of the system, but it also has important contents. We can design attractive interfaces to utilize cultural data and behaviors.","","978-0-7695-5047-3","10.1109/CultureComputing.2013.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680369","augmented reality;cultural education;motional contents","Cultural differences;Psychology;Games;Augmented reality;Educational institutions;Mobile communication","augmented reality;humanities","virtual stamping;augmented reality;cultural behavior;electrical methods;mobile device portability;cultural essential extraction;psychological factor;cultural data","","","","7","IEEE","12 Dec 2013","","","IEEE","IEEE Conferences"
"SLAM-based Augmented Reality System in Interactive Exhibition","H. -C. Chi; T. -H. Tsai; S. -Y. Chen","Department of Communications Design, Shih Chien University, Taipei, Taiwan; Department of Communications Design, Shih Chien University, Taipei, Taiwan; Department of Industrial Design, Shih Chien University, Taipei, Taiwan","2020 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE)","29 Dec 2020","2020","","","258","262","A SLAM-based AR technology makes the exhibition richer and diversified. The audience can move in the real space to interact with virtual objects that are realistic in the interactive form. Besides, the integration between virtual objects and real space is also closer. This research designs an interactive solution called “AR Cross-center Interactive Device” by using buttons and combining the advantages of SLAM-based AR. The cross-center system is used for users to quickly understand the target of the interactive object and simply operate with buttons. This research uses the device in an interactive exhibition that related to the history of education in Taiwan. We expect that the introduction of this system helps users respond intuitively and provides an effective interactive solution in the SLAM-based AR exhibitions.","","978-1-7281-8060-1","10.1109/ECICE50847.2020.9302012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302012","Augmented Reality;Exhibition;Interactive;SLAM","Augmented reality;Simultaneous localization and mapping;Target recognition;Games;Real-time systems;Three-dimensional displays;Task analysis","augmented reality;interactive devices;SLAM (robots)","interactive object;interactive exhibition;effective interactive solution;SLAM-based augmented reality system;SLAM-based AR technology;virtual objects;AR cross-center interactive device","","","","10","IEEE","29 Dec 2020","","","IEEE","IEEE Conferences"
"Augmented Reality Hologram","J. J. Gan; O. N. N. Fernando","School of Computer Science and Engineering Nanyang Technological University (NTU), Singapore; School of Computer Science and Engineering Nanyang Technological University (NTU), Singapore","2019 International Conference on Cyberworlds (CW)","5 Dec 2019","2019","","","352","355","This paper presents the development of a mobile application that enables the creation of holographic objects and displays holographic objects on mobile devices. This project aims to demonstrate how the functionalities are implemented, and testing would be conducted to ensure the accuracy of creation and exhibitions of the holographic objects. During the app testing, there would be two approaches, which were tested based on two different lightings conditions. Users would be able to create their holographic objects with minimum lighting changes based on the results of the two approaches.","2642-3596","978-1-7281-2297-7","10.1109/CW.2019.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918954","Augmented Reality;Green Screen;Holograms;Interaction","Color;Videos;Lighting;Augmented reality;Green products;Google;Cameras","augmented reality;computer-generated holography;mobile computing","mobile application;holographic objects;mobile devices;app testing;augmented reality hologram","","","","13","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Matching historical images for augmented reality","G. A. Tataroğlu; K. E. Özden","Bilgisayar Mühendisliği Bölümü, Bahçeşehir Üniversitesi, İstanbul, Türkiye; Bilgisayar Mühendisliği Bölümü, Bahçeşehir Üniversitesi, İstanbul, Türkiye","2014 22nd Signal Processing and Communications Applications Conference (SIU)","12 Jun 2014","2014","","","1311","1314","In this report, an innovative virtual tourism application that designed to work on mobile devices and that uses location based technology is being presented. Users of the application will be able to display older pictures of historical places and monuments in place of the pictures they have been taking which will be placed together by algorithms that work on pixel level. Combining the old pictures with new, it will be possible to observe the changes on landmarks, buildings, places and social life through history. Innovative part of the project is designing two phase convertion and calculation technique to be able to solve challenge of finding geometrical relation between the old and new photographs which can be taken from different views and different angles. Further details on this technique can be found on the report itself as well as experiment results.","2165-0608","978-1-4799-4874-1","10.1109/SIU.2014.6830478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830478","augmented reality;image matching;mobile vision;cultural heritage","Signal processing;Conferences;Three-dimensional displays;Signal processing algorithms;Global Positioning System;Augmented reality;Algorithm design and analysis","augmented reality;history;image matching;mobile computing;travel industry","historical image matching;augmented reality;virtual tourism application;mobile devices;location based technology;historical places;monuments;pixel level;convertion technique;calculation technique;geometrical relation;photographs","","","","9","IEEE","12 Jun 2014","","","IEEE","IEEE Conferences"
"Development of engineering educational support system for manufacturing using Augmented Reality","Y. Shiba; S. Imai","Faculty of Education, Former Tokyo Gakugei University, 4-1-1 Nukuikita, Koganei, Tokyo, Japan; Department of Natural Science, Technology and Information Sciences, Tokyo Gakugei University, 4-1-1 Nukuikita, Koganei, Tokyo, Japan","2020 International Conference on Advanced Mechatronic Systems (ICAMechS)","6 Jan 2021","2020","","","198","202","In recent years, technologies such as AR and VR have rapidly evolved and become widely used. One of its most important areas of use is the use of VR and AR in education. By visualizing invisible phenomena, AR may be more likely to promote students' understanding than conventional methods. Therefore, in this report, we newly develop a lesson support system using AR in engineering manufacturing. The reason for this is that in engineering manufacturing, a large amount of data can be managed collectively by associating the data saved in the e-portfolio with the AR. In addition, when working as an engineer, the work and the learning records such as memos are stored separately, so there is a problem that they will be forgotten or lost during the next week's class. Therefore, by developing an AR education support system, by putting digital data in the work, it is possible to unify management and solve the problem. Moreover, the burden on the teacher can be reduced, and the contribution to the field of education can be further enhanced. The effectiveness of the developed AR education support system will be verified by conducting an evaluation experiment.","2325-0690","978-1-7281-6530-1","10.1109/ICAMechS49982.2020.9310166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310166","Augmented Reality;Engineering Education;Class support;Information and Communication Technology;Evaluation experiment","Education;Augmented reality;Three-dimensional displays;Manufacturing;Training;Software;Portfolios","augmented reality;computer aided instruction;engineering education","lesson support system;engineering manufacturing;AR education support system;digital data;engineering educational support system;augmented reality;invisible phenomena","","","","14","IEEE","6 Jan 2021","","","IEEE","IEEE Conferences"
"Development of Educational Application about Mental Disorders with Augmented Reality for Android","J. F. Maringka; R. Hargyo Pambuko; M. Haldi Widianto","Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2022 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS)","20 Jan 2023","2022","","","390","394","The goal of developing this MentalAR application is to educate people about the existence of mental illness because the authors feels that this topic is rarely discussed and rarely gets the public spotlight, but according to a survey data the number of people with mental disorder is high. The development method that the author uses is Waterfall method where the author must collect requirements, design applications from the collected needs, build applications according to the designs made, test applications using black box and U AT, and refine applications according to user input. The result of this project is an educational application that is easy to use, easily accessible and can explain mental illness to the public.","","978-1-6654-7327-9","10.1109/ICIMCIS56303.2022.10017580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017580","Mental illness;Education application;Augmented Reality","Mental disorders;Multimedia systems;Interviews;Informatics;Augmented reality;Testing","Android (operating system);augmented reality;computer aided instruction;handicapped aids;Internet;medical disorders","Android;augmented reality;black box;design applications;development method;educational application;mental disorder;mental illness;MentalAR application;refine applications;test applications;U AT;Waterfall method","","","","16","IEEE","20 Jan 2023","","","IEEE","IEEE Conferences"
"Understanding augmented reality applications continuance","Keesung Kim; Hwansoo Lee; Jiyeon Hwang; Hangjung Zo","Department of Management Science, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Management Science, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Management Science, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Management Science, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea","2013 International Conference on ICT Convergence (ICTC)","2 Dec 2013","2013","","","189","190","The purpose of this study is to determine which factors influence continuous intention in AR smart phone applications. The result is that information quality and relative vividness positively influence to perceived usefulness and continuous intention is positively influenced by perceived usefulness.","2162-1241","978-1-4799-0698-7","10.1109/ICTC.2013.6675336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6675336","Augmented Reality;Smartphone Application;Continuous Intention","Smart phones;Augmented reality;Information systems;Mobile communication;Context;Reliability;Real-time systems","augmented reality;mobile computing;smart phones","augmented reality;AR smart phone applications;information quality;continuous intention","","","","7","IEEE","2 Dec 2013","","","IEEE","IEEE Conferences"
"On Pending Interest Table in Named Data Networking based Edge Computing: The Case of Mobile Augmented Reality","R. Ullah; M. A. Ur Rehman; B. -S. Kim; B. Sonkoly; J. Tapolcai","Dept. of Electronics and Computer Engineering, Hongik University, Sejong, Repulic of Korea; Dept. of Electronics and Computer Engineering, Hongik University, Sejong, Repulic of Korea; Dept. of Software and Communications Engineering, Hongik University, Sejong, Repulic of Korea; Dept. of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary; Dept. of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary","2019 Eleventh International Conference on Ubiquitous and Future Networks (ICUFN)","22 Aug 2019","2019","","","263","265","Future networks require fast information response time, scalable content distribution, security and mobility. In order to enable future Internet many key enabling technologies have been proposed such as Edge computing (EC) and Named Data Networking (NDN). In EC substantial compute and storage resources are placed at the edge of the network, in close proximity to end users. Similarly, NDN provides an alternative to traditional host centric IP architecture which seems a perfect candidate for distributed computation. Although NDN with EC seems a promising approach for enabling future Internet, it can cause various challenges such as expiry time of the Pending Interest Table (PIT) and non-trivial computation of the edge node. In this paper we discuss the expiry time and non-trivial computation in NDN based EC. We argue that if NDN is integrated in EC, then the PIT expiry time will be affected in relation with the processing time on the edge node. Our analysis shows that integrating NDN in EC without considering PIT expiry time may result in the degradation of network performance in terms of Interest Satisfaction Rate.","2165-8536","978-1-7281-1340-1","10.1109/ICUFN.2019.8805923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805923","PIT expiry time;latency;remote computation;augmented reality;named data networking;edge computing","Cloud computing;Task analysis;Edge computing;Computer architecture;Augmented reality;Internet of Things","augmented reality;Internet;IP networks;mobile computing;security of data","mobile augmented reality;security;mobility;storage resources;distributed computation;NDN based EC;named data networking;pending interest table;edge computing;host centric IP architecture;interest satisfaction rate","","","","8","IEEE","22 Aug 2019","","","IEEE","IEEE Conferences"
"Internal and external scene graphs: a new approach for flexible distributed render engines","J. Ohlenburg; T. Frohlich; W. Broll","Collaborative Virtual and Augmented Environments Department, Fraunhofer Institute of Applied Information Technology, Sankt Augustin, Germany; Collaborative Virtual and Augmented Environments Department, Fraunhofer Institute of Applied Information Technology, Sankt Augustin, Germany; Collaborative Virtual and Augmented Environments Department, Fraunhofer Institute of Applied Information Technology, Sankt Augustin, Germany","IEEE Proceedings. VR 2005. Virtual Reality, 2005.","15 Aug 2005","2005","","","293","294","Render engines or render APIs are a core part of each virtual reality (VR) or augmented reality (AR) environment as well as 3D games. Most existing approaches either focus on rendering speed for high frame rates or on the presentation of advanced visual features. However, no approach exists to integrate scene descriptions based on multiple file formats without converting and thereby partly destroying the native scene format. In this paper we will present our approach of internal and external scene graphs for realizing render engines. We will show how this approach overcomes existing limitations, while still providing decent frame rates and rendering features. By using internal scene graphs for rendering, we use external scene graphs to store format or application specific information, preserving its native structure and content.","2375-5334","0-7803-8929-8","10.1109/VR.2005.1492801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1492801","","Layout;Engines;Rendering (computer graphics);Virtual reality;Graphics;Augmented reality;Application software;Pipelines;ISO standards;Buffer storage","augmented reality;rendering (computer graphics);distributed processing;spatial data structures;application program interfaces","scene graphs;distributed render engines;render API;application program interface;virtual reality environment;augmented reality environment;3D games;visual features;scene descriptions;file formats;scene format;application specific information;distributed system design","","","","4","IEEE","15 Aug 2005","","","IEEE","IEEE Conferences"
"Work-in-progress—Visualization of Area Units with Augmented Reality","L. M. Mueller; M. Platz","Faculty of Mathematics and Computer Science, Saarland University, Saarbruecken, Germany; Faculty of Mathematics and Computer Science, Saarland University, Saarbruecken, Germany","2022 8th International Conference of the Immersive Learning Research Network (iLRN)","11 Jul 2022","2022","","","1","3","Area measurement has a high priority in mathematics school education. Nevertheless, many students have problems understanding the concept of area measurement. An AR tool for visualizing square units on objects in the real world is developed to enable teachers to support understanding already in primary school. This work-in-progress paper presents the initial test version and discusses the first teaching experiment results. The students’ feedback and use of the app showed possible adaptations of the AR tool, e.g., that the idea of dynamic geometry could be incorporated in the future.","","978-1-7348995-3-5","10.23919/iLRN55037.2022.9815951","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815951","Augmented Reality;mathematics education;primary school;area measurement","Geometry;Visualization;Area measurement;Education;Augmented reality","augmented reality;computer aided instruction;educational institutions;teaching","area units;augmented reality;area measurement;mathematics school education;problems understanding;square units;primary school;work-in-progress paper;initial test version;teaching experiment results;students;work-in-progress-visualization","","","","27","","11 Jul 2022","","","IEEE","IEEE Conferences"
"Tactile Echoes: Multisensory Augmented Reality for the Hand","A. Kawazoe; G. Reardon; E. Woo; M. D. Luca; Y. Visell","Media Arts and Technology Program, University of California Santa Barbara, Santa Barbara, CA, USA; Media Arts and Technology Program, University of California Santa Barbara, Santa Barbara, CA, USA; Department of Electrical, and Computer Engineering, University of California Santa Barbara, Santa Barbara, CA, USA; School of Psychology, University of Birmingham, Birmingham, U.K; Department of Electrical and Computer Engineering and Media Arts and Technology Program, University of California Santa Barbara, Santa Barbara, CA, USA","IEEE Transactions on Haptics","16 Dec 2021","2021","14","4","835","848","Touch interactions are central to many human activities, but there are few technologies for computationally augmenting free-hand interactions with real environments. Here, we describe Tactile Echoes, a finger-wearable system for augmenting touch interactions with physical objects. This system captures and processes touch-elicited vibrations in real-time in order to enliven tactile experiences. In this article, we process these signals via a parametric signal processing network in order to generate responsive tactile and auditory feedback. Just as acoustic echoes are produced through the delayed replication and modification of sounds, so are Tactile Echoes produced through transformations of vibrotactile inputs in the skin. The echoes also reflect the contact interactions and touched objects involved. A transient tap produces discrete echoes, while a continuous slide yields sustained feedback. We also demonstrate computational and spatial tracking methods that allow these effects to be selectively assigned to different objects or actions. A large variety of distinct multisensory effects can be designed via ten processing parameters. We investigated how Tactile Echoes are perceived in several perceptual experiments using multidimensional scaling methods. This allowed us to deduce low-dimensional, semantically grounded perceptual descriptions. We present several virtual and augmented reality applications of Tactile Echoes. In a user study, we found that these effects made interactions more responsive and engaging. Our findings show how to endow a large variety of touch interactions with expressive multisensory effects.","2329-4051","","10.1109/TOH.2021.3084117","National Science Foundation(grant numbers:NSF-1 628 831,NSF-1 623 459,NSF-1 751 348); Biotechnology and Biological Sciences Research Council(grant numbers:BB/R003971/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442315","Tactile augmented reality;wearable haptics;haptic rendering;multisensory feedback","Haptic interfaces;Vibrations;Skin;Augmented reality;Tactile sensors;Feedback","augmented reality;haptic interfaces;human computer interaction;touch (physiological)","parametric signal processing network;responsive tactile feedback;auditory feedback;acoustic echoes;discrete echoes;multisensory augmented reality;free-hand interactions;augmenting touch interactions;system captures;processes touch-elicited vibrations;tactile experiences;tactile echoes;spatial tracking;augmented reality;virtual reality;multidimensional scaling","Augmented Reality;Feedback, Sensory;Fingers;Hand;Humans;Touch;Touch Perception","3","","63","IEEE","26 May 2021","","","IEEE","IEEE Journals"
"Multisensory Proximity and Transition Cues for Improving Target Awareness in Narrow Field of View Augmented Reality Displays","C. Trepkowski; A. Marquardt; T. D. Eibich; Y. Shikanai; J. Maiero; K. Kiyokawa; E. Kruijff; J. Schöning; P. König","Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany; Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany; Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany; Nara Institute of Science and Technology, Ikoma, Nara, Japan; Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany; Nara Institute of Science and Technology, Ikoma, Nara, Japan; Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany; University of St. Gallen, St. Gallen, Switzerland; Osnabrück University, Osnabrück, Germany","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2021","2022","28","2","1342","1362","Augmented reality applications allow users to enrich their real surroundings with additional digital content. However, due to the limited field of view of augmented reality devices, it can sometimes be difficult to become aware of newly emerging information inside or outside the field of view. Typical visual conflicts like clutter and occlusion of augmentations occur and can be further aggravated especially in the context of dense information spaces. In this article, we evaluate how multisensory cue combinations can improve the awareness for moving out-of-view objects in narrow field of view augmented reality displays. We distinguish between proximity and transition cues in either visual, auditory or tactile manner. Proximity cues are intended to enhance spatial awareness of approaching out-of-view objects while transition cues inform the user that the object just entered the field of view. In study 1, user preference was determined for 6 different cue combinations via forced-choice decisions. In study 2, the 3 most preferred modes were then evaluated with respect to performance and awareness measures in a divided attention reaction task. Both studies were conducted under varying noise levels. We show that on average the Visual-Tactile combination leads to 63% and Audio-Tactile to 65% faster reactions to incoming out-of-view augmentations than their Visual-Audio counterpart, indicating a high usefulness of tactile transition cues. We further show a detrimental effect of visual and audio noise on performance when feedback included visual proximity cues. Based on these results, we make recommendations to determine which cue combination is appropriate for which application.","1941-0506","","10.1109/TVCG.2021.3116673","Deutsche Forschungsgemeinschaft(grant numbers:KR 4521/2-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555238","Augmented reality;view management;guidance;multisensory cues;performance;situation awareness","Visualization;Task analysis;Three-dimensional displays;Augmented reality;Urban areas;Working environment noise;Search problems","augmented reality;data visualisation","multisensory proximity;target awareness;augmented reality applications;digital content;augmented reality devices;visual conflicts;augmentations occur;dense information spaces;cue combination;out-of-view objects;reality displays;visual manner;auditory manner;tactile manner;spatial awareness;user preference;cue combinations;awareness measures;Visual-Tactile combination;out-of-view augmentations;Visual-Audio counterpart;tactile transition cues;visual noise;audio noise;visual proximity cues","Augmented Reality;Computer Graphics;Cues;Touch;Visual Perception","4","","126","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"Virtual/Mixed/Augmented Reality Laboratory Research for the Study of Augmented Human and Human-Machine Systems","K. Helin; J. Karjalainen; T. Kuula; N. Philippon","Human factors in complex systems, VTT Technical Research Centre of Finland Ltd, Espoo, Finland; Human factors in complex systems, VTT Technical Research Centre of Finland Ltd, Espoo, Finland; Human factors in complex systems, VTT Technical Research Centre of Finland Ltd, Espoo, Finland; Human factors in complex systems, VTT Technical Research Centre of Finland Ltd, Espoo, Finland","2016 12th International Conference on Intelligent Environments (IE)","27 Oct 2016","2016","","","163","166","In this work we introduce a new research concept called Augmented Human, and consider how it may benefit from prior research efforts. In essence, the paper describes the long research history of a specific Virtual/Mixed/Augmented Reality (VR/MR/AR) laboratory and reflects how it may well be employed as a premise for Augmented Human research and the design of new human-machine systems. The paper briefly describes how constitutive laboratory research has already been employed for some years in more than a hundred company cases, which have exploited participatory design and human-centered design for the human-machine system development. The paper describes further how the latest cases have moved closer to the human boundary level and thus oriented towards Augmented Human research. This fifth generation VR/MR/AR/AH laboratory has taken the form of an open cave-like environment with a motion platform, 3D sound, haptics, VR/AR Head-mounted displays and physical objects.","2472-7571","978-1-5090-4056-8","10.1109/IE.2016.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723488","Virtual reality;mixed reality;augmented reality;augmented human;human centered design;participatory design","","augmented reality;haptic interfaces;helmet mounted displays;man-machine systems;user centred design","virtual-mixed-augmented reality laboratory research;augmented human;human-centered design;human-machine system development;VR/MR/AR/AH laboratory;open cave-like environment;motion platform;3D sound;haptics;VR-AR head-mounted displays;physical objects","","6","","9","IEEE","27 Oct 2016","","","IEEE","IEEE Conferences"
"CAVE-AR: A VR Authoring System to Interactively Design, Simulate, and Debug Multi-user AR Experiences","M. Cavallo; A. G. Forbes","IBM Research University of Illinois at Chicago; University of California, Santa Cruz University of Illinois at Chicago","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","872","873","Despite advances in augmented reality (AR), the process of creating meaningful experiences with this technology is still extremely challenging. Due to different tracking implementations and hardware constraints, developing AR applications either requires low-level programming skills, or is done through specific authoring tools that largely sacrifice the possibility of customizing the AR experience. Existing development workflows also do not support previewing or simulating the AR experience, requiring a lengthy process of trial and error by which content creators deploy and physically test applications in each iteration. To mitigate these limitations, we propose CAVE-AR, a novel virtual reality system for authoring, simulating and debugging custom augmented reality experiences. Available both as a standalone or a plug-in tool, CAVE-AR is based on the concept of representing in the same global reference system both in AR content and tracking information, mixing geographical information, architectural features, and sensor data to simulate the context of an AR experience. Thanks to its novel abstraction of existing tracking technologies, CAVE-AR operates independently of users' devices, and integrates with existing programming tools to provide maximum flexibility. Our VR application provides designers with ways to create and modify an AR application, even while others are in the midst of using it. CAVE-AR further allows the designer to track how users are behaving, preview what they are currently seeing, and interact with them through several different channels. To illustrate our proposed development workflow and demonstrate the advantages of our authoring system, we introduce two CAVE-AR use cases in which an augmented reality application is created and tested. In particular, we compare the CAVE-AR workflow to traditional development methods and demonstrate the importance of simulation and live application debugging.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798148","Human-centered computing—Human computer interaction (HCI)—Interactive systems and tools;Computing methodologies—Computer graphics—Graphics systems and interfaces—Mixed / augmented reality","Authoring systems;Augmented reality;Debugging;Hardware;Tools;Mobile handsets","augmented reality;authoring systems;program debugging","VR authoring system;meaningful experiences;hardware constraints;AR application;low-level programming skills;plug-in tool;global reference system;tracking information;geographical information;programming tools;VR application;augmented reality application;CAVE-AR workflow;live application debugging;interactive design;authoring tools;virtual reality system;augmented reality","","4","","2","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Virtual reality and augmented reality in aircraft design and manufacturing","D. W. Mizell","Research & Technology Organization, Boeing Computer Services, Inc., Seattle, WA, USA","Proceedings of WESCON '94","6 Aug 2002","1994","","","91","","Summary form only given. The author is working on two research projects in Boeing Computer Services that have to do with virtual reality technology. The first involves importing aircraft CAD data into a VR environment. Applications include a side range of engineering and design activities, all of which involve being able to view and interact with the CAD geometry as if one were inside an actual physical mockup of the aircraft. He refers to the technology being explored in the second project as ""Augmented Reality"". This entails the use of a see-through head-mounted display with an optical focal length of about 20 inches, along with VR-style position/orientation sensing system. The intended application area is in touch labor manufacturing: superimposing diagrams or text onto the surface of a workpiece and stabilizing it there on specific coordinates, so that the appropriate information needed by a factory worker for each step of a manufacturing or assembly operation appears on the surface of the workpiece as if it were painted there. The hardest technical problem for augmented reality is position tracking. Long-range head position/orientation sensing systems that can operate in factory environments are needed. This requirement and others give rise to some interesting computational problems, including wearer registration and position sensing using image processing.<>","1095-791X","0-7803-9992-7","10.1109/WESCON.1994.403622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=403622","","Virtual reality;Augmented reality;Aircraft propulsion;Design automation;Manufacturing;Production facilities;Application software;Aerospace engineering;Design engineering;Geometrical optics","virtual reality;aerospace computing;engineering graphics;manufacture;aircraft;CAD","virtual reality technology;aircraft design;aircraft manufacturing;research projects;Boeing Computer Services;aircraft CAD data;CAD geometry;augmented reality;head-mounted display;position/orientation sensing system;touch labor manufacturing;position tracking;factory environments","","15","","","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Extending the Metaverse: Hyper-Connected Smart Environments with Mixed Reality and the Internet of Things","J. Guan; A. Morris; J. Irizawa",Adaptive Context Environment (ACE) Lab OCAD University; Adaptive Context Environment (ACE) Lab OCAD University; Adaptive Context Environment (ACE) Lab OCAD University,"2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","817","818","The metaverse, i.e., the collection of technologies that provide a virtual twin of the real world via mixed reality, internet of things, and others, is gaining prominence. However, the metaverse faces challenges as it grows toward mainstream adoption. Among these is the lack of strong connections between metaverse objects and traditional physical objects and environments, which leads to incon-sistencies for users within metaverse environments. To address this issue, this work explores the design and development of a framework for bridging the physical environment and the metaverse through the use of internet-of-things objects and mixed reality designs. The contributions of this include: i) an architectural framework for ex-tending the metaverse, ii) design prototypes using the framework. Together, this exploration charts the course toward a more cohesive and hyper-connected metaverse smart environment.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108578","Virtual Reality;Mixed Reality;Augmented Reality;Extended Reality;Internet of Things;Human Computer Interaction","Three-dimensional displays;Metaverse;Conferences;Mixed reality;Prototypes;Virtual reality;User interfaces","augmented reality;Internet;Internet of Things;virtual reality","cohesive metaverse smart environment;hyper-connected metaverse smart environment;hyper-connected smart environments;internet-of-things objects;metaverse environments;metaverse faces;metaverse objects;mixed reality designs;physical environment;strong connections;traditional physical objects","","","","6","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Investigating Display Position of a Head-Fixed Augmented Reality Notification for Dual-task","H. Lee; W. Woo",KAIST UVR Lab; KAIST UVR Lab KAIST KI-ITC ARRC,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","584","585","Providing additional information in the proper position of augmented reality (AR) head-mounted display (HMD) can help increase AR performance and usability for dual-task. Therefore, our study inves-tigated how to place notifications for the dual-task to address this. We compared eight display positions and two tasks (single and dual tasks) to identify the appropriate area for displaying notifications. We confirmed that the middle-right reduces response time and task load. In contrast, the top-left is the location, which should avoid providing any notification in AR dual-task. Our study contributes to designing AR notifications on HMDs to enhance everyday AR experiences.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757570","Human-centered computing-Human Computer Interaction (HCI)-Interaction paradigms-Virtual reality;Mixed / augmented reality","Three-dimensional displays;TV;Head-mounted displays;Conferences;Resists;User interfaces;Time factors","augmented reality;helmet mounted displays","AR dual-task;AR notifications;head-fixed;reality notification;augmented reality head-mounted display;display positions;single tasks;HMD","","2","","7","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Exploring How, for Whom and in Which Contexts Extended Reality Training 'Works' in Upskilling Healthcare Workers: A Realist Review","N. Gasteiger; S. N. van der Veer; P. Wilson; D. Dowding","School of Health Sciences, University of Manchester; School of Health Sciences, University of Manchester; School of Health Sciences, University of Manchester; School of Health Sciences, University of Manchester","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","734","735","Extended reality (XR), including virtual reality (VR) and augmented reality (AR) may overcome barriers to training healthcare workers, such as resource constraints. However, the effectiveness of XR training is disputed and not well understood. Our realist review explores how, for whom and in what contexts AR and VR training 'works' in upskilling healthcare workers. Eighty papers informed our program theory, while 46 empirical studies tested/refined it. We conclude that XR triggers perceptions of realism and deep immersion, and enables visualization, interactive learning, enhancement of skills and repeated practice within a safe learning environment, consequently bettering skills, learning/knowledge and learner satisfaction.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00218","NIHR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757555","Healthcare;virtual reality;training;augmented reality;J.3 [Computing Applications]: Life and Medical sciences;J.4 [Computing Applications]: Social and Behavioral Sciences","Training;Visualization;Three-dimensional displays;Extended reality;Conferences;Medical services;User interfaces","augmented reality;computer aided instruction;computer based training;health care;personnel;virtual reality","augmented reality;training healthcare workers;resource constraints;XR training;realist review;VR training works;upskilling healthcare workers;contexts extended reality training works","","","","14","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Developing an eXtended Reality platform for Immersive and Interactive Experiences for Cultural Heritage: Serralves Museum and Coa Archeologic Park","M. Silva; L. Teixeira","School of Arts - Digital Creativity Center, CITAR Universidade Católica Portuguesa, Porto, Portugal; School of Arts - Digital Creativity Center, CITAR Universidade Católica Portuguesa, Porto, Portugal","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","300","302","Digital Heritage and Digital Humanities focus on distinct typologies of heritage: tangible and intangible Cultural Heritage (CH) objects and their preservation, education, and research versus the application of digital technologies to support research in the humanities. Both allow scholars to go beyond textual sources to integrate digital tools into the humanistic study. This project aims at supporting a new way of experiencing CH in the Serralves Museum and Coa Archeologic Park through more involving and culturally-qualified user experience. The main goal is to understand the potential of eXtended Reality within CH while also proposing the idea of developing a digital experience platform: an authoring tool based on an engine with core experiences functions that can be applied for developing multiple experiences for CH. This platform will contribute to new approaches, technologies, and tools for creating, processing, and delivering immersive and interactive content for engaging and meaningful experiences in these specific CH environments.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288434","Cultural Heritage;Serralves Museum;Coa Archeological Park;Immersive and Interactive Experience;eXtended Reality;Platform","Extended reality;Education;Tools;User experience;Cultural differences;Augmented reality;Engines","history;museums;user experience;virtual reality","digital experience platform;authoring tool;interactive experiences;Serralves Museum;Coa Archeologic Park;digital heritage;digital humanities;tangible cultural heritage;digital technologies;textual sources;digital tools;humanistic study;culturally-qualified user experience;extended reality platform;immersive experiences;intangible cultural heritage;augmented reality","","5","","21","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"A Nested Marker for Augmented Reality","K. Tateno; I. Kitahara; Y. Ohta","Graduate School of Systems and Information Engineering, University of Tsukuba, Japan; Graduate School of Systems and Information Engineering, University of Tsukuba, Japan; Graduate School of Systems and Information Engineering, University of Tsukuba, Japan","2007 IEEE Virtual Reality Conference","23 Apr 2007","2007","","","259","262","A Nested Marker, a novel visual marker for camera calibration in augmented reality (AR), enables accurate calibration even when the observer is moving very close to or far away from the marker. Our proposed Nested Marker has a recursive layered structure. One marker at an upper layer contains four smaller markers at the lower layer. Smaller markers can also have lower-layer markers nesting inside them. Each marker can be identified by its inside pattern, so the system can select a proper calibration parameter set for the marker. When the observer views the marker close-up, the lowest layer marker will work. When the observer views the marker from a distance, the top-layer marker will work. It is also possible to simultaneously utilize all visible markers in different layers for more stable calibration. Note that Nested Marker can be used in a standard ARToolkit framework. We have also developed an AR system to demonstrate the ability of Nested Marker","2375-5334","1-4244-0905-5","10.1109/VR.2007.352495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161037","","Augmented reality;Cameras;Calibration;Space technology;Watches;Systems engineering and theory;Intrusion detection;Robustness;Computer vision;Sensor systems","augmented reality;calibration;pattern recognition","nested marker;augmented reality;visual marker;camera calibration;recursive layered structure;calibration parameter;ARToolkit framework","","22","5","7","IEEE","23 Apr 2007","","","IEEE","IEEE Conferences"
"Bringing user-generated content from Internet services to mobile augmented reality clients","P. Belimpasakis; P. Selonen; Y. You","Nokia Research Center, Tampere, Finland; Nokia Research Center, Tampere, Finland; Nokia Research Center, Tampere, Finland","2010 Cloud-Mobile Convergence for Virtual Reality Workshop (CMCVR 2010) Proceedings","2 Sep 2010","2010","","","14","17","In this paper we describe a system for bringing usergenerated content to mobile augmented reality clients, taking in consideration the metadata required for visualizing it, at a sensor based tracking solution. Our proposal assumes that content is stored in multiple external Internet services, simply treated as a “cloud”, thus making the mobile client service agnostic. A prototype implementation was created for the Image Space service and the learnings of integrating with the popular Flickr service are discussed.","2160-2891","978-1-4244-5861-5","10.1109/CMCVR.2010.5560611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560611","","Mobile communication;Augmented reality;Web and internet services;User-generated content;Cameras;Prototypes","augmented reality;data visualisation;meta data;mobile computing;Web services","user generated content;Internet service;mobile augmented reality client;metadata consideration;content visualization;sensor based tracking solution;mobile client service;image space service;flickr service","","14","2","7","IEEE","2 Sep 2010","","","IEEE","IEEE Conferences"
"Augmented Reality Scouting for Interactive 3D Reconstruction","B. Reitinger; C. Zach; D. Schmalstieg","Institute for Computer Graphics and Vision, Graz University of Technology, Austria; VRVis Research Center, Austria; Institute for Computer Graphics and Vision, Graz University of Technology, Austria","2007 IEEE Virtual Reality Conference","23 Apr 2007","2007","","","219","222","This paper presents a first prototype of an interactive 3D reconstruction system for modeling urban scenes. An augmented reality scout is a person who is equipped with an ultra-mobile PC, an attached USB camera and a GPS receiver. The scout is exploring the urban environment and delivers a sequence of 2D images. These images are annotated with according GPS data and used iteratively as input for a 3D reconstruction engine which generates the 3D models on-the-fly. This turns modeling into an interactive and collaborative task","2375-5334","1-4244-0905-5","10.1109/VR.2007.352485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161027","scouting;interactive 3d reconstruction;urban planning","Augmented reality;Image reconstruction;Layout;Image databases;Engines;Visual databases;Cameras;Global Positioning System;Data visualization;Feedback","augmented reality;geographic information systems;Global Positioning System;image reconstruction;image sequences;town and country planning","augmented reality scouting;interactive 3D reconstruction;urban scenes;ultra-mobile PC;USB camera;GPS receiver;urban environment;GPS data;collaborative task.;urban planning","","13","6","18","IEEE","23 Apr 2007","","","IEEE","IEEE Conferences"
"An Augmented Reality Motion Planning Interface for Robotics","C. Hutton; N. Sohre; B. Davis; S. Guy; E. S. Rosenberg","University of Minnesota, Minneapolis, MN, US; University of Minnesota, Minneapolis, MN, US; University of Minnesota, Minneapolis, MN, US; University of Minnesota, Minneapolis, MN, US; University of Minnesota, Minneapolis, MN, US","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1313","1314","With recent advances in hardware technology, autonomous robots are increasingly present in research activities outside of robotics, performing a multitude of tasks such as image capture and sample collection. However, user interfaces for task-oriented robots have not kept pace with hardware breakthroughs. Current planning and control interfaces for robots are not intuitive and often place a large cognitive burden on those who are not highly trained in their use. Augmented reality (AR) has also seen major advances in recent years. This demonstration illustrates an initial system design for an AR user interface for path planning with robotics.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798010","","Robots;Task analysis;User interfaces;Drones;Path planning;Augmented reality","augmented reality;control engineering computing;mobile robots;path planning;user interfaces","augmented reality motion planning interface;robotics;autonomous robots;image capture;user interfaces;task-oriented robots;control interfaces;AR user interface;path planning","","3","","10","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Prompting Techniques for Guidance and Action Assistance Using Augmented-Reality Smart-Glasses","P. Renner","Center of Excellence Cognitive Interaction Technology, Bielefeld University","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","820","822","In the context of picking and assembly tasks, assistance systems based on Augmented Reality (AR) can help finding target objects and conducting correct actions. The aim is to develop guiding and action assistance techniques for smart glasses, which are easily understandable not only for workers, but also for impaired and elderly people.","","978-1-5386-3365-6","10.1109/VR.2018.8446292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446292","","Task analysis;Three-dimensional displays;Visualization;Augmented reality;Manuals;Gaze tracking","augmented reality;geriatrics;handicapped aids;helmet mounted displays;power aware computing","augmented-reality smart-glasses;assembly tasks;assistance systems;target objects;smart glasses;picking tasks;action assistance techniques;impaired people;elderly people","","3","","10","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Uncertainty Boundaries for Complex Objects in Augmented Reality","J. Chen; B. MacIntyre","School of Interactive Computing, Georgia Institute of Technology, USA; School of Interactive Computing, Georgia Institute of Technology, USA","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","247","248","Registration errors between the physical world and computer- generated objects are a central problem in Augmented Reality (AR) systems. Some existing AR systems have demonstrated how to dynamically estimate registration errors based on estimates of spatial errors in the system. Using these error estimates, these systems also demonstrated a number of ways of ameliorating the effects of registration error. One central part of this previous work was the creation and use of error regions around objects; unfortunately, the analytic methods used only created accurate regions for simple convex objects. In this paper, we present a simple and stable algorithm for generating the uncertainty regions for complex objects, including non-convex objects and objects with interior holes. We demonstrate how our approach can be used to create a set of more accurate error-based highlights in the presence of registration error, and also be used as a general highlighting mechanism.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480784","AR;registration error;non-convex objects;spatial uncertainty;I.3.3 [Computer Graphics]: Picture/Image Generation - Viewing Algorithms;I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction Techniques","Uncertainty;Augmented reality;Computer errors;Computer graphics;Sensor systems;Physics computing;Image generation;Shape;Application software;Delay","augmented reality;uncertainty handling","uncertainty boundaries;complex objects;augmented reality;computer-generated objects;registration errors","","2","","6","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"Words Game in an Educational Context: Augmented Reality Aplication","V. C. d. Silva; E. S. d. Goes Jr.; M. d. H. França; P. E. Ambrósio","Departamento de Ciências Exatas e Tecnológicas, Universidade Estadual de Santa Cruz UESC, Ilhéus, BA, Brasil; Departamento de Ciências Exatas e Tecnológicas, Universidade Estadual de Santa Cruz UESC, Ilhéus, BA, Brasil; Departamento de Ciências Exatas e Tecnológicas, Universidade Estadual de Santa Cruz UESC, Ilhéus, BA, Brasil; Departamento de Ciências Exatas e Tecnológicas, Universidade Estadual de Santa Cruz UESC, Ilhéus, BA, Brasil","2011 XIII Symposium on Virtual Reality","14 Jul 2011","2011","","","128","133","This paper presents the development of a play on words using concepts of augmented reality, embedded in a web environment, whose goal is to assist the classroom teacher in the literacy process of children. Offering tools to make lessons more interesting and dynamic, with the goal of teaching by exploring the playful character of the educational process.","","978-0-7695-4445-8","10.1109/SVR.2011.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5951844","Realidade Aumentada;jogos computacionais educativos;informÃ¡tica educativa","Games;Augmented reality;Education;Tornadoes;Mice;Ethics;Cascading style sheets","augmented reality;computer aided instruction;computer games;Internet;teaching","augmented reality;Web environment;classroom teacher;literacy process;teaching;playful character;educational process;word game","","1","","6","IEEE","14 Jul 2011","","","IEEE","IEEE Conferences"
"User Engagement for Collaborative Learning on a Mobile and Desktop Augmented Reality Application","C. Arce-Lopera; A. Gomez; C. Montoya",Universidad Icesi; Universidad Icesi; Universidad Icesi,"2019 International Conference on Virtual Reality and Visualization (ICVRV)","6 Oct 2020","2019","","","193","195","User engagement and information understanding was assessed for a basic electronics tutorial designed using Augmented Reality (AR). The main idea was to compare user performance in collaborative environments between two different versions of the AR application: a desktop version and a mobile version. Preliminary testing of both versions revealed that users were interested in AR technology but did not intuitively understand how to better utilize the system in comparison with a static video. Moreover, in spite there was not a statistically significant difference between information understanding between both conditions, the mobile application was rated significantly lower than the desktop application in user engagement for collaborative environments.","2375-141X","978-1-7281-4752-9","10.1109/ICVRV47840.2019.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212860","Human centered computing Collaborative and social computing Empirical studies in collaborative and social computing;Human centered computing;Visualization;Visualization design and evaluation methods","Tutorials;Augmented reality;Collaboration;Visualization;Usability;User interfaces","augmented reality;computer aided instruction;electronic engineering computing;electronic engineering education;groupware;mobile learning","desktop augmented reality application;desktop application;mobile application;AR application;collaborative environments;basic electronics tutorial;information understanding;user engagement;collaborative learning","","1","","5","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"The effect of an occluder on near field depth matching in optical see-through augmented reality","C. Hua; K. Moser; J. Edward Swan",Mississippi State University; Mississippi State University; Mississippi State University,"2014 IEEE Virtual Reality (VR)","24 Apr 2014","2014","","","149","149","We have conducted an experiment to study the effect of an occluding surface on the accuracy of near field depth matching in augmented reality (AR). Our experiment was based on replicating a similar experiment conducted by Edwards et al. [2]. We used an AR haploscope [1], which allows us to independently manipulate accommodative demand and vergence angle of the visible image. Fifteen observers matched the perceived depth of an AR-presented virtual object with a physical pointer. Overall, observers overestimated depth by 5 mm or less in the presence of the occluder, while in the absence of an occluder they overestimated depth by 5 to 10 mm. The data from Edwards et al. [2] is normalized, and when we performed the same normalization procedure on our own data, our results do not agree with Edwards et al. [2]. We suspect that eye vergence explains these results.","2375-5334","978-1-4799-2871-2","10.1109/VR.2014.6802095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802095","","Augmented reality;Optical imaging;Educational institutions;Observers;Hardware;Light emitting diodes;Abstracts","augmented reality;computer graphic equipment","normalization;eye vergence;AR-presented virtual object;visible image vergence angle;AR haploscope;occluding surface effect;optical see-through augmented reality;near field depth matching;occluder effect","","1","","2","IEEE","24 Apr 2014","","","IEEE","IEEE Conferences"
"An adaptive color marker for Spatial Augmented Reality environments and visual feedback","R. T. Smith; M. R. Marner; B. H. Thomas","Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia","2011 IEEE Virtual Reality Conference","29 Apr 2011","2011","","","269","270","This demonstration presents an adaptive visual marker optimised to improve tracking performance in Spatial Augmented Reality environments. The adaptive marker uses a color light sensor to capture the projected light color from a SAR system. The color information is used to select the optimal tracking color that is displayed on a diffused Red, Green, Blue Light Emitting Diode marker attached to a user's finger. We have selected to use the visible light spectrum for the marker since it can be leveraged to present visual feedback to support user interface interactions in addition to the tracking system operation. Our initial results have shown a performance improvement compared to a fixed color passive marker.","2375-5334","978-1-4577-0038-5","10.1109/VR.2011.5759502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759502","","Color;Augmented reality;Visualization;Laboratories;Wearable computers;Robot sensing systems","augmented reality;colour;graphical user interfaces;light emitting diodes;optical sensors;tracking","spatial augmented reality;visual feedback;adaptive visual marker;color light sensor;projected light color;optimal tracking;light emitting diode;visible light spectrum;user interface;fixed color passive marker","","1","","2","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"PRASAD: an augmented reality based non-invasive pre-operative visualization framework for lungs","A. P. Santhanam; C. Fidopiastis; B. Hoffman-Ruddy; J. P. Rolland","Department of Computer Science, University of Central Florida, USA; Institute of Simulation and Training, University of Central Florida, USA; NA; School of Optics/CREOL/FPCE, University of Central Florida, USA","IEEE Virtual Reality 2004","12 Jul 2004","2004","","","253","254","This paper presents a preoperative anatomical visualization framework, PRASAD (physically realistic adaptive and scalable anatomical deformation system), which combines a bio-mathematical representation of deformable lungs with real-time deformation and stereoscopic visualization technology. This framework provides a visualization of a dynamic patient-specific deformation of synthetic 3D anatomical models, that physicians can view from different viewpoints in a stereoscopic augmented reality environment for efficient diagnosis.","1087-8270","0-7803-8415-6","10.1109/VR.2004.1310095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310095","","Augmented reality;Visualization;Lungs;Deformable models;Surgery;Physiology;Battery charge measurement;Capacitive sensors;Biomedical imaging;Medical diagnostic imaging","medical diagnostic computing;augmented reality;lung;deformation;physiological models;data visualisation","augmented reality;noninvasive visualization;preoperative visualization;lungs;anatomical visualization;anatomical deformation;bio-mathematical representation;stereoscopic visualization;3D anatomical models;PRASAD","","1","","6","IEEE","12 Jul 2004","","","IEEE","IEEE Conferences"
"Anthropomorphism of Virtual Agents and Human Cognitive Performance in Augmented Reality","F. Mostajeran; N. Burke; N. Ertugrul; K. Hildebrandt; J. Matov; N. Tapie; W. G. Zittel; P. Reisewitz; F. Steinicke",Universität Hamburg; Universität Hamburg; Universität Hamburg; Universität Hamburg; Universität Hamburg; Universität Hamburg; Universität Hamburg; Universität Hamburg; Universität Hamburg,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","329","332","In this preliminary study, we aimed to explore the role of anthropomorphism on cognitive task performance in augmented reality (AR). We implemented five different levels of anthropomorphic representations of a virtual agent, ranging from voice to whole-body. Participants performed anagram tasks in the presence of each representation. The results suggest that, except for the voice condition, social presence and cognitive performance increase as the level of anthropomorphism increases.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00074","German Research Foundation (DFG); German Federal Ministry of Education and Research (BMBF); Federal Ministry for Economic Affairs and Energy (BMWi); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757379","","Three-dimensional displays;Conferences;User interfaces;Distance measurement;Anthropomorphism;Task analysis;Augmented reality","augmented reality;cognition","augmented reality;cognitive task performance;anthropomorphic representations;virtual agent;anagram tasks;voice condition;cognitive performance;anthropomorphism;social presence","","","","27","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Designing flexible manufacturing systems with augmented reality","J. Fruend; C. Matysczok","Heinz Nixdorf Institute, University of Paderborn, Paderborn, Germany; Heinz Nixdorf Institute, University of Paderborn, Paderborn, Germany","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","3 pp.","","The technology of augmented reality (AR), as a new user interface, introduces a completely new perspective for the design of technical manufacturing systems. This technique supports face to face collaboration where users need to be able to easily cooperate with each other. As with typical construction sets like LEGO or Fischertechnik, planning engineers model the future manufacturing system in their real environment. The components are taken from virtual construction sets and are positioned interactively in the manufacturing hall. Planning rules are used to assist the user and to prevent possible errors.","","0-7803-7680-3","10.1109/ART.2002.1106962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106962","","Flexible manufacturing systems;Augmented reality;Process planning;User interfaces;Databases;Production planning;Software tools;Safety;Power supplies;Manufacturing systems","flexible manufacturing systems;augmented reality;engineering graphics;graphical user interfaces;computer aided production planning","flexible manufacturing system design;augmented reality;user interface;face to face collaboration;virtual construction sets;planning rules","","","","4","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Photorealistic rendering for augmented reality","K. Agusanto; Zhu Chuangui; Ng Wan Sing; Kwoh Chee Keong","School of Mechanical & Production Engineering, Nanyang Technological University, Singapore; School of Mechanical & Production Engineering, Nanyang Technological University, Singapore; School of Mechanical & Production Engineering, Nanyang Technological University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","2 pp.","","This paper explores an image-based approach to improve photorealism for rendering synthetic objects in augmented reality. It uses pre-filtered high-dynamic range environment maps of the real scene, containing real lighting information, to render diffuse and glossy virtual objects with a multi-pass technique via texture mapping operation. In addition, the light sources, required for soft shadows generation, can be estimated from the maps. Soft shadows are added to the virtual objects using shadow buffer technique, which can utilize graphics hardware. This work can be beneficial for ARToolkit development in improving photorealism of virtual objects.","","0-7803-7680-3","10.1109/ART.2002.1106986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106986","","Augmented reality;Rendering (computer graphics);Optical reflection;Lighting;Probes;Layout;Graphics;Hardware;Neutron spin echo;Production engineering","rendering (computer graphics);augmented reality;software tools","photorealistic rendering;augmented reality;image-based approach;synthetic objects rendering;high-dynamic range environment maps;virtual objects;texture mapping;soft shadows generation;shadow buffer technique;ARToolkit development","","","","8","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"DC: Research on Augmented Reality","P. Yu",Nanjing University,"2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","997","998","Augmented reality technology can integrate virtual information (objects, pictures, videos, sounds, etc.) into the real environment, enrich the real world, and build a more comprehensive and better world. Outdoor illumination is essential for AR applications. We will discuss our proposed two methods which predict outdoor illumination from a single outdoor image. With predicted illumination, the virtual object can be inserted into the real environment, with consistent shadow information and occlusion relationship.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00341","National Natural Science Foundation of China(grant numbers:62032011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108762","Computing methodologies-Computing methodologies-Computer vision;Human-centered computing-Visualization-Visualization application domains","Three-dimensional displays;Conferences;Lighting;User interfaces;Augmented reality;Videos","augmented reality","AR applications;augmented reality technology;consistent shadow information;DC;occlusion relationship;outdoor illumination;predicted illumination;single outdoor image;virtual information;virtual object","","","","2","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Traffic Signs Detection and Augmented Reality Based on Multithreading","W. Li; Q. Li; S. Gao; C. Cai","Faculty of Computer and Software Engineering, Huaiyin Institute of Technology, Huaian, P.R. China; Faculty of Computer and Software Engineering, Huaiyin Institute of Technology, Huaian, P.R. China; Faculty of Computer and Software Engineering, Huaiyin Institute of Technology, Huaian, P.R. China; Faculty of Computer and Software Engineering, Huaiyin Institute of Technology, Huaian, P.R. China","2018 International Conference on Virtual Reality and Visualization (ICVRV)","13 May 2019","2018","","","86","89","The detection algorithm of existing traffic signs was improved, and the implementation of traffic sign detection and recognition was described in detail. This article mainly contains the following: Through targeted feature extraction, a trained cascaded classifier is used to obtain the location of traffic signs. Combined with the previous detection results, feature extraction is performed on the specified part of the target. The results are analyzed according to the location of detection or the results of the trained support vector machine are used to classify, and the classification results are obtained to realize the recognition of traffic signs. The total number of samples used for goal training in this article has reached thousands. The test results show that the detection rate of the traffic sign under the trained scene has been more than 90%. The algorithm has been optimized by the multi-thread method and combined with augmented reality to achieve real-time feedback.","2375-141X","978-1-5386-8497-9","10.1109/ICVRV.2018.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8711259","Traffic sign detection;feature extraction;cascaded classifier;support vector machine","Training;Visualization;Rendering (computer graphics);Feature extraction;Streaming media;Eigenvalues and eigenfunctions;Augmented reality","augmented reality;feature extraction;image classification;image colour analysis;learning (artificial intelligence);multi-threading;object detection;support vector machines;traffic engineering computing","augmented reality;traffic signs detection;detection algorithm;traffic sign detection;targeted feature extraction;trained cascaded classifier;previous detection results;detection rate","","","","7","IEEE","13 May 2019","","","IEEE","IEEE Conferences"
"Empower VR Art and AR Book with Spatial Interaction","Y. X. Zhang; Z. Zhu; Z. Yun","Department of Communication of Science and Technology, University of Science and Technology of China, Hefei, Anhui, China; Department of Communication of Science and Technology, University of Science and Technology of China, Hefei, Anhui, China; Department of Communication of Science and Technology, University of Science and Technology of China, Hefei, Anhui, China","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","274","279","In some circumstances it is necessary to allow the public to interact with AR or VR contents in physical space in an easy to use and low cost way, such as mark based AR book in classroom and interactive VR art or AR art in exhibition or museum in open space. The authors developed tangible user interface elements based on marker recognition. The user interface elements include virtual buttons, virtual rotate, and virtual hotspot. The user elements were integrated into various kinds of digital presentation systems by optimizing the logistic structure and interaction design of the user interface system to realize convenient spatial interactions. Thus, providing friendly user interaction and effective communication of information. Especially when interacting with art works, this interface could hide technology aspects and reduce the technology noise over art, and bring magical and amazing experience to users.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836515","Augmented Reality;Spatial Interaction;Virtual Controller;Interface","Augmented reality;Art;Cameras;Mice;Sensors;Flowcharts","art;augmented reality;human computer interaction;user interface management systems","AR book;spatial interaction;AR contents;VR contents;interactive VR art;interactive AR art;exhibition;museum;tangible user interface;marker recognition;virtual buttons;virtual rotate;virtual hotspot;digital presentation systems;logistic structure;interaction design;user interface system;user friendly interaction;technology noise reduction;augmented reality;virtual reality","","3","","34","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Randomly Distributed Small Chip Makers","S. Ikeda; A. N. Trung; T. Komae; F. Shibata; A. Kimura",Ritsumeikan University; Ritsumeikan University; Ritsumeikan University; Ritsumeikan University; Ritsumeikan University,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","258","259","In this paper, we propose a novel marker design and its tracking algorithm for room-sized MR/AR environments. The markers and the algorithm are designed to solve the following practical problems: i) the difficulties in creating and arranging markers and ii) the trade-off between inconspicuousness and robustness of markers. The proposed markers are small chips that are cut off a large paper sheet, and are arranged at random positions in an environment or on objects. This paper shows the design concept and feasibility of the proposed markers.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836509","H.5.1 [Information Intefaces and Presentation]: Multimedia Information Systems—Artificial;augmented;and virtual realities; I.4.8 [Image processing and Computer Vision]: Scene Analysis—Tracking","Visualization;Augmented reality;Three-dimensional displays;Robustness;Cameras;Simultaneous localization and mapping;Shape","augmented reality;object tracking","randomly distributed small chip makers;tracking algorithm;room-sized MR-AR environments;mixed reality;augmented reality","","","","12","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Mixed Reality in Smart Computing Education System","M. V. Pridhvi Krishna; S. Mehta; S. Verma; S. Rane","Computer Engineering, Army Institute of Technology, Pune, MH, India; Computer Engineering, Army Institute of Technology, Pune, MH, India; Computer Engineering, Army Institute of Technology, Pune, MH, India; Computer Engineering, Army Institute of Technology, Pune, MH, India","2018 International Conference on Smart Systems and Inventive Technology (ICSSIT)","1 Jul 2019","2018","","","72","75","One of the technologies that has been showing possibilities of application in educational environments is the Mixed Reality (MR) comprising of both Augmented Reality(AR) and virtual Reality(VR), in addition to its application to other fields such as tourism, advertising, video games, among others. The primary reason for this research work is to depict and condense trials with production training and education applications utilizing mixed reality gadgets. The entry of new and further developed mobile devices opens up more opportunities for the applications to develop and be circulated. This paper tries to build upon the current state of mixed reality and its application in education. The first segment describes basic structure of mixed reality and its different parts. Following segments give a definitive structure of some experimental applications that were developed for the mixed reality, with the inference taken from the data of experiment done by the National university of Columbia on secondary school students and lastly, the paper shows the benefits of those applications over the traditional teaching methods and the basic user reactions to them.","","978-1-5386-5873-4","10.1109/ICSSIT.2018.8748813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8748813","Mixed Reality;Augmented Reality;Virtual Reality;Mobile Devices;High-End;Teaching-Learning Processes;Virtualization","Three-dimensional displays;Education;Technological innovation;Mobile handsets;Solid modeling;Augmented reality","augmented reality;computer aided instruction;mobile computing;teaching","smart computing education system;educational environments;mixed reality gadgets;augmented reality;production training;secondary school students;teaching methods;mobile devices","","4","","14","IEEE","1 Jul 2019","","","IEEE","IEEE Conferences"
"MTMR: A conceptual interior design framework integrating Mixed Reality with the Multi-Touch tabletop interface","D. Wei; S. Z. Zhou; D. Xie","Interactive Multimedia Laboratory, National University of Singapore, Singapore; Interactive Multimedia Lab, National University of Singapore, Singapore; Interactive Multimedia Laboratory, National University of Singapore, Singapore","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","279","280","This paper introduces a conceptual interior design framework - Multi-Touch Mixed Reality (MTMR), which integrates mixed reality with the multi-touch tabletop interface, to provide an intuitive and efficient interface for collaborative design and an augmented 3D view to users at the same time. Under this framework, multiple designers can carry out design work simultaneously on the top view displayed on the tabletop, while live video of the ongoing design work is captured and augmented by overlaying virtual 3D furniture models to their 2D virtual counterparts, and shown on a vertical screen in front of the tabletop. Meanwhile, the remote client's camera view of the physical room is augmented with the interior design layout in real time, that is, as the designers place, move, and modify the virtual furniture models on the tabletop, the client sees the corresponding life-size 3D virtual furniture models residing, moving, and changing in the physical room through the camera view on his/her screen. By adopting MTMR, which we argue may also apply to other kinds of collaborative work, the designers can expect a good working experience in terms of naturalness and intuitiveness, while the client can be involved in the design process and view the design result without moving around heavy furniture. By presenting MTMR, we hope to provide reliable and precise freehand interactions to mixed reality systems, with multi-touch inputs on tabletop interfaces.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643606","Mixed reality;multi-touch tabletop interfaces","Three dimensional displays;Virtual reality;Cameras;Solid modeling;Streaming media;Collaborative work;Layout","augmented reality;cameras;groupware;user interfaces","multitouch tabletop interface;conceptual interior design framework;multitouch mixed reality;collaborative design;augmented 3D view;virtual 3D furniture models;2D virtual counterparts;virtual furniture models;3D virtual furniture models;freehand interactions","","16","","3","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"DUIRA: An interactive learning platform for mixed reality","R. -C. Chang; S. -N. Chen; H. -J. Lin; H. -M. Yu","Department of Digital Media Design, Asia University, Taichung, Taiwan; Department of Computer Science & Information Engineering, Asia University, Taichung, Taiwan; Department of Digital Media Design, Asia University, Taichung, Taiwan; Department of Digital Media Design, Asia University, Taichung, Taiwan","2010 IEEE International Conference on Multimedia and Expo","23 Sep 2010","2010","","","1152","1153","This demonstration aims to construct an interactive multimedia learning platform for ecology education, which allows young children to learn interactively through the virtual reality of digital media. This enhanced learning experience integrates augmented reality (AR) and Arduino features, and utilizes digital animation design software and 3D technologies to design a sequence of AR markers based on the growth of plants. Learners can use a webcam to capture AR marker information and generate three-dimensional objects and media on-screen. With changes or angle tilt of the AR marker, users can interact directly with the 3D objects and learn about plant growth through this virtual reality platform.","1945-788X","978-1-4244-7493-6","10.1109/ICME.2010.5583212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583212","Mixed Reality;Augmented Reality;Arduino;Interactive Multimedia;Interactive Installation","Media;Three dimensional displays;Animation;Clocks;Augmented reality;Rain","augmented reality;computer aided instruction;computer animation;ecology;multimedia computing","DUIRA;interactive learning platform;mixed reality;interactive multimedia learning platform;ecology education;digital media;enhanced learning experience;augmented reality;Arduino features;digital animation design software;3D technology;AR markers;webcam;AR marker information;media on-screen;angle tilt;3D objects;plant growth;virtual reality platform","","1","","2","IEEE","23 Sep 2010","","","IEEE","IEEE Conferences"
"Improving procedural task performance with Augmented Reality annotations","M. R. Marner; A. Irlitti; B. H. Thomas","Wearable Computer Lab, University of South Australia; Wearable Computer Lab, University of South Australia; Wearable Computer Lab, University of South Australia","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","39","48","This paper presents results of a study measuring user performance in a procedural task using Spatial Augmented Reality (SAR). The task required participants to press sequences of buttons on two control panel designs in the correct order. Instructions for the task were shown either on a computer monitor, or projected directly onto the control panels. This work was motivated by discrepancies between the expectations from AR proponents and experimental findings. AR is often promoted as a way of improving user performance and understanding. With notable exceptions however, experimental results do not confirm these expectations. Reasons cited for results include limitations of current display technologies and misregistration caused by tracking and calibration errors. Our experiment utilizes SAR to remove these effects. Our results show that augmented annotations lead to significantly faster task completion speed, fewer errors, and reduced head movement, when compared to monitor based instructions. Subjectively, our results show augmented annotations are preferred by users.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671762","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671762","Spatial Augmented Reality;User Interfaces;User Study","Monitoring;Presses;Augmented reality;Assembly;Pressing;Atmospheric measurements;Particle measurements","augmented reality","procedural task performance improvement;augmented reality annotations;user performance measurement;spatial augmented reality;computer monitor;augmented annotations","","41","2","29","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"A study of depth perception in hand-held augmented reality using autostereoscopic displays","M. Berning; D. Kleinert; T. Riedel; M. Beigl","TECO, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; TECO, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; TECO, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; TECO, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","6 Nov 2014","2014","","","93","98","Displaying three-dimensional content on a flat display is bound to reduce the impression of depth, particularly for mobile video see-trough augmented reality. Several applications in this domain can benefit from accurate depth perception, especially if there are contradictory depth cues, like occlusion in a x-ray visualization. The use of stereoscopy for this effect is already prevalent in head-mounted displays, but there is little research on the applicability for hand-held augmented reality. We have implemented such a prototype using an off-the-shelf smartphone equipped with a stereo camera and an autostereoscopic display. We designed and conducted an extensive user study to explore the effects of stereoscopic hand-held augmented reality on depth perception. The results show that in this scenario depth judgment is mostly influenced by monoscopic depth cues, but our system can improve positioning accuracy in challenging scenes.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948413","Autostereoscopy;mobile devices;depth perception;augmented reality;user study","Stereo image processing;Cameras;Augmented reality;Accuracy;Visualization;Hardware;Three-dimensional displays","augmented reality;computer displays","depth perception;handheld augmented reality;autostereoscopic displays;three-dimensional content;mobile video see-trough augmented reality;depth cue;occlusion;X-ray visualization;stereo camera","","23","","19","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"A Proposed Learning Content for Teaching Handheld Augmented Reality in a Classroom Setting","N. P. D. Gallego","De La Salle University, 2401 Taft Avenue, Malate, Manila, Philippines","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","111","118","Augmented reality is an interactive experience wherein digital objects are placed on the physical environment. Augmented reality (AR) applications have gained popularity especially when smartphones gained capable camera sensors, gyroscope, and other sensors. However, there has been a lack of framework or recommendations on how to formally teach developing mobile AR applications in a classroom setting. In this paper, we present a learning content, called ARVRDEV Courseware, that aims to teach undergraduate students how to develop augmented reality applications deployed on handheld devices. We carefully designed the lessons of the course, consistent with AR techniques from literature, and designed hands-on activities not typically presented in publicly available materials. A pilot run of the course was offered at De La Salle University, where a total of 76 undergraduate students took the course as an elective during their 4th year. We analyzed the effectiveness of the hands-on activities based on the assessment results of the students and discussed the outstanding projects developed by the students, which are observed to be inspired by the hands-on activities designed for the course.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00030","De La Salle University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262690","augmented reality;computing education;course design;application","Cameras;Augmented reality;Engines;Tools;Tutorials;Three-dimensional displays;Proteins","augmented reality;cameras;courseware;educational courses;mobile computing;smart phones;teaching","ARVRDEV courseware;physical environment;digital objects;interactive experience;teaching handheld augmented reality;undergraduate students;publicly available materials;hands-on activities;handheld devices;augmented reality applications;learning content;classroom setting;mobile AR applications;capable camera sensors","","","","50","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"Augmented reality in-situ 3D model menu for outdoors","T. N. Hoang; B. H. Thomas","Wearable Computer Laboratory, University of South Australia, Australia; Wearable Computer Laboratory, University of South Australia, Australia","2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality","3 Oct 2008","2008","","","185","186","We present a design and implementation of an in-situation menu system for loading and visualising 3D models in a physical world context. The menu system uses 3D objects as menu items, and the whole menu is placed within the context of the augmented environment. The use of 3D objects supports the visualisation and placement of 3D models into the augmented world. The menu system employs techniques for the placement of 3D models in two relative coordinate systems: head relative and world relative.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637358","H.5.2 [User Interfaces]: Graphical user interfaces (GUI) — Interaction styles;I.3.7 [Three-Dimensional Graphics and Realism]: Virtual reality — Animation","","augmented reality;data visualisation;graphical user interfaces","augmented reality;in-situ 3D model menu;outdoors;head relative coordinate system;world relative coordinate system","","3","5","5","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"An Implementation Review of Occlusion-Based Interaction in Augmented Reality Environment","M. S. Shahidan; N. Ibrahim; M. H. M. Zabil; A. Yusof","Graphics & Multimedia Department, Universiti Tenaga Malaysia (UNITEN), Selangor, Malaysia; Graphics & Multimedia Department, Universiti Tenaga Malaysia (UNITEN), Selangor, Malaysia; Department of Software Engineering, Universiti Tenaga Malaysia (UNITEN), Selangor, Malaysia; Department of Software Engineering, Universiti Tenaga Malaysia (UNITEN), Selangor, Malaysia","2009 Sixth International Conference on Computer Graphics, Imaging and Visualization","30 Oct 2009","2009","","","153","157","Augmented reality (AR) technology shows some potential in providing new approach of interaction with computer. It shares similar potential in virtual reality (VR) but at lower cost. In this paper, an AR application is developed to explore the capability of the interaction approach called occlusion based interaction using low cost device. The implementation of the application is utilizing the ARToolKit library as the main library to handle the AR part while OpenGL and GLUT to handle the graphics manipulation and windows management respectively.","","978-0-7695-3789-4","10.1109/CGIV.2009.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5298250","Augmented Reality;Occlusion Based Interaction","Augmented reality;Costs;Computer graphics;Virtual reality;Application software;Software libraries;Visualization;Software engineering;Productivity;Testing","human computer interaction;virtual reality","occlusion-based interaction;augmented reality technology;virtual reality;ARToolKit library;OpenGL;GLUT;graphics manipulation;windows management","","2","","4","IEEE","30 Oct 2009","","","IEEE","IEEE Conferences"
"Fine-Grained Visual Recognition in Mobile Augmented Reality for Technical Support","B. Zhou; S. Güven","IBM T. J. Watson Research Center, Yorktown Heights, New York, United States; IBM T. J. Watson Research Center, Yorktown Heights, New York, United States","IEEE Transactions on Visualization and Computer Graphics","10 Nov 2020","2020","26","12","3514","3523","Augmented Reality is increasingly explored as the new medium for two-way remote collaboration applications to guide the participants more effectively and efficiently via visual instructions. As users strive for more natural interaction and automation in augmented reality applications, new visual recognition techniques are needed to enhance the user experience. Although simple object recognition is often used in augmented reality towards this goal, most collaboration tasks are too complex for such recognition algorithms to suffice. In this paper, we propose a fine-grained visual recognition approach for mobile augmented reality, which leverages RGB video frames and sparse depth feature points identified in real-time, as well as camera pose data to detect various visual states of an object. We demonstrate the value of our approach through a mobile application designed for hardware support, which automatically detects the state of an object to present the right set of information in the right context.","1941-0506","","10.1109/TVCG.2020.3023635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199568","Visual recognition;augmented reality;mobile","Visualization;Cameras;Three-dimensional displays;Image recognition;Augmented reality;Maintenance engineering","augmented reality;cameras;feature extraction;image colour analysis;mobile computing;object recognition","mobile augmented reality;two-way remote collaboration applications;augmented reality applications;visual recognition techniques;user experience;object recognition;collaboration tasks;recognition algorithms;fine-grained visual recognition approach;mobile application;RGB video frames;sparse depth feature points","Algorithms;Augmented Reality;Humans;Image Processing, Computer-Assisted;Mobile Applications;Smartphone;Video Recording","8","","40","IEEE","17 Sep 2020","","","IEEE","IEEE Journals"
"Application of Augmented Reality in Campus Navigation","L. Zhigang; Q. Guanglei; H. Wenkai; M. Xiangyu; G. Qinsheng","Department of Computer Science and Technology, Century College, Beijing University of Posts and Telecommunications, Kangzhuang Town, Yanqing County, Beijing, China; Department of Computer Science and Technology, Century College, Beijing University of Posts and Telecommunications, Kangzhuang Town, Yanqing County, Beijing, China; Department of Computer Science and Technology, Century College, Beijing University of Posts and Telecommunications, Kangzhuang Town, Yanqing County, Beijing, China; Department of Computer Science and Technology, Century College, Beijing University of Posts and Telecommunications, Kangzhuang Town, Yanqing County, Beijing, China; Department of Computer Science and Technology, Century College, Beijing University of Posts and Telecommunications, Kangzhuang Town, Yanqing County, Beijing, China","2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP)","26 Apr 2021","2021","","","889","893","Augmented reality(AR) has the unique quality of providing a direct link between the physical reality and virtual information about that reality. In the application of a visitor visiting the campus with a smartphone, the location and pose information of the phone are acquired and calculated in real time. Then registration in 3D is realized by tracking the visitor's viewpoint and the phone post based on the result data. Also the location and orientation of the campus buildings relative to the visitor are identified. When the visitor is watching campus buildings, additional digital information appears to become part of the real world in the visitor's perception utilized by AR technology. As a result, the visitor not only appreciates the appearances and styles of the buildings directly, but also learn their history from the additional information which they can't intuitively understand.","","978-1-6654-0413-6","10.1109/ICSP51882.2021.9408770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408770","Augmented Reality;Location Based Service;Pose;Navigation","Three-dimensional displays;Navigation;Buildings;Signal processing;Real-time systems;History;Augmented reality","augmented reality;educational institutions;Global Positioning System;smart phones","campus navigation;direct link;physical reality;virtual information;visitor;phone post;campus buildings;digital information;AR technology;smartphone;visitor perception;location information;pose information","","","","12","IEEE","26 Apr 2021","","","IEEE","IEEE Conferences"
"Plausibility and Perception of Personalized Virtual Humans between Virtual and Augmented Reality","E. Wolf; D. Mal; V. Frohnapfel; N. Döllinger; S. Wenninger; M. Botsch; M. E. Latoschik; C. Wienrich","HCI Group, University of Würzburg; HCI Group, University of Würzburg; HCI Group, University of Würzburg; PIIS Group, University of Würzburg; Computer Graphics Group, TU Dortmund University; Computer Graphics Group, TU Dortmund University; HCI Group, University of Würzburg; PIIS Group, University of Würzburg","2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","27 Dec 2022","2022","","","489","498","This article investigates the effects of different XR displays on the perception and plausibility of personalized virtual humans. We compared immersive virtual reality (VR), video see-through augmented reality (VST AR), and optical see-through AR (OST AR). The personalized virtual alter egos were generated by state-of-the-art photogrammetry methods. 42 participants were repeatedly exposed to animated versions of their 3D-reconstructed virtual alter egos in each of the three XR display conditions. The reconstructed virtual alter egos were additionally modified in body weight for each repetition. We show that the display types lead to different degrees of incongruence between the renderings of the virtual humans and the presentation of the respective environmental backgrounds, leading to significant effects of perceived mismatches as part of a plausibility measurement. The device-related effects were further partly confirmed by subjective misestimations of the modified body weight and the measured spatial presence. Here, the exceedingly incongruent OST AR condition leads to the significantly highest weight misestimations as well as to the lowest perceived spatial presence. However, similar effects could not be confirmed for the affective appraisal (i.e., humanness, eeriness, or attractiveness) of the virtual humans, giving rise to the assumption that these factors might be unrelated to each other.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00065","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995637","Mixed reality;immersion;coherence;presence;body weight perception;body image;serious application;uncanny valley Human-centered computing;Empirical studies in HCI;Mixed / augmented reality;Virtual reality","Weight measurement;Rendering (computer graphics);Optical imaging;Appraisal;X reality;Image reconstruction","augmented reality;computer animation;human factors;image reconstruction;photogrammetry;virtual reality","3D-reconstructed virtual alter egos;augmented reality;device-related effects;different XR displays;display types;exceedingly incongruent OST AR condition;humanness;immersive virtual reality;modified body weight;personalized virtual alter egos;personalized virtual humans;plausibility measurement;state-of-the-art photogrammetry methods;XR display conditions","","","","68","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"Virtual Reality and Augmented Reality in Education","L. -C. Bazavan; H. Roibu; F. B. Petcu; S. I. Cismaru; B. N. George","Mechatronics and Robotics Department, Faculty of Automation, Computers and Electronics, University of Craiova, Craiova, Romania; Mechatronics and Robotics Department, Faculty of Automation, Computers and Electronics, University of Craiova, Craiova, Romania; Mechatronics and Robotics Department, Faculty of Automation, Computers and Electronics, University of Craiova, Craiova, Romania; Mechatronics and Robotics Department, Faculty of Automation, Computers and Electronics, University of Craiova, Craiova, Romania; Mechatronics and Robotics Department, Faculty of Automation, Computers and Electronics, University of Craiova, Craiova, Romania","2021 30th Annual Conference of the European Association for Education in Electrical and Information Engineering (EAEEIE)","10 Sep 2021","2021","","","1","4","Educational environment has faced and continues to face a lack of personnel, especially in fields of activity difficult to be understood like mathematics or physics. For this reason, schools are required to teach their students in classes with more students, being difficult for teachers to explain and exercise with every student individually. This involves blocking the activity during class of both the teacher and the other students. For a better understanding, in all science courses, the teachers usually spend multiple hours on the same subject, at the same time. After completing the subject, students need practice for memorizing and often need the teacher to help with homework. Because an active individual teacher, even virtual, is easier to be understood than a written instruction, the authors propose the use of virtual environments as a Virtual Reality/Augmented Reality (VR/AR) teacher. The use of augmented reality glasses offers a number of advantages, including: the possibility of working at the same time while following the instructions, reviewing the course material or following a teacher resolving an exercise without having to interrupt or taking a long time to resolve the homework. This paper presents the possibilities of using virtual and augmented reality devices such as Google Glass or Oculus Rift for individual teaching classes.","2472-7687","978-1-7281-9327-4","10.1109/EAEEIE50507.2021.9531005","European Social Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9531005","Virtual Reality;Augmented Reality;Education;Display devices","Education;Virtual environments;Glass;Mathematics;Libraries;Internet;Personnel","augmented reality;computer aided instruction;educational courses;teaching","educational environment;active individual teacher;virtual environments;augmented reality glasses;individual teaching classes;virtual reality;augmented reality devices;Google Glass;Oculus Rift","","2","","9","IEEE","10 Sep 2021","","","IEEE","IEEE Conferences"
"Evolutionary augmented reality at the Natural History Museum","P. Debenham; G. Thomas; J. Trout","BBC Research & Development; BBC Research & Development, UK; Natural History Museum, London, UK","2011 10th IEEE International Symposium on Mixed and Augmented Reality","5 Mar 2012","2011","","","249","250","In this paper we describe the development of an augmented reality system designed to provide an exciting new way for the Natural History Museum in London to present evolutionary history to their visitors. The system uses a through-the-lens tracker and infrared LED markers to provide an unobtrusive and robust system that can operate for multiple users across a wide area.","","978-1-4577-2185-4","10.1109/ISMAR.2011.6092400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162901","Augmented Reality application;camera tracking","Cameras;History;Films;Augmented reality;Light emitting diodes;Multimedia communication;Optical sensors","","","","4","","5","IEEE","5 Mar 2012","","","IEEE","IEEE Conferences"
"Usability of one handed interaction methods for hand-held projection-based augmented reality","J. Choi; Y. Kim; G. J. Kim","Digital Experience Laboratory, Korea University, Seoul, South Korea; Digital Experience Laboratory, Korea University, Seoul, South Korea; Digital Experience Laboratory, Korea University, Seoul, South Korea","2011 10th IEEE International Symposium on Mixed and Augmented Reality","5 Mar 2012","2011","","","233","234","With the advent of portable projectors (also embedded in a smart phone), projection based augmented reality (AR) will be an attractive form of AR as the augmentation is made directly in real space (instead of on the video screen). Several interaction methods for “Procam” systems, also applicable to projection based AR, have been developed, but their comparative usability has not been studied in depth. In this paper, we compare the usability of four representative interaction methods, applied to the menu selection task, for the hand-held projection based AR. The four menu selection methods studied are formed by combinations of two types of cursor control (projector cursor vs. on-device touch screen), and two types of item selection (explicit click vs. crossing). Experimental results have shown that the menu selection task was most efficient, usable and preferred when the projector cursor with the crossing widget was used. Furthermore, the task performance was not statistically different between using the dominant, non-dominant hand and even both hands.","","978-1-4577-2185-4","10.1109/ISMAR.2011.6092392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162894","Augmented Reality;Projection based;Interaction;Menu Selection","Smart phones;Usability;Augmented reality;Educational institutions;Thumb;Prototypes","","","","2","","7","IEEE","5 Mar 2012","","","IEEE","IEEE Conferences"
"HoloRoyale: A Large Scale High Fidelity Augmented Reality Game","D. Hompapas; C. Sandor; A. Plopski; D. Saakes; D. H. Yun; T. Taketomi; H. Kato","Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Department of Industrial Design, KAIST; Department of Industrial Design, KAIST; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","409","410","Recent years saw an explosion in Augmented Reality (AR) experiences for consumers. These experiences can be classified based on the scale of the interactive area (room vs city/global scale), or the fidelity of the experience (high vs low) [4]. Experiences that target large areas, such as campus or world scale [6], [7], commonly have only rudimentary interactions with the physical world, and suffer from registration errors and jitter. We classify these experiences as large scale and low fidelity. On the other hand, various room sized experiences [5], [8] feature realistic interaction of virtual content with the real world. We classify these experiences as small scale and high fidelity.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699298","Human-centered Computing;Mixed/Augmented Reality","Games;Augmented reality;Synchronization;Servers;Navigation;Three-dimensional displays;Drones","","","","","","8","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Augmented reality based upper limb rehabilitation system","W. Ying; W. Aimin","School of Instruments Science and Engineering, Southeast Uniersity, Nanjing, China; School of Instruments Science and Engineering, Southeast Uniersity, Nanjing, China","2017 13th IEEE International Conference on Electronic Measurement & Instruments (ICEMI)","22 Jan 2018","2017","","","426","430","Traditional motor rehabilitation is monotonous and dull. There is little interaction between the users and the system. The effect of rehabilitation is far from satisfying. To overcome the shortcomings of traditional rehabilitation, augmented reality (AR) technology is introduced into rehabilitation, and a novel upper limb rehabilitation system is proposed. Vision based method is used to register virtual objects. The integration of virtual objects and real world brings benefits of both traditional rehabilitation system and virtual reality (VR) rehabilitation system. The proposed system offers 3 augmented reality games, in which a patient controls virtual objects by manipulating some marker attached appliances. The patient's performances are recorded. The remote therapist system is established, by which the data and the patient's training video are provided to the therapists Thus, therapists can easily get the information of a patient and give the patient professional guidance.","","978-1-5090-5035-2","10.1109/ICEMI.2017.8265843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8265843","virtual reality;augmented reality;upper-limb rehabilitation","Games;Training;Real-time systems;Transmission line matrix methods;Instruments;Conferences;Virtual reality","augmented reality;computer games;computer vision;medical robotics;patient rehabilitation","remote therapist system;upper limb rehabilitation system;vision based method;virtual reality rehabilitation system;augmented reality games;virtual objects","","13","","16","IEEE","22 Jan 2018","","","IEEE","IEEE Conferences"
"A study of depth visualization techniques for virtual annotations in augmented reality","K. Uratani; T. Machida; K. Kiyokawa; H. Takemura","Graduate School of Information Science and Technology, Osaka University, Japan; Cybermedia Center, Graduate School of Information Science and Technology, Osaka University, Japan; Cybermedia Center, Graduate School of Information Science and Technology, Osaka University, Japan; Cybermedia Center, Graduate School of Information Science and Technology, Osaka University, Japan","IEEE Proceedings. VR 2005. Virtual Reality, 2005.","15 Aug 2005","2005","","","295","296","In this paper, we discuss depth visualization techniques for virtual annotations to alleviate the depth ambiguity problem. We begin by describing the depth ambiguity problem with regard to virtual annotations. Then a number of possible solutions are discussed by introducing a metaphor of monocular depth cues, and the effectiveness and characteristics of the three visualization techniques are shown through the preliminary experiments.","2375-5334","0-7803-8929-8","10.1109/VR.2005.1492802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1492802","","Visualization;Augmented reality;Information science;Rendering (computer graphics);Virtual reality;Chromium;Multimedia systems;Navigation;Geometry;Convergence","augmented reality;user interfaces;human computer interaction;helmet mounted displays;data visualisation;rendering (computer graphics)","depth visualization;virtual annotations;augmented reality;depth ambiguity problem;monocular depth cues;depth information","","6","1","2","IEEE","15 Aug 2005","","","IEEE","IEEE Conferences"
"Control with Vergence Eye Movement in Augmented Reality See-Through Vision","Z. Wang; Y. Zhao; F. Lu","State Key Laboratory of VR Technology and Systems, School of Computer Science and Engineering, Beihang University; State Key Laboratory of VR Technology and Systems, School of Computer Science and Engineering, Beihang University; State Key Laboratory of VR Technology and Systems, School of Computer Science and Engineering, Beihang University","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","548","549","Augmented Reality (AR) see-through vision has become a recent research focus since it enables the user to see through a wall and see the occluded objects. Most existing works only used common modalities to control the display for see-through vision, e.g., button clicking and speech control. However, we use visual system to observe see-through vision. Using an addition interaction channel will distract the user and degrade the user experience. In this paper, we propose a novel interaction method using vergence eye movement for controlling see-through vision in AR. Specifically, we first customize eye cameras and design gaze depth estimation method for Microsoft HoloLens 2. With our algorithm, fixation depth can be computed from the vergence, and used to manage the see-through vision. We also propose two control techniques of gaze vergence. The experimental results show that the gaze depth estimation method is efficient. The difference cannot be found between these two modalities in terms of completion time and the number of successes.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757383","Augmented Reality;See-through Vision;Vergence Eye Movement;Human Computer Interaction (HCI)","Human computer interaction;Three-dimensional displays;Conferences;Estimation;Visual systems;Cameras;User experience","augmented reality;computer vision;eye","vergence eye movement;augmented Reality;Augmented Reality;recent research focus;occluded objects;common modalities;button clicking;speech control;visual system;addition interaction channel;user experience;novel interaction method;eye cameras;design gaze depth estimation method;fixation depth;control techniques;gaze vergence","","2","","7","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Augmented Reality Guidance for Configuring an Anesthesia Machine to Serve as a Ventilator for COVID-19 Patients","F. He; M. Li; R. B. Maniker; D. O. Kessler; S. K. Feiner",Columbia University; Columbia University; Columbia University Irving Medical Center; Columbia University Irving Medical Center; Columbia University,"2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","701","702","When there is a shortage of ventilators in a hospital, an anesthesia machine can be used as a ventilator. However, using an anesthesia machine as a ventilator requires that it be set up in a way that would not be familiar to medical personnel who normally work with ventilators. To teach medical staff how to do this, we developed a smartphone augmented reality app that allows a user to interact with a life-size virtual anesthesia machine, and leads them through the necessary steps. This makes it possible for the user to practice the setup procedures in a way that preserves the 3D spatial layout of the tasks without requiring access to the physical machine.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419313","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Applied computing;Life and medical sciences;Health informatics","Ventilators;Three-dimensional displays;Conferences;Layout;User interfaces;Anesthesia;Personnel","augmented reality;computer aided instruction;diseases;medical computing;smart phones","medical staff;medical personnel;smartphone augmented reality app;COVID-19 patients;ventilator;augmented reality guidance;physical machine;life-size virtual anesthesia machine","","2","","4","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Rediscovering Neighborhood History Through Augmented Reality","M. -C. Lee","School of Architecture University of North Carolina at Charlotte, Charlotte, USA","2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","22 Dec 2021","2021","","","60","64","Augmented Reality (AR) goes beyond conventional methods of engagement with the public. It offers an interactive method to expand visualization techniques in civic engagement necessary for museum exhibitions that are focused on cultural and social issues. This paper discusses four AR projects conducted by a partnership between a history museum and a university in the City of Charlotte, USA. These projects, which utilize a variety of AR technologies, support a series of community events that are aimed at expanding overall public participation with a goal of increasing awareness of neighborhood history through data visualization and storytelling.","","978-1-6654-3225-2","10.1109/AIVR52153.2021.00018","John S. and James L. Knight Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644257","Augmented Reality;immersive technologies;civic engagement;data visualization;Geographic Information System","Conferences;Urban areas;Data visualization;History;Global communication;Cultural differences;Artificial intelligence","augmented reality;data visualisation;exhibitions;history;museums","neighborhood history;augmented Reality;Augmented Reality;interactive method;visualization techniques;civic engagement;museum exhibitions;cultural issues;social issues;AR projects;history museum;public participation;data visualization;storytelling","","","","14","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Virtual Loupes: An Augmented Reality Aid for Microsurgery","C. Ilo; W. Zheng; D. A. Bowman","Center for Human-Computer Interaction, Virginia Tech; Virginia Tech Carilion School of Medicine; Center for Human-Computer Interaction, Virginia Tech","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","617","618","Microsurgery requires the use of loupes, which are optical elements attached to eyeglass frames that magnify objects such as blood vessels and nerves. To address the inflexibility of loupes, we have developed an augmented reality system that provides virtual loupes with a video see-through headset, allowing for easy-to-use variable zoom in a surgical context. Our prototype solution utilizes a gaze-controlled interface, which allows for the zoom level to be selected in either a discrete or continuous manner. A feasibility study revealed both the potential of virtual loupes and the limitations of current technology to realize this concept.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419112","Augmented reality;Microsurgery;Gaze-controlled interfaces;Video see-through headset","Headphones;Three-dimensional displays;Conferences;Prototypes;Microsurgery;User interfaces;Blood vessels","augmented reality;blood vessels;medical computing;surgery","virtual loupes;augmented reality aid;microsurgery;optical elements;magnify objects;blood vessels;augmented reality system;easy-to-use variable zoom","","","","3","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"ARCritique: Supporting Remote Design Critique of Physical Artifacts through Collaborative Augmented Reality","Y. Li; D. Hicks; W. S. Lages; S. Won Lee; A. Sharma; D. A. Bowman","Center for Human-Computer Interaction, Virginia Tech; Center for Human-Computer Interaction, Virginia Tech; Center for Human-Computer Interaction, Virginia Tech; Center for Human-Computer Interaction, Virginia Tech; Center for Human-Computer Interaction, Virginia Tech; Center for Human-Computer Interaction, Virginia Tech","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","585","586","Design critique sessions require students and instructors to jointly view and discuss physical artifacts. However, in remote learning scenarios, available tools (such as videoconferencing) are insufficient due to ineffective, inefficient communication of spatial information. This paper presents ARCritique, a mobile augmented reality application that combines KinectFusion and ARKit to allow users to 1) scan artifacts and share the resulting 3D models, 2) view the model simultaneously in a shared virtual environment from remote physical locations, and 3) point to and draw on the model to aid communication. A preliminary evaluation of ARCritique revealed great potential for supporting remote design education.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00175","Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419257","Human-centered computing;Mixed / augmented reality;Collaborative and social computing;Collaborative and social computing systems and tools","Solid modeling;Teleconferencing;Social computing;Three-dimensional displays;Distance learning;Conferences;Virtual environments","augmented reality;distance learning;groupware;mobile computing;teleconferencing","ARCritique;remote design critique;physical artifacts;collaborative augmented reality;design critique sessions;remote learning scenarios;ineffective communication;inefficient communication;spatial information;mobile augmented reality application;shared virtual environment;remote physical locations;remote design education;KinectFusion;ARKit","","","","4","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Nurse Perceptions of the Usability of Augmented Reality to Support Clinical Decision Making: Results of a Pilot Study","N. E. Anton; G. Zhou; T. M. Hornbeck; D. Yu","School of Industrial Engineering, Purdue University, West Lafayette, IN; School of Industrial Engineering, Purdue University, West Lafayette, IN; School of Nursing, Purdue University, West Lafayette, IN; School of Industrial Engineering, Purdue University, West Lafayette, IN","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","517","520","Clinically, nurses must rapidly identify deteriorating patients and escalate patient care to adverse events. Novices, however, can easily succumb to cognitive overload. Augmented-reality (AR) devices, such as the Microsoft HoloLens 2, may help nurses attend to task-relevant information more effectively. The aim of this pilot study was to assess experienced nurses' perceptions on the usability of AR. Practicing nurses were recruited for this study. Following a brief tutorial, demonstration and hands-on use of the HoloLens, nurses completed the system-usability scale (SUS) to rate usability. Additionally, interviews were conducted after the simulated use session. Experienced nurses (n= 11) rated the usability of AR as 62.5±7.8. Themes that emerged from our open-ended interviews included the need for AR in nursing education and the potential benefit of a patient care checklist. Use of AR to support nurse decision making may reduce cognitive workload and focus attention on critical areas to recognize patient deterioration.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00115","National Science Foundation(grant numbers:IIS 1928661); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757397","Augmented Reality;Nurses;Students;Decision Making;Human computer interaction (HCI);Education","Training;Three-dimensional displays;Conferences;Decision making;Tutorials;User interfaces;Usability","augmented reality;biomedical education;cognition;decision making;decision support systems;diseases;health care;medical computing;medical information systems;patient care;patient treatment","nurse perceptions;augmented reality;clinical decision making;cognitive overload;augmented-reality devices;Microsoft HoloLens 2;task-relevant information;experienced nurses;practicing nurses;system-usability scale;rate usability;patient care checklist;nurse decision making;patient deterioration","","","","19","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"An Augmented Reality Application for Clinical Breast Examination Training","K. Wang; A. Muralidharan; J. Cuasay; S. Pruthi; T. Kesavadas","Health Care Engineering Systems Center, University of Illinois Urbana-Champaign, Urbana, Illinois; Health Care Engineering Systems Center, University of Illinois Urbana-Champaign, Urbana, Illinois; Health Care Engineering Systems Center, University of Illinois Urbana-Champaign, Urbana, Illinois; Division of General Internal Medicine, Mayo Clinic, Rochester, Minnesota; Health Care Engineering Systems Center, University of Illinois Urbana-Champaign, Urbana, Illinois","2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","22 Dec 2021","2021","","","224","227","Clinical breast examinations (CBE) are physical exams of breasts done by healthcare providers to detect and screen for breast cancers. They play an important role in the early detection of breast cancer. Performing CBE has been limited due to the lack of training available to healthcare professionals. In this paper, we describe our development of a training simulator that combines hardware-based and augmented reality (AR) technology to train and evaluate medical providers on CBE skills. The AR application contains two modules: one is used to visualize breast deformation and the other supports visualization of the palpation force applied by the user on the breast phantom.","","978-1-6654-3225-2","10.1109/AIVR52153.2021.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644293","Clinical breast examination;Breast deformation;Simulation;Training;Augmented reality","Training;Deformable models;Solid modeling;Force;Phantoms;Data visualization;Medical services","augmented reality;biological organs;cancer;health care;mammography;medical image processing;phantoms;training","augmented reality application;clinical breast examination training;healthcare providers;breast cancer;training simulator;medical providers;CBE skills;AR application;breast deformation;breast phantom;augmented reality technology;visualize breast deformation","","","","20","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality Technology for the Treatment of Mental Health Disorders: An Overview","Anjali; G. Singh; J. Kaur Sandhu","Department of Computer Science and Engineering, Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, Rajpura, India; Department of Electronics and Communication Engineering, Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, Rajpura, India; Department of Computer Science and Engineering, Chandigarh University, Punjab, Mohali, India","2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)","26 Dec 2022","2022","","","1","5","Augmented and Virtual Reality plays an important role in the field of medical health science. According to the study of past decades, Human computer interaction helps the patients to recover from their issues very quickly. Virtual Reality is used in several fields nowadays and the study of this paper is in the field of clinical sector. The purpose of using Virtual Reality concepts on the patients is that it helps to change the functioning of the brain and also change the behavior, mood, and perception of the person. For example phobias, and addicted person, when person is in an abnormal situation and their mind is not working properly at that time they need a virtual environment. There is a requirement to show the virtual videos to the patients according to their problems. So to analyze the problem of the patients, use virtual reality concept to check the level of the stress, anxiety, and phobias.","","978-1-6654-5262-5","10.1109/ICCCNT54827.2022.9984551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9984551","Virtual Reality;Cognitive Behavioral Therapy;Augmented Reality;Exposure Therapy;Psychological Behavior","Human computer interaction;Pain;Mood;Anxiety disorders;Education;Virtual environments;Virtual reality","augmented reality;behavioural sciences computing;human computer interaction;human factors;patient treatment","augmented reality technology;human computer interaction;medical health science;mental health disorders;virtual environment;virtual reality technology;virtual videos","","","","27","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"Collaborative Augmented Reality for Chess Game in Handheld Devices","C. S. Yusof; T. S. Low; A. W. Ismail; M. S. Sunar","Media and Game Innovation Centre of Excellence (MaGICX), Universiti Teknologi Malaysia, Skudai, Malaysia; School of Computing, Universiti Teknologi Malaysia, Skudai, Malaysia; School of Computing, Universiti Teknologi Malaysia, Skudai, Malaysia; Media and Game Innovation Centre of Excellence (MaGICX), Universiti Teknologi Malaysia, Skudai, Malaysia","2019 IEEE Conference on Graphics and Media (GAME)","6 Feb 2020","2019","","","32","37","Augmented Reality (AR) merges virtual and real entities into single environment and thus, create a higher immersion and presence of virtual object in real environment. A collaborative interface allows AR entities to be shared across multiple devices. Handheld devices readily support network connectivity with high processing power can be used to enable collaborative Handheld Augmented Reality (HAR) interface for AR game. AR game is combining the complex rule in computerized game with real interaction and high immersion in physical game. This paper proposes an implementation of collaborative HAR interface in handheld devices for chess game. A design of chess game is developed, then enabled for AR display with image marker tracking by using Vuforia AR Software Development Kit. The implementation of Photon Unity Networking as the collaborative interface bridges the connection between multiple handheld devices to synchronize the AR chess game with multiuser interaction technique. The result from evaluation indicates that the chess game is readily acceptable by the users and is enhancing the gameplay experience of ordinary chess game. This paper depicts the significance in enabling a collaborative HAR interface in games to boost the gameplay experience while preserving the physical presence of the game.","","978-1-7281-3944-9","10.1109/GAME47560.2019.8980979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8980979","Collaborative augmented reality;handheld augmented reality;augmented reality game;chess game","","augmented reality;computer games;groupware;human computer interaction;mobile computing;software development management;user experience","collaborative Augmented Reality;collaborative Handheld Augmented Reality interface;AR game;computerized game;physical game;collaborative HAR interface;collaborative interface bridges;multiple handheld devices;AR chess game;Vuforia AR software development kit;gameplay experience","","8","","23","IEEE","6 Feb 2020","","","IEEE","IEEE Conferences"
"A mediated reality environment using a loose and sketchy rendering technique","M. Haller; F. Landerl","Media Technology and Design, Upper Austria University of Applied Sciences, Hagenberg, Austria; Media Technology and Design, Upper Austria University of Applied Sciences, Hagenberg, Austria","Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)","5 Dec 2005","2005","","","184","185","We present sketchy-ar-us, a modified, realtime version of the Loose and Sketchy algorithm used to render graphics in an AR environment. The primary challenge was to modify the original algorithm to produce a NPR effect at interactive frame rate. Our algorithm renders moderately complex scenes at multiple frames per second. Equipped with a handheld visor, visitors can see the real environment overlaid with virtual objects with both the real and virtual content rendered in a non-photorealistic style.","","0-7695-2459-1","10.1109/ISMAR.2005.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544685","","Rendering (computer graphics);Layout;Algorithm design and analysis;Augmented reality;Filters;Computer graphics;Filtering;Image segmentation;Cameras;Real time systems","rendering (computer graphics);augmented reality","mediated reality environment;rendering technique;sketchy-ar-us realtime version;Loose and Sketchy algorithm;augmented reality;interactive frame rate","","4","","3","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Changing the World with Virtual\/Augmented Reality Technologies","Y. Yuan","IEEE Digital Senses Initiative, IEEE Transportation Electrification Community","IEEE Consumer Electronics Magazine","16 Dec 2016","2017","6","1","40","41","Although the concepts of virtual reality (VR) and augmented reality (AR) were invented decades ago (if not centuries ago, in a broader sense), the technologies enabling VR and AR just collectively met a critical point in recent years as people started enjoying the experience rather than merely tolerating it, as they did in the early days. From this point, more and more people believe that VR and AR have the potential to disruptively change our world in many respects.","2162-2256","","10.1109/MCE.2016.2614411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7786938","","Augmented reality;Training;Virtual reality;Market opportunities","augmented reality","virtual reality;VR technology;augmented reality;AR technology","","15","","","IEEE","16 Dec 2016","","","IEEE","IEEE Magazines"
"Being an Avatar “for Real”: A Survey on Virtual Embodiment in Augmented Reality","A. Genay; A. Lécuyer; M. Hachet","Inria, Bordeaux, France; Inria, Rennes, France; Inria, Bordeaux, France","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2022","2022","28","12","5071","5090","Virtual self-avatars have been increasingly used in Augmented Reality (AR) where one can see virtual content embedded into physical space. However, little is known about the perception of self-avatars in such a context. The possibility that their embodiment could be achieved in a similar way as in Virtual Reality opens the door to numerous applications in education, communication, entertainment, or the medical field. This article aims to review the literature covering the embodiment of virtual self-avatars in AR. Our goal is (i) to guide readers through the different options and challenges linked to the implementation of AR embodiment systems, (ii) to provide a better understanding of AR embodiment perception by classifying the existing knowledge, and (iii) to offer insight on future research topics and trends for AR and avatar research. To do so, we introduce a taxonomy of virtual embodiment experiences by defining a “body avatarization” continuum. The presented knowledge suggests that the sense of embodiment evolves in the same way in AR as in other settings, but this possibility has yet to be fully investigated. We suggest that, whilst it is yet to be well understood, the embodiment of avatars has a promising future in AR and conclude by discussing possible directions for research.","1941-0506","","10.1109/TVCG.2021.3099290","Institut national de recherche en informatique et en automatique (INRIA); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9495125","Augmented reality;avatar;sense of embodiment;psychology;social and behavioral sciences","Avatars;Psychology;Visualization;Behavioral sciences;Taxonomy;Augmented reality;Virtual environments","augmented reality;avatars;human factors","AR embodiment perception;AR embodiment systems;augmented reality;body avatarization continuum;entertainment;medical field;physical space;virtual content;virtual embodiment experiences;virtual reality;virtual self-avatars","Augmented Reality;User-Computer Interface;Computer Graphics;Virtual Reality;Surveys and Questionnaires","12","","171","IEEE","26 Jul 2021","","","IEEE","IEEE Journals"
"Enhancing Immersive Cinematic Experience with Augmented Virtuality","G. A. Lee; J. Chen; M. Billinghurst; R. Lindeman","School of Information Technology and Mathematical Sciences, University of South Australia; The Human Interface Technology Laboratory New Zealand, University of Canterbury; School of Information Technology and Mathematical Sciences, University of South Australia; The Human Interface Technology Laboratory New Zealand, University of Canterbury","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","115","116","Watching spherical panorama movies is one of the applications of head mounted displays, especially the growing number of lowcost consumer devices. In this poster, we show how to enhance a personal immersive cinematic experience by embedding the user's body in the movie scene using Augmented Virtuality technology. User embodiment, transitioning between real and virtual spaces, and adding interactivity are the main benefits of our approach. We present a proof of concept prototype, and summarize the findings from a focus group held to collect feedback from potential users. These insights will help developers who are creating immersive cinematic experiences.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836475","Augmented Virtuality;Mixed Reality;Panorama Movie;Transitional Interface","Motion pictures;Prototypes;Augmented virtuality;Resists;Head;Virtual environments","augmented reality;cinematography;helmet mounted displays","interactivity;virtual spaces;real spaces;movie scene immersion;head mounted displays;spherical panorama movies;augmented virtuality technology;immersive cinematic experience enhancement","","2","","6","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Contextualizing Educational Robotics Programming with Augmented Reality","C. Pasalidou; N. Fachantidis","dept. Educational and Social Policy, LIRES lab University of Macedonia, Thessaloniki, Greece; dept. Educational and Social Policy, LIRES lab University of Macedonia, Thessaloniki, Greece","2022 8th International Conference of the Immersive Learning Research Network (iLRN)","11 Jul 2022","2022","","","1","5","The development of technology in recent years has led to the research of innovative tools in education. Technologies, such as Augmented, Virtual, and Mixed Reality can be utilized in immersive environments for educational purposes. Educational Robotics has also been prevalent in K-12 and STEM education. In this paper, we describe a mobile augmented reality learning environment to support robotics programming. An augmented reality application was developed and evaluated by two experts. Two experiments were conducted, including the non-AR and the AR condition. The participants were primary school students. Both observation and interviews were conducted. Our results showed that augmented reality attracts students’ interest in robotics programming, prompts them to participate in the learning process and is easy to use. Limitations and advantages of the AR approach in educational robotics were pointed out. The results indicate that contextualizing robotics with augmented reality is promising and should be further studied.","","978-1-7348995-3-5","10.23919/iLRN55037.2022.9815969","University of Macedonia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815969","augmented reality;immersive learning;robotics","Education;Mixed reality;Interviews;Augmented reality;Robot programming","augmented reality;computer aided instruction;educational robots;mobile computing;robot programming;virtual reality","mobile augmented reality learning environment;augmented reality application;educational Robotics programming;Mixed Reality;immersive environments;educational purposes","","","","34","","11 Jul 2022","","","IEEE","IEEE Conferences"
"A replication study testing the validity of AR simulation in VR for controlled experiments","C. Lee; S. Bonebrake; T. Hollerer; D. A. Bowman","University of California, Santa Barbara, USA; University of California, Santa Barbara, USA; University of California, Santa Barbara, USA; Virginia Technology, USA","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","203","204","It is extremely challenging to run controlled studies comparing multiple augmented reality (AR) systems. We use an ldquoAR simulationrdquo approach, in which a virtual reality (VR) system is used to simulate multiple AR systems. In order to validate this approach, we carefully replicated a well-known study by Ellis et al. using our simulator, obtaining comparable results.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336464","I.3.7 [Three-Dimensional Graphics and Realism]: Virtual Reality;AR Simulation; I.3.6 [Methodology and Techniques]: Device independence;Replication","Virtual reality;Delay;Augmented reality;Hardware;Performance analysis;System testing;Graphics;Control system synthesis;Displays;Computational modeling","augmented reality","AR simulation system testing;virtual reality system;VR system;controlled experiment;multiple augmented reality system","","22","","4","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Novel Augmented Reality Enhanced Solution towards Vocational Training for People with Mental Disabilities","B. Soon Wei Chiam; I. Mun Wah Leung; O. Zane Devilly; C. Yun Da Ow; F. Yunqing Guan; B. Leet Tan","Health and Social Sciences Cluster, Singapore Institute of Technology; Health and Social Sciences Cluster, Singapore Institute of Technology; InfoComm Technology Cluster, Singapore Institute of Technology; InfoComm Technology Cluster, Singapore Institute of Technology; InfoComm Technology Cluster, Singapore Institute of Technology; Health and Social Sciences Cluster, Singapore Institute of Technology","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","195","200","Augmented Reality is widely recognized as the next computing platform and has found applications in various sectors, including training, education, entertainment, engineering, etc. Although AR has been applied to cognitive training for people with neurological and psychiatric conditions, there is a huge potential in its use within the field of vocational rehabilitation for persons with psychiatric and neurodevelopmental disabilities. In this paper, we present a novel AR enhanced solution towards vocational rehabilitation for people with a range of cognitively functional levels. Multiple immersive training scenarios are designed and developed with a target of allowing users to develop their vocational skills which is evaluated by the Feasibility Evaluation Checklist. Proper user interface design approach was deployed with considerations given to the target users. The solution also supports multiplayer mode thus allowing the therapists to keep track of vital performance data of the users in the co-immersed AR environment. A user study was conducted with satisfying results achieved.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585856","Augmented Reality;Vocational Training;Cognitive Rehabilitation;Computing methodologies;Computer graphics;Graphics systems and interfaces;Mixed / augmented reality","Target tracking;Entertainment industry;User interfaces;Vocational training;Augmented reality","augmented reality;cognition;computer based training;handicapped aids;neurophysiology;patient rehabilitation;user interfaces;vocational training","vocational training;cognitive training;neurological conditions;psychiatric conditions;vocational rehabilitation;psychiatric disabilities;neurodevelopmental disabilities;cognitively functional levels;multiple immersive training scenarios;vocational skills;user interface;augmented reality enhanced solution;feasibility evaluation checklist","","","","32","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Studying Exocentric Distance Perception in Optical See-Through Augmented Reality","E. Peillard; F. Argelaguet; J. -M. Normand; A. Lécuyer; G. Moreau","Inria, Univ. Rennes; Inria, Univ. Rennes; École Centrale de Nantes, Inria Hybrid; IRISH, Univ. Rennes, Rennes, France; École Centrale de Nantes, Inria Hybrid","2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","30 Dec 2019","2019","","","115","122","While perceptual biases have been widely investigated in Virtual Reality (VR), very few studies have considered the challenging environment of Optical See-through Augmented Reality (OST-AR). Moreover, regarding distance perception, existing works mainly focus on the assessment of egocentric distance perception, i.e. distance between the observer and a real or a virtual object. In this paper, we study exocentric distance perception in AR, hereby considered as the distance between two objects, none of them being directly linked to the user. We report a user study (n=29) aiming at estimating distances between two objects lying in a frontoparallel plane at 2.1m from the observer (i.e. in the medium-field perceptual space). Four conditions were tested in our study: real objects on the left and on the right of the participant (called real-real), virtual objects on both sides (virtual-virtual), a real object on the left and a virtual one on the right (real-virtual) and finally a virtual object on the left and a real object on the right (virtual-real). Participants had to reproduce the distance between the objects by spreading two real identical objects presented in front of them. The main findings of this study are the overestimation (20%) of exocentric distances for all tested conditions. Surprisingly, the real-real condition was significantly more overestimated (by about 4%, p=.0166) compared to the virtual-virtual condition, i.e. participants obtained better estimates of the exocentric distance for the virtual-virtual condition. Finally, for the virtual-real/real-virtual conditions, the analysis showed a non-symmetrical behavior, which suggests that the relationship between real and virtual objects with respect to the user might be affected by other external factors. Considered together, these unexpected results illustrate the need for additional experiments to better understand the perceptual phenomena involved in exocentric distance perception with real and virtual objects.","1554-7868","978-1-7281-0987-9","10.1109/ISMAR.2019.00-13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943756","Perception;Distance;Augmented Reality;User Experiment;Psychophysical Study","Augmented reality","augmented reality;visual perception","augmented reality;Virtual Reality;egocentric distance perception;virtual object;exocentric distance perception;virtual-virtual condition;optical see-through augmented reality;exocentric distances","","9","","33","IEEE","30 Dec 2019","","","IEEE","IEEE Conferences"
"Mirrorlabs - creating accessible Digital Twins of robotic production environment with Mixed Reality","D. Aschenbrenner; J. S. I. Rieder; D. van Tol; J. van Dam; Z. Rusak; J. O. Blech; M. Azangoo; S. Panu; K. Kruusamäe; H. Masnavi; I. Rybalskii; A. Aabloo; M. Petry; G. Teixeira; B. Thiede; P. Pedrazzoli; A. Ferrario; M. Foletti; M. Confalonieri; D. Bertaggia; T. Togias; S. Makris","Industrial Design Engineering TU Delft, Delft, Netherlands; Industrial Design Engineering TU Delft, Delft, Netherlands; Industrial Design Engineering TU Delft, Delft, Netherlands; Industrial Design Engineering TU Delft, Delft, Netherlands; Industrial Design Engineering TU Delft, Delft, Netherlands; Electrical Engineering and Automation, Aalto University, Espoo, Finland; Electrical Engineering and Automation, Aalto University, Espoo, Finland; Electrical Engineering and Automation, Aalto University, Espoo, Finland; Intelligent Materials and Systems, Lab University Tartu, Tartu, Estonia; Intelligent Materials and Systems, Lab University Tartu, Tartu, Estonia; Intelligent Materials and Systems, Lab University Tartu, Tartu, Estonia; Intelligent Materials and Systems, Lab University Tartu, Tartu, Estonia; CRIIS, INESC TEC - Institute for Systems and Computer Engineering, Technology and Science, Porto, Portugal; CRIIS, INESC TEC - Institute for Systems and Computer Engineering, Technology and Science, Porto, Portugal; TU Braunschweig, Braunschweig, Germany; SUPSI, Manno, Switzerland; SUPSI, Manno, Switzerland; SUPSI, Manno, Switzerland; SUPSI, Manno, Switzerland; SUPSI, Manno, Switzerland; LMS, University of Patras, Patras, Greece; LMS, University of Patras, Patras, Greece","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","43","48","How to visualize recorded production data in Virtual Reality? How to use state of the art Augmented Reality displays that can show robot data? This paper introduces an opensource ICT framework approach for combining Unity-based Mixed Reality applications with robotic production equipment using ROS Industrial. This publication gives details on the implementation and demonstrates the use as a data analysis tool in the context of scientific exchange within the area of Mixed Reality enabled human-robot co-production.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319071","Industry 4.0;manufacturing;Augmented Reality;Virtual Reality;Human Robot Co production;Human Robot Interaction","Robots;Service robots;Robot sensing systems;Production;Mixed reality;Hardware;Software","augmented reality;data analysis;data visualisation;human-robot interaction;industrial robots;production engineering computing;production equipment;public domain software","virtual reality;augmented reality;robotic production equipment;data analysis tool;human robot co-production;mirrorlabs;digital twins;robotic production environment;Unity based mixed reality applications;production data visualization;open source ICT framework;ROS Industrial","","2","","17","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"An Augmented Reality ecosystem for learning environment","R. C. Saritha; U. Mankad; G. Venkataswamy; S. Bindhumadhava Bapu","Department of Real time Sytems & Internet of Things, Centre for Development of Advanced Computing(CDAC), Bangalore, India; Department of Real time Sytems & Internet of Things, Centre for Development of Advanced Computing(CDAC), Bangalore, India; Department of Real time Sytems & Internet of Things, Centre for Development of Advanced Computing(CDAC), Bangalore, India; Department of Real time Sytems & Internet of Things, Centre for Development of Advanced Computing(CDAC), Bangalore, India","2018 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS)","9 May 2019","2018","","","1","6","The world has witnessed a significant change in the learning methodology by students in the last decade. With drastic technological developments in the education domain, the learning methods used by students have also evolved. The learning methods changed from, traditional classroom learning to e-learning, from e-learning to mlearning and subsequently to a new way of learning using Augmented Reality. Augmented Reality really helps in making the learning very effective and interesting in real time. It also helps in understanding some of the complex subjects in a very lucid and intuitive way. This paper discusses about an Augmented Reality learning ecosystem, which consists of Augmented Reality(AR) Learning framework and AR applications for learning environment. The implementation and benefits of Augmented Reality applications targeted for education community, namely AR Board, AR Book and AR Game are discussed.","2153-1684","978-1-5386-8134-3","10.1109/ANTS.2018.8710093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710093","Augmented Reality;education technology;Augmented Reality Board;Augmented Reality Book;Augmented Reality Game;Computer vision applications;advanced learning;virtual board;mobile learning","Augmented reality;Education;Ecosystems;Games;Real-time systems;Mobile handsets;Internet of Things","augmented reality;computer aided instruction","learning environment;classroom learning;augmented reality learning ecosystem;education domain;AR game;AR book;AR board;AR learning framework","","","","11","IEEE","9 May 2019","","","IEEE","IEEE Conferences"
"An Augmented Reality Setup with an Omnidirectional Camera Based on Multiple Object Detection","T. Hayashi; H. Uchiyama; J. Pilet; H. Saito","Keio University, Yokohama, Japan; Keio University, Yokohama, Japan; Keio University, Yokohama, Japan; Keio University, Yokohama, Japan","2010 20th International Conference on Pattern Recognition","7 Oct 2010","2010","","","3171","3174","We propose a novel augmented reality (AR) setup with an omni directional camera on a table top display. The table acts as a mirror on which real playing cards appear augmented with virtual elements. The omni directional camera captures and recognizes its surrounding based on a feature based image retrieval approach which achieves fast and scalable registration. It allows our system to superimpose virtual visual effects to the omni directional camera image. In our AR card game, users sit around a table top display and show a card to the other players. The system recognizes it and augments it with virtual elements in the omni directional image acting as a mirror. While playing the game, the users can interact with each other directly and through the display. Our setup is a new, simple, and natural approach to augmented reality. It opens new doors to traditional card games.","1051-4651","978-1-4244-7541-4","10.1109/ICPR.2010.776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597181","augumented reality;multiple object detection;bag-of-features;omnidirectional camera","Cameras;Games;Augmented reality;Image retrieval;Mirrors;Visualization","augmented reality;computer games;image registration;image retrieval;object detection","augmented reality;omnidirectional camera;multiple object detection;image retrieval approach;scalable registration;superimpose virtual visual effect;AR card game","","4","","17","IEEE","7 Oct 2010","","","IEEE","IEEE Conferences"
"[POSTER] RGB-D/C-arm Calibration and Application in Medical Augmented Reality","X. Wang; S. Habert; M. Ma; C. -H. Huang; P. Fallavollita; N. Navab","Beihang University, Technische Universität München; Technische Universität München; Technische Universität München; Technische Universität München; Technische Universität München; Technische Universität München, John Hopkins University","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","100","103","Calibration and registration are the first steps for augmented reality and mixed reality applications. In the medical field, the calibration between an RGB-D camera and a mobile C-arm fluoroscope is a new topic which introduces challenges. In this paper, we propose a precise 3D/2D calibration method to achieve a video augmented fluoroscope. With the design of a suitable calibration phantom for RGB-D/C-arm calibration, we calculate the projection matrix from the depth camera coordinates to the X-ray image. Through a comparison experiment by combining different steps leading to the calibration, we evaluate the effect of every step of our calibration process. Results demonstrated that we obtain a calibration RMS error of 0.54±1.40 mm which is promising for surgical applications. We conclude this paper by showcasing two clinical applications. One is a markerless registration application, the other is an RGB-D camera augmented mobile C-arm visualization.","","978-1-4673-7660-0","10.1109/ISMAR.2015.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328071","","X-ray imaging;Calibration;Three-dimensional displays;Cameras;Sensors;Biomedical imaging;Distortion","augmented reality;diagnostic radiography;image colour analysis;image registration;medical image processing;surgery","RGB-D/C-arm calibration;medical augmented reality;mixed reality application;RGB-D camera;red-green-blue-depth camera;mobile C-arm fluoroscope;3D-2D calibration method;video augmented fluoroscope;X-ray image;surgical application;markerless registration application","","3","","18","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"As-built Industrial Scene Reconstruction based on Photogrammetry and Prior-Knowledge for Extended Reality Scenarios","L. Rudolph; G. Klinker","Department of Informatics, Technical University of Munich; Department of Informatics, Technical University of Munich","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","480","482","This paper proposes approaches for reconstructing a scene in the process industries based on photogrammetry. The focus is on preprocessing steps making the model available as a virtual scene for several tasks in maintenance like off-site maintenance planning or revamping. For this purpose, it proposes a pipeline built upon current methods of photogrammetry, change-detection in scene reconstructions, and prior-knowledge-based meshing and segmentation methods. Then it outlines the evaluation process. Finally, it discusses future research directions and possible issues of the concept.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00113","Ministry of Economic Affairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585884","Mixed / augmented reality;Reconstruction","Industries;Extended reality;Pipelines;Maintenance engineering;Planning;Task analysis;Augmented reality","image reconstruction;image segmentation;maintenance engineering;photogrammetry;production engineering computing;virtual reality","industrial scene reconstruction;photogrammetry;extended reality scenarios;virtual scene;off-site maintenance planning;change-detection;prior-knowledge-based meshing;segmentation methods","","","","9","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Integration of Virtual Reality and Augmented Reality for Immersive Gaming and Learning","S. Tripathi","Amity University, Amity Institute Of Information Technology, Noida, Uttar Pradesh","2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC)","3 Feb 2020","2019","","","63","66","Augmented reality and Virtual reality provide two different types of immersive gaming and learning experience, by integrating the two together we can enhance both the gaming and learning experience separately. Integration is the act of combining small components into a unified system that works as one. In terms of Information Technology, it means adding features of one technology to another. This paper proposes a new hardware which will use existing hardware called a head mounted display (HMD) with a dual camera on the front along with a various array of sensors to integrate Virtual Reality and Augmented Reality. This method of using traditional Hardware will be a more cost effective solution when compared to other Head mounted display currently available. a Virtual Reality is a 3D interactive stimulation of an environment. It requires a wearable display to work. Whereas augmented reality is a superimposed Computer-generated image on a view of actual word. Combining the two together can result is a more immersive augmented reality experience which will help in learning and an enhanced gaming experience.","","978-1-7281-1793-5","10.1109/PEEIC47157.2019.8976608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8976608","Virtual Reality;Augmented Reality","","augmented reality;computer aided instruction;computer games;helmet mounted displays;sensor fusion","virtual reality;immersive augmented reality experience;immersive gaming experience;head mounted display;immersive learning experience;information technology;dual camera;sensor array;3D interactive stimulation;e-learning;proximity sensor;brightness sensor","","1","","12","IEEE","3 Feb 2020","","","IEEE","IEEE Conferences"
"Pokemon Fight Augmented Reality Game","A. Karkera; S. Dhadse; V. Gawde; K. Jain","Xavier Institute Of Engineering, Mumbai University, Mumbai, India; Xavier Institute Of Engineering, Mumbai University, Mumbai, India; Xavier Institute Of Engineering, Mumbai University, Mumbai, India; Department of Computer Engineering, Mumbai University, Mumbai, India","2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)","27 Sep 2018","2018","","","1762","1764","Earlier small children used to collect various types of cards such as Pokemon cards, cartoon cards, WWF cards etc. Also, they used to play against each other depending on the power, health, etc. factors mentioned on the card. With the rise of augmented reality technology, it is possible to bring the 3D objects in the real world. So what if we use the same concept on the cards & bring those virtual Pokemon, cartoon characters in the real world & play with them by controlling them ourselves. In this paper, we are presenting the game Pokemon Fight which unites the virtual & real world to make the game more realistic as well as interesting for the player. The augmented reality applications are not only limited to the gaming but it can also be used in the educational field, marketing the product, etc.","","978-1-5386-1974-2","10.1109/ICICCT.2018.8473108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8473108","augumented reality;mobile game;Pokemon fight;trading card","Games;Augmented reality;Three-dimensional displays;Conferences;Cameras;Visualization;Entertainment industry","augmented reality;computer games","Pokemon cards;cartoon cards;WWF cards;augmented reality technology;augumented reality game;3D objects;cartoon characters;educational field;product marketing;Pokemon fight","","2","","11","IEEE","27 Sep 2018","","","IEEE","IEEE Conferences"
"Comparing principally imagination and interaction versions of a play anywhere mobile AR location-based story","G. Raeburn; L. Tokarchuk","Queen Mary, University of London; Queen Mary, University of London","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","616","617","Augmented Reality (AR) allows virtual elements to be overlaid on the real world, providing new opportunities for location-based storytelling, by offering blended environments to more closely resemble those in a story. However, there is limited research considering how different interaction opportunities with such augmented surroundings, affect user engagement and immersion in such a story. A mobile AR app, Map Story 2, was developed to investigate this, offering a guided story-walk around a user's chosen location, either interacting with overlaid virtual objects to progress the story, or being asked to imagine the same events playing out at each augmented location.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757656","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality","Three-dimensional displays;Conferences;User interfaces;Augmented reality","augmented reality;computer aided instruction;computer displays;interactive systems;mobile computing;virtual reality","imagination;interaction versions;play anywhere mobile;location-based story;Augmented Reality;virtual elements;location-based storytelling;blended environments;different interaction opportunities;augmented surroundings;user engagement;mobile AR app;Map Story 2;guided story-walk;overlaid virtual objects;augmented location","","","","12","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality Systems for Renal Interventions: A Systematic Review","F. J. Detmer; J. Hettig; D. Schindele; M. Schostak; C. Hansen","Department of Bioengineering, George Mason University, Fairfax, VA, USA; Institute for Simulation and Graphics, Department of Computer Science, Otto-von-Guericke University, Magdeburg, Germany; Clinic of Urology and Pediatric Urology, University Hospital of Magdeburg, Magdeburg, Germany; Clinic of Urology and Pediatric Urology, University Hospital of Magdeburg, Magdeburg, Germany; Institute for Simulation and Graphics, Department of Computer Science, Otto-von-Guericke University, Magdeburg, Germany","IEEE Reviews in Biomedical Engineering","29 Dec 2017","2017","10","","78","94","Purpose: Many virtual and augmented reality systems have been proposed to support renal interventions. This paper reviews such systems employed in the treatment of renal cell carcinoma and renal stones. Methods: A systematic literature search was performed. Inclusion criteria were virtual and augmented reality systems for radical or partial nephrectomy and renal stone treatment, excluding systems solely developed or evaluated for training purposes. Results: In total, 52 research papers were identified and analyzed. Most of the identified literature (87%) deals with systems for renal cell carcinoma treatment. About 44% of the systems have already been employed in clinical practice, but only 20% in studies with ten or more patients. Main challenges remaining for future research include the consideration of organ movement and deformation, human factor issues, and the conduction of large clinical studies. Conclusion: Augmented and virtual reality systems have the potential to improve safety and outcomes of renal interventions. In the last ten years, many technical advances have led to more sophisticated systems, which are already applied in clinical practice. Further research is required to cope with current limitations of virtual and augmented reality assistance in clinical environments.","1941-1189","","10.1109/RBME.2017.2749527","German Research Foundation (DFG)(grant numbers:HA 7819/1-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8026164","Augmented reality;image-guided surgery;nephrectomy;renal interventions;virtual reality","Tumors;Kidney;Augmented reality;Solid modeling;Minimally invasive surgery;Laparoscopes;VIrtual reality;Surgery;Biomedical image processing","augmented reality;biological organs;biomechanics;cellular biophysics;deformation;medical computing;patient treatment;reviews","virtual reality systems;augmented reality systems;renal interventions;reviews;radical nephrectomy;partial nephrectomy;renal stone treatment;renal cell carcinoma treatment;organ movement;organ deformation;human factor;clinical environments","Humans;Image Processing, Computer-Assisted;Kidney;Virtual Reality","31","","107","IEEE","6 Sep 2017","","","IEEE","IEEE Journals"
"Interactions and systems for augmenting a live dance performance","A. Clay; N. Couture; L. Nigay; J. -B. de la Rivière; J. -C. Martin; M. Courgeon; M. Desainte-Catherine; E. Orvain; V. Girondel; G. Domengero","ESTIA, France; LaBRI; LIG, France; IMMERSION, France; LIMSI CNRS, France; LIMSI CNRS, France; LaBRI, France; IMMERSION, France; GIPSA-LAB, France; Malandain Ballet Biarritz, France","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","29","38","The context of this work is to develop, adapt and integrate augmented reality related tools to enhance the emotion involved in cultural performances. Part of the work was dedicated to augmenting a stage in a live performance, with dance as an application case. In this paper, we present a milestone of this work, an augmented dance show that brings together several tools and technologies that were developed over the project's lifetime. This is the result of mixing an artistic process with scientific research and development. This augmented show brings to stage issues from the research fields of Human-Machine Interaction (HMI) and Augmented Reality (AR). Virtual elements are added on stage (visual and audio) and the dancer is able to interact with them in real-time, using different interaction techniques. The originality of this work is threefold. Firstly, we propose a set of movement-based interaction techniques that can be used independently on stage or in another context. In this set, some techniques are direct, while others go through a high level of abstraction. Namely, we performed movement-based emotion recognition on the dancer, and used the recognized emotions to generate emotional music pieces and emotional poses for a humanoid robot. Secondly, those interaction techniques rely on various interconnected systems that can be reassembled. We hence propose an integrated, interactive system for augmenting a live performance, a context where system failure is not tolerated. The final system can be adapted following the artist's preferences. Finally, those systems were validated through an on field experiment - the show itself - after which we gathered and analyzed the feedback from both the audience and the choreographer.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483986","Augmented reality;augmented dance;emotion recognition;interaction for performing arts","Emotion recognition;Augmented reality;Robots;Real-time systems;Software;Context;Tracking","augmented reality;emotion recognition;humanities;humanoid robots;human-robot interaction","live dance performance augmentation;augmented reality related tools;emotion enhancement;cultural performances;augmented dance show;artistic process;scientific research and development;human-machine interaction;HMI;augmented reality;AR;virtual elements;movement-based interaction techniques;movement-based emotion recognition;emotional music pieces;emotional poses;humanoid robot;choreographer feedback analysis;audience feedback analysis","","13","","40","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Augmented reality camera tracking with homographies","S. J. D. Prince; Ke Xu; A. D. Cheok","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore","IEEE Computer Graphics and Applications","10 Dec 2002","2002","22","6","39","45","To realistically integrate 3D graphics into an unprepared environment, camera position must be estimated by tracking natural image features. We apply our technique to cases where feature positions in adjacent frames of an image sequence are related by a homography, or projective transformation. We describe this transformation's computation and demonstrate several applications. First, we use an augmented notice board to explain how a homography, between two images of a planar scene, completely determines the relative camera positions. Second, we show that the homography can also recover pure camera rotations, and we use this to develop an outdoor AR tracking system. Third, we use the system to measure head rotation and form a simple low-cost virtual reality (VR) tracking solution.","1558-1756","","10.1109/MCG.2002.1046627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1046627","","Augmented reality;Cameras;Layout;Transmission line matrix methods;Application software;Motion estimation;Virtual reality;Video sequences;Robustness;Prototypes","augmented reality;optical tracking;stereo image processing","augmented reality camera tracking;homography;image sequence;feature positions;projective transformation;augmented notice board;planar scene;relative camera positions;pure camera rotation recovery;outdoor augmented reality tracking system;head rotation measurement;low-cost virtual reality tracking solution","","41","8","12","IEEE","10 Dec 2002","","","IEEE","IEEE Magazines"
"Roadmap to Create an Augmented Reality Application","C. Y. F. Panizo","Systems Engineer, Universidad Nacional de Ingenieria, Lima, Peru","2022 8th International Conference on Virtual Reality (ICVR)","18 Aug 2022","2022","","","116","125","Augmented Reality (AR) combines real and virtual objects and makes them coexist in the same space, which highlights reality. This characteristic makes the creation of Augmented Reality applications attractive in several industries, such as medicine, education, entertainment, and so on. With this heyday of Augmented Reality, it is imperative to know what is required to create Augmented Reality applications. This paper explains what Augmented Reality is, defines the tools necessary to create an Augmented Reality application, and presents a software selection methodology. This paper stated that four tools are required to create an Augmented Reality application. First, the Integration tool manages the integration of all the tools. Second, the Virtual Object tool handles the creation of virtual objects. Third, the Coding tool allows to write code, locate its errors, and compile the code. Finally, the fourth tool is the Development tool, which provides functions that other tools do not offer, such as marker recognition. Although four tools are required to create an Augmented Reality application, this does not mean that four software should be used, it may be more or less. The amount of software to use in creating an application is a unique number for each project.","2331-9569","978-1-6654-7911-0","10.1109/ICVR55215.2022.9847782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9847782","augmented reality;augmented reality tools;software selection","Codes;Education;Entertainment industry;Writing;Software;Encoding;Augmented reality","augmented reality;software selection;software tools","marker recognition;development tool;coding tool;virtual object tool;integration tool;software selection method;real object;augmented reality application","","","","24","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"VirtualWorx™: Transforming Maintenance Concepts through Augmented Reality Collaboration Capabilities","R. Nepal; R. J. Pavlovich; C. E. Guilherme",Raytheon Missiles and Defense; Raytheon Missiles and Defense; Raytheon Missiles and Defense,"2023 Annual Reliability and Maintainability Symposium (RAMS)","5 Apr 2023","2023","","","1","5","SUMMARY & CONCLUSIONSVirtualWorx™ began as a 2015 Raytheon Six Sigma process improvement project to solve challenges faced by customers who were being asked to ""do more with less"" such that Operations & Sustainment (O&S) costs became a significant aspect in the planning and awarding of new systems, as well as for upgrades to existing systems. This raised the need to investigate opportunities that reduced O&S costs, which spanned the spectrum from technology-enabled maintenance operations to autonomy and analytics. VirtualWorx™ focused on the former and in particular, the process of flying technicians to international field sites to solve challenging troubleshooting and repair issues that were beyond the capabilities of the local maintainers but would have broader implications affecting product maintainability.The opportunity focused on business process improvement through the insertion of technology to better leverage global human resources and extend the significant breadth and depth of engineering expertise from Raytheon Centers of Excellence. This would allow support of deployed systems anywhere in the world through secure two-way audio & video communication up to and including augmented reality-based interactive remote collaboration. Figure 1 depicts the brainstorming session that resulted in a ""back-of-the-napkin"" design.The vision was to provide a secure enterprise, technical collaboration solution by implementing augmented reality-based communication capability to improve operational availability (Ao) of a system to perform its mission, reduce overall sustainment costs (including significant reduction in program travel), and provide effective troubleshooting of systems under repair.The proposed strategy prioritized customer driven use cases and network architecture development to:•Establish scalable Outside Contiguous United State (OCONUS) reach-back connectivity for technical support between a remote user and subject matter expert over a secure infrastructure worldwide•Facilitate technical support via a common environment using Augmented Reality (AR) capabilities over existing company network infrastructure•Enable the spectrum of collaboration across the enterprise to reduce staffing costs, leverage technical expertise, and provide improved Efficiency, Effectiveness, Capacity, and Capability (E2C2).With a strong business case, a successful proof-of-concept phase gained support from senior leadership in engineering and digital technology and earned further investment through Raytheon Independent Research and Development (IRAD) funding to move the project forward into a pilot phase for the first use case - remotely supported maintenance.To date, VirtualWorx™ has been successfully piloted and deployed on various internal and customer programs handling a variety of data and communication-rich exchanges that span the entire development life cycle.Underneath the system’s hardware and Raytheon Technologies’ global network infrastructure, VirtualWorx™ is powered by Librestream’s Onsite software platform that provides responsive technical support throughout the product life cycle allowing the emerging workforce to respond in a way employees feel most comfortable—via video.VirtualWorx™ has become a Raytheon Technologies Enterprise solution for end-to-end augmented reality collaboration specifically tailored to support remote maintenance of aerospace and defense repairable assets. The on-premises solution carries export controlled technical data and delivers live reach-back support over an increasing variety of use cases since the initial proof-of-concept—to support maintenance and repair of deployed systems around the world. It streams AR-enhanced live audio & video between field service engineers, subject matter experts, domestic and international business partners and is accessible anywhere on the company’s global network and through virtual private networking (VPN) access from off-site locations.Return on investment (ROI) has been realized from the initial remote maintenance use case to broader applications of the technology to resolve both internal and external challenges. Many of these recent challenges were especially brought on by recent COVID pandemic conditions that restricted global travel, limited face-to-face communication, and prevented movement of personnel as sites were locked-down due to COVID exposure concerns.","2577-0993","978-1-6654-6053-8","10.1109/RAMS51473.2023.10088179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10088179","Advanced Visualization;Augmented Reality Remote Collaboration;Technical Support;Operations & Sustainment","COVID-19;Costs;Collaboration;Maintenance engineering;Streaming media;Software;Virtual private networks","augmented reality;groupware;human resource management;maintenance engineering;personnel;six sigma (quality);video communication;virtual private networks","2015 Raytheon six sigma process improvement project;AR;augmented reality collaboration capabilities;augmented reality-based communication capability;augmented reality-based interactive remote collaboration;back-of-the-napkin design;business process improvement;company network infrastructure;domestic business partners;E2C2;end-to-end augmented reality collaboration;engineering expertise;export controlled technical data;field service engineers;global human resources;global network infrastructure;international business partners;international field sites;maintenance concepts transformation;network architecture development;OCONUS;outside contiguous United State reach-back connectivity;proof-of-concept phase gained support;Raytheon technologies enterprise solution;remote user;ROI;technical collaboration solution;technology-enabled maintenance operations;video communication;virtual private networking access;VirtualWorx™;VPN","","","","3","IEEE","5 Apr 2023","","","IEEE","IEEE Conferences"
"The Prospect for the Application of the Surgical Navigation System Based on Artificial Intelligence and Augmented Reality","Y. Liu; P. Tang","University of Montpellier, Montpellier, France; Shanghai Lin Yan Medical Technology Co., Ltd., Shanghai, China","2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","17 Jan 2019","2018","","","244","246","With the development of the artificial intelligence, the artificial intelligence technology is gradually applied to medicine to assist the doctors for disease diagnosis and surgery, which promotes the rapid development of the precision medicine. In this paper, the surgical system based on the artificial intelligence and the augmented reality is explored. In the future, the surgery system based on the artificial and augmented reality will intelligently assist doctors to perform the operation and achieve the goal of the minimally invasive surgery.","","978-1-5386-9269-1","10.1109/AIVR.2018.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613675","artificial intelligence;augmented reality;surgical navigation system;minimally invasive surgery","Surgery;Navigation;Medical diagnostic imaging;Artificial intelligence;Diseases","artificial intelligence;augmented reality;diseases;patient diagnosis;surgery","surgical navigation system;augmented reality;artificial intelligence technology;disease diagnosis;surgical system;surgery system;artificial reality","","8","","14","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"A Teaching Kinematics: Augmented Reality and Virtualization in the Observation","A. Arcella; E. Balzano; S. Cavaliere; R. Iura","Department of Physical Sciences, Complesso Universitario MSA, Napoli, Italy; Department of Physical Sciences, Complesso Universitario MSA, Napoli, Italy; Department of Physical Sciences, Complesso Universitario MSA, Napoli, Italy; Department of Physical Sciences, Complesso Universitario MSA, Napoli, Italy","2008 International Conference on Computer Science and Software Engineering","22 Dec 2008","2008","5","","929","932","Our paper reports on an ongoing experiment aiming to use broadly principles and methods from virtual reality and augmented reality for didactical purposes. The specific field in which these methodologies have been proposed, studied and implemented, at a first stage, is in teaching physics, in particular, kinematics. Key idea is that of providing the observer, an elementary school student, with real time information on the kinematics of some moving object on which experiments are being carried on. This real time information will be provided by using the methods of augmented reality, that is mixing images from the real world with synthetic data; this is done just adding to the moving objects computer generated images for velocities and accelerations; thus the user may watch to a physical experiment by means of a webcam: on the computer screen he will see real bodies and superimposed to these relevant graphical annotations, mainly vectors for velocities; also virtualization is achieved by means of sonification of the events; sounds controlled by speed, varying speed (acceleration), crashes and similar are superimposed to the real scene in order to provide evidence of the events by means of augmented perception, using in this case, the acoustical channel for communicating events and parameters of the environment.","","978-0-7695-3336-0","10.1109/CSSE.2008.1625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4723057","","Education;Kinematics;Augmented reality;Physics computing;Acceleration;Virtual reality;Educational institutions;Image generation;Watches;Velocity control","augmented reality;computer aided instruction;kinematics;physics computing;physics education","kinematics;augmented reality;virtual reality;physics education;augmented perception;acoustical channel;didactical purpose","","3","","9","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"Collaborative Augmented Reality Ping-Pong Via Markerless Real Rackets","Y. Yan; X. Chen; X. Li","State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Technology, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Technology, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Technology, Beihang University, Beijing, China","2011 International Conference on Virtual Reality and Visualization","1 Dec 2011","2011","","","136","143","This article proposes a method of constructing a ping-pong system via markerless real rackets in collaborative augmented reality. Except a pair of video cameras, without any other sensors or artificial markers, users can use real rackets to hit virtual ping-pong ball on a virtual table and interact with remote partners in augmented reality scene just as they were playing ping-pong in the same place. First, the real racket can be detected and tracked in real-time in the video captured by a single camera in each site. By 3D registration, the real racket can seamlessly interact with the virtual ping-pong ball and table. Then, a communication scheme is designed for the consistent perception between users in collaborative augmented reality ping-pong system. To achieve real-time interaction, the whole method is implemented in a parallel computing environment through multi-core processors. Experimental results demonstrate that our system can provide consistent perception and natural user interaction with low latency and high precision.","","978-1-4577-2156-4","10.1109/ICVRV.2011.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6092704","collaborative augmented reality;ping-pong;real racket;real-time","Three dimensional displays;Augmented reality;Cameras;Real time systems;Collaboration;Streaming media;Detection algorithms","augmented reality;image sensors;multiprocessing systems;parallel processing;video signal processing","collaborative augmented reality ping-pong;markerless real rackets;video cameras;artificial markers;sensor markers;3D registration;real-time interaction;parallel computing environment;multicore processors","","2","","15","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Designing real-time vision based augmented reality environments for 3D collaborative applications","Peiran Liu; N. D. Georganas; P. Boulanger","Multimedia Communication Research Laboratory, University of Ottawa, Canada; Multimedia Communication Research Laboratory, University of Ottawa, Canada; University of Alberta, Canada","IEEE CCECE2002. Canadian Conference on Electrical and Computer Engineering. Conference Proceedings (Cat. No.02CH37373)","7 Aug 2002","2002","2","","715","720 vol.2","Augmented reality (AR) is a variation of virtual reality. It allows the user to see computer generated virtual objects superimposed upon the real world through the use of some kind of see-through head-mounted display. Human users of such system can interact with the virtual world and have additional information, such as character description of physical objects and instruction for performing physical tasks in form of annotation, speech instruction, image, and 3D model. This paper describes our work of building a wireless augmented reality prototype, which supports video-based 3D graphics and a keyboard interface over wearable computers to interact with virtual objects. A new technique for identifying real world objects and estimating their coordinate systems is introduced. The method utilizes a binary square marker, which can identify a great number of real world objects with markers tagged on them by using computer vision techniques.","0840-7789","0-7803-7514-9","10.1109/CCECE.2002.1013029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1013029","","Augmented reality;Collaboration;Computer displays;Object recognition;Application software;Virtual reality;Humans;Speech;Virtual prototyping;Computer graphics","computer vision;augmented reality;real-time systems;portable computers","real-time vision-based augmented reality environment design;3D collaborative applications;AR;virtual reality;computer generated virtual objects;see-through headmounted display;character description;physical objects;physical task instruction;annotation;speech instruction;image;3D model;wireless augmented reality prototype;video-based 3D graphics;keyboard interface;wearable computers;real world objects;coordinate systems;binary square marker;computer vision techniques","","1","1","14","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Augmented Reality Fitts' Law Input Comparison Between Touchpad, Pointing Gesture, and Raycast","D. M. Mifsud; A. S. Williams; F. Ortega; R. J. Teather",Colorado State University; Colorado State University; Colorado State University; Carleton University,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","590","591","With the goal of exploring the impact of transparency on selection in augmented reality (AR), we present a Fitts' law experiment with 18 participants, comparing three different input methods (finger based Pointing Gesture, controller using the Touchpad, and controller using Raycast), across 4 different target transparency levels (0%, 30%, 60%, and 90%) in an optical see-through AR head-mounted display. The results indicate that transparency has little effect on selection throughput and error rates. Overall, the Raycast input method performed significantly better than the pointing gesture and Touchpad inputs in terms of error rate and throughput in all opacity conditions.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00146","NSF(grant numbers:2106590,2016714,2037417,1948254); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757658","Human-centered computing—Human computer interaction (HCI)—Interaction techniques—Pointing;Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality","Three-dimensional displays;Head-mounted displays;Error analysis;Conferences;Fingers;User interfaces;Throughput","augmented reality;gesture recognition;helmet mounted displays;virtual reality","augmented reality Fitts' law input comparison;pointing gesture;Fitts' law experiment;different input methods;Touchpad,;4 different target transparency levels;AR head-mounted display;selection throughput;error rates;Raycast input method;Touchpad inputs","","","","5","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"[DC] Annotation in Asynchronous Collaborative Immersive Analytic Environments using Augmented Reality","Z. Borhani",Colorado State University,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","950","951","Immersive Analytics (IA) and Augmented Reality (AR) head-mounted displays provide a different paradigm for people to analyze multidimensional data and externalize their thoughts by utilizing the stereoscopic nature of headsets. However, using annotation in IA-AR is challenging and not well-understood. In addition, IA collaborative environments add another complexity level for users operating on complex visualized datasets. Current AR systems focus mainly on synchronized collaboration, while asynchronous collaboration has remained unexplored. This project investigates annotation in IA for asynchronous collaborative environments. We present our research studies on virtual annotation types and introduce a new filtering annotation technique for IA.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757653","Annotation;Immersive Analytics;Collaborative Augmented Reality;Asynchronous Collaboration","Headphones;Three-dimensional displays;Annotations;Conferences;Stereo image processing;Collaboration;Data visualization","augmented reality;data visualisation;groupware;helmet mounted displays;interactive systems;virtual reality","asynchronous collaborative environments;virtual annotation types;filtering annotation technique;[DC] annotation;asynchronous collaborative immersive analytic environments;augmented reality;Immersive Analytics;head-mounted displays;different paradigm;multidimensional data;IA-AR;IA collaborative environments;complexity level;complex visualized datasets;synchronized collaboration;asynchronous collaboration","","","","13","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Interference avoidance in multi-user hand-held augmented reality","O. Oda; S. Feiner","Columbia University, USA; Columbia University, USA","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","13","22","In a multi-user augmented reality application for a shared physical environment, it is possible for users to interfere with each other. For example, in a multi-player game in which each player holds a display whose tracked position and orientation affect the outcome, one player may physically block another player's view or physically contact another player. We explore software techniques intended to avoid such interference. These techniques modify what a user sees or hears, and what interaction capabilities they have, when their display gets too close to another user's display. We present Redirected Motion, an effective, yet nondistracting, interference avoidance technique for hand-held AR, which transforms the 3D space in which the user moves their display, to direct the display away from other displays. We conducted a within-subject, formal user study to evaluate the effectiveness and distraction level of Redirected Motion compared to other interference avoidance techniques. The study is based on an instrumented, two-player, first-person-shooter, augmented reality game, in which each player holds a 6DOF-tracked ultra-mobile computer. Comparison conditions include an unmanipulated control condition and three other software techniques for avoiding interference: dimming the display, playing disturbing sounds, and disabling interaction capabilities. Subjective evaluation indicates that Redirected Motion was unnoticeable, and quantitative analysis shows that the mean distance between users during Redirected Motion was significantly larger than for the comparison conditions.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336507","Collaborative/competitive augmented reality;computer games;interference avoidance;computer-supported cooperative play/work (CSCP/CSCW)","Interference;Augmented reality;Collaborative work;Three dimensional displays;Computer displays;Solid modeling;Motion analysis;Computer interfaces;Visualization;Instruments","augmented reality;computer displays;computer games;groupware;mobile computing","interference avoidance;multiuser hand-held augmented reality;shared physical environment;multiplayer game;position tracking;orientation tracking;software technique;interaction capability;user display;redirected motion;3D space;instrumented two-player first-person-shooter;augmented reality game;ultramobile computer;unmanipulated control condition;display dimming;disturbing sounds","","7","1","44","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"AR Circuit Constructor: Combining Electricity Building Blocks and Augmented Reality for Analogy-Driven Learning and Experimentation","T. Kreienbühl; R. Wetzel; N. Burgess; A. Maria Schmid; D. Brovelli",Lucerne University of Applied Sciences and Arts; Lucerne University of Applied Sciences and Arts; Lucerne University of Applied Sciences and Arts; University of Teacher Education Lucerne; University of Teacher Education Lucerne,"2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","13","18","We present AR Circuit Constructor (ARCC), an augmented reality application to explore and inspect electric circuits for use in educational settings. Learners use tangible electricity building blocks to construct a working electric circuit. Then, they can use a tablet device for exploring the circuit in an augmented reality visualization. Learners can switch between three distinct conceptual analogies: bicycle chain, water pipes, and waterfalls. Through experimentation with different circuit configurations, learners explore different properties of electricity to ultimately improve their understanding of it. We describe the development of our application, including a qualitative user study with a group of STEM teachers. The latter allowed us to gain insights into the qualities required for such an application before it can ultimately be deployed in a classroom setting.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287826","Augmented reality;learning;electricity;electric circuits;tangible user interfaces;human-computer interaction","Human computer interaction;Visualization;Switches;Bicycles;Augmented reality","augmented reality;bicycles;computer aided instruction;data visualisation;electrical engineering computing;electrical engineering education","tangible electricity building blocks;working electric circuit;tablet device;augmented reality visualization;distinct conceptual analogies;circuit configurations;AR Circuit Constructor;augmented reality application;electric circuits;educational settings;bicycle chain;water pipes;waterfalls;STEM teachers;analogy-driven learning","","4","","21","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"The Ghosting Technique Applied to Augmented Reality Visualization","A. Padilha; C. Rolim; V. Teichrieb","Voxar Labs Centro de Informática-UFPE, Recife, Brasil; Voxar Labs Centro de Informática-UFPE, Recife, Brasil; Voxar Labs Centro de Informática-UFPE, Recife, Brasil","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","159","166","Functional realism focuses on delivering to the user the best visual information from the target scene. The virtual scenes/objects do not need to behave or look like the real ones, but they need to help users in tasks execution. In this sense, this paper focuses on functional realism applied to Augmented Reality scenes. The technique presented here applies a visualization technique called Ghosting to generate an importance map from the real scene in order to blend in the virtual objects in a more adequate way. A careless augmentation can prejudice the user Augmented Reality based experience. The importance map is built from a saliency map, edge detection, super pixel representation and texture analysis. We present results in outdoor and indoor environments in order to prove the technique effectiveness.","","978-0-7695-5001-5","10.1109/SVR.2013.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655774","Augmented Reality;Ghosting Technique;Visualization;Transparency;Saliency Map","Visualization;Image segmentation;Augmented reality;Pipelines;Art;Abstracts;Image edge detection","augmented reality;data visualisation;edge detection;image representation;image texture;natural scenes","ghosting technique;augmented reality scene visualization;visual information;target scene;virtual scenes;functional realism;importance map generation;real scene;virtual objects;user augmented reality-based experience;saliency map;edge detection;superpixel representation;texture analysis;outdoor environments;indoor environments","","4","","22","IEEE","7 Nov 2013","","","IEEE","IEEE Conferences"
"ARkanoidAR: An Augmented Reality System to Guide Biomechanical Movements at Sagittal Plane","R. R. Barioni; T. M. Chaves; L. Figueiredo; V. Teichrieb; E. V. Neto; A. E. F. Da Gama","Voxar Labs, Informatics Center, UFPE, Recife, Brazil; Voxar Labs, Informatics Center, UFPE, Recife, Brazil; Voxar Labs, Informatics Center, UFPE, Recife, Brazil; Voxar Labs, Informatics Center, UFPE, Recife, Brazil; Voxar Labs, Informatics Center, UFPE, Recife, Brazil; Biomedical Engineering Department, Voxar Labs, Informatics Center, Universidade Federal de Pernambuco, Recife, PE, BR","2017 19th Symposium on Virtual and Augmented Reality (SVR)","20 Nov 2017","2017","","","207","214","In motor rehabilitation, the search for better methodologies is intense. In parallel, natural interaction technologies are considered to be a nice approach for rehabilitation guidance, as they can provide content for visual feedback in augmented reality. This paper describes an augmented reality physiotherapy rehabilitation system called ARkanoidAR, which was implemented using the Microsoft Kinect and whose main focus is to provide feedback for biomechanical movements, more specifically those which occurs on the sagittal plane. The main objective of this paper is to propose the ARkanoidAR and evaluate its usability in the rehabilitation context. We conceived and applied a usability quiz, and its results obtained shows that the application is efficient in guiding and engaging users to do motor rehabilitation exercises and that it is easy to be set up and handled.","","978-1-5386-3588-9","10.1109/SVR.2017.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114439","augmented reality;physiotherapy;rehabilitation","Games;Visualization;Augmented reality;Biomechanics;Informatics;Real-time systems;Elbow","augmented reality;biomechanics;medical computing;patient rehabilitation;patient treatment","augmented reality system;biomechanical movements;sagittal plane;natural interaction technologies;rehabilitation guidance;visual feedback;augmented reality physiotherapy rehabilitation system;motor rehabilitation exercises;ARkanoidAR system;Microsoft Kinect","","3","","23","IEEE","20 Nov 2017","","","IEEE","IEEE Conferences"
"Augmented and Virtual Reality in Education: The Role of Brazilian Research Groups","A. C. M Queiroz; R. Tori; A. M. Nascimento; M. I. d. S. Leme","Instituto de Psicologia, Universidade de São Paulo, São Paulo, Brasil; Escola Politécnica, Universidade de São Paulo, São Paulo, Brasil; Inst de Ciências e Tecnologia, Universidade Federal de São Paulo, Sao José dos Campos, Brasil; Instituto de Psicologia, Universidade de São Paulo, São Paulo, Brasil","2018 20th Symposium on Virtual and Augmented Reality (SVR)","19 Aug 2019","2018","","","170","175","Virtual Reality (VR) and Augmented Reality (AR) technologies have become quite popular and affordable. Given their potential as teaching tools, their increasing introduction into both traditional and virtual classrooms is natural. The mapping of Brazilian research groups that investigate VR, AR and Education can contribute to the identification of gaps, overlaps and opportunities as well as aid pedagogical and public policy planning. This article presents a study that analyzes CNPq Research Group's Directory with a focus on VR and AR lines of research that also involve education as theme. Evidences that inspire future works are identified.","","978-1-7281-0604-5","10.1109/SVR.2018.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802496","virtual reality;augmented reality;education;CNPq Research Group Directory","Augmented reality;Training;Planning;Global Positioning System;Public policy","augmented reality;computer aided instruction;teaching","virtual classrooms;Brazilian research groups;public policy planning;CNPq Research Group's Directory;teaching tools;augmented reality;virtual reality;VR;AR","","2","","55","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"Augmenting a Psoriasis-patient Doctor-dialogue through Intergrating Real Face and Maps of Psoriasis Pathology","Y. Jiang; D. Weng; R. Ju","MRAD of Beijing Institute of Technology; MRAD of Beijing Institute of Technology, AICFVEof Beijing Film Academy; MRAD of Beijing Institute of Technology","2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","160","164","The severity and development of psoriasis is difficult to describe and discuss between patients and doctors. Such phenomenon mainly caused by traditional medical communication methods (language and pictures) cannot visually show the disease status and the comprehension largely depend on doctors' (variable) skills to describe the anomaly. In this paper, we propose a solution based on augmented reality (AR). Patients can see psoriasis develop on their face by making accurate and reliable psoriasis maps. Heuristic analysis and pilot testing of 24 participants demonstrated that the solution can significantly increase comprehension and promote the patient's willingness to receive medical support. We believe that AR can be an effective tool to assist the treatment of psoriasis.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951969","Augmented-reality,-psoriasis,-augmented-faces.","Face;Diseases;Mobile handsets;Skin;Pathology;Lesions","augmented reality;biomedical communication;decision making;diseases;health care;medical computing;medical image processing;medical information systems;patient treatment;skin;telemedicine","psoriasis-patient doctor-dialogue;psoriasis pathology;doctors;traditional medical communication methods;language;disease status;augmented reality;accurate psoriasis maps;reliable psoriasis maps;pilot testing","","","","9","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Can Retinal Projection Displays Improve Spatial Perception in Augmented Reality?","E. Peillard; Y. Itoh; G. Moreau; J. -M. Normand; A. Lécuyer; F. Argelaguet","École Centrale de Nantes, AAU, Inria Hybrid; Augmented Vision Lab, Tokyo Institute of Technology, Japan and RIKEN AIP, Japan; École Centrale de Nantes, AAU, Inria Hybrid; École Centrale de Nantes, AAU, Inria Hybrid; Inria, University Rennes, IRISA, CNRS; Inria, University Rennes, IRISA, CNRS","2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","80","89","Commonly used Head Mounted Displays (HMDs) in Augmented Reality (AR), namely Optical See-Through (OST) displays, suffer from a main drawback: their focal lenses can only provide a fixed focal distance. Such a limitation is suspected to be one of the main factors for distance misperception in AR. In this paper, we studied the use of an emerging new kind of AR display to tackle such perception issues: Retinal Projection Displays (RPDs). With RPDs, virtual images have no focal distance and the AR content is always in focus. We conducted the first reported experiment evaluating egocentric distance perception of observers using Retinal Projection Displays. We compared the precision and accuracy of the depth estimation between real and virtual targets, displayed by either OST HMDs or RPDs. Interestingly, our results show that RPDs provide depth estimates in AR closer to real ones compared to OST HMDs. Indeed, the use of an OST device was found to lead to an overestimation of the perceived distance by 16%, whereas the distance overestimation bias dropped to 4% with RPDs. Besides, the task was reported with the same level of difficulty and no difference in precision. As such, our results shed the first light on retinal projection displays' benefits in terms of user's perception in Augmented Reality, suggesting that RPD is a promising technology for AR applications in which an accurate distance perception is required.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284699","Perception;Distance;Augmented Reality;User Experiment;Psychophysical Study","Performance evaluation;Estimation;Resists;Retina;Optical imaging;Task analysis;Augmented reality","augmented reality;computer vision;helmet mounted displays;lenses;visual perception","virtual images;spatial perception;AR display;distance misperception;fixed focal distance;head mounted displays;retinal projection displays;egocentric distance perception;augmented reality;users perception;distance overestimation;OST HMDs;RPDs","","4","","50","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Inspiring healthy Food Choices in a Virtual Reality Supermarket by adding a tangible Dimension in the Form of an Augmented Virtuality Smartphone","C. Eichhorn; M. Lurz; D. A. Plecher; S. Weber; M. Wintergerst; B. Kaiser; S. L. Holzmann; C. Holzapfel; H. Hauner; K. Gedrich; G. Groh; M. Böhm; H. Krcmar; G. Klinker",Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich,"2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","548","549","We want to understand the changing shopping behaviour, influenced by health-targeting nutrition apps on mobile devices. To achieve that, we have built a realistic Virtual Reality (VR) supermarket simulation and addressed core aspects such as handling virtual products, prevention of cybersickness, rounded off with an initial pilot study. On top of that, we built a virtual replica smartphone in VR with nutritionrelated functionality. This has been extended with an Augmented Virtuality (AV) feature, that enables us to track the screen of a participant's own smartphone, hence allowing us to integrate real-world apps and letting the user interact with them during the simulation. To achieve a high-quality tracking, we propose a hybrid approach, utilizing an add-on RGB camera on the VR headset fused with data provided through a WLAN connection in the case of self-made apps. This enables the users to manipulate the simulation from within the smartphone app, introducing a versatile, highly usability-centered controller because they can handle their phone naturally.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419274","Virtual Reality;Augmented Virtuality;Food Choices;HCI;Behavioral Change;Virtual Supermarket","Headphones;Solid modeling;Wireless LAN;Three-dimensional displays;Augmented virtuality;Conferences;User interfaces","medical computing;mobile computing;smart phones;virtual reality;wireless LAN","real-world apps;high-quality tracking;VR headset;self-made apps;smartphone app;inspiring healthy food choices;tangible dimension;Augmented Virtuality smartphone;changing shopping behaviour;health-targeting nutrition apps;mobile devices;realistic Virtual Reality supermarket simulation;core aspects;virtual products;initial pilot study;virtual replica smartphone;Augmented Virtuality feature;participant","","1","","5","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Visual Feedback in Augmented Reality to Walk at Predefined Speed Cross-Sectional Study Including Children With Cerebral Palsy","A. -L. Guinet; G. Bouyer; S. Otmane; E. Desailly","IBISC, Université Paris-Saclay, Univ Evry, Evry-Courcouronnes, France; IBISC, Université Paris-Saclay, Univ Evry, Evry-Courcouronnes, France; IBISC, Université Paris-Saclay, Univ Evry, Evry-Courcouronnes, France; Fondation Ellen Poidatz, Pole Recherche & Innovation, Saint-Fargeau-Ponthierry, France","IEEE Transactions on Neural Systems and Rehabilitation Engineering","22 Aug 2022","2022","30","","2322","2331","In an augmented reality environment, the range of possible real-time visual feedback is extensive. This study aimed to compare the impact of six scenarios in augmented reality combining four visual feedback characteristics on achieving a target walking speed. The six scenarios have been developed for Microsoft Hololens augmented reality headset. The four feedback characteristics that we have varied were: Color; Spatial anchoring; Speed of the feedback, and Persistence. Each characteristic could have different values (for example, the color could be unicolor, bicolor, or gradient). Participants had to walk for two consecutive walking trials for each scenario: at their maximal speed and an intermediate speed. Mean speed, percentage of time spent above or around target speed, and time to reach target speed were compared between scenarios using mixed linear models. A total of 25 children with disabilities have been included. The feasibility and user experience were excellent. Mean speed during scenario 6, which displayed feedback with gradient color, attached to the world, with a speed relative to the player equal to his speed, and that disappeared over time, was significantly higher than other scenarios and control (p =0.003). Participants spent 80.98% of time above target speed during scenario 6. This scenario mixed the best combination of feedback characteristics to exceed the target walking speed (p=0.0058). Scenarios 5 and 6, which shared the same feedback characteristics for spatial anchoring (world-locked) and feedback speed (equal to the player speed), decreased the time to reach the target speed (p=0.019). Delivering multi-modal feedback has been recognized as more effective for improving motor performance. Therefore, our results showed that not all visual feedback had the same impact on performance. Further studies are required to test the weight of each feedback characteristic and their possible interactions inside each scenario. This study was registered in the ClinicalTrials.gov database (NCT04460833).","1558-0210","","10.1109/TNSRE.2022.3198243","ARRoW-CP Project through Ellen Poidatz and Association Nationale Recherche et Technologie (ANRT), in collaboration with Université Paris-Saclay, Université Evry, IBISC, équipe IRA2, Paris, France; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854877","Augmented reality;assistive technology;feedback;gait disorders;patient rehabilitation","Legged locomotion;Shape;Augmented reality;Visualization;Color;Headphones;Games","augmented reality;feedback;gait analysis;handicapped aids;medical disorders","cerebral palsy;player speed;mean speed;intermediate speed;maximal speed;consecutive walking trials;Microsoft Hololens augmented reality;target walking speed;visual feedback characteristics;real-time visual feedback;augmented reality environment;predefined speed cross-sectional study;feedback characteristic;multimodal feedback;target speed","Augmented Reality;Cerebral Palsy;Child;Cross-Sectional Studies;Feedback, Sensory;Humans;Walking","","","48","CCBY","11 Aug 2022","","","IEEE","IEEE Journals"
"Peripheral visual information and its effect on the perception of egocentric depth in virtual and augmented environments","J. A. Jones; J. E. Swan; G. Singh; S. R. Ellis","Mississippi State University, USA; Mississippi State University, USA; Mississippi State University, USA; NASA Ames Research Center, USA","2011 IEEE Virtual Reality Conference","29 Apr 2011","2011","","","215","216","A frequently observed problem in virtual environments is the underestimation of egocentric depth. This problem has been described numerous times and with widely varying degrees of severity. Though there has been considerable progress made in modifying observer behavior to compensate for these misperceptions, the question of why these errors exist is still an open issue. The study detailed in this document presents the preliminary findings of a large, between-subjects experiment (N=98) that attempts to identify and quantify the source of a pattern of adaptation and improved accuracy in the absence of explicit feedback found in Jones et al. [1].","2375-5334","978-1-4577-0038-5","10.1109/VR.2011.5759475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759475","depth perception;augmented reality;virtual reality;perceptual adaptation","Observers;Legged locomotion;Visualization;Virtual environment;Servers;Augmented reality","augmented reality","peripheral visual information;egocentric depth perception;virtual environment;augmented environment;observer behavior;adaptation pattern source","","1","","3","IEEE","29 Apr 2011","","","IEEE","IEEE Conferences"
"Impact of Augmented Reality and Virtual Reality in the Transformation of Virtual Customer Relationship Management Sector","H. R. Malik; N. A. Nawaz; M. B. Al-Zghoul","Department of Computer Science, Umm Al-Qura University, Al-Qunfida, KSA; Department of Computer Science, Umm Al-Qura University, Makkah Almukarmah, KSA; Department of Computer Science, Umm Al-Qura University, Al-Qunfida, KSA","2020 IEEE 7th International Conference on Engineering Technologies and Applied Sciences (ICETAS)","19 Jul 2021","2020","","","1","5","The integration of virtual reality and artificial intelligence into the business environment takes human-machine interaction to an advanced level. The inception of these technologies along with deep learning approaches has transformed the business environment completely, especially customer relationship management. Additionally, augmented reality has changed the business production environment with interactive designs and machines learning approaches. Augmented reality is expected to grow by $814.7B in 2025 which will bring a huge transformation in the businesses. Though leveraging technologies have been introduced to transform customer experience, with an ever-accelerating tidal wave of advancing technology, the adoption rate of these technologies in business is not satisfactory. This is because of unawareness of the experience transformation rate of augmented reality on business. Many applications related to Artificial Intelligence and Virtual Reality experience were found but no success rate was observed because of unfamiliarity with the key features to the technology. There is a need to introduce the power of technology by engaging with it. A systematic approach to identify the key aspects of augmented reality and virtual reality for the successful adoption of business in customer relationship management sector has been used for the present study. A case study of Amazon is considered to analyze the impact of the implementation of Virtual Reality on product sales.","","978-1-6654-2317-5","10.1109/ICETAS51660.2020.9484306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484306","Virtual Customer Relationship Management (V-CRM);Virtual Reality (VR);Augmented Reality (AR);Neural Learning","Deep learning;Systematics;Shape;Conferences;Customer relationship management;Transforms;Production","augmented reality;customer relationship management;customer services;human computer interaction;learning (artificial intelligence)","business production environment;experience transformation rate;Virtual Reality experience;virtual customer relationship management sector;artificial intelligence;augmented reality","","","","17","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"AR 2.0: Social Augmented Reality - social computing meets Augmented Reality","T. Hollerer; D. Schmalstieg; M. Billinghurst","University of California, Santa Barbara, USA; Technische Universität Graz, Austria; University of Canterbury, Hit Lab, New Zealand","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","229","230","","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336443","","Augmented reality;Social network services;Cameras;Large-scale systems;Australia;Lighting;Displays;Physics computing;Cellular phones;Graphics","","","","","","","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"HoloInset: 3D Biomedical Image Data Exploration through Augmented Hologram Insets","J. Choi; H. Jeong; W. -K. Jeong",UNIST; Korea University; Korea University,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","604","605","The extended reality (XR) provides realistic depth perception and huge visualization spaces, which can serve as a powerful workspace for 3D data exploration and analysis. However, a direct adaptation of XR to conventional 3D data exploration tasks is less feasible due to several hardware limitations, such as low screen resolution, dizziness, narrow field of view, etc. In this paper, we propose a novel mixed reality visualization scheme, HoloInset, which combines a conventional visual analytics system and a virtual environment to effectively explore 3D biomedi-cal image data. We also demonstrate the usability of the proposed visualization through a real-world analysis case.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00153","National Research Foundation of Korea(grant numbers:NRF-2019M3E5D2A01063819,NRF-2021R1A6A1A13044830); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757540","Human-centered computing-Human computer interaction (HCI);Interaction paradigms-Mixed / augmented reality","Three-dimensional displays;Visual analytics;Conferences;Data visualization;Mixed reality;Virtual environments;X reality","augmented reality;data analysis;data visualisation;medical image processing;virtual reality","HoloInset;3D biomedical image data exploration;augmented hologram;extended reality;XR;realistic depth perception;huge visualization spaces;powerful workspace;direct adaptation;conventional 3D data exploration tasks;hardware limitations;low screen resolution;novel mixed reality visualization scheme;conventional visual analytics system;3D biomedi-cal image data","","","","5","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"WaterHCI Part 1: Open Water Monitoring with Realtime Augmented Reality","S. Mann; F. Sadrzadeh-Afsharazar; S. Khaki; Z. Lu; C. Mann; J. Bhimani","MannLab Canada, Toronto, Ontario; MannLab Canada, Toronto, Ontario; MannLab Canada, Toronto, Ontario; MannLab Canada, Toronto, Ontario; MannLab Canada, Toronto, Ontario; MannLab Canada, Toronto, Ontario","2022 IEEE International Conference on Signal Processing, Informatics, Communication and Energy Systems (SPICES)","16 May 2022","2022","1","","49","54","This is the first of our two accepted papers in this conference so we are presenting it as Part 1 in the new and growing field known as Water-HCI or WaterHCI (Water-Human-Computer Interface/Interaction/Intersection). WaterHCI originated in the 1960s and 1970s as a form of water interaction, water monitoring, water-based augmented reality / extended reality, and the like. Much of this work began with hydraulophones (underwater musical instruments) in the 1960s and underwater Augmented Reality (AR) or eXtended Reality (XR) with the SWIM (Sequential Wave Imprinting Machine) in the 1970s. SWIM is a sensing and meta-sensing (sensing-of-sensing) tool with real-world applications in the XR visualization of otherwise invisible phenomena. In this paper, SWIM is applied to understanding open water, such as at beaches, to realtime understanding of water characteristics, and their spatial variations. A sensor and meta-sensor pod was developed and can be towed behind a swimmer to provide immediate XR feedback of the current water characteristics to enable the swimmer to choose an optimal path to swim. Part 2 of WaterHCI was also developed based on autonomous crafts, drones, and the like to sense water quality and generate an XR ""heatmap"" that shows spatial variations of water properties such as water temperature, turbidity, conductivity, etc., made visible to a swimmer’s head-up display in realtime.","","978-1-6654-4940-3","10.1109/SPICES52834.2022.9774174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774174","SWIM (Sequential Wave Imprinting Machine);Augmented Reality (AR);eXtended Reality (XR);Sensing;Meta-sensing;Open water;Water reservoir;Robotics;Autonomous sensing;Digital Signal Processing (DSP)","Water;Temperature sensors;Visualization;Temperature;Extended reality;Water heating;Water quality","augmented reality;human computer interaction;water;water quality","WaterHCI Part 1;Water-HCI;water interaction;water-based;hydraulophones;underwater musical instruments;SWIM;sequential wave imprinting machine;meta-sensing;sensing-of-sensing;XR visualization;spatial variations;meta-sensor pod;immediate XR feedback;current water characteristics;water quality;XR heatmap;water properties;water temperature;realtime augmented reality;open water monitoring","","2","","9","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"Fish-be-with-you: An Augmented Reality Mobile Application About Endangered Marine Species","M. J. Y. Mina; M. D. T. Antonio; J. M. B. Clemente; C. I. M. Yap; J. Q. Calleja; M. C. Fernando-Raguro; A. C. Lagman; J. H. Jasper Ortega","FEU Institute of Technology, Manila, Philippines; FEU Institute of Technology, Manila, Philippines; FEU Institute of Technology, Manila, Philippines; FEU Institute of Technology, Manila, Philippines; FEU Institute of Technology, Manila, Philippines; FEU Institute of Technology, Manila, Philippines; FEU Institute of Technology, Manila, Philippines; FEU Institute of Technology, Manila, Philippines","2022 2nd International Conference in Information and Computing Research (iCORE)","28 Mar 2023","2022","","","20","24","This project aims to develop an augmented reality mobile application about endangered marine species. The program has made use of augmented reality technology to scan target photos on the card and show three-dimensional reconstructions of six endangered marine species. When a target image is detected, the program will show the 3D model of the sea species to the user. The application was built using Vuforia and Unity, the 3D models were modeled with Substance Painter and ZBrush, and the card layout was designed with Adobe Illustrator. The created system is one of the country's first augmented reality (AR) apps regarding endangered marine species, with the purpose of spreading information and increasing awareness about the situation of endangered marine species via AR. To demonstrate that the program is productive and user-friendly, the researchers surveyed ten IT experts. The survey findings demonstrate that the approach is effective and useable for sharing information and increasing awareness about the state of endangered marine species. Future researchers may enhance the system by incorporating some of the features and refining the mobile application so that people can still use it without the visual book.","","979-8-3503-3390-9","10.1109/iCORE58172.2022.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10071645","Augmented Reality;mobile application;Augmented Reality Cards;3D model;Endangered Marine species","Solid modeling;Visualization;Three-dimensional displays;Computational modeling;Refining;Layout;Mobile applications","augmented reality;mobile computing;virtual reality","augmented reality mobile application;augmented reality technology;country;endangered marine species","","","","10","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"A Generic Architecture of Augmented and Virtual Reality in Classrooms","H. Elkoubaiti; R. Mrabet","Smart Systems Laboratory, Ecole Nationale Supérieure d’Informatique et d’Analyse des Systèmes – ENSIAS, University Mohammed V of Rabat, Morocco; Smart Systems Laboratory, Ecole Nationale Supérieure d’Informatique et d’Analyse des Systèmes – ENSIAS, University Mohammed V of Rabat, Morocco","2018 6th International Conference on Multimedia Computing and Systems (ICMCS)","8 Nov 2018","2018","","","1","4","With the increasingly growing interest to develop the educational sector, the use of technology in classrooms is gaining more and more concern all over the world. In fact, emerging technologies have great potential to enhance learning and teaching process. Augmented reality (AR) and virtual reality (VR) are among those technologies that help to boost education. This paper presents a generic architecture that supports both AR and VR applications inside the classroom.","2472-7652","978-1-5386-6220-5","10.1109/ICMCS.2018.8525976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525976","Virtual reality;augmented reality;generic architecture of AR and VR","Software;Three-dimensional displays;Tools;Rendering (computer graphics);Visualization;Cameras;Virtual reality","augmented reality;computer aided instruction;teaching;technology management","virtual reality;classroom;educational sector;augmented reality;technology usage;learning process enhancement;teaching process enhancement","","1","","14","IEEE","8 Nov 2018","","","IEEE","IEEE Conferences"
"The Peripheral Display for Augmented Reality of Self-motion","T. Nojima; Y. Saiga; Y. Okano; Y. Hashimoto; H. Kajimoto","Institute of Aerospace Technology, Japan Aerospace Exploration Agency, Japan; The Department of Human Communication, University of Electro-Communications, Japan; The Department of Human Communication, University of Electro-Communications, Japan; The Department of Human Communication, University of Electro-Communications, Japan; The Department of Human Communication, University of Electro-Communications, Japan","17th International Conference on Artificial Reality and Telexistence (ICAT 2007)","2 Jan 2008","2007","","","308","309","It is known that peripheral vision strongly contributes to the sense of self-motion, and that users of visual displays with a narrow field of view often find it hard to experience such sensations fully. In this research, we propose a peripheral display that augments the feeling of self-motion. This consists of simple displays that stimulate the user's peripheral area of vision. By changing the stimulus on the peripheral display, the system should be able to increase or reduce the user's sense of self-motion. In this report, we describe a prototype of the display system and the result of its evaluation.","","0-7695-3056-7","10.1109/ICAT.2007.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414660","","Augmented reality;Liquid crystal displays;Aerospace simulation;Helicopters;Eyes;Light emitting diodes;Optical arrays;Optical sensors;Image motion analysis;Prototypes","augmented reality;computer displays","peripheral display;augmented reality;self motion;visual displays","","2","1","6","IEEE","2 Jan 2008","","","IEEE","IEEE Conferences"
"Single Image Augmented Reality Using Planar Structures in Urban Environments","E. McClean; Y. Cao; J. McDonald","National University of Ireland Maynooth, Maynooth, IE; National University of Ireland Maynooth, Maynooth, IE; National University of Ireland Maynooth, Maynooth, IE","2011 Irish Machine Vision and Image Processing Conference","24 Nov 2014","2011","","","1","6","In this paper, we present an effective method for integrating 3D augmented reality graphics into single images taken in urban environments. Building facades usually contain a large number of parallel lines aligned along several principal directions. We make use of the images of these 3D parallel lines and their corresponding vanishing points to recover a number of 3D planes from single 2D images of urban environments and then use them to represent the spatial layout of a scene. 3D objects are then aligned with respect to these recovered planes to achieve realistic augmented reality effects. In experiments we applied the proposed method to implement augmented reality in images from a benchmark image dataset of urban environments.","","978-0-7695-4629-2","10.1109/IMVIP.2011.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6167872","Line Projection Function;Visual SLAM;Failure Recovery","Three dimensional displays;Buildings;Cameras;Solid modeling;Strips;Augmented reality;Image segmentation","augmented reality;computer graphics;image processing","single image augmented reality;planar structures;urban environments;3D augmented reality graphics;3D parallel lines;spatial layout;realistic augmented reality effects","","5","","","IEEE","24 Nov 2014","","","IEEE","IEEE Conferences"
"Invited Talk: Emerging Role of Digital Assistant in Augmented Reality Driven Human-City Interaction","L. -H. Lee","Center for Ubiquitous Computing, University of Oulu, Oulu, Finland","2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)","4 Aug 2020","2020","","","1","1","This keynote presentation will discuss the unique research issues and challenges in the intersection between augmented reality and smart cities. Designing interaction approaches for Mobile Augmented Reality (MAR) in city-wide urban scenarios are receiving rising attention. In our envisioned framework of Human-City Interaction, we foresee that MAR with complementary digital assistant will become critical enablers for immersive interaction in our smart cities. The proposed framework is on the basis of numerous works on MAR interaction design. We will discuss several illustrative examples to elaborate on the framework and accordingly highlight the importance of the digital assistant. The presentation will be concluded with future directions for Human-City Interaction.","","978-1-7281-4716-1","10.1109/PerComWorkshops48775.2020.9156243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156243","","Augmented reality;Smart cities;Mars;Conferences;Smart devices;Headphones","augmented reality;mobile computing;smart cities;social aspects of automation","augmented reality driven human-city interaction;MAR interaction design;immersive interaction;complementary digital assistant;city-wide urban scenarios;Mobile Augmented Reality;smart cities","","","","0","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Design of collaborative 3D user interfaces for virtual and augmented reality","J. G. Grandi","Institute of Informatics, Federal University of Rio Grande do Sul, Brazil","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","419","420","We explore design approaches for cooperative work in virtual manipulation tasks. We seek to understand the fundamental aspects of the human cooperation and design interfaces and manipulation actions to enhance the group's ability to solve complex manipulation tasks in various immersion scenarios.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892355","H.5.2. [Information Interfaces and Presentation]: User Interfaces — Input devices and strategies;H.5.3. [Information Interfaces and Presentation]: Group and Organization Interfaces — Computer-supported cooperative work","Three-dimensional displays;Collaboration;User interfaces;Virtual environments;Visualization;Augmented reality","augmented reality;groupware;user interfaces","collaborative 3D user interfaces;augmented reality;virtual manipulation tasks;virtual reality","","3","","5","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Stiffness modulation for Haptic Augmented Reality: Extension to 3D interaction","S. Jeon; S. Choi","Haptics and Virtual Reality Laboratory, Department of Computer Science and Engineering, Pohang University of Science and Technology, South Korea; Haptics and Virtual Reality Laboratory, Department of Computer Science and Engineering, Pohang University of Science and Technology, South Korea","2010 IEEE Haptics Symposium","8 Apr 2010","2010","","","273","280","Haptic Augmented Reality (AR) allows a user to touch a real environment augmented with synthetic haptic stimuli. For example, medical students can palpate a virtual tumor inside a real mannequin using a haptic AR system to practice cancer detection. To realize such functionality, we need to alter the haptic attributes of a real object by means of virtual haptic feedback. Previously, we presented a haptic AR system with stiffness as a goal modulation property, and demonstrated its competent physical and perceptual performances for 1D interaction. In this paper, we extend the system so that a user can interact with a real object in any 3D exploratory pattern while perceiving its augmented stiffness. A series of algorithms are developed for contact detection, deformation estimation, force rendering, and force control. Their performances are thoroughly evaluated with real samples. A particular focus has been on minimizing the amount of preprocessing such as geometry modeling. Our haptic AR system can provide convincing stiffness modulation for real objects of relatively homogeneous deformation properties. The limitations of our AR system are also discussed along with a plan for future work.","2324-7355","978-1-4244-6822-5","10.1109/HAPTIC.2010.5444645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444645","","Haptic interfaces;Augmented reality;Neoplasms;Virtual reality;Performance evaluation;Space technology;Force control;Industrial training;Computer science;Biomedical engineering","augmented reality;deformation;geometry;haptic interfaces","stiffness modulation;haptic augmented reality;3D interaction;synthetic haptic stimuli;virtual tumor;haptic AR system;cancer detection;virtual haptic feedback;3D exploratory pattern;augmented stiffness;contact detection;deformation estimation;force rendering;force control;geometry modeling;homogeneous deformation properties","","19","","29","IEEE","8 Apr 2010","","","IEEE","IEEE Conferences"
"AR-based Video-Mediated Communication: A Social Presence Enhancing Experience","I. d. S. Almeida; M. A. Oikawa; J. P. Carres; J. Miyazaki; H. Kato; M. Billinghurst","Nara Institute of Science and Technology, Nara, japan; Nara Institute of Science and Technology, Nara, japan; Nara Institute of Science and Technology, Nara, japan; Nara Institute of Science and Technology, Nara, japan; Nara Institute of Science and Technology, Nara, japan; University of Canterbury, Canterbury, New Zealand","2012 14th Symposium on Virtual and Augmented Reality","10 Sep 2012","2012","","","125","130","Video-mediated communication systems attempt toprovide users with a channel that could bring out the ""feeling""of face-to-face communication. Among the many qualities thesesystems aim for, a high level of Social Presence isunquestionably a desirable one; however, little effort has beenmade to improve upon the user's perception of ""presence"". Wepropose an AR approach to enhance social presence for video mediatedsystems by allowing one user to be present in theother user's video image. We conducted a preliminary pilotstudy with 10 participants coupled in 5 pairs to evaluate oursystem and compare with the traditional video-chat setup.Results indicated that our system has higher degree of socialpresence compared to traditional video-chat systems. Thisconclusion was supported by the positive feedback from thesubjects.","","978-1-4673-1929-4","10.1109/SVR.2012.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6297568","augmented reality;social presence;video-mediated communication","Cameras;Face;Training;Streaming media;Augmented reality;Games;Merging","augmented reality;computer mediated communication;user interfaces;video communication;video signal processing","AR-based video-mediated communication systems;augmented reality;social presence enhancing experience;face-to-face communication;video-chat systems","","15","3","13","IEEE","10 Sep 2012","","","IEEE","IEEE Conferences"
"Aspects of what makes or breaks a museum AR experience","C. B. Madsen; J. B. Madsen; A. Morrison","Department of Architecture, Design and Media Technology, Aalborg University, Denmark; Department of Architecture, Design and Media Technology, Aalborg University, Denmark; Department of Architecture, Design and Media Technology, Aalborg University, Denmark","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","91","92","The paper critically evaluates central aspects of an iPad AR application developed for a museum context. The application is designed for children aged 8 to 12 and mixes AR and mini-game elements to convey dramatized historical events. The game has been deployed for roughly 3 months and the findings in the paper are supported by extensive in-application activity logging. Actual usage of the application at the museum proved far less extensive than envisaged. Hypotheses for this finding are presented and discussed, with support from the logging data.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483996","Augmented Reality;edutainment;infotainment;museum;iPad;game;children;embodiment;visual exploration","Games;Tablet computers;Augmented reality;Visualization;Animation;Floors","augmented reality;museums","museum AR experience;iPad AR application;museum context;minigame elements;logging data;augmented reality","","9","","","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Modeling Physical Structure as Additional Constraints for Stereoscopic Optical See-Through Head-Mounted Display Calibration","L. Qian; A. Winkler; B. Fuerst; P. Kazanzides; N. Navab","Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","154","155","For stereoscopic optical see-through head-mounted display calibration, existing methods that calibrate both eyes at the same time highly depend on the HMD user's unreliable depth perception. On the other hand, treating both eyes separately requires the user to perform twice the number of alignment tasks, and does not satisfy the physical structure of the system. This paper introduces a novel method that models physical structure as additional constraints and explicitly solves for intrinsic and extrinsic parameters of the stereoscopic system by optimizing a unified cost function. The calibration does not involve the unreliable depth alignment of the user, and lessens the burden for user interaction.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836486","Augmented Reality;SPAAM;OST-HMD Calibration and Human Factors","Calibration;Stereo image processing;Augmented reality;Adaptive optics;Optimization methods;Data acquisition","augmented reality;calibration;helmet mounted displays;optimisation","physical structure;stereoscopic optical see-through head-mounted display calibration;HMD user depth perception;cost function optimization;augmented reality","","6","","6","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Reduction of Interaction Space in Single Point Active Alignment Method for Optical See-Through Head-Mounted Display Calibration","L. Qian; A. Winkler; B. Fuerst; P. Kazanzides; N. Navab","Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States; Johns Hopkins University, Baltimore, MD, United States","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","156","157","With users always involved in the calibration of optical see-through head-mounted displays, the accuracy of calibration is subject to human-related errors, for example, postural sway, an unstable input medium, and fatigue. In this paper we propose a new calibration approach: Fixed-head 2 degree-of-freedom (DOF) interaction for Single Point Active Alignment Method (SPAAM) reduces the interaction space from a typical 6 DOF head motion to a 2 DOF cursor position on the semi-transparent screen. It uses a mouse as input medium, which is more intuitive and stable, and reduces user fatigue by simplifying and speeding up the calibration procedure. A multi-user study confirmed the significant reduction of human-related error by comparing our novel fixed-head 2 DOF interaction to the traditional interaction methods for SPAAM.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836487","Augmented Reality;SPAAM;OST-HMD Calibration and Human Factors","Calibration;Augmented reality;Head;Adaptive optics;Three-dimensional displays;Optical imaging;Mice","augmented reality;calibration;helmet mounted displays;human factors;mouse controllers (computers)","interaction space reduction;single point active alignment method;optical see-through head-mounted display calibration;human-related errors;fixed-head 2 degree-of-freedom interaction;DOF interaction;SPAAM;6 DOF head motion;2 DOF cursor position;semitransparent screen;mouse;user fatigue reduction;augmented reality","","5","","7","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"[POSTER] Hands-Free AR Work Support System Monitoring Work Progress with Point-cloud Data Processing","H. Sagawa; H. Nagayoshi; H. Kiyomizu; T. Kurihara","Research & Development Group, Center for Technology Innovation - Systems Engineering, Tokyo, Japan; Research & Development Group, Center for Technology Innovation - Systems Engineering, Tokyo, Japan; Research & Development Group, Center for Technology Innovation - Systems Engineering, Tokyo, Japan; Research & Development Group, Center for Technology Innovation - Systems Engineering, Tokyo, Japan","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","172","173","We present a hands-free AR work support system that provides work instructions to workers without interrupting normal work procedures. This system estimates the work progress by monitoring the status of work objects only on the basis of 3D data captured from a depth sensor mounted on a helmet, and it selects appropriate information to be displayed on a head-mounted display (HMD) on the basis of the estimated work progress. We describe a prototype of the proposed system and the results of primary experiments carried out to evaluate the accuracy and performance of the system.","","978-1-4673-7660-0","10.1109/ISMAR.2015.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328090","augmented reality;work support;hands-free","Three-dimensional displays;Solid modeling;Augmented reality;Accuracy;Monitoring;Prototypes;Data models","augmented reality","hands-free AR work support system;point-cloud data processing;work instructions;3D data;depth sensor;helmet;head-mounted display;HMD;augmented reality","","4","","9","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"[POSTER] Natural 3D Interaction Using a See-Through Mobile AR System","Y. Unuma; T. Komuro",Saitama University; Saitama University,"2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","84","87","In this paper, we propose an interaction system in which the appearance of the image displayed on a mobile display is consistent with that of the real space and that enables a user to interact with virtual objects overlaid on the image using the user's hand. The three-dimensional scene obtained by a depth camera is projected according to the user's viewpoint position obtained by face tracking, and the see-through image whose appearance is consistent with that outside the mobile display is generated. Interaction with virtual objects is realized by using the depth information obtained by the depth camera. To move virtual objects as if they were in real space, virtual objects are rendered in the world coordinate system that is fixed to a real scene even if the mobile display moves, and the direction of gravitational force added to virtual objects is made consistent with that of the world coordinate system. The former is realized by using the ICP (Iterative Closest Point) algorithm and the latter is realized by using the information obtained by an accelerometer. Thus, natural interaction with virtual objects using the user's hand is realized.","","978-1-4673-7660-0","10.1109/ISMAR.2015.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328067","Augmented reality;mobile device;geometric consistency;depth camera","Cameras;Mobile communication;Three-dimensional displays;Face;Mobile handsets;Augmented reality;Iterative closest point algorithm","augmented reality;iterative methods;user interfaces","natural 3D interaction;see-through mobile AR system;augmented reality;mobile display;virtual objects;three-dimensional scene;depth camera;gravitational force;world coordinate system;ICP algorithm;iterative closest point algorithm;user hand","","4","","14","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Accessing BIM-Related Information Through AR","M. Uimonen; M. Hakkarainen",VTT Technical Research Centre of Finland; VTT Technical Research Centre of Finland,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","399","400","The demonstration in hand is a facility management interface for handheld devices. It utilizes a combination of VTT's ALVAR point cloud tracking for accurate coupling of indoor location and information related to points of interest, and Google's ARCore for enhanced mobility and less restricted experience. The application can connect to a database of a Finnish commercial facility management operator Granlund Oy, allowing the user to instantly access and modify information related to a selected part of a Building Information Model (BIM). Such information includes temperature and flow rate of air conditioning, for example.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699282","Augmented and mixed reality;BIM;facility management","Augmented reality","augmented reality;building information modelling","Finnish commercial facility management operator Granlund Oy;BIM-related Information;facility management interface;handheld devices;building information model;Google ARCore;VTT ALVAR point cloud tracking;augmented reality","","4","","3","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Enhancing the Understanding of 3D Objects for Engineering Students: A Mixed Methodology of AR Application and Traditional Educational Materials","M. P. Bergamaschi; I. F. Silveira","Instituto Federal de Educação, Ciência e Tecnologia (IFSP), Brasil; Instituto Federal de Educação, Ciência e Tecnologia (IFSP), Brasil","2014 XVI Symposium on Virtual and Augmented Reality","2 Oct 2014","2014","","","127","130","Several studies report that Engineering students face difficulties in understanding the concepts of Spatial Geometry in Technical Drawing courses. Thus, this papers goal is to present a mixed methodology that combines AR artifacts with traditional educational materials, like books and course packs. Some results of this methodology are shown in an Engineering course along five years, indicating that its application could be effective to improve students' apprehension of 3D forms.","","978-1-4799-4261-9","10.1109/SVR.2014.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913083","Augmented Reality;Spatial Geometry;Technical Drawing","Visualization;Materials;Augmented reality;Three-dimensional displays;Solid modeling;Technical drawing;Engineering students","augmented reality;computer aided instruction;educational courses;engineering computing;engineering education;technical drawing","3D object understanding;engineering students;AR application;traditional educational materials;spatial geometry;technical drawing courses;AR artifacts;books;course packs;engineering course;student apprehension;augmented reality","","3","","17","IEEE","2 Oct 2014","","","IEEE","IEEE Conferences"
"[POSTER] A Comprehensive Interaction Model for AR Systems","M. Salazar; C. Laorden; P. G. Bringas","DeustoTech, University of Deusto, Bilbao, Spain; DeustoTech, University of Deusto, Bilbao, Spain; DeustoTech, University of Deusto, Bilbao, Spain","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","104","107","In this extended poster, we present a model that aims to provide developers with an extensive and extensible set of context-aware interaction techniques, greatly facilitating the creation of meaningful AR-based user experiences. To provide a complete view of the model, we detail the different aspects that form its theoretical foundations, while also discussing several considerations for its correct implementation.","","978-1-4673-7660-0","10.1109/ISMAR.2015.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328072","Interaction model;Augmented Reality","Computational modeling;Computers;User interfaces;Context;Augmented reality;Context modeling;Unified modeling language","augmented reality;human computer interaction;user interfaces","AR system;augmented reality;context-aware interaction technique;AR-based user experience;human-computer interaction","","1","","18","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"[POSTER] Vergence-Based AR X-ray Vision","Y. Kitajima; S. Ikeda; K. Sato","Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University","2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","188","189","The ideal AR x-ray vision should enable users to clearly observe and grasp not only occludees, but also occluders. We propose a novel selective visualization method of both occludee and oc-cluder layers with dynamic opacity depending on the user's gaze depth. Using the gaze depth as a trigger to select the layers has a essential advantage over using other gestures or spoken commands in the sense of avoiding collision between user's intentional commands and unintentional actions. Our experiment by a visual paired-comparison task shows that our method has achieved a 20% higher success rate, and significantly reduced 30% of the average task completion time than a non-selective method using a constant and half transparency.","","978-1-4673-7660-0","10.1109/ISMAR.2015.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328098","x-ray vision;ghosted views;visibility;vergence;gaze-contingent display;augmented reality","Visualization;Three-dimensional displays;Augmented reality;X-ray imaging;Yttrium;Indexes;Brain-computer interfaces","augmented reality;opacity;X-ray imaging","vergence-based AR x-ray vision;selective visualization method;opacity;users gaze depth;AR ghosted views;augmented reality","","","","5","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Depth cueing for augmented reality","E. W. Tatham","School of Mathematical and Information Sciences, Coventry University, UK","Proceedings. 1997 IEEE Conference on Information Visualization (Cat. No.97TB100165)","6 Aug 2002","1997","","","348","349","Computer-augmented reality systems promise to overcome some of the problems inherent in virtual reality and, in addition, to provide numerous other application possibilities. However, if augmented reality is to become fully practicable a number of hurdles need to be surmounted. Not least of these is the ability to achieve convincing real-time visual integration of virtual objects within real scenes. To this end, it is particularly important that virtual entities appear to exist at their appropriate depth within a real environment. This article outlines an experimental system to determine the efficacy of alternative static monocular depth cues in an augmented reality display.","1093-9547","0-8186-8076-8","10.1109/IV.1997.626548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=626548","","Augmented reality;Computer displays;Computer graphics;Virtual reality;Layout;Application software;Mirrors;Humans;Eyes;Monitoring","virtual reality;realistic images;image registration;visual perception","depth cueing;augmented reality;computer-augmented reality systems;virtual reality;convincing real-time visual integration;virtual objects;real scenes;virtual entities;appropriate depth;static monocular depth cues;computer graphic superimposition;super-imposition","","","","8","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Press dedicated machine Show-room, a direct application of Augmented reality in industry. An industrial Augmented reality experience","D. Vilacoba; M. Á. Trujillo; A. Viñuales; P. Weber","DMRO Press Automation, ABB, Sant Quirze del Vallés, Spain; DMRO Press Automation, ABB, Sant Quirze del Vallés, Spain; DMRO Press Automation, ABB, Sant Quirze del Vallés, Spain; ABB, Corporate Research, Ladenburg, Germany","2016 IEEE International Conference on Industrial Technology (ICIT)","26 May 2016","2016","","","1990","1995","This Augmented reality (AR) has rapidly evolved to a state-of-the-art technology for superimposing digital information onto the reality. This technology recently gained more attention in industrial environments. Typical applications range from maintenance tasks, where device specific information and maintenance instructions are placed into a real context, to virtual engineering which supports engineering tasks based on virtual prototypes. This paper focuses on a virtual engineering experience in robotics applying virtual prototyping in combination with AR technology, including practical experiences from concept verification and major technology gaps identified.","","978-1-4673-8075-1","10.1109/ICIT.2016.7475072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7475072","","Presses;Solid modeling;Robot kinematics;Service robots;Augmented reality;Robot sensing systems","augmented reality;control engineering computing;robots;virtual prototyping","press dedicated machine show-room;industrial augmented reality experience;virtual engineering;robotics;virtual prototyping;AR technology","","1","","9","IEEE","26 May 2016","","","IEEE","IEEE Conferences"
"Transitional interface: concept, issues and framework","R. Grasset; J. Looser; M. Billinghurst","HitLab NZ, University of Canterbury, Christchurch, NZ, New Zealand; HitLab NZ, University of Canterbury, Christchurch, NZ, New Zealand; HitLab NZ, University of Canterbury, Christchurch, NZ","2006 IEEE/ACM International Symposium on Mixed and Augmented Reality","5 Feb 2007","2006","","","231","232","Transitional Interfaces have emerged as a new way to interact and collaborate between different interactive spaces such as reality, virtual reality and augmented reality environments. In this paper we explore this concept further. We introduce a descriptive model of the concept, its collaborative aspect and how it can be generalized to describe natural and continuous transitions between contexts (e.g. across space, scale, viewpoints, and representation).","","1-4244-0650-1","10.1109/ISMAR.2006.297819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4079281","","Navigation;Virtual reality;Collaboration;Augmented reality;Collaborative work;Switches;Context modeling;Chemistry;Legged locomotion;Interpolation","augmented reality;groupware;user interfaces","collaborative transitional interface;interactive space;continuous perceptual transition;augmented reality;virtual reality","","13","","3","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Augmented Visual Instruction for Surgical Practice and Training","D. Andersen; C. Lin; V. Popescu; E. R. Muñoz; M. Eugenia Cabrera; B. Mullis; B. Zarzaur; S. Marley; J. Wachs",Purdue University; Purdue University; Purdue University; Purdue University; Purdue University; Indiana University; Indiana University; Indiana University; Indiana University,"2018 IEEE Workshop on Augmented and Virtual Realities for Good (VAR4Good)","16 Dec 2018","2018","","","1","5","This paper presents two positions about the use of augmented reality (AR) in healthcare scenarios, informed by the authors' experience as an interdisciplinary team of academics and medical practitioners who have been researching, implementing, and validating an AR surgical telementoring system. First, AR has the potential to greatly improve the areas of surgical telementoring and of medical training on patient simulators. In austere environments, surgical telementoring that connects surgeons with remote experts can be enhanced with the use of AR annotations visualized directly in the surgeon's field of view. Patient simulators can gain additional value for medical training by overlaying the current and future steps of procedures as AR imagery onto a physical simulator. Second, AR annotations for telementoring and for simulator-based training can be delivered either by video see-through tablet displays or by AR head-mounted displays (HMDs). The paper discusses the two AR approaches by looking at accuracy, depth perception, visualization continuity, visualization latency, and user encumbrance. Specific advantages and disadvantages to each approach mean that the choice of one display method or another must be carefully tailored to the healthcare application in which it is being used.","","978-1-5386-5977-9","10.1109/VAR4GOOD.2018.8576884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576884","Human-centered computing—Mixed / augmented reality;Applied computing—Health care information systems","Surgery;Training;Resists;Visualization;Biomedical imaging;Cameras","augmented reality;computer aided instruction;health care;helmet mounted displays;medical computing;surgery;telemedicine","surgical training;surgical practice;augmented visual instruction;visualization latency;visualization continuity;AR head-mounted displays;simulator-based training;physical simulator;AR annotations;austere environments;patient simulators;medical training;AR surgical telementoring system;augmented reality","","4","","12","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Performance Envelopes of in-Air Direct and Smartwatch Indirect Control for Head-Mounted Augmented Reality","D. Wolf; J. J. Dudley; P. O. Kristensson","University of Cambridge, Ulm University; University of Cambridge; University of Cambridge","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","347","354","The scarcity of established input methods for augmented reality (AR) head-mounted displays (HMD) motivates us to investigate the performance envelopes of two easily realisable solutions: indirect cursor control via a smartwatch and direct control by in-air touch. Indirect cursor control via a smartwatch has not been previously investigated for AR HMDs. We evaluate these two techniques for carrying out three fundamental user interface actions: target acquisition, goal crossing, and circular steering. We find that in-air is faster than smartwatch (p <; 0.001) for target acquisition and circular steering. We observe, however, that in-air selection can lead to discomfort after extended use and suggest that smartwatch control offers a complementary alternative.","","978-1-5386-3365-6","10.1109/VR.2018.8448289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8448289","Fitts' law;steering law;goal crossing;in-air selection;smartwatch;indirect cursor;AR;augmented reality: Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Mixed / augmented reality","Task analysis;User interfaces;Augmented reality;Mathematical model;Navigation;Trajectory;Resists","augmented reality;helmet mounted displays;human computer interaction;mouse controllers (computers)","performance envelopes;in-air direct;smartwatch indirect control;head-mounted augmented reality;augmented reality head-mounted displays;indirect cursor control;direct control;in-air touch;fundamental user interface actions;target acquisition;circular steering;in-air selection;smartwatch control","","9","","26","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"An interactive augmented reality coloring book","A. Clark; A. Dünser","The HIT Laboratory NZ, University of Canterbury, Christchurch, New Zealand; The HIT Laboratory NZ, University of Canterbury, Christchurch, New Zealand","2012 IEEE Symposium on 3D User Interfaces (3DUI)","19 Apr 2012","2012","","","7","10","Creating entertaining and educational books not only requires providing visually stimulating content but also means for students to interact, create, and express themselves. In this paper we present a new type of mixed-reality book experience, which augments an educational coloring book with user-generated three dimensional content. We explore a “pop-up book” metaphor and describe a process by which children's drawing and coloring is used as input to generate and change the appearance of the book content. Our system is based on natural feature tracking and image processing techniques that can be easily exploited for other AR publishing applications.","","978-1-4673-1205-9","10.1109/3DUI.2012.6184168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184168","Natural Feature Tracking;Mixed Reality book;interactive AR;edutainment;education;3D texturing","Image color analysis;Books;Augmented reality;Three dimensional displays;Solid modeling;Software;Materials","augmented reality;computer aided instruction;object tracking;publishing","interactive augmented reality coloring book;entertaining books;mixed-reality book experience;educational coloring book;user-generated three dimensional content;pop-up book metaphor;children drawing;children coloring;natural feature tracking;image processing techniques;AR publishing applications","","30","2","19","IEEE","19 Apr 2012","","","IEEE","IEEE Conferences"
"A virtual and augmented reality approach to collaborative product design and demonstration","K. Smparounis; D. Mavrikios; M. Pappas; V. Xanthakis; G. P. Viganò; K. Pentenrieder","Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece; Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece; Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece; Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece; National Research Council, Institute of Industrial Technologies and Automation, Milano, Italy; Metaio GmbH, Munich, Germany","2008 IEEE International Technology Management Conference (ICE)","28 Apr 2016","2008","","","1","8","This paper describes the framework and the implementation plan of a web-based platform for supporting collaborative product design evaluation, demonstration and customization. The relevant industrial needs are first outlined. A short overview is given on current Research and Development (R&D) activities aiming at addressing these needs. The conceptual framework and the functionality of the suggested web-based platform are then presented, mainly focusing on the Virtual / Augmented Reality and collaboration features. The design and implementation of the suggested platform are discussed, providing an insight on the architecture and communication aspects. An indicative pilot case is outlined to demonstrate how the suggested approach and tools will be applied in the collaborative review, demonstration and customization of products coming from the textiles industry. Finally, the potential of the web-based platform in addressing the needs of collaborative product development activities is briefly mentioned.","","978-0-85358-244-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7462046","Collaborative design review;distributed cooperative design;web-based collaboration;virtual reality;shared virtual environments","Collaboration;Augmented reality;Three-dimensional displays;Product design;Virtual environments;Prototypes","augmented reality;groupware;Internet;manufacturing data processing;product customisation;product design;textile industry","virtual reality;augmented reality;collaborative product design;Web-based platform;product customization;collaborative review;textile industry;collaborative product development activities","","","","21","","28 Apr 2016","","","IEEE","IEEE Conferences"
"Image Features Detection and Tracking for Image Based Target Augmented Reality Application","M. K. Mokhtar; F. Mohamed; M. S. Sunar; A. A. Abd Aziz; M. A. M. Arshad; M. K. M. Sidik","Media and Game Innovation Centre of Excellence, Universiti Teknologi Malaysia, Skudai, Malaysia; Media and Game Innovation Centre of Excellence, Universiti Teknologi Malaysia, Skudai, Malaysia; Media and Game Innovation Centre of Excellence, Universiti Teknologi Malaysia, Skudai, Malaysia; Media and Game Innovation Centre of Excellence, Universiti Teknologi Malaysia, Skudai, Malaysia; V3X Malaysia Sdn. Bhd., Skudai, Malaysia; Universiti Brunei Darussalam, Gadong, Brunei Darussalam","2019 IEEE Conference on Graphics and Media (GAME)","6 Feb 2020","2019","","","38","43","Image based target used in augmented reality application is not the same as traditional fiducial markers, data markers code and QR-codes in detection and tracking. The available features from the image detected and tracked are naturally found in the image itself. Image target commonly used in recognizing and augmented hard copy media and product for marketing campaigns, gaming, and visualizing products in the environment where the product was targeted to be used. HOwever, for mobile-based augmented reality application, image features detection and tracking still expose many challenges. This paper aims to review previous and current keypoint detection and tracking techniques for image target and address several issues face in mobile based augmented reality application. Most traditional interest-point detection and description methods are handcrafted. These methods focus on interest points in a generic setting and lack provision to adapt toward a specific dataset. Learning-based approaches can be a new solution to real-time application such mobile-based application. This project continuity work from our previous work done for mobile-based augmented reality coloring application [1].","","978-1-7281-3944-9","10.1109/GAME47560.2019.8980604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8980604","Augmented Reality;Interest Point;Image Features;Image-based Target","","augmented reality;feature extraction;learning (artificial intelligence);mobile computing;object detection;object tracking","description methods;learning-based approaches;real-time application;mobile-based augmented reality coloring application;image features detection;image based target augmented reality application;traditional fiducial markers;data markers code;available features;image target;mobile-based augmented reality application;keypoint detection;tracking techniques;augmented hard copy media;interest-point detection","","3","","27","IEEE","6 Feb 2020","","","IEEE","IEEE Conferences"
"Simplifying the Process of Creating Augmented Outdoor Scenes","R. Chalumattu; S. Schaub-Meyer; R. Wiethuchter; S. Klingler; M. Gross","Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich","2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","9 Jun 2020","2020","","","1","6","Creating augmented reality content has experienced increasing interest. However, existing tools for the broad audience are often limited in the capabilities they provide – applying filters and placing predefined assets. In this paper, we propose an intuitive framework to generate large scale augmented overlays for outdoor scenes supporting the creative process and allowing simple sharing of the location-based experience. We introduce a novel concept of using virtual reality for content creation. This includes using a simple 3D city model. Based on this model we are also able to improve the resulting AR visualization by handling occlusions as well as a content-specific improved alignment.","","978-1-7281-1485-9","10.1109/ICMEW46912.2020.9106030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106030","Augmented reality;content creation","Solid modeling;Visualization;Three-dimensional displays;Conferences;Urban areas;Pipelines;Augmented reality","augmented reality;location based services","intuitive framework;creative process;allowing simple sharing;location-based experience;virtual reality;content creation;3D city model;content-specific improved alignment;augmented reality content;filters;augmented outdoor scenes;predefined assets placement;large scale augmented overlays","","1","","11","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Security and privacy in a middleware for large scale mobile and pervasive augmented reality","P. Ferreira; J. Orvalho; F. Boavida","Centro de Informática e Sistemas, Department of Informatics Engineering, University of Coimbra, Coimbra, Portugal; Centro de Informática e Sistemas, Department of Informatics Engineering, University of Coimbra, Coimbra, Portugal; Centro de Informática e Sistemas, Department of Informatics Engineering, University of Coimbra, Coimbra, Portugal","2007 15th International Conference on Software, Telecommunications and Computer Networks","1 Feb 2008","2007","","","1","5","Ubiquitous or pervasive computing is a new kind of computing, where specialized elements of hardware and software will have such high level of deployment that their use will be fully integrated with the environment. Augmented reality extends reality with virtual elements but tries to place the computer in a relatively unobtrusive, assistive role. In this paper we propose, test and analyse a security and privacy architecture for a previously proposed middleware architecture for mobile and pervasive large scale augmented reality games, which is the main contribution of this paper. The results show that the security features proposed in the scope of this work do not affect the overall performance of the system.","","978-953-6114-93-1","10.1109/SOFTCOM.2007.4446125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4446125","","Privacy;Middleware;Large-scale systems;Augmented reality;Personal area networks;Pervasive computing;Information security;Application software;Testing;Computer architecture","augmented reality;computer games;data privacy;middleware;mobile computing;security of data","pervasive augmented reality;ubiquitous computing;pervasive computing;virtual elements;security architecture;privacy architecture;middleware architecture;mobile augmented reality games;pervasive large scale augmented reality games","","1","6","18","","1 Feb 2008","","","IEEE","IEEE Conferences"
"Flaneur: Augmented exploration of the architectural urbanscape","A. Ioannidi; D. Gavalas; V. Kasapakis","Department of Cultural Technology & Communication, University of the Aegean, Mytilene, Greece; CTI, Patras, Greece; CTI, Patras, Greece","2017 IEEE Symposium on Computers and Communications (ISCC)","4 Sep 2017","2017","","","529","533","The recent developments in the area of mobile technologies have enabled the diffusion of augmented reality. This article explores new possibilities for leveraging the power of augmented reality, further to its typical use as a means for projecting virtual content over physical objects. That is, it investigates the potential of augmented reality as a tool for participatory content creation and sharing. In order to demonstrate this idea, we have developed Flaneur, a mobile augmented reality application which invites users to wander around a city to discover and highlight its architectural assets. Flaneur serves both as an architectural heritage guide and as a crowdsourcing platform. In particular, further to consuming content edited by administrators, users are enabled to share their knowledge and experiences about heritage buildings through uploading textual and graphical annotation, which is later delivered to peer users as augmented context. The platform allows the documentation of architecture-relevant content either for whole building blocks or even for specific architectural and decorative elements. Moreover, it enables the precise placement and arrangement of digital content over the physical asset to be augmented. Flaneur has been evaluated though field trials, which provided valuable insights as regards the effectiveness, utility and restrictions of the application.","","978-1-5386-1629-1","10.1109/ISCC.2017.8024582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8024582","Augmented reality;crowdsourcing;cultural heritage;architecture","Buildings;Crowdsourcing;Cultural differences;Global Positioning System;Image recognition;Augmented reality;Mobile communication","architecture;augmented reality;crowdsourcing;history;mobile computing","decorative elements;architectural elements;architecture-relevant content;crowdsourcing platform;architectural heritage guide;architectural assets;mobile augmented reality application;participatory content sharing;participatory content creation;virtual content;architectural urbanscape;augmented exploration;Flaneur","","4","","14","IEEE","4 Sep 2017","","","IEEE","IEEE Conferences"
"Augmented VR","A. Karakottas; A. Papachristou; A. Doumanoqlou; N. Zioulis; D. Zarpalas; P. Daras","Information Technologies Institute, Centre for Research and Technology, Hellas; Information Technologies Institute, Centre for Research and Technology, Hellas; Information Technologies Institute, Centre for Research and Technology, Hellas; Information Technologies Institute, Centre for Research and Technology, Hellas; Information Technologies Institute, Centre for Research and Technology, Hellas; Information Technologies Institute, Centre for Research and Technology, Hellas","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","1","1","Traditional VR is mostly about headset experiences either in completely virtual environments or 360° videos. On the other hand AR has been mixing realities by inserting the virtual within the real. In this work we present the Augmented VR concept that lies at the middle right of the virtuality continuum, typically referred to as augmented virtuality. We offer another perspective by blending the real within the virtual focusing on capturing actual human performances in three dimensions and emplacing them within virtual environments [1]-[3]. By compressing and transmitting this new type of 3D media we can also achieve real-time interaction, communication and collaboration between users. Being in full 3D our media are compatible with a variety of applications be it either VR, AR, MR and open up new exciting opportunities like free viewpoint spectating while also increasing the feeling of immersion of all participating users. We demonstrate our technology via a prototype two player game that can support spectating in various devices like head mounted displays (VR) or tablet laptops (AR). Our system is easy to setup, requiring minimal non-technical human intervention, and relatively low cost taking one step ahead in making this technology available to the consumer public.","","978-1-5386-3365-6","10.1109/VR.2018.8446561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446561","Human-centered computing - Human computer interaction (HCI) - Interaction paradigms - Virtual reality;Human-centered computing - Human computer interaction (HCI) - Interaction paradigms - Mixed/augmented reality;Computing methodologies - Computer graphics - Graphics systems and interfaces - Mixed/augmented reality;Computing methodologies - Computer vision - Image and video acquisition - Camera calibration;Computing methodologies-Computer vision - Computer vision representations - Appearance and texture representations;Computing methodologies - Computer vision - Computer vision problems - Reconstruction;Multi-user Virtual Reality;Teleimmersion","Three-dimensional displays;Real-time systems;Media;Virtual environments;Videos","augmented reality;computer games;helmet mounted displays;social aspects of automation","traditional VR;headset experiences;completely virtual environments;Augmented VR concept;virtuality continuum;augmented virtuality;free viewpoint spectating;tablet laptops;nontechnical human intervention;actual human performances;AR;MR;head mounted displays;consumer public;virtual focusing","","8","","3","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Seamless Bare-Hand Interaction in Mixed Reality","C. Battisti; S. Messelodi; F. Poiesi","Technologies of Vision, Fondazione Bruno Kessler, Trento, Italy; Technologies of Vision, Fondazione Bruno Kessler, Trento, Italy; Technologies of Vision, Fondazione Bruno Kessler, Trento, Italy","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","198","203","Unrealistic Mixed Reality (MR) experiences can be caused by unprocessed occlusions between real and augmented objects during interactions. Depth knowledge is indeed key to achieve a seamless visualisation when a bare hand interacts with an augmented object. This can be addressed by blending real-time 3D finger tracking information with the visualisation of the hand in MR. We propose an approach that automatically localises the hand in RGB images and associates the respective depth, estimated with an auxiliary infrared stereo camera used for hand tracking, to each RGB hand pixel. Because misalignments between the outline of the hand and its depth may occur due to tracking errors, we use the distance transform algorithm to densely associate depth values to hand pixels. In this way hand and augmented object depths can be compared, and the object can be rendered accordingly. We evaluate our approach by using an MR setup composed of a smartphone and a Leap Motion mounted on it. We analyse several hand configurations and measure the erroneously classified pixels when occlusions occur.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699329","Human Computer Interaction;Mixed Reality;Hand Interaction;Leap Motion","Cameras;Three-dimensional displays;Virtual reality;Transforms;Solid modeling;Tracking;Skin","augmented reality;cameras;computer vision;gesture recognition;human computer interaction;image colour analysis;rendering (computer graphics);stereo image processing","hand tracking;RGB hand pixel;hand pixels;object depths;realtime 3D finger tracking information;unrealistic mixed reality;Leap Motion;smart phone;auxiliary infrared stereo camera;seamless visualisation;depth knowledge;augmented object;MR;seamless bare-hand interaction","","7","","22","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Mixed Voxel Reality: Presence and Embodiment in Low Fidelity, Visually Coherent, Mixed Reality Environments","H. Regenbrecht; K. Meng; A. Reepen; S. Beck; T. Langlotz","School of Computer and Information Security, Guilin University of Electronic Technology, Guilin, Guangxi China; School of Computer and Information Security, Guilin University of Electronic Technology, Guilin, Guangxi China; School of Computer and Information Security, Guilin University of Electronic Technology, Guilin, Guangxi China; School of Computer and Information Security, Guilin University of Electronic Technology, Guilin, Guangxi China; School of Computer and Information Security, Guilin University of Electronic Technology, Guilin, Guangxi China","2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Nov 2017","2017","","","90","99","Mixed Reality aims at combining virtual reality with the user's surrounding real environment in a way that they form one, coherent reality. A coherent visual quality is of utmost importance, expressed in measures of e.g. resolution, framerate, and latency for both the real and the virtual domains. For years, researchers have focused on maximizing the quality of the virtual visualization mimicking the real world to get closer to visual coherence. This however, makes Mixed Reality systems overly complex and requires high computational power. In this paper, we propose a different approach by decreasing the realism of one or both visual realms, real and virtual, to achieve visual coherence. Our system coarsely voxelizes the real and virtual environments, objects, and people to provide a believable, coherent mixed voxel reality. In this paper we present the general idea, the current implementation and demonstrate the effectiveness of our approach by technical and empirical evaluations. Our mixed voxel reality system serves as a platform for low-cost presence research and studies on human perception and cognition, a host of diagnostic and therapeutic applications, and for a variety of Mixed Reality applications where users' embodiment is important. Our findings challenge some commonplace assumptions on more is better approaches in mixed reality research and practice-sometimes less can be more.","","978-1-5386-2943-7","10.1109/ISMAR.2017.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115408","mixed reality;augmented reality;believability;presence;voxel grid","Virtual reality;Visualization;Cameras;Rendering (computer graphics);Hardware;Coherence","augmented reality;data visualisation","mixed reality research;Mixed Reality applications;low-cost presence research;mixed voxel reality system;coherent mixed voxel reality;believable voxel reality;virtual environments;real environments;visual realms;high computational power;Mixed Reality systems;visual coherence;virtual visualization;virtual domains;coherent visual quality;virtual reality;mixed reality environments;coherent reality environments","","20","","42","IEEE","23 Nov 2017","","","IEEE","IEEE Conferences"
"Towards Trustworthy Augmented Reality in The Metaverse Era: Probing Manipulative Designs in Virtual-Physical Commercial Platforms","E. De Haas; H. Yiming; C. Bermejo; Z. Lin; P. Hui; L. -H. Lee","KAIST; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; London School of Economics and Political Science; Hong Kong University of Science and Technology, Guangzhou; The Hong Kong Polytechnic University, and KAIST","2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","1 May 2023","2023","","","779","780","E-commerce has become an important activity where new advances in technology shape the shopper experience. At the same time, the metaverse is seen as the next milestone to revolutionize the e-commerce experience, where immersion, realism, and ubiquity are its main features. However, under such circumstances, manipulative designs to ‘trick’ users toward intended choices or outcomes can become more effective. This paper sheds light on the design space of manipulative techniques in e-commerce applications for the meta-verse, reinforcing our understanding of interface design guidelines and counteracting malicious practices.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108880","Human-centered computing-Human computer interaction-Interaction paradigms-Mixed/ augmented reality & Virtual reality;Human-centered computing-User experience-User experience & usability-","Mars;Three-dimensional displays;Metaverse;Shape;Design methodology;Conferences;User interfaces","augmented reality;electronic commerce;Internet;retail data processing;virtual reality","counteracting malicious practices;design space;e-commerce applications;e-commerce experience;important activity;intended choices;interface design guidelines;manipulative designs;manipulative techniques;meta-verse;metaverse era;shopper experience;technology shape;towards trustworthy augmented reality;trick users;virtual-physical commercial platforms","","","","8","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Augmented instructions - a fusion of augmented reality and printed learning materials","K. Asai; H. Kobayashi; T. Kondo","National Institute of Multimedia Education, Japan; Graduate University of Advanced Studies (SOKENDAI); National Institute of Multimedia Education, Japan","Fifth IEEE International Conference on Advanced Learning Technologies (ICALT'05)","19 Sep 2005","2005","","","213","215","Augmented reality (AR), which overlays virtual objects onto real scenes, has large potential to provide learners with a new type of learning material. Although many AR systems have been developed for demonstration, there is a gap between their ideal and practical use. We discuss a concept for augmented instructions that mix AR and traditional printed materials. Improvement of human-computer interface is considered to serve as a bridge for the gap. To investigate on characteristics of augmented instructions and its appropriate interface, we conducted subjective evaluation, comparing 3D presentation systems; a handheld PC and a head-mounted display. The result suggested that a handheld PC was more suitable for a presentation tool of augmented instructions.","2161-377X","0-7695-2338-2","10.1109/ICALT.2005.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1508653","","Augmented reality;Layout;Geometry;Chemistry;Learning systems;Target tracking;Conducting materials;Bridges;Three dimensional displays;Prototypes","computer aided instruction;augmented reality;helmet mounted displays;notebook computers;human computer interaction;multimedia computing","augmented instructions;augmented reality;printed learning materials;virtual objects;human-computer interface;subjective evaluation;3D presentation systems;handheld PC;head-mounted display","","26","5","7","IEEE","19 Sep 2005","","","IEEE","IEEE Conferences"
"Interactive Embodied Agent for Navigation in Virtual Environments","T. Cao; C. Cao; Y. Guo; G. Wu; X. Shen","State Key Laboratory of Virtual Reality Technology and Systems, China; State Key Laboratory of Virtual Reality Technology and Systems, China; School of New Media Art and Design, Beihang University, China; School of New Media Art and Design, Beihang University, China; State Key Laboratory of Virtual Reality Technology and Systems, China","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","224","227","With the rapid development of virtual reality hardware, virtual tours in galleries and museums are more and more popular in recent years. However, users sometimes get lost in the virtual space and miss displaying items during free exploration of the virtual scene. Therefore, proper navigation assistance is very important to help the user finish the tour and concentrate on the exhibits. Embodied agent can help users explore the scene effectively with higher interactivity and enhance user presence, but it cannot ensure completeness of visiting.In this paper, we investigate the effect of embodied agent on providing navigation assistance in virtual environments. We focus on the motion control of the agent and experiment on different speed, stay time and interactivity settings of the agent. The result shows that interactive agent can enhance visiting completeness and user presence. With these findings, we provide important considerations for the design of embodied agent for navigation in virtual environments.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00053","State Key Laboratory of Virtual Reality Technology and Systems; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585897","Virtual Reality;Embodied Agent;Interactive Navigation","Navigation;Virtual environments;Hardware;Motion control;Augmented reality","museums;navigation;software agents;virtual reality","interactive embodied agent;virtual environments;virtual reality hardware;virtual tours;navigation assistance;galleries;museums","","","","12","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Technologies of Virtual and Augmented Reality in Biomedical Engineering","K. A. Demidova; N. Markovkina","Department of Cyber-Physical Systems, St. Petersburg State Marine Technical University, Saint Petersburg, Russia; Department of Cyber-Physical Systems, St. Petersburg State Marine Technical University, Saint Petersburg, Russia","2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus)","20 Apr 2022","2022","","","1496","1499","Technologies such as Virtual and Augmented Reality have gained popularity lately. Because of their convenience and accessibility, these technologies have been adopted in various domains. Virtual reality and augmented reality create an immersive experience, enabling 3D visualization of the content. This technology lets you visualize data from different sensors at the same time, overlaying relevant and helpful information over your environment through a headset. In this article, we give a perspective on these technologies from a biomedical engineering standpoint. In this article, we discuss the various technologies of current biomedical engineering. These technologies allow us to move beyond traditional 2D images towards 3D models that can be made visible and manipulated with Augmented and Virtual Reality. The basic applications of biomedical engineering include representation of mechanisms in space and time dimensions and three-dimensional visualizations of difficult structures in anatomy. The article is an attempt to bring the latest results on the benefits of virtual and augmented reality in biomedical engineering.","2376-6565","978-1-6654-0993-3","10.1109/ElConRus54750.2022.9755844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9755844","Virtual Reality;Augmented Reality;Biomedical Engineering","Solid modeling;Three-dimensional displays;Biological system modeling;Data visualization;Medical treatment;User experience;Sensors","augmented reality;biomedical engineering;data visualisation;virtual reality","augmented reality;biomedical engineering standpoint;current biomedical engineering;Virtual Reality;Virtual reality","","","","10","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"RealityMedia: An Experimental Digital Book in WebXR","M. Engberg; J. David Bolter; B. Maclntyre","Dept. of Computer Science and Media Technology, Malmö University; Georgia Tech, School of Literature, Communication, and Culture; Emerging Technologies, Mozilla School of Interactive Computing","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","324","327","This paper presents an ongoing experiment using WebXR to create something analogous to a non-fiction book in AR and VR; an immersive, interactive experience that stands on its own, rather than merely complementing a traditional book. The book introduces the reader/user to AR and VR both as technologies and as media. The printed book is one of the more influential communicative interfaces in history. AR and VR have the potential to remediate several genres of printed books, but somewhat different conventions may need to be developed for different combinations of genre and modality. The lessons learned through this experiment should contribute to the establishment of guidelines for this new form of multimedia, in particular conventions that facilitate the reader/user's transition from discursive to immersive modes and back.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699264","Augmented reality;virtual reality;world wide web;UX design;• Human-centered computing∼Mixed / augmented reality;• Human-centered computing∼Virtual reality;• Human-centered computing∼Interface design prototyping","Media;Portals;Three-dimensional displays;History;Two dimensional displays;Augmented reality;Writing","augmented reality;electronic publishing","experimental digital book;WebXR;ongoing experiment;nonfiction book;immersive experience;interactive experience;traditional book;printed book;influential communicative interfaces;AR;VR","","7","","9","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Augmented Reality Technology and Art: The Analysis and Visualization of Evolving Conceptual Models","V. Geroimenko","School of Art and Media, Plymouth University, Plymouth, UK","2012 16th International Conference on Information Visualisation","6 Sep 2012","2012","","","445","453","This paper provides a logical and methodological reconstruction of the evolving concept of Augmented Reality (AR) and also of the paradigmatic shift in art, caused by this emerging technology. It starts with an analysis of the notion of Augmented Reality, that leads to the construction of a conceptual model and a definition which together capture the nature of present AR applications. This is followed by a detailed conceptual analysis of major types of Augmented Reality that contribute to an understanding of current concepts. Finally, the resulting conceptual models are applied to the newly emerging field of Augmented Reality Art in order to assess the paradigmatic potential of AR as a new artistic medium. The paper puts a strong emphasis on the effective and adequate visualisation of the analysed conceptual frameworks, in order to promote a better comprehension of the logical structures underlying the notions of Augmented Reality and AR Art. This paper was intended to be presented at the opening of the First International Symposium on Augmented Reality Visualisation and Art, proposed and chaired by the author as part of the 16th International Conference on Information Visualization, IV2012.","2375-0138","978-1-4673-2260-7","10.1109/IV.2012.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6295852","Augmented reality;augmented reality art;logical and methodological analysis;conceptual model;visualization;concept visualization","Augmented reality;Art;Visualization;Humans;Face;Games","art;augmented reality;data visualisation","augmented reality technology;AR art;conceptual model analysis;conceptual model visualization;First International Symposium on Augmented Reality Visualisation and Art;16th International Conference on Information Visualization","","31","","24","IEEE","6 Sep 2012","","","IEEE","IEEE Conferences"
"Augmented Reality Based Learning Environment for Children with Special Needs","E. H. Shaltout; A. Afifi; K. M. Amin","Information Technology Dept, Faculty of Computers and Information, Menoufia University, Egypt, Behira, Egypt; Information Technology Dept, Faculty of Computers and Information, Menoufia University, Egypt, Behira, Egypt; Information Technology Dept, Faculty of Computers and Information, Menoufia University, Egypt, Behira, Egypt","2020 15th International Conference on Computer Engineering and Systems (ICCES)","1 Feb 2021","2020","","","1","7","Technology interference has become noticeable in all aspects of life. One of the most popular technologies is Augmented Reality (AR) used in all fields to facilitate and enhance those fields. The education filed is one of the areas in which augmented reality has been used extensively during the last years. Augmented reality has contributed to improving traditional educational methods through the integration of digital information with the user's environment in real-time. Therefore, augmented reality technology can be utilized to teach children with special needs due to its advantages in enriching the learning methodology. This paper introduces the design, development and evaluation of an efficient and low-cost AR-based educational environment for children with special needs. This environment utilizes augmented reality and educational cards to teach children the word from the card, its 3D model and its pronunciation. The proposed educational environment is developed as a mobile-based augmented reality (AR) application to be more attractive for children. The results showed that children enjoy sessions and interact with the application, which improves learning outcomes. Moreover, the user experience questionnaire shows a high level of satisfaction among parents and specialists.","","978-0-7381-0559-8","10.1109/ICCES51560.2020.9334571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9334571","Augmented Reality;Mobile Augmented Reality;Serious games;children with special needs;Vuforia SDK","Solid modeling;Three-dimensional displays;User experience;Real-time systems;Safety;Mobile applications;Augmented reality","augmented reality;computer aided instruction;handicapped aids;human computer interaction;teaching;user experience","AR-based educational environment;user experience;special needs;mobile-based augmented reality;augmented reality technology;children","","2","","20","IEEE","1 Feb 2021","","","IEEE","IEEE Conferences"
"Views, alignment and incongruity in indirect augmented reality","G. Liestøl; A. Morrison","Department of Media & Communication, University of Oslo, Norway; Centre for Design Research, Oslo School of Architecture and Design","2013 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","19 Dec 2013","2013","","","23","28","Alignment between the real and the virtual has been a defining quality of mixed and augmented reality. With the emergence of Indirect Augmented Reality the problem of alignment is no longer primarily concerned with the relationship between a live video feed and a 3D graphics layer at the level of the screen, but with the relationship between the visual information on the display and the real world perspective outside the display of the device. Experiments show that users easily connect the perspective into the 3D virtual environment on the full screen with their parallel perspective in the real world. It also turns out that although congruence and alignment between the two perspectives is fundamental to the user experience, in certain contexts it may be transcended. This paper describes and discusses applications of Indirect Augmented Reality where we explore how the discrepancy between the virtual and the real perspectives in a variety of ways can be used to improve the user experience. We call these features views. The views will be exemplified with several Indirect Augmented Reality applications: reconstructions of Augustus' Forum and the Republican Forum in Rome and a preconstruction of the planned National Museum in Oslo. The applications have been tested with users on location, and their feedback and evaluation is included in the discussion. Finally, we relate the experiential value of the views to some epistemological and pedagogical perspectives.","2381-8360","978-1-4799-2945-0","10.1109/ISMAR-AMH.2013.6671263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671263","Indirect Augmented Reality;Situated Simulations;sitsim;Views;situated learning","Augmented reality;Cameras;Context;Three-dimensional displays;Visualization;Media","augmented reality;computer graphics","indirect augmented reality;mixed reality;video feed;3D graphics layer;visual information;3D virtual environment;full screen;parallel perspective;republican forum;Rome;national museum;Oslo","","10","","17","IEEE","19 Dec 2013","","","IEEE","IEEE Conferences"
"Identifying Accessibility Conditions for Children with Multiple Disabilities: A Virtual Reality Wheelchair Simulator","N. Rodriguez",L1RMM - University of Montpellier - CNRS,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","370","372","Training is one of the main domain applications of Virtual Reality (VR). Simulation and visual realism provide training situations very close to practice with real systems while reducing cost and with greater safety. Furthermore, VR offers the possibility of change time or space scales, visualize from different perspectives, experience inaccessible real environments, all under the user's control, without risks, at her own pace. This allows to develop skills and to have confidence to work thereafter in real conditions with real equipment. Interaction technologies are now more widely available and affordable. But generally devices are conceived for “standard” people leaving behind people with impairments and further accentuating the digital gap. In this paper, we present our work in the development of an accessible wheelchair simulator designed to allow children with multiple disabilities to familiarize themselves with the wheelchair, and practitioners to better understand children capabilities.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699276","virtual reality;simulator;disability;multiple disabilities;wheelchair;learning;augmented and alternative communication;interaction devices;I.3.1 [Computer Graphics]: Hardware Architecture — Input devices;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism – Virtual reality;H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces And Presentation]: User Interfaces — Input devices and strategies","Wheelchairs;Virtual reality;Tools;Solid modeling;Visualization;Games;Adaptation models","computer based training;computer simulation;handicapped aids;virtual reality;wheelchairs","accessibility conditions;VR;visual realism;interaction technologies;accessible wheelchair simulator;virtual reality wheelchair simulator;children with multiple disabilities","","1","","12","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Subjective Evaluation of Egocentric Human Segmentation for Mixed Reality","E. González-Sosa; P. Perez-Garcia; D. Gonzalez-Morin; A. Villegas","Nokia Bell Labs, Madrid, Spain; Nokia Bell Labs, Madrid, Spain; Nokia Bell Labs, Madrid, Spain; Nokia Bell Labs, Madrid, Spain","2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","22 Dec 2021","2021","","","232","236","Augmented Virtuality (AV) represents the combination of an immersive environment and a selection of the egocentric local reality. The latter is carried out by applying a particular image segmentation method selected according to the specific application requirements. These image segmentation algorithms can be evaluated from a computer vision perspective using traditional quantitative metrics such as Intersection over Union (1oU), Pixel Accuracy (PA), among others. As AV applications are designed to create experiences for real users, it is also desired to bare in mind their subjective feedback. Thus, in this work we compare segmentation methods from a perceptual point of view, by conducting subjective experiments with a group of users. Subsequently, we compare obtained perceptual results with algorithmic metrics, showing a significant correlation between them. However, we also found subtle differences that could influence decision-making.","","978-1-6654-3225-2","10.1109/AIVR52153.2021.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644385","Semantic segmentation;mixed reality;egocentric;QoE;user experience;augmented virtuality","Measurement;Image segmentation;Computer vision;Correlation;Augmented virtuality;Conferences;Semantics","augmented reality;computer vision;decision making;image segmentation;virtual reality","Pixel Accuracy;AV applications;subjective feedback;segmentation methods;subjective experiments;perceptual results;algorithmic metrics;subjective evaluation;egocentric human segmentation;mixed reality;Augmented Virtuality;immersive environment;egocentric local reality;particular image segmentation method;specific application requirements;image segmentation algorithms;computer vision perspective;traditional quantitative metrics;Union","","2","","16","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Tutorial 2: Developing Virtual Reality applications with the Visualization Toolkit (VTK)","L. Gandel; J. Jomier",NA; NA,"2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","xxxi","xxxi","The aim of this tutorial is to provide an introduction to the recent features added to the Visualization Toolkit (VTK) that now allows for rendering in external immersive environment. An introduction to VTK will be given in order to explain the basics and how to create visualization applications, followed by a description of modules allowing you to take your application into virtual reality (VR). The last part of the tutorial will focus on interactions by presenting different ways to interact in a VR environment using the VTK pipeline. The aim is for attendees to be able to build their first application in VR using VTK. They will get strong knowledge on a cross-platform, open-source and freely available system software. By taking more people into the VTK-VR loop, we hope to make mixed and augmented reality benefit more from VTK's advanced visualization, processing and modeling techniques, such as volume rendering or point cloud visualization.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088434","","Virtual reality","augmented reality;data visualisation;public domain software;rendering (computer graphics)","VR environment;VTK-VR loop;volume rendering;virtual reality applications;visualization toolkit;mixed reality;augmented reality;cross-platform software;open-source software","","1","","","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Pose Estimation and Non-Rigid Registration for Augmented Reality During Neurosurgery","N. Haouchine; P. Juvekar; M. Nercessian; W. M. Wells III; A. Golby; S. Frisken","Harvard Medical School and the Department of Radiology at Brigham and Women’s Hospital, Boston, MA 02115, USA; Harvard Medical School and the Department of Neurosurgery at Brigham and Women’s Hospital, USA; Cornell University, Ithaca, NY, USA; Massachusetts Institute of Technology, Harvard Medical School and the Department of Radiology at Brigham and Women’s Hospital, USA; Harvard Medical School and the Department of Neurosurgery at Brigham and Women’s Hospital, USA; Harvard Medical School and the Department of Radiology at Brigham and Women’s Hospital, USA","IEEE Transactions on Biomedical Engineering","18 Mar 2022","2022","69","4","1310","1317","Objective: A craniotomy is the removal of a part of the skull to allow surgeons to have access to the brain and treat tumors. When accessing the brain, a tissue deformation occurs and can negatively influence the surgical procedure outcome. In this work, we present a novel Augmented Reality neurosurgical system to superimpose pre-operative 3D meshes derived from MRI onto a view of the brain surface acquired during surgery. Methods: Our method uses cortical vessels as main features to drive a rigid then non-rigid 3D/2D registration. We first use a feature extractor network to produce probability maps that are fed to a pose estimator network to infer the 6-DoF rigid pose. Then, to account for brain deformation, we add a non-rigid refinement step formulated as a Shape-from-Template problem using physics-based constraints that helps propagate the deformation to sub-cortical level and update tumor location. Results: We tested our method retrospectively on 6 clinical datasets and obtained low pose error, and showed using synthetic dataset that considerable brain shift compensation and low TRE can be achieved at cortical and sub-cortical levels. Conclusion: The results show that our solution achieved accuracy below the actual clinical errors demonstrating the feasibility of practical use of our system. Significance: This work shows that we can provide coherent Augmented Reality visualization of 3D cortical vessels observed through the craniotomy using a single camera view and that cortical vessels provide strong features for performing both rigid and non-rigid registration.","1558-2531","","10.1109/TBME.2021.3113841","National Institutes of Health(grant numbers:R01 EB027134-01,R01 NS049251); BWH Radiology Department Research Pilot; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9541257","Augmented reality;image-guided intervention;pose estimation;registration;neurosurgery","Brain;Visualization;Three-dimensional displays;Pose estimation;Feature extraction;Neurosurgery;Augmented reality","augmented reality;biomechanics;biomedical MRI;brain;cameras;deformation;feature extraction;image registration;medical image processing;neurophysiology;pose estimation;surgery;tumours","pose estimator network;brain deformation;nonrigid refinement step;Shape-from-Template problem;sub-cortical level;tumor location;6 clinical datasets;considerable brain shift compensation;coherent Augmented Reality visualization;cortical vessels;craniotomy;nonrigid registration;pose estimation;tissue deformation;surgical procedure outcome;novel Augmented Reality neurosurgical system;pre-operative 3D meshes;brain surface;feature extractor network","Augmented Reality;Brain;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Neurosurgery;Retrospective Studies;Surgery, Computer-Assisted","4","","31","IEEE","20 Sep 2021","","","IEEE","IEEE Journals"
"“Never Blind VR” enhancing the virtual reality headset experience with augmented virtuality","D. Nahon; G. Subileau; B. Capel","Dassault Systèmes, Immersive Virtuality (iV) Lab; Dassault Systèmes, Immersive Virtuality (iV) Lab; Dassault Systèmes, Immersive Virtuality (iV) Lab","2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","347","348","In this demo, we share our findings in building real-time 3D experiences with consumer headsets so as to go beyond the first person shooter gaming usage for which they are designed. We address the key problems of such user experiences which are to isolate the user from his own body, have him lose contact with other people in the room and with the real world. To solve those issues we use an off-the-shelf Kinect for Windows v2 to inject some reality in the virtuality. A video describing the demo is available here [1].","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223438","Augmented Virtuality;Immersive User Experience;Head Mounted Display;Kinect","Three-dimensional displays;Technological innovation;Headphones;Augmented virtuality;Buildings;Cable TV","augmented reality;computer games;helmet mounted displays","never blind VR;virtual reality headset experience;augmented virtuality;real-time 3D experiences;consumer headsets;off-the-shelf Kinect;Windows v2;head mounted display","","8","4","4","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"[POSTER] Feasibility of Corneal Imaging for Handheld Augmented Reality","D. Schneider; J. Grubert",Coburg University; Coburg University,"2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","44","45","Smartphones are a popular device class for mobile Augmented Reality but suffer from a limited input space. Around-device interaction techniques aim at extending this input space using various sensing modalities. In this paper we present our work towards extending the input area of mobile devices using front-facing device-centered cameras that capture reflections in the cornea. As current generation mobile devices lack high resolution front-facing cameras, we study the feasibility of around-device interaction using corneal reflective imaging based on a high resolution camera. We present a workflow, a technical prototype and a feasibility evaluation.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088446","","Cameras;Mobile handsets;Image resolution;Mobile communication;Cornea;Pipelines","augmented reality;cameras;eye;mobile computing;smart phones","corneal imaging;smartphones;high resolution front-facing cameras;corneal reflective imaging;high resolution camera;mobile augmented reality;mobile devices;handheld augmented reality","","1","","10","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Mobile Based Augmented Reality to Improve Learning of Volcanology for High School Students","H. Akhmalludin; M. A. Ayu","Department of Computer Science, Sampoerna University, Jakarta, Indonesia; Department of Computer Science, Sampoerna University, Jakarta, Indonesia","2019 5th International Conference on Computing Engineering and Design (ICCED)","6 Aug 2020","2019","","","1","6","Augmented Reality (AR) has become popularly used in various fields nowadays. One of the areas that utilized this recent technology is education. This paper presents a study on the use of Augmented Reality to improve students' performance in learning a complicated subject. In this paper, a proposed application was created as a tool for teaching and learning volcanology as part of Geography subject where many students showed weak performance in it. An experimental study and user-based testing were performed to see whether the proposed AR application could really benefit the teaching and learning toward increasing students' understanding of the subject. Pre-test and post-test were conducted and the results are encouraging. The tests' results revealed that the proposed mobile-based AR application is more proficient in improving students' performance than the traditional method.","","978-1-7281-2094-2","10.1109/ICCED46541.2019.9161130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9161130","Reality;Volcanology;mobile-based AR;AR in education;Vuforia;Unity","Augmented reality;Geography;Tools;Education;Volcanoes;Three-dimensional displays;Solid modeling","augmented reality;computer aided instruction;geography;mobile learning;teaching;volcanology","Geography subject;user-based testing;teaching;high school students;mobile based augmented reality;volcanology learning;mobile-based AR application;student performance","","1","","16","IEEE","6 Aug 2020","","","IEEE","IEEE Conferences"
"A 3D Reconstruction Method for Augmented Reality Sandbox Based on Depth Sensor","X. Wang; Q. Chen; Z. Li",Shanghai Branch of National Computer network Emergency Response technical Team/Coordination Center of China; Shanghai Branch of National Computer network Emergency Response technical Team/Coordination Center of China; Shanghai Branch of National Computer network Emergency Response technical Team/Coordination Center of China,"2021 IEEE 2nd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)","3 Feb 2022","2021","2","","844","849","This paper builds an Augmented Reality Sandbox (AR Sandbox) system based on augmented reality technology, and performs a 3D reconstruction for the sandbox terrain using the depth sensor Microsoft Kinect in the AR Sandbox, as an entry point to pave the way for later development of related metaverse applications, such as the metaverse architecting and visual interactive modeling. The innovation of this paper is that for the AR Sandbox scene, a 3D reconstruction method based on depth sensor is proposed, which can automatically cut off the edge of the sandbox table in Kinect field of view, and accurately and completely reconstruct the sandbox terrain in Matlab.","","978-1-6654-2877-4","10.1109/ICIBA52610.2021.9687867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687867","augmented reality;depth sensor;3D reconstruction;Augmented Reality Sandbox;Microsoft Kinect;terrain reconstruction","Visualization;Solid modeling;Technological innovation;Three-dimensional displays;Conferences;Europe;Data models","augmented reality;image reconstruction;image sensors;virtual reality","related metaverse applications;AR Sandbox scene;3D reconstruction method;sandbox table;sandbox terrain;Augmented Reality Sandbox system;augmented reality technology;depth sensor Microsoft Kinect","","","","9","IEEE","3 Feb 2022","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality Animals in Smart and Playful Cities: (Invited Paper)","A. Nijholt","University of Twente, Enschede, the Netherlands","2020 Joint 9th International Conference on Informatics, Electronics & Vision (ICIEV) and 2020 4th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)","7 Jan 2021","2020","","","1","7","Our future urban environments are smart. Sensors and actuators are embedded in these environments and their inhabitants. We have an Internet of Things, where the `Things' include objects, cars, tools, buildings, street furniture, and whatever can be equipped with sensors and actuators, including human and non-human animals. Augmented humans and augmented animals have their senses extended with digital technology. Their smart wearables connected with the smart environment make humans and animals smarter. Rather than on living animals, in this survey paper we focus on non-living virtual and augmented reality non-human animals that will inhabit our smart and playable urban environments. They will co-exist with robotic animals and (digitally augmented) humans and non-human animals. We include observations on augmented humans interacting with virtual and augmented reality animals. The paper is meant to raise awareness for the possibilities of augmented reality to introduce virtual animals for social, entertainment, and educational reasons.","","978-1-7281-9331-1","10.1109/ICIEVicIVPR48672.2020.9306528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306528","animal-computer interaction;augmented humans;augmented animals;virtual animals;augmented reality;smart cities;playable cities;entertainment technology;sensors;actuators;street furniture","Animals;Urban areas;Augmented reality;Dogs;Actuators;Smart cities;Intelligent sensors","augmented reality;computer animation;virtual reality","augmented reality;future urban environments;actuators;Internet of Things;street furniture;sensors;nonhuman animals;augmented humans;augmented animals;smart wearables;smart environment;living animals;smart environments;playable urban environments;robotic animals;virtual animals","","3","","13","IEEE","7 Jan 2021","","","IEEE","IEEE Conferences"
"Augmenting Human Perception: Mediation of Extrasensory Signals in Head-Worn Augmented Reality","A. Erickson; D. Reiners; G. Bruder; G. F. Welch","University of Central Florida, Orlando, Florida, United States; University of Central Florida, Orlando, Florida, United States; University of Central Florida, Orlando, Florida, United States; University of Central Florida, Orlando, Florida, United States","2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","3 Nov 2021","2021","","","373","377","Mediated perception systems are systems in which sensory signals from the user’s environment are mediated to the user’s sensory channels. This type of system has great potential for enhancing the perception of the user via augmenting and/or diminishing incoming sensory signals according to the user’s context, preferences, and perceptual capability. They also allow for extending the perception of the user to enable them to sense signals typically imperceivable to human senses, such as regions of the electromagnetic spectrum beyond visible light.In this paper, we present a prototype mediated perception system that maps extrasensory spatial data into visible light displayed within an augmented reality (AR) optical see-through head-mounted display (OST-HMD). Although the system is generalized such that it could support any spatial sensor data with minor modification, we chose to test the system using thermal infrared sensors. This system improves upon previous extended perception augmented reality prototypes in that it is capable of projecting registered egocentric sensor data in real time onto a 3D mesh generated by the OST-HMD that is representative of the user’s environment. We present the lessons learned through iterative improvements to the system, as well as a performance analysis of the system and recommendations for future work.","","978-1-6654-1298-8","10.1109/ISMAR-Adjunct54149.2021.00085","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585835","Computing methodologies;Computer graphics;Graphics systems and interfaces;Mixed / augmented reality;Human-centered computing;Visualization;Visualization systems and tools","Optical filters;Three-dimensional displays;Prototypes;Thermal sensors;Tools;Spatial databases;Real-time systems","augmented reality;helmet mounted displays;mesh generation","spatial sensor data;previous extended perception augmented reality prototypes;augmenting human perception;mediation;extrasensory signals;head-worn augmented reality;mediated perception systems;sensory channels;incoming sensory signals;human senses;visible light;prototype mediated perception system;maps extrasensory spatial data;head-mounted display","","","","12","IEEE","3 Nov 2021","","","IEEE","IEEE Conferences"
"Cognitive Aspects of Interaction in Virtual and Augmented Reality Systems (CAIVARS)","",,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","xxxiii","xxxiii","Augmented (AR) and Virtual Reality (VR) systems are designed to immerse humans into rich and compelling simulated environments by leveraging our perceptual systems (i.e. vision, touch, sound). In turn, exposure to AR/VR can reshape and alter our perceptual processing by tapping into the brain's significant ability to adapt to changes in the environment through neural plasticity. Therefore, to design successful AR/VR systems, we must first understand the functioning and limitations of our perceptual and cognitive systems. We can then tailor AR/VR technology to optimally stimulate our senses and maximize user experience. Understanding how to wield AR/VR tools to reshape how we perceive the world also has incredible potential for societal and clinical applications.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699302","","User experience;Tutorials;Virtual environments;Neuroplasticity;Machine vision;Entertainment industry;Cognitive systems","augmented reality;brain;cognitive systems","perceptual systems;perceptual processing;brain;neural plasticity;cognitive systems;augmented reality systems;virtual reality systems","","","","","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"ARWand: Phone-Based 3D Object Manipulation in Augmented Reality Environment","T. Ha; W. Woo","GIST U VR Laboratory, South Korea; GIST U VR Laboratory, South Korea","2011 International Symposium on Ubiquitous Virtual Reality","3 Nov 2011","2011","","","44","47","In this paper, we suggest a mobile phone-based indirect 3D object manipulation method that uses sensor information in an augmented reality environment. Specifically, we propose 1) a method that exploits a 2D touch screen, a 3DOF accelerometer, and compass sensors information to manipulate 3D objects in 3D space, 2) design transfer functions to map the control space of mobile phones to an augmented reality (AR) display space, and 3) confirm the feasibility of the transfer functions by implementation. Our work could be applicable to the design and implementation of a future mobile phone-based 3D user interface for AR application in normal indoor and outdoor environments without any special tracking installations.","","978-1-4577-0356-0","10.1109/ISUVR.2011.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6068304","Augmented reality;HMD-based wearable computing;3D object manipulation;sensor based interaction;mobile phone","Three dimensional displays;Mobile handsets;Vectors;Aerospace electronics;Transfer functions;Equations;Mathematical model","augmented reality;helmet mounted displays;mobile computing;mobile handsets;object tracking;sensor fusion;solid modelling;touch sensitive screens;transfer functions;user interfaces","ARWand;mobile phone-based indirect 3D object manipulation method;sensor information;2D touch screen;3DOF accelerometer;compass sensors;transfer functions;augmented reality display space;mobile phone-based 3D user interface;tracking installations","","16","","10","IEEE","3 Nov 2011","","","IEEE","IEEE Conferences"
"A Projection-based AR system to display brain angiography via Stereo Vision","J. -D. Lee; H. -K. Wu; C. -T. Wu","Department of Neurosurgery, Chang Gung Memorial Hospital at LinKou, Taoyuan, Taiwan; Department of Electrical Engineering, Chang Gung University, Taoyuan, Taiwan; Department of Neurosurgery and Medical Augmented Reality Research Center, Chang Gung Memorial Hospital, Tao-Yuan, Taiwan","2018 IEEE 7th Global Conference on Consumer Electronics (GCCE)","13 Dec 2018","2018","","","130","131","In this paper, a projector-based augmented reality (AR) system to display segmented brain angiography is proposed. Firstly, this scheme employed an adaptive algorithm to find the optimal threshold to segment the computer tomography's (CT) vascular image. Then, with the help of computer vision technology, the geometrical relationship between the facial data and the CT's angiography information is derived, and the registration process is executed. When the image registration is finished, the correct location of the vascular image is obtained. Since the surface of the head is irregular, directly project the uncorrected CT angiography images on the surface will be deformed. To alleviate this problem, we employed a projector to project a set of lines on the head, and then a camera is used to capture these lines to derive the correction information required for surface deformation. Finally, the vascular image after deformation correction is projected on the head to provide the doctors as a reference.","2378-8143","978-1-5386-6309-7","10.1109/GCCE.2018.8574761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8574761","augmented reality;projector-based","Computed tomography;Head;Augmented reality;Surgery;Three-dimensional displays;Stereo vision;Image segmentation","angiocardiography;augmented reality;brain;computer vision;computerised tomography;diagnostic radiography;image reconstruction;image registration;image segmentation;medical image processing;stereo image processing","projection-based AR system;Stereo Vision;projector-based augmented reality system;segmented brain angiography;adaptive algorithm;optimal threshold;computer tomography;computer vision technology;geometrical relationship;facial data;CT's angiography information;registration process;image registration;correct location;vascular image;uncorrected CT angiography images;correction information;surface deformation;deformation correction","","3","","5","IEEE","13 Dec 2018","","","IEEE","IEEE Conferences"
"Distance Estimation with Mobile Augmented Reality in Action Space: Effects of Animated Cues","S. Chakraborty; J. K. Stefanucci; S. Creem-Regehr; B. Bodenheimer","Vanderbilt University, USA; University of Utah, USA; University of Utah, USA; Vanderbilt University, USA","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","144","147","Augmented reality is standard on many modern smartphone platforms. The distance of virtual objects seen through the smartphone display should be perceived accurately for easy interaction with virtual objects with high fidelity. We investigate whether distance perception through mobile augmented reality devices is affected by an animated avatar. The avatar walks and is positioned from near to far action space. We conduct a distributed experiment ""in the wild"" to investigate these effects.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00034","National Science Foundation; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419174","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Augmented reality;Collaborative interaction","Legged locomotion;Three-dimensional displays;Avatars;Conferences;Estimation;User interfaces;Aerospace electronics","augmented reality;avatars;mobile computing;smart phones","distance estimation;action space;animated cues;modern smartphone platforms;virtual objects;smartphone display;easy interaction;distance perception;mobile augmented reality devices;animated avatar","","1","","21","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Spatial augmented reality for environmentally-lit real-world objects","A. J. Law; D. G. Aliaga","Department of Computer Science, Purdue University, USA; Department of Computer Science, Purdue University, USA","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","7","10","One augmented reality approach is to use digital projectors to alter the appearance of a physical scene, avoiding the need for head-mounted displays or special goggles. Instead, spatial augmented reality (SAR) systems depend on having sufficient light radiance to compensate the surface's colors to those of a target visualization. However, standard SAR systems in dark room settings may suffer from insufficient light radiance causing bright colors to exhibit unexpected color shifts, resulting in a misleading visualization. We introduce a SAR framework which focuses on minimally altering the appearance of arbitrarily shaped and colored objects to exploit the presence of environment/room light as an additional light source to achieve compliancy for bright colors. While previous approaches have compensated for environment light, none have explicitly exploited the environment light to achieve bright, previously incompliant colors. We implement a full working system and compared our results to solutions achievable with standard SAR systems.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180867","spatial-augmented reality;projector-based displays;interaction design;mobile and ubiquitous visualization","Visualization;Image color analysis;Color;Lighting;Mathematical model;Equations;Radiometry","augmented reality;brightness;data visualisation;optical projectors","spatial augmented reality approach;environmentally-lit real-world objects;digital projectors;physical scene appearance;head-mounted displays;goggles;sufficient light radiance;surface color compensation;target visualization;standard SAR systems;dark room settings;unexpected color shifts;arbitrarily shaped objects;colored objects","","1","","22","IEEE","12 Apr 2012","","","IEEE","IEEE Conferences"
"KARLI: Kid-friendly Augmented Reality for Primary School Health Education","M. Seel; M. Andorfer; M. Heller; A. Jakl","Institute of Creative\Media/Technologies, University of Applied Sciences, St. Pölten, Austria; Institute of Creative\Media/Technologies, University of Applied Sciences, St. Pölten, Austria; Institute of Creative\Media/Technologies, University of Applied Sciences, St. Pölten, Austria; Institute of Creative\Media/Technologies, University of Applied Sciences, St. Pölten, Austria","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","610","611","Acquiring health knowledge is essential and starts already in primary school. Augmented Reality (AR) helps to convey complex topics in a more understandable way. In this paper, we present the prototype of KARLI, the “Kid-friendly Augmented Reality Learning Interface”. This AR smartphone app for in-school use is designed for age level 8 to 10, enabling pupils to explore a 3D model of the human body based on the primary school curriculum. Underlining the importance of kid-friendly app development and testing, our evaluation results of 38 pupils and 3 teachers indicate that KARLI is suitable and helpful for health education in primary schools.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757475","Human-centered computing—Mixed / augmented reality Human-centered computing—Usability testing Applied computing—Education—Collaborative learning Social and professional topics—User characteristics—Age—Children","Solid modeling;Three-dimensional displays;Conferences;Biological system modeling;Prototypes;User interfaces;Pupils","augmented reality;computer aided instruction;smart phones","complex topics;KARLI;Kid-friendly Augmented Reality Learning Interface;in-school use;primary school curriculum;kid-friendly app development;primary school health education;health knowledge","","1","","11","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Add-on Occlusion: An External Module for Optical See-through Augmented Reality Displays to Support Mutual Occlusion","Y. Zhang; K. Kiyokawa; N. Lsoyama; H. Uchiyama; X. Yang",Nara Institute of Science and Technology; Nara Institute of Science and Technology; Nara Institute of Science and Technology; Nara Institute of Science and Technology; Shanghai Jiao Tong University,"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","800","801","The occlusion function benefits augmented reality (AR) in many aspects. However, existing occlusion-capable optical see-through augmented reality (OC-OST-AR) displays are designed by integrating virtual displays into a dedicated occlusion-capable architecture, hereby, we miss merits from emerging OST-AR displays. In this article, we propose an external occlusion module that can be added to common OST-AR displays. Per-pixel occlusion is supported with a small form-factor by using polarization-based optical path compression. The occlusion function can be switched on/off by controlling the incident light polarization. A prototype within a volume of $6\times 6\times 3\text{cm}$ is built. A preliminary experiment proves that occlusion is realized successfully.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757695","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality;Hardware—Emerging technologies—Emerging optical and photonic technologies","Optical polarization;Three-dimensional displays;Conferences;Optical switches;Prototypes;User interfaces;Optical imaging","augmented reality;hidden feature removal;light polarisation","mutual occlusion;virtual displays;external occlusion module;per-pixel occlusion;polarization-based optical path compression;add-on occlusion;occlusion-capable optical see-through augmented reality displays;OC-OST-AR displays;form-factor;incident light polarization","","","","8","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Augmented Reality as Didactic Strategy for Facilitate the Learning of the Solar System","A. D. M. Acosta; S. A. S. Hernandez; J. C. G. Henao","Engineering Faculty Corposucre, Sincelejo, Colombia; Engineering Faculty Corposucre, Sincelejo, Colombia; Engineering Faculty Corposucre, Sincelejo, Colombia","2020 IEEE Games, Multimedia, Animation and Multiple Realities Conference (GMAX)","18 Nov 2020","2020","","","1","4","The globalization of knowledge, the information society, the emergence of new information and communication technologies, have generated new ways of working, challenging education institutions a change in their ability to adapt and a better information management. Among the emerging technologies of recent decades, we can find a high increase of augmented reality (AR), which is a set of technologies that allow the user to visualize virtual information in real-world scenarios, through a digital camera of a device mobile. This feature makes this technology attractive in the educational field for topics where observation is a key element in the student's learning process. For this reason, the objective of this research is to develop a prototype using augmented reality as a didactic strategy to strengthen the concepts of the Solar System in the area of Social Sciences for the sixth grade of secondary school of the San Vicente de Paul Educational Institution. To accomplish the objective, the research was carried out in four stages using the extreme programming methodology. From the results obtained it is concluded that the minimum requirements that a mobile device must have to use the (AR) application, are marked in mid-range devices, accessible for both, teachers and students community, it can also be argued that the technological tools in the classroom have allowed to add a added value to the educational processes, generating motivation and interest in studies by students.","","978-1-7281-6147-1","10.1109/GMAX49668.2020.9256839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256839","Augmented Reality (AR);Solar System;Technology;Prototype;Learning","Prototypes;Planets;Planetary orbits;Orbits;Education;Three-dimensional displays;Tools","astronomy computing;augmented reality;computer aided instruction;data visualisation;educational institutions;mobile learning;solar system","didactic strategy;solar system learning;San Vicente de Paul Educational Institution;mobile device;educational processes;augmented reality;information and communication technologies;education institutions;information management;educational field;student learning process;virtual information visualization","","","","9","IEEE","18 Nov 2020","","","IEEE","IEEE Conferences"
"EIT-based Gesture Recognition Training with Augmented Reality","C. Gießer; C. Gibas; A. Gruenewald; T. J. Eiler; V. Schmuecker; R. Brueck","Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany; Medical Informatics and Microsys. Eng., University of Siegen, Siegen, Germany","2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","22 Dec 2021","2021","","","198","200","Electrical impedance tomography (EIT) combined with artificial intelligence (AI) methods is suitable for recognizing gestures that can be used to control prostheses for disabled people. In this work, augmented reality (AR) is used to visualize gestures so that a neural network can be trained using EIT data. The aim is to create an AI that is as general and person-independent as possible. Person-specific differences should be automatically recognized and negated by a calibration process. The use of augmented reality helps to improve the AI-based training process on the basis of EIT data. Users work in an environment that is natural to them and are not distracted or confused by menus or complicated programs.","","978-1-6654-3225-2","10.1109/AIVR52153.2021.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644348","Artificial Intelligence;Augmented Reality;Electrical Impedance Tomography;Magic Leap;Prosthesis Control","Training;Electrical impedance tomography;Conferences;Neural networks;Data visualization;Gesture recognition;Calibration","artificial intelligence;augmented reality;electric impedance imaging;gesture recognition;handicapped aids;neural nets","EIT data;person-specific differences;augmented reality;AI-based training process;EIT-based gesture recognition training;electrical impedance tomography;artificial intelligence methods;disabled people;neural network;calibration process","","","","3","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Designing Sound Synthesis Interfaces for Head-mounted Augmented Reality","Y. Wang; C. Martin","School of Computing, The Australian National University; School of Computing, The Australian National University","2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","20 Apr 2022","2022","","","351","353","We report on designing a sound synthesis interface for a head-mounted augmented reality environment. The increased accessibility of augmented reality (AR) devices has incentivised the exploration of sound applications for music performance in computer music and other relevant communities. However, interaction affordances vary based on the specific AR device and thus implies different design considerations. In this poster, we present different interface prototypes for a frequency modulation synthesis system in the Microsoft HoloLens 2 and report our insights during the process of their developments.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757512","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed/augmented reality;Applied computing—Arts and humanities—Sound and music computing","Performance evaluation;Three-dimensional displays;Frequency modulation;Conferences;Affordances;Music;Prototypes","audio signal processing;augmented reality;frequency modulation;helmet mounted displays","design considerations;interface prototypes;frequency modulation synthesis system;head-mounted augmented reality;sound synthesis interfaces designing","","","","11","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Collocated learning experience within collaborative augmented environment (anatomy course)","S. Touel; M. Mekkadem; M. Kenoui; S. Benbelkacem","University of Boumerdes, Boumerdes, Algeria; University of Boumerdes, Boumerdes, Algeria; Centre de Développement des Technologies Avancées CDTA, Algiers, Algeria; Centre de Développement des Technologies Avancées CDTA, Algiers, Algeria","2017 5th International Conference on Electrical Engineering - Boumerdes (ICEE-B)","14 Dec 2017","2017","","","1","5","Nowadays, collaborative systems and applications are widely used to allow multiple users to work together in order to achieve one same goal. In the field of virtual and augmented realities, such collaboration is often sought to effectuate complex activities in some relevant experiences. Users can share virtual objects, but most importantly, they use collaborative 3D interaction, visualize their objects manipulation in real time and communicate with each other to coordinate their actions efficiently. These users will, therefore, be able to work together in a shared virtual environment to carry out different tasks. In this paper, we present our work related to the design and implementation of a collaborative augmented system, our application introduces a multi-users experience in a face-to-face configuration and can be used by the students in anatomy course.","","978-1-5386-0686-5","10.1109/ICEE-B.2017.8192219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8192219","Augmented reality;Collaborative environment;Learning application;Anatomy course","Three-dimensional displays;Augmented reality;Collaboration;Visualization;Protocols;Games;Servers","augmented reality;computer aided instruction;educational courses;groupware;human factors","augmented realities;virtual objects;collaborative 3D interaction;objects manipulation;shared virtual environment;collaborative augmented system;multiusers experience;anatomy course;collocated learning experience;collaborative augmented environment;collaborative systems;virtual realities","","8","","23","IEEE","14 Dec 2017","","","IEEE","IEEE Conferences"
"3D Reconstruction and Visual SLAM of Indoor Scenes for Augmented Reality Application","Y. -J. Yeh; H. -Y. Lin","Department of Electrical Engineering, National Chung Cheng University, Chiayi, Taiwan; Department of Electrical Engineering and Advanced Institute of Manufacturing with High-Tech Innovation, National Chung Cheng University, Chiayi, Taiwan","2018 IEEE 14th International Conference on Control and Automation (ICCA)","23 Aug 2018","2018","","","94","99","The indoor environments are usually considered as GPS-denied areas, which make the localization of mobile devices a challenging task. The visual SLAM (simultaneous localization and mapping) is a commonly adopted technique for indoor localization and 3D reconstruction. It processes the image information of the scene to derive the location of the camera-equipped device and the 3D structure of the environment. Moreover, many modern mobile devices come with multiple built-in sensors. The integration of multi-sensor information is able to provide more robust localization results compared to the monocular camera based methods. In this paper we implement an indoor augmented reality system based on Project Tango developed by Google. This system is able to construct the 3D environment and reuses the constructed data to relocalize the mobile device. The constructed 3D point cloud can be transformed to the map data, and let the system estimate the navigation path. With the accurate pose estimation provided by Tango, the augmented reality content can keep the original position after a long distance movement.","1948-3457","978-1-5386-6089-8","10.1109/ICCA.2018.8444222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444222","","Three-dimensional displays;Cameras;Augmented reality;Image color analysis;Smart phones;Rendering (computer graphics)","augmented reality;cameras;image reconstruction;mobile computing;pose estimation;sensor fusion;SLAM (robots);stereo image processing","mobile device localization;simultaneous localization and mapping;image information processing;camera-equipped device location;Project Tango;Project Tango;Google;3D environment;pose estimation;augmented reality content;map data;3D point cloud;indoor augmented reality system;robust localization results;multisensor information;indoor localization;GPS-denied areas;indoor environments;augmented reality application;indoor scenes;visual SLAM;3D reconstruction","","7","","17","IEEE","23 Aug 2018","","","IEEE","IEEE Conferences"
"Usability Evaluation of an Augmented Reality Children's Book","V. Farinazzo Martins; G. B. Sanches; N. G. d. Almeida; M. A. Eliseo; A. L. S. Kawamoto","Faculdade de Computaçáo e Informática, Universidade Presbiteriana Mackenzie, Sáo Paulo, Brazil; Faculdade de Computaçáo e Informática, Universidade Presbiteriana Mackenzie, Sáo Paulo, Brazil; Faculdade de Computaçáo e Informática, Universidade Presbiteriana Mackenzie, Sáo Paulo, Brazil; Faculdade de Computaçáo e Informática, Universidade Presbiteriana Mackenzie, Sáo Paulo, Brazil; Departamento Acadêmico de Computaçáo, Universidade Tecnológica Federal do Paraná, Campo Mouráo, Brazil","2019 XIV Latin American Conference on Learning Technologies (LACLO)","13 Feb 2020","2019","","","381","386","This paper aims to contribute to the Augmented Reality area by evaluating a mobile application in books designed for children. Two sets of usability evaluation criteria for Augmented Reality were compiled from two systematic reviews. The first one served as base for a heuristic evaluation, and the second one for a usability evaluation. We also present the entire process of evaluation, as well as the results and discussion.","","978-1-7281-4286-9","10.1109/LACLO49268.2019.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8995062","Augmented Reality, Mobile Devices, Augmented Reality Textbooks, Usability Evaluation","","augmented reality;mobile computing;product design;user interfaces","mobile application;usability evaluation criteria;heuristic evaluation;augmented reality children's book","","1","","","IEEE","13 Feb 2020","","","IEEE","IEEE Conferences"
"Comparing Non-Visual and Visual Guidance Methods for Narrow Field of View Augmented Reality Displays","A. Marquardt; C. Trepkowski; T. D. Eibich; J. Maiero; E. Kruijff; J. Schöning",Bonn-Rhein-Sieg University of Applied Sciences; Bonn-Rhein-Sieg University of Applied Sciences; Bonn-Rhein-Sieg University of Applied Sciences; Bonn-Rhein-Sieg University of Applied Sciences; Bonn-Rhein-Sieg University of Applied Sciences; University of Bremen,"IEEE Transactions on Visualization and Computer Graphics","10 Nov 2020","2020","26","12","3389","3401","Current augmented reality displays still have a very limited field of view compared to the human vision. In order to localize out-of-view objects, researchers have predominantly explored visual guidance approaches to visualize information in the limited (in-view) screen space. Unfortunately, visual conflicts like cluttering or occlusion of information often arise, which can lead to search performance issues and a decreased awareness about the physical environment. In this paper, we compare an innovative non-visual guidance approach based on audio-tactile cues with the state-of-the-art visual guidance technique EyeSee360 for localizing out-of-view objects in augmented reality displays with limited field of view. In our user study, we evaluate both guidance methods in terms of search performance and situation awareness. We show that although audio-tactile guidance is generally slower than the well-performing EyeSee360 in terms of search times, it is on a par regarding the hit rate. Even more so, the audio-tactile method provides a significant improvement in situation awareness compared to the visual approach.","1941-0506","","10.1109/TVCG.2020.3023605","Deutsche Forschungsgemeinschaft(grant numbers:KR 4521/2-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199570","Augmented Reality;view-management;guidance;audio-tactile cues;performance;situation awareness","Visualization;Task analysis;Augmented reality;Navigation;Three-dimensional displays;Search problems","augmented reality;data visualisation","augmented reality displays;human vision;out-of-view objects;visual guidance approaches;search performance issues;nonvisual guidance approach;audio-tactile cues;guidance methods;situation awareness;audio-tactile guidance;audio-tactile method;visual approach;visual guidance technique;EyeSee360 technique","Adult;Augmented Reality;Awareness;Computer Graphics;Cues;Equipment Design;Female;Humans;Male;Middle Aged;Task Performance and Analysis;User-Computer Interface;Virtual Reality;Young Adult","20","","93","IEEE","17 Sep 2020","","","IEEE","IEEE Journals"
"Enhancing First-Person View Task Instruction Videos with Augmented Reality Cues","G. A. Lee; S. Ahn; W. Hoff; M. Billinghurst",University of South Australia; University of South Australia; Colorado School of Mines; University of South Australia,"2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","498","508","This research investigates enhancing first-person view (FPV) task instruction videos by applying Augmented Reality (AR) visualisation of spatial cues. With personal mobile devices, recording and sharing a video clip has become very easy, and how-to videos are becoming popular on social video sharing services. Instructional videos are actively used not only in formal education and training, but also in everyday life. However, video clips are limited to two-dimensional representation of the task space, making it hard for the viewer to follow and match the objects in the video to those in the real world task space. We propose augmenting task instruction videos with AR visualisation of spatial cues to overcome this problem, focusing on creating and viewing FPV instruction videos. We designed and implemented a prototype system, AR Tips, which allows users to capture and share augmented FPV instruction videos on a wearable AR device. We conducted a user study to evaluate the benefit of our approach, and the results showed that with the help of augmented spatial cues users better understood the instructions, performed the tasks faster with fewer errors, and had lower mental effort.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00078","University of South Australia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284669","Augmented Reality;instruction video;task guide","Training;Performance evaluation;Visualization;Prototypes;Task analysis;Augmented reality;Videos","augmented reality;cognition;mobile computing;social networking (online)","first-person view task instruction videos;augmented reality visualisation;personal mobile devices;video clip;social video sharing services;instructional videos;world task space;augmented FPV instruction videos;augmented spatial cues users;AR device;AR Tips;mental effort","","9","","42","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"k-MART: Authoring tool for mixed reality contents","J. Choi; Y. Kim; M. Lee; G. J. Kim; Y. Nam; Y. Kwon","Digital Experience Laboratory, Korea University, Seoul, South Korea; Digital Experience Laboratory, Korea University, Seoul, South Korea; Digital Experience Laboratory, Korea University, Seoul, South Korea; Digital Experience Laboratory, Korea University, Seoul, South Korea; Department of Digital Media, Ewha Womans University, Seoul, South Korea; Imaging Media Research Center, Korea Institute of Science and Technology, Seoul, South Korea","2010 IEEE International Symposium on Mixed and Augmented Reality","22 Nov 2010","2010","","","219","220","In this poster, we present an authoring tool for mixed reality (MR) contents, called k-MART. The tool is comprehensive to accommodate many different types of mixed reality applications and platforms, being able to mix and match different types of contexts and behaviors for content creation. The content is intuitively modeled as a collection of “context-behavior” pairs and saved in a declarative manner to be “played” by a content browser. The tool is designed to minimize user programming and offers many abstractions of functionalities with only important details to be filled in by the user using graphical user interfaces. We believe that our approach has a good potential for the wide dissemination and sharing of MR contents.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643576","Authoring;Mixed Reality;Context;Behavior;Contents","Virtual reality;Context;Three dimensional displays;User interfaces;Standards;Software;Context modeling","augmented reality;authoring systems;graphical user interfaces","k-MART;mixed reality contents;authoring tool;context-behavior pairs;content browser;graphical user interfaces;mixed and augmented reality authoring tool","","7","1","11","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Side-by-Side Comparison of Human Perception and Performance Using Augmented, Hybrid, and Virtual Reality","N. T. Banerjee; A. J. Baughman; S. -Y. Lin; Z. A. Witte; D. M. Klaus; A. P. Anderson","Ann and H.J. Smead Department of Aerospace Engineering Sciences, University of Colorado at Boulder, Boulder, CO, USA; Ann and H.J. Smead Department of Aerospace Engineering Sciences, University of Colorado at Boulder, Boulder, CO, USA; Ann and H.J. Smead Department of Aerospace Engineering Sciences, University of Colorado at Boulder, Boulder, CO, USA; Ann and H.J. Smead Department of Aerospace Engineering Sciences, University of Colorado at Boulder, Boulder, CO, USA; Ann and H.J. Smead Department of Aerospace Engineering Sciences, University of Colorado at Boulder, Boulder, CO, USA; Ann and H.J. Smead Department of Aerospace Engineering Sciences, University of Colorado at Boulder, Boulder, CO, USA","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2022","2022","28","12","4787","4796","Alternative reality (XR) technologies, including physical, augmented, hybrid, and virtual reality, offer ways for engineered spaces to be evaluated. Traditionally, practitioners (such as those designing spacecraft habitats) have relied on physical mockups to perform such design evaluations, but digital XR technologies present several streamlining advantages over their physical counterparts. These digital environments vary in their level of virtuality, and consequently have different effects on human perception and performance, with respect to a completely physical mockup environment. To date, very little has been done to characterize and quantify such differences in human perception and performance across XR environments of equal fidelity for the same end application. Here, we show that perception and performance in the virtual reality environment most closely mirror those in the physical reality environment, as measured through volumetric assessment and functional task experiments. These experiments required subjects to judge the dimensions of 3D objects and perform operational tasks presented via checklists. Our results highlight the potential for virtual reality systems to accelerate the iterative design of engineered spaces relative to the use of physical mockups, while preserving the human perception and performance characteristics of a completely physical environment. These findings also elucidate specific advantages and disadvantages to specific digital XR technologies with respect to one another and the physical reality baseline. Practitioners may inform their selection of an XR modality for their specific end application based on this comparative analysis, as it contextualizes the niche for each technology in the realm of iterative design for engineered spaces.","1941-0506","","10.1109/TVCG.2021.3105606","NASA(grant numbers:80NSSC18K0198); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516987","Artificial;augmented;virtual realities;human-computer interaction;human factors;ergonomics;usability testing;virtual environment modeling","Ergonomics;X reality;Space vehicles;Solid modeling;Virtual environments;Three-dimensional displays;Artificial intelligence;Virtual reality;Augmented reality;Human factors","augmented reality;human computer interaction;solid modelling","alternative reality technologies;completely physical environment;completely physical mockup environment;design evaluations;digital environments;engineered spaces;human perception;iterative design;performance characteristics;physical counterparts;physical mockups;physical reality baseline;physical reality environment;spacecraft habitats;specific digital XR technologies;virtual reality environment;virtual reality systems;XR environments;XR modality","Humans;Computer Graphics;Virtual Reality;User-Computer Interface;Perception","2","","55","IEEE","18 Aug 2021","","","IEEE","IEEE Journals"
"A framework for debating augmented futures: Classifying the visions, promises and ideographs advanced about augmented reality","T. Liao","Department of Communication, Cornell University, USA","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","3","12","While AR is slowly becoming reality, projections about the technology are divided. The direction that AR will take, the form AR will come in, how it should be used and the societal impact it will have are all being contested. With emerging technologies such as AR, these debates occur in a mostly rhetorical space, as positions and visions of the future are advanced. Some of these are also negative visions, arguing against the technology. These communications, arguments, and positions are how the technology is made persuasive to those in and outside the AR community, but have yet to be empirically studied or understood. This study seeks to map out the rhetorical promises that are being made about AR. Through qualitative interviews with a variety of actors in the AR community, this study advances a taxonomy of technological promises, higher order principles that those promises appeal to, and finally the contested characteristic that can change the valence of the vision. This framework will help make the debate about AR clearer, and help people frame their discussions and debates about AR in a more productive way.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483982","Augmented reality;futures;promises;debate;ideographs","Interviews;Augmented reality;Fires;Buildings;Communities;Glass","augmented reality;social sciences","augmented reality;societal impact;rhetorical space;AR community;ideograph classification;rhetorical promises;negative visions;technological promises","","7","1","49","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"The augmented composer project: the music table","R. Berry; M. Makino; N. Hikawa; M. Suzuki","ATR Media Information Science Research Laboratories, Japan; ATR Media Information Science Laboratories; ATR Media Information Science Laboratories; ATR Media Information Science Laboratories","The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.","27 Oct 2003","2003","","","338","339","The music table enables the composition of musical patterns by arranging cards on a tabletop. An overhead camera allows the computer to track the movements and positions of the cards and to provide immediate feedback in the form of music and on-screen computer generated images. Musical structure is experienced as a tangible space enriched with physical and visual cues about the music produced.","","0-7695-2006-5","10.1109/ISMAR.2003.1240749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1240749","","Multiple signal classification;Augmented reality;Instruments;Cameras;Tracking;Feedback;Image generation;Timing;Information science;Laboratories","music;augmented reality;cameras;software tools;computer graphics","augmented composer project;music table;music composition;musical patterns;tabletop;computer generated images;musical structure;physical cues;visual cues;tracking","","7","3","4","IEEE","27 Oct 2003","","","IEEE","IEEE Conferences"
"User-Aided Global Registration Method using Geospatial 3D Data for Large-Scale Mobile Outdoor Augmented Reality","S. Burkard; F. Fuchs-Kittowski","HTW Berlin, University of Applied Science, Germany; HTW Berlin, University of Applied Science, Germany","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","104","109","Accurate global camera registration is a key requirement for precise AR visualizations in large-scale outdoor AR applications. Existing approaches mostly use complex image-based registration methods requiring large pre-registered databases of geo-referenced images or point clouds that are hardly applicable to large-scale areas. In this paper, we present a simple yet effective user-aided registration method that utilizes common geospatial 3D data to globally register mobile devices. For this purpose, text-based 3D geospatial data including digital 3D terrain and city models is processed into small-scale 3D meshes and displayed in a live AR view. Via two common mobile touch gestures the generated virtual models can be aligned manually to match the actual perception of the real-world environment. Experimental results show that - combined with a robust local visual-inertial tracking system - this approach enables an efficient and accurate global registration of mobile devices in various environments determining the camera attitude with less than one degree deviation while achieving a high degree of immersion through realistic occlusion behavior.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00041","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288413","Computing methodologies;Computer graphics;Graphics systems and interfaces;Mixed / augmented reality;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality","Solid modeling;Three-dimensional displays;Urban areas;Cameras;Mobile handsets;Geospatial analysis;Augmented reality","augmented reality;cameras;data visualisation;geophysical image processing;image registration;mobile computing;solid modelling","AR visualizations;large-scale outdoor AR applications;geo-referenced images;mobile devices;text-based 3D geospatial data;city models;small-scale 3D meshes;visual-inertial tracking system;large-scale mobile outdoor augmented reality;user-aided global registration;geospatial 3D data;user-aided registration;global camera registration;digital 3D terrain;live AR view;mobile touch gestures;camera attitude;realistic occlusion behavior","","1","","23","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"A pragmatic approach to augmented reality authoring","M. Haringer; H. T. Regenbrecht","Fachhochschule Ulm, University of Applied Sciences, Ulm, Germany; Research and Technology, Virtual and Augmented Environments, DaimlerChrysler Aerospace, Ulm, Germany","Proceedings. International Symposium on Mixed and Augmented Reality","6 Jan 2003","2002","","","237","245","In this paper we describe the augmented reality (AR) authoring system ""PowerSpace"" which allows fast and comfortable generation of AR worlds. The system presented uses the functionality of a 2D presentation program (Microsoft PowerPoint) as the basis for the composition of 3D content. An MS PowerPoint export is used to generate an XML-based extensible description of a presentation. This description is enriched by 3D content with the help of an editor, which is also part of the PowerSpace system. The content of this presentation is finally converted into 3D scenes and used in an AR-viewer.","","0-7695-1781-1","10.1109/ISMAR.2002.1115093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1115093","","Augmented reality;Layout;Power generation;Rendering (computer graphics);Geometry;Engines;Switches;Authoring systems;Power system modeling;Graphics","augmented reality;authoring systems;hypermedia markup languages","augmented reality authoring;PowerSpace;augmented reality world generation;2D presentation program;Microsoft PowerPoint;3D content composition;XML-based extensible description;editor;3D scenes;augmented reality viewer","","35","1","18","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Immersive authoring of tangible augmented reality applications","G. A. Lee; C. Nelles; M. Billinghurst; G. J. Kim","Virtual Reality Laboratory, Pohang University of Science and Technology, South Korea; Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; Human Interface Technology Laboratory New Zealand, University of Canterbury, New Zealand; Virtual Reality Laboratory, Pohang University of Science and Technology, South Korea","Third IEEE and ACM International Symposium on Mixed and Augmented Reality","24 Jan 2005","2004","","","172","181","In this paper, we suggest a new approach for authoring tangible augmented reality applications, called 'immersive authoring.' The approach allows the user to carry out the authoring tasks within the AR application being built, so that the development and testing of the application can be done concurrently throughout the development process. We describe the functionalities and the interaction design for the proposed authoring system that are specifically targeted for intuitive specification of scenes and various object behaviors. Several cases of applications developed using the authoring system are presented. A small pilot user study was conducted to compare the proposed method to a non-immersive approach, and the results have shown that the users generally found it easier and faster to carry out authoring tasks in the immersive environment.","","0-7695-2191-6","10.1109/ISMAR.2004.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383054","","Augmented reality;Authoring systems;Programming profession;Virtual reality;Testing;Layout;Application software;Software libraries;Humans;Educational programs","augmented reality;authoring systems","immersive authoring;tangible augmented reality;authoring tasks;AR application;interaction design;authoring system;immersive environment","","87","6","21","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"The Virtual Mirror: A New Interaction Paradigm for Augmented Reality Environments","C. Bichlmeier; S. M. Heining; M. Feuerstein; N. Navab","Computer Aided Medical Procedures and Augmented Reality, Department of Computer Science, Technische Universität München, Munchen, Germany; Trauma Surgery Department, Klinikum Innenstadt, Ludwig Maximilians Universität, Munchen, Germany; Department of Media Science, Graduate School of Information Science, University of Nagoya, Japan; Computer Aided Medical Procedures and Augmented Reality, Department of Computer Science, Technische Universität München, Munchen, Germany","IEEE Transactions on Medical Imaging","25 Aug 2009","2009","28","9","1498","1510"," Medical augmented reality (AR) has been widely discussed within the medical imaging as well as computer aided surgery communities. Different systems for exemplary medical applications have been proposed. Some of them produced promising results. One major issue still hindering AR technology to be regularly used in medical applications is the interaction between physician and the superimposed 3-D virtual data. Classical interaction paradigms, for instance with keyboard and mouse, to interact with visualized medical 3-D imaging data are not adequate for an AR environment. This paper introduces the concept of a tangible/controllable Virtual Mirror for medical AR applications. This concept intuitively augments the direct view of the surgeon with all desired views on volumetric medical imaging data registered with the operation site without moving around the operating table or displacing the patient. We selected two medical procedures to demonstrate and evaluate the potentials of the Virtual Mirror for the surgical workflow. Results confirm the intuitiveness of this new paradigm and its perceptive advantages for AR-based computer aided interventions. ","1558-254X","","10.1109/TMI.2009.2018622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4804754","Augmented reality (AR);interactive systems;medical information systems;mirrors;mixed reality;user interface human factors;reflection","Mirrors;Augmented reality;Biomedical imaging;Surgery;Medical services;Biomedical equipment;Keyboards;Mice;Data visualization;Surges","biomedical imaging;medical diagnostic computing;surgery","augmented reality environments;medical augmented reality;tangible-controllable virtual mirror;surgeon;computer aided surgery;surgical workflow;AR-based computer aided interventions","Adult;Female;Humans;Imaging, Three-Dimensional;Liver Neoplasms;Male;Phantoms, Imaging;Spine;Surgery, Computer-Assisted;Surgical Procedures, Minimally Invasive;User-Computer Interface","74","1","57","IEEE","24 Mar 2009","","","IEEE","IEEE Journals"
"Imagination: The third reality to the virtuality continuum","C. Stapleton; J. Davies","Simiosys, Real World Laboratory, Interplay Academy, USA; Institute of Cognitive Science, Science of the Imagination Laboratory, Carleton University, Canada","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","53","60","Both the art and science of the imagination have integral roles in defining compelling Mixed Reality (MR) experiences. In this paper we posit that the audience member's own imagination is an essential third kind of input in defining the full virtuality continuum for MR. It is traditionally accepted that there are two experiential inputs in MR incorporating a combination of stimuli of the real world as well as from virtual artifacts (typically from computers). Using a case study of a MemoryScape Prototype for the Maitland Holocaust Museum, we explore how, in addition to reality and augmented/virtual reality, imagination artistically and scientifically serves as an important third reality to the virtuality continuum to achieve the experience designer's intent for the audience's perception of MR experiences.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093657","Theory;design methodology;augmented reality;mixed reality;virtual reality;imagination;cognitive science;interplay (story, play & game) conventions","Media;Visualization;Augmented reality;Motion pictures;Education;Art","augmented reality;museums","imagination;third reality;virtuality continuum;mixed reality experiences;real world stimuli;virtual artifacts;MemoryScape Prototype;Maitland Holocaust Museum;augmented reality;virtual reality","","5","","24","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Towards a Desktop-AR Prototyping Framework: Prototyping Cross-Reality Between Desktops and Augmented Reality","R. Cools; M. Gottsacker; A. Simeone; G. Bruder; G. Welch; S. Feiner","Department of Computer Science, KU Leuven; Department of Computer Science, KU Leuven; Department of Computer Science, KU Leuven; University of Central Florida; University of Central Florida; Columbia University","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","175","182","Augmented reality (AR) head-worn displays (HWDs) allow users to view and interact with virtual objects anchored in the 3D space around them. These devices extend users' digital interaction space compared to traditional desktop computing environments by both allowing users to interact with a larger virtual display and by affording new interactions (e.g., intuitive 3D manipulations) with virtual content. Yet, 2D desktop displays still have advantages over AR HWDs for common computing tasks and will continue to be used well into the future. Because of their not entirely overlapping set of affordances, AR HWDs and 2D desktops may be useful in a hybrid configuration; that is, users may benefit from being able to work on computing tasks in either environment (or simultaneously in both environments) while transitioning virtual content between them. In support of such computing environments, we propose a prototyping framework for bidirectional Cross-Reality interactions between a desktop and an AR HWD. We further implemented a proof-of-concept seamless Desktop-AR display space, and describe two concrete use cases for our framework. In future work we aim to further develop our proof-of-concept into the proposed framework.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974207","Human-centered computing-Human computer in-teraction (HCI)-Interaction paradigms-Mixed / augmented reality","Three-dimensional displays;Head-mounted displays;Conferences;Affordances;Mice;Space exploration;Task analysis","augmented reality;helmet mounted displays;three-dimensional displays;virtual reality","AR HWD;augmented reality head worn displays;bidirectional cross reality interactions;common computing;intuitive 3D manipulations;larger virtual display;proof-of-concept seamless desktop-AR display space;prototyping cross reality;prototyping framework;traditional desktop computing environments;users digital interaction space;virtual content;virtual objects","","","","37","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Do you remember that building? Exploring old Zakynthos through an augmented reality mobile game","D. Chalvatzaras; N. Yiannoutsou; C. Sintoris; N. Avouris","SoFar, Zakynthos, Greece; HCI Group, University of Patras, Patras, Greece; HCI Group, University of Patras, Patras, Greece; HCI Group, University of Patras, Patras, Greece","2014 International Conference on Interactive Mobile Communication Technologies and Learning (IMCL2014)","19 Jan 2015","2014","","","222","225","This paper presents a mobile augmented reality application, that was designed with the objective of visitors, to experience the historical center of old Zakynthos, Greece, that was destroyed after an earthquake, and allow the users to re-live the atmosphere and life of the historic place. Special attention is given to the mental model of the landmarks developed by the users after interacting with the application, discussing some of the observed flaws of this model.","","978-1-4799-4742-3","10.1109/IMCTL.2014.7011136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7011136","augmented realtity;location-based mobile game;cultural heritage","Games;Buildings;Cities and towns;Augmented reality;Mobile communication;Three-dimensional displays;Cultural differences","augmented reality;computer games;mobile computing","old Zakynthos;augmented reality mobile game;Greece;landmark mental model","","11","","11","IEEE","19 Jan 2015","","","IEEE","IEEE Conferences"
"Using optical flow as lightweight SLAM alternative","G. Bleser; G. Hendeby","Augmented Vision, German Research Center for Artificial Intelligence, Germany; Augmented Vision, German Research Center for Artificial Intelligence, Germany","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","175","176","Visual simultaneous localisation and mapping (SLAM) is since the last decades an often addressed problem. Online mapping enables tracking in unknown environments. However, it also suffers from high computational complexity and potential drift. Moreover, in augmented reality applications the map itself is often not needed and the target environment is partially known, e.g. in a few 3D anchor or marker points. In this paper, rather than using SLAM, measurements based on optical flow are introduced. With these measurements, a modified visual-inertial tracking method is derived, which in Monte Carlo simulations reduces the need for 3D points and allows tracking for extended periods of time without any 3D point registrations.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336475","augmented reality;camera tracking;visual SLAM;inertial sensors;sensor fusion;optical flow","Image motion analysis;Simultaneous localization and mapping;Optical sensors;Fluid flow measurement;Optical filters;Cameras;Optical variables control;Sensor fusion;Time measurement;Kinematics","augmented reality;computational complexity;flow measurement;image sequences;Monte Carlo methods;optical tracking;optical variables measurement","optical flow;lightweight SLAM;simultaneous visual localisation and mapping;online mapping;computational complexity;visual-inertial tracking method;Monte Carlo simulations;augmented reality applications","","4","2","9","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Glance-Box: Multi-LOD Glanceable Interfaces for Machine Shop Guidance in Augmented Reality using Blink and Hand Interaction","G. Daskalogrigorakis; A. McNamara; A. Marinakis; A. Antoniadis; K. Mania","Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; Department of Visualization, Texas A&M University, United States; Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; Electrical and Computer Engineering, Technical University of Crete, Chania, Greece","2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","15 Dec 2022","2022","","","315","321","Glanceable User Interfaces for Augmented Reality (AR) reveal virtual content “at a glance,” providing rapid information retrieval, often based on gaze interaction. They are ideal when the augmented content covers a small proportion of the view space. When the size of virtual content grows, the potential to occlude the real-world increases provoking safety concerns. Compounding this is the Midas Touch Problem, where users unintentionally select virtual elements by simply looking at them. Extending dwell time does not eliminate involuntary selections, impeding interaction time. In this work, we present Glance-Box, a novel interaction system for AR combining Glanceable interfaces and world-based $3\mathrm{D}$ interfaces across three Levels-Of-Detail, including progressively more information and visuals. Glance-box combines eye-gaze and hand interactions, focusing on user safety. A $2\mathrm{D}$ Glanceable interface facilitates rapid information retrieval at a glance, while extended $3\mathrm{D}$ interfaces provide interaction with denser content and $3\mathrm{D}$ objects. Glance-Box couples blink-based and gaze-based interactions to minimize errors arising from the Midas Touch Problem. While applicable across domains, the Glance-Box interface is designed and optimized for performing manufacturing tasks in the real world. We evaluated the Glance-Box interface using an object selection task of a manufacturing process. Participants completed tasks faster using Glance-Box, employing less dense LOD over time as they gained experience. The perceived accuracy of Glance-Box gaze-based input was high, even when the device's eye tracker accuracy was coarse.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974349","Human-centered computing;Mixed / augmented reality;Augmented Reality;Interaction Desing;Gaze-based interaction Human-centered computing;User interface design","Performance evaluation;Visualization;Three-dimensional displays;Tracking;Information retrieval;Safety;Manufacturing","augmented reality;eye;gaze tracking;human computer interaction;information retrieval;interactive systems;user interfaces;virtual reality","A2DGlanceable interface facilitates rapid information retrieval;augmented content;Augmented Reality;denser content;extended3Dinterfaces;gaze interaction;Glance-box combines eye-gaze;Glance-Box couples blink-based;Glance-Box gaze-based input;Glance-Box interface;Glanceable User Interfaces;hand interaction;including progressively more information;interaction time;machine shop guidance;Midas Touch Problem;multiLOD Glanceable Interfaces;novel interaction system;real-world increases;user safety;virtual content;virtual elements;visuals;world-based3Dinterfaces","","","","34","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Seeing the unseen: user experience and technology acceptance in Augmented Reality science literacy","I. Vrellis; M. Delimitros; P. Chalki; P. Gaintatzis; I. Bellou; T. A. Mikropoulos","Educational Approaches to Virtual Reality Technologies Lab, University of Ioannina, Ioannina, Greece; Educational Approaches to Virtual Reality Technologies Lab, University of Ioannina, Ioannina, Greece; Educational Approaches to Virtual Reality Technologies Lab, University of Ioannina, Ioannina, Greece; Educational Approaches to Virtual Reality Technologies Lab, University of Ioannina, Ioannina, Greece; Educational Approaches to Virtual Reality Technologies Lab, University of Ioannina, Ioannina, Greece; Educational Approaches to Virtual Reality Technologies Lab, University of Ioannina, Ioannina, Greece","2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)","4 Aug 2020","2020","","","333","337","Augmented Reality (AR) appears to have great potential in education and training. Although this technology has become mainstream through the use of handheld mobile devices, consumer-grade AR glasses are beginning to become available. These glasses could unlock the potential of AR by increasing freedom of movement, performance and safety. This preliminary study explores user experience and acceptance of state-of-the-art AR glasses. A simple activity was created to visualize electromagnetic radiation for science literacy purposes and then evaluated by university students (N=154). The results showed moderate spatial presence, low simulator sickness and high levels of acceptance and satisfaction.","2161-377X","978-1-7281-6090-0","10.1109/ICALT49669.2020.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155934","Augmented Reality;User experience;Presence;Simulator Sickness;Technology Acceptance","Glass;Visualization;Augmented reality;Training;Performance evaluation;Electromagnetic fields","augmented reality;computational electromagnetics;computer aided instruction;data visualisation;mobile computing;serious games (computing)","science literacy purposes;technology acceptance;Augmented Reality science literacy;handheld mobile devices;electromagnetic radiation visualization;consumer-grade AR glasses","","13","","15","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"A solution for navigating user-generated content","S. Uusitalo; P. Eskolin; P. Belimpasakis","Nokia Research Center, Mixed Reality Solutions, Finland; Nokia Research Center, Mixed Reality Solutions, Finland; Nokia Research Center, Mixed Reality Solutions, Finland","2009 8th IEEE International Symposium on Mixed and Augmented Reality","17 Nov 2009","2009","","","219","220","We are interested how to contextualize the digital content of an individual user with the help of content from other users, how to create a positive user experience from that, and what kind of interaction that can encourage between users. As a result the environment can be modelled. Creating a digital representation of the world from photographs is an exciting opportunity, for e.g. as a registering system for Augmented Reality (AR), forming one cornerstone for what Hollerer et al. call Anywhere Augmentation (AA). In this paper we present the user experience of the prototype and its key features. We have implemented a prototype solution for discovering shared digital media via a novel user interface, presenting the spatial relationships of the content.","","978-1-4244-5390-0","10.1109/ISMAR.2009.5336451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336451","","User-generated content;Prototypes;Augmented reality;Mirrors;Photography;Satellite navigation systems;Virtual reality;Videos;Digital cameras;Application software","augmented reality;data mining;multimedia computing;user interfaces","navigating user generated content;discovering shared digital media via user interface;content spatial relationship;individual user digital content;world digital representation","","7","","7","IEEE","17 Nov 2009","","","IEEE","IEEE Conferences"
"Augmented Reality for Industrial Building Acceptance","R. Schoenfelder; D. Schmalstieg","Graz University of Technology, Austria; Graz University of Technology, Austria","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","83","90","In this paper we present an augmented reality (AR) application for industrial building acceptance. Building acceptance is the process of comparing as-planned documentation with the factory that was actually built. A self-supported mobile AR device, the AR-planar, is used to facilitate this comparison by overlaying 3D models on top of a video image. The suitability of this approach is assessed using an expert heuristic in a real factory, and furthermore the usability of the AR-planar in comparison to other AR systems was examined in a complementary user study.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480755","H.5.1 [Information interfaces and presentation]: Multimedia Information Systems - Artificial, augmented, and virtual realities;H.5.2 [Information interfaces and presentation]: User Interfaces;J.7 [Computers in other systems]: Industrial control;ergonomics;user study;augmented reality","Augmented reality;Production facilities;Buildings;Construction industry;Strategic planning;Virtual manufacturing;Documentation;Usability;Virtual reality;User interfaces","augmented reality;ergonomics","augmented reality;industrial building acceptance;AR-Planar;3D models;video image","","25","3","20","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"An Empirical Study of Hear-Through Augmented Reality: Using Bone Conduction to Deliver Spatialized Audio","R. W. Lindeman; H. Noma; P. G. de Barros","Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA, USA; ATR International, Knowledge Science Labs, 2-2-2 Hikari-dai, Seika-cho, Souraku-gun, 619-0288 Kyoto, JAPAN, e-mail: noma@atr.jp; Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA, USA","2008 IEEE Virtual Reality Conference","4 Apr 2008","2008","","","35","42","Augmented reality (AR) is the mixing of computer-generated stimuli with real-world stimuli. In this paper, we present results from a controlled, empirical study comparing three ways of delivering spatialized audio for AR applications: a speaker array, headphones, and a bone-conduction headset. Analogous to optical-see-through AR in the visual domain, hear-through AR allows users to receive computer-generated audio using the bone-conduction headset, and real-world audio using their unoccluded ears. Our results show that subjects achieved the best accuracy using a speaker array physically located around the listener when stationary sounds were played, but that there was no difference in accuracy between the speaker array and the bone-conduction device for sounds that were moving, and that both devices outperformed standard headphones for moving sounds. Subjective comments by subjects following the experiment support this performance data.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480747","Augmented reality;audio;bone conduction;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Audio input/output;Artificial, augmented, and virtual realities","Augmented reality;Bones;Character generation;Ear;Headphones;Loudspeakers;Virtual reality;Frequency;Microphones;Irrigation","augmented reality;bone;handicapped aids;headphones;hearing aids","hear-through augmented reality;bone conduction;spatialized audio;computer-generated stimuli;speaker array;headphones","","9","","19","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"AHA: ADHD Augmented (Learning Environment)","E. Mangina; G. Chiazzese; T. Hasegawa","University College Dublin, Dublin, IE; Istituto per le Tecnologie Didattiche Consiglio Nazionale delle Ricerche, Genova, Liguria, IT; University College Dublin, Dublin, IE","2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)","17 Jan 2019","2018","","","774","777","Augmented Reality based learning solutions represent a challenge for utilization of emerging technologies within the context of educational systems, especially for children with special needs. AHA (AdHd Augmented) is a pilot project aimed to investigate how to effectively combine existing web-based technologies, embed Augmented Reality (AR) objects for a literacy programme in order to support the academic engagement and the literacy of students with Attention Deficit Hyperactivity Disorder (ADHD). The aim of the project, which is work in progress, is to evaluate the effect of the system on reading and spelling skills and study the effectiveness of AR on learning and task engagement for student with ADHD. Considerations, implications and future direction of the project are also be discussed.","2470-6698","978-1-5386-6522-0","10.1109/TALE.2018.8615222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615222","Computer Aided Instruction;Augmented Reality;Human Computer Interaction;ADHD","Education;Pediatrics;Stakeholders;Task analysis;Europe;Monitoring;Augmented reality","augmented reality;computer aided instruction;handicapped aids;Internet;medical disorders","AHA;ADHD Augmented;learning solutions;educational systems;AdHd Augmented;embed Augmented Reality;literacy programme;academic engagement;Attention Deficit Hyperactivity Disorder;task engagement;Web-based technologies","","8","","16","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"[DC] Auto-focus Augmented Reality Eyeglasses for both Real World and Virtual Imagery","P. Chakravarthula",UNC Chapel Hill,"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1379","1380","Near-eye displays presenting accommodation cues, thereby mitigating the vergence-accommodation conflict, have garnered interest in the recent past. However, considering that at least 40% of US population is presbyopic and similarly a sizable world population suffering other refractive errors in eye, it requires that the users wear their prescription glasses along with the AR goggles, despite focus support for virtual imagery, making the overall experience uncomfortable. In the recent work published at ISMAR-TVCG 2018, which won a Best Paper Award, my collaborators and I presented an AR display which can automatically adjust for focus for both real and virtual imagery, avoiding an extra pair of prescription correcting glasses along with AR glasses. My recent work has been on a near-eye display design which integrates with the bifocals of a presbyopic user, thereby providing depth dependent stimuli to the user who is already well adapted to bifocal lenses. A variant of these ideas are going to be presented at IEEE VR 2018 through our accepted TVCG paper. I propose that the above mentioned works combined with my future work on integrating eye trackers and depth sensors to make the display glasses more robust and completely automatic, followed by evaluating the perceptual qualities of the display are the topics of my dissertation.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797780","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797780","","Lenses;Glass;Liquids;Augmented reality;Sensors;Liquid crystal displays","augmented reality;eye;Gaussian processes;helmet mounted displays;image enhancement;image resolution;ophthalmic lenses;three-dimensional displays;vision defects","virtual imagery;near-eye displays;vergence-accommodation conflict;US population;sizable world population;refractive errors;experience uncomfortable;ISMAR-TVCG;Best Paper Award;AR display;prescription correcting glasses;AR glasses;near-eye display design;presbyopic user;IEEE VR 2018;accepted TVCG paper;eye trackers;display glasses;auto-focus augmented reality eyeglasses","","2","","16","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Extended Abstract: CoShopper - Leveraging Artificial Intelligence for an Enhanced Augmented Reality Grocery Shopping Experience","Y. Alhamdan; S. Alabachi; N. Khan","Master of Digital Media, Ryerson University, Toronto, Canada; Computer Engineering, University of Technology, Baghdad, Iraq; Master of Digital Media, Ryerson University, Toronto, Canada","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","337","338","This paper presents a system that integrates Artificial Intelligence (AI) methods with Augmented Reality (AR) techniques to enhance grocery shopping experience through the use of smart glasses. Our proposed framework deploys a Convolutional Neural Network (CNN) object detection model that allows for item identification. By simultaneously retrieving data from a large nutrition database, personal medical reports, and other grocery store related datasets, our intelligent system is able to provide user-centric nutrition facts, health and wellness tips, and unhealthy selection warnings that are augmented on a real time broadcasting of the smart glasses. Our state-of-the-art framework CoShopper demonstrates high accuracy in detecting grocery items, improves product selection, increases cost efficiency, and reduces the time spent in the process. Video demo of CoShopper can be viewed at [shorturl.at/mqIPX]","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319053","Augmented Reality;Artificial Intelligence;Deep Learning;Smart Grocery Shopping;Smart Glasses","Smart glasses;Visualization;Training;Streaming media;Real-time systems;Object recognition;Medical diagnostic imaging","augmented reality;consumer behaviour;convolutional neural nets;database management systems;object detection;retail data processing;user interfaces","smart glasses;convolutional neural network;object detection model;item identification;nutrition database;personal medical reports;grocery store related datasets;intelligent system;user-centric nutrition facts;unhealthy selection warnings;artificial intelligence methods;augmented reality grocery shopping experience;CoShopper;CNN;AR;AI","","2","","4","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"Integrating the Augmented Reality Toolkit with broadcast video chroma key systems","J. Pair; J. Wilson","NA; Biomedical Interactive Technology Center, Georgia Institute of Technology, USA","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","1 pp.","","The speed and visual quality of AR Toolkit applications is often restricted by a system's CPU, video capture card, or 3D acceleration hardware. Many AR toolkit users find that they must limit video resolution to 320/spl times/240. Furthermore, complex 3D geometry, textures, and animations can lower video frame rates forcing users to reduce the quality of their content. In broadcast and feature film production, chroma key techniques are used to composite real time 2D and 3D graphics with live scenes. This technique can be used in conjunction with the AR Toolkit to improve an application's 3D rendering and video capture performance.","","0-7803-7680-3","10.1109/ART.2002.1106967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106967","","Augmented reality;Multimedia communication;Broadcasting;Acceleration;Hardware;Geometry;Animation;Production;Graphics;Layout","augmented reality;rendering (computer graphics);video equipment;computer graphic equipment","Augmented Reality Toolkit;broadcast video chroma key systems;AR Toolkit applications;feature film production;real time 2D graphics;3D graphics;live scenes;3D rendering;video capture performance;compositing","","","","","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Assistance to maintenance in industrial process using an augmented reality system","N. Zenati; N. Zerhouni; K. Achour","Centre de Dévelopment des Technologies Avancées, Algeria; Labomtoire ďAutornatique de Besançon, France; Centre de Dévelopment des Technologies Avancées, Algeria","2004 IEEE International Conference on Industrial Technology, 2004. IEEE ICIT '04.","1 Aug 2005","2004","2","","848","852 Vol. 2","Augmented reality (AR) application is an excellent domain for maintenance task in industrial environment. It allows the user to see computer generated virtual objects superimposed upon the real world through the see-through head mounted display. Technician of maintenance when using this system can interact with the virtual world and have additional information, such as instruction for performing maintenance tasks inform of text messages, images, 3-D models of pieces or audio such as speech instruction. In this paper, we describe a prototype of a maintenance system based on distributed augmented reality in industrial context. For the good results of the virtual overlays, aspect of the usage of optical tracking system and the calibration procedures based on computer vision techniques are discussed.","","0-7803-8662-0","10.1109/ICIT.2004.1490185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1490185","","Augmented reality;Computer displays;Calibration;Industrial training;Cameras;Computer vision;Humans;Virtual reality;Assembly systems;Artificial intelligence","maintenance engineering;augmented reality;computer vision;optical tracking;calibration;helmet mounted displays","maintenance;industrial process;augmented reality system;computer vision;calibration;industrial environment;head mounted display;text messages;distributed augmented reality;virtual overlays;optical tracking","","5","1","17","IEEE","1 Aug 2005","","","IEEE","IEEE Conferences"
"Multi-ring color fiducial systems for scalable fiducial tracking augmented reality","Youngkwan Cho; U. Neumann","Computer Science Department Integrated Media Systems Centera, University of Southern California, USA; Computer Science Department Integrated Media Systems Centera, University of Southern California, USA","Proceedings. IEEE 1998 Virtual Reality Annual International Symposium (Cat. No.98CB36180)","6 Aug 2002","1998","","","212","","Registration is one of the major issues in augmented reality (AR). It requires high accuracy or an error-correction mechanism in tracking. Fiducial tracking has been gaining interest as a solution of the registration problem. A single-size fiducial might help fast fiducial detection, but the system will have a narrow tracking range, since all fiducials have the same detection range. Different size fiducials have different detection ranges, and by combining a series of different detection ranges from multi-size fiducials, the whole tracking range can be extended seamlessly. Multi-ring color fiducials have different number of rings at different fiducial levels. We extend the concentric circular fiducials to multi-ring, multi-size fiducial systems. These provide scalability to fiducial tracking AR. Because the fiducial systems are incremental, they allow the tracking range to be easily extended. The fiducial systems also introduce a large number of unique fiducials, and that makes fiducial identification easier. These fiducial systems help in building large-scale applications by providing a convenient way to unify multiple local coordinate systems. It makes it easy to determine fiducial positions in a large-scale application with a small-range digitizer. We analyze the optimality of ring widths and develop formulas to get an optimal set of fiducials easily for any size of working area by plugging in some system-specific parameters. We provide a simple and low-cost way to achieve wide-area tracking.","","0-8186-8362-7","10.1109/VRAIS.1998.658494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=658494","","Augmented reality;Cameras;Computer science;Computer errors;Virtual reality;Layout;Physics computing;Milling machines;Tracking;Scalability","tracking;virtual reality;image colour analysis;motion estimation;image registration","multi-ring color fiducial systems;scalable fiducial tracking;augmented reality;image registration;accuracy;error-correction mechanism;tracking range;detection range;multi-size fiducial systems;concentric circular fiducials;incremental systems;fiducial identification;large-scale applications;multiple local coordinate systems;small-range digitizer;optimal ring width;working area;system-specific parameters;wide-area tracking","","5","1","","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Understanding Multimodal User Gesture and Speech Behavior for Object Manipulation in Augmented Reality Using Elicitation","A. S. Williams; J. Garcia; F. Ortega","Computer Science Department, Colorado State University, Fort Collins, Colorado; Computer Science Department, Colorado State University, Fort Collins, Colorado; Computer Science Department, Colorado State University, Fort Collins, Colorado","IEEE Transactions on Visualization and Computer Graphics","10 Nov 2020","2020","26","12","3479","3489","The primary objective of this research is to understand how users manipulate virtual objects in augmented reality using multimodal interaction (gesture and speech) and unimodal interaction (gesture). Through this understanding, natural-feeling interactions can be designed for this technology. These findings are derived from an elicitation study employing Wizard of Oz design aimed at developing user-defined multimodal interaction sets for building tasks in 3D environments using optical see-through augmented reality headsets. The modalities tested are gesture and speech combined, gesture only, and speech only. The study was conducted with 24 participants. The canonical referents for translation, rotation, and scale were used along with some abstract referents (create, destroy, and select). A consensus set of gestures for interactions is provided. Findings include the types of gestures performed, the timing between co-occurring gestures and speech (130 milliseconds), perceived workload by modality (using NASA TLX), and design guidelines arising from this study. Multimodal interaction, in particular gesture and speech interactions for augmented reality headsets, are essential as this technology becomes the future of interactive computing. It is possible that in the near future, augmented reality glasses will become pervasive.","1941-0506","","10.1109/TVCG.2020.3023566","National Science Foundation (NSF)(grant numbers:NSF IIS-1948254,NSF BCS-1928502); Defense Advanced Research Projects Agency (DARPA) ARO(grant numbers:W911NF-15-1-0459); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199555","","Two dimensional displays;Augmented reality;Optical design;Gesture recognition;Speech recognition;Headphones","augmented reality;gesture recognition;user interfaces","speech behavior;multimodal user gesture;augmented reality glasses;interactive computing;speech interactions;augmented reality headsets;user-defined multimodal interaction sets;natural-feeling interactions;virtual objects;object manipulation;time 130.0 ms","Adolescent;Adult;Augmented Reality;Behavior;Computer Graphics;Female;Gestures;Humans;Male;Speech;User-Computer Interface;Virtual Reality;Young Adult","21","","66","IEEE","17 Sep 2020","","","IEEE","IEEE Journals"
"A Comparative Evaluation of a Virtual Reality Table and a HoloLens-Based Augmented Reality System for Anatomy Training","R. Serrano Vergel; P. Morillo Tena; S. Casas Yrurzum; C. Cruz-Neira","Emerging Analytics Center, University of Arkansas at Little Rock, Little Rock, USA; Institute on Robotics and Information and Communication Technologies, University of Valencia, València, Spain; Institute on Robotics and Information and Communication Technologies, University of Valencia, València, Spain; Agere Chair in Computer Science, University of Central Florida, Orlando, USA","IEEE Transactions on Human-Machine Systems","15 Jul 2020","2020","50","4","337","348","Anatomy training with real cadavers poses many practical problems for which new training and educational solutions have been developed making use of technologies based on real-time 3-D graphics. Although virtual reality (VR) and augmented reality (AR) have been previously used in the medical field, it is not easy to select the right 3-D technology or setup for each particular problem. For this reason, this article presents a comprehensive comparative study with 82 participants between two different 3-D interactive setups: an optical-based AR setup, implemented with a Microsoft HoloLens device, and a semi-immersive setup based on a VR Table. Both setups are tested using an anatomy training software application. Our primary hypothesis is that there would be statistically significant differences between the use of the AR application and the use of the VR Table. Our secondary hypothesis is that user preference and recommendation for the VR setup would be higher than for the HoloLens-based system. After completing two different tasks with both setups, the participants filled two questionnaires about the use of the anatomy training application. Three objective measures are also recorded (time, number of movements, and a score). The results of the experiments show that more than two-thirds of the users prefer, recommend, and find more useful the VR setup. The results also show that there are statistically significant differences in the use of both systems in favor of the VR Table.","2168-2305","","10.1109/THMS.2020.2984746","Spanish MINECO(grant numbers:RTI2018-098156-B-C55,RTC-2016-5336-7); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106786","Anatomy;augmented reality;comparative study;Microsoft HoloLens;training;virtual reality (VR);VR table","Training;Cadaver;TV;Augmented reality;Biomedical optical imaging;Hardware","augmented reality;biology computing;computer based training;human computer interaction","3D interactive setups;hololens-based augmented reality system;anatomy training application;HoloLens-based system;VR setup;user preference;primary hypothesis;anatomy training software application;semiimmersive setup;Microsoft HoloLens device;AR setup;medical field;real-time 3D graphics;educational solutions;augmented reality system;virtual reality table;comparative evaluation;VR Table;statistically significant differences","","32","","80","IEEE","2 Jun 2020","","","IEEE","IEEE Journals"
"Goal-Directed Reaching in Real, Augmented, and Virtual Environments","G. Resch; J. Manzone; T. Welsh; M. Nitsche; A. Mazalek","Synaesthetic Media Lab Ryerson University, Toronto, Canada; Action and Attention Lab University of Toronto, Toronto, Canada; Action and Attention Lab University of Toronto, Toronto, Canada; School of LMC Georgia Tech, Atlanta, United States; Synaesthetic Media Lab Ryerson University, Toronto, Canada","2021 International Conference on Advanced Learning Technologies (ICALT)","2 Aug 2021","2021","","","398","400","Multi-modal technologies, including augmented reality (AR) and virtual reality (VR), have become increasingly common in education and training contexts. Despite growing adoption of these technologies, our understanding of how basic perceptual-cognitive processes are influenced or altered by AR and VR mediation remains limited. The present paper describes a pilot study in which participants performed goal-directed reaching movements toward visual illusions in three different mediation conditions: unmediated reality (UR), AR, and VR. This pilot assessed whether the speed-accuracy relationship of reaching movements in different mediation conditions was modulated by contextual information surrounding a target. Preliminary results showed that there was a trend toward an effect of the contextual information in VR, but not in UR or AR. These findings may indicate that movements in VR are generated by different sensorimotor processes than in UR and AR.","2161-377X","978-1-6654-4106-3","10.1109/ICALT52272.2021.00127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499846","virtual reality;augmented reality;action planning","Training;Visualization;Virtual environments;Market research;Planning;Mediation;Augmented reality","augmented reality;biomechanics;cognition;neurophysiology","goal-directed reaching;augmented environments;virtual environments;multimodal technologies;virtual reality;VR;education;perceptual-cognitive processes;visual illusions;contextual information;sensorimotor processes;mediation conditions;UR;unmediated reality","","","","10","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"Augmented Reality Experience for Real-World Objects, Monuments, and Cities","C. Z. Basha; D. P. k. Reddy; S. R. P. Chand; A. Krishna","Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India","2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Oct 2021","2021","","","670","675","Augmented reality experience enables us to view real-world objects in 3D by overlapping real-world objects with digital 3d objects to provide a much-enhanced user experience. This paper explains and presents the ways to construct a 3D (3 Dimension) asset of the real world like cities, monuments, and other objects using blender and then the3D digital asset will be incorporated into our application. So that whenever our marker scans the object i.e., the 3D asset gets overlayed. The main idea of this concept is to experience real-world objects in the absence of real-world objects. Let us say that, a person wants to see the Eiffel tower and he/she searches it on Google. Now, the person could only see the images of Eiffel tower. To experience it in 3D he/she can use Google earth but it does not provide an original 3D experience. So, this is the point where augmented reality enters into the scene. The proposed research work has created a 3D asset by using a blender tool. Now, that asset will be imported and applied it to a marker. Whenever, this marker is scanned by using our application, the 3D effect of Eiffel tower will be overlayed on the screen. Augmented Reality is overlapping real-world objects with 3d objects. The main objective of augmented reality is that users cannot notice the discrepancy between augmented objects and real-world objects. AR is a wholly distinct technology, which helps our daily living and many other experiences so improved. It uses our most common hardware such as mobiles, cameras, etc. This makes this technology very beneficial and effortless to use. It is also a lot more different from VR in terms of hardware. But most of the purpose is the same.","","978-1-6654-3877-3","10.1109/ICIRCA51532.2021.9544792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544792","Augmented Reality;Vuforia;Blender;Unity;3D objects;Augmenting;Positioning;Tracking;Augmented Reality Applications","Industries;Three-dimensional displays;Poles and towers;Urban areas;Tools;Hardware;User experience","augmented reality;user experience","augmented reality experience;real-world objects;3D digital asset;monuments;cities;user experience","","1","","17","IEEE","1 Oct 2021","","","IEEE","IEEE Conferences"
"An Explore of Virtual Reality for Awareness of the Climate Change Crisis: A Simulation of Sea Level Rise","Z. Xu; Y. Liang; A. G. Campbell; S. Dev","School of Computer Science, University College Dublin, Dublin, Ireland; School of Computer Science, University College Dublin, Dublin, Ireland; School of Computer Science, University College Dublin, Dublin, Ireland; School of Computer Science, University College Dublin, Dublin, Ireland","2022 8th International Conference of the Immersive Learning Research Network (iLRN)","11 Jul 2022","2022","","","1","5","Virtual Reality (VR) technology has been shown to achieve remarkable results in multiple fields. Due to the nature of the immersive medium of Virtual Reality it logically follows that it can be used as a high-quality educational tool as it offers potentially a higher bandwidth than other mediums such as text, pictures and videos. This short paper illustrates the development of a climate change educational awareness application for virtual reality to simulate virtual scenes of local scenery and sea level rising until 2100 using prediction data. The paper also reports on the current in progress work of porting the system to Augmented Reality (AR) and future work to evaluate the system.","","978-1-7348995-3-5","10.23919/iLRN55037.2022.9815983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815983","virtual reality;climate change;environmental education;human-computer-interaction;augmented reality","COVID-19;Climate change;Solid modeling;Education;Bandwidth;Sea level;Augmented reality","augmented reality;computer aided instruction","augmented reality;sea level rise;climate change crisis;local scenery;virtual scenes;climate change educational awareness application;high-quality educational tool;immersive medium;virtual reality technology","","1","","15","","11 Jul 2022","","","IEEE","IEEE Conferences"
"[POSTER] Semantic Augmented Reality Environment with Material-Aware Physical Interactions","L. Chen; K. Francis; W. Tang",Bournemouth University; Bournemouth University; Bournemouth University,"2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","30 Oct 2017","2017","","","135","136","In Augmented Reality (AR) environment, realistic interactions between the virtual and real objects play a crucial role in user experience. Much of recent advances in AR has been largely focused on developing geometry-aware environment, but little has been done in dealing with interactions at the semantic level. High-level scene understanding and semantic descriptions in AR would allow effective design of complex applications and enhanced user experience. In this paper, we present a novel approach and a prototype system that enables the deeper understanding of semantic properties of the real world environment, so that realistic physical interactions between the real and the virtual objects can be generated. A material-aware AR environment has been created based on the deep material learning using a fully convolutional network (FCN). The state-of-the-art dense Simultaneous Localisation and Mapping (SLAM) has been used for the semantic mapping. Together with efficient accelerated 3D ray casting, natural and realistic physical interactions are generated for interactive AR games. Our approach has significant impact on the future development of advanced AR systems and applications.","","978-0-7695-6327-5","10.1109/ISMAR-Adjunct.2017.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088466","","Semantics;Three-dimensional displays;Solid modeling;Cameras;Games;Real-time systems;Simultaneous localization and mapping","augmented reality;computer games;feedforward neural nets;human factors;learning (artificial intelligence);SLAM (robots);virtual reality","high-level scene understanding;semantic descriptions;enhanced user experience;semantic properties;realistic physical interactions;virtual objects;material-aware AR environment;deep material learning;semantic mapping;interactive AR games;material-aware physical interactions;geometry-aware environment;semantic level;semantic Augmented Reality environment;accelerated 3D ray casting;simultaneous localisation and mapping","","2","","10","IEEE","30 Oct 2017","","","IEEE","IEEE Conferences"
"Augmented Reality Applications for Special Kids","A. S; S. A. T; H. S. Hotagi","Dept. of MCA, Ramaiah Institute of Technology, Bangalore, India; Dept. of MCA, Ramaiah Institute of Technology, Bangalore, India; Dept. of MCA, Ramaiah Institute of Technology, Bangalore, India","2022 4th International Conference on Circuits, Control, Communication and Computing (I4C)","7 Mar 2023","2022","","","382","386","As there is no medical test to detect some of the particular needs, there is much work to be done when it comes to caring for special children who have neuro-developmental disorders. Learning difficulties and poor social skills are special needs children's main problems. They are unable to converse like people in the physical world do. They can learn skills more effectively by using an augmented reality or augmented world to build these skills. It lessens the dread of close relationships. They employ virtual and augmented reality to hone their talents and as a platform for phobia therapy. Through the stimulation of augmented reality, these technologies provide children with straightforward techniques that help them become aware of and accepting of the real physical world. The understanding of concepts is enhanced when Augmented Reality (AR) and Virtual Reality (VR) are used in the teaching of special needs children. The stimulation of the real world and its objects, as opposed to learning from outdated or domestic teaching methods, can improve the experience of learning, understanding, and applying the knowledge or discipline gained from a process in the real world without the fear of being incorrect and by reducing the margin for error. This results in a child to have a regular life and a good education. In this work we have created an application using unity, vuforia, C#, android studio. Audio implemented in this app helps the children to learn the scenarios in English and Kannada. This app helps the parents and care taker to teach social behaviour to special children.","2381-4128","979-8-3503-9747-5","10.1109/I4C57141.2022.10057738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10057738","Augmented Reality;Virtual Reality;Special Kids;Social Needs;Unity;Vuforia;Audio","Solid modeling;Pediatrics;Operating systems;Education;Medical treatment;Medical tests;Boosting","augmented reality;computer aided instruction;medical computing;mobile computing;patient treatment;teaching;virtual reality","Augmented Reality applications;learning difficulties;physical world;poor social skills;special children;special kids;special needs children;Virtual Reality","","","","22","IEEE","7 Mar 2023","","","IEEE","IEEE Conferences"
"Perception and Action in Peripersonal Space: A Comparison Between Video and Optical See-Through Augmented Reality Devices","G. Ballestin; F. Solari; M. Chessa","Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Italy; Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Italy; Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Italy","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","184","189","In this paper, we analyze how we perceive the peripersonal space when involved in a reaching task in an Augmented Reality (AR) environment. In particular, we aim to quantify whether distortions in perception of the spatial layout of the scene occur, by taking into consideration two different AR wearable devices, in particular head-mounted displays (HMD). We performed two tests, and compared the results between the subjects who used an Optical See-Through (OST) HMD (Metavision Meta 2) and those who used a Video See-Through (VST) HMD (a smartphone in conjunction with a headset like the Google Cardboard). The data has been collected from a total of 45 volunteer participants. In the experiment, the subjects had to perform a precision reaching task by overlapping the hand on the perceived target position. Then, we observed how the presence or absence of an internal feedback influenced the homing performance. Our results revealed a better depth estimation, thus a more precise interaction, when using the OST device, which also revealed a lower impact on eye strain and fatigue.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699267","Human-centered computing [Human computer interaction (HCI)]:;—[Human-centered computing]: Human computer interaction (HCI)—Interaction paradigmsMixed / augmented reality;Human-centered computing [Human computer interaction (HCI)]: Empirical studies in HCI—","Resists;Task analysis;Cameras;Augmented reality;Performance evaluation;Headphones;Google","augmented reality;helmet mounted displays;human computer interaction;smart phones;wearable computers","Metavision Meta 2;Google Cardboard;precision reaching task;perceived target position;homing performance;OST device;peripersonal space;spatial layout;head-mounted displays;augmented reality environment;AR wearable devices;augmented reality devices;optical see-through HMD;video see-through HMD;smartphone","","10","","16","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
"Riverwalk: Incorporating Historical Photographs in Public Outdoor Augmented Reality Experiences","M. Cavallo; G. A. Rhodes; A. G. Forbes","Dept. of Computer Science, University Of Illinois, Chicago; Dept. of Visual Communication Design, School of the Art Institute, Chicago; Dept. of Computer Science, University Of Illinois, Chicago","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","160","165","This paper introduces a user-centered Augmented Reality (AR) approach for publishing 2D media archives as interactive content. We discuss the relevant technical considerations for developing an effective application for public outdoor AR experiences that leverage context-specific elements in a challenging, real-world environment. Specifically, we show how a classical marker-less approach can be combined with mobile sensors and geospatial information in order apply our knowledge of the surroundings to the experience itself. Our contributions provide the enabling technology for Chicago 0,0 Riverwalk, a novel app-based AR experience that superimposes historical imagery onto matching views in downtown Chicago, Illinois along an open, pedestrian waterfront located on the bank of the Chicago River. Historical photographs of sites along the river are superimposed onto buildings, bridges, and other architectural features through image-based AR tracking, providing a striking experience of the city's history as rooted in extant locations along the river.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836489","H.5.1 [Information interfaces and presentation (e.g. HCI)]: Multimedia Information Systems—Artificial;augmented and virtual realities","Cameras;Sensors;Two dimensional displays;Rivers;Three-dimensional displays;Augmented reality;Mobile communication","augmented reality;history;image processing;multimedia computing;user interfaces","historical photographs;public outdoor augmented reality experiences;user-centered augmented reality;2D media archive;interactive content;context-specific elements;mobile sensors;geospatial information;Chicago Riverwalk;historical imagery;Chicago Illinois;pedestrian waterfront;Chicago river;image-based AR tracking;multimedia information systems","","10","","17","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Enhancing Visitor Experience or Hindering Docent Roles: Attentional Issues in Augmented Reality Supported Installations","B. V. Syiem; R. M. Kelly; E. Velloso; J. Goncalves; T. Dingler","School of Computing and Information Systems, University of Melbourne; School of Computing and Information Systems, University of Melbourne; School of Computing and Information Systems, University of Melbourne; School of Computing and Information Systems, University of Melbourne; School of Computing and Information Systems, University of Melbourne","2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","279","288","Studies using augmented reality (AR) technology have suggested that users focus excessively on the virtual content in the AR environment at the expense of the physical world around them. This has implications related to the design of installations that aim to incorporate the user's physical environment as part of the AR experience. To better understand how user attention is managed in an AR environment, we present an observational study of Rewild Our Planet, a multi-modal installation that combined video, audio, a human docent and mobile AR to promote awareness about environmental issues. We found that, while AR was successful in engaging visitors, it drew attention away from other modalities within the installation. This impacts the work of the human docent and affects how visitors absorb information presented in the installation. Based on these observations, we present guidelines to inform the design of future AR-supported installations with the aim of minimizing or taking advantage of the observed attentional issues.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284688","Human-centered computing;Mixed / augmented reality;Human-centered computing;Empirical studies in HCI;Human-centered computing;Field studies","Planets;User experience;Augmented reality;Guidelines","augmented reality;user interfaces","visitor experience;hindering docent roles;augmented reality supported installations;virtual content;AR environment;physical world;AR experience;user attention;Rewild Our Planet;multimodal installation;human docent;environmental issues;observed attentional issues;AR-supported installations;augmented reality technology;user physical environment;mobile AR","","3","","61","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Small Marker Tracking with Low-Cost, Unsynchronized, Movable Consumer Cameras For Augmented Reality Surgical Training","N. Rewkowski; A. State; H. Fuchs","UNC Chapel Hill, UMD College Park; UNC Chapel Hill; UNC Chapel Hill","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","90","95","Surgeons improve their skills through repetition of training tasks in order to operate on living patients, ideally receiving timely, useful, and objective performance feedback. However, objective performance measurement is currently difficult without 3D visualization, with effective surgical training apparatus being extremely expensive or limited in accessibility. This is problematic for medical students, especially in situations such as the COVID-19 pandemic in which they are needed by the community but have few ways of practicing without lab access. In this work, we propose and prototype a system for augmented reality (AR) visualization of laparoscopic training tasks using cheap and widely-compatible borescopes, which can track small objects typical of surgical training. We use forward kinematics for calibration and multi-threading to attempt synchronization in order to increase compatibility with consumer applications, resulting in an effective AR simulation with low-cost devices and consumer software, while also providing dynamic camera and marker tracking. We test the system with a typical peg transfer task on the HoloLens 1 and MagicLeap One.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288414","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Computing methodologies;Artificial intelligence;Computer vision;Computer vision problems;Tracking","Training;Visualization;Three-dimensional displays;Surgery;Cameras;Task analysis;Augmented reality","augmented reality;computer based training;medical computing;medical image processing;object tracking;surgery","MagicLeap One;HoloLens 1;surgical training apparatus;peg transfer task;dynamic camera;consumer software;low-cost devices;AR simulation;consumer applications;widely-compatible borescopes;laparoscopic training tasks;augmented reality visualization;COVID-19 pandemic;medical students;objective performance measurement;objective performance feedback;augmented reality surgical training;movable consumer cameras;marker tracking","","3","","35","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Co-creativity fusions in interdisciplinary augmented reality game developments","R. K. C. Koh; H. B. -L. Duh; Cheng-Ho Chen; Yun-Ting Wong","Keio-NUS CUTE Center/IDMI, National University of Singapore, Singapore; Keio-NUS CUTE Center/IDMI, National University of Singapore, Singapore; Keio-NUS CUTE Center/IDMI, National University of Singapore, Singapore; Keio-NUS CUTE Center/IDMI, National University of Singapore, Singapore","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)","21 Mar 2013","2012","","","47","56","This paper recognizes and reflects upon the important co-creativity roles and intimacies that arts students may play in increasingly interdisciplinary environments where research and design potentials of evolving new media technologies are being explored. We report a real-world case study where two students played the dedicated artists' roles of art and game design developments while working with staff researchers from technical, design and social science (education) backgrounds to develop an outdoor location-based handheld augmented reality game project. The paper relates how a clearer understanding of such didactic situations can empower and invoke co-evolutions of both art and technology.","2381-8360","978-1-4673-4665-8","10.1109/ISMAR-AMH.2012.6483988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483988","Interdisciplinary Research;Augmented Reality;Human-Computer Interaction;Games","Games;Art;Collaboration;Educational institutions;Visualization;Augmented reality","art;augmented reality;computer games","interdisciplinary augmented reality game developments;media technologies;art;outdoor location-based handheld augmented reality game project;didactic situations","","2","","45","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Layerable Apps: Comparing Concurrent and Exclusive Display of Augmented Reality Applications","B. Huynh; A. Wysopal; V. Ross; J. Orlosky; T. Höllerer","University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara; Augusta University and Osaka University; University of California, Santa Barbara","2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","27 Dec 2022","2022","","","857","863","Current augmented reality (AR) interfaces are often designed for interacting with one application at a time, significantly limiting a user’s ability to concurrently interact with and switch between multiple applications or modalities that could run in parallel. In this work, we introduce an application model called Layerable Apps, which supports a variety of AR application types while enabling multitasking through concurrent execution, fast application switching, and the ability to layer application views to adjust the degree of augmentation to the user’s preference. We evaluated Layerable Apps through a within-subjects user study (n=44), compared against a traditional single-focus application model on a split-information task involving the simultaneous use of multiple applications. We report the results of our study, where we found differences in quantitative task performance, favoring Layerable mode. We also analyzed app usage patterns, spatial awareness, and overall preferences between both modes as well as between experienced and novice AR users.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00104","Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995039","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Interaction design;Interaction design process and methods;User interface design","Limiting;Prototypes;Switches;Multitasking;Task analysis;Augmented reality","augmented reality;mobile computing;user interfaces","app usage patterns;AR application types;augmented reality applications;augmented reality interfaces;concurrent display;concurrent execution;exclusive display;experienced novice AR users;fast application switching;layer application views;layerable apps;layerable mode;single-focus application model;within-subjects user study","","","","34","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"A Sense of Quality for Augmented Reality Assisted Process Guidance","A. Redžepagić; C. Löffler; T. Feigl; C. Mutschler","Friedrich-Alexander University Erlangen-Nuremberg (FAU), Erlangen, Germany; Friedrich-Alexander University Erlangen-Nuremberg (FAU), Erlangen, Germany; Friedrich-Alexander University Erlangen-Nuremberg (FAU), Erlangen, Germany; Fraunhofer Institute for Integrated Cirtuits IIS, Nuremberg, Germany","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","129","134","The ongoing automation of modern production processes requires novel human-computer interaction concepts that support employees in dealing with the unstoppable increase in time pressure, cognitive load, and the required fine-grained and process-specific knowledge. Augmented Reality (AR) systems support employees by guiding and teaching work processes. Such systems still lack a precise process quality analysis (monitoring), which is, however, crucial to close gaps in the quality assurance of industrial processes.We combine inertial sensors, mounted on work tools, with AR headsets to enrich modern assistance systems with a sense of process quality. For this purpose, we develop a Machine Learning (ML) classifier that predicts quality metrics from a 9-degrees of freedom inertial measurement unit, while we simultaneously guide and track the work processes with a HoloLens AR system. In our user study, 6 test subjects perform typical assembly tasks with our system. We evaluate the tracking accuracy of the system based on a precise optical reference system and evaluate the classification of each work step quality based on the collected ground truth data. Our evaluation shows a tracking accuracy of fast dynamic movements of 4.92mm and our classifier predicts the actions carried out with mean F1 value of 93.8% on average.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288435","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality","Quality assurance;Measurement units;Tracking;Tools;Task analysis;Augmented reality;Monitoring","assembling;augmented reality;human computer interaction;learning (artificial intelligence);pattern classification;personnel;production engineering computing;quality assurance","assembly tasks;HoloLens AR system;9-degrees of freedom inertial measurement unit;machine learning classifier;AR headsets;process-specific knowledge;employees;augmented reality assisted process guidance;process quality analysis;work step quality;optical reference system;tracking accuracy;quality metrics;assistance systems;work tools;inertial sensors;industrial processes;quality assurance;augmented reality systems;cognitive load;time pressure;human-computer interaction;production processes","","","","21","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Indirect Augmented Reality Browser for GIS Data","P. Skinner; J. Ventura; S. Zollmann","University of Otago; Colorado Springs, University of Colorado; University of Otago","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","145","150","In Augmented Reality applications, user experience is highly dependent on the accuracy of registration between digital content and the real world. Errors in tracking and registration can arise due to inaccuracy of sensors or challenging conditions such as urban canyon effects or magnetic distortions. Indirect augmented reality is an approach that avoid these issues by using precaptured and preregistered images instead of a live video feed. However, indirect augmented reality highly depends on the availability of those preregistered images. In particular, when being used for browsing geographic information, it is important to access data in an omnipresent way. In this work, we propose an Indirect Augmented Reality browser that aims to address these availability problems by combining indirect Augmented Reality with crowd sourced precaptured street level imagery with geospatial data. We demonstrate how our indirect augmented reality browser annotates buildings and landmarks in the users' environment and investigate the feasibility by analysing the performance of such an approach. In addition, we investigate issues of visibility and legibility when labelling the environment.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699275","Human-centered computing—Visualization—Visualization application domains—Geographic visualization;Human-centered computing—Human computer interaction (HCI)— Interaction paradigms—Mixed / augmented reality","Browsers;Augmented reality;Buildings;Three-dimensional displays;Cameras;User experience;Databases","augmented reality;geographic information systems;image registration","preregistered images;indirect augmented reality browser;GIS data;precaptured images;geographic information;crowd sourced precaptured street level imagery;geospatial data","","3","","14","IEEE","29 Apr 2019","","","IEEE","IEEE Conferences"
